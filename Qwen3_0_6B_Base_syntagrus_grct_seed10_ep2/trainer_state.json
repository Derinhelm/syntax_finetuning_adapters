{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 8704,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00022977941176470588,
      "grad_norm": 2.427452802658081,
      "learning_rate": 0.0,
      "loss": 2.5655,
      "step": 1
    },
    {
      "epoch": 0.00045955882352941176,
      "grad_norm": 2.6721720695495605,
      "learning_rate": 4.595588235294118e-09,
      "loss": 2.9265,
      "step": 2
    },
    {
      "epoch": 0.0006893382352941177,
      "grad_norm": 2.641021966934204,
      "learning_rate": 9.191176470588236e-09,
      "loss": 2.6744,
      "step": 3
    },
    {
      "epoch": 0.0009191176470588235,
      "grad_norm": 2.8754231929779053,
      "learning_rate": 1.3786764705882355e-08,
      "loss": 2.8578,
      "step": 4
    },
    {
      "epoch": 0.0011488970588235295,
      "grad_norm": 2.5390079021453857,
      "learning_rate": 1.8382352941176472e-08,
      "loss": 2.6876,
      "step": 5
    },
    {
      "epoch": 0.0013786764705882354,
      "grad_norm": 2.7553598880767822,
      "learning_rate": 2.297794117647059e-08,
      "loss": 2.8642,
      "step": 6
    },
    {
      "epoch": 0.001608455882352941,
      "grad_norm": 2.363079071044922,
      "learning_rate": 2.757352941176471e-08,
      "loss": 2.5175,
      "step": 7
    },
    {
      "epoch": 0.001838235294117647,
      "grad_norm": 2.8532114028930664,
      "learning_rate": 3.216911764705883e-08,
      "loss": 2.9333,
      "step": 8
    },
    {
      "epoch": 0.002068014705882353,
      "grad_norm": 2.7540500164031982,
      "learning_rate": 3.6764705882352945e-08,
      "loss": 2.8783,
      "step": 9
    },
    {
      "epoch": 0.002297794117647059,
      "grad_norm": 3.010209798812866,
      "learning_rate": 4.136029411764706e-08,
      "loss": 3.0001,
      "step": 10
    },
    {
      "epoch": 0.002527573529411765,
      "grad_norm": 2.877033233642578,
      "learning_rate": 4.595588235294118e-08,
      "loss": 3.0253,
      "step": 11
    },
    {
      "epoch": 0.0027573529411764708,
      "grad_norm": 2.6778688430786133,
      "learning_rate": 5.05514705882353e-08,
      "loss": 2.8755,
      "step": 12
    },
    {
      "epoch": 0.0029871323529411763,
      "grad_norm": 2.6891210079193115,
      "learning_rate": 5.514705882352942e-08,
      "loss": 2.733,
      "step": 13
    },
    {
      "epoch": 0.003216911764705882,
      "grad_norm": 2.7394959926605225,
      "learning_rate": 5.974264705882352e-08,
      "loss": 2.9902,
      "step": 14
    },
    {
      "epoch": 0.003446691176470588,
      "grad_norm": 2.91416335105896,
      "learning_rate": 6.433823529411765e-08,
      "loss": 2.9551,
      "step": 15
    },
    {
      "epoch": 0.003676470588235294,
      "grad_norm": 2.838265895843506,
      "learning_rate": 6.893382352941177e-08,
      "loss": 2.8755,
      "step": 16
    },
    {
      "epoch": 0.00390625,
      "grad_norm": 2.7998554706573486,
      "learning_rate": 7.352941176470589e-08,
      "loss": 3.0376,
      "step": 17
    },
    {
      "epoch": 0.004136029411764706,
      "grad_norm": 3.258572578430176,
      "learning_rate": 7.8125e-08,
      "loss": 3.0379,
      "step": 18
    },
    {
      "epoch": 0.004365808823529412,
      "grad_norm": 2.6419355869293213,
      "learning_rate": 8.272058823529412e-08,
      "loss": 2.8381,
      "step": 19
    },
    {
      "epoch": 0.004595588235294118,
      "grad_norm": 2.726670503616333,
      "learning_rate": 8.731617647058824e-08,
      "loss": 2.9214,
      "step": 20
    },
    {
      "epoch": 0.004825367647058824,
      "grad_norm": 2.5182998180389404,
      "learning_rate": 9.191176470588236e-08,
      "loss": 2.9195,
      "step": 21
    },
    {
      "epoch": 0.00505514705882353,
      "grad_norm": 2.1715166568756104,
      "learning_rate": 9.650735294117649e-08,
      "loss": 2.5337,
      "step": 22
    },
    {
      "epoch": 0.005284926470588236,
      "grad_norm": 2.8113484382629395,
      "learning_rate": 1.011029411764706e-07,
      "loss": 2.9603,
      "step": 23
    },
    {
      "epoch": 0.0055147058823529415,
      "grad_norm": 2.772958517074585,
      "learning_rate": 1.0569852941176472e-07,
      "loss": 2.9079,
      "step": 24
    },
    {
      "epoch": 0.0057444852941176475,
      "grad_norm": 2.634983777999878,
      "learning_rate": 1.1029411764705884e-07,
      "loss": 2.7897,
      "step": 25
    },
    {
      "epoch": 0.0059742647058823525,
      "grad_norm": 2.78686785697937,
      "learning_rate": 1.1488970588235296e-07,
      "loss": 2.9553,
      "step": 26
    },
    {
      "epoch": 0.0062040441176470585,
      "grad_norm": 2.3940317630767822,
      "learning_rate": 1.1948529411764705e-07,
      "loss": 2.6585,
      "step": 27
    },
    {
      "epoch": 0.006433823529411764,
      "grad_norm": 3.265164375305176,
      "learning_rate": 1.240808823529412e-07,
      "loss": 3.0938,
      "step": 28
    },
    {
      "epoch": 0.00666360294117647,
      "grad_norm": 2.625317096710205,
      "learning_rate": 1.286764705882353e-07,
      "loss": 2.7484,
      "step": 29
    },
    {
      "epoch": 0.006893382352941176,
      "grad_norm": 3.0086255073547363,
      "learning_rate": 1.3327205882352943e-07,
      "loss": 2.6606,
      "step": 30
    },
    {
      "epoch": 0.007123161764705882,
      "grad_norm": 2.6605045795440674,
      "learning_rate": 1.3786764705882354e-07,
      "loss": 2.8099,
      "step": 31
    },
    {
      "epoch": 0.007352941176470588,
      "grad_norm": 2.4035818576812744,
      "learning_rate": 1.4246323529411766e-07,
      "loss": 2.6955,
      "step": 32
    },
    {
      "epoch": 0.007582720588235294,
      "grad_norm": 2.8461592197418213,
      "learning_rate": 1.4705882352941178e-07,
      "loss": 2.8777,
      "step": 33
    },
    {
      "epoch": 0.0078125,
      "grad_norm": 2.612048864364624,
      "learning_rate": 1.516544117647059e-07,
      "loss": 2.9112,
      "step": 34
    },
    {
      "epoch": 0.008042279411764705,
      "grad_norm": 2.9773621559143066,
      "learning_rate": 1.5625e-07,
      "loss": 3.1578,
      "step": 35
    },
    {
      "epoch": 0.008272058823529412,
      "grad_norm": 2.73818039894104,
      "learning_rate": 1.608455882352941e-07,
      "loss": 2.8251,
      "step": 36
    },
    {
      "epoch": 0.008501838235294117,
      "grad_norm": 2.68778657913208,
      "learning_rate": 1.6544117647058825e-07,
      "loss": 2.9103,
      "step": 37
    },
    {
      "epoch": 0.008731617647058824,
      "grad_norm": 2.501868486404419,
      "learning_rate": 1.7003676470588236e-07,
      "loss": 2.6857,
      "step": 38
    },
    {
      "epoch": 0.008961397058823529,
      "grad_norm": 2.6993355751037598,
      "learning_rate": 1.7463235294117648e-07,
      "loss": 2.8023,
      "step": 39
    },
    {
      "epoch": 0.009191176470588236,
      "grad_norm": 2.810021162033081,
      "learning_rate": 1.792279411764706e-07,
      "loss": 2.9503,
      "step": 40
    },
    {
      "epoch": 0.00942095588235294,
      "grad_norm": 2.8239598274230957,
      "learning_rate": 1.8382352941176472e-07,
      "loss": 2.9689,
      "step": 41
    },
    {
      "epoch": 0.009650735294117647,
      "grad_norm": 2.7430429458618164,
      "learning_rate": 1.8841911764705883e-07,
      "loss": 2.7748,
      "step": 42
    },
    {
      "epoch": 0.009880514705882353,
      "grad_norm": 2.465785264968872,
      "learning_rate": 1.9301470588235298e-07,
      "loss": 2.7734,
      "step": 43
    },
    {
      "epoch": 0.01011029411764706,
      "grad_norm": 2.2819554805755615,
      "learning_rate": 1.9761029411764707e-07,
      "loss": 2.7272,
      "step": 44
    },
    {
      "epoch": 0.010340073529411764,
      "grad_norm": 3.1632800102233887,
      "learning_rate": 2.022058823529412e-07,
      "loss": 2.9949,
      "step": 45
    },
    {
      "epoch": 0.010569852941176471,
      "grad_norm": 2.5545108318328857,
      "learning_rate": 2.068014705882353e-07,
      "loss": 2.7085,
      "step": 46
    },
    {
      "epoch": 0.010799632352941176,
      "grad_norm": 2.8543219566345215,
      "learning_rate": 2.1139705882352945e-07,
      "loss": 2.8536,
      "step": 47
    },
    {
      "epoch": 0.011029411764705883,
      "grad_norm": 3.0928096771240234,
      "learning_rate": 2.1599264705882354e-07,
      "loss": 3.2742,
      "step": 48
    },
    {
      "epoch": 0.011259191176470588,
      "grad_norm": 2.759774684906006,
      "learning_rate": 2.2058823529411768e-07,
      "loss": 2.9116,
      "step": 49
    },
    {
      "epoch": 0.011488970588235295,
      "grad_norm": 2.8053555488586426,
      "learning_rate": 2.2518382352941177e-07,
      "loss": 2.9097,
      "step": 50
    },
    {
      "epoch": 0.01171875,
      "grad_norm": 2.8031485080718994,
      "learning_rate": 2.2977941176470592e-07,
      "loss": 2.9329,
      "step": 51
    },
    {
      "epoch": 0.011948529411764705,
      "grad_norm": 2.414836883544922,
      "learning_rate": 2.3437500000000003e-07,
      "loss": 2.659,
      "step": 52
    },
    {
      "epoch": 0.012178308823529412,
      "grad_norm": 3.186929225921631,
      "learning_rate": 2.389705882352941e-07,
      "loss": 3.0387,
      "step": 53
    },
    {
      "epoch": 0.012408088235294117,
      "grad_norm": 2.3429160118103027,
      "learning_rate": 2.4356617647058827e-07,
      "loss": 2.6109,
      "step": 54
    },
    {
      "epoch": 0.012637867647058824,
      "grad_norm": 2.3306286334991455,
      "learning_rate": 2.481617647058824e-07,
      "loss": 2.7197,
      "step": 55
    },
    {
      "epoch": 0.012867647058823529,
      "grad_norm": 2.5156478881835938,
      "learning_rate": 2.527573529411765e-07,
      "loss": 2.7927,
      "step": 56
    },
    {
      "epoch": 0.013097426470588236,
      "grad_norm": 2.9199187755584717,
      "learning_rate": 2.573529411764706e-07,
      "loss": 2.92,
      "step": 57
    },
    {
      "epoch": 0.01332720588235294,
      "grad_norm": 2.4834749698638916,
      "learning_rate": 2.6194852941176474e-07,
      "loss": 2.7173,
      "step": 58
    },
    {
      "epoch": 0.013556985294117647,
      "grad_norm": 2.52475643157959,
      "learning_rate": 2.6654411764705885e-07,
      "loss": 2.7621,
      "step": 59
    },
    {
      "epoch": 0.013786764705882353,
      "grad_norm": 2.357027530670166,
      "learning_rate": 2.7113970588235297e-07,
      "loss": 2.727,
      "step": 60
    },
    {
      "epoch": 0.01401654411764706,
      "grad_norm": 2.6130292415618896,
      "learning_rate": 2.757352941176471e-07,
      "loss": 2.8539,
      "step": 61
    },
    {
      "epoch": 0.014246323529411764,
      "grad_norm": 2.7512989044189453,
      "learning_rate": 2.803308823529412e-07,
      "loss": 3.018,
      "step": 62
    },
    {
      "epoch": 0.014476102941176471,
      "grad_norm": 2.2571425437927246,
      "learning_rate": 2.849264705882353e-07,
      "loss": 2.5426,
      "step": 63
    },
    {
      "epoch": 0.014705882352941176,
      "grad_norm": 2.788440704345703,
      "learning_rate": 2.8952205882352944e-07,
      "loss": 2.984,
      "step": 64
    },
    {
      "epoch": 0.014935661764705883,
      "grad_norm": 2.661285877227783,
      "learning_rate": 2.9411764705882356e-07,
      "loss": 2.8096,
      "step": 65
    },
    {
      "epoch": 0.015165441176470588,
      "grad_norm": 2.613746166229248,
      "learning_rate": 2.987132352941177e-07,
      "loss": 2.6986,
      "step": 66
    },
    {
      "epoch": 0.015395220588235295,
      "grad_norm": 2.9084179401397705,
      "learning_rate": 3.033088235294118e-07,
      "loss": 2.9119,
      "step": 67
    },
    {
      "epoch": 0.015625,
      "grad_norm": 2.275167465209961,
      "learning_rate": 3.079044117647059e-07,
      "loss": 2.5685,
      "step": 68
    },
    {
      "epoch": 0.015854779411764705,
      "grad_norm": 2.4643259048461914,
      "learning_rate": 3.125e-07,
      "loss": 2.7513,
      "step": 69
    },
    {
      "epoch": 0.01608455882352941,
      "grad_norm": 2.3439810276031494,
      "learning_rate": 3.1709558823529414e-07,
      "loss": 2.7449,
      "step": 70
    },
    {
      "epoch": 0.01631433823529412,
      "grad_norm": 3.042628288269043,
      "learning_rate": 3.216911764705882e-07,
      "loss": 2.8741,
      "step": 71
    },
    {
      "epoch": 0.016544117647058824,
      "grad_norm": 2.462540626525879,
      "learning_rate": 3.262867647058824e-07,
      "loss": 2.5251,
      "step": 72
    },
    {
      "epoch": 0.01677389705882353,
      "grad_norm": 2.611513376235962,
      "learning_rate": 3.308823529411765e-07,
      "loss": 2.9069,
      "step": 73
    },
    {
      "epoch": 0.017003676470588234,
      "grad_norm": 2.4993531703948975,
      "learning_rate": 3.354779411764706e-07,
      "loss": 2.6794,
      "step": 74
    },
    {
      "epoch": 0.017233455882352942,
      "grad_norm": 2.738124370574951,
      "learning_rate": 3.4007352941176473e-07,
      "loss": 2.9558,
      "step": 75
    },
    {
      "epoch": 0.017463235294117647,
      "grad_norm": 2.8961679935455322,
      "learning_rate": 3.446691176470589e-07,
      "loss": 2.7501,
      "step": 76
    },
    {
      "epoch": 0.017693014705882353,
      "grad_norm": 2.5847043991088867,
      "learning_rate": 3.4926470588235296e-07,
      "loss": 2.7921,
      "step": 77
    },
    {
      "epoch": 0.017922794117647058,
      "grad_norm": 2.352642297744751,
      "learning_rate": 3.538602941176471e-07,
      "loss": 2.7854,
      "step": 78
    },
    {
      "epoch": 0.018152573529411766,
      "grad_norm": 2.975900173187256,
      "learning_rate": 3.584558823529412e-07,
      "loss": 3.0958,
      "step": 79
    },
    {
      "epoch": 0.01838235294117647,
      "grad_norm": 2.5848805904388428,
      "learning_rate": 3.6305147058823537e-07,
      "loss": 3.0601,
      "step": 80
    },
    {
      "epoch": 0.018612132352941176,
      "grad_norm": 2.635469913482666,
      "learning_rate": 3.6764705882352943e-07,
      "loss": 2.803,
      "step": 81
    },
    {
      "epoch": 0.01884191176470588,
      "grad_norm": 2.505124092102051,
      "learning_rate": 3.7224264705882355e-07,
      "loss": 2.9112,
      "step": 82
    },
    {
      "epoch": 0.01907169117647059,
      "grad_norm": 2.544710159301758,
      "learning_rate": 3.7683823529411767e-07,
      "loss": 2.8261,
      "step": 83
    },
    {
      "epoch": 0.019301470588235295,
      "grad_norm": 2.7540786266326904,
      "learning_rate": 3.8143382352941184e-07,
      "loss": 2.7017,
      "step": 84
    },
    {
      "epoch": 0.01953125,
      "grad_norm": 3.002431869506836,
      "learning_rate": 3.8602941176470595e-07,
      "loss": 2.989,
      "step": 85
    },
    {
      "epoch": 0.019761029411764705,
      "grad_norm": 2.485623598098755,
      "learning_rate": 3.90625e-07,
      "loss": 2.8592,
      "step": 86
    },
    {
      "epoch": 0.01999080882352941,
      "grad_norm": 2.8979475498199463,
      "learning_rate": 3.9522058823529414e-07,
      "loss": 2.9907,
      "step": 87
    },
    {
      "epoch": 0.02022058823529412,
      "grad_norm": 2.7473490238189697,
      "learning_rate": 3.9981617647058825e-07,
      "loss": 2.7915,
      "step": 88
    },
    {
      "epoch": 0.020450367647058824,
      "grad_norm": 2.6798095703125,
      "learning_rate": 4.044117647058824e-07,
      "loss": 2.718,
      "step": 89
    },
    {
      "epoch": 0.02068014705882353,
      "grad_norm": 2.9157867431640625,
      "learning_rate": 4.090073529411765e-07,
      "loss": 2.7932,
      "step": 90
    },
    {
      "epoch": 0.020909926470588234,
      "grad_norm": 2.5715527534484863,
      "learning_rate": 4.136029411764706e-07,
      "loss": 2.6336,
      "step": 91
    },
    {
      "epoch": 0.021139705882352942,
      "grad_norm": 3.124891996383667,
      "learning_rate": 4.181985294117647e-07,
      "loss": 2.9823,
      "step": 92
    },
    {
      "epoch": 0.021369485294117647,
      "grad_norm": 2.59019136428833,
      "learning_rate": 4.227941176470589e-07,
      "loss": 2.811,
      "step": 93
    },
    {
      "epoch": 0.021599264705882353,
      "grad_norm": 2.2032339572906494,
      "learning_rate": 4.27389705882353e-07,
      "loss": 2.5912,
      "step": 94
    },
    {
      "epoch": 0.021829044117647058,
      "grad_norm": 2.432255506515503,
      "learning_rate": 4.319852941176471e-07,
      "loss": 2.6074,
      "step": 95
    },
    {
      "epoch": 0.022058823529411766,
      "grad_norm": 3.5143520832061768,
      "learning_rate": 4.365808823529412e-07,
      "loss": 3.1458,
      "step": 96
    },
    {
      "epoch": 0.02228860294117647,
      "grad_norm": 2.6182520389556885,
      "learning_rate": 4.4117647058823536e-07,
      "loss": 2.9717,
      "step": 97
    },
    {
      "epoch": 0.022518382352941176,
      "grad_norm": 2.8021156787872314,
      "learning_rate": 4.457720588235295e-07,
      "loss": 3.1457,
      "step": 98
    },
    {
      "epoch": 0.02274816176470588,
      "grad_norm": 2.816843032836914,
      "learning_rate": 4.5036764705882354e-07,
      "loss": 2.8975,
      "step": 99
    },
    {
      "epoch": 0.02297794117647059,
      "grad_norm": 2.647676706314087,
      "learning_rate": 4.5496323529411766e-07,
      "loss": 2.8385,
      "step": 100
    },
    {
      "epoch": 0.023207720588235295,
      "grad_norm": 2.626728057861328,
      "learning_rate": 4.5955882352941183e-07,
      "loss": 2.7714,
      "step": 101
    },
    {
      "epoch": 0.0234375,
      "grad_norm": 2.74303936958313,
      "learning_rate": 4.6415441176470595e-07,
      "loss": 2.6702,
      "step": 102
    },
    {
      "epoch": 0.023667279411764705,
      "grad_norm": 2.736738443374634,
      "learning_rate": 4.6875000000000006e-07,
      "loss": 2.9504,
      "step": 103
    },
    {
      "epoch": 0.02389705882352941,
      "grad_norm": 2.6353840827941895,
      "learning_rate": 4.7334558823529413e-07,
      "loss": 2.9367,
      "step": 104
    },
    {
      "epoch": 0.02412683823529412,
      "grad_norm": 2.6472253799438477,
      "learning_rate": 4.779411764705882e-07,
      "loss": 2.7621,
      "step": 105
    },
    {
      "epoch": 0.024356617647058824,
      "grad_norm": 2.928156614303589,
      "learning_rate": 4.825367647058824e-07,
      "loss": 2.783,
      "step": 106
    },
    {
      "epoch": 0.02458639705882353,
      "grad_norm": 2.5030434131622314,
      "learning_rate": 4.871323529411765e-07,
      "loss": 2.821,
      "step": 107
    },
    {
      "epoch": 0.024816176470588234,
      "grad_norm": 2.706434488296509,
      "learning_rate": 4.917279411764707e-07,
      "loss": 3.0611,
      "step": 108
    },
    {
      "epoch": 0.025045955882352942,
      "grad_norm": 2.738152027130127,
      "learning_rate": 4.963235294117648e-07,
      "loss": 2.7704,
      "step": 109
    },
    {
      "epoch": 0.025275735294117647,
      "grad_norm": 2.7249014377593994,
      "learning_rate": 5.009191176470589e-07,
      "loss": 2.7346,
      "step": 110
    },
    {
      "epoch": 0.025505514705882353,
      "grad_norm": 2.323115110397339,
      "learning_rate": 5.05514705882353e-07,
      "loss": 2.5421,
      "step": 111
    },
    {
      "epoch": 0.025735294117647058,
      "grad_norm": 2.3018555641174316,
      "learning_rate": 5.101102941176471e-07,
      "loss": 2.682,
      "step": 112
    },
    {
      "epoch": 0.025965073529411766,
      "grad_norm": 2.2949378490448,
      "learning_rate": 5.147058823529412e-07,
      "loss": 2.6953,
      "step": 113
    },
    {
      "epoch": 0.02619485294117647,
      "grad_norm": 2.7561397552490234,
      "learning_rate": 5.193014705882354e-07,
      "loss": 3.1263,
      "step": 114
    },
    {
      "epoch": 0.026424632352941176,
      "grad_norm": 2.704799175262451,
      "learning_rate": 5.238970588235295e-07,
      "loss": 2.8898,
      "step": 115
    },
    {
      "epoch": 0.02665441176470588,
      "grad_norm": 2.25681209564209,
      "learning_rate": 5.284926470588236e-07,
      "loss": 2.4837,
      "step": 116
    },
    {
      "epoch": 0.02688419117647059,
      "grad_norm": 2.569464921951294,
      "learning_rate": 5.330882352941177e-07,
      "loss": 2.7454,
      "step": 117
    },
    {
      "epoch": 0.027113970588235295,
      "grad_norm": 2.496782064437866,
      "learning_rate": 5.376838235294118e-07,
      "loss": 2.8017,
      "step": 118
    },
    {
      "epoch": 0.02734375,
      "grad_norm": 2.1307899951934814,
      "learning_rate": 5.422794117647059e-07,
      "loss": 2.4767,
      "step": 119
    },
    {
      "epoch": 0.027573529411764705,
      "grad_norm": 2.5124692916870117,
      "learning_rate": 5.468750000000001e-07,
      "loss": 2.5944,
      "step": 120
    },
    {
      "epoch": 0.02780330882352941,
      "grad_norm": 2.3253839015960693,
      "learning_rate": 5.514705882352942e-07,
      "loss": 2.7865,
      "step": 121
    },
    {
      "epoch": 0.02803308823529412,
      "grad_norm": 2.564486503601074,
      "learning_rate": 5.560661764705883e-07,
      "loss": 2.7782,
      "step": 122
    },
    {
      "epoch": 0.028262867647058824,
      "grad_norm": 2.427222728729248,
      "learning_rate": 5.606617647058824e-07,
      "loss": 2.9725,
      "step": 123
    },
    {
      "epoch": 0.02849264705882353,
      "grad_norm": 2.8070504665374756,
      "learning_rate": 5.652573529411765e-07,
      "loss": 2.9674,
      "step": 124
    },
    {
      "epoch": 0.028722426470588234,
      "grad_norm": 2.635143995285034,
      "learning_rate": 5.698529411764706e-07,
      "loss": 2.8584,
      "step": 125
    },
    {
      "epoch": 0.028952205882352942,
      "grad_norm": 2.5672483444213867,
      "learning_rate": 5.744485294117648e-07,
      "loss": 2.7633,
      "step": 126
    },
    {
      "epoch": 0.029181985294117647,
      "grad_norm": 2.393491268157959,
      "learning_rate": 5.790441176470589e-07,
      "loss": 2.6694,
      "step": 127
    },
    {
      "epoch": 0.029411764705882353,
      "grad_norm": 2.7418131828308105,
      "learning_rate": 5.83639705882353e-07,
      "loss": 2.6966,
      "step": 128
    },
    {
      "epoch": 0.029641544117647058,
      "grad_norm": 2.817552328109741,
      "learning_rate": 5.882352941176471e-07,
      "loss": 2.8045,
      "step": 129
    },
    {
      "epoch": 0.029871323529411766,
      "grad_norm": 2.434823751449585,
      "learning_rate": 5.928308823529412e-07,
      "loss": 2.7036,
      "step": 130
    },
    {
      "epoch": 0.03010110294117647,
      "grad_norm": 2.6909432411193848,
      "learning_rate": 5.974264705882353e-07,
      "loss": 2.7998,
      "step": 131
    },
    {
      "epoch": 0.030330882352941176,
      "grad_norm": 2.4031221866607666,
      "learning_rate": 6.020220588235295e-07,
      "loss": 2.8582,
      "step": 132
    },
    {
      "epoch": 0.03056066176470588,
      "grad_norm": 2.996182441711426,
      "learning_rate": 6.066176470588236e-07,
      "loss": 2.9136,
      "step": 133
    },
    {
      "epoch": 0.03079044117647059,
      "grad_norm": 2.1378986835479736,
      "learning_rate": 6.112132352941177e-07,
      "loss": 2.5109,
      "step": 134
    },
    {
      "epoch": 0.031020220588235295,
      "grad_norm": 2.094789981842041,
      "learning_rate": 6.158088235294118e-07,
      "loss": 2.5205,
      "step": 135
    },
    {
      "epoch": 0.03125,
      "grad_norm": 2.313985824584961,
      "learning_rate": 6.204044117647059e-07,
      "loss": 2.5921,
      "step": 136
    },
    {
      "epoch": 0.031479779411764705,
      "grad_norm": 2.4123706817626953,
      "learning_rate": 6.25e-07,
      "loss": 2.8007,
      "step": 137
    },
    {
      "epoch": 0.03170955882352941,
      "grad_norm": 2.7950804233551025,
      "learning_rate": 6.295955882352942e-07,
      "loss": 2.8401,
      "step": 138
    },
    {
      "epoch": 0.031939338235294115,
      "grad_norm": 2.8944473266601562,
      "learning_rate": 6.341911764705883e-07,
      "loss": 2.9612,
      "step": 139
    },
    {
      "epoch": 0.03216911764705882,
      "grad_norm": 2.0795509815216064,
      "learning_rate": 6.387867647058824e-07,
      "loss": 2.447,
      "step": 140
    },
    {
      "epoch": 0.03239889705882353,
      "grad_norm": 2.3712174892425537,
      "learning_rate": 6.433823529411764e-07,
      "loss": 2.6385,
      "step": 141
    },
    {
      "epoch": 0.03262867647058824,
      "grad_norm": 2.6614811420440674,
      "learning_rate": 6.479779411764707e-07,
      "loss": 2.8564,
      "step": 142
    },
    {
      "epoch": 0.03285845588235294,
      "grad_norm": 2.0008552074432373,
      "learning_rate": 6.525735294117648e-07,
      "loss": 2.4625,
      "step": 143
    },
    {
      "epoch": 0.03308823529411765,
      "grad_norm": 2.951465368270874,
      "learning_rate": 6.571691176470589e-07,
      "loss": 2.7984,
      "step": 144
    },
    {
      "epoch": 0.03331801470588235,
      "grad_norm": 3.2066242694854736,
      "learning_rate": 6.61764705882353e-07,
      "loss": 2.9717,
      "step": 145
    },
    {
      "epoch": 0.03354779411764706,
      "grad_norm": 2.820636034011841,
      "learning_rate": 6.663602941176471e-07,
      "loss": 2.8867,
      "step": 146
    },
    {
      "epoch": 0.03377757352941176,
      "grad_norm": 2.238008737564087,
      "learning_rate": 6.709558823529412e-07,
      "loss": 2.5844,
      "step": 147
    },
    {
      "epoch": 0.03400735294117647,
      "grad_norm": 2.5987424850463867,
      "learning_rate": 6.755514705882353e-07,
      "loss": 2.74,
      "step": 148
    },
    {
      "epoch": 0.03423713235294118,
      "grad_norm": 2.9208624362945557,
      "learning_rate": 6.801470588235295e-07,
      "loss": 3.0179,
      "step": 149
    },
    {
      "epoch": 0.034466911764705885,
      "grad_norm": 2.90173602104187,
      "learning_rate": 6.847426470588237e-07,
      "loss": 2.814,
      "step": 150
    },
    {
      "epoch": 0.03469669117647059,
      "grad_norm": 2.434037685394287,
      "learning_rate": 6.893382352941178e-07,
      "loss": 2.4775,
      "step": 151
    },
    {
      "epoch": 0.034926470588235295,
      "grad_norm": 2.668998956680298,
      "learning_rate": 6.939338235294118e-07,
      "loss": 2.8445,
      "step": 152
    },
    {
      "epoch": 0.03515625,
      "grad_norm": 2.834064245223999,
      "learning_rate": 6.985294117647059e-07,
      "loss": 3.0923,
      "step": 153
    },
    {
      "epoch": 0.035386029411764705,
      "grad_norm": 2.8205504417419434,
      "learning_rate": 7.03125e-07,
      "loss": 3.0349,
      "step": 154
    },
    {
      "epoch": 0.03561580882352941,
      "grad_norm": 2.361215353012085,
      "learning_rate": 7.077205882352942e-07,
      "loss": 2.6447,
      "step": 155
    },
    {
      "epoch": 0.035845588235294115,
      "grad_norm": 2.3127670288085938,
      "learning_rate": 7.123161764705883e-07,
      "loss": 2.5503,
      "step": 156
    },
    {
      "epoch": 0.03607536764705882,
      "grad_norm": 2.570904493331909,
      "learning_rate": 7.169117647058824e-07,
      "loss": 2.7842,
      "step": 157
    },
    {
      "epoch": 0.03630514705882353,
      "grad_norm": 2.371432065963745,
      "learning_rate": 7.215073529411765e-07,
      "loss": 2.698,
      "step": 158
    },
    {
      "epoch": 0.03653492647058824,
      "grad_norm": 2.430854082107544,
      "learning_rate": 7.261029411764707e-07,
      "loss": 2.7396,
      "step": 159
    },
    {
      "epoch": 0.03676470588235294,
      "grad_norm": 2.35768723487854,
      "learning_rate": 7.306985294117649e-07,
      "loss": 2.6539,
      "step": 160
    },
    {
      "epoch": 0.03699448529411765,
      "grad_norm": 2.6789910793304443,
      "learning_rate": 7.352941176470589e-07,
      "loss": 2.7136,
      "step": 161
    },
    {
      "epoch": 0.03722426470588235,
      "grad_norm": 2.351348638534546,
      "learning_rate": 7.39889705882353e-07,
      "loss": 2.6094,
      "step": 162
    },
    {
      "epoch": 0.03745404411764706,
      "grad_norm": 2.68581223487854,
      "learning_rate": 7.444852941176471e-07,
      "loss": 2.7295,
      "step": 163
    },
    {
      "epoch": 0.03768382352941176,
      "grad_norm": 2.2269983291625977,
      "learning_rate": 7.490808823529412e-07,
      "loss": 2.6795,
      "step": 164
    },
    {
      "epoch": 0.03791360294117647,
      "grad_norm": 2.614335536956787,
      "learning_rate": 7.536764705882353e-07,
      "loss": 3.0282,
      "step": 165
    },
    {
      "epoch": 0.03814338235294118,
      "grad_norm": 2.592752456665039,
      "learning_rate": 7.582720588235295e-07,
      "loss": 2.804,
      "step": 166
    },
    {
      "epoch": 0.038373161764705885,
      "grad_norm": 2.7233614921569824,
      "learning_rate": 7.628676470588237e-07,
      "loss": 2.7757,
      "step": 167
    },
    {
      "epoch": 0.03860294117647059,
      "grad_norm": 2.457684278488159,
      "learning_rate": 7.674632352941178e-07,
      "loss": 2.8172,
      "step": 168
    },
    {
      "epoch": 0.038832720588235295,
      "grad_norm": 2.1870510578155518,
      "learning_rate": 7.720588235294119e-07,
      "loss": 2.4848,
      "step": 169
    },
    {
      "epoch": 0.0390625,
      "grad_norm": 2.1170830726623535,
      "learning_rate": 7.766544117647059e-07,
      "loss": 2.5675,
      "step": 170
    },
    {
      "epoch": 0.039292279411764705,
      "grad_norm": 2.881277322769165,
      "learning_rate": 7.8125e-07,
      "loss": 2.9106,
      "step": 171
    },
    {
      "epoch": 0.03952205882352941,
      "grad_norm": 2.5749430656433105,
      "learning_rate": 7.858455882352942e-07,
      "loss": 2.7946,
      "step": 172
    },
    {
      "epoch": 0.039751838235294115,
      "grad_norm": 2.5446605682373047,
      "learning_rate": 7.904411764705883e-07,
      "loss": 2.7162,
      "step": 173
    },
    {
      "epoch": 0.03998161764705882,
      "grad_norm": 2.5498087406158447,
      "learning_rate": 7.950367647058824e-07,
      "loss": 2.7343,
      "step": 174
    },
    {
      "epoch": 0.04021139705882353,
      "grad_norm": 2.2619364261627197,
      "learning_rate": 7.996323529411765e-07,
      "loss": 2.6053,
      "step": 175
    },
    {
      "epoch": 0.04044117647058824,
      "grad_norm": 2.9801275730133057,
      "learning_rate": 8.042279411764707e-07,
      "loss": 2.9704,
      "step": 176
    },
    {
      "epoch": 0.04067095588235294,
      "grad_norm": 2.6773345470428467,
      "learning_rate": 8.088235294117648e-07,
      "loss": 2.7844,
      "step": 177
    },
    {
      "epoch": 0.04090073529411765,
      "grad_norm": 2.5907816886901855,
      "learning_rate": 8.13419117647059e-07,
      "loss": 2.79,
      "step": 178
    },
    {
      "epoch": 0.04113051470588235,
      "grad_norm": 2.275672674179077,
      "learning_rate": 8.18014705882353e-07,
      "loss": 2.7739,
      "step": 179
    },
    {
      "epoch": 0.04136029411764706,
      "grad_norm": 3.1457748413085938,
      "learning_rate": 8.226102941176471e-07,
      "loss": 3.2641,
      "step": 180
    },
    {
      "epoch": 0.04159007352941176,
      "grad_norm": 2.526020050048828,
      "learning_rate": 8.272058823529412e-07,
      "loss": 2.7371,
      "step": 181
    },
    {
      "epoch": 0.04181985294117647,
      "grad_norm": 2.0898852348327637,
      "learning_rate": 8.318014705882353e-07,
      "loss": 2.577,
      "step": 182
    },
    {
      "epoch": 0.04204963235294118,
      "grad_norm": 3.0278680324554443,
      "learning_rate": 8.363970588235294e-07,
      "loss": 2.9226,
      "step": 183
    },
    {
      "epoch": 0.042279411764705885,
      "grad_norm": 2.2993485927581787,
      "learning_rate": 8.409926470588237e-07,
      "loss": 2.6312,
      "step": 184
    },
    {
      "epoch": 0.04250919117647059,
      "grad_norm": 2.747087240219116,
      "learning_rate": 8.455882352941178e-07,
      "loss": 2.9685,
      "step": 185
    },
    {
      "epoch": 0.042738970588235295,
      "grad_norm": 2.4270753860473633,
      "learning_rate": 8.501838235294119e-07,
      "loss": 2.7893,
      "step": 186
    },
    {
      "epoch": 0.04296875,
      "grad_norm": 2.2453417778015137,
      "learning_rate": 8.54779411764706e-07,
      "loss": 2.7364,
      "step": 187
    },
    {
      "epoch": 0.043198529411764705,
      "grad_norm": 2.380835771560669,
      "learning_rate": 8.59375e-07,
      "loss": 2.7095,
      "step": 188
    },
    {
      "epoch": 0.04342830882352941,
      "grad_norm": 2.495959758758545,
      "learning_rate": 8.639705882352941e-07,
      "loss": 2.7754,
      "step": 189
    },
    {
      "epoch": 0.043658088235294115,
      "grad_norm": 2.0448644161224365,
      "learning_rate": 8.685661764705883e-07,
      "loss": 2.4532,
      "step": 190
    },
    {
      "epoch": 0.04388786764705882,
      "grad_norm": 2.487983226776123,
      "learning_rate": 8.731617647058824e-07,
      "loss": 2.7806,
      "step": 191
    },
    {
      "epoch": 0.04411764705882353,
      "grad_norm": 2.134036064147949,
      "learning_rate": 8.777573529411765e-07,
      "loss": 2.5547,
      "step": 192
    },
    {
      "epoch": 0.04434742647058824,
      "grad_norm": 2.4034347534179688,
      "learning_rate": 8.823529411764707e-07,
      "loss": 2.8648,
      "step": 193
    },
    {
      "epoch": 0.04457720588235294,
      "grad_norm": 2.4954569339752197,
      "learning_rate": 8.869485294117648e-07,
      "loss": 2.8553,
      "step": 194
    },
    {
      "epoch": 0.04480698529411765,
      "grad_norm": 2.6540939807891846,
      "learning_rate": 8.91544117647059e-07,
      "loss": 2.7885,
      "step": 195
    },
    {
      "epoch": 0.04503676470588235,
      "grad_norm": 2.726055860519409,
      "learning_rate": 8.961397058823531e-07,
      "loss": 2.7839,
      "step": 196
    },
    {
      "epoch": 0.04526654411764706,
      "grad_norm": 2.3904457092285156,
      "learning_rate": 9.007352941176471e-07,
      "loss": 2.7985,
      "step": 197
    },
    {
      "epoch": 0.04549632352941176,
      "grad_norm": 2.8788485527038574,
      "learning_rate": 9.053308823529412e-07,
      "loss": 2.9426,
      "step": 198
    },
    {
      "epoch": 0.04572610294117647,
      "grad_norm": 2.6364965438842773,
      "learning_rate": 9.099264705882353e-07,
      "loss": 2.8577,
      "step": 199
    },
    {
      "epoch": 0.04595588235294118,
      "grad_norm": 2.5342941284179688,
      "learning_rate": 9.145220588235294e-07,
      "loss": 2.7112,
      "step": 200
    },
    {
      "epoch": 0.046185661764705885,
      "grad_norm": 2.3379862308502197,
      "learning_rate": 9.191176470588237e-07,
      "loss": 2.6771,
      "step": 201
    },
    {
      "epoch": 0.04641544117647059,
      "grad_norm": 2.497572660446167,
      "learning_rate": 9.237132352941178e-07,
      "loss": 2.7101,
      "step": 202
    },
    {
      "epoch": 0.046645220588235295,
      "grad_norm": 2.7170393466949463,
      "learning_rate": 9.283088235294119e-07,
      "loss": 3.024,
      "step": 203
    },
    {
      "epoch": 0.046875,
      "grad_norm": 2.2667007446289062,
      "learning_rate": 9.32904411764706e-07,
      "loss": 2.4651,
      "step": 204
    },
    {
      "epoch": 0.047104779411764705,
      "grad_norm": 2.2803022861480713,
      "learning_rate": 9.375000000000001e-07,
      "loss": 2.7154,
      "step": 205
    },
    {
      "epoch": 0.04733455882352941,
      "grad_norm": 2.590280532836914,
      "learning_rate": 9.420955882352941e-07,
      "loss": 2.8205,
      "step": 206
    },
    {
      "epoch": 0.047564338235294115,
      "grad_norm": 2.937410831451416,
      "learning_rate": 9.466911764705883e-07,
      "loss": 2.9955,
      "step": 207
    },
    {
      "epoch": 0.04779411764705882,
      "grad_norm": 2.3566982746124268,
      "learning_rate": 9.512867647058824e-07,
      "loss": 2.5833,
      "step": 208
    },
    {
      "epoch": 0.04802389705882353,
      "grad_norm": 2.399996519088745,
      "learning_rate": 9.558823529411764e-07,
      "loss": 2.7358,
      "step": 209
    },
    {
      "epoch": 0.04825367647058824,
      "grad_norm": 2.1023292541503906,
      "learning_rate": 9.604779411764707e-07,
      "loss": 2.4273,
      "step": 210
    },
    {
      "epoch": 0.04848345588235294,
      "grad_norm": 2.3240628242492676,
      "learning_rate": 9.650735294117648e-07,
      "loss": 2.6349,
      "step": 211
    },
    {
      "epoch": 0.04871323529411765,
      "grad_norm": 2.2861926555633545,
      "learning_rate": 9.69669117647059e-07,
      "loss": 2.6973,
      "step": 212
    },
    {
      "epoch": 0.04894301470588235,
      "grad_norm": 2.3527379035949707,
      "learning_rate": 9.74264705882353e-07,
      "loss": 2.5683,
      "step": 213
    },
    {
      "epoch": 0.04917279411764706,
      "grad_norm": 2.6114261150360107,
      "learning_rate": 9.788602941176472e-07,
      "loss": 2.7453,
      "step": 214
    },
    {
      "epoch": 0.04940257352941176,
      "grad_norm": 2.0909645557403564,
      "learning_rate": 9.834558823529413e-07,
      "loss": 2.5501,
      "step": 215
    },
    {
      "epoch": 0.04963235294117647,
      "grad_norm": 2.322262763977051,
      "learning_rate": 9.880514705882354e-07,
      "loss": 2.5986,
      "step": 216
    },
    {
      "epoch": 0.04986213235294118,
      "grad_norm": 2.2162647247314453,
      "learning_rate": 9.926470588235295e-07,
      "loss": 2.4372,
      "step": 217
    },
    {
      "epoch": 0.050091911764705885,
      "grad_norm": 2.2854576110839844,
      "learning_rate": 9.972426470588237e-07,
      "loss": 2.6088,
      "step": 218
    },
    {
      "epoch": 0.05032169117647059,
      "grad_norm": 2.226473093032837,
      "learning_rate": 1.0018382352941178e-06,
      "loss": 2.5337,
      "step": 219
    },
    {
      "epoch": 0.050551470588235295,
      "grad_norm": 2.5803616046905518,
      "learning_rate": 1.0064338235294119e-06,
      "loss": 2.7085,
      "step": 220
    },
    {
      "epoch": 0.05078125,
      "grad_norm": 2.355628490447998,
      "learning_rate": 1.011029411764706e-06,
      "loss": 2.7,
      "step": 221
    },
    {
      "epoch": 0.051011029411764705,
      "grad_norm": 2.727339506149292,
      "learning_rate": 1.0156250000000001e-06,
      "loss": 2.9379,
      "step": 222
    },
    {
      "epoch": 0.05124080882352941,
      "grad_norm": 2.458127021789551,
      "learning_rate": 1.0202205882352942e-06,
      "loss": 2.5507,
      "step": 223
    },
    {
      "epoch": 0.051470588235294115,
      "grad_norm": 2.207127332687378,
      "learning_rate": 1.0248161764705884e-06,
      "loss": 2.6349,
      "step": 224
    },
    {
      "epoch": 0.05170036764705882,
      "grad_norm": 2.875199794769287,
      "learning_rate": 1.0294117647058825e-06,
      "loss": 2.8018,
      "step": 225
    },
    {
      "epoch": 0.05193014705882353,
      "grad_norm": 2.196488380432129,
      "learning_rate": 1.0340073529411766e-06,
      "loss": 2.7478,
      "step": 226
    },
    {
      "epoch": 0.05215992647058824,
      "grad_norm": 2.6069209575653076,
      "learning_rate": 1.0386029411764707e-06,
      "loss": 2.8694,
      "step": 227
    },
    {
      "epoch": 0.05238970588235294,
      "grad_norm": 2.523899555206299,
      "learning_rate": 1.0431985294117648e-06,
      "loss": 2.795,
      "step": 228
    },
    {
      "epoch": 0.05261948529411765,
      "grad_norm": 2.7757201194763184,
      "learning_rate": 1.047794117647059e-06,
      "loss": 2.794,
      "step": 229
    },
    {
      "epoch": 0.05284926470588235,
      "grad_norm": 2.6861133575439453,
      "learning_rate": 1.052389705882353e-06,
      "loss": 2.7549,
      "step": 230
    },
    {
      "epoch": 0.05307904411764706,
      "grad_norm": 2.6641037464141846,
      "learning_rate": 1.0569852941176472e-06,
      "loss": 2.7735,
      "step": 231
    },
    {
      "epoch": 0.05330882352941176,
      "grad_norm": 2.0802464485168457,
      "learning_rate": 1.0615808823529413e-06,
      "loss": 2.6437,
      "step": 232
    },
    {
      "epoch": 0.05353860294117647,
      "grad_norm": 2.4415924549102783,
      "learning_rate": 1.0661764705882354e-06,
      "loss": 2.588,
      "step": 233
    },
    {
      "epoch": 0.05376838235294118,
      "grad_norm": 2.522428512573242,
      "learning_rate": 1.0707720588235295e-06,
      "loss": 2.8006,
      "step": 234
    },
    {
      "epoch": 0.053998161764705885,
      "grad_norm": 2.28190279006958,
      "learning_rate": 1.0753676470588236e-06,
      "loss": 2.6364,
      "step": 235
    },
    {
      "epoch": 0.05422794117647059,
      "grad_norm": 2.0259270668029785,
      "learning_rate": 1.0799632352941178e-06,
      "loss": 2.5754,
      "step": 236
    },
    {
      "epoch": 0.054457720588235295,
      "grad_norm": 2.405421495437622,
      "learning_rate": 1.0845588235294119e-06,
      "loss": 2.9115,
      "step": 237
    },
    {
      "epoch": 0.0546875,
      "grad_norm": 2.5278406143188477,
      "learning_rate": 1.089154411764706e-06,
      "loss": 2.5866,
      "step": 238
    },
    {
      "epoch": 0.054917279411764705,
      "grad_norm": 2.2960166931152344,
      "learning_rate": 1.0937500000000001e-06,
      "loss": 2.6007,
      "step": 239
    },
    {
      "epoch": 0.05514705882352941,
      "grad_norm": 2.3260674476623535,
      "learning_rate": 1.0983455882352942e-06,
      "loss": 2.6005,
      "step": 240
    },
    {
      "epoch": 0.055376838235294115,
      "grad_norm": 2.373694896697998,
      "learning_rate": 1.1029411764705884e-06,
      "loss": 2.5277,
      "step": 241
    },
    {
      "epoch": 0.05560661764705882,
      "grad_norm": 2.1223559379577637,
      "learning_rate": 1.1075367647058825e-06,
      "loss": 2.5075,
      "step": 242
    },
    {
      "epoch": 0.05583639705882353,
      "grad_norm": 2.2103025913238525,
      "learning_rate": 1.1121323529411766e-06,
      "loss": 2.5765,
      "step": 243
    },
    {
      "epoch": 0.05606617647058824,
      "grad_norm": 2.222520112991333,
      "learning_rate": 1.1167279411764707e-06,
      "loss": 2.5084,
      "step": 244
    },
    {
      "epoch": 0.05629595588235294,
      "grad_norm": 2.5075197219848633,
      "learning_rate": 1.1213235294117648e-06,
      "loss": 2.6264,
      "step": 245
    },
    {
      "epoch": 0.05652573529411765,
      "grad_norm": 2.717867612838745,
      "learning_rate": 1.125919117647059e-06,
      "loss": 2.8057,
      "step": 246
    },
    {
      "epoch": 0.05675551470588235,
      "grad_norm": 2.1183652877807617,
      "learning_rate": 1.130514705882353e-06,
      "loss": 2.5295,
      "step": 247
    },
    {
      "epoch": 0.05698529411764706,
      "grad_norm": 2.04518985748291,
      "learning_rate": 1.1351102941176472e-06,
      "loss": 2.5099,
      "step": 248
    },
    {
      "epoch": 0.05721507352941176,
      "grad_norm": 2.5631906986236572,
      "learning_rate": 1.1397058823529413e-06,
      "loss": 2.6464,
      "step": 249
    },
    {
      "epoch": 0.05744485294117647,
      "grad_norm": 2.4347002506256104,
      "learning_rate": 1.1443014705882354e-06,
      "loss": 2.7771,
      "step": 250
    },
    {
      "epoch": 0.05767463235294118,
      "grad_norm": 2.330678939819336,
      "learning_rate": 1.1488970588235295e-06,
      "loss": 2.5492,
      "step": 251
    },
    {
      "epoch": 0.057904411764705885,
      "grad_norm": 2.4005300998687744,
      "learning_rate": 1.1534926470588236e-06,
      "loss": 2.6141,
      "step": 252
    },
    {
      "epoch": 0.05813419117647059,
      "grad_norm": 2.3077468872070312,
      "learning_rate": 1.1580882352941178e-06,
      "loss": 2.6195,
      "step": 253
    },
    {
      "epoch": 0.058363970588235295,
      "grad_norm": 2.2968523502349854,
      "learning_rate": 1.1626838235294119e-06,
      "loss": 2.6211,
      "step": 254
    },
    {
      "epoch": 0.05859375,
      "grad_norm": 2.516780138015747,
      "learning_rate": 1.167279411764706e-06,
      "loss": 2.7651,
      "step": 255
    },
    {
      "epoch": 0.058823529411764705,
      "grad_norm": 2.136025905609131,
      "learning_rate": 1.1718750000000001e-06,
      "loss": 2.5979,
      "step": 256
    },
    {
      "epoch": 0.05905330882352941,
      "grad_norm": 2.52128005027771,
      "learning_rate": 1.1764705882352942e-06,
      "loss": 2.787,
      "step": 257
    },
    {
      "epoch": 0.059283088235294115,
      "grad_norm": 1.9237819910049438,
      "learning_rate": 1.1810661764705883e-06,
      "loss": 2.4449,
      "step": 258
    },
    {
      "epoch": 0.05951286764705882,
      "grad_norm": 2.189558982849121,
      "learning_rate": 1.1856617647058825e-06,
      "loss": 2.4641,
      "step": 259
    },
    {
      "epoch": 0.05974264705882353,
      "grad_norm": 2.0249245166778564,
      "learning_rate": 1.1902573529411766e-06,
      "loss": 2.4792,
      "step": 260
    },
    {
      "epoch": 0.05997242647058824,
      "grad_norm": 2.9973549842834473,
      "learning_rate": 1.1948529411764707e-06,
      "loss": 2.8874,
      "step": 261
    },
    {
      "epoch": 0.06020220588235294,
      "grad_norm": 2.1474947929382324,
      "learning_rate": 1.1994485294117648e-06,
      "loss": 2.5483,
      "step": 262
    },
    {
      "epoch": 0.06043198529411765,
      "grad_norm": 2.197092294692993,
      "learning_rate": 1.204044117647059e-06,
      "loss": 2.6183,
      "step": 263
    },
    {
      "epoch": 0.06066176470588235,
      "grad_norm": 2.142988681793213,
      "learning_rate": 1.208639705882353e-06,
      "loss": 2.5757,
      "step": 264
    },
    {
      "epoch": 0.06089154411764706,
      "grad_norm": 2.124887704849243,
      "learning_rate": 1.2132352941176472e-06,
      "loss": 2.3334,
      "step": 265
    },
    {
      "epoch": 0.06112132352941176,
      "grad_norm": 2.0501182079315186,
      "learning_rate": 1.2178308823529413e-06,
      "loss": 2.3814,
      "step": 266
    },
    {
      "epoch": 0.06135110294117647,
      "grad_norm": 2.8528664112091064,
      "learning_rate": 1.2224264705882354e-06,
      "loss": 2.7847,
      "step": 267
    },
    {
      "epoch": 0.06158088235294118,
      "grad_norm": 2.111253261566162,
      "learning_rate": 1.2270220588235295e-06,
      "loss": 2.4818,
      "step": 268
    },
    {
      "epoch": 0.061810661764705885,
      "grad_norm": 2.1707847118377686,
      "learning_rate": 1.2316176470588236e-06,
      "loss": 2.538,
      "step": 269
    },
    {
      "epoch": 0.06204044117647059,
      "grad_norm": 2.1172304153442383,
      "learning_rate": 1.2362132352941178e-06,
      "loss": 2.5757,
      "step": 270
    },
    {
      "epoch": 0.062270220588235295,
      "grad_norm": 1.9751813411712646,
      "learning_rate": 1.2408088235294119e-06,
      "loss": 2.3532,
      "step": 271
    },
    {
      "epoch": 0.0625,
      "grad_norm": 2.363729476928711,
      "learning_rate": 1.245404411764706e-06,
      "loss": 2.6259,
      "step": 272
    },
    {
      "epoch": 0.0627297794117647,
      "grad_norm": 2.259160041809082,
      "learning_rate": 1.25e-06,
      "loss": 2.62,
      "step": 273
    },
    {
      "epoch": 0.06295955882352941,
      "grad_norm": 2.2769765853881836,
      "learning_rate": 1.2545955882352942e-06,
      "loss": 2.3926,
      "step": 274
    },
    {
      "epoch": 0.06318933823529412,
      "grad_norm": 2.15429949760437,
      "learning_rate": 1.2591911764705883e-06,
      "loss": 2.6593,
      "step": 275
    },
    {
      "epoch": 0.06341911764705882,
      "grad_norm": 2.123744010925293,
      "learning_rate": 1.2637867647058825e-06,
      "loss": 2.4993,
      "step": 276
    },
    {
      "epoch": 0.06364889705882353,
      "grad_norm": 2.264218330383301,
      "learning_rate": 1.2683823529411766e-06,
      "loss": 2.4605,
      "step": 277
    },
    {
      "epoch": 0.06387867647058823,
      "grad_norm": 2.6346659660339355,
      "learning_rate": 1.2729779411764707e-06,
      "loss": 2.746,
      "step": 278
    },
    {
      "epoch": 0.06410845588235294,
      "grad_norm": 2.5766186714172363,
      "learning_rate": 1.2775735294117648e-06,
      "loss": 2.6859,
      "step": 279
    },
    {
      "epoch": 0.06433823529411764,
      "grad_norm": 2.098262310028076,
      "learning_rate": 1.2821691176470587e-06,
      "loss": 2.4213,
      "step": 280
    },
    {
      "epoch": 0.06456801470588236,
      "grad_norm": 2.2665529251098633,
      "learning_rate": 1.2867647058823528e-06,
      "loss": 2.6258,
      "step": 281
    },
    {
      "epoch": 0.06479779411764706,
      "grad_norm": 2.266832113265991,
      "learning_rate": 1.2913602941176474e-06,
      "loss": 2.4045,
      "step": 282
    },
    {
      "epoch": 0.06502757352941177,
      "grad_norm": 2.3047327995300293,
      "learning_rate": 1.2959558823529415e-06,
      "loss": 2.5602,
      "step": 283
    },
    {
      "epoch": 0.06525735294117647,
      "grad_norm": 2.448233127593994,
      "learning_rate": 1.3005514705882356e-06,
      "loss": 2.6028,
      "step": 284
    },
    {
      "epoch": 0.06548713235294118,
      "grad_norm": 2.4055120944976807,
      "learning_rate": 1.3051470588235295e-06,
      "loss": 2.614,
      "step": 285
    },
    {
      "epoch": 0.06571691176470588,
      "grad_norm": 2.2620792388916016,
      "learning_rate": 1.3097426470588236e-06,
      "loss": 2.482,
      "step": 286
    },
    {
      "epoch": 0.06594669117647059,
      "grad_norm": 2.511169672012329,
      "learning_rate": 1.3143382352941177e-06,
      "loss": 2.637,
      "step": 287
    },
    {
      "epoch": 0.0661764705882353,
      "grad_norm": 2.3543689250946045,
      "learning_rate": 1.3189338235294119e-06,
      "loss": 2.6237,
      "step": 288
    },
    {
      "epoch": 0.06640625,
      "grad_norm": 2.446774482727051,
      "learning_rate": 1.323529411764706e-06,
      "loss": 2.5528,
      "step": 289
    },
    {
      "epoch": 0.0666360294117647,
      "grad_norm": 2.187218427658081,
      "learning_rate": 1.328125e-06,
      "loss": 2.5321,
      "step": 290
    },
    {
      "epoch": 0.06686580882352941,
      "grad_norm": 2.2864222526550293,
      "learning_rate": 1.3327205882352942e-06,
      "loss": 2.4485,
      "step": 291
    },
    {
      "epoch": 0.06709558823529412,
      "grad_norm": 2.3979713916778564,
      "learning_rate": 1.3373161764705883e-06,
      "loss": 2.7018,
      "step": 292
    },
    {
      "epoch": 0.06732536764705882,
      "grad_norm": 2.691196918487549,
      "learning_rate": 1.3419117647058824e-06,
      "loss": 2.6812,
      "step": 293
    },
    {
      "epoch": 0.06755514705882353,
      "grad_norm": 2.348463773727417,
      "learning_rate": 1.3465073529411766e-06,
      "loss": 2.5488,
      "step": 294
    },
    {
      "epoch": 0.06778492647058823,
      "grad_norm": 2.1595466136932373,
      "learning_rate": 1.3511029411764707e-06,
      "loss": 2.456,
      "step": 295
    },
    {
      "epoch": 0.06801470588235294,
      "grad_norm": 2.0589439868927,
      "learning_rate": 1.3556985294117648e-06,
      "loss": 2.5251,
      "step": 296
    },
    {
      "epoch": 0.06824448529411764,
      "grad_norm": 2.13954758644104,
      "learning_rate": 1.360294117647059e-06,
      "loss": 2.5065,
      "step": 297
    },
    {
      "epoch": 0.06847426470588236,
      "grad_norm": 2.608344554901123,
      "learning_rate": 1.3648897058823528e-06,
      "loss": 2.6995,
      "step": 298
    },
    {
      "epoch": 0.06870404411764706,
      "grad_norm": 2.024195909500122,
      "learning_rate": 1.3694852941176474e-06,
      "loss": 2.4466,
      "step": 299
    },
    {
      "epoch": 0.06893382352941177,
      "grad_norm": 2.5706515312194824,
      "learning_rate": 1.3740808823529415e-06,
      "loss": 2.7353,
      "step": 300
    },
    {
      "epoch": 0.06916360294117647,
      "grad_norm": 2.3907506465911865,
      "learning_rate": 1.3786764705882356e-06,
      "loss": 2.6659,
      "step": 301
    },
    {
      "epoch": 0.06939338235294118,
      "grad_norm": 2.1038591861724854,
      "learning_rate": 1.3832720588235295e-06,
      "loss": 2.3584,
      "step": 302
    },
    {
      "epoch": 0.06962316176470588,
      "grad_norm": 2.139673948287964,
      "learning_rate": 1.3878676470588236e-06,
      "loss": 2.3974,
      "step": 303
    },
    {
      "epoch": 0.06985294117647059,
      "grad_norm": 2.364180088043213,
      "learning_rate": 1.3924632352941177e-06,
      "loss": 2.4854,
      "step": 304
    },
    {
      "epoch": 0.0700827205882353,
      "grad_norm": 2.3580985069274902,
      "learning_rate": 1.3970588235294119e-06,
      "loss": 2.5321,
      "step": 305
    },
    {
      "epoch": 0.0703125,
      "grad_norm": 2.214031457901001,
      "learning_rate": 1.401654411764706e-06,
      "loss": 2.3277,
      "step": 306
    },
    {
      "epoch": 0.0705422794117647,
      "grad_norm": 2.2221450805664062,
      "learning_rate": 1.40625e-06,
      "loss": 2.5157,
      "step": 307
    },
    {
      "epoch": 0.07077205882352941,
      "grad_norm": 2.1276590824127197,
      "learning_rate": 1.4108455882352942e-06,
      "loss": 2.5122,
      "step": 308
    },
    {
      "epoch": 0.07100183823529412,
      "grad_norm": 2.3323099613189697,
      "learning_rate": 1.4154411764705883e-06,
      "loss": 2.5327,
      "step": 309
    },
    {
      "epoch": 0.07123161764705882,
      "grad_norm": 2.2307190895080566,
      "learning_rate": 1.4200367647058824e-06,
      "loss": 2.5404,
      "step": 310
    },
    {
      "epoch": 0.07146139705882353,
      "grad_norm": 2.768699884414673,
      "learning_rate": 1.4246323529411766e-06,
      "loss": 2.7146,
      "step": 311
    },
    {
      "epoch": 0.07169117647058823,
      "grad_norm": 2.4553334712982178,
      "learning_rate": 1.4292279411764707e-06,
      "loss": 2.6823,
      "step": 312
    },
    {
      "epoch": 0.07192095588235294,
      "grad_norm": 1.9411311149597168,
      "learning_rate": 1.4338235294117648e-06,
      "loss": 2.2545,
      "step": 313
    },
    {
      "epoch": 0.07215073529411764,
      "grad_norm": 2.220008373260498,
      "learning_rate": 1.438419117647059e-06,
      "loss": 2.623,
      "step": 314
    },
    {
      "epoch": 0.07238051470588236,
      "grad_norm": 2.588571548461914,
      "learning_rate": 1.443014705882353e-06,
      "loss": 2.7209,
      "step": 315
    },
    {
      "epoch": 0.07261029411764706,
      "grad_norm": 2.3457703590393066,
      "learning_rate": 1.4476102941176474e-06,
      "loss": 2.5312,
      "step": 316
    },
    {
      "epoch": 0.07284007352941177,
      "grad_norm": 1.9742143154144287,
      "learning_rate": 1.4522058823529415e-06,
      "loss": 2.4009,
      "step": 317
    },
    {
      "epoch": 0.07306985294117647,
      "grad_norm": 1.984005331993103,
      "learning_rate": 1.4568014705882356e-06,
      "loss": 2.3423,
      "step": 318
    },
    {
      "epoch": 0.07329963235294118,
      "grad_norm": 2.242793083190918,
      "learning_rate": 1.4613970588235297e-06,
      "loss": 2.5193,
      "step": 319
    },
    {
      "epoch": 0.07352941176470588,
      "grad_norm": 2.1206986904144287,
      "learning_rate": 1.4659926470588236e-06,
      "loss": 2.3891,
      "step": 320
    },
    {
      "epoch": 0.07375919117647059,
      "grad_norm": 2.0609302520751953,
      "learning_rate": 1.4705882352941177e-06,
      "loss": 2.3784,
      "step": 321
    },
    {
      "epoch": 0.0739889705882353,
      "grad_norm": 2.1531434059143066,
      "learning_rate": 1.4751838235294118e-06,
      "loss": 2.3601,
      "step": 322
    },
    {
      "epoch": 0.07421875,
      "grad_norm": 2.2025818824768066,
      "learning_rate": 1.479779411764706e-06,
      "loss": 2.4444,
      "step": 323
    },
    {
      "epoch": 0.0744485294117647,
      "grad_norm": 1.9322112798690796,
      "learning_rate": 1.484375e-06,
      "loss": 2.3521,
      "step": 324
    },
    {
      "epoch": 0.07467830882352941,
      "grad_norm": 2.374871015548706,
      "learning_rate": 1.4889705882352942e-06,
      "loss": 2.709,
      "step": 325
    },
    {
      "epoch": 0.07490808823529412,
      "grad_norm": 2.0629165172576904,
      "learning_rate": 1.4935661764705883e-06,
      "loss": 2.2977,
      "step": 326
    },
    {
      "epoch": 0.07513786764705882,
      "grad_norm": 1.8736400604248047,
      "learning_rate": 1.4981617647058824e-06,
      "loss": 2.3437,
      "step": 327
    },
    {
      "epoch": 0.07536764705882353,
      "grad_norm": 2.283860445022583,
      "learning_rate": 1.5027573529411766e-06,
      "loss": 2.6704,
      "step": 328
    },
    {
      "epoch": 0.07559742647058823,
      "grad_norm": 2.1139490604400635,
      "learning_rate": 1.5073529411764707e-06,
      "loss": 2.4006,
      "step": 329
    },
    {
      "epoch": 0.07582720588235294,
      "grad_norm": 2.3281517028808594,
      "learning_rate": 1.5119485294117648e-06,
      "loss": 2.5883,
      "step": 330
    },
    {
      "epoch": 0.07605698529411764,
      "grad_norm": 1.7670265436172485,
      "learning_rate": 1.516544117647059e-06,
      "loss": 2.2554,
      "step": 331
    },
    {
      "epoch": 0.07628676470588236,
      "grad_norm": 2.5338680744171143,
      "learning_rate": 1.521139705882353e-06,
      "loss": 2.5747,
      "step": 332
    },
    {
      "epoch": 0.07651654411764706,
      "grad_norm": 2.310533046722412,
      "learning_rate": 1.5257352941176473e-06,
      "loss": 2.5656,
      "step": 333
    },
    {
      "epoch": 0.07674632352941177,
      "grad_norm": 2.2719295024871826,
      "learning_rate": 1.5303308823529415e-06,
      "loss": 2.4613,
      "step": 334
    },
    {
      "epoch": 0.07697610294117647,
      "grad_norm": 2.433525562286377,
      "learning_rate": 1.5349264705882356e-06,
      "loss": 2.48,
      "step": 335
    },
    {
      "epoch": 0.07720588235294118,
      "grad_norm": 2.5816547870635986,
      "learning_rate": 1.5395220588235297e-06,
      "loss": 2.6065,
      "step": 336
    },
    {
      "epoch": 0.07743566176470588,
      "grad_norm": 2.322272539138794,
      "learning_rate": 1.5441176470588238e-06,
      "loss": 2.4748,
      "step": 337
    },
    {
      "epoch": 0.07766544117647059,
      "grad_norm": 2.471027135848999,
      "learning_rate": 1.5487132352941177e-06,
      "loss": 2.6187,
      "step": 338
    },
    {
      "epoch": 0.0778952205882353,
      "grad_norm": 2.559199810028076,
      "learning_rate": 1.5533088235294118e-06,
      "loss": 2.5056,
      "step": 339
    },
    {
      "epoch": 0.078125,
      "grad_norm": 2.605844020843506,
      "learning_rate": 1.557904411764706e-06,
      "loss": 2.5133,
      "step": 340
    },
    {
      "epoch": 0.0783547794117647,
      "grad_norm": 1.913428544998169,
      "learning_rate": 1.5625e-06,
      "loss": 2.1441,
      "step": 341
    },
    {
      "epoch": 0.07858455882352941,
      "grad_norm": 2.4808592796325684,
      "learning_rate": 1.5670955882352942e-06,
      "loss": 2.5467,
      "step": 342
    },
    {
      "epoch": 0.07881433823529412,
      "grad_norm": 2.1611855030059814,
      "learning_rate": 1.5716911764705883e-06,
      "loss": 2.2832,
      "step": 343
    },
    {
      "epoch": 0.07904411764705882,
      "grad_norm": 2.2873892784118652,
      "learning_rate": 1.5762867647058824e-06,
      "loss": 2.3868,
      "step": 344
    },
    {
      "epoch": 0.07927389705882353,
      "grad_norm": 1.9757786989212036,
      "learning_rate": 1.5808823529411765e-06,
      "loss": 2.3778,
      "step": 345
    },
    {
      "epoch": 0.07950367647058823,
      "grad_norm": 2.047146797180176,
      "learning_rate": 1.5854779411764707e-06,
      "loss": 2.3502,
      "step": 346
    },
    {
      "epoch": 0.07973345588235294,
      "grad_norm": 1.838474988937378,
      "learning_rate": 1.5900735294117648e-06,
      "loss": 2.2699,
      "step": 347
    },
    {
      "epoch": 0.07996323529411764,
      "grad_norm": 2.1720662117004395,
      "learning_rate": 1.594669117647059e-06,
      "loss": 2.3292,
      "step": 348
    },
    {
      "epoch": 0.08019301470588236,
      "grad_norm": 2.064509153366089,
      "learning_rate": 1.599264705882353e-06,
      "loss": 2.2868,
      "step": 349
    },
    {
      "epoch": 0.08042279411764706,
      "grad_norm": 2.376168966293335,
      "learning_rate": 1.6038602941176473e-06,
      "loss": 2.5014,
      "step": 350
    },
    {
      "epoch": 0.08065257352941177,
      "grad_norm": 1.8777871131896973,
      "learning_rate": 1.6084558823529415e-06,
      "loss": 2.3029,
      "step": 351
    },
    {
      "epoch": 0.08088235294117647,
      "grad_norm": 2.204272508621216,
      "learning_rate": 1.6130514705882356e-06,
      "loss": 2.42,
      "step": 352
    },
    {
      "epoch": 0.08111213235294118,
      "grad_norm": 2.165144443511963,
      "learning_rate": 1.6176470588235297e-06,
      "loss": 2.3717,
      "step": 353
    },
    {
      "epoch": 0.08134191176470588,
      "grad_norm": 1.973712682723999,
      "learning_rate": 1.6222426470588238e-06,
      "loss": 2.4053,
      "step": 354
    },
    {
      "epoch": 0.08157169117647059,
      "grad_norm": 2.44649076461792,
      "learning_rate": 1.626838235294118e-06,
      "loss": 2.4771,
      "step": 355
    },
    {
      "epoch": 0.0818014705882353,
      "grad_norm": 1.8956574201583862,
      "learning_rate": 1.6314338235294118e-06,
      "loss": 2.2383,
      "step": 356
    },
    {
      "epoch": 0.08203125,
      "grad_norm": 2.3997745513916016,
      "learning_rate": 1.636029411764706e-06,
      "loss": 2.5,
      "step": 357
    },
    {
      "epoch": 0.0822610294117647,
      "grad_norm": 2.4010937213897705,
      "learning_rate": 1.640625e-06,
      "loss": 2.3682,
      "step": 358
    },
    {
      "epoch": 0.08249080882352941,
      "grad_norm": 2.703333854675293,
      "learning_rate": 1.6452205882352942e-06,
      "loss": 2.7188,
      "step": 359
    },
    {
      "epoch": 0.08272058823529412,
      "grad_norm": 2.165442943572998,
      "learning_rate": 1.6498161764705883e-06,
      "loss": 2.3393,
      "step": 360
    },
    {
      "epoch": 0.08295036764705882,
      "grad_norm": 2.033254384994507,
      "learning_rate": 1.6544117647058824e-06,
      "loss": 2.3547,
      "step": 361
    },
    {
      "epoch": 0.08318014705882353,
      "grad_norm": 1.9558091163635254,
      "learning_rate": 1.6590073529411765e-06,
      "loss": 2.2949,
      "step": 362
    },
    {
      "epoch": 0.08340992647058823,
      "grad_norm": 2.245474100112915,
      "learning_rate": 1.6636029411764707e-06,
      "loss": 2.2692,
      "step": 363
    },
    {
      "epoch": 0.08363970588235294,
      "grad_norm": 2.2405128479003906,
      "learning_rate": 1.6681985294117648e-06,
      "loss": 2.1715,
      "step": 364
    },
    {
      "epoch": 0.08386948529411764,
      "grad_norm": 2.0389976501464844,
      "learning_rate": 1.6727941176470589e-06,
      "loss": 2.4149,
      "step": 365
    },
    {
      "epoch": 0.08409926470588236,
      "grad_norm": 1.9977130889892578,
      "learning_rate": 1.677389705882353e-06,
      "loss": 2.2994,
      "step": 366
    },
    {
      "epoch": 0.08432904411764706,
      "grad_norm": 2.1934545040130615,
      "learning_rate": 1.6819852941176473e-06,
      "loss": 2.3206,
      "step": 367
    },
    {
      "epoch": 0.08455882352941177,
      "grad_norm": 2.397961378097534,
      "learning_rate": 1.6865808823529415e-06,
      "loss": 2.4708,
      "step": 368
    },
    {
      "epoch": 0.08478860294117647,
      "grad_norm": 2.063847541809082,
      "learning_rate": 1.6911764705882356e-06,
      "loss": 2.3107,
      "step": 369
    },
    {
      "epoch": 0.08501838235294118,
      "grad_norm": 2.2623867988586426,
      "learning_rate": 1.6957720588235297e-06,
      "loss": 2.334,
      "step": 370
    },
    {
      "epoch": 0.08524816176470588,
      "grad_norm": 2.3999693393707275,
      "learning_rate": 1.7003676470588238e-06,
      "loss": 2.6089,
      "step": 371
    },
    {
      "epoch": 0.08547794117647059,
      "grad_norm": 2.214416265487671,
      "learning_rate": 1.704963235294118e-06,
      "loss": 2.4389,
      "step": 372
    },
    {
      "epoch": 0.0857077205882353,
      "grad_norm": 2.4047939777374268,
      "learning_rate": 1.709558823529412e-06,
      "loss": 2.2602,
      "step": 373
    },
    {
      "epoch": 0.0859375,
      "grad_norm": 1.9616403579711914,
      "learning_rate": 1.714154411764706e-06,
      "loss": 2.2684,
      "step": 374
    },
    {
      "epoch": 0.0861672794117647,
      "grad_norm": 1.8227869272232056,
      "learning_rate": 1.71875e-06,
      "loss": 2.1668,
      "step": 375
    },
    {
      "epoch": 0.08639705882352941,
      "grad_norm": 2.342108726501465,
      "learning_rate": 1.7233455882352942e-06,
      "loss": 2.4679,
      "step": 376
    },
    {
      "epoch": 0.08662683823529412,
      "grad_norm": 2.70190691947937,
      "learning_rate": 1.7279411764705883e-06,
      "loss": 2.6139,
      "step": 377
    },
    {
      "epoch": 0.08685661764705882,
      "grad_norm": 2.104644775390625,
      "learning_rate": 1.7325367647058824e-06,
      "loss": 2.3241,
      "step": 378
    },
    {
      "epoch": 0.08708639705882353,
      "grad_norm": 2.1572036743164062,
      "learning_rate": 1.7371323529411765e-06,
      "loss": 2.3504,
      "step": 379
    },
    {
      "epoch": 0.08731617647058823,
      "grad_norm": 2.015174388885498,
      "learning_rate": 1.7417279411764706e-06,
      "loss": 2.3533,
      "step": 380
    },
    {
      "epoch": 0.08754595588235294,
      "grad_norm": 3.053239583969116,
      "learning_rate": 1.7463235294117648e-06,
      "loss": 2.6382,
      "step": 381
    },
    {
      "epoch": 0.08777573529411764,
      "grad_norm": 2.294372797012329,
      "learning_rate": 1.7509191176470589e-06,
      "loss": 2.4397,
      "step": 382
    },
    {
      "epoch": 0.08800551470588236,
      "grad_norm": 2.2918851375579834,
      "learning_rate": 1.755514705882353e-06,
      "loss": 2.374,
      "step": 383
    },
    {
      "epoch": 0.08823529411764706,
      "grad_norm": 2.243969678878784,
      "learning_rate": 1.7601102941176473e-06,
      "loss": 2.5003,
      "step": 384
    },
    {
      "epoch": 0.08846507352941177,
      "grad_norm": 1.8856102228164673,
      "learning_rate": 1.7647058823529414e-06,
      "loss": 2.1776,
      "step": 385
    },
    {
      "epoch": 0.08869485294117647,
      "grad_norm": 2.306433916091919,
      "learning_rate": 1.7693014705882356e-06,
      "loss": 2.2859,
      "step": 386
    },
    {
      "epoch": 0.08892463235294118,
      "grad_norm": 2.3266851902008057,
      "learning_rate": 1.7738970588235297e-06,
      "loss": 2.4361,
      "step": 387
    },
    {
      "epoch": 0.08915441176470588,
      "grad_norm": 2.032684564590454,
      "learning_rate": 1.7784926470588238e-06,
      "loss": 2.3622,
      "step": 388
    },
    {
      "epoch": 0.08938419117647059,
      "grad_norm": 1.9310638904571533,
      "learning_rate": 1.783088235294118e-06,
      "loss": 2.205,
      "step": 389
    },
    {
      "epoch": 0.0896139705882353,
      "grad_norm": 1.8973370790481567,
      "learning_rate": 1.787683823529412e-06,
      "loss": 2.1554,
      "step": 390
    },
    {
      "epoch": 0.08984375,
      "grad_norm": 2.33600115776062,
      "learning_rate": 1.7922794117647061e-06,
      "loss": 2.3824,
      "step": 391
    },
    {
      "epoch": 0.0900735294117647,
      "grad_norm": 2.0574541091918945,
      "learning_rate": 1.796875e-06,
      "loss": 2.3945,
      "step": 392
    },
    {
      "epoch": 0.09030330882352941,
      "grad_norm": 2.056459426879883,
      "learning_rate": 1.8014705882352942e-06,
      "loss": 2.4023,
      "step": 393
    },
    {
      "epoch": 0.09053308823529412,
      "grad_norm": 2.4113051891326904,
      "learning_rate": 1.8060661764705883e-06,
      "loss": 2.4261,
      "step": 394
    },
    {
      "epoch": 0.09076286764705882,
      "grad_norm": 2.7168450355529785,
      "learning_rate": 1.8106617647058824e-06,
      "loss": 2.517,
      "step": 395
    },
    {
      "epoch": 0.09099264705882353,
      "grad_norm": 2.455946922302246,
      "learning_rate": 1.8152573529411765e-06,
      "loss": 2.4048,
      "step": 396
    },
    {
      "epoch": 0.09122242647058823,
      "grad_norm": 1.8591307401657104,
      "learning_rate": 1.8198529411764706e-06,
      "loss": 2.2398,
      "step": 397
    },
    {
      "epoch": 0.09145220588235294,
      "grad_norm": 2.3212504386901855,
      "learning_rate": 1.8244485294117648e-06,
      "loss": 2.4147,
      "step": 398
    },
    {
      "epoch": 0.09168198529411764,
      "grad_norm": 1.9056092500686646,
      "learning_rate": 1.8290441176470589e-06,
      "loss": 2.2358,
      "step": 399
    },
    {
      "epoch": 0.09191176470588236,
      "grad_norm": 2.1038389205932617,
      "learning_rate": 1.833639705882353e-06,
      "loss": 2.2827,
      "step": 400
    },
    {
      "epoch": 0.09214154411764706,
      "grad_norm": 1.8138819932937622,
      "learning_rate": 1.8382352941176473e-06,
      "loss": 2.1916,
      "step": 401
    },
    {
      "epoch": 0.09237132352941177,
      "grad_norm": 2.257904291152954,
      "learning_rate": 1.8428308823529414e-06,
      "loss": 2.3503,
      "step": 402
    },
    {
      "epoch": 0.09260110294117647,
      "grad_norm": 2.158000946044922,
      "learning_rate": 1.8474264705882356e-06,
      "loss": 2.4016,
      "step": 403
    },
    {
      "epoch": 0.09283088235294118,
      "grad_norm": 2.1547439098358154,
      "learning_rate": 1.8520220588235297e-06,
      "loss": 2.1627,
      "step": 404
    },
    {
      "epoch": 0.09306066176470588,
      "grad_norm": 2.148454427719116,
      "learning_rate": 1.8566176470588238e-06,
      "loss": 2.288,
      "step": 405
    },
    {
      "epoch": 0.09329044117647059,
      "grad_norm": 1.921360731124878,
      "learning_rate": 1.861213235294118e-06,
      "loss": 2.0616,
      "step": 406
    },
    {
      "epoch": 0.0935202205882353,
      "grad_norm": 2.117537498474121,
      "learning_rate": 1.865808823529412e-06,
      "loss": 2.2577,
      "step": 407
    },
    {
      "epoch": 0.09375,
      "grad_norm": 1.8224133253097534,
      "learning_rate": 1.8704044117647061e-06,
      "loss": 2.2599,
      "step": 408
    },
    {
      "epoch": 0.0939797794117647,
      "grad_norm": 2.311958074569702,
      "learning_rate": 1.8750000000000003e-06,
      "loss": 2.4671,
      "step": 409
    },
    {
      "epoch": 0.09420955882352941,
      "grad_norm": 2.0221381187438965,
      "learning_rate": 1.8795955882352942e-06,
      "loss": 2.2003,
      "step": 410
    },
    {
      "epoch": 0.09443933823529412,
      "grad_norm": 2.1837220191955566,
      "learning_rate": 1.8841911764705883e-06,
      "loss": 2.2723,
      "step": 411
    },
    {
      "epoch": 0.09466911764705882,
      "grad_norm": 1.719760775566101,
      "learning_rate": 1.8887867647058824e-06,
      "loss": 2.0805,
      "step": 412
    },
    {
      "epoch": 0.09489889705882353,
      "grad_norm": 1.9946277141571045,
      "learning_rate": 1.8933823529411765e-06,
      "loss": 2.179,
      "step": 413
    },
    {
      "epoch": 0.09512867647058823,
      "grad_norm": 1.8663086891174316,
      "learning_rate": 1.8979779411764706e-06,
      "loss": 2.061,
      "step": 414
    },
    {
      "epoch": 0.09535845588235294,
      "grad_norm": 1.960608720779419,
      "learning_rate": 1.9025735294117648e-06,
      "loss": 2.248,
      "step": 415
    },
    {
      "epoch": 0.09558823529411764,
      "grad_norm": 1.996590256690979,
      "learning_rate": 1.9071691176470589e-06,
      "loss": 2.1388,
      "step": 416
    },
    {
      "epoch": 0.09581801470588236,
      "grad_norm": 2.087390184402466,
      "learning_rate": 1.9117647058823528e-06,
      "loss": 2.1411,
      "step": 417
    },
    {
      "epoch": 0.09604779411764706,
      "grad_norm": 2.2659146785736084,
      "learning_rate": 1.9163602941176475e-06,
      "loss": 2.2526,
      "step": 418
    },
    {
      "epoch": 0.09627757352941177,
      "grad_norm": 2.3628156185150146,
      "learning_rate": 1.9209558823529414e-06,
      "loss": 2.2555,
      "step": 419
    },
    {
      "epoch": 0.09650735294117647,
      "grad_norm": 2.0019047260284424,
      "learning_rate": 1.9255514705882358e-06,
      "loss": 2.1985,
      "step": 420
    },
    {
      "epoch": 0.09673713235294118,
      "grad_norm": 2.0364701747894287,
      "learning_rate": 1.9301470588235297e-06,
      "loss": 2.1012,
      "step": 421
    },
    {
      "epoch": 0.09696691176470588,
      "grad_norm": 1.9360302686691284,
      "learning_rate": 1.9347426470588236e-06,
      "loss": 2.2136,
      "step": 422
    },
    {
      "epoch": 0.09719669117647059,
      "grad_norm": 1.8290845155715942,
      "learning_rate": 1.939338235294118e-06,
      "loss": 2.0126,
      "step": 423
    },
    {
      "epoch": 0.0974264705882353,
      "grad_norm": 2.1382076740264893,
      "learning_rate": 1.943933823529412e-06,
      "loss": 2.325,
      "step": 424
    },
    {
      "epoch": 0.09765625,
      "grad_norm": 2.0314781665802,
      "learning_rate": 1.948529411764706e-06,
      "loss": 2.2561,
      "step": 425
    },
    {
      "epoch": 0.0978860294117647,
      "grad_norm": 2.020942211151123,
      "learning_rate": 1.953125e-06,
      "loss": 2.3022,
      "step": 426
    },
    {
      "epoch": 0.09811580882352941,
      "grad_norm": 2.171902894973755,
      "learning_rate": 1.9577205882352944e-06,
      "loss": 2.1908,
      "step": 427
    },
    {
      "epoch": 0.09834558823529412,
      "grad_norm": 1.9628190994262695,
      "learning_rate": 1.9623161764705883e-06,
      "loss": 2.0729,
      "step": 428
    },
    {
      "epoch": 0.09857536764705882,
      "grad_norm": 2.447439193725586,
      "learning_rate": 1.9669117647058826e-06,
      "loss": 2.4015,
      "step": 429
    },
    {
      "epoch": 0.09880514705882353,
      "grad_norm": 2.7007386684417725,
      "learning_rate": 1.9715073529411765e-06,
      "loss": 2.4089,
      "step": 430
    },
    {
      "epoch": 0.09903492647058823,
      "grad_norm": 2.1394259929656982,
      "learning_rate": 1.976102941176471e-06,
      "loss": 2.2975,
      "step": 431
    },
    {
      "epoch": 0.09926470588235294,
      "grad_norm": 1.9989477396011353,
      "learning_rate": 1.9806985294117647e-06,
      "loss": 2.2433,
      "step": 432
    },
    {
      "epoch": 0.09949448529411764,
      "grad_norm": 2.1111958026885986,
      "learning_rate": 1.985294117647059e-06,
      "loss": 2.1795,
      "step": 433
    },
    {
      "epoch": 0.09972426470588236,
      "grad_norm": 1.8516204357147217,
      "learning_rate": 1.989889705882353e-06,
      "loss": 2.0368,
      "step": 434
    },
    {
      "epoch": 0.09995404411764706,
      "grad_norm": 2.3092896938323975,
      "learning_rate": 1.9944852941176473e-06,
      "loss": 2.2209,
      "step": 435
    },
    {
      "epoch": 0.10018382352941177,
      "grad_norm": 2.189603090286255,
      "learning_rate": 1.9990808823529416e-06,
      "loss": 2.1745,
      "step": 436
    },
    {
      "epoch": 0.10041360294117647,
      "grad_norm": 1.911697268486023,
      "learning_rate": 2.0036764705882355e-06,
      "loss": 2.0458,
      "step": 437
    },
    {
      "epoch": 0.10064338235294118,
      "grad_norm": 2.178297519683838,
      "learning_rate": 2.0082720588235294e-06,
      "loss": 2.2419,
      "step": 438
    },
    {
      "epoch": 0.10087316176470588,
      "grad_norm": 1.8948780298233032,
      "learning_rate": 2.0128676470588238e-06,
      "loss": 2.1104,
      "step": 439
    },
    {
      "epoch": 0.10110294117647059,
      "grad_norm": 2.277475118637085,
      "learning_rate": 2.0174632352941177e-06,
      "loss": 2.3958,
      "step": 440
    },
    {
      "epoch": 0.1013327205882353,
      "grad_norm": 2.3745200634002686,
      "learning_rate": 2.022058823529412e-06,
      "loss": 2.2747,
      "step": 441
    },
    {
      "epoch": 0.1015625,
      "grad_norm": 2.2328717708587646,
      "learning_rate": 2.026654411764706e-06,
      "loss": 2.2566,
      "step": 442
    },
    {
      "epoch": 0.1017922794117647,
      "grad_norm": 2.2705533504486084,
      "learning_rate": 2.0312500000000002e-06,
      "loss": 2.345,
      "step": 443
    },
    {
      "epoch": 0.10202205882352941,
      "grad_norm": 2.390350580215454,
      "learning_rate": 2.035845588235294e-06,
      "loss": 2.2119,
      "step": 444
    },
    {
      "epoch": 0.10225183823529412,
      "grad_norm": 2.2019152641296387,
      "learning_rate": 2.0404411764705885e-06,
      "loss": 2.2949,
      "step": 445
    },
    {
      "epoch": 0.10248161764705882,
      "grad_norm": 2.4525327682495117,
      "learning_rate": 2.0450367647058824e-06,
      "loss": 2.271,
      "step": 446
    },
    {
      "epoch": 0.10271139705882353,
      "grad_norm": 1.9626052379608154,
      "learning_rate": 2.0496323529411767e-06,
      "loss": 1.9771,
      "step": 447
    },
    {
      "epoch": 0.10294117647058823,
      "grad_norm": 2.2809369564056396,
      "learning_rate": 2.0542279411764706e-06,
      "loss": 2.2966,
      "step": 448
    },
    {
      "epoch": 0.10317095588235294,
      "grad_norm": 2.0382680892944336,
      "learning_rate": 2.058823529411765e-06,
      "loss": 2.1698,
      "step": 449
    },
    {
      "epoch": 0.10340073529411764,
      "grad_norm": 2.4763834476470947,
      "learning_rate": 2.063419117647059e-06,
      "loss": 2.3114,
      "step": 450
    },
    {
      "epoch": 0.10363051470588236,
      "grad_norm": 1.829847812652588,
      "learning_rate": 2.068014705882353e-06,
      "loss": 2.0509,
      "step": 451
    },
    {
      "epoch": 0.10386029411764706,
      "grad_norm": 2.2310919761657715,
      "learning_rate": 2.0726102941176475e-06,
      "loss": 2.1554,
      "step": 452
    },
    {
      "epoch": 0.10409007352941177,
      "grad_norm": 2.6538467407226562,
      "learning_rate": 2.0772058823529414e-06,
      "loss": 2.2588,
      "step": 453
    },
    {
      "epoch": 0.10431985294117647,
      "grad_norm": 1.7040307521820068,
      "learning_rate": 2.0818014705882357e-06,
      "loss": 1.9699,
      "step": 454
    },
    {
      "epoch": 0.10454963235294118,
      "grad_norm": 2.0933468341827393,
      "learning_rate": 2.0863970588235297e-06,
      "loss": 2.1717,
      "step": 455
    },
    {
      "epoch": 0.10477941176470588,
      "grad_norm": 2.3361542224884033,
      "learning_rate": 2.0909926470588236e-06,
      "loss": 2.2733,
      "step": 456
    },
    {
      "epoch": 0.10500919117647059,
      "grad_norm": 1.9469685554504395,
      "learning_rate": 2.095588235294118e-06,
      "loss": 2.0066,
      "step": 457
    },
    {
      "epoch": 0.1052389705882353,
      "grad_norm": 1.5942286252975464,
      "learning_rate": 2.100183823529412e-06,
      "loss": 1.849,
      "step": 458
    },
    {
      "epoch": 0.10546875,
      "grad_norm": 2.135175943374634,
      "learning_rate": 2.104779411764706e-06,
      "loss": 2.2565,
      "step": 459
    },
    {
      "epoch": 0.1056985294117647,
      "grad_norm": 2.0919315814971924,
      "learning_rate": 2.109375e-06,
      "loss": 2.0082,
      "step": 460
    },
    {
      "epoch": 0.10592830882352941,
      "grad_norm": 1.6641589403152466,
      "learning_rate": 2.1139705882352944e-06,
      "loss": 2.0068,
      "step": 461
    },
    {
      "epoch": 0.10615808823529412,
      "grad_norm": 2.152482509613037,
      "learning_rate": 2.1185661764705883e-06,
      "loss": 2.3053,
      "step": 462
    },
    {
      "epoch": 0.10638786764705882,
      "grad_norm": 2.0840134620666504,
      "learning_rate": 2.1231617647058826e-06,
      "loss": 2.2135,
      "step": 463
    },
    {
      "epoch": 0.10661764705882353,
      "grad_norm": 1.721703052520752,
      "learning_rate": 2.1277573529411765e-06,
      "loss": 1.8575,
      "step": 464
    },
    {
      "epoch": 0.10684742647058823,
      "grad_norm": 1.8542094230651855,
      "learning_rate": 2.132352941176471e-06,
      "loss": 1.9765,
      "step": 465
    },
    {
      "epoch": 0.10707720588235294,
      "grad_norm": 2.388493537902832,
      "learning_rate": 2.1369485294117647e-06,
      "loss": 2.2198,
      "step": 466
    },
    {
      "epoch": 0.10730698529411764,
      "grad_norm": 2.200218915939331,
      "learning_rate": 2.141544117647059e-06,
      "loss": 1.9703,
      "step": 467
    },
    {
      "epoch": 0.10753676470588236,
      "grad_norm": 1.8766695261001587,
      "learning_rate": 2.146139705882353e-06,
      "loss": 2.1426,
      "step": 468
    },
    {
      "epoch": 0.10776654411764706,
      "grad_norm": 2.045867919921875,
      "learning_rate": 2.1507352941176473e-06,
      "loss": 2.0542,
      "step": 469
    },
    {
      "epoch": 0.10799632352941177,
      "grad_norm": 2.0703623294830322,
      "learning_rate": 2.1553308823529416e-06,
      "loss": 2.107,
      "step": 470
    },
    {
      "epoch": 0.10822610294117647,
      "grad_norm": 1.950073480606079,
      "learning_rate": 2.1599264705882355e-06,
      "loss": 2.0364,
      "step": 471
    },
    {
      "epoch": 0.10845588235294118,
      "grad_norm": 2.1464550495147705,
      "learning_rate": 2.16452205882353e-06,
      "loss": 2.0736,
      "step": 472
    },
    {
      "epoch": 0.10868566176470588,
      "grad_norm": 1.9916106462478638,
      "learning_rate": 2.1691176470588238e-06,
      "loss": 2.0694,
      "step": 473
    },
    {
      "epoch": 0.10891544117647059,
      "grad_norm": 2.4625892639160156,
      "learning_rate": 2.1737132352941177e-06,
      "loss": 2.1794,
      "step": 474
    },
    {
      "epoch": 0.1091452205882353,
      "grad_norm": 1.9393852949142456,
      "learning_rate": 2.178308823529412e-06,
      "loss": 2.1396,
      "step": 475
    },
    {
      "epoch": 0.109375,
      "grad_norm": 2.001551628112793,
      "learning_rate": 2.182904411764706e-06,
      "loss": 2.0577,
      "step": 476
    },
    {
      "epoch": 0.1096047794117647,
      "grad_norm": 2.092622995376587,
      "learning_rate": 2.1875000000000002e-06,
      "loss": 2.1497,
      "step": 477
    },
    {
      "epoch": 0.10983455882352941,
      "grad_norm": 2.4090311527252197,
      "learning_rate": 2.192095588235294e-06,
      "loss": 2.2861,
      "step": 478
    },
    {
      "epoch": 0.11006433823529412,
      "grad_norm": 1.9938526153564453,
      "learning_rate": 2.1966911764705885e-06,
      "loss": 2.1203,
      "step": 479
    },
    {
      "epoch": 0.11029411764705882,
      "grad_norm": 1.691596508026123,
      "learning_rate": 2.2012867647058824e-06,
      "loss": 1.885,
      "step": 480
    },
    {
      "epoch": 0.11052389705882353,
      "grad_norm": 2.3119356632232666,
      "learning_rate": 2.2058823529411767e-06,
      "loss": 2.0952,
      "step": 481
    },
    {
      "epoch": 0.11075367647058823,
      "grad_norm": 2.303248882293701,
      "learning_rate": 2.2104779411764706e-06,
      "loss": 2.2236,
      "step": 482
    },
    {
      "epoch": 0.11098345588235294,
      "grad_norm": 1.8875528573989868,
      "learning_rate": 2.215073529411765e-06,
      "loss": 2.0043,
      "step": 483
    },
    {
      "epoch": 0.11121323529411764,
      "grad_norm": 1.946542501449585,
      "learning_rate": 2.219669117647059e-06,
      "loss": 1.9891,
      "step": 484
    },
    {
      "epoch": 0.11144301470588236,
      "grad_norm": 2.266798257827759,
      "learning_rate": 2.224264705882353e-06,
      "loss": 2.253,
      "step": 485
    },
    {
      "epoch": 0.11167279411764706,
      "grad_norm": 1.8478275537490845,
      "learning_rate": 2.2288602941176475e-06,
      "loss": 1.9592,
      "step": 486
    },
    {
      "epoch": 0.11190257352941177,
      "grad_norm": 1.8073577880859375,
      "learning_rate": 2.2334558823529414e-06,
      "loss": 2.0129,
      "step": 487
    },
    {
      "epoch": 0.11213235294117647,
      "grad_norm": 1.7909835577011108,
      "learning_rate": 2.2380514705882357e-06,
      "loss": 2.0261,
      "step": 488
    },
    {
      "epoch": 0.11236213235294118,
      "grad_norm": 1.790865421295166,
      "learning_rate": 2.2426470588235296e-06,
      "loss": 1.9018,
      "step": 489
    },
    {
      "epoch": 0.11259191176470588,
      "grad_norm": 1.8479704856872559,
      "learning_rate": 2.247242647058824e-06,
      "loss": 2.0755,
      "step": 490
    },
    {
      "epoch": 0.11282169117647059,
      "grad_norm": 1.9732728004455566,
      "learning_rate": 2.251838235294118e-06,
      "loss": 2.1648,
      "step": 491
    },
    {
      "epoch": 0.1130514705882353,
      "grad_norm": 1.934624195098877,
      "learning_rate": 2.2564338235294118e-06,
      "loss": 1.9987,
      "step": 492
    },
    {
      "epoch": 0.11328125,
      "grad_norm": 1.9961191415786743,
      "learning_rate": 2.261029411764706e-06,
      "loss": 1.9871,
      "step": 493
    },
    {
      "epoch": 0.1135110294117647,
      "grad_norm": 2.0470588207244873,
      "learning_rate": 2.265625e-06,
      "loss": 1.9992,
      "step": 494
    },
    {
      "epoch": 0.11374080882352941,
      "grad_norm": 2.0401124954223633,
      "learning_rate": 2.2702205882352943e-06,
      "loss": 1.959,
      "step": 495
    },
    {
      "epoch": 0.11397058823529412,
      "grad_norm": 2.1312713623046875,
      "learning_rate": 2.2748161764705882e-06,
      "loss": 2.047,
      "step": 496
    },
    {
      "epoch": 0.11420036764705882,
      "grad_norm": 2.248948574066162,
      "learning_rate": 2.2794117647058826e-06,
      "loss": 2.0715,
      "step": 497
    },
    {
      "epoch": 0.11443014705882353,
      "grad_norm": 1.9258531332015991,
      "learning_rate": 2.2840073529411765e-06,
      "loss": 2.0185,
      "step": 498
    },
    {
      "epoch": 0.11465992647058823,
      "grad_norm": 1.805536150932312,
      "learning_rate": 2.288602941176471e-06,
      "loss": 1.9276,
      "step": 499
    },
    {
      "epoch": 0.11488970588235294,
      "grad_norm": 2.2139229774475098,
      "learning_rate": 2.2931985294117647e-06,
      "loss": 1.9903,
      "step": 500
    },
    {
      "epoch": 0.11488970588235294,
      "eval_loss": 2.0917468070983887,
      "eval_runtime": 418.4694,
      "eval_samples_per_second": 21.282,
      "eval_steps_per_second": 10.641,
      "step": 500
    },
    {
      "epoch": 0.11511948529411764,
      "grad_norm": 1.9081215858459473,
      "learning_rate": 2.297794117647059e-06,
      "loss": 2.0851,
      "step": 501
    },
    {
      "epoch": 0.11534926470588236,
      "grad_norm": 2.067260265350342,
      "learning_rate": 2.302389705882353e-06,
      "loss": 1.9992,
      "step": 502
    },
    {
      "epoch": 0.11557904411764706,
      "grad_norm": 1.956086277961731,
      "learning_rate": 2.3069852941176473e-06,
      "loss": 1.9884,
      "step": 503
    },
    {
      "epoch": 0.11580882352941177,
      "grad_norm": 2.3737590312957764,
      "learning_rate": 2.3115808823529416e-06,
      "loss": 2.1669,
      "step": 504
    },
    {
      "epoch": 0.11603860294117647,
      "grad_norm": 1.7968569993972778,
      "learning_rate": 2.3161764705882355e-06,
      "loss": 2.0286,
      "step": 505
    },
    {
      "epoch": 0.11626838235294118,
      "grad_norm": 2.1621744632720947,
      "learning_rate": 2.32077205882353e-06,
      "loss": 1.8387,
      "step": 506
    },
    {
      "epoch": 0.11649816176470588,
      "grad_norm": 1.8031169176101685,
      "learning_rate": 2.3253676470588237e-06,
      "loss": 1.8484,
      "step": 507
    },
    {
      "epoch": 0.11672794117647059,
      "grad_norm": 2.0955984592437744,
      "learning_rate": 2.329963235294118e-06,
      "loss": 2.1012,
      "step": 508
    },
    {
      "epoch": 0.1169577205882353,
      "grad_norm": 2.0064380168914795,
      "learning_rate": 2.334558823529412e-06,
      "loss": 2.0114,
      "step": 509
    },
    {
      "epoch": 0.1171875,
      "grad_norm": 2.5260818004608154,
      "learning_rate": 2.339154411764706e-06,
      "loss": 2.0467,
      "step": 510
    },
    {
      "epoch": 0.1174172794117647,
      "grad_norm": 2.0417518615722656,
      "learning_rate": 2.3437500000000002e-06,
      "loss": 1.9476,
      "step": 511
    },
    {
      "epoch": 0.11764705882352941,
      "grad_norm": 1.9029674530029297,
      "learning_rate": 2.348345588235294e-06,
      "loss": 1.9344,
      "step": 512
    },
    {
      "epoch": 0.11787683823529412,
      "grad_norm": 1.7769514322280884,
      "learning_rate": 2.3529411764705885e-06,
      "loss": 1.9233,
      "step": 513
    },
    {
      "epoch": 0.11810661764705882,
      "grad_norm": 2.160036563873291,
      "learning_rate": 2.3575367647058824e-06,
      "loss": 2.0945,
      "step": 514
    },
    {
      "epoch": 0.11833639705882353,
      "grad_norm": 2.0797207355499268,
      "learning_rate": 2.3621323529411767e-06,
      "loss": 2.1731,
      "step": 515
    },
    {
      "epoch": 0.11856617647058823,
      "grad_norm": 2.044922113418579,
      "learning_rate": 2.3667279411764706e-06,
      "loss": 1.9007,
      "step": 516
    },
    {
      "epoch": 0.11879595588235294,
      "grad_norm": 2.00244140625,
      "learning_rate": 2.371323529411765e-06,
      "loss": 1.9774,
      "step": 517
    },
    {
      "epoch": 0.11902573529411764,
      "grad_norm": 2.6947972774505615,
      "learning_rate": 2.375919117647059e-06,
      "loss": 2.1282,
      "step": 518
    },
    {
      "epoch": 0.11925551470588236,
      "grad_norm": 1.6771591901779175,
      "learning_rate": 2.380514705882353e-06,
      "loss": 1.8863,
      "step": 519
    },
    {
      "epoch": 0.11948529411764706,
      "grad_norm": 1.839377999305725,
      "learning_rate": 2.3851102941176475e-06,
      "loss": 2.0019,
      "step": 520
    },
    {
      "epoch": 0.11971507352941177,
      "grad_norm": 1.821750521659851,
      "learning_rate": 2.3897058823529414e-06,
      "loss": 1.9512,
      "step": 521
    },
    {
      "epoch": 0.11994485294117647,
      "grad_norm": 2.1402041912078857,
      "learning_rate": 2.3943014705882357e-06,
      "loss": 1.9322,
      "step": 522
    },
    {
      "epoch": 0.12017463235294118,
      "grad_norm": 2.0765249729156494,
      "learning_rate": 2.3988970588235296e-06,
      "loss": 1.9577,
      "step": 523
    },
    {
      "epoch": 0.12040441176470588,
      "grad_norm": 1.9137879610061646,
      "learning_rate": 2.403492647058824e-06,
      "loss": 1.9225,
      "step": 524
    },
    {
      "epoch": 0.12063419117647059,
      "grad_norm": 1.774799108505249,
      "learning_rate": 2.408088235294118e-06,
      "loss": 1.7445,
      "step": 525
    },
    {
      "epoch": 0.1208639705882353,
      "grad_norm": 1.737743854522705,
      "learning_rate": 2.412683823529412e-06,
      "loss": 1.9554,
      "step": 526
    },
    {
      "epoch": 0.12109375,
      "grad_norm": 2.4227590560913086,
      "learning_rate": 2.417279411764706e-06,
      "loss": 1.9235,
      "step": 527
    },
    {
      "epoch": 0.1213235294117647,
      "grad_norm": 2.309931755065918,
      "learning_rate": 2.421875e-06,
      "loss": 1.9843,
      "step": 528
    },
    {
      "epoch": 0.12155330882352941,
      "grad_norm": 2.111628770828247,
      "learning_rate": 2.4264705882352943e-06,
      "loss": 1.8692,
      "step": 529
    },
    {
      "epoch": 0.12178308823529412,
      "grad_norm": 2.0277152061462402,
      "learning_rate": 2.4310661764705882e-06,
      "loss": 2.0258,
      "step": 530
    },
    {
      "epoch": 0.12201286764705882,
      "grad_norm": 1.979457139968872,
      "learning_rate": 2.4356617647058826e-06,
      "loss": 1.9782,
      "step": 531
    },
    {
      "epoch": 0.12224264705882353,
      "grad_norm": 1.892867088317871,
      "learning_rate": 2.4402573529411765e-06,
      "loss": 1.8301,
      "step": 532
    },
    {
      "epoch": 0.12247242647058823,
      "grad_norm": 1.6768649816513062,
      "learning_rate": 2.444852941176471e-06,
      "loss": 1.8654,
      "step": 533
    },
    {
      "epoch": 0.12270220588235294,
      "grad_norm": 2.401851177215576,
      "learning_rate": 2.4494485294117647e-06,
      "loss": 2.0451,
      "step": 534
    },
    {
      "epoch": 0.12293198529411764,
      "grad_norm": 1.8018715381622314,
      "learning_rate": 2.454044117647059e-06,
      "loss": 1.8333,
      "step": 535
    },
    {
      "epoch": 0.12316176470588236,
      "grad_norm": 2.068031072616577,
      "learning_rate": 2.458639705882353e-06,
      "loss": 1.9925,
      "step": 536
    },
    {
      "epoch": 0.12339154411764706,
      "grad_norm": 2.1948812007904053,
      "learning_rate": 2.4632352941176473e-06,
      "loss": 1.9379,
      "step": 537
    },
    {
      "epoch": 0.12362132352941177,
      "grad_norm": 2.0042712688446045,
      "learning_rate": 2.4678308823529416e-06,
      "loss": 1.8402,
      "step": 538
    },
    {
      "epoch": 0.12385110294117647,
      "grad_norm": 2.1967291831970215,
      "learning_rate": 2.4724264705882355e-06,
      "loss": 1.9413,
      "step": 539
    },
    {
      "epoch": 0.12408088235294118,
      "grad_norm": 1.864974856376648,
      "learning_rate": 2.47702205882353e-06,
      "loss": 1.7149,
      "step": 540
    },
    {
      "epoch": 0.12431066176470588,
      "grad_norm": 1.9305305480957031,
      "learning_rate": 2.4816176470588237e-06,
      "loss": 1.9294,
      "step": 541
    },
    {
      "epoch": 0.12454044117647059,
      "grad_norm": 2.221781015396118,
      "learning_rate": 2.486213235294118e-06,
      "loss": 1.9681,
      "step": 542
    },
    {
      "epoch": 0.1247702205882353,
      "grad_norm": 1.9880989789962769,
      "learning_rate": 2.490808823529412e-06,
      "loss": 1.9366,
      "step": 543
    },
    {
      "epoch": 0.125,
      "grad_norm": 2.133944034576416,
      "learning_rate": 2.4954044117647063e-06,
      "loss": 2.0923,
      "step": 544
    },
    {
      "epoch": 0.12522977941176472,
      "grad_norm": 1.8513368368148804,
      "learning_rate": 2.5e-06,
      "loss": 1.8784,
      "step": 545
    },
    {
      "epoch": 0.1254595588235294,
      "grad_norm": 1.8946070671081543,
      "learning_rate": 2.5045955882352945e-06,
      "loss": 1.8693,
      "step": 546
    },
    {
      "epoch": 0.12568933823529413,
      "grad_norm": 1.729576826095581,
      "learning_rate": 2.5091911764705884e-06,
      "loss": 1.764,
      "step": 547
    },
    {
      "epoch": 0.12591911764705882,
      "grad_norm": 1.7512913942337036,
      "learning_rate": 2.5137867647058828e-06,
      "loss": 1.8901,
      "step": 548
    },
    {
      "epoch": 0.12614889705882354,
      "grad_norm": 1.855919361114502,
      "learning_rate": 2.5183823529411767e-06,
      "loss": 1.7838,
      "step": 549
    },
    {
      "epoch": 0.12637867647058823,
      "grad_norm": 2.032679796218872,
      "learning_rate": 2.522977941176471e-06,
      "loss": 1.8906,
      "step": 550
    },
    {
      "epoch": 0.12660845588235295,
      "grad_norm": 1.9763214588165283,
      "learning_rate": 2.527573529411765e-06,
      "loss": 1.903,
      "step": 551
    },
    {
      "epoch": 0.12683823529411764,
      "grad_norm": 2.1045641899108887,
      "learning_rate": 2.5321691176470592e-06,
      "loss": 2.0611,
      "step": 552
    },
    {
      "epoch": 0.12706801470588236,
      "grad_norm": 1.8790466785430908,
      "learning_rate": 2.536764705882353e-06,
      "loss": 1.8822,
      "step": 553
    },
    {
      "epoch": 0.12729779411764705,
      "grad_norm": 1.9638723134994507,
      "learning_rate": 2.5413602941176475e-06,
      "loss": 1.9108,
      "step": 554
    },
    {
      "epoch": 0.12752757352941177,
      "grad_norm": 2.0029542446136475,
      "learning_rate": 2.5459558823529414e-06,
      "loss": 1.8974,
      "step": 555
    },
    {
      "epoch": 0.12775735294117646,
      "grad_norm": 2.154594659805298,
      "learning_rate": 2.5505514705882357e-06,
      "loss": 1.9139,
      "step": 556
    },
    {
      "epoch": 0.12798713235294118,
      "grad_norm": 1.7972732782363892,
      "learning_rate": 2.5551470588235296e-06,
      "loss": 1.731,
      "step": 557
    },
    {
      "epoch": 0.12821691176470587,
      "grad_norm": 1.8413139581680298,
      "learning_rate": 2.559742647058824e-06,
      "loss": 1.7448,
      "step": 558
    },
    {
      "epoch": 0.1284466911764706,
      "grad_norm": 2.003491163253784,
      "learning_rate": 2.5643382352941174e-06,
      "loss": 1.9977,
      "step": 559
    },
    {
      "epoch": 0.12867647058823528,
      "grad_norm": 1.8907934427261353,
      "learning_rate": 2.568933823529412e-06,
      "loss": 1.8214,
      "step": 560
    },
    {
      "epoch": 0.12890625,
      "grad_norm": 1.768540620803833,
      "learning_rate": 2.5735294117647057e-06,
      "loss": 1.7598,
      "step": 561
    },
    {
      "epoch": 0.12913602941176472,
      "grad_norm": 1.8798437118530273,
      "learning_rate": 2.5781250000000004e-06,
      "loss": 1.877,
      "step": 562
    },
    {
      "epoch": 0.1293658088235294,
      "grad_norm": 1.9013522863388062,
      "learning_rate": 2.5827205882352947e-06,
      "loss": 1.9213,
      "step": 563
    },
    {
      "epoch": 0.12959558823529413,
      "grad_norm": 1.754088282585144,
      "learning_rate": 2.5873161764705882e-06,
      "loss": 1.763,
      "step": 564
    },
    {
      "epoch": 0.12982536764705882,
      "grad_norm": 2.170544147491455,
      "learning_rate": 2.591911764705883e-06,
      "loss": 1.8842,
      "step": 565
    },
    {
      "epoch": 0.13005514705882354,
      "grad_norm": 1.8496131896972656,
      "learning_rate": 2.5965073529411765e-06,
      "loss": 1.8563,
      "step": 566
    },
    {
      "epoch": 0.13028492647058823,
      "grad_norm": 1.9059478044509888,
      "learning_rate": 2.601102941176471e-06,
      "loss": 1.9023,
      "step": 567
    },
    {
      "epoch": 0.13051470588235295,
      "grad_norm": 1.9124670028686523,
      "learning_rate": 2.6056985294117647e-06,
      "loss": 1.8919,
      "step": 568
    },
    {
      "epoch": 0.13074448529411764,
      "grad_norm": 2.11655592918396,
      "learning_rate": 2.610294117647059e-06,
      "loss": 1.9124,
      "step": 569
    },
    {
      "epoch": 0.13097426470588236,
      "grad_norm": 1.9223517179489136,
      "learning_rate": 2.614889705882353e-06,
      "loss": 1.8754,
      "step": 570
    },
    {
      "epoch": 0.13120404411764705,
      "grad_norm": 2.1252660751342773,
      "learning_rate": 2.6194852941176473e-06,
      "loss": 1.8958,
      "step": 571
    },
    {
      "epoch": 0.13143382352941177,
      "grad_norm": 2.035598039627075,
      "learning_rate": 2.624080882352941e-06,
      "loss": 1.8939,
      "step": 572
    },
    {
      "epoch": 0.13166360294117646,
      "grad_norm": 2.136976718902588,
      "learning_rate": 2.6286764705882355e-06,
      "loss": 1.9009,
      "step": 573
    },
    {
      "epoch": 0.13189338235294118,
      "grad_norm": 2.107665777206421,
      "learning_rate": 2.6332720588235294e-06,
      "loss": 1.883,
      "step": 574
    },
    {
      "epoch": 0.13212316176470587,
      "grad_norm": 2.0768604278564453,
      "learning_rate": 2.6378676470588237e-06,
      "loss": 1.754,
      "step": 575
    },
    {
      "epoch": 0.1323529411764706,
      "grad_norm": 1.8981949090957642,
      "learning_rate": 2.6424632352941176e-06,
      "loss": 1.7767,
      "step": 576
    },
    {
      "epoch": 0.13258272058823528,
      "grad_norm": 2.058211088180542,
      "learning_rate": 2.647058823529412e-06,
      "loss": 1.8508,
      "step": 577
    },
    {
      "epoch": 0.1328125,
      "grad_norm": 2.0560803413391113,
      "learning_rate": 2.651654411764706e-06,
      "loss": 1.6799,
      "step": 578
    },
    {
      "epoch": 0.13304227941176472,
      "grad_norm": 2.0930335521698,
      "learning_rate": 2.65625e-06,
      "loss": 1.816,
      "step": 579
    },
    {
      "epoch": 0.1332720588235294,
      "grad_norm": 1.8234658241271973,
      "learning_rate": 2.6608455882352945e-06,
      "loss": 1.6745,
      "step": 580
    },
    {
      "epoch": 0.13350183823529413,
      "grad_norm": 1.7765957117080688,
      "learning_rate": 2.6654411764705884e-06,
      "loss": 1.7404,
      "step": 581
    },
    {
      "epoch": 0.13373161764705882,
      "grad_norm": 1.7221401929855347,
      "learning_rate": 2.6700367647058828e-06,
      "loss": 1.6984,
      "step": 582
    },
    {
      "epoch": 0.13396139705882354,
      "grad_norm": 2.0568716526031494,
      "learning_rate": 2.6746323529411767e-06,
      "loss": 1.901,
      "step": 583
    },
    {
      "epoch": 0.13419117647058823,
      "grad_norm": 1.8626989126205444,
      "learning_rate": 2.679227941176471e-06,
      "loss": 1.7038,
      "step": 584
    },
    {
      "epoch": 0.13442095588235295,
      "grad_norm": 1.6586947441101074,
      "learning_rate": 2.683823529411765e-06,
      "loss": 1.7132,
      "step": 585
    },
    {
      "epoch": 0.13465073529411764,
      "grad_norm": 2.0039663314819336,
      "learning_rate": 2.6884191176470592e-06,
      "loss": 1.7911,
      "step": 586
    },
    {
      "epoch": 0.13488051470588236,
      "grad_norm": 2.2679030895233154,
      "learning_rate": 2.693014705882353e-06,
      "loss": 1.863,
      "step": 587
    },
    {
      "epoch": 0.13511029411764705,
      "grad_norm": 1.921601414680481,
      "learning_rate": 2.6976102941176475e-06,
      "loss": 1.7508,
      "step": 588
    },
    {
      "epoch": 0.13534007352941177,
      "grad_norm": 1.7566126585006714,
      "learning_rate": 2.7022058823529414e-06,
      "loss": 1.6457,
      "step": 589
    },
    {
      "epoch": 0.13556985294117646,
      "grad_norm": 2.0485143661499023,
      "learning_rate": 2.7068014705882357e-06,
      "loss": 1.6469,
      "step": 590
    },
    {
      "epoch": 0.13579963235294118,
      "grad_norm": 1.8245373964309692,
      "learning_rate": 2.7113970588235296e-06,
      "loss": 1.7227,
      "step": 591
    },
    {
      "epoch": 0.13602941176470587,
      "grad_norm": 1.8790009021759033,
      "learning_rate": 2.715992647058824e-06,
      "loss": 1.6763,
      "step": 592
    },
    {
      "epoch": 0.1362591911764706,
      "grad_norm": 1.7903029918670654,
      "learning_rate": 2.720588235294118e-06,
      "loss": 1.6464,
      "step": 593
    },
    {
      "epoch": 0.13648897058823528,
      "grad_norm": 1.968739628791809,
      "learning_rate": 2.725183823529412e-06,
      "loss": 1.8407,
      "step": 594
    },
    {
      "epoch": 0.13671875,
      "grad_norm": 2.050689697265625,
      "learning_rate": 2.7297794117647056e-06,
      "loss": 1.7299,
      "step": 595
    },
    {
      "epoch": 0.13694852941176472,
      "grad_norm": 2.1373417377471924,
      "learning_rate": 2.7343750000000004e-06,
      "loss": 1.7392,
      "step": 596
    },
    {
      "epoch": 0.1371783088235294,
      "grad_norm": 2.055236339569092,
      "learning_rate": 2.7389705882352947e-06,
      "loss": 1.6649,
      "step": 597
    },
    {
      "epoch": 0.13740808823529413,
      "grad_norm": 1.8151307106018066,
      "learning_rate": 2.7435661764705886e-06,
      "loss": 1.6725,
      "step": 598
    },
    {
      "epoch": 0.13763786764705882,
      "grad_norm": 1.9767706394195557,
      "learning_rate": 2.748161764705883e-06,
      "loss": 1.5641,
      "step": 599
    },
    {
      "epoch": 0.13786764705882354,
      "grad_norm": 1.8099255561828613,
      "learning_rate": 2.7527573529411764e-06,
      "loss": 1.6501,
      "step": 600
    },
    {
      "epoch": 0.13809742647058823,
      "grad_norm": 1.9163933992385864,
      "learning_rate": 2.757352941176471e-06,
      "loss": 1.7938,
      "step": 601
    },
    {
      "epoch": 0.13832720588235295,
      "grad_norm": 1.9029291868209839,
      "learning_rate": 2.7619485294117647e-06,
      "loss": 1.7836,
      "step": 602
    },
    {
      "epoch": 0.13855698529411764,
      "grad_norm": 1.7766666412353516,
      "learning_rate": 2.766544117647059e-06,
      "loss": 1.7806,
      "step": 603
    },
    {
      "epoch": 0.13878676470588236,
      "grad_norm": 2.024599552154541,
      "learning_rate": 2.771139705882353e-06,
      "loss": 1.5891,
      "step": 604
    },
    {
      "epoch": 0.13901654411764705,
      "grad_norm": 2.058452606201172,
      "learning_rate": 2.7757352941176472e-06,
      "loss": 1.7005,
      "step": 605
    },
    {
      "epoch": 0.13924632352941177,
      "grad_norm": 1.9918076992034912,
      "learning_rate": 2.780330882352941e-06,
      "loss": 1.7576,
      "step": 606
    },
    {
      "epoch": 0.13947610294117646,
      "grad_norm": 1.7439815998077393,
      "learning_rate": 2.7849264705882355e-06,
      "loss": 1.6775,
      "step": 607
    },
    {
      "epoch": 0.13970588235294118,
      "grad_norm": 1.7172232866287231,
      "learning_rate": 2.7895220588235294e-06,
      "loss": 1.7301,
      "step": 608
    },
    {
      "epoch": 0.13993566176470587,
      "grad_norm": 1.763515830039978,
      "learning_rate": 2.7941176470588237e-06,
      "loss": 1.6374,
      "step": 609
    },
    {
      "epoch": 0.1401654411764706,
      "grad_norm": 2.105971574783325,
      "learning_rate": 2.7987132352941176e-06,
      "loss": 1.5959,
      "step": 610
    },
    {
      "epoch": 0.14039522058823528,
      "grad_norm": 1.6706910133361816,
      "learning_rate": 2.803308823529412e-06,
      "loss": 1.6168,
      "step": 611
    },
    {
      "epoch": 0.140625,
      "grad_norm": 1.9129010438919067,
      "learning_rate": 2.807904411764706e-06,
      "loss": 1.6514,
      "step": 612
    },
    {
      "epoch": 0.14085477941176472,
      "grad_norm": 1.5713807344436646,
      "learning_rate": 2.8125e-06,
      "loss": 1.5775,
      "step": 613
    },
    {
      "epoch": 0.1410845588235294,
      "grad_norm": 1.9569053649902344,
      "learning_rate": 2.8170955882352945e-06,
      "loss": 1.7152,
      "step": 614
    },
    {
      "epoch": 0.14131433823529413,
      "grad_norm": 1.791799783706665,
      "learning_rate": 2.8216911764705884e-06,
      "loss": 1.5704,
      "step": 615
    },
    {
      "epoch": 0.14154411764705882,
      "grad_norm": 1.883469581604004,
      "learning_rate": 2.8262867647058827e-06,
      "loss": 1.6619,
      "step": 616
    },
    {
      "epoch": 0.14177389705882354,
      "grad_norm": 1.8646761178970337,
      "learning_rate": 2.8308823529411766e-06,
      "loss": 1.6078,
      "step": 617
    },
    {
      "epoch": 0.14200367647058823,
      "grad_norm": 1.6090351343154907,
      "learning_rate": 2.835477941176471e-06,
      "loss": 1.5761,
      "step": 618
    },
    {
      "epoch": 0.14223345588235295,
      "grad_norm": 1.8186532258987427,
      "learning_rate": 2.840073529411765e-06,
      "loss": 1.6045,
      "step": 619
    },
    {
      "epoch": 0.14246323529411764,
      "grad_norm": 1.4715001583099365,
      "learning_rate": 2.844669117647059e-06,
      "loss": 1.608,
      "step": 620
    },
    {
      "epoch": 0.14269301470588236,
      "grad_norm": 1.446036458015442,
      "learning_rate": 2.849264705882353e-06,
      "loss": 1.4876,
      "step": 621
    },
    {
      "epoch": 0.14292279411764705,
      "grad_norm": 1.8623100519180298,
      "learning_rate": 2.8538602941176474e-06,
      "loss": 1.5826,
      "step": 622
    },
    {
      "epoch": 0.14315257352941177,
      "grad_norm": 2.1226370334625244,
      "learning_rate": 2.8584558823529413e-06,
      "loss": 1.7407,
      "step": 623
    },
    {
      "epoch": 0.14338235294117646,
      "grad_norm": 1.7147152423858643,
      "learning_rate": 2.8630514705882357e-06,
      "loss": 1.5642,
      "step": 624
    },
    {
      "epoch": 0.14361213235294118,
      "grad_norm": 1.9789527654647827,
      "learning_rate": 2.8676470588235296e-06,
      "loss": 1.6644,
      "step": 625
    },
    {
      "epoch": 0.14384191176470587,
      "grad_norm": 1.854677677154541,
      "learning_rate": 2.872242647058824e-06,
      "loss": 1.5555,
      "step": 626
    },
    {
      "epoch": 0.1440716911764706,
      "grad_norm": 1.5443283319473267,
      "learning_rate": 2.876838235294118e-06,
      "loss": 1.5082,
      "step": 627
    },
    {
      "epoch": 0.14430147058823528,
      "grad_norm": 1.7179956436157227,
      "learning_rate": 2.881433823529412e-06,
      "loss": 1.6309,
      "step": 628
    },
    {
      "epoch": 0.14453125,
      "grad_norm": 1.7482643127441406,
      "learning_rate": 2.886029411764706e-06,
      "loss": 1.5446,
      "step": 629
    },
    {
      "epoch": 0.14476102941176472,
      "grad_norm": 2.249936819076538,
      "learning_rate": 2.8906250000000004e-06,
      "loss": 1.6399,
      "step": 630
    },
    {
      "epoch": 0.1449908088235294,
      "grad_norm": 1.7665846347808838,
      "learning_rate": 2.8952205882352947e-06,
      "loss": 1.5948,
      "step": 631
    },
    {
      "epoch": 0.14522058823529413,
      "grad_norm": 2.283902168273926,
      "learning_rate": 2.8998161764705886e-06,
      "loss": 1.7386,
      "step": 632
    },
    {
      "epoch": 0.14545036764705882,
      "grad_norm": 1.864943504333496,
      "learning_rate": 2.904411764705883e-06,
      "loss": 1.5642,
      "step": 633
    },
    {
      "epoch": 0.14568014705882354,
      "grad_norm": 1.86959969997406,
      "learning_rate": 2.909007352941177e-06,
      "loss": 1.6447,
      "step": 634
    },
    {
      "epoch": 0.14590992647058823,
      "grad_norm": 1.7284098863601685,
      "learning_rate": 2.913602941176471e-06,
      "loss": 1.5943,
      "step": 635
    },
    {
      "epoch": 0.14613970588235295,
      "grad_norm": 1.829307198524475,
      "learning_rate": 2.9181985294117647e-06,
      "loss": 1.5533,
      "step": 636
    },
    {
      "epoch": 0.14636948529411764,
      "grad_norm": 1.8923438787460327,
      "learning_rate": 2.9227941176470594e-06,
      "loss": 1.6231,
      "step": 637
    },
    {
      "epoch": 0.14659926470588236,
      "grad_norm": 1.6255217790603638,
      "learning_rate": 2.927389705882353e-06,
      "loss": 1.6039,
      "step": 638
    },
    {
      "epoch": 0.14682904411764705,
      "grad_norm": 1.8199702501296997,
      "learning_rate": 2.9319852941176472e-06,
      "loss": 1.6589,
      "step": 639
    },
    {
      "epoch": 0.14705882352941177,
      "grad_norm": 1.9724128246307373,
      "learning_rate": 2.936580882352941e-06,
      "loss": 1.643,
      "step": 640
    },
    {
      "epoch": 0.14728860294117646,
      "grad_norm": 1.8555887937545776,
      "learning_rate": 2.9411764705882355e-06,
      "loss": 1.6442,
      "step": 641
    },
    {
      "epoch": 0.14751838235294118,
      "grad_norm": 1.7873249053955078,
      "learning_rate": 2.9457720588235294e-06,
      "loss": 1.6294,
      "step": 642
    },
    {
      "epoch": 0.14774816176470587,
      "grad_norm": 2.393176555633545,
      "learning_rate": 2.9503676470588237e-06,
      "loss": 1.4959,
      "step": 643
    },
    {
      "epoch": 0.1479779411764706,
      "grad_norm": 1.7305110692977905,
      "learning_rate": 2.9549632352941176e-06,
      "loss": 1.6244,
      "step": 644
    },
    {
      "epoch": 0.14820772058823528,
      "grad_norm": 1.874386191368103,
      "learning_rate": 2.959558823529412e-06,
      "loss": 1.5539,
      "step": 645
    },
    {
      "epoch": 0.1484375,
      "grad_norm": 1.6896755695343018,
      "learning_rate": 2.964154411764706e-06,
      "loss": 1.4727,
      "step": 646
    },
    {
      "epoch": 0.14866727941176472,
      "grad_norm": 1.8637017011642456,
      "learning_rate": 2.96875e-06,
      "loss": 1.5167,
      "step": 647
    },
    {
      "epoch": 0.1488970588235294,
      "grad_norm": 1.8652368783950806,
      "learning_rate": 2.9733455882352945e-06,
      "loss": 1.6202,
      "step": 648
    },
    {
      "epoch": 0.14912683823529413,
      "grad_norm": 1.5739809274673462,
      "learning_rate": 2.9779411764705884e-06,
      "loss": 1.5455,
      "step": 649
    },
    {
      "epoch": 0.14935661764705882,
      "grad_norm": 1.9956119060516357,
      "learning_rate": 2.9825367647058827e-06,
      "loss": 1.6651,
      "step": 650
    },
    {
      "epoch": 0.14958639705882354,
      "grad_norm": 2.174240827560425,
      "learning_rate": 2.9871323529411766e-06,
      "loss": 1.5706,
      "step": 651
    },
    {
      "epoch": 0.14981617647058823,
      "grad_norm": 2.1916143894195557,
      "learning_rate": 2.991727941176471e-06,
      "loss": 1.5672,
      "step": 652
    },
    {
      "epoch": 0.15004595588235295,
      "grad_norm": 1.7628027200698853,
      "learning_rate": 2.996323529411765e-06,
      "loss": 1.5563,
      "step": 653
    },
    {
      "epoch": 0.15027573529411764,
      "grad_norm": 1.6791940927505493,
      "learning_rate": 3.000919117647059e-06,
      "loss": 1.4546,
      "step": 654
    },
    {
      "epoch": 0.15050551470588236,
      "grad_norm": 2.3491156101226807,
      "learning_rate": 3.005514705882353e-06,
      "loss": 1.6639,
      "step": 655
    },
    {
      "epoch": 0.15073529411764705,
      "grad_norm": 1.7998695373535156,
      "learning_rate": 3.0101102941176474e-06,
      "loss": 1.4411,
      "step": 656
    },
    {
      "epoch": 0.15096507352941177,
      "grad_norm": 1.6436800956726074,
      "learning_rate": 3.0147058823529413e-06,
      "loss": 1.5031,
      "step": 657
    },
    {
      "epoch": 0.15119485294117646,
      "grad_norm": 1.7832766771316528,
      "learning_rate": 3.0193014705882357e-06,
      "loss": 1.5421,
      "step": 658
    },
    {
      "epoch": 0.15142463235294118,
      "grad_norm": 1.9831347465515137,
      "learning_rate": 3.0238970588235296e-06,
      "loss": 1.6045,
      "step": 659
    },
    {
      "epoch": 0.15165441176470587,
      "grad_norm": 1.5335240364074707,
      "learning_rate": 3.028492647058824e-06,
      "loss": 1.4102,
      "step": 660
    },
    {
      "epoch": 0.1518841911764706,
      "grad_norm": 1.888569951057434,
      "learning_rate": 3.033088235294118e-06,
      "loss": 1.6352,
      "step": 661
    },
    {
      "epoch": 0.15211397058823528,
      "grad_norm": 1.9508765935897827,
      "learning_rate": 3.037683823529412e-06,
      "loss": 1.5753,
      "step": 662
    },
    {
      "epoch": 0.15234375,
      "grad_norm": 1.7474262714385986,
      "learning_rate": 3.042279411764706e-06,
      "loss": 1.5663,
      "step": 663
    },
    {
      "epoch": 0.15257352941176472,
      "grad_norm": 2.1249382495880127,
      "learning_rate": 3.0468750000000004e-06,
      "loss": 1.5349,
      "step": 664
    },
    {
      "epoch": 0.1528033088235294,
      "grad_norm": 2.43401837348938,
      "learning_rate": 3.0514705882352947e-06,
      "loss": 1.5395,
      "step": 665
    },
    {
      "epoch": 0.15303308823529413,
      "grad_norm": 2.201918363571167,
      "learning_rate": 3.0560661764705886e-06,
      "loss": 1.5918,
      "step": 666
    },
    {
      "epoch": 0.15326286764705882,
      "grad_norm": 1.9429981708526611,
      "learning_rate": 3.060661764705883e-06,
      "loss": 1.4787,
      "step": 667
    },
    {
      "epoch": 0.15349264705882354,
      "grad_norm": 1.509531021118164,
      "learning_rate": 3.065257352941177e-06,
      "loss": 1.3949,
      "step": 668
    },
    {
      "epoch": 0.15372242647058823,
      "grad_norm": 1.8337900638580322,
      "learning_rate": 3.069852941176471e-06,
      "loss": 1.5177,
      "step": 669
    },
    {
      "epoch": 0.15395220588235295,
      "grad_norm": 2.275456428527832,
      "learning_rate": 3.0744485294117646e-06,
      "loss": 1.5398,
      "step": 670
    },
    {
      "epoch": 0.15418198529411764,
      "grad_norm": 2.2067935466766357,
      "learning_rate": 3.0790441176470594e-06,
      "loss": 1.5992,
      "step": 671
    },
    {
      "epoch": 0.15441176470588236,
      "grad_norm": 1.7899973392486572,
      "learning_rate": 3.083639705882353e-06,
      "loss": 1.3974,
      "step": 672
    },
    {
      "epoch": 0.15464154411764705,
      "grad_norm": 1.938049554824829,
      "learning_rate": 3.0882352941176476e-06,
      "loss": 1.544,
      "step": 673
    },
    {
      "epoch": 0.15487132352941177,
      "grad_norm": 1.7820258140563965,
      "learning_rate": 3.092830882352941e-06,
      "loss": 1.3881,
      "step": 674
    },
    {
      "epoch": 0.15510110294117646,
      "grad_norm": 1.9083582162857056,
      "learning_rate": 3.0974264705882354e-06,
      "loss": 1.4501,
      "step": 675
    },
    {
      "epoch": 0.15533088235294118,
      "grad_norm": 2.1298298835754395,
      "learning_rate": 3.1020220588235294e-06,
      "loss": 1.5373,
      "step": 676
    },
    {
      "epoch": 0.15556066176470587,
      "grad_norm": 2.034464120864868,
      "learning_rate": 3.1066176470588237e-06,
      "loss": 1.4329,
      "step": 677
    },
    {
      "epoch": 0.1557904411764706,
      "grad_norm": 1.9801183938980103,
      "learning_rate": 3.1112132352941176e-06,
      "loss": 1.6,
      "step": 678
    },
    {
      "epoch": 0.15602022058823528,
      "grad_norm": 1.9967079162597656,
      "learning_rate": 3.115808823529412e-06,
      "loss": 1.6006,
      "step": 679
    },
    {
      "epoch": 0.15625,
      "grad_norm": 1.8465495109558105,
      "learning_rate": 3.120404411764706e-06,
      "loss": 1.487,
      "step": 680
    },
    {
      "epoch": 0.15647977941176472,
      "grad_norm": 1.726859450340271,
      "learning_rate": 3.125e-06,
      "loss": 1.4658,
      "step": 681
    },
    {
      "epoch": 0.1567095588235294,
      "grad_norm": 1.6404646635055542,
      "learning_rate": 3.1295955882352945e-06,
      "loss": 1.4767,
      "step": 682
    },
    {
      "epoch": 0.15693933823529413,
      "grad_norm": 1.8253607749938965,
      "learning_rate": 3.1341911764705884e-06,
      "loss": 1.3166,
      "step": 683
    },
    {
      "epoch": 0.15716911764705882,
      "grad_norm": 1.4912976026535034,
      "learning_rate": 3.1387867647058827e-06,
      "loss": 1.3981,
      "step": 684
    },
    {
      "epoch": 0.15739889705882354,
      "grad_norm": 2.0387017726898193,
      "learning_rate": 3.1433823529411766e-06,
      "loss": 1.4178,
      "step": 685
    },
    {
      "epoch": 0.15762867647058823,
      "grad_norm": 1.819126009941101,
      "learning_rate": 3.147977941176471e-06,
      "loss": 1.4736,
      "step": 686
    },
    {
      "epoch": 0.15785845588235295,
      "grad_norm": 2.2327120304107666,
      "learning_rate": 3.152573529411765e-06,
      "loss": 1.5207,
      "step": 687
    },
    {
      "epoch": 0.15808823529411764,
      "grad_norm": 1.5961315631866455,
      "learning_rate": 3.157169117647059e-06,
      "loss": 1.3879,
      "step": 688
    },
    {
      "epoch": 0.15831801470588236,
      "grad_norm": 2.0383551120758057,
      "learning_rate": 3.161764705882353e-06,
      "loss": 1.4257,
      "step": 689
    },
    {
      "epoch": 0.15854779411764705,
      "grad_norm": 1.5690735578536987,
      "learning_rate": 3.1663602941176474e-06,
      "loss": 1.3375,
      "step": 690
    },
    {
      "epoch": 0.15877757352941177,
      "grad_norm": 1.7773221731185913,
      "learning_rate": 3.1709558823529413e-06,
      "loss": 1.4514,
      "step": 691
    },
    {
      "epoch": 0.15900735294117646,
      "grad_norm": 1.7950518131256104,
      "learning_rate": 3.1755514705882357e-06,
      "loss": 1.3803,
      "step": 692
    },
    {
      "epoch": 0.15923713235294118,
      "grad_norm": 1.6486812829971313,
      "learning_rate": 3.1801470588235296e-06,
      "loss": 1.4758,
      "step": 693
    },
    {
      "epoch": 0.15946691176470587,
      "grad_norm": 1.7138744592666626,
      "learning_rate": 3.184742647058824e-06,
      "loss": 1.4306,
      "step": 694
    },
    {
      "epoch": 0.1596966911764706,
      "grad_norm": 1.9375605583190918,
      "learning_rate": 3.189338235294118e-06,
      "loss": 1.5061,
      "step": 695
    },
    {
      "epoch": 0.15992647058823528,
      "grad_norm": 1.6058781147003174,
      "learning_rate": 3.193933823529412e-06,
      "loss": 1.3716,
      "step": 696
    },
    {
      "epoch": 0.16015625,
      "grad_norm": 1.7152756452560425,
      "learning_rate": 3.198529411764706e-06,
      "loss": 1.448,
      "step": 697
    },
    {
      "epoch": 0.16038602941176472,
      "grad_norm": 1.6655035018920898,
      "learning_rate": 3.2031250000000004e-06,
      "loss": 1.4543,
      "step": 698
    },
    {
      "epoch": 0.1606158088235294,
      "grad_norm": 1.7221311330795288,
      "learning_rate": 3.2077205882352947e-06,
      "loss": 1.4202,
      "step": 699
    },
    {
      "epoch": 0.16084558823529413,
      "grad_norm": 1.7233232259750366,
      "learning_rate": 3.2123161764705886e-06,
      "loss": 1.4068,
      "step": 700
    },
    {
      "epoch": 0.16107536764705882,
      "grad_norm": 1.7602843046188354,
      "learning_rate": 3.216911764705883e-06,
      "loss": 1.4717,
      "step": 701
    },
    {
      "epoch": 0.16130514705882354,
      "grad_norm": 1.7757936716079712,
      "learning_rate": 3.221507352941177e-06,
      "loss": 1.3741,
      "step": 702
    },
    {
      "epoch": 0.16153492647058823,
      "grad_norm": 1.693404197692871,
      "learning_rate": 3.226102941176471e-06,
      "loss": 1.4411,
      "step": 703
    },
    {
      "epoch": 0.16176470588235295,
      "grad_norm": 1.6516579389572144,
      "learning_rate": 3.230698529411765e-06,
      "loss": 1.4099,
      "step": 704
    },
    {
      "epoch": 0.16199448529411764,
      "grad_norm": 1.638645052909851,
      "learning_rate": 3.2352941176470594e-06,
      "loss": 1.4205,
      "step": 705
    },
    {
      "epoch": 0.16222426470588236,
      "grad_norm": 2.089038133621216,
      "learning_rate": 3.239889705882353e-06,
      "loss": 1.3989,
      "step": 706
    },
    {
      "epoch": 0.16245404411764705,
      "grad_norm": 1.7867484092712402,
      "learning_rate": 3.2444852941176476e-06,
      "loss": 1.236,
      "step": 707
    },
    {
      "epoch": 0.16268382352941177,
      "grad_norm": 1.7001184225082397,
      "learning_rate": 3.249080882352941e-06,
      "loss": 1.3628,
      "step": 708
    },
    {
      "epoch": 0.16291360294117646,
      "grad_norm": 1.565622091293335,
      "learning_rate": 3.253676470588236e-06,
      "loss": 1.2882,
      "step": 709
    },
    {
      "epoch": 0.16314338235294118,
      "grad_norm": 2.059086322784424,
      "learning_rate": 3.2582720588235293e-06,
      "loss": 1.3797,
      "step": 710
    },
    {
      "epoch": 0.16337316176470587,
      "grad_norm": 1.5537117719650269,
      "learning_rate": 3.2628676470588237e-06,
      "loss": 1.4,
      "step": 711
    },
    {
      "epoch": 0.1636029411764706,
      "grad_norm": 1.436509132385254,
      "learning_rate": 3.2674632352941176e-06,
      "loss": 1.2879,
      "step": 712
    },
    {
      "epoch": 0.16383272058823528,
      "grad_norm": 1.8669941425323486,
      "learning_rate": 3.272058823529412e-06,
      "loss": 1.2858,
      "step": 713
    },
    {
      "epoch": 0.1640625,
      "grad_norm": 1.7501447200775146,
      "learning_rate": 3.276654411764706e-06,
      "loss": 1.3869,
      "step": 714
    },
    {
      "epoch": 0.16429227941176472,
      "grad_norm": 1.921918511390686,
      "learning_rate": 3.28125e-06,
      "loss": 1.2703,
      "step": 715
    },
    {
      "epoch": 0.1645220588235294,
      "grad_norm": 1.7125686407089233,
      "learning_rate": 3.2858455882352945e-06,
      "loss": 1.3523,
      "step": 716
    },
    {
      "epoch": 0.16475183823529413,
      "grad_norm": 1.6623313426971436,
      "learning_rate": 3.2904411764705884e-06,
      "loss": 1.3481,
      "step": 717
    },
    {
      "epoch": 0.16498161764705882,
      "grad_norm": 1.58990478515625,
      "learning_rate": 3.2950367647058827e-06,
      "loss": 1.2624,
      "step": 718
    },
    {
      "epoch": 0.16521139705882354,
      "grad_norm": 1.6209717988967896,
      "learning_rate": 3.2996323529411766e-06,
      "loss": 1.2951,
      "step": 719
    },
    {
      "epoch": 0.16544117647058823,
      "grad_norm": 1.7351701259613037,
      "learning_rate": 3.304227941176471e-06,
      "loss": 1.4028,
      "step": 720
    },
    {
      "epoch": 0.16567095588235295,
      "grad_norm": 1.695424199104309,
      "learning_rate": 3.308823529411765e-06,
      "loss": 1.3359,
      "step": 721
    },
    {
      "epoch": 0.16590073529411764,
      "grad_norm": 1.5338176488876343,
      "learning_rate": 3.313419117647059e-06,
      "loss": 1.3758,
      "step": 722
    },
    {
      "epoch": 0.16613051470588236,
      "grad_norm": 1.5150989294052124,
      "learning_rate": 3.318014705882353e-06,
      "loss": 1.2596,
      "step": 723
    },
    {
      "epoch": 0.16636029411764705,
      "grad_norm": 2.0055480003356934,
      "learning_rate": 3.3226102941176474e-06,
      "loss": 1.4392,
      "step": 724
    },
    {
      "epoch": 0.16659007352941177,
      "grad_norm": 1.529941201210022,
      "learning_rate": 3.3272058823529413e-06,
      "loss": 1.2789,
      "step": 725
    },
    {
      "epoch": 0.16681985294117646,
      "grad_norm": 1.918836236000061,
      "learning_rate": 3.3318014705882356e-06,
      "loss": 1.3475,
      "step": 726
    },
    {
      "epoch": 0.16704963235294118,
      "grad_norm": 1.6435238122940063,
      "learning_rate": 3.3363970588235295e-06,
      "loss": 1.3352,
      "step": 727
    },
    {
      "epoch": 0.16727941176470587,
      "grad_norm": 1.5470702648162842,
      "learning_rate": 3.340992647058824e-06,
      "loss": 1.2919,
      "step": 728
    },
    {
      "epoch": 0.1675091911764706,
      "grad_norm": 1.6085113286972046,
      "learning_rate": 3.3455882352941178e-06,
      "loss": 1.3661,
      "step": 729
    },
    {
      "epoch": 0.16773897058823528,
      "grad_norm": 2.072573184967041,
      "learning_rate": 3.350183823529412e-06,
      "loss": 1.3321,
      "step": 730
    },
    {
      "epoch": 0.16796875,
      "grad_norm": 1.6956905126571655,
      "learning_rate": 3.354779411764706e-06,
      "loss": 1.2544,
      "step": 731
    },
    {
      "epoch": 0.16819852941176472,
      "grad_norm": 1.6837058067321777,
      "learning_rate": 3.3593750000000003e-06,
      "loss": 1.3364,
      "step": 732
    },
    {
      "epoch": 0.1684283088235294,
      "grad_norm": 1.7105425596237183,
      "learning_rate": 3.3639705882352947e-06,
      "loss": 1.3562,
      "step": 733
    },
    {
      "epoch": 0.16865808823529413,
      "grad_norm": 1.7302762269973755,
      "learning_rate": 3.3685661764705886e-06,
      "loss": 1.2725,
      "step": 734
    },
    {
      "epoch": 0.16888786764705882,
      "grad_norm": 1.7497386932373047,
      "learning_rate": 3.373161764705883e-06,
      "loss": 1.2882,
      "step": 735
    },
    {
      "epoch": 0.16911764705882354,
      "grad_norm": 1.8076443672180176,
      "learning_rate": 3.377757352941177e-06,
      "loss": 1.3431,
      "step": 736
    },
    {
      "epoch": 0.16934742647058823,
      "grad_norm": 1.6428172588348389,
      "learning_rate": 3.382352941176471e-06,
      "loss": 1.241,
      "step": 737
    },
    {
      "epoch": 0.16957720588235295,
      "grad_norm": 1.8436733484268188,
      "learning_rate": 3.386948529411765e-06,
      "loss": 1.3362,
      "step": 738
    },
    {
      "epoch": 0.16980698529411764,
      "grad_norm": 1.8562572002410889,
      "learning_rate": 3.3915441176470594e-06,
      "loss": 1.2797,
      "step": 739
    },
    {
      "epoch": 0.17003676470588236,
      "grad_norm": 1.8909908533096313,
      "learning_rate": 3.3961397058823533e-06,
      "loss": 1.228,
      "step": 740
    },
    {
      "epoch": 0.17026654411764705,
      "grad_norm": 1.8509927988052368,
      "learning_rate": 3.4007352941176476e-06,
      "loss": 1.1846,
      "step": 741
    },
    {
      "epoch": 0.17049632352941177,
      "grad_norm": 1.831346035003662,
      "learning_rate": 3.405330882352941e-06,
      "loss": 1.3507,
      "step": 742
    },
    {
      "epoch": 0.17072610294117646,
      "grad_norm": 1.9708150625228882,
      "learning_rate": 3.409926470588236e-06,
      "loss": 1.2316,
      "step": 743
    },
    {
      "epoch": 0.17095588235294118,
      "grad_norm": 2.1740076541900635,
      "learning_rate": 3.4145220588235293e-06,
      "loss": 1.2419,
      "step": 744
    },
    {
      "epoch": 0.17118566176470587,
      "grad_norm": 1.813158631324768,
      "learning_rate": 3.419117647058824e-06,
      "loss": 1.2911,
      "step": 745
    },
    {
      "epoch": 0.1714154411764706,
      "grad_norm": 2.1079776287078857,
      "learning_rate": 3.4237132352941176e-06,
      "loss": 1.1899,
      "step": 746
    },
    {
      "epoch": 0.17164522058823528,
      "grad_norm": 1.5746970176696777,
      "learning_rate": 3.428308823529412e-06,
      "loss": 1.1435,
      "step": 747
    },
    {
      "epoch": 0.171875,
      "grad_norm": 1.565003752708435,
      "learning_rate": 3.432904411764706e-06,
      "loss": 1.2996,
      "step": 748
    },
    {
      "epoch": 0.17210477941176472,
      "grad_norm": 1.6275780200958252,
      "learning_rate": 3.4375e-06,
      "loss": 1.2697,
      "step": 749
    },
    {
      "epoch": 0.1723345588235294,
      "grad_norm": 1.7620108127593994,
      "learning_rate": 3.4420955882352945e-06,
      "loss": 1.2925,
      "step": 750
    },
    {
      "epoch": 0.17256433823529413,
      "grad_norm": 1.6046173572540283,
      "learning_rate": 3.4466911764705884e-06,
      "loss": 1.2261,
      "step": 751
    },
    {
      "epoch": 0.17279411764705882,
      "grad_norm": 1.935591459274292,
      "learning_rate": 3.4512867647058827e-06,
      "loss": 1.394,
      "step": 752
    },
    {
      "epoch": 0.17302389705882354,
      "grad_norm": 1.7258957624435425,
      "learning_rate": 3.4558823529411766e-06,
      "loss": 1.3162,
      "step": 753
    },
    {
      "epoch": 0.17325367647058823,
      "grad_norm": 1.641406536102295,
      "learning_rate": 3.460477941176471e-06,
      "loss": 1.2362,
      "step": 754
    },
    {
      "epoch": 0.17348345588235295,
      "grad_norm": 1.6193556785583496,
      "learning_rate": 3.465073529411765e-06,
      "loss": 1.1276,
      "step": 755
    },
    {
      "epoch": 0.17371323529411764,
      "grad_norm": 1.8055915832519531,
      "learning_rate": 3.469669117647059e-06,
      "loss": 1.312,
      "step": 756
    },
    {
      "epoch": 0.17394301470588236,
      "grad_norm": 1.674411654472351,
      "learning_rate": 3.474264705882353e-06,
      "loss": 1.2353,
      "step": 757
    },
    {
      "epoch": 0.17417279411764705,
      "grad_norm": 1.7533938884735107,
      "learning_rate": 3.4788602941176474e-06,
      "loss": 1.1973,
      "step": 758
    },
    {
      "epoch": 0.17440257352941177,
      "grad_norm": 1.6614657640457153,
      "learning_rate": 3.4834558823529413e-06,
      "loss": 1.1873,
      "step": 759
    },
    {
      "epoch": 0.17463235294117646,
      "grad_norm": 1.395356297492981,
      "learning_rate": 3.4880514705882356e-06,
      "loss": 1.15,
      "step": 760
    },
    {
      "epoch": 0.17486213235294118,
      "grad_norm": 1.781636357307434,
      "learning_rate": 3.4926470588235295e-06,
      "loss": 1.1927,
      "step": 761
    },
    {
      "epoch": 0.17509191176470587,
      "grad_norm": 1.5820071697235107,
      "learning_rate": 3.497242647058824e-06,
      "loss": 1.2017,
      "step": 762
    },
    {
      "epoch": 0.1753216911764706,
      "grad_norm": 1.8631591796875,
      "learning_rate": 3.5018382352941178e-06,
      "loss": 1.2842,
      "step": 763
    },
    {
      "epoch": 0.17555147058823528,
      "grad_norm": 1.7256264686584473,
      "learning_rate": 3.506433823529412e-06,
      "loss": 1.1808,
      "step": 764
    },
    {
      "epoch": 0.17578125,
      "grad_norm": 1.702239990234375,
      "learning_rate": 3.511029411764706e-06,
      "loss": 1.1175,
      "step": 765
    },
    {
      "epoch": 0.17601102941176472,
      "grad_norm": 1.737647294998169,
      "learning_rate": 3.5156250000000003e-06,
      "loss": 1.2661,
      "step": 766
    },
    {
      "epoch": 0.1762408088235294,
      "grad_norm": 2.0659027099609375,
      "learning_rate": 3.5202205882352947e-06,
      "loss": 1.2484,
      "step": 767
    },
    {
      "epoch": 0.17647058823529413,
      "grad_norm": 1.616379976272583,
      "learning_rate": 3.5248161764705886e-06,
      "loss": 1.1585,
      "step": 768
    },
    {
      "epoch": 0.17670036764705882,
      "grad_norm": 1.764746904373169,
      "learning_rate": 3.529411764705883e-06,
      "loss": 1.2034,
      "step": 769
    },
    {
      "epoch": 0.17693014705882354,
      "grad_norm": 1.8183270692825317,
      "learning_rate": 3.534007352941177e-06,
      "loss": 1.1896,
      "step": 770
    },
    {
      "epoch": 0.17715992647058823,
      "grad_norm": 1.7283618450164795,
      "learning_rate": 3.538602941176471e-06,
      "loss": 1.2321,
      "step": 771
    },
    {
      "epoch": 0.17738970588235295,
      "grad_norm": 2.2466914653778076,
      "learning_rate": 3.543198529411765e-06,
      "loss": 1.2168,
      "step": 772
    },
    {
      "epoch": 0.17761948529411764,
      "grad_norm": 1.9592431783676147,
      "learning_rate": 3.5477941176470594e-06,
      "loss": 1.3042,
      "step": 773
    },
    {
      "epoch": 0.17784926470588236,
      "grad_norm": 1.6461888551712036,
      "learning_rate": 3.5523897058823533e-06,
      "loss": 1.2143,
      "step": 774
    },
    {
      "epoch": 0.17807904411764705,
      "grad_norm": 1.5953601598739624,
      "learning_rate": 3.5569852941176476e-06,
      "loss": 1.1406,
      "step": 775
    },
    {
      "epoch": 0.17830882352941177,
      "grad_norm": 1.6344548463821411,
      "learning_rate": 3.5615808823529415e-06,
      "loss": 1.2367,
      "step": 776
    },
    {
      "epoch": 0.17853860294117646,
      "grad_norm": 1.7817708253860474,
      "learning_rate": 3.566176470588236e-06,
      "loss": 1.2882,
      "step": 777
    },
    {
      "epoch": 0.17876838235294118,
      "grad_norm": 1.8805348873138428,
      "learning_rate": 3.5707720588235293e-06,
      "loss": 1.1438,
      "step": 778
    },
    {
      "epoch": 0.17899816176470587,
      "grad_norm": 1.529781460762024,
      "learning_rate": 3.575367647058824e-06,
      "loss": 1.0997,
      "step": 779
    },
    {
      "epoch": 0.1792279411764706,
      "grad_norm": 2.047342300415039,
      "learning_rate": 3.5799632352941175e-06,
      "loss": 1.2682,
      "step": 780
    },
    {
      "epoch": 0.17945772058823528,
      "grad_norm": 1.4201310873031616,
      "learning_rate": 3.5845588235294123e-06,
      "loss": 1.1034,
      "step": 781
    },
    {
      "epoch": 0.1796875,
      "grad_norm": 1.6195783615112305,
      "learning_rate": 3.5891544117647058e-06,
      "loss": 1.1176,
      "step": 782
    },
    {
      "epoch": 0.17991727941176472,
      "grad_norm": 1.535452961921692,
      "learning_rate": 3.59375e-06,
      "loss": 1.1372,
      "step": 783
    },
    {
      "epoch": 0.1801470588235294,
      "grad_norm": 1.3658406734466553,
      "learning_rate": 3.598345588235295e-06,
      "loss": 1.1424,
      "step": 784
    },
    {
      "epoch": 0.18037683823529413,
      "grad_norm": 1.9878777265548706,
      "learning_rate": 3.6029411764705883e-06,
      "loss": 1.0747,
      "step": 785
    },
    {
      "epoch": 0.18060661764705882,
      "grad_norm": 1.4101896286010742,
      "learning_rate": 3.6075367647058827e-06,
      "loss": 1.098,
      "step": 786
    },
    {
      "epoch": 0.18083639705882354,
      "grad_norm": 1.7163962125778198,
      "learning_rate": 3.6121323529411766e-06,
      "loss": 1.1349,
      "step": 787
    },
    {
      "epoch": 0.18106617647058823,
      "grad_norm": 2.316403388977051,
      "learning_rate": 3.616727941176471e-06,
      "loss": 1.1916,
      "step": 788
    },
    {
      "epoch": 0.18129595588235295,
      "grad_norm": 1.4707937240600586,
      "learning_rate": 3.621323529411765e-06,
      "loss": 1.0885,
      "step": 789
    },
    {
      "epoch": 0.18152573529411764,
      "grad_norm": 1.656314730644226,
      "learning_rate": 3.625919117647059e-06,
      "loss": 1.1683,
      "step": 790
    },
    {
      "epoch": 0.18175551470588236,
      "grad_norm": 1.6902908086776733,
      "learning_rate": 3.630514705882353e-06,
      "loss": 1.1222,
      "step": 791
    },
    {
      "epoch": 0.18198529411764705,
      "grad_norm": 1.5456408262252808,
      "learning_rate": 3.6351102941176474e-06,
      "loss": 1.1341,
      "step": 792
    },
    {
      "epoch": 0.18221507352941177,
      "grad_norm": 1.4710289239883423,
      "learning_rate": 3.6397058823529413e-06,
      "loss": 1.1439,
      "step": 793
    },
    {
      "epoch": 0.18244485294117646,
      "grad_norm": 1.6094634532928467,
      "learning_rate": 3.6443014705882356e-06,
      "loss": 1.1404,
      "step": 794
    },
    {
      "epoch": 0.18267463235294118,
      "grad_norm": 1.4200563430786133,
      "learning_rate": 3.6488970588235295e-06,
      "loss": 1.189,
      "step": 795
    },
    {
      "epoch": 0.18290441176470587,
      "grad_norm": 1.7290862798690796,
      "learning_rate": 3.653492647058824e-06,
      "loss": 1.1516,
      "step": 796
    },
    {
      "epoch": 0.1831341911764706,
      "grad_norm": 1.6300379037857056,
      "learning_rate": 3.6580882352941178e-06,
      "loss": 1.1052,
      "step": 797
    },
    {
      "epoch": 0.18336397058823528,
      "grad_norm": 1.7973228693008423,
      "learning_rate": 3.662683823529412e-06,
      "loss": 1.1328,
      "step": 798
    },
    {
      "epoch": 0.18359375,
      "grad_norm": 1.7244329452514648,
      "learning_rate": 3.667279411764706e-06,
      "loss": 1.1627,
      "step": 799
    },
    {
      "epoch": 0.18382352941176472,
      "grad_norm": 1.866358995437622,
      "learning_rate": 3.6718750000000003e-06,
      "loss": 1.1479,
      "step": 800
    },
    {
      "epoch": 0.1840533088235294,
      "grad_norm": 1.4747124910354614,
      "learning_rate": 3.6764705882352946e-06,
      "loss": 1.1273,
      "step": 801
    },
    {
      "epoch": 0.18428308823529413,
      "grad_norm": 1.411651611328125,
      "learning_rate": 3.6810661764705885e-06,
      "loss": 1.0746,
      "step": 802
    },
    {
      "epoch": 0.18451286764705882,
      "grad_norm": 1.7772252559661865,
      "learning_rate": 3.685661764705883e-06,
      "loss": 1.0641,
      "step": 803
    },
    {
      "epoch": 0.18474264705882354,
      "grad_norm": 1.3737878799438477,
      "learning_rate": 3.6902573529411768e-06,
      "loss": 1.1727,
      "step": 804
    },
    {
      "epoch": 0.18497242647058823,
      "grad_norm": 1.4904980659484863,
      "learning_rate": 3.694852941176471e-06,
      "loss": 1.076,
      "step": 805
    },
    {
      "epoch": 0.18520220588235295,
      "grad_norm": 1.6441643238067627,
      "learning_rate": 3.699448529411765e-06,
      "loss": 1.0896,
      "step": 806
    },
    {
      "epoch": 0.18543198529411764,
      "grad_norm": 1.820467472076416,
      "learning_rate": 3.7040441176470593e-06,
      "loss": 1.155,
      "step": 807
    },
    {
      "epoch": 0.18566176470588236,
      "grad_norm": 1.384543776512146,
      "learning_rate": 3.7086397058823533e-06,
      "loss": 1.0711,
      "step": 808
    },
    {
      "epoch": 0.18589154411764705,
      "grad_norm": 2.0599660873413086,
      "learning_rate": 3.7132352941176476e-06,
      "loss": 1.0984,
      "step": 809
    },
    {
      "epoch": 0.18612132352941177,
      "grad_norm": 1.486453890800476,
      "learning_rate": 3.7178308823529415e-06,
      "loss": 1.1167,
      "step": 810
    },
    {
      "epoch": 0.18635110294117646,
      "grad_norm": 1.7592350244522095,
      "learning_rate": 3.722426470588236e-06,
      "loss": 1.045,
      "step": 811
    },
    {
      "epoch": 0.18658088235294118,
      "grad_norm": 1.7933671474456787,
      "learning_rate": 3.7270220588235297e-06,
      "loss": 1.1656,
      "step": 812
    },
    {
      "epoch": 0.18681066176470587,
      "grad_norm": 1.7020717859268188,
      "learning_rate": 3.731617647058824e-06,
      "loss": 1.098,
      "step": 813
    },
    {
      "epoch": 0.1870404411764706,
      "grad_norm": 1.51386296749115,
      "learning_rate": 3.7362132352941175e-06,
      "loss": 1.1109,
      "step": 814
    },
    {
      "epoch": 0.18727022058823528,
      "grad_norm": 1.7692327499389648,
      "learning_rate": 3.7408088235294123e-06,
      "loss": 1.1433,
      "step": 815
    },
    {
      "epoch": 0.1875,
      "grad_norm": 1.4973427057266235,
      "learning_rate": 3.7454044117647058e-06,
      "loss": 1.1449,
      "step": 816
    },
    {
      "epoch": 0.18772977941176472,
      "grad_norm": 1.7206523418426514,
      "learning_rate": 3.7500000000000005e-06,
      "loss": 1.1645,
      "step": 817
    },
    {
      "epoch": 0.1879595588235294,
      "grad_norm": 1.8043659925460815,
      "learning_rate": 3.754595588235295e-06,
      "loss": 1.1249,
      "step": 818
    },
    {
      "epoch": 0.18818933823529413,
      "grad_norm": 1.7179452180862427,
      "learning_rate": 3.7591911764705883e-06,
      "loss": 1.0654,
      "step": 819
    },
    {
      "epoch": 0.18841911764705882,
      "grad_norm": 1.6514767408370972,
      "learning_rate": 3.763786764705883e-06,
      "loss": 1.0279,
      "step": 820
    },
    {
      "epoch": 0.18864889705882354,
      "grad_norm": 1.9518486261367798,
      "learning_rate": 3.7683823529411766e-06,
      "loss": 1.1033,
      "step": 821
    },
    {
      "epoch": 0.18887867647058823,
      "grad_norm": 1.7954096794128418,
      "learning_rate": 3.772977941176471e-06,
      "loss": 1.1366,
      "step": 822
    },
    {
      "epoch": 0.18910845588235295,
      "grad_norm": 1.515099048614502,
      "learning_rate": 3.777573529411765e-06,
      "loss": 1.0546,
      "step": 823
    },
    {
      "epoch": 0.18933823529411764,
      "grad_norm": 1.431091070175171,
      "learning_rate": 3.782169117647059e-06,
      "loss": 1.0689,
      "step": 824
    },
    {
      "epoch": 0.18956801470588236,
      "grad_norm": 1.65492582321167,
      "learning_rate": 3.786764705882353e-06,
      "loss": 1.1282,
      "step": 825
    },
    {
      "epoch": 0.18979779411764705,
      "grad_norm": 1.7830851078033447,
      "learning_rate": 3.7913602941176474e-06,
      "loss": 1.0598,
      "step": 826
    },
    {
      "epoch": 0.19002757352941177,
      "grad_norm": 1.5708767175674438,
      "learning_rate": 3.7959558823529413e-06,
      "loss": 1.0198,
      "step": 827
    },
    {
      "epoch": 0.19025735294117646,
      "grad_norm": 1.3326232433319092,
      "learning_rate": 3.8005514705882356e-06,
      "loss": 1.0708,
      "step": 828
    },
    {
      "epoch": 0.19048713235294118,
      "grad_norm": 1.6853517293930054,
      "learning_rate": 3.8051470588235295e-06,
      "loss": 1.1564,
      "step": 829
    },
    {
      "epoch": 0.19071691176470587,
      "grad_norm": 1.6463109254837036,
      "learning_rate": 3.809742647058824e-06,
      "loss": 1.1099,
      "step": 830
    },
    {
      "epoch": 0.1909466911764706,
      "grad_norm": 1.6003634929656982,
      "learning_rate": 3.8143382352941177e-06,
      "loss": 1.0316,
      "step": 831
    },
    {
      "epoch": 0.19117647058823528,
      "grad_norm": 1.4620078802108765,
      "learning_rate": 3.818933823529412e-06,
      "loss": 1.046,
      "step": 832
    },
    {
      "epoch": 0.19140625,
      "grad_norm": 1.1915606260299683,
      "learning_rate": 3.8235294117647055e-06,
      "loss": 1.0092,
      "step": 833
    },
    {
      "epoch": 0.19163602941176472,
      "grad_norm": 1.4626421928405762,
      "learning_rate": 3.828125000000001e-06,
      "loss": 1.0103,
      "step": 834
    },
    {
      "epoch": 0.1918658088235294,
      "grad_norm": 1.5930784940719604,
      "learning_rate": 3.832720588235295e-06,
      "loss": 1.1243,
      "step": 835
    },
    {
      "epoch": 0.19209558823529413,
      "grad_norm": 1.610852599143982,
      "learning_rate": 3.8373161764705885e-06,
      "loss": 1.0578,
      "step": 836
    },
    {
      "epoch": 0.19232536764705882,
      "grad_norm": 1.567981481552124,
      "learning_rate": 3.841911764705883e-06,
      "loss": 1.0294,
      "step": 837
    },
    {
      "epoch": 0.19255514705882354,
      "grad_norm": 1.8432629108428955,
      "learning_rate": 3.846507352941176e-06,
      "loss": 0.9802,
      "step": 838
    },
    {
      "epoch": 0.19278492647058823,
      "grad_norm": 1.4926036596298218,
      "learning_rate": 3.8511029411764715e-06,
      "loss": 0.9891,
      "step": 839
    },
    {
      "epoch": 0.19301470588235295,
      "grad_norm": 1.479980230331421,
      "learning_rate": 3.855698529411765e-06,
      "loss": 0.9451,
      "step": 840
    },
    {
      "epoch": 0.19324448529411764,
      "grad_norm": 1.4589775800704956,
      "learning_rate": 3.860294117647059e-06,
      "loss": 1.1295,
      "step": 841
    },
    {
      "epoch": 0.19347426470588236,
      "grad_norm": 1.5986815690994263,
      "learning_rate": 3.864889705882353e-06,
      "loss": 1.0398,
      "step": 842
    },
    {
      "epoch": 0.19370404411764705,
      "grad_norm": 1.6570366621017456,
      "learning_rate": 3.869485294117647e-06,
      "loss": 1.1065,
      "step": 843
    },
    {
      "epoch": 0.19393382352941177,
      "grad_norm": 1.298639178276062,
      "learning_rate": 3.8740808823529415e-06,
      "loss": 0.8846,
      "step": 844
    },
    {
      "epoch": 0.19416360294117646,
      "grad_norm": 1.460658073425293,
      "learning_rate": 3.878676470588236e-06,
      "loss": 1.0689,
      "step": 845
    },
    {
      "epoch": 0.19439338235294118,
      "grad_norm": 1.3314274549484253,
      "learning_rate": 3.883272058823529e-06,
      "loss": 1.0291,
      "step": 846
    },
    {
      "epoch": 0.19462316176470587,
      "grad_norm": 1.5087380409240723,
      "learning_rate": 3.887867647058824e-06,
      "loss": 0.9935,
      "step": 847
    },
    {
      "epoch": 0.1948529411764706,
      "grad_norm": 1.4932475090026855,
      "learning_rate": 3.892463235294118e-06,
      "loss": 1.0954,
      "step": 848
    },
    {
      "epoch": 0.19508272058823528,
      "grad_norm": 1.558915615081787,
      "learning_rate": 3.897058823529412e-06,
      "loss": 1.0551,
      "step": 849
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 1.5827797651290894,
      "learning_rate": 3.901654411764706e-06,
      "loss": 1.0117,
      "step": 850
    },
    {
      "epoch": 0.19554227941176472,
      "grad_norm": 1.6532686948776245,
      "learning_rate": 3.90625e-06,
      "loss": 1.0288,
      "step": 851
    },
    {
      "epoch": 0.1957720588235294,
      "grad_norm": 1.2642017602920532,
      "learning_rate": 3.910845588235294e-06,
      "loss": 1.0528,
      "step": 852
    },
    {
      "epoch": 0.19600183823529413,
      "grad_norm": 1.470530390739441,
      "learning_rate": 3.915441176470589e-06,
      "loss": 1.074,
      "step": 853
    },
    {
      "epoch": 0.19623161764705882,
      "grad_norm": 1.6121584177017212,
      "learning_rate": 3.920036764705883e-06,
      "loss": 0.9581,
      "step": 854
    },
    {
      "epoch": 0.19646139705882354,
      "grad_norm": 1.7304725646972656,
      "learning_rate": 3.9246323529411766e-06,
      "loss": 1.0344,
      "step": 855
    },
    {
      "epoch": 0.19669117647058823,
      "grad_norm": 1.6555851697921753,
      "learning_rate": 3.929227941176471e-06,
      "loss": 0.9439,
      "step": 856
    },
    {
      "epoch": 0.19692095588235295,
      "grad_norm": 1.3799067735671997,
      "learning_rate": 3.933823529411765e-06,
      "loss": 0.981,
      "step": 857
    },
    {
      "epoch": 0.19715073529411764,
      "grad_norm": 1.4433796405792236,
      "learning_rate": 3.9384191176470595e-06,
      "loss": 0.9852,
      "step": 858
    },
    {
      "epoch": 0.19738051470588236,
      "grad_norm": 1.5848556756973267,
      "learning_rate": 3.943014705882353e-06,
      "loss": 1.0368,
      "step": 859
    },
    {
      "epoch": 0.19761029411764705,
      "grad_norm": 1.2831183671951294,
      "learning_rate": 3.947610294117647e-06,
      "loss": 0.9331,
      "step": 860
    },
    {
      "epoch": 0.19784007352941177,
      "grad_norm": 2.2618868350982666,
      "learning_rate": 3.952205882352942e-06,
      "loss": 1.006,
      "step": 861
    },
    {
      "epoch": 0.19806985294117646,
      "grad_norm": 1.31715726852417,
      "learning_rate": 3.956801470588236e-06,
      "loss": 1.0438,
      "step": 862
    },
    {
      "epoch": 0.19829963235294118,
      "grad_norm": 1.619006633758545,
      "learning_rate": 3.9613970588235295e-06,
      "loss": 1.0908,
      "step": 863
    },
    {
      "epoch": 0.19852941176470587,
      "grad_norm": 1.6864840984344482,
      "learning_rate": 3.965992647058824e-06,
      "loss": 1.0778,
      "step": 864
    },
    {
      "epoch": 0.1987591911764706,
      "grad_norm": 1.3869762420654297,
      "learning_rate": 3.970588235294118e-06,
      "loss": 1.0022,
      "step": 865
    },
    {
      "epoch": 0.19898897058823528,
      "grad_norm": 1.5158106088638306,
      "learning_rate": 3.9751838235294125e-06,
      "loss": 1.0449,
      "step": 866
    },
    {
      "epoch": 0.19921875,
      "grad_norm": 1.4343852996826172,
      "learning_rate": 3.979779411764706e-06,
      "loss": 1.0284,
      "step": 867
    },
    {
      "epoch": 0.19944852941176472,
      "grad_norm": 1.7535810470581055,
      "learning_rate": 3.984375e-06,
      "loss": 1.0829,
      "step": 868
    },
    {
      "epoch": 0.1996783088235294,
      "grad_norm": 1.6561757326126099,
      "learning_rate": 3.988970588235295e-06,
      "loss": 0.9906,
      "step": 869
    },
    {
      "epoch": 0.19990808823529413,
      "grad_norm": 1.4583370685577393,
      "learning_rate": 3.993566176470589e-06,
      "loss": 0.9749,
      "step": 870
    },
    {
      "epoch": 0.20013786764705882,
      "grad_norm": 1.5866318941116333,
      "learning_rate": 3.998161764705883e-06,
      "loss": 1.0898,
      "step": 871
    },
    {
      "epoch": 0.20036764705882354,
      "grad_norm": 1.6706515550613403,
      "learning_rate": 4.002757352941177e-06,
      "loss": 0.981,
      "step": 872
    },
    {
      "epoch": 0.20059742647058823,
      "grad_norm": 2.1044414043426514,
      "learning_rate": 4.007352941176471e-06,
      "loss": 0.8825,
      "step": 873
    },
    {
      "epoch": 0.20082720588235295,
      "grad_norm": 1.5189563035964966,
      "learning_rate": 4.0119485294117646e-06,
      "loss": 0.9982,
      "step": 874
    },
    {
      "epoch": 0.20105698529411764,
      "grad_norm": 1.720942735671997,
      "learning_rate": 4.016544117647059e-06,
      "loss": 1.0522,
      "step": 875
    },
    {
      "epoch": 0.20128676470588236,
      "grad_norm": 1.549636721611023,
      "learning_rate": 4.021139705882353e-06,
      "loss": 0.9398,
      "step": 876
    },
    {
      "epoch": 0.20151654411764705,
      "grad_norm": 1.5210366249084473,
      "learning_rate": 4.0257352941176476e-06,
      "loss": 0.9396,
      "step": 877
    },
    {
      "epoch": 0.20174632352941177,
      "grad_norm": 1.4447747468948364,
      "learning_rate": 4.030330882352941e-06,
      "loss": 0.9613,
      "step": 878
    },
    {
      "epoch": 0.20197610294117646,
      "grad_norm": 1.2044328451156616,
      "learning_rate": 4.034926470588235e-06,
      "loss": 0.9657,
      "step": 879
    },
    {
      "epoch": 0.20220588235294118,
      "grad_norm": 1.437429666519165,
      "learning_rate": 4.03952205882353e-06,
      "loss": 1.0277,
      "step": 880
    },
    {
      "epoch": 0.20243566176470587,
      "grad_norm": 1.5386288166046143,
      "learning_rate": 4.044117647058824e-06,
      "loss": 0.997,
      "step": 881
    },
    {
      "epoch": 0.2026654411764706,
      "grad_norm": 1.6482301950454712,
      "learning_rate": 4.0487132352941175e-06,
      "loss": 1.0286,
      "step": 882
    },
    {
      "epoch": 0.20289522058823528,
      "grad_norm": 1.275122046470642,
      "learning_rate": 4.053308823529412e-06,
      "loss": 1.0465,
      "step": 883
    },
    {
      "epoch": 0.203125,
      "grad_norm": 1.574485421180725,
      "learning_rate": 4.057904411764706e-06,
      "loss": 1.0466,
      "step": 884
    },
    {
      "epoch": 0.20335477941176472,
      "grad_norm": 1.4119096994400024,
      "learning_rate": 4.0625000000000005e-06,
      "loss": 0.9998,
      "step": 885
    },
    {
      "epoch": 0.2035845588235294,
      "grad_norm": 2.0252697467803955,
      "learning_rate": 4.067095588235295e-06,
      "loss": 0.9134,
      "step": 886
    },
    {
      "epoch": 0.20381433823529413,
      "grad_norm": 1.4210824966430664,
      "learning_rate": 4.071691176470588e-06,
      "loss": 0.9471,
      "step": 887
    },
    {
      "epoch": 0.20404411764705882,
      "grad_norm": 1.414495825767517,
      "learning_rate": 4.076286764705883e-06,
      "loss": 0.9367,
      "step": 888
    },
    {
      "epoch": 0.20427389705882354,
      "grad_norm": 1.8265912532806396,
      "learning_rate": 4.080882352941177e-06,
      "loss": 0.9759,
      "step": 889
    },
    {
      "epoch": 0.20450367647058823,
      "grad_norm": 1.398316740989685,
      "learning_rate": 4.085477941176471e-06,
      "loss": 0.9916,
      "step": 890
    },
    {
      "epoch": 0.20473345588235295,
      "grad_norm": 1.3341755867004395,
      "learning_rate": 4.090073529411765e-06,
      "loss": 0.9993,
      "step": 891
    },
    {
      "epoch": 0.20496323529411764,
      "grad_norm": 1.571495532989502,
      "learning_rate": 4.094669117647059e-06,
      "loss": 0.9367,
      "step": 892
    },
    {
      "epoch": 0.20519301470588236,
      "grad_norm": 1.6342374086380005,
      "learning_rate": 4.0992647058823534e-06,
      "loss": 0.928,
      "step": 893
    },
    {
      "epoch": 0.20542279411764705,
      "grad_norm": 1.6911870241165161,
      "learning_rate": 4.103860294117648e-06,
      "loss": 0.9357,
      "step": 894
    },
    {
      "epoch": 0.20565257352941177,
      "grad_norm": 1.3313896656036377,
      "learning_rate": 4.108455882352941e-06,
      "loss": 0.9109,
      "step": 895
    },
    {
      "epoch": 0.20588235294117646,
      "grad_norm": 1.5684674978256226,
      "learning_rate": 4.1130514705882356e-06,
      "loss": 0.96,
      "step": 896
    },
    {
      "epoch": 0.20611213235294118,
      "grad_norm": 1.5475363731384277,
      "learning_rate": 4.11764705882353e-06,
      "loss": 1.0086,
      "step": 897
    },
    {
      "epoch": 0.20634191176470587,
      "grad_norm": 1.9285629987716675,
      "learning_rate": 4.122242647058824e-06,
      "loss": 1.0388,
      "step": 898
    },
    {
      "epoch": 0.2065716911764706,
      "grad_norm": 1.5012729167938232,
      "learning_rate": 4.126838235294118e-06,
      "loss": 0.9999,
      "step": 899
    },
    {
      "epoch": 0.20680147058823528,
      "grad_norm": 1.4431374073028564,
      "learning_rate": 4.131433823529412e-06,
      "loss": 1.0168,
      "step": 900
    },
    {
      "epoch": 0.20703125,
      "grad_norm": 1.546248197555542,
      "learning_rate": 4.136029411764706e-06,
      "loss": 0.9624,
      "step": 901
    },
    {
      "epoch": 0.20726102941176472,
      "grad_norm": 1.7778382301330566,
      "learning_rate": 4.140625000000001e-06,
      "loss": 1.0033,
      "step": 902
    },
    {
      "epoch": 0.2074908088235294,
      "grad_norm": 1.4593018293380737,
      "learning_rate": 4.145220588235295e-06,
      "loss": 0.9865,
      "step": 903
    },
    {
      "epoch": 0.20772058823529413,
      "grad_norm": 1.6357276439666748,
      "learning_rate": 4.1498161764705885e-06,
      "loss": 0.974,
      "step": 904
    },
    {
      "epoch": 0.20795036764705882,
      "grad_norm": 1.6871836185455322,
      "learning_rate": 4.154411764705883e-06,
      "loss": 0.9574,
      "step": 905
    },
    {
      "epoch": 0.20818014705882354,
      "grad_norm": 1.4194270372390747,
      "learning_rate": 4.159007352941177e-06,
      "loss": 0.915,
      "step": 906
    },
    {
      "epoch": 0.20840992647058823,
      "grad_norm": 1.525083303451538,
      "learning_rate": 4.1636029411764715e-06,
      "loss": 0.9564,
      "step": 907
    },
    {
      "epoch": 0.20863970588235295,
      "grad_norm": 1.3934422731399536,
      "learning_rate": 4.168198529411765e-06,
      "loss": 0.8755,
      "step": 908
    },
    {
      "epoch": 0.20886948529411764,
      "grad_norm": 1.316556692123413,
      "learning_rate": 4.172794117647059e-06,
      "loss": 0.9322,
      "step": 909
    },
    {
      "epoch": 0.20909926470588236,
      "grad_norm": 1.2843115329742432,
      "learning_rate": 4.177389705882353e-06,
      "loss": 0.8859,
      "step": 910
    },
    {
      "epoch": 0.20932904411764705,
      "grad_norm": 1.5492604970932007,
      "learning_rate": 4.181985294117647e-06,
      "loss": 0.9545,
      "step": 911
    },
    {
      "epoch": 0.20955882352941177,
      "grad_norm": 1.6717334985733032,
      "learning_rate": 4.1865808823529414e-06,
      "loss": 0.9004,
      "step": 912
    },
    {
      "epoch": 0.20978860294117646,
      "grad_norm": 1.471771001815796,
      "learning_rate": 4.191176470588236e-06,
      "loss": 0.9559,
      "step": 913
    },
    {
      "epoch": 0.21001838235294118,
      "grad_norm": 1.499351143836975,
      "learning_rate": 4.195772058823529e-06,
      "loss": 0.9638,
      "step": 914
    },
    {
      "epoch": 0.21024816176470587,
      "grad_norm": 1.5169589519500732,
      "learning_rate": 4.200367647058824e-06,
      "loss": 0.9791,
      "step": 915
    },
    {
      "epoch": 0.2104779411764706,
      "grad_norm": 1.5388298034667969,
      "learning_rate": 4.204963235294118e-06,
      "loss": 1.0239,
      "step": 916
    },
    {
      "epoch": 0.21070772058823528,
      "grad_norm": 1.4694099426269531,
      "learning_rate": 4.209558823529412e-06,
      "loss": 0.9096,
      "step": 917
    },
    {
      "epoch": 0.2109375,
      "grad_norm": 1.4946047067642212,
      "learning_rate": 4.214154411764706e-06,
      "loss": 0.8836,
      "step": 918
    },
    {
      "epoch": 0.21116727941176472,
      "grad_norm": 1.6917535066604614,
      "learning_rate": 4.21875e-06,
      "loss": 0.8774,
      "step": 919
    },
    {
      "epoch": 0.2113970588235294,
      "grad_norm": 1.5066429376602173,
      "learning_rate": 4.223345588235294e-06,
      "loss": 0.9818,
      "step": 920
    },
    {
      "epoch": 0.21162683823529413,
      "grad_norm": 1.8102164268493652,
      "learning_rate": 4.227941176470589e-06,
      "loss": 0.8597,
      "step": 921
    },
    {
      "epoch": 0.21185661764705882,
      "grad_norm": 1.4307881593704224,
      "learning_rate": 4.232536764705883e-06,
      "loss": 0.8242,
      "step": 922
    },
    {
      "epoch": 0.21208639705882354,
      "grad_norm": 1.3752483129501343,
      "learning_rate": 4.2371323529411765e-06,
      "loss": 0.9101,
      "step": 923
    },
    {
      "epoch": 0.21231617647058823,
      "grad_norm": 1.2709790468215942,
      "learning_rate": 4.241727941176471e-06,
      "loss": 0.8989,
      "step": 924
    },
    {
      "epoch": 0.21254595588235295,
      "grad_norm": 1.5576035976409912,
      "learning_rate": 4.246323529411765e-06,
      "loss": 0.9228,
      "step": 925
    },
    {
      "epoch": 0.21277573529411764,
      "grad_norm": 1.4531774520874023,
      "learning_rate": 4.2509191176470595e-06,
      "loss": 0.9516,
      "step": 926
    },
    {
      "epoch": 0.21300551470588236,
      "grad_norm": 1.5051966905593872,
      "learning_rate": 4.255514705882353e-06,
      "loss": 0.9552,
      "step": 927
    },
    {
      "epoch": 0.21323529411764705,
      "grad_norm": 1.3641012907028198,
      "learning_rate": 4.260110294117647e-06,
      "loss": 0.8979,
      "step": 928
    },
    {
      "epoch": 0.21346507352941177,
      "grad_norm": 1.5487921237945557,
      "learning_rate": 4.264705882352942e-06,
      "loss": 0.9111,
      "step": 929
    },
    {
      "epoch": 0.21369485294117646,
      "grad_norm": 1.6607567071914673,
      "learning_rate": 4.269301470588236e-06,
      "loss": 0.9587,
      "step": 930
    },
    {
      "epoch": 0.21392463235294118,
      "grad_norm": 1.6945080757141113,
      "learning_rate": 4.2738970588235295e-06,
      "loss": 0.9058,
      "step": 931
    },
    {
      "epoch": 0.21415441176470587,
      "grad_norm": 1.4137948751449585,
      "learning_rate": 4.278492647058824e-06,
      "loss": 0.9211,
      "step": 932
    },
    {
      "epoch": 0.2143841911764706,
      "grad_norm": 1.6328667402267456,
      "learning_rate": 4.283088235294118e-06,
      "loss": 0.9721,
      "step": 933
    },
    {
      "epoch": 0.21461397058823528,
      "grad_norm": 1.6565005779266357,
      "learning_rate": 4.2876838235294124e-06,
      "loss": 0.9203,
      "step": 934
    },
    {
      "epoch": 0.21484375,
      "grad_norm": 1.4153962135314941,
      "learning_rate": 4.292279411764706e-06,
      "loss": 0.8543,
      "step": 935
    },
    {
      "epoch": 0.21507352941176472,
      "grad_norm": 1.7290794849395752,
      "learning_rate": 4.296875e-06,
      "loss": 1.0124,
      "step": 936
    },
    {
      "epoch": 0.2153033088235294,
      "grad_norm": 1.2880553007125854,
      "learning_rate": 4.301470588235295e-06,
      "loss": 0.857,
      "step": 937
    },
    {
      "epoch": 0.21553308823529413,
      "grad_norm": 1.3884931802749634,
      "learning_rate": 4.306066176470589e-06,
      "loss": 0.942,
      "step": 938
    },
    {
      "epoch": 0.21576286764705882,
      "grad_norm": 1.602056622505188,
      "learning_rate": 4.310661764705883e-06,
      "loss": 0.9598,
      "step": 939
    },
    {
      "epoch": 0.21599264705882354,
      "grad_norm": 1.7285884618759155,
      "learning_rate": 4.315257352941177e-06,
      "loss": 0.9133,
      "step": 940
    },
    {
      "epoch": 0.21622242647058823,
      "grad_norm": 1.6394954919815063,
      "learning_rate": 4.319852941176471e-06,
      "loss": 0.9679,
      "step": 941
    },
    {
      "epoch": 0.21645220588235295,
      "grad_norm": 1.3256672620773315,
      "learning_rate": 4.3244485294117645e-06,
      "loss": 0.8497,
      "step": 942
    },
    {
      "epoch": 0.21668198529411764,
      "grad_norm": 1.7462620735168457,
      "learning_rate": 4.32904411764706e-06,
      "loss": 0.8778,
      "step": 943
    },
    {
      "epoch": 0.21691176470588236,
      "grad_norm": 1.682278037071228,
      "learning_rate": 4.333639705882353e-06,
      "loss": 0.9121,
      "step": 944
    },
    {
      "epoch": 0.21714154411764705,
      "grad_norm": 1.4150735139846802,
      "learning_rate": 4.3382352941176475e-06,
      "loss": 0.9547,
      "step": 945
    },
    {
      "epoch": 0.21737132352941177,
      "grad_norm": 1.5990564823150635,
      "learning_rate": 4.342830882352941e-06,
      "loss": 0.798,
      "step": 946
    },
    {
      "epoch": 0.21760110294117646,
      "grad_norm": 1.2695250511169434,
      "learning_rate": 4.347426470588235e-06,
      "loss": 0.8954,
      "step": 947
    },
    {
      "epoch": 0.21783088235294118,
      "grad_norm": 1.4444119930267334,
      "learning_rate": 4.35202205882353e-06,
      "loss": 0.8434,
      "step": 948
    },
    {
      "epoch": 0.21806066176470587,
      "grad_norm": 1.632956624031067,
      "learning_rate": 4.356617647058824e-06,
      "loss": 0.9818,
      "step": 949
    },
    {
      "epoch": 0.2182904411764706,
      "grad_norm": 1.524137258529663,
      "learning_rate": 4.3612132352941175e-06,
      "loss": 0.8328,
      "step": 950
    },
    {
      "epoch": 0.21852022058823528,
      "grad_norm": 1.3437896966934204,
      "learning_rate": 4.365808823529412e-06,
      "loss": 0.9417,
      "step": 951
    },
    {
      "epoch": 0.21875,
      "grad_norm": 1.6073113679885864,
      "learning_rate": 4.370404411764706e-06,
      "loss": 0.8374,
      "step": 952
    },
    {
      "epoch": 0.21897977941176472,
      "grad_norm": 1.4406625032424927,
      "learning_rate": 4.3750000000000005e-06,
      "loss": 0.889,
      "step": 953
    },
    {
      "epoch": 0.2192095588235294,
      "grad_norm": 1.5491218566894531,
      "learning_rate": 4.379595588235295e-06,
      "loss": 0.8843,
      "step": 954
    },
    {
      "epoch": 0.21943933823529413,
      "grad_norm": 1.7004897594451904,
      "learning_rate": 4.384191176470588e-06,
      "loss": 1.0281,
      "step": 955
    },
    {
      "epoch": 0.21966911764705882,
      "grad_norm": 1.7049458026885986,
      "learning_rate": 4.388786764705883e-06,
      "loss": 0.9282,
      "step": 956
    },
    {
      "epoch": 0.21989889705882354,
      "grad_norm": 1.482163906097412,
      "learning_rate": 4.393382352941177e-06,
      "loss": 0.9149,
      "step": 957
    },
    {
      "epoch": 0.22012867647058823,
      "grad_norm": 1.3317632675170898,
      "learning_rate": 4.397977941176471e-06,
      "loss": 0.8396,
      "step": 958
    },
    {
      "epoch": 0.22035845588235295,
      "grad_norm": 1.3658174276351929,
      "learning_rate": 4.402573529411765e-06,
      "loss": 0.9341,
      "step": 959
    },
    {
      "epoch": 0.22058823529411764,
      "grad_norm": 1.3418678045272827,
      "learning_rate": 4.407169117647059e-06,
      "loss": 0.8579,
      "step": 960
    },
    {
      "epoch": 0.22081801470588236,
      "grad_norm": 1.391416311264038,
      "learning_rate": 4.411764705882353e-06,
      "loss": 0.874,
      "step": 961
    },
    {
      "epoch": 0.22104779411764705,
      "grad_norm": 1.4222468137741089,
      "learning_rate": 4.416360294117648e-06,
      "loss": 0.8493,
      "step": 962
    },
    {
      "epoch": 0.22127757352941177,
      "grad_norm": 1.4980844259262085,
      "learning_rate": 4.420955882352941e-06,
      "loss": 0.8413,
      "step": 963
    },
    {
      "epoch": 0.22150735294117646,
      "grad_norm": 1.5803861618041992,
      "learning_rate": 4.4255514705882355e-06,
      "loss": 0.8263,
      "step": 964
    },
    {
      "epoch": 0.22173713235294118,
      "grad_norm": 1.5375699996948242,
      "learning_rate": 4.43014705882353e-06,
      "loss": 0.8801,
      "step": 965
    },
    {
      "epoch": 0.22196691176470587,
      "grad_norm": 1.6060336828231812,
      "learning_rate": 4.434742647058824e-06,
      "loss": 0.8885,
      "step": 966
    },
    {
      "epoch": 0.2221966911764706,
      "grad_norm": 1.5060800313949585,
      "learning_rate": 4.439338235294118e-06,
      "loss": 0.8621,
      "step": 967
    },
    {
      "epoch": 0.22242647058823528,
      "grad_norm": 1.4725797176361084,
      "learning_rate": 4.443933823529412e-06,
      "loss": 0.9486,
      "step": 968
    },
    {
      "epoch": 0.22265625,
      "grad_norm": 1.4858139753341675,
      "learning_rate": 4.448529411764706e-06,
      "loss": 0.8848,
      "step": 969
    },
    {
      "epoch": 0.22288602941176472,
      "grad_norm": 1.3856199979782104,
      "learning_rate": 4.453125000000001e-06,
      "loss": 0.9265,
      "step": 970
    },
    {
      "epoch": 0.2231158088235294,
      "grad_norm": 1.6305302381515503,
      "learning_rate": 4.457720588235295e-06,
      "loss": 0.8414,
      "step": 971
    },
    {
      "epoch": 0.22334558823529413,
      "grad_norm": 1.5937820672988892,
      "learning_rate": 4.4623161764705885e-06,
      "loss": 0.7935,
      "step": 972
    },
    {
      "epoch": 0.22357536764705882,
      "grad_norm": 1.6021182537078857,
      "learning_rate": 4.466911764705883e-06,
      "loss": 0.9148,
      "step": 973
    },
    {
      "epoch": 0.22380514705882354,
      "grad_norm": 1.4372456073760986,
      "learning_rate": 4.471507352941177e-06,
      "loss": 0.8964,
      "step": 974
    },
    {
      "epoch": 0.22403492647058823,
      "grad_norm": 1.419081449508667,
      "learning_rate": 4.4761029411764715e-06,
      "loss": 0.865,
      "step": 975
    },
    {
      "epoch": 0.22426470588235295,
      "grad_norm": 1.3276463747024536,
      "learning_rate": 4.480698529411765e-06,
      "loss": 0.8331,
      "step": 976
    },
    {
      "epoch": 0.22449448529411764,
      "grad_norm": 1.6817057132720947,
      "learning_rate": 4.485294117647059e-06,
      "loss": 0.9599,
      "step": 977
    },
    {
      "epoch": 0.22472426470588236,
      "grad_norm": 1.64548659324646,
      "learning_rate": 4.489889705882353e-06,
      "loss": 0.8045,
      "step": 978
    },
    {
      "epoch": 0.22495404411764705,
      "grad_norm": 1.54683518409729,
      "learning_rate": 4.494485294117648e-06,
      "loss": 0.8233,
      "step": 979
    },
    {
      "epoch": 0.22518382352941177,
      "grad_norm": 1.7668087482452393,
      "learning_rate": 4.499080882352941e-06,
      "loss": 0.8026,
      "step": 980
    },
    {
      "epoch": 0.22541360294117646,
      "grad_norm": 1.6576329469680786,
      "learning_rate": 4.503676470588236e-06,
      "loss": 0.8687,
      "step": 981
    },
    {
      "epoch": 0.22564338235294118,
      "grad_norm": 1.4748119115829468,
      "learning_rate": 4.508272058823529e-06,
      "loss": 0.9209,
      "step": 982
    },
    {
      "epoch": 0.22587316176470587,
      "grad_norm": 1.444039225578308,
      "learning_rate": 4.5128676470588236e-06,
      "loss": 0.869,
      "step": 983
    },
    {
      "epoch": 0.2261029411764706,
      "grad_norm": 1.6994823217391968,
      "learning_rate": 4.517463235294118e-06,
      "loss": 0.7951,
      "step": 984
    },
    {
      "epoch": 0.22633272058823528,
      "grad_norm": 1.3220767974853516,
      "learning_rate": 4.522058823529412e-06,
      "loss": 0.8556,
      "step": 985
    },
    {
      "epoch": 0.2265625,
      "grad_norm": 1.2634629011154175,
      "learning_rate": 4.526654411764706e-06,
      "loss": 0.8182,
      "step": 986
    },
    {
      "epoch": 0.22679227941176472,
      "grad_norm": 1.4119412899017334,
      "learning_rate": 4.53125e-06,
      "loss": 0.7981,
      "step": 987
    },
    {
      "epoch": 0.2270220588235294,
      "grad_norm": 1.4600824117660522,
      "learning_rate": 4.535845588235294e-06,
      "loss": 0.9273,
      "step": 988
    },
    {
      "epoch": 0.22725183823529413,
      "grad_norm": 1.2716190814971924,
      "learning_rate": 4.540441176470589e-06,
      "loss": 0.7909,
      "step": 989
    },
    {
      "epoch": 0.22748161764705882,
      "grad_norm": 1.4158188104629517,
      "learning_rate": 4.545036764705883e-06,
      "loss": 0.8059,
      "step": 990
    },
    {
      "epoch": 0.22771139705882354,
      "grad_norm": 1.2948262691497803,
      "learning_rate": 4.5496323529411765e-06,
      "loss": 0.7359,
      "step": 991
    },
    {
      "epoch": 0.22794117647058823,
      "grad_norm": 1.4574068784713745,
      "learning_rate": 4.554227941176471e-06,
      "loss": 0.7984,
      "step": 992
    },
    {
      "epoch": 0.22817095588235295,
      "grad_norm": 1.5638717412948608,
      "learning_rate": 4.558823529411765e-06,
      "loss": 0.8594,
      "step": 993
    },
    {
      "epoch": 0.22840073529411764,
      "grad_norm": 1.4429686069488525,
      "learning_rate": 4.5634191176470595e-06,
      "loss": 0.8186,
      "step": 994
    },
    {
      "epoch": 0.22863051470588236,
      "grad_norm": 1.6488629579544067,
      "learning_rate": 4.568014705882353e-06,
      "loss": 0.8214,
      "step": 995
    },
    {
      "epoch": 0.22886029411764705,
      "grad_norm": 1.4898368120193481,
      "learning_rate": 4.572610294117647e-06,
      "loss": 0.8917,
      "step": 996
    },
    {
      "epoch": 0.22909007352941177,
      "grad_norm": 1.591254711151123,
      "learning_rate": 4.577205882352942e-06,
      "loss": 0.8232,
      "step": 997
    },
    {
      "epoch": 0.22931985294117646,
      "grad_norm": 1.3990665674209595,
      "learning_rate": 4.581801470588236e-06,
      "loss": 0.8625,
      "step": 998
    },
    {
      "epoch": 0.22954963235294118,
      "grad_norm": 1.5470945835113525,
      "learning_rate": 4.5863970588235294e-06,
      "loss": 0.8341,
      "step": 999
    },
    {
      "epoch": 0.22977941176470587,
      "grad_norm": 1.6008085012435913,
      "learning_rate": 4.590992647058824e-06,
      "loss": 0.7793,
      "step": 1000
    },
    {
      "epoch": 0.22977941176470587,
      "eval_loss": 0.8078427314758301,
      "eval_runtime": 421.0273,
      "eval_samples_per_second": 21.153,
      "eval_steps_per_second": 10.577,
      "step": 1000
    },
    {
      "epoch": 0.2300091911764706,
      "grad_norm": 1.5181300640106201,
      "learning_rate": 4.595588235294118e-06,
      "loss": 0.8333,
      "step": 1001
    },
    {
      "epoch": 0.23023897058823528,
      "grad_norm": 1.4204559326171875,
      "learning_rate": 4.600183823529412e-06,
      "loss": 0.8368,
      "step": 1002
    },
    {
      "epoch": 0.23046875,
      "grad_norm": 1.5317320823669434,
      "learning_rate": 4.604779411764706e-06,
      "loss": 0.8093,
      "step": 1003
    },
    {
      "epoch": 0.23069852941176472,
      "grad_norm": 1.4443702697753906,
      "learning_rate": 4.609375e-06,
      "loss": 0.777,
      "step": 1004
    },
    {
      "epoch": 0.2309283088235294,
      "grad_norm": 1.598568320274353,
      "learning_rate": 4.6139705882352946e-06,
      "loss": 0.9196,
      "step": 1005
    },
    {
      "epoch": 0.23115808823529413,
      "grad_norm": 1.6634666919708252,
      "learning_rate": 4.618566176470589e-06,
      "loss": 0.8434,
      "step": 1006
    },
    {
      "epoch": 0.23138786764705882,
      "grad_norm": 1.6207212209701538,
      "learning_rate": 4.623161764705883e-06,
      "loss": 0.8081,
      "step": 1007
    },
    {
      "epoch": 0.23161764705882354,
      "grad_norm": 1.8095623254776,
      "learning_rate": 4.627757352941177e-06,
      "loss": 0.8806,
      "step": 1008
    },
    {
      "epoch": 0.23184742647058823,
      "grad_norm": 1.5029091835021973,
      "learning_rate": 4.632352941176471e-06,
      "loss": 0.7491,
      "step": 1009
    },
    {
      "epoch": 0.23207720588235295,
      "grad_norm": 1.3258788585662842,
      "learning_rate": 4.636948529411765e-06,
      "loss": 0.7715,
      "step": 1010
    },
    {
      "epoch": 0.23230698529411764,
      "grad_norm": 1.220115065574646,
      "learning_rate": 4.64154411764706e-06,
      "loss": 0.8221,
      "step": 1011
    },
    {
      "epoch": 0.23253676470588236,
      "grad_norm": 1.7411760091781616,
      "learning_rate": 4.646139705882353e-06,
      "loss": 0.9082,
      "step": 1012
    },
    {
      "epoch": 0.23276654411764705,
      "grad_norm": 1.357113242149353,
      "learning_rate": 4.6507352941176475e-06,
      "loss": 0.8076,
      "step": 1013
    },
    {
      "epoch": 0.23299632352941177,
      "grad_norm": 1.560445785522461,
      "learning_rate": 4.655330882352941e-06,
      "loss": 0.6857,
      "step": 1014
    },
    {
      "epoch": 0.23322610294117646,
      "grad_norm": 1.3750221729278564,
      "learning_rate": 4.659926470588236e-06,
      "loss": 0.7469,
      "step": 1015
    },
    {
      "epoch": 0.23345588235294118,
      "grad_norm": 1.8442920446395874,
      "learning_rate": 4.66452205882353e-06,
      "loss": 0.8718,
      "step": 1016
    },
    {
      "epoch": 0.23368566176470587,
      "grad_norm": 1.5324602127075195,
      "learning_rate": 4.669117647058824e-06,
      "loss": 0.9002,
      "step": 1017
    },
    {
      "epoch": 0.2339154411764706,
      "grad_norm": 1.380039095878601,
      "learning_rate": 4.6737132352941174e-06,
      "loss": 0.7805,
      "step": 1018
    },
    {
      "epoch": 0.23414522058823528,
      "grad_norm": 1.3559573888778687,
      "learning_rate": 4.678308823529412e-06,
      "loss": 0.7996,
      "step": 1019
    },
    {
      "epoch": 0.234375,
      "grad_norm": 1.562117099761963,
      "learning_rate": 4.682904411764706e-06,
      "loss": 0.817,
      "step": 1020
    },
    {
      "epoch": 0.23460477941176472,
      "grad_norm": 1.4063751697540283,
      "learning_rate": 4.6875000000000004e-06,
      "loss": 0.8541,
      "step": 1021
    },
    {
      "epoch": 0.2348345588235294,
      "grad_norm": 1.2638484239578247,
      "learning_rate": 4.692095588235295e-06,
      "loss": 0.8777,
      "step": 1022
    },
    {
      "epoch": 0.23506433823529413,
      "grad_norm": 1.5980912446975708,
      "learning_rate": 4.696691176470588e-06,
      "loss": 0.8058,
      "step": 1023
    },
    {
      "epoch": 0.23529411764705882,
      "grad_norm": 1.764588475227356,
      "learning_rate": 4.7012867647058826e-06,
      "loss": 0.7661,
      "step": 1024
    },
    {
      "epoch": 0.23552389705882354,
      "grad_norm": 1.337100625038147,
      "learning_rate": 4.705882352941177e-06,
      "loss": 0.7728,
      "step": 1025
    },
    {
      "epoch": 0.23575367647058823,
      "grad_norm": 1.4588083028793335,
      "learning_rate": 4.710477941176471e-06,
      "loss": 0.7484,
      "step": 1026
    },
    {
      "epoch": 0.23598345588235295,
      "grad_norm": 1.5663833618164062,
      "learning_rate": 4.715073529411765e-06,
      "loss": 0.7593,
      "step": 1027
    },
    {
      "epoch": 0.23621323529411764,
      "grad_norm": 1.5342389345169067,
      "learning_rate": 4.719669117647059e-06,
      "loss": 0.7521,
      "step": 1028
    },
    {
      "epoch": 0.23644301470588236,
      "grad_norm": 1.4052022695541382,
      "learning_rate": 4.724264705882353e-06,
      "loss": 0.8381,
      "step": 1029
    },
    {
      "epoch": 0.23667279411764705,
      "grad_norm": 1.6901957988739014,
      "learning_rate": 4.728860294117648e-06,
      "loss": 0.7196,
      "step": 1030
    },
    {
      "epoch": 0.23690257352941177,
      "grad_norm": 1.3321794271469116,
      "learning_rate": 4.733455882352941e-06,
      "loss": 0.9031,
      "step": 1031
    },
    {
      "epoch": 0.23713235294117646,
      "grad_norm": 1.5004956722259521,
      "learning_rate": 4.7380514705882355e-06,
      "loss": 0.8226,
      "step": 1032
    },
    {
      "epoch": 0.23736213235294118,
      "grad_norm": 1.6696354150772095,
      "learning_rate": 4.74264705882353e-06,
      "loss": 0.7994,
      "step": 1033
    },
    {
      "epoch": 0.23759191176470587,
      "grad_norm": 1.6776034832000732,
      "learning_rate": 4.747242647058824e-06,
      "loss": 0.9127,
      "step": 1034
    },
    {
      "epoch": 0.2378216911764706,
      "grad_norm": 1.7408350706100464,
      "learning_rate": 4.751838235294118e-06,
      "loss": 0.8084,
      "step": 1035
    },
    {
      "epoch": 0.23805147058823528,
      "grad_norm": 1.3423733711242676,
      "learning_rate": 4.756433823529412e-06,
      "loss": 0.6878,
      "step": 1036
    },
    {
      "epoch": 0.23828125,
      "grad_norm": 1.6742383241653442,
      "learning_rate": 4.761029411764706e-06,
      "loss": 0.7636,
      "step": 1037
    },
    {
      "epoch": 0.23851102941176472,
      "grad_norm": 1.359220266342163,
      "learning_rate": 4.765625000000001e-06,
      "loss": 0.6908,
      "step": 1038
    },
    {
      "epoch": 0.2387408088235294,
      "grad_norm": 1.4735742807388306,
      "learning_rate": 4.770220588235295e-06,
      "loss": 0.7722,
      "step": 1039
    },
    {
      "epoch": 0.23897058823529413,
      "grad_norm": 1.540176272392273,
      "learning_rate": 4.7748161764705885e-06,
      "loss": 0.86,
      "step": 1040
    },
    {
      "epoch": 0.23920036764705882,
      "grad_norm": 1.5303268432617188,
      "learning_rate": 4.779411764705883e-06,
      "loss": 0.7265,
      "step": 1041
    },
    {
      "epoch": 0.23943014705882354,
      "grad_norm": 1.4363466501235962,
      "learning_rate": 4.784007352941177e-06,
      "loss": 0.766,
      "step": 1042
    },
    {
      "epoch": 0.23965992647058823,
      "grad_norm": 1.3864164352416992,
      "learning_rate": 4.7886029411764714e-06,
      "loss": 0.7099,
      "step": 1043
    },
    {
      "epoch": 0.23988970588235295,
      "grad_norm": 1.2950079441070557,
      "learning_rate": 4.793198529411765e-06,
      "loss": 0.708,
      "step": 1044
    },
    {
      "epoch": 0.24011948529411764,
      "grad_norm": 1.6795035600662231,
      "learning_rate": 4.797794117647059e-06,
      "loss": 0.7871,
      "step": 1045
    },
    {
      "epoch": 0.24034926470588236,
      "grad_norm": 1.3434654474258423,
      "learning_rate": 4.802389705882354e-06,
      "loss": 0.7811,
      "step": 1046
    },
    {
      "epoch": 0.24057904411764705,
      "grad_norm": 1.8339812755584717,
      "learning_rate": 4.806985294117648e-06,
      "loss": 0.7612,
      "step": 1047
    },
    {
      "epoch": 0.24080882352941177,
      "grad_norm": 1.3058993816375732,
      "learning_rate": 4.811580882352941e-06,
      "loss": 0.7448,
      "step": 1048
    },
    {
      "epoch": 0.24103860294117646,
      "grad_norm": 1.231378197669983,
      "learning_rate": 4.816176470588236e-06,
      "loss": 0.7515,
      "step": 1049
    },
    {
      "epoch": 0.24126838235294118,
      "grad_norm": 1.3531873226165771,
      "learning_rate": 4.820772058823529e-06,
      "loss": 0.7311,
      "step": 1050
    },
    {
      "epoch": 0.24149816176470587,
      "grad_norm": 1.5328373908996582,
      "learning_rate": 4.825367647058824e-06,
      "loss": 0.7344,
      "step": 1051
    },
    {
      "epoch": 0.2417279411764706,
      "grad_norm": 1.6875247955322266,
      "learning_rate": 4.829963235294118e-06,
      "loss": 0.7327,
      "step": 1052
    },
    {
      "epoch": 0.24195772058823528,
      "grad_norm": 1.3288397789001465,
      "learning_rate": 4.834558823529412e-06,
      "loss": 0.7651,
      "step": 1053
    },
    {
      "epoch": 0.2421875,
      "grad_norm": 1.875801682472229,
      "learning_rate": 4.839154411764706e-06,
      "loss": 0.755,
      "step": 1054
    },
    {
      "epoch": 0.24241727941176472,
      "grad_norm": 1.1456522941589355,
      "learning_rate": 4.84375e-06,
      "loss": 0.7462,
      "step": 1055
    },
    {
      "epoch": 0.2426470588235294,
      "grad_norm": 1.392838954925537,
      "learning_rate": 4.848345588235295e-06,
      "loss": 0.7009,
      "step": 1056
    },
    {
      "epoch": 0.24287683823529413,
      "grad_norm": 1.3436710834503174,
      "learning_rate": 4.852941176470589e-06,
      "loss": 0.7144,
      "step": 1057
    },
    {
      "epoch": 0.24310661764705882,
      "grad_norm": 1.786557912826538,
      "learning_rate": 4.857536764705883e-06,
      "loss": 0.8283,
      "step": 1058
    },
    {
      "epoch": 0.24333639705882354,
      "grad_norm": 1.269420862197876,
      "learning_rate": 4.8621323529411765e-06,
      "loss": 0.7764,
      "step": 1059
    },
    {
      "epoch": 0.24356617647058823,
      "grad_norm": 1.3722102642059326,
      "learning_rate": 4.866727941176471e-06,
      "loss": 0.792,
      "step": 1060
    },
    {
      "epoch": 0.24379595588235295,
      "grad_norm": 1.5151301622390747,
      "learning_rate": 4.871323529411765e-06,
      "loss": 0.7265,
      "step": 1061
    },
    {
      "epoch": 0.24402573529411764,
      "grad_norm": 1.5833990573883057,
      "learning_rate": 4.8759191176470595e-06,
      "loss": 0.6859,
      "step": 1062
    },
    {
      "epoch": 0.24425551470588236,
      "grad_norm": 2.063685894012451,
      "learning_rate": 4.880514705882353e-06,
      "loss": 0.8038,
      "step": 1063
    },
    {
      "epoch": 0.24448529411764705,
      "grad_norm": 1.3219308853149414,
      "learning_rate": 4.885110294117647e-06,
      "loss": 0.7661,
      "step": 1064
    },
    {
      "epoch": 0.24471507352941177,
      "grad_norm": 1.5987112522125244,
      "learning_rate": 4.889705882352942e-06,
      "loss": 0.7187,
      "step": 1065
    },
    {
      "epoch": 0.24494485294117646,
      "grad_norm": 1.4633525609970093,
      "learning_rate": 4.894301470588236e-06,
      "loss": 0.6864,
      "step": 1066
    },
    {
      "epoch": 0.24517463235294118,
      "grad_norm": 1.561607003211975,
      "learning_rate": 4.898897058823529e-06,
      "loss": 0.7096,
      "step": 1067
    },
    {
      "epoch": 0.24540441176470587,
      "grad_norm": 1.5272949934005737,
      "learning_rate": 4.903492647058824e-06,
      "loss": 0.8262,
      "step": 1068
    },
    {
      "epoch": 0.2456341911764706,
      "grad_norm": 1.762752890586853,
      "learning_rate": 4.908088235294118e-06,
      "loss": 0.7237,
      "step": 1069
    },
    {
      "epoch": 0.24586397058823528,
      "grad_norm": 1.556827425956726,
      "learning_rate": 4.912683823529412e-06,
      "loss": 0.7628,
      "step": 1070
    },
    {
      "epoch": 0.24609375,
      "grad_norm": 1.7178072929382324,
      "learning_rate": 4.917279411764706e-06,
      "loss": 0.7904,
      "step": 1071
    },
    {
      "epoch": 0.24632352941176472,
      "grad_norm": 1.1769700050354004,
      "learning_rate": 4.921875e-06,
      "loss": 0.7611,
      "step": 1072
    },
    {
      "epoch": 0.2465533088235294,
      "grad_norm": 1.6203340291976929,
      "learning_rate": 4.9264705882352945e-06,
      "loss": 0.7414,
      "step": 1073
    },
    {
      "epoch": 0.24678308823529413,
      "grad_norm": 1.4517866373062134,
      "learning_rate": 4.931066176470589e-06,
      "loss": 0.7869,
      "step": 1074
    },
    {
      "epoch": 0.24701286764705882,
      "grad_norm": 1.5602213144302368,
      "learning_rate": 4.935661764705883e-06,
      "loss": 0.7647,
      "step": 1075
    },
    {
      "epoch": 0.24724264705882354,
      "grad_norm": 1.5560472011566162,
      "learning_rate": 4.940257352941177e-06,
      "loss": 0.7991,
      "step": 1076
    },
    {
      "epoch": 0.24747242647058823,
      "grad_norm": 1.5351625680923462,
      "learning_rate": 4.944852941176471e-06,
      "loss": 0.7903,
      "step": 1077
    },
    {
      "epoch": 0.24770220588235295,
      "grad_norm": 1.6789965629577637,
      "learning_rate": 4.949448529411765e-06,
      "loss": 0.6961,
      "step": 1078
    },
    {
      "epoch": 0.24793198529411764,
      "grad_norm": 1.2797967195510864,
      "learning_rate": 4.95404411764706e-06,
      "loss": 0.727,
      "step": 1079
    },
    {
      "epoch": 0.24816176470588236,
      "grad_norm": 1.5806007385253906,
      "learning_rate": 4.958639705882353e-06,
      "loss": 0.7631,
      "step": 1080
    },
    {
      "epoch": 0.24839154411764705,
      "grad_norm": 1.5746394395828247,
      "learning_rate": 4.9632352941176475e-06,
      "loss": 0.7866,
      "step": 1081
    },
    {
      "epoch": 0.24862132352941177,
      "grad_norm": 1.7030421495437622,
      "learning_rate": 4.967830882352942e-06,
      "loss": 0.7268,
      "step": 1082
    },
    {
      "epoch": 0.24885110294117646,
      "grad_norm": 1.4900990724563599,
      "learning_rate": 4.972426470588236e-06,
      "loss": 0.6729,
      "step": 1083
    },
    {
      "epoch": 0.24908088235294118,
      "grad_norm": 1.7779871225357056,
      "learning_rate": 4.97702205882353e-06,
      "loss": 0.6288,
      "step": 1084
    },
    {
      "epoch": 0.24931066176470587,
      "grad_norm": 1.072381615638733,
      "learning_rate": 4.981617647058824e-06,
      "loss": 0.726,
      "step": 1085
    },
    {
      "epoch": 0.2495404411764706,
      "grad_norm": 1.6226845979690552,
      "learning_rate": 4.986213235294117e-06,
      "loss": 0.6812,
      "step": 1086
    },
    {
      "epoch": 0.24977022058823528,
      "grad_norm": 1.7214561700820923,
      "learning_rate": 4.990808823529413e-06,
      "loss": 0.779,
      "step": 1087
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.4885472059249878,
      "learning_rate": 4.995404411764706e-06,
      "loss": 0.7874,
      "step": 1088
    },
    {
      "epoch": 0.2502297794117647,
      "grad_norm": 1.3300646543502808,
      "learning_rate": 5e-06,
      "loss": 0.7449,
      "step": 1089
    },
    {
      "epoch": 0.25045955882352944,
      "grad_norm": 1.4130736589431763,
      "learning_rate": 5.004595588235295e-06,
      "loss": 0.7235,
      "step": 1090
    },
    {
      "epoch": 0.2506893382352941,
      "grad_norm": 1.3392250537872314,
      "learning_rate": 5.009191176470589e-06,
      "loss": 0.7823,
      "step": 1091
    },
    {
      "epoch": 0.2509191176470588,
      "grad_norm": 1.3507224321365356,
      "learning_rate": 5.0137867647058825e-06,
      "loss": 0.6654,
      "step": 1092
    },
    {
      "epoch": 0.25114889705882354,
      "grad_norm": 2.002643346786499,
      "learning_rate": 5.018382352941177e-06,
      "loss": 0.7617,
      "step": 1093
    },
    {
      "epoch": 0.25137867647058826,
      "grad_norm": 1.645204782485962,
      "learning_rate": 5.022977941176471e-06,
      "loss": 0.6698,
      "step": 1094
    },
    {
      "epoch": 0.2516084558823529,
      "grad_norm": 1.3306519985198975,
      "learning_rate": 5.0275735294117655e-06,
      "loss": 0.7552,
      "step": 1095
    },
    {
      "epoch": 0.25183823529411764,
      "grad_norm": 1.6413075923919678,
      "learning_rate": 5.032169117647059e-06,
      "loss": 0.7592,
      "step": 1096
    },
    {
      "epoch": 0.25206801470588236,
      "grad_norm": 1.2829819917678833,
      "learning_rate": 5.036764705882353e-06,
      "loss": 0.8915,
      "step": 1097
    },
    {
      "epoch": 0.2522977941176471,
      "grad_norm": 1.7154827117919922,
      "learning_rate": 5.041360294117648e-06,
      "loss": 0.6135,
      "step": 1098
    },
    {
      "epoch": 0.25252757352941174,
      "grad_norm": 1.4318822622299194,
      "learning_rate": 5.045955882352942e-06,
      "loss": 0.7016,
      "step": 1099
    },
    {
      "epoch": 0.25275735294117646,
      "grad_norm": 1.6368359327316284,
      "learning_rate": 5.0505514705882355e-06,
      "loss": 0.6907,
      "step": 1100
    },
    {
      "epoch": 0.2529871323529412,
      "grad_norm": 1.375410556793213,
      "learning_rate": 5.05514705882353e-06,
      "loss": 0.7002,
      "step": 1101
    },
    {
      "epoch": 0.2532169117647059,
      "grad_norm": 2.0028507709503174,
      "learning_rate": 5.059742647058824e-06,
      "loss": 0.769,
      "step": 1102
    },
    {
      "epoch": 0.25344669117647056,
      "grad_norm": 1.6082913875579834,
      "learning_rate": 5.0643382352941185e-06,
      "loss": 0.6818,
      "step": 1103
    },
    {
      "epoch": 0.2536764705882353,
      "grad_norm": 1.4417427778244019,
      "learning_rate": 5.068933823529412e-06,
      "loss": 0.679,
      "step": 1104
    },
    {
      "epoch": 0.25390625,
      "grad_norm": 1.6911848783493042,
      "learning_rate": 5.073529411764706e-06,
      "loss": 0.7404,
      "step": 1105
    },
    {
      "epoch": 0.2541360294117647,
      "grad_norm": 1.3446358442306519,
      "learning_rate": 5.078125000000001e-06,
      "loss": 0.6348,
      "step": 1106
    },
    {
      "epoch": 0.25436580882352944,
      "grad_norm": 1.562624454498291,
      "learning_rate": 5.082720588235295e-06,
      "loss": 0.6454,
      "step": 1107
    },
    {
      "epoch": 0.2545955882352941,
      "grad_norm": 1.4763587713241577,
      "learning_rate": 5.087316176470589e-06,
      "loss": 0.7988,
      "step": 1108
    },
    {
      "epoch": 0.2548253676470588,
      "grad_norm": 1.724249005317688,
      "learning_rate": 5.091911764705883e-06,
      "loss": 0.7548,
      "step": 1109
    },
    {
      "epoch": 0.25505514705882354,
      "grad_norm": 1.551653504371643,
      "learning_rate": 5.096507352941177e-06,
      "loss": 0.6764,
      "step": 1110
    },
    {
      "epoch": 0.25528492647058826,
      "grad_norm": 1.7333624362945557,
      "learning_rate": 5.101102941176471e-06,
      "loss": 0.7243,
      "step": 1111
    },
    {
      "epoch": 0.2555147058823529,
      "grad_norm": 1.5142337083816528,
      "learning_rate": 5.105698529411766e-06,
      "loss": 0.7516,
      "step": 1112
    },
    {
      "epoch": 0.25574448529411764,
      "grad_norm": 1.3459372520446777,
      "learning_rate": 5.110294117647059e-06,
      "loss": 0.6005,
      "step": 1113
    },
    {
      "epoch": 0.25597426470588236,
      "grad_norm": 1.5462042093276978,
      "learning_rate": 5.1148897058823536e-06,
      "loss": 0.6602,
      "step": 1114
    },
    {
      "epoch": 0.2562040441176471,
      "grad_norm": 1.2959553003311157,
      "learning_rate": 5.119485294117648e-06,
      "loss": 0.7459,
      "step": 1115
    },
    {
      "epoch": 0.25643382352941174,
      "grad_norm": 1.277793526649475,
      "learning_rate": 5.124080882352942e-06,
      "loss": 0.6168,
      "step": 1116
    },
    {
      "epoch": 0.25666360294117646,
      "grad_norm": 1.459820032119751,
      "learning_rate": 5.128676470588235e-06,
      "loss": 0.6422,
      "step": 1117
    },
    {
      "epoch": 0.2568933823529412,
      "grad_norm": 2.3355448246002197,
      "learning_rate": 5.13327205882353e-06,
      "loss": 0.7249,
      "step": 1118
    },
    {
      "epoch": 0.2571231617647059,
      "grad_norm": 1.3546732664108276,
      "learning_rate": 5.137867647058824e-06,
      "loss": 0.6785,
      "step": 1119
    },
    {
      "epoch": 0.25735294117647056,
      "grad_norm": 1.528947353363037,
      "learning_rate": 5.142463235294119e-06,
      "loss": 0.6316,
      "step": 1120
    },
    {
      "epoch": 0.2575827205882353,
      "grad_norm": 1.4917389154434204,
      "learning_rate": 5.147058823529411e-06,
      "loss": 0.708,
      "step": 1121
    },
    {
      "epoch": 0.2578125,
      "grad_norm": 1.133252501487732,
      "learning_rate": 5.151654411764706e-06,
      "loss": 0.676,
      "step": 1122
    },
    {
      "epoch": 0.2580422794117647,
      "grad_norm": 1.732594609260559,
      "learning_rate": 5.156250000000001e-06,
      "loss": 0.7814,
      "step": 1123
    },
    {
      "epoch": 0.25827205882352944,
      "grad_norm": 1.542986273765564,
      "learning_rate": 5.160845588235295e-06,
      "loss": 0.6902,
      "step": 1124
    },
    {
      "epoch": 0.2585018382352941,
      "grad_norm": 1.2525804042816162,
      "learning_rate": 5.1654411764705895e-06,
      "loss": 0.6864,
      "step": 1125
    },
    {
      "epoch": 0.2587316176470588,
      "grad_norm": 1.5880849361419678,
      "learning_rate": 5.170036764705882e-06,
      "loss": 0.7523,
      "step": 1126
    },
    {
      "epoch": 0.25896139705882354,
      "grad_norm": 1.950832724571228,
      "learning_rate": 5.1746323529411764e-06,
      "loss": 0.6881,
      "step": 1127
    },
    {
      "epoch": 0.25919117647058826,
      "grad_norm": 1.5695602893829346,
      "learning_rate": 5.179227941176472e-06,
      "loss": 0.6624,
      "step": 1128
    },
    {
      "epoch": 0.2594209558823529,
      "grad_norm": 1.4425911903381348,
      "learning_rate": 5.183823529411766e-06,
      "loss": 0.6538,
      "step": 1129
    },
    {
      "epoch": 0.25965073529411764,
      "grad_norm": 1.494753122329712,
      "learning_rate": 5.188419117647059e-06,
      "loss": 0.6802,
      "step": 1130
    },
    {
      "epoch": 0.25988051470588236,
      "grad_norm": 1.4435863494873047,
      "learning_rate": 5.193014705882353e-06,
      "loss": 0.6139,
      "step": 1131
    },
    {
      "epoch": 0.2601102941176471,
      "grad_norm": 1.7763235569000244,
      "learning_rate": 5.197610294117647e-06,
      "loss": 0.7272,
      "step": 1132
    },
    {
      "epoch": 0.26034007352941174,
      "grad_norm": 1.5164246559143066,
      "learning_rate": 5.202205882352942e-06,
      "loss": 0.6497,
      "step": 1133
    },
    {
      "epoch": 0.26056985294117646,
      "grad_norm": 1.6634458303451538,
      "learning_rate": 5.206801470588235e-06,
      "loss": 0.6761,
      "step": 1134
    },
    {
      "epoch": 0.2607996323529412,
      "grad_norm": 1.5939809083938599,
      "learning_rate": 5.211397058823529e-06,
      "loss": 0.717,
      "step": 1135
    },
    {
      "epoch": 0.2610294117647059,
      "grad_norm": 1.425180196762085,
      "learning_rate": 5.215992647058824e-06,
      "loss": 0.6287,
      "step": 1136
    },
    {
      "epoch": 0.26125919117647056,
      "grad_norm": 1.7420226335525513,
      "learning_rate": 5.220588235294118e-06,
      "loss": 0.7361,
      "step": 1137
    },
    {
      "epoch": 0.2614889705882353,
      "grad_norm": 1.4311637878417969,
      "learning_rate": 5.2251838235294115e-06,
      "loss": 0.6454,
      "step": 1138
    },
    {
      "epoch": 0.26171875,
      "grad_norm": 1.5723989009857178,
      "learning_rate": 5.229779411764706e-06,
      "loss": 0.6769,
      "step": 1139
    },
    {
      "epoch": 0.2619485294117647,
      "grad_norm": 1.3082423210144043,
      "learning_rate": 5.234375e-06,
      "loss": 0.7033,
      "step": 1140
    },
    {
      "epoch": 0.26217830882352944,
      "grad_norm": 1.340738296508789,
      "learning_rate": 5.2389705882352945e-06,
      "loss": 0.6356,
      "step": 1141
    },
    {
      "epoch": 0.2624080882352941,
      "grad_norm": 1.5011407136917114,
      "learning_rate": 5.243566176470589e-06,
      "loss": 0.7245,
      "step": 1142
    },
    {
      "epoch": 0.2626378676470588,
      "grad_norm": 1.5341572761535645,
      "learning_rate": 5.248161764705882e-06,
      "loss": 0.6077,
      "step": 1143
    },
    {
      "epoch": 0.26286764705882354,
      "grad_norm": 1.4901034832000732,
      "learning_rate": 5.252757352941177e-06,
      "loss": 0.623,
      "step": 1144
    },
    {
      "epoch": 0.26309742647058826,
      "grad_norm": 1.1980897188186646,
      "learning_rate": 5.257352941176471e-06,
      "loss": 0.7421,
      "step": 1145
    },
    {
      "epoch": 0.2633272058823529,
      "grad_norm": 1.5084959268569946,
      "learning_rate": 5.261948529411765e-06,
      "loss": 0.6502,
      "step": 1146
    },
    {
      "epoch": 0.26355698529411764,
      "grad_norm": 1.7638723850250244,
      "learning_rate": 5.266544117647059e-06,
      "loss": 0.6114,
      "step": 1147
    },
    {
      "epoch": 0.26378676470588236,
      "grad_norm": 1.3807908296585083,
      "learning_rate": 5.271139705882353e-06,
      "loss": 0.6971,
      "step": 1148
    },
    {
      "epoch": 0.2640165441176471,
      "grad_norm": 1.427532434463501,
      "learning_rate": 5.2757352941176474e-06,
      "loss": 0.6683,
      "step": 1149
    },
    {
      "epoch": 0.26424632352941174,
      "grad_norm": 1.5638772249221802,
      "learning_rate": 5.280330882352942e-06,
      "loss": 0.6114,
      "step": 1150
    },
    {
      "epoch": 0.26447610294117646,
      "grad_norm": 1.8162447214126587,
      "learning_rate": 5.284926470588235e-06,
      "loss": 0.6678,
      "step": 1151
    },
    {
      "epoch": 0.2647058823529412,
      "grad_norm": 1.5132850408554077,
      "learning_rate": 5.28952205882353e-06,
      "loss": 0.7119,
      "step": 1152
    },
    {
      "epoch": 0.2649356617647059,
      "grad_norm": 1.5945936441421509,
      "learning_rate": 5.294117647058824e-06,
      "loss": 0.6077,
      "step": 1153
    },
    {
      "epoch": 0.26516544117647056,
      "grad_norm": 1.4941930770874023,
      "learning_rate": 5.298713235294118e-06,
      "loss": 0.7146,
      "step": 1154
    },
    {
      "epoch": 0.2653952205882353,
      "grad_norm": 1.400731086730957,
      "learning_rate": 5.303308823529412e-06,
      "loss": 0.6496,
      "step": 1155
    },
    {
      "epoch": 0.265625,
      "grad_norm": 1.4168305397033691,
      "learning_rate": 5.307904411764706e-06,
      "loss": 0.6077,
      "step": 1156
    },
    {
      "epoch": 0.2658547794117647,
      "grad_norm": 1.5029950141906738,
      "learning_rate": 5.3125e-06,
      "loss": 0.6812,
      "step": 1157
    },
    {
      "epoch": 0.26608455882352944,
      "grad_norm": 1.4629029035568237,
      "learning_rate": 5.317095588235295e-06,
      "loss": 0.6569,
      "step": 1158
    },
    {
      "epoch": 0.2663143382352941,
      "grad_norm": 1.285975456237793,
      "learning_rate": 5.321691176470589e-06,
      "loss": 0.5835,
      "step": 1159
    },
    {
      "epoch": 0.2665441176470588,
      "grad_norm": 1.5497807264328003,
      "learning_rate": 5.3262867647058825e-06,
      "loss": 0.709,
      "step": 1160
    },
    {
      "epoch": 0.26677389705882354,
      "grad_norm": 1.5704710483551025,
      "learning_rate": 5.330882352941177e-06,
      "loss": 0.6275,
      "step": 1161
    },
    {
      "epoch": 0.26700367647058826,
      "grad_norm": 1.4421193599700928,
      "learning_rate": 5.335477941176471e-06,
      "loss": 0.6568,
      "step": 1162
    },
    {
      "epoch": 0.2672334558823529,
      "grad_norm": 1.573690414428711,
      "learning_rate": 5.3400735294117655e-06,
      "loss": 0.7255,
      "step": 1163
    },
    {
      "epoch": 0.26746323529411764,
      "grad_norm": 1.5362643003463745,
      "learning_rate": 5.344669117647059e-06,
      "loss": 0.6565,
      "step": 1164
    },
    {
      "epoch": 0.26769301470588236,
      "grad_norm": 1.4876148700714111,
      "learning_rate": 5.349264705882353e-06,
      "loss": 0.6906,
      "step": 1165
    },
    {
      "epoch": 0.2679227941176471,
      "grad_norm": 1.2822452783584595,
      "learning_rate": 5.353860294117648e-06,
      "loss": 0.6644,
      "step": 1166
    },
    {
      "epoch": 0.26815257352941174,
      "grad_norm": 1.5017718076705933,
      "learning_rate": 5.358455882352942e-06,
      "loss": 0.6736,
      "step": 1167
    },
    {
      "epoch": 0.26838235294117646,
      "grad_norm": 1.2934777736663818,
      "learning_rate": 5.3630514705882355e-06,
      "loss": 0.5395,
      "step": 1168
    },
    {
      "epoch": 0.2686121323529412,
      "grad_norm": 1.6544532775878906,
      "learning_rate": 5.36764705882353e-06,
      "loss": 0.7559,
      "step": 1169
    },
    {
      "epoch": 0.2688419117647059,
      "grad_norm": 1.5114171504974365,
      "learning_rate": 5.372242647058824e-06,
      "loss": 0.6316,
      "step": 1170
    },
    {
      "epoch": 0.26907169117647056,
      "grad_norm": 1.546178936958313,
      "learning_rate": 5.3768382352941184e-06,
      "loss": 0.6269,
      "step": 1171
    },
    {
      "epoch": 0.2693014705882353,
      "grad_norm": 1.6855599880218506,
      "learning_rate": 5.381433823529412e-06,
      "loss": 0.7285,
      "step": 1172
    },
    {
      "epoch": 0.26953125,
      "grad_norm": 1.4137636423110962,
      "learning_rate": 5.386029411764706e-06,
      "loss": 0.6814,
      "step": 1173
    },
    {
      "epoch": 0.2697610294117647,
      "grad_norm": 1.5046600103378296,
      "learning_rate": 5.390625000000001e-06,
      "loss": 0.6169,
      "step": 1174
    },
    {
      "epoch": 0.26999080882352944,
      "grad_norm": 1.539379596710205,
      "learning_rate": 5.395220588235295e-06,
      "loss": 0.6653,
      "step": 1175
    },
    {
      "epoch": 0.2702205882352941,
      "grad_norm": 1.7023764848709106,
      "learning_rate": 5.399816176470589e-06,
      "loss": 0.6631,
      "step": 1176
    },
    {
      "epoch": 0.2704503676470588,
      "grad_norm": 1.2073882818222046,
      "learning_rate": 5.404411764705883e-06,
      "loss": 0.6546,
      "step": 1177
    },
    {
      "epoch": 0.27068014705882354,
      "grad_norm": 1.5138272047042847,
      "learning_rate": 5.409007352941177e-06,
      "loss": 0.7242,
      "step": 1178
    },
    {
      "epoch": 0.27090992647058826,
      "grad_norm": 1.4693115949630737,
      "learning_rate": 5.413602941176471e-06,
      "loss": 0.6413,
      "step": 1179
    },
    {
      "epoch": 0.2711397058823529,
      "grad_norm": 1.2012511491775513,
      "learning_rate": 5.418198529411766e-06,
      "loss": 0.6145,
      "step": 1180
    },
    {
      "epoch": 0.27136948529411764,
      "grad_norm": 1.569820761680603,
      "learning_rate": 5.422794117647059e-06,
      "loss": 0.698,
      "step": 1181
    },
    {
      "epoch": 0.27159926470588236,
      "grad_norm": 1.6352307796478271,
      "learning_rate": 5.4273897058823535e-06,
      "loss": 0.6973,
      "step": 1182
    },
    {
      "epoch": 0.2718290441176471,
      "grad_norm": 1.4228160381317139,
      "learning_rate": 5.431985294117648e-06,
      "loss": 0.6864,
      "step": 1183
    },
    {
      "epoch": 0.27205882352941174,
      "grad_norm": 1.507992148399353,
      "learning_rate": 5.436580882352942e-06,
      "loss": 0.6078,
      "step": 1184
    },
    {
      "epoch": 0.27228860294117646,
      "grad_norm": 1.3970627784729004,
      "learning_rate": 5.441176470588236e-06,
      "loss": 0.6461,
      "step": 1185
    },
    {
      "epoch": 0.2725183823529412,
      "grad_norm": 1.4996311664581299,
      "learning_rate": 5.44577205882353e-06,
      "loss": 0.6533,
      "step": 1186
    },
    {
      "epoch": 0.2727481617647059,
      "grad_norm": 1.3809819221496582,
      "learning_rate": 5.450367647058824e-06,
      "loss": 0.6532,
      "step": 1187
    },
    {
      "epoch": 0.27297794117647056,
      "grad_norm": 1.7544430494308472,
      "learning_rate": 5.454963235294119e-06,
      "loss": 0.6875,
      "step": 1188
    },
    {
      "epoch": 0.2732077205882353,
      "grad_norm": 1.3308370113372803,
      "learning_rate": 5.459558823529411e-06,
      "loss": 0.7015,
      "step": 1189
    },
    {
      "epoch": 0.2734375,
      "grad_norm": 1.8033820390701294,
      "learning_rate": 5.4641544117647065e-06,
      "loss": 0.6392,
      "step": 1190
    },
    {
      "epoch": 0.2736672794117647,
      "grad_norm": 1.338188648223877,
      "learning_rate": 5.468750000000001e-06,
      "loss": 0.702,
      "step": 1191
    },
    {
      "epoch": 0.27389705882352944,
      "grad_norm": 1.7582324743270874,
      "learning_rate": 5.473345588235295e-06,
      "loss": 0.6322,
      "step": 1192
    },
    {
      "epoch": 0.2741268382352941,
      "grad_norm": 1.6860114336013794,
      "learning_rate": 5.4779411764705894e-06,
      "loss": 0.5778,
      "step": 1193
    },
    {
      "epoch": 0.2743566176470588,
      "grad_norm": 1.370098352432251,
      "learning_rate": 5.482536764705882e-06,
      "loss": 0.7184,
      "step": 1194
    },
    {
      "epoch": 0.27458639705882354,
      "grad_norm": 1.4714468717575073,
      "learning_rate": 5.487132352941177e-06,
      "loss": 0.6657,
      "step": 1195
    },
    {
      "epoch": 0.27481617647058826,
      "grad_norm": 1.424708604812622,
      "learning_rate": 5.491727941176472e-06,
      "loss": 0.6778,
      "step": 1196
    },
    {
      "epoch": 0.2750459558823529,
      "grad_norm": 1.6287827491760254,
      "learning_rate": 5.496323529411766e-06,
      "loss": 0.5295,
      "step": 1197
    },
    {
      "epoch": 0.27527573529411764,
      "grad_norm": 1.7019294500350952,
      "learning_rate": 5.5009191176470586e-06,
      "loss": 0.5945,
      "step": 1198
    },
    {
      "epoch": 0.27550551470588236,
      "grad_norm": 1.336308479309082,
      "learning_rate": 5.505514705882353e-06,
      "loss": 0.6653,
      "step": 1199
    },
    {
      "epoch": 0.2757352941176471,
      "grad_norm": 1.8654863834381104,
      "learning_rate": 5.510110294117648e-06,
      "loss": 0.6255,
      "step": 1200
    },
    {
      "epoch": 0.27596507352941174,
      "grad_norm": 1.3930346965789795,
      "learning_rate": 5.514705882352942e-06,
      "loss": 0.6542,
      "step": 1201
    },
    {
      "epoch": 0.27619485294117646,
      "grad_norm": 1.5336159467697144,
      "learning_rate": 5.519301470588235e-06,
      "loss": 0.6201,
      "step": 1202
    },
    {
      "epoch": 0.2764246323529412,
      "grad_norm": 1.3335344791412354,
      "learning_rate": 5.523897058823529e-06,
      "loss": 0.5866,
      "step": 1203
    },
    {
      "epoch": 0.2766544117647059,
      "grad_norm": 1.4807215929031372,
      "learning_rate": 5.528492647058824e-06,
      "loss": 0.5512,
      "step": 1204
    },
    {
      "epoch": 0.27688419117647056,
      "grad_norm": 1.6853185892105103,
      "learning_rate": 5.533088235294118e-06,
      "loss": 0.7217,
      "step": 1205
    },
    {
      "epoch": 0.2771139705882353,
      "grad_norm": 1.582523226737976,
      "learning_rate": 5.5376838235294115e-06,
      "loss": 0.5237,
      "step": 1206
    },
    {
      "epoch": 0.27734375,
      "grad_norm": 1.2463867664337158,
      "learning_rate": 5.542279411764706e-06,
      "loss": 0.6421,
      "step": 1207
    },
    {
      "epoch": 0.2775735294117647,
      "grad_norm": 1.5398902893066406,
      "learning_rate": 5.546875e-06,
      "loss": 0.5506,
      "step": 1208
    },
    {
      "epoch": 0.27780330882352944,
      "grad_norm": 1.597299575805664,
      "learning_rate": 5.5514705882352945e-06,
      "loss": 0.6714,
      "step": 1209
    },
    {
      "epoch": 0.2780330882352941,
      "grad_norm": 1.4217381477355957,
      "learning_rate": 5.556066176470589e-06,
      "loss": 0.5658,
      "step": 1210
    },
    {
      "epoch": 0.2782628676470588,
      "grad_norm": 1.7778514623641968,
      "learning_rate": 5.560661764705882e-06,
      "loss": 0.6028,
      "step": 1211
    },
    {
      "epoch": 0.27849264705882354,
      "grad_norm": 1.4142926931381226,
      "learning_rate": 5.565257352941177e-06,
      "loss": 0.6054,
      "step": 1212
    },
    {
      "epoch": 0.27872242647058826,
      "grad_norm": 1.3546761274337769,
      "learning_rate": 5.569852941176471e-06,
      "loss": 0.6817,
      "step": 1213
    },
    {
      "epoch": 0.2789522058823529,
      "grad_norm": 1.4404383897781372,
      "learning_rate": 5.574448529411765e-06,
      "loss": 0.6608,
      "step": 1214
    },
    {
      "epoch": 0.27918198529411764,
      "grad_norm": 1.2228354215621948,
      "learning_rate": 5.579044117647059e-06,
      "loss": 0.5816,
      "step": 1215
    },
    {
      "epoch": 0.27941176470588236,
      "grad_norm": 1.8446054458618164,
      "learning_rate": 5.583639705882353e-06,
      "loss": 0.6318,
      "step": 1216
    },
    {
      "epoch": 0.2796415441176471,
      "grad_norm": 1.4542243480682373,
      "learning_rate": 5.588235294117647e-06,
      "loss": 0.5141,
      "step": 1217
    },
    {
      "epoch": 0.27987132352941174,
      "grad_norm": 1.87953782081604,
      "learning_rate": 5.592830882352942e-06,
      "loss": 0.5537,
      "step": 1218
    },
    {
      "epoch": 0.28010110294117646,
      "grad_norm": 1.5986380577087402,
      "learning_rate": 5.597426470588235e-06,
      "loss": 0.6269,
      "step": 1219
    },
    {
      "epoch": 0.2803308823529412,
      "grad_norm": 1.4388054609298706,
      "learning_rate": 5.6020220588235296e-06,
      "loss": 0.5469,
      "step": 1220
    },
    {
      "epoch": 0.2805606617647059,
      "grad_norm": 1.5562177896499634,
      "learning_rate": 5.606617647058824e-06,
      "loss": 0.5457,
      "step": 1221
    },
    {
      "epoch": 0.28079044117647056,
      "grad_norm": 1.5581501722335815,
      "learning_rate": 5.611213235294118e-06,
      "loss": 0.6588,
      "step": 1222
    },
    {
      "epoch": 0.2810202205882353,
      "grad_norm": 2.1692094802856445,
      "learning_rate": 5.615808823529412e-06,
      "loss": 0.6579,
      "step": 1223
    },
    {
      "epoch": 0.28125,
      "grad_norm": 1.5466095209121704,
      "learning_rate": 5.620404411764706e-06,
      "loss": 0.558,
      "step": 1224
    },
    {
      "epoch": 0.2814797794117647,
      "grad_norm": 1.5699325799942017,
      "learning_rate": 5.625e-06,
      "loss": 0.6128,
      "step": 1225
    },
    {
      "epoch": 0.28170955882352944,
      "grad_norm": 1.3369406461715698,
      "learning_rate": 5.629595588235295e-06,
      "loss": 0.6427,
      "step": 1226
    },
    {
      "epoch": 0.2819393382352941,
      "grad_norm": 1.53071928024292,
      "learning_rate": 5.634191176470589e-06,
      "loss": 0.6077,
      "step": 1227
    },
    {
      "epoch": 0.2821691176470588,
      "grad_norm": 1.9810796976089478,
      "learning_rate": 5.6387867647058825e-06,
      "loss": 0.6701,
      "step": 1228
    },
    {
      "epoch": 0.28239889705882354,
      "grad_norm": 1.2942326068878174,
      "learning_rate": 5.643382352941177e-06,
      "loss": 0.6132,
      "step": 1229
    },
    {
      "epoch": 0.28262867647058826,
      "grad_norm": 1.914011001586914,
      "learning_rate": 5.647977941176471e-06,
      "loss": 0.5986,
      "step": 1230
    },
    {
      "epoch": 0.2828584558823529,
      "grad_norm": 1.755989670753479,
      "learning_rate": 5.6525735294117655e-06,
      "loss": 0.6467,
      "step": 1231
    },
    {
      "epoch": 0.28308823529411764,
      "grad_norm": 1.4735255241394043,
      "learning_rate": 5.657169117647059e-06,
      "loss": 0.5334,
      "step": 1232
    },
    {
      "epoch": 0.28331801470588236,
      "grad_norm": 1.375179409980774,
      "learning_rate": 5.661764705882353e-06,
      "loss": 0.6651,
      "step": 1233
    },
    {
      "epoch": 0.2835477941176471,
      "grad_norm": 1.659498929977417,
      "learning_rate": 5.666360294117648e-06,
      "loss": 0.5652,
      "step": 1234
    },
    {
      "epoch": 0.28377757352941174,
      "grad_norm": 1.755083441734314,
      "learning_rate": 5.670955882352942e-06,
      "loss": 0.6398,
      "step": 1235
    },
    {
      "epoch": 0.28400735294117646,
      "grad_norm": 1.5319950580596924,
      "learning_rate": 5.6755514705882354e-06,
      "loss": 0.5278,
      "step": 1236
    },
    {
      "epoch": 0.2842371323529412,
      "grad_norm": 1.765563726425171,
      "learning_rate": 5.68014705882353e-06,
      "loss": 0.614,
      "step": 1237
    },
    {
      "epoch": 0.2844669117647059,
      "grad_norm": 1.5420113801956177,
      "learning_rate": 5.684742647058824e-06,
      "loss": 0.5572,
      "step": 1238
    },
    {
      "epoch": 0.28469669117647056,
      "grad_norm": 1.3526930809020996,
      "learning_rate": 5.689338235294118e-06,
      "loss": 0.5657,
      "step": 1239
    },
    {
      "epoch": 0.2849264705882353,
      "grad_norm": 1.232116937637329,
      "learning_rate": 5.693933823529412e-06,
      "loss": 0.5292,
      "step": 1240
    },
    {
      "epoch": 0.28515625,
      "grad_norm": 1.5758872032165527,
      "learning_rate": 5.698529411764706e-06,
      "loss": 0.5421,
      "step": 1241
    },
    {
      "epoch": 0.2853860294117647,
      "grad_norm": 1.621394157409668,
      "learning_rate": 5.7031250000000006e-06,
      "loss": 0.6944,
      "step": 1242
    },
    {
      "epoch": 0.28561580882352944,
      "grad_norm": 1.70447838306427,
      "learning_rate": 5.707720588235295e-06,
      "loss": 0.6186,
      "step": 1243
    },
    {
      "epoch": 0.2858455882352941,
      "grad_norm": 1.4253071546554565,
      "learning_rate": 5.712316176470589e-06,
      "loss": 0.6863,
      "step": 1244
    },
    {
      "epoch": 0.2860753676470588,
      "grad_norm": 1.5741662979125977,
      "learning_rate": 5.716911764705883e-06,
      "loss": 0.7431,
      "step": 1245
    },
    {
      "epoch": 0.28630514705882354,
      "grad_norm": 1.478464126586914,
      "learning_rate": 5.721507352941177e-06,
      "loss": 0.5665,
      "step": 1246
    },
    {
      "epoch": 0.28653492647058826,
      "grad_norm": 1.5327821969985962,
      "learning_rate": 5.726102941176471e-06,
      "loss": 0.659,
      "step": 1247
    },
    {
      "epoch": 0.2867647058823529,
      "grad_norm": 1.2776621580123901,
      "learning_rate": 5.730698529411766e-06,
      "loss": 0.5725,
      "step": 1248
    },
    {
      "epoch": 0.28699448529411764,
      "grad_norm": 1.470761775970459,
      "learning_rate": 5.735294117647059e-06,
      "loss": 0.594,
      "step": 1249
    },
    {
      "epoch": 0.28722426470588236,
      "grad_norm": 1.5292283296585083,
      "learning_rate": 5.7398897058823535e-06,
      "loss": 0.5978,
      "step": 1250
    },
    {
      "epoch": 0.2874540441176471,
      "grad_norm": 1.360590934753418,
      "learning_rate": 5.744485294117648e-06,
      "loss": 0.6207,
      "step": 1251
    },
    {
      "epoch": 0.28768382352941174,
      "grad_norm": 1.6583806276321411,
      "learning_rate": 5.749080882352942e-06,
      "loss": 0.5518,
      "step": 1252
    },
    {
      "epoch": 0.28791360294117646,
      "grad_norm": 1.2985607385635376,
      "learning_rate": 5.753676470588236e-06,
      "loss": 0.6603,
      "step": 1253
    },
    {
      "epoch": 0.2881433823529412,
      "grad_norm": 1.6718779802322388,
      "learning_rate": 5.75827205882353e-06,
      "loss": 0.6416,
      "step": 1254
    },
    {
      "epoch": 0.2883731617647059,
      "grad_norm": 1.311384677886963,
      "learning_rate": 5.762867647058824e-06,
      "loss": 0.5778,
      "step": 1255
    },
    {
      "epoch": 0.28860294117647056,
      "grad_norm": 1.2313594818115234,
      "learning_rate": 5.767463235294119e-06,
      "loss": 0.5281,
      "step": 1256
    },
    {
      "epoch": 0.2888327205882353,
      "grad_norm": 1.4031981229782104,
      "learning_rate": 5.772058823529412e-06,
      "loss": 0.546,
      "step": 1257
    },
    {
      "epoch": 0.2890625,
      "grad_norm": 1.7490708827972412,
      "learning_rate": 5.7766544117647064e-06,
      "loss": 0.6646,
      "step": 1258
    },
    {
      "epoch": 0.2892922794117647,
      "grad_norm": 1.3966572284698486,
      "learning_rate": 5.781250000000001e-06,
      "loss": 0.6074,
      "step": 1259
    },
    {
      "epoch": 0.28952205882352944,
      "grad_norm": 1.9039629697799683,
      "learning_rate": 5.785845588235295e-06,
      "loss": 0.5699,
      "step": 1260
    },
    {
      "epoch": 0.2897518382352941,
      "grad_norm": 1.690874695777893,
      "learning_rate": 5.790441176470589e-06,
      "loss": 0.5115,
      "step": 1261
    },
    {
      "epoch": 0.2899816176470588,
      "grad_norm": 2.0022072792053223,
      "learning_rate": 5.795036764705883e-06,
      "loss": 0.5752,
      "step": 1262
    },
    {
      "epoch": 0.29021139705882354,
      "grad_norm": 1.6121110916137695,
      "learning_rate": 5.799632352941177e-06,
      "loss": 0.6242,
      "step": 1263
    },
    {
      "epoch": 0.29044117647058826,
      "grad_norm": 1.6470729112625122,
      "learning_rate": 5.8042279411764716e-06,
      "loss": 0.5714,
      "step": 1264
    },
    {
      "epoch": 0.2906709558823529,
      "grad_norm": 1.8125555515289307,
      "learning_rate": 5.808823529411766e-06,
      "loss": 0.5839,
      "step": 1265
    },
    {
      "epoch": 0.29090073529411764,
      "grad_norm": 1.6837496757507324,
      "learning_rate": 5.8134191176470585e-06,
      "loss": 0.7278,
      "step": 1266
    },
    {
      "epoch": 0.29113051470588236,
      "grad_norm": 1.5359083414077759,
      "learning_rate": 5.818014705882354e-06,
      "loss": 0.6693,
      "step": 1267
    },
    {
      "epoch": 0.2913602941176471,
      "grad_norm": 1.2161446809768677,
      "learning_rate": 5.822610294117648e-06,
      "loss": 0.5873,
      "step": 1268
    },
    {
      "epoch": 0.29159007352941174,
      "grad_norm": 1.6729633808135986,
      "learning_rate": 5.827205882352942e-06,
      "loss": 0.6372,
      "step": 1269
    },
    {
      "epoch": 0.29181985294117646,
      "grad_norm": 1.3211818933486938,
      "learning_rate": 5.831801470588235e-06,
      "loss": 0.5764,
      "step": 1270
    },
    {
      "epoch": 0.2920496323529412,
      "grad_norm": 1.3823093175888062,
      "learning_rate": 5.836397058823529e-06,
      "loss": 0.5343,
      "step": 1271
    },
    {
      "epoch": 0.2922794117647059,
      "grad_norm": 1.7130566835403442,
      "learning_rate": 5.840992647058824e-06,
      "loss": 0.5621,
      "step": 1272
    },
    {
      "epoch": 0.29250919117647056,
      "grad_norm": 1.4712451696395874,
      "learning_rate": 5.845588235294119e-06,
      "loss": 0.6169,
      "step": 1273
    },
    {
      "epoch": 0.2927389705882353,
      "grad_norm": 1.6402974128723145,
      "learning_rate": 5.8501838235294115e-06,
      "loss": 0.5706,
      "step": 1274
    },
    {
      "epoch": 0.29296875,
      "grad_norm": 1.6746981143951416,
      "learning_rate": 5.854779411764706e-06,
      "loss": 0.575,
      "step": 1275
    },
    {
      "epoch": 0.2931985294117647,
      "grad_norm": 2.0333077907562256,
      "learning_rate": 5.859375e-06,
      "loss": 0.5872,
      "step": 1276
    },
    {
      "epoch": 0.29342830882352944,
      "grad_norm": 1.5509109497070312,
      "learning_rate": 5.8639705882352945e-06,
      "loss": 0.5366,
      "step": 1277
    },
    {
      "epoch": 0.2936580882352941,
      "grad_norm": 1.85853910446167,
      "learning_rate": 5.86856617647059e-06,
      "loss": 0.587,
      "step": 1278
    },
    {
      "epoch": 0.2938878676470588,
      "grad_norm": 1.270140290260315,
      "learning_rate": 5.873161764705882e-06,
      "loss": 0.6065,
      "step": 1279
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 1.4754301309585571,
      "learning_rate": 5.877757352941177e-06,
      "loss": 0.6018,
      "step": 1280
    },
    {
      "epoch": 0.29434742647058826,
      "grad_norm": 1.5754759311676025,
      "learning_rate": 5.882352941176471e-06,
      "loss": 0.5356,
      "step": 1281
    },
    {
      "epoch": 0.2945772058823529,
      "grad_norm": 2.0193867683410645,
      "learning_rate": 5.886948529411765e-06,
      "loss": 0.5661,
      "step": 1282
    },
    {
      "epoch": 0.29480698529411764,
      "grad_norm": 1.6556205749511719,
      "learning_rate": 5.891544117647059e-06,
      "loss": 0.6056,
      "step": 1283
    },
    {
      "epoch": 0.29503676470588236,
      "grad_norm": 1.8507415056228638,
      "learning_rate": 5.896139705882353e-06,
      "loss": 0.5938,
      "step": 1284
    },
    {
      "epoch": 0.2952665441176471,
      "grad_norm": 1.5932873487472534,
      "learning_rate": 5.900735294117647e-06,
      "loss": 0.6125,
      "step": 1285
    },
    {
      "epoch": 0.29549632352941174,
      "grad_norm": 1.3720868825912476,
      "learning_rate": 5.905330882352942e-06,
      "loss": 0.6421,
      "step": 1286
    },
    {
      "epoch": 0.29572610294117646,
      "grad_norm": 1.7853881120681763,
      "learning_rate": 5.909926470588235e-06,
      "loss": 0.5459,
      "step": 1287
    },
    {
      "epoch": 0.2959558823529412,
      "grad_norm": 1.591792345046997,
      "learning_rate": 5.9145220588235295e-06,
      "loss": 0.5801,
      "step": 1288
    },
    {
      "epoch": 0.2961856617647059,
      "grad_norm": 1.6189789772033691,
      "learning_rate": 5.919117647058824e-06,
      "loss": 0.6129,
      "step": 1289
    },
    {
      "epoch": 0.29641544117647056,
      "grad_norm": 1.847761631011963,
      "learning_rate": 5.923713235294118e-06,
      "loss": 0.5298,
      "step": 1290
    },
    {
      "epoch": 0.2966452205882353,
      "grad_norm": 1.6216400861740112,
      "learning_rate": 5.928308823529412e-06,
      "loss": 0.5465,
      "step": 1291
    },
    {
      "epoch": 0.296875,
      "grad_norm": 1.759710431098938,
      "learning_rate": 5.932904411764706e-06,
      "loss": 0.5934,
      "step": 1292
    },
    {
      "epoch": 0.2971047794117647,
      "grad_norm": 1.5520378351211548,
      "learning_rate": 5.9375e-06,
      "loss": 0.601,
      "step": 1293
    },
    {
      "epoch": 0.29733455882352944,
      "grad_norm": 1.5058021545410156,
      "learning_rate": 5.942095588235295e-06,
      "loss": 0.5987,
      "step": 1294
    },
    {
      "epoch": 0.2975643382352941,
      "grad_norm": 1.6629633903503418,
      "learning_rate": 5.946691176470589e-06,
      "loss": 0.599,
      "step": 1295
    },
    {
      "epoch": 0.2977941176470588,
      "grad_norm": 1.4470469951629639,
      "learning_rate": 5.9512867647058825e-06,
      "loss": 0.5843,
      "step": 1296
    },
    {
      "epoch": 0.29802389705882354,
      "grad_norm": 1.7266731262207031,
      "learning_rate": 5.955882352941177e-06,
      "loss": 0.6032,
      "step": 1297
    },
    {
      "epoch": 0.29825367647058826,
      "grad_norm": 1.6084691286087036,
      "learning_rate": 5.960477941176471e-06,
      "loss": 0.5681,
      "step": 1298
    },
    {
      "epoch": 0.2984834558823529,
      "grad_norm": 1.4626766443252563,
      "learning_rate": 5.9650735294117655e-06,
      "loss": 0.6174,
      "step": 1299
    },
    {
      "epoch": 0.29871323529411764,
      "grad_norm": 1.586024522781372,
      "learning_rate": 5.969669117647059e-06,
      "loss": 0.5595,
      "step": 1300
    },
    {
      "epoch": 0.29894301470588236,
      "grad_norm": 1.5950798988342285,
      "learning_rate": 5.974264705882353e-06,
      "loss": 0.4955,
      "step": 1301
    },
    {
      "epoch": 0.2991727941176471,
      "grad_norm": 1.7943556308746338,
      "learning_rate": 5.978860294117648e-06,
      "loss": 0.5296,
      "step": 1302
    },
    {
      "epoch": 0.29940257352941174,
      "grad_norm": 1.4578889608383179,
      "learning_rate": 5.983455882352942e-06,
      "loss": 0.5391,
      "step": 1303
    },
    {
      "epoch": 0.29963235294117646,
      "grad_norm": 1.481601595878601,
      "learning_rate": 5.988051470588235e-06,
      "loss": 0.5337,
      "step": 1304
    },
    {
      "epoch": 0.2998621323529412,
      "grad_norm": 1.5163350105285645,
      "learning_rate": 5.99264705882353e-06,
      "loss": 0.6174,
      "step": 1305
    },
    {
      "epoch": 0.3000919117647059,
      "grad_norm": 1.8169710636138916,
      "learning_rate": 5.997242647058824e-06,
      "loss": 0.5322,
      "step": 1306
    },
    {
      "epoch": 0.30032169117647056,
      "grad_norm": 1.7622267007827759,
      "learning_rate": 6.001838235294118e-06,
      "loss": 0.6009,
      "step": 1307
    },
    {
      "epoch": 0.3005514705882353,
      "grad_norm": 1.618357539176941,
      "learning_rate": 6.006433823529412e-06,
      "loss": 0.62,
      "step": 1308
    },
    {
      "epoch": 0.30078125,
      "grad_norm": 1.8211911916732788,
      "learning_rate": 6.011029411764706e-06,
      "loss": 0.6618,
      "step": 1309
    },
    {
      "epoch": 0.3010110294117647,
      "grad_norm": 1.4253642559051514,
      "learning_rate": 6.0156250000000005e-06,
      "loss": 0.5104,
      "step": 1310
    },
    {
      "epoch": 0.30124080882352944,
      "grad_norm": 1.3913882970809937,
      "learning_rate": 6.020220588235295e-06,
      "loss": 0.5097,
      "step": 1311
    },
    {
      "epoch": 0.3014705882352941,
      "grad_norm": 1.4516568183898926,
      "learning_rate": 6.024816176470589e-06,
      "loss": 0.5736,
      "step": 1312
    },
    {
      "epoch": 0.3017003676470588,
      "grad_norm": 1.6156543493270874,
      "learning_rate": 6.029411764705883e-06,
      "loss": 0.5079,
      "step": 1313
    },
    {
      "epoch": 0.30193014705882354,
      "grad_norm": 1.6516900062561035,
      "learning_rate": 6.034007352941177e-06,
      "loss": 0.537,
      "step": 1314
    },
    {
      "epoch": 0.30215992647058826,
      "grad_norm": 1.546038031578064,
      "learning_rate": 6.038602941176471e-06,
      "loss": 0.5675,
      "step": 1315
    },
    {
      "epoch": 0.3023897058823529,
      "grad_norm": 1.6169003248214722,
      "learning_rate": 6.043198529411766e-06,
      "loss": 0.5651,
      "step": 1316
    },
    {
      "epoch": 0.30261948529411764,
      "grad_norm": 1.4518942832946777,
      "learning_rate": 6.047794117647059e-06,
      "loss": 0.5716,
      "step": 1317
    },
    {
      "epoch": 0.30284926470588236,
      "grad_norm": 1.3588371276855469,
      "learning_rate": 6.0523897058823535e-06,
      "loss": 0.5586,
      "step": 1318
    },
    {
      "epoch": 0.3030790441176471,
      "grad_norm": 1.7201757431030273,
      "learning_rate": 6.056985294117648e-06,
      "loss": 0.5041,
      "step": 1319
    },
    {
      "epoch": 0.30330882352941174,
      "grad_norm": 1.7186610698699951,
      "learning_rate": 6.061580882352942e-06,
      "loss": 0.6164,
      "step": 1320
    },
    {
      "epoch": 0.30353860294117646,
      "grad_norm": 1.3926879167556763,
      "learning_rate": 6.066176470588236e-06,
      "loss": 0.5239,
      "step": 1321
    },
    {
      "epoch": 0.3037683823529412,
      "grad_norm": 1.7113953828811646,
      "learning_rate": 6.07077205882353e-06,
      "loss": 0.5498,
      "step": 1322
    },
    {
      "epoch": 0.3039981617647059,
      "grad_norm": 1.3973370790481567,
      "learning_rate": 6.075367647058824e-06,
      "loss": 0.588,
      "step": 1323
    },
    {
      "epoch": 0.30422794117647056,
      "grad_norm": 1.8501430749893188,
      "learning_rate": 6.079963235294119e-06,
      "loss": 0.6074,
      "step": 1324
    },
    {
      "epoch": 0.3044577205882353,
      "grad_norm": 1.77595853805542,
      "learning_rate": 6.084558823529412e-06,
      "loss": 0.609,
      "step": 1325
    },
    {
      "epoch": 0.3046875,
      "grad_norm": 1.3531460762023926,
      "learning_rate": 6.089154411764706e-06,
      "loss": 0.478,
      "step": 1326
    },
    {
      "epoch": 0.3049172794117647,
      "grad_norm": 1.670361042022705,
      "learning_rate": 6.093750000000001e-06,
      "loss": 0.5691,
      "step": 1327
    },
    {
      "epoch": 0.30514705882352944,
      "grad_norm": 1.573858380317688,
      "learning_rate": 6.098345588235295e-06,
      "loss": 0.5607,
      "step": 1328
    },
    {
      "epoch": 0.3053768382352941,
      "grad_norm": 1.5016731023788452,
      "learning_rate": 6.102941176470589e-06,
      "loss": 0.5631,
      "step": 1329
    },
    {
      "epoch": 0.3056066176470588,
      "grad_norm": 1.6238250732421875,
      "learning_rate": 6.107536764705883e-06,
      "loss": 0.5793,
      "step": 1330
    },
    {
      "epoch": 0.30583639705882354,
      "grad_norm": 1.7494707107543945,
      "learning_rate": 6.112132352941177e-06,
      "loss": 0.6109,
      "step": 1331
    },
    {
      "epoch": 0.30606617647058826,
      "grad_norm": 1.7070940732955933,
      "learning_rate": 6.1167279411764715e-06,
      "loss": 0.6452,
      "step": 1332
    },
    {
      "epoch": 0.3062959558823529,
      "grad_norm": 1.2981464862823486,
      "learning_rate": 6.121323529411766e-06,
      "loss": 0.5769,
      "step": 1333
    },
    {
      "epoch": 0.30652573529411764,
      "grad_norm": 1.4607434272766113,
      "learning_rate": 6.125919117647059e-06,
      "loss": 0.5337,
      "step": 1334
    },
    {
      "epoch": 0.30675551470588236,
      "grad_norm": 1.4814916849136353,
      "learning_rate": 6.130514705882354e-06,
      "loss": 0.5794,
      "step": 1335
    },
    {
      "epoch": 0.3069852941176471,
      "grad_norm": 1.5215520858764648,
      "learning_rate": 6.135110294117648e-06,
      "loss": 0.5821,
      "step": 1336
    },
    {
      "epoch": 0.30721507352941174,
      "grad_norm": 1.8721950054168701,
      "learning_rate": 6.139705882352942e-06,
      "loss": 0.5026,
      "step": 1337
    },
    {
      "epoch": 0.30744485294117646,
      "grad_norm": 1.508347749710083,
      "learning_rate": 6.144301470588235e-06,
      "loss": 0.595,
      "step": 1338
    },
    {
      "epoch": 0.3076746323529412,
      "grad_norm": 1.6539621353149414,
      "learning_rate": 6.148897058823529e-06,
      "loss": 0.5464,
      "step": 1339
    },
    {
      "epoch": 0.3079044117647059,
      "grad_norm": 1.5424360036849976,
      "learning_rate": 6.1534926470588245e-06,
      "loss": 0.5208,
      "step": 1340
    },
    {
      "epoch": 0.30813419117647056,
      "grad_norm": 1.498500943183899,
      "learning_rate": 6.158088235294119e-06,
      "loss": 0.5462,
      "step": 1341
    },
    {
      "epoch": 0.3083639705882353,
      "grad_norm": 1.4581979513168335,
      "learning_rate": 6.1626838235294114e-06,
      "loss": 0.5525,
      "step": 1342
    },
    {
      "epoch": 0.30859375,
      "grad_norm": 1.6954935789108276,
      "learning_rate": 6.167279411764706e-06,
      "loss": 0.5701,
      "step": 1343
    },
    {
      "epoch": 0.3088235294117647,
      "grad_norm": 1.3369619846343994,
      "learning_rate": 6.171875e-06,
      "loss": 0.4946,
      "step": 1344
    },
    {
      "epoch": 0.30905330882352944,
      "grad_norm": 1.6038622856140137,
      "learning_rate": 6.176470588235295e-06,
      "loss": 0.5628,
      "step": 1345
    },
    {
      "epoch": 0.3092830882352941,
      "grad_norm": 1.4300905466079712,
      "learning_rate": 6.18106617647059e-06,
      "loss": 0.5958,
      "step": 1346
    },
    {
      "epoch": 0.3095128676470588,
      "grad_norm": 1.219235897064209,
      "learning_rate": 6.185661764705882e-06,
      "loss": 0.5426,
      "step": 1347
    },
    {
      "epoch": 0.30974264705882354,
      "grad_norm": 1.54556143283844,
      "learning_rate": 6.1902573529411766e-06,
      "loss": 0.4167,
      "step": 1348
    },
    {
      "epoch": 0.30997242647058826,
      "grad_norm": 1.512462854385376,
      "learning_rate": 6.194852941176471e-06,
      "loss": 0.4638,
      "step": 1349
    },
    {
      "epoch": 0.3102022058823529,
      "grad_norm": 1.6040735244750977,
      "learning_rate": 6.199448529411766e-06,
      "loss": 0.6435,
      "step": 1350
    },
    {
      "epoch": 0.31043198529411764,
      "grad_norm": 1.465732455253601,
      "learning_rate": 6.204044117647059e-06,
      "loss": 0.5051,
      "step": 1351
    },
    {
      "epoch": 0.31066176470588236,
      "grad_norm": 1.64806067943573,
      "learning_rate": 6.208639705882353e-06,
      "loss": 0.5124,
      "step": 1352
    },
    {
      "epoch": 0.3108915441176471,
      "grad_norm": 1.6177287101745605,
      "learning_rate": 6.213235294117647e-06,
      "loss": 0.5014,
      "step": 1353
    },
    {
      "epoch": 0.31112132352941174,
      "grad_norm": 1.4308258295059204,
      "learning_rate": 6.217830882352942e-06,
      "loss": 0.5104,
      "step": 1354
    },
    {
      "epoch": 0.31135110294117646,
      "grad_norm": 1.6267364025115967,
      "learning_rate": 6.222426470588235e-06,
      "loss": 0.5936,
      "step": 1355
    },
    {
      "epoch": 0.3115808823529412,
      "grad_norm": 1.6229429244995117,
      "learning_rate": 6.2270220588235295e-06,
      "loss": 0.4463,
      "step": 1356
    },
    {
      "epoch": 0.3118106617647059,
      "grad_norm": 1.7988958358764648,
      "learning_rate": 6.231617647058824e-06,
      "loss": 0.5547,
      "step": 1357
    },
    {
      "epoch": 0.31204044117647056,
      "grad_norm": 1.4812287092208862,
      "learning_rate": 6.236213235294118e-06,
      "loss": 0.5837,
      "step": 1358
    },
    {
      "epoch": 0.3122702205882353,
      "grad_norm": 1.5643742084503174,
      "learning_rate": 6.240808823529412e-06,
      "loss": 0.5445,
      "step": 1359
    },
    {
      "epoch": 0.3125,
      "grad_norm": 1.561596393585205,
      "learning_rate": 6.245404411764706e-06,
      "loss": 0.4932,
      "step": 1360
    },
    {
      "epoch": 0.3127297794117647,
      "grad_norm": 1.961983323097229,
      "learning_rate": 6.25e-06,
      "loss": 0.5846,
      "step": 1361
    },
    {
      "epoch": 0.31295955882352944,
      "grad_norm": 1.456864833831787,
      "learning_rate": 6.254595588235295e-06,
      "loss": 0.4627,
      "step": 1362
    },
    {
      "epoch": 0.3131893382352941,
      "grad_norm": 1.60708487033844,
      "learning_rate": 6.259191176470589e-06,
      "loss": 0.4607,
      "step": 1363
    },
    {
      "epoch": 0.3134191176470588,
      "grad_norm": 1.5998826026916504,
      "learning_rate": 6.2637867647058824e-06,
      "loss": 0.5417,
      "step": 1364
    },
    {
      "epoch": 0.31364889705882354,
      "grad_norm": 1.511898398399353,
      "learning_rate": 6.268382352941177e-06,
      "loss": 0.5764,
      "step": 1365
    },
    {
      "epoch": 0.31387867647058826,
      "grad_norm": 1.6305522918701172,
      "learning_rate": 6.272977941176471e-06,
      "loss": 0.5644,
      "step": 1366
    },
    {
      "epoch": 0.3141084558823529,
      "grad_norm": 1.4687340259552002,
      "learning_rate": 6.2775735294117654e-06,
      "loss": 0.4981,
      "step": 1367
    },
    {
      "epoch": 0.31433823529411764,
      "grad_norm": 1.4652398824691772,
      "learning_rate": 6.282169117647059e-06,
      "loss": 0.6,
      "step": 1368
    },
    {
      "epoch": 0.31456801470588236,
      "grad_norm": 1.9388588666915894,
      "learning_rate": 6.286764705882353e-06,
      "loss": 0.5392,
      "step": 1369
    },
    {
      "epoch": 0.3147977941176471,
      "grad_norm": 1.2961616516113281,
      "learning_rate": 6.2913602941176476e-06,
      "loss": 0.4787,
      "step": 1370
    },
    {
      "epoch": 0.31502757352941174,
      "grad_norm": 1.6420249938964844,
      "learning_rate": 6.295955882352942e-06,
      "loss": 0.541,
      "step": 1371
    },
    {
      "epoch": 0.31525735294117646,
      "grad_norm": 1.7429778575897217,
      "learning_rate": 6.300551470588235e-06,
      "loss": 0.6149,
      "step": 1372
    },
    {
      "epoch": 0.3154871323529412,
      "grad_norm": 1.6702682971954346,
      "learning_rate": 6.30514705882353e-06,
      "loss": 0.5509,
      "step": 1373
    },
    {
      "epoch": 0.3157169117647059,
      "grad_norm": 1.3384147882461548,
      "learning_rate": 6.309742647058824e-06,
      "loss": 0.527,
      "step": 1374
    },
    {
      "epoch": 0.31594669117647056,
      "grad_norm": 1.52706778049469,
      "learning_rate": 6.314338235294118e-06,
      "loss": 0.5441,
      "step": 1375
    },
    {
      "epoch": 0.3161764705882353,
      "grad_norm": 1.7903060913085938,
      "learning_rate": 6.318933823529412e-06,
      "loss": 0.5176,
      "step": 1376
    },
    {
      "epoch": 0.31640625,
      "grad_norm": 1.6865769624710083,
      "learning_rate": 6.323529411764706e-06,
      "loss": 0.568,
      "step": 1377
    },
    {
      "epoch": 0.3166360294117647,
      "grad_norm": 1.856594204902649,
      "learning_rate": 6.3281250000000005e-06,
      "loss": 0.4799,
      "step": 1378
    },
    {
      "epoch": 0.31686580882352944,
      "grad_norm": 1.4079588651657104,
      "learning_rate": 6.332720588235295e-06,
      "loss": 0.5602,
      "step": 1379
    },
    {
      "epoch": 0.3170955882352941,
      "grad_norm": 1.4623113870620728,
      "learning_rate": 6.337316176470589e-06,
      "loss": 0.4944,
      "step": 1380
    },
    {
      "epoch": 0.3173253676470588,
      "grad_norm": 1.4344453811645508,
      "learning_rate": 6.341911764705883e-06,
      "loss": 0.516,
      "step": 1381
    },
    {
      "epoch": 0.31755514705882354,
      "grad_norm": 1.3971366882324219,
      "learning_rate": 6.346507352941177e-06,
      "loss": 0.5298,
      "step": 1382
    },
    {
      "epoch": 0.31778492647058826,
      "grad_norm": 1.4738249778747559,
      "learning_rate": 6.351102941176471e-06,
      "loss": 0.4664,
      "step": 1383
    },
    {
      "epoch": 0.3180147058823529,
      "grad_norm": 1.6919276714324951,
      "learning_rate": 6.355698529411766e-06,
      "loss": 0.4931,
      "step": 1384
    },
    {
      "epoch": 0.31824448529411764,
      "grad_norm": 1.260358452796936,
      "learning_rate": 6.360294117647059e-06,
      "loss": 0.4594,
      "step": 1385
    },
    {
      "epoch": 0.31847426470588236,
      "grad_norm": 1.5479040145874023,
      "learning_rate": 6.3648897058823534e-06,
      "loss": 0.6281,
      "step": 1386
    },
    {
      "epoch": 0.3187040441176471,
      "grad_norm": 1.513872742652893,
      "learning_rate": 6.369485294117648e-06,
      "loss": 0.5323,
      "step": 1387
    },
    {
      "epoch": 0.31893382352941174,
      "grad_norm": 1.7476592063903809,
      "learning_rate": 6.374080882352942e-06,
      "loss": 0.5944,
      "step": 1388
    },
    {
      "epoch": 0.31916360294117646,
      "grad_norm": 1.446517825126648,
      "learning_rate": 6.378676470588236e-06,
      "loss": 0.4659,
      "step": 1389
    },
    {
      "epoch": 0.3193933823529412,
      "grad_norm": 1.7612860202789307,
      "learning_rate": 6.38327205882353e-06,
      "loss": 0.5487,
      "step": 1390
    },
    {
      "epoch": 0.3196231617647059,
      "grad_norm": 1.827711582183838,
      "learning_rate": 6.387867647058824e-06,
      "loss": 0.5486,
      "step": 1391
    },
    {
      "epoch": 0.31985294117647056,
      "grad_norm": 1.2914379835128784,
      "learning_rate": 6.3924632352941186e-06,
      "loss": 0.4752,
      "step": 1392
    },
    {
      "epoch": 0.3200827205882353,
      "grad_norm": 1.6416122913360596,
      "learning_rate": 6.397058823529412e-06,
      "loss": 0.5214,
      "step": 1393
    },
    {
      "epoch": 0.3203125,
      "grad_norm": 1.5683774948120117,
      "learning_rate": 6.401654411764706e-06,
      "loss": 0.6095,
      "step": 1394
    },
    {
      "epoch": 0.3205422794117647,
      "grad_norm": 2.1564724445343018,
      "learning_rate": 6.406250000000001e-06,
      "loss": 0.4904,
      "step": 1395
    },
    {
      "epoch": 0.32077205882352944,
      "grad_norm": 1.6632506847381592,
      "learning_rate": 6.410845588235295e-06,
      "loss": 0.477,
      "step": 1396
    },
    {
      "epoch": 0.3210018382352941,
      "grad_norm": 1.7824139595031738,
      "learning_rate": 6.415441176470589e-06,
      "loss": 0.5053,
      "step": 1397
    },
    {
      "epoch": 0.3212316176470588,
      "grad_norm": 1.8855079412460327,
      "learning_rate": 6.420036764705883e-06,
      "loss": 0.5732,
      "step": 1398
    },
    {
      "epoch": 0.32146139705882354,
      "grad_norm": 1.4643778800964355,
      "learning_rate": 6.424632352941177e-06,
      "loss": 0.5166,
      "step": 1399
    },
    {
      "epoch": 0.32169117647058826,
      "grad_norm": 1.9350589513778687,
      "learning_rate": 6.4292279411764715e-06,
      "loss": 0.5142,
      "step": 1400
    },
    {
      "epoch": 0.3219209558823529,
      "grad_norm": 1.8256807327270508,
      "learning_rate": 6.433823529411766e-06,
      "loss": 0.4497,
      "step": 1401
    },
    {
      "epoch": 0.32215073529411764,
      "grad_norm": 1.3786295652389526,
      "learning_rate": 6.438419117647059e-06,
      "loss": 0.5092,
      "step": 1402
    },
    {
      "epoch": 0.32238051470588236,
      "grad_norm": 1.8362150192260742,
      "learning_rate": 6.443014705882354e-06,
      "loss": 0.5145,
      "step": 1403
    },
    {
      "epoch": 0.3226102941176471,
      "grad_norm": 1.8718886375427246,
      "learning_rate": 6.447610294117648e-06,
      "loss": 0.6025,
      "step": 1404
    },
    {
      "epoch": 0.32284007352941174,
      "grad_norm": 1.5105870962142944,
      "learning_rate": 6.452205882352942e-06,
      "loss": 0.5392,
      "step": 1405
    },
    {
      "epoch": 0.32306985294117646,
      "grad_norm": 1.4490395784378052,
      "learning_rate": 6.456801470588236e-06,
      "loss": 0.4607,
      "step": 1406
    },
    {
      "epoch": 0.3232996323529412,
      "grad_norm": 1.45708429813385,
      "learning_rate": 6.46139705882353e-06,
      "loss": 0.5715,
      "step": 1407
    },
    {
      "epoch": 0.3235294117647059,
      "grad_norm": 1.2201262712478638,
      "learning_rate": 6.4659926470588244e-06,
      "loss": 0.5248,
      "step": 1408
    },
    {
      "epoch": 0.32375919117647056,
      "grad_norm": 1.9040117263793945,
      "learning_rate": 6.470588235294119e-06,
      "loss": 0.5452,
      "step": 1409
    },
    {
      "epoch": 0.3239889705882353,
      "grad_norm": 1.4519351720809937,
      "learning_rate": 6.475183823529411e-06,
      "loss": 0.4674,
      "step": 1410
    },
    {
      "epoch": 0.32421875,
      "grad_norm": 1.5717099905014038,
      "learning_rate": 6.479779411764706e-06,
      "loss": 0.4658,
      "step": 1411
    },
    {
      "epoch": 0.3244485294117647,
      "grad_norm": 1.9457772970199585,
      "learning_rate": 6.484375000000001e-06,
      "loss": 0.5235,
      "step": 1412
    },
    {
      "epoch": 0.32467830882352944,
      "grad_norm": 1.3744003772735596,
      "learning_rate": 6.488970588235295e-06,
      "loss": 0.4962,
      "step": 1413
    },
    {
      "epoch": 0.3249080882352941,
      "grad_norm": 1.6701841354370117,
      "learning_rate": 6.4935661764705896e-06,
      "loss": 0.5773,
      "step": 1414
    },
    {
      "epoch": 0.3251378676470588,
      "grad_norm": 1.487615942955017,
      "learning_rate": 6.498161764705882e-06,
      "loss": 0.4914,
      "step": 1415
    },
    {
      "epoch": 0.32536764705882354,
      "grad_norm": 1.5642715692520142,
      "learning_rate": 6.5027573529411765e-06,
      "loss": 0.5459,
      "step": 1416
    },
    {
      "epoch": 0.32559742647058826,
      "grad_norm": 1.6549361944198608,
      "learning_rate": 6.507352941176472e-06,
      "loss": 0.5449,
      "step": 1417
    },
    {
      "epoch": 0.3258272058823529,
      "grad_norm": 1.6099141836166382,
      "learning_rate": 6.511948529411766e-06,
      "loss": 0.5226,
      "step": 1418
    },
    {
      "epoch": 0.32605698529411764,
      "grad_norm": 1.4027193784713745,
      "learning_rate": 6.516544117647059e-06,
      "loss": 0.5052,
      "step": 1419
    },
    {
      "epoch": 0.32628676470588236,
      "grad_norm": 1.6550168991088867,
      "learning_rate": 6.521139705882353e-06,
      "loss": 0.5199,
      "step": 1420
    },
    {
      "epoch": 0.3265165441176471,
      "grad_norm": 1.5740301609039307,
      "learning_rate": 6.525735294117647e-06,
      "loss": 0.5041,
      "step": 1421
    },
    {
      "epoch": 0.32674632352941174,
      "grad_norm": 1.2612203359603882,
      "learning_rate": 6.5303308823529425e-06,
      "loss": 0.4757,
      "step": 1422
    },
    {
      "epoch": 0.32697610294117646,
      "grad_norm": 1.4164848327636719,
      "learning_rate": 6.534926470588235e-06,
      "loss": 0.5671,
      "step": 1423
    },
    {
      "epoch": 0.3272058823529412,
      "grad_norm": 2.2568867206573486,
      "learning_rate": 6.5395220588235295e-06,
      "loss": 0.5261,
      "step": 1424
    },
    {
      "epoch": 0.3274356617647059,
      "grad_norm": 1.1791932582855225,
      "learning_rate": 6.544117647058824e-06,
      "loss": 0.4969,
      "step": 1425
    },
    {
      "epoch": 0.32766544117647056,
      "grad_norm": 1.4911261796951294,
      "learning_rate": 6.548713235294118e-06,
      "loss": 0.5403,
      "step": 1426
    },
    {
      "epoch": 0.3278952205882353,
      "grad_norm": 1.4660305976867676,
      "learning_rate": 6.553308823529412e-06,
      "loss": 0.5479,
      "step": 1427
    },
    {
      "epoch": 0.328125,
      "grad_norm": 1.7080177068710327,
      "learning_rate": 6.557904411764706e-06,
      "loss": 0.4844,
      "step": 1428
    },
    {
      "epoch": 0.3283547794117647,
      "grad_norm": 1.3222548961639404,
      "learning_rate": 6.5625e-06,
      "loss": 0.4359,
      "step": 1429
    },
    {
      "epoch": 0.32858455882352944,
      "grad_norm": 1.5125391483306885,
      "learning_rate": 6.567095588235295e-06,
      "loss": 0.532,
      "step": 1430
    },
    {
      "epoch": 0.3288143382352941,
      "grad_norm": 1.6698859930038452,
      "learning_rate": 6.571691176470589e-06,
      "loss": 0.5661,
      "step": 1431
    },
    {
      "epoch": 0.3290441176470588,
      "grad_norm": 1.8255587816238403,
      "learning_rate": 6.576286764705882e-06,
      "loss": 0.4999,
      "step": 1432
    },
    {
      "epoch": 0.32927389705882354,
      "grad_norm": 1.210347056388855,
      "learning_rate": 6.580882352941177e-06,
      "loss": 0.4139,
      "step": 1433
    },
    {
      "epoch": 0.32950367647058826,
      "grad_norm": 1.6117348670959473,
      "learning_rate": 6.585477941176471e-06,
      "loss": 0.58,
      "step": 1434
    },
    {
      "epoch": 0.3297334558823529,
      "grad_norm": 1.6313389539718628,
      "learning_rate": 6.590073529411765e-06,
      "loss": 0.5128,
      "step": 1435
    },
    {
      "epoch": 0.32996323529411764,
      "grad_norm": 1.4743876457214355,
      "learning_rate": 6.594669117647059e-06,
      "loss": 0.5338,
      "step": 1436
    },
    {
      "epoch": 0.33019301470588236,
      "grad_norm": 1.5526463985443115,
      "learning_rate": 6.599264705882353e-06,
      "loss": 0.5082,
      "step": 1437
    },
    {
      "epoch": 0.3304227941176471,
      "grad_norm": 1.3592215776443481,
      "learning_rate": 6.6038602941176475e-06,
      "loss": 0.5072,
      "step": 1438
    },
    {
      "epoch": 0.33065257352941174,
      "grad_norm": 1.8005403280258179,
      "learning_rate": 6.608455882352942e-06,
      "loss": 0.5551,
      "step": 1439
    },
    {
      "epoch": 0.33088235294117646,
      "grad_norm": 1.5865561962127686,
      "learning_rate": 6.613051470588235e-06,
      "loss": 0.4607,
      "step": 1440
    },
    {
      "epoch": 0.3311121323529412,
      "grad_norm": 1.3742479085922241,
      "learning_rate": 6.61764705882353e-06,
      "loss": 0.5253,
      "step": 1441
    },
    {
      "epoch": 0.3313419117647059,
      "grad_norm": 1.9800219535827637,
      "learning_rate": 6.622242647058824e-06,
      "loss": 0.5144,
      "step": 1442
    },
    {
      "epoch": 0.33157169117647056,
      "grad_norm": 1.7477047443389893,
      "learning_rate": 6.626838235294118e-06,
      "loss": 0.5381,
      "step": 1443
    },
    {
      "epoch": 0.3318014705882353,
      "grad_norm": 1.7041618824005127,
      "learning_rate": 6.631433823529412e-06,
      "loss": 0.5025,
      "step": 1444
    },
    {
      "epoch": 0.33203125,
      "grad_norm": 1.820414662361145,
      "learning_rate": 6.636029411764706e-06,
      "loss": 0.5432,
      "step": 1445
    },
    {
      "epoch": 0.3322610294117647,
      "grad_norm": 1.3110171556472778,
      "learning_rate": 6.6406250000000005e-06,
      "loss": 0.4848,
      "step": 1446
    },
    {
      "epoch": 0.33249080882352944,
      "grad_norm": 1.7064512968063354,
      "learning_rate": 6.645220588235295e-06,
      "loss": 0.5697,
      "step": 1447
    },
    {
      "epoch": 0.3327205882352941,
      "grad_norm": 1.4992444515228271,
      "learning_rate": 6.649816176470589e-06,
      "loss": 0.4408,
      "step": 1448
    },
    {
      "epoch": 0.3329503676470588,
      "grad_norm": 1.3505760431289673,
      "learning_rate": 6.654411764705883e-06,
      "loss": 0.5518,
      "step": 1449
    },
    {
      "epoch": 0.33318014705882354,
      "grad_norm": 1.2204997539520264,
      "learning_rate": 6.659007352941177e-06,
      "loss": 0.4618,
      "step": 1450
    },
    {
      "epoch": 0.33340992647058826,
      "grad_norm": 1.4126393795013428,
      "learning_rate": 6.663602941176471e-06,
      "loss": 0.4733,
      "step": 1451
    },
    {
      "epoch": 0.3336397058823529,
      "grad_norm": 1.4898141622543335,
      "learning_rate": 6.668198529411766e-06,
      "loss": 0.504,
      "step": 1452
    },
    {
      "epoch": 0.33386948529411764,
      "grad_norm": 1.3743280172348022,
      "learning_rate": 6.672794117647059e-06,
      "loss": 0.4609,
      "step": 1453
    },
    {
      "epoch": 0.33409926470588236,
      "grad_norm": 1.600661277770996,
      "learning_rate": 6.677389705882353e-06,
      "loss": 0.5227,
      "step": 1454
    },
    {
      "epoch": 0.3343290441176471,
      "grad_norm": 1.4835093021392822,
      "learning_rate": 6.681985294117648e-06,
      "loss": 0.48,
      "step": 1455
    },
    {
      "epoch": 0.33455882352941174,
      "grad_norm": 1.5997381210327148,
      "learning_rate": 6.686580882352942e-06,
      "loss": 0.5023,
      "step": 1456
    },
    {
      "epoch": 0.33478860294117646,
      "grad_norm": 1.455634593963623,
      "learning_rate": 6.6911764705882356e-06,
      "loss": 0.5202,
      "step": 1457
    },
    {
      "epoch": 0.3350183823529412,
      "grad_norm": 1.4059183597564697,
      "learning_rate": 6.69577205882353e-06,
      "loss": 0.4133,
      "step": 1458
    },
    {
      "epoch": 0.3352481617647059,
      "grad_norm": 1.5890111923217773,
      "learning_rate": 6.700367647058824e-06,
      "loss": 0.4374,
      "step": 1459
    },
    {
      "epoch": 0.33547794117647056,
      "grad_norm": 1.3903255462646484,
      "learning_rate": 6.7049632352941185e-06,
      "loss": 0.4989,
      "step": 1460
    },
    {
      "epoch": 0.3357077205882353,
      "grad_norm": 1.31208074092865,
      "learning_rate": 6.709558823529412e-06,
      "loss": 0.4555,
      "step": 1461
    },
    {
      "epoch": 0.3359375,
      "grad_norm": 1.4016571044921875,
      "learning_rate": 6.714154411764706e-06,
      "loss": 0.4143,
      "step": 1462
    },
    {
      "epoch": 0.3361672794117647,
      "grad_norm": 1.6292489767074585,
      "learning_rate": 6.718750000000001e-06,
      "loss": 0.5277,
      "step": 1463
    },
    {
      "epoch": 0.33639705882352944,
      "grad_norm": 1.5258952379226685,
      "learning_rate": 6.723345588235295e-06,
      "loss": 0.5004,
      "step": 1464
    },
    {
      "epoch": 0.3366268382352941,
      "grad_norm": 1.482823371887207,
      "learning_rate": 6.727941176470589e-06,
      "loss": 0.4738,
      "step": 1465
    },
    {
      "epoch": 0.3368566176470588,
      "grad_norm": 1.9317705631256104,
      "learning_rate": 6.732536764705883e-06,
      "loss": 0.5125,
      "step": 1466
    },
    {
      "epoch": 0.33708639705882354,
      "grad_norm": 1.6407047510147095,
      "learning_rate": 6.737132352941177e-06,
      "loss": 0.4822,
      "step": 1467
    },
    {
      "epoch": 0.33731617647058826,
      "grad_norm": 1.691527247428894,
      "learning_rate": 6.7417279411764715e-06,
      "loss": 0.4343,
      "step": 1468
    },
    {
      "epoch": 0.3375459558823529,
      "grad_norm": 1.5797561407089233,
      "learning_rate": 6.746323529411766e-06,
      "loss": 0.5351,
      "step": 1469
    },
    {
      "epoch": 0.33777573529411764,
      "grad_norm": 1.5029115676879883,
      "learning_rate": 6.750919117647059e-06,
      "loss": 0.5637,
      "step": 1470
    },
    {
      "epoch": 0.33800551470588236,
      "grad_norm": 1.4415189027786255,
      "learning_rate": 6.755514705882354e-06,
      "loss": 0.5352,
      "step": 1471
    },
    {
      "epoch": 0.3382352941176471,
      "grad_norm": 1.8726646900177002,
      "learning_rate": 6.760110294117648e-06,
      "loss": 0.4601,
      "step": 1472
    },
    {
      "epoch": 0.33846507352941174,
      "grad_norm": 1.7692705392837524,
      "learning_rate": 6.764705882352942e-06,
      "loss": 0.4474,
      "step": 1473
    },
    {
      "epoch": 0.33869485294117646,
      "grad_norm": 2.141995429992676,
      "learning_rate": 6.769301470588236e-06,
      "loss": 0.4677,
      "step": 1474
    },
    {
      "epoch": 0.3389246323529412,
      "grad_norm": 2.054309606552124,
      "learning_rate": 6.77389705882353e-06,
      "loss": 0.486,
      "step": 1475
    },
    {
      "epoch": 0.3391544117647059,
      "grad_norm": 1.4558442831039429,
      "learning_rate": 6.778492647058824e-06,
      "loss": 0.5108,
      "step": 1476
    },
    {
      "epoch": 0.33938419117647056,
      "grad_norm": 1.3909499645233154,
      "learning_rate": 6.783088235294119e-06,
      "loss": 0.4741,
      "step": 1477
    },
    {
      "epoch": 0.3396139705882353,
      "grad_norm": 1.3995392322540283,
      "learning_rate": 6.787683823529411e-06,
      "loss": 0.464,
      "step": 1478
    },
    {
      "epoch": 0.33984375,
      "grad_norm": 1.627396821975708,
      "learning_rate": 6.7922794117647066e-06,
      "loss": 0.4466,
      "step": 1479
    },
    {
      "epoch": 0.3400735294117647,
      "grad_norm": 1.4783258438110352,
      "learning_rate": 6.796875000000001e-06,
      "loss": 0.4206,
      "step": 1480
    },
    {
      "epoch": 0.34030330882352944,
      "grad_norm": 2.015626907348633,
      "learning_rate": 6.801470588235295e-06,
      "loss": 0.5358,
      "step": 1481
    },
    {
      "epoch": 0.3405330882352941,
      "grad_norm": 1.4539319276809692,
      "learning_rate": 6.8060661764705895e-06,
      "loss": 0.4962,
      "step": 1482
    },
    {
      "epoch": 0.3407628676470588,
      "grad_norm": 1.350040078163147,
      "learning_rate": 6.810661764705882e-06,
      "loss": 0.5308,
      "step": 1483
    },
    {
      "epoch": 0.34099264705882354,
      "grad_norm": 1.36878502368927,
      "learning_rate": 6.815257352941177e-06,
      "loss": 0.455,
      "step": 1484
    },
    {
      "epoch": 0.34122242647058826,
      "grad_norm": 1.4255815744400024,
      "learning_rate": 6.819852941176472e-06,
      "loss": 0.5397,
      "step": 1485
    },
    {
      "epoch": 0.3414522058823529,
      "grad_norm": 1.942826747894287,
      "learning_rate": 6.824448529411766e-06,
      "loss": 0.5929,
      "step": 1486
    },
    {
      "epoch": 0.34168198529411764,
      "grad_norm": 1.7310888767242432,
      "learning_rate": 6.829044117647059e-06,
      "loss": 0.4728,
      "step": 1487
    },
    {
      "epoch": 0.34191176470588236,
      "grad_norm": 1.505937933921814,
      "learning_rate": 6.833639705882353e-06,
      "loss": 0.4665,
      "step": 1488
    },
    {
      "epoch": 0.3421415441176471,
      "grad_norm": 1.5545473098754883,
      "learning_rate": 6.838235294117648e-06,
      "loss": 0.4927,
      "step": 1489
    },
    {
      "epoch": 0.34237132352941174,
      "grad_norm": 1.8511669635772705,
      "learning_rate": 6.8428308823529425e-06,
      "loss": 0.5493,
      "step": 1490
    },
    {
      "epoch": 0.34260110294117646,
      "grad_norm": 1.6574594974517822,
      "learning_rate": 6.847426470588235e-06,
      "loss": 0.4381,
      "step": 1491
    },
    {
      "epoch": 0.3428308823529412,
      "grad_norm": 1.4093464612960815,
      "learning_rate": 6.8520220588235294e-06,
      "loss": 0.5061,
      "step": 1492
    },
    {
      "epoch": 0.3430606617647059,
      "grad_norm": 1.835138201713562,
      "learning_rate": 6.856617647058824e-06,
      "loss": 0.5214,
      "step": 1493
    },
    {
      "epoch": 0.34329044117647056,
      "grad_norm": 1.932827115058899,
      "learning_rate": 6.861213235294119e-06,
      "loss": 0.5563,
      "step": 1494
    },
    {
      "epoch": 0.3435202205882353,
      "grad_norm": 1.5661847591400146,
      "learning_rate": 6.865808823529412e-06,
      "loss": 0.4752,
      "step": 1495
    },
    {
      "epoch": 0.34375,
      "grad_norm": 1.7126566171646118,
      "learning_rate": 6.870404411764706e-06,
      "loss": 0.5122,
      "step": 1496
    },
    {
      "epoch": 0.3439797794117647,
      "grad_norm": 1.589012861251831,
      "learning_rate": 6.875e-06,
      "loss": 0.4731,
      "step": 1497
    },
    {
      "epoch": 0.34420955882352944,
      "grad_norm": 1.4185503721237183,
      "learning_rate": 6.8795955882352946e-06,
      "loss": 0.5132,
      "step": 1498
    },
    {
      "epoch": 0.3444393382352941,
      "grad_norm": 1.7603511810302734,
      "learning_rate": 6.884191176470589e-06,
      "loss": 0.412,
      "step": 1499
    },
    {
      "epoch": 0.3446691176470588,
      "grad_norm": 1.6226204633712769,
      "learning_rate": 6.888786764705882e-06,
      "loss": 0.4702,
      "step": 1500
    },
    {
      "epoch": 0.3446691176470588,
      "eval_loss": 0.46419087052345276,
      "eval_runtime": 420.9758,
      "eval_samples_per_second": 21.156,
      "eval_steps_per_second": 10.578,
      "step": 1500
    },
    {
      "epoch": 0.34489889705882354,
      "grad_norm": 1.4619321823120117,
      "learning_rate": 6.893382352941177e-06,
      "loss": 0.491,
      "step": 1501
    },
    {
      "epoch": 0.34512867647058826,
      "grad_norm": 1.625599980354309,
      "learning_rate": 6.897977941176471e-06,
      "loss": 0.4241,
      "step": 1502
    },
    {
      "epoch": 0.3453584558823529,
      "grad_norm": 1.5436569452285767,
      "learning_rate": 6.902573529411765e-06,
      "loss": 0.4758,
      "step": 1503
    },
    {
      "epoch": 0.34558823529411764,
      "grad_norm": 1.4453736543655396,
      "learning_rate": 6.907169117647059e-06,
      "loss": 0.4509,
      "step": 1504
    },
    {
      "epoch": 0.34581801470588236,
      "grad_norm": 1.5809099674224854,
      "learning_rate": 6.911764705882353e-06,
      "loss": 0.498,
      "step": 1505
    },
    {
      "epoch": 0.3460477941176471,
      "grad_norm": 1.7979092597961426,
      "learning_rate": 6.9163602941176475e-06,
      "loss": 0.5348,
      "step": 1506
    },
    {
      "epoch": 0.34627757352941174,
      "grad_norm": 1.7266855239868164,
      "learning_rate": 6.920955882352942e-06,
      "loss": 0.4966,
      "step": 1507
    },
    {
      "epoch": 0.34650735294117646,
      "grad_norm": 1.789844036102295,
      "learning_rate": 6.925551470588235e-06,
      "loss": 0.4008,
      "step": 1508
    },
    {
      "epoch": 0.3467371323529412,
      "grad_norm": 1.8021727800369263,
      "learning_rate": 6.93014705882353e-06,
      "loss": 0.4242,
      "step": 1509
    },
    {
      "epoch": 0.3469669117647059,
      "grad_norm": 2.0383810997009277,
      "learning_rate": 6.934742647058824e-06,
      "loss": 0.6052,
      "step": 1510
    },
    {
      "epoch": 0.34719669117647056,
      "grad_norm": 1.6643165349960327,
      "learning_rate": 6.939338235294118e-06,
      "loss": 0.5767,
      "step": 1511
    },
    {
      "epoch": 0.3474264705882353,
      "grad_norm": 1.21432626247406,
      "learning_rate": 6.943933823529412e-06,
      "loss": 0.47,
      "step": 1512
    },
    {
      "epoch": 0.34765625,
      "grad_norm": 1.573032259941101,
      "learning_rate": 6.948529411764706e-06,
      "loss": 0.5453,
      "step": 1513
    },
    {
      "epoch": 0.3478860294117647,
      "grad_norm": 1.3821104764938354,
      "learning_rate": 6.9531250000000004e-06,
      "loss": 0.4276,
      "step": 1514
    },
    {
      "epoch": 0.34811580882352944,
      "grad_norm": 1.7687013149261475,
      "learning_rate": 6.957720588235295e-06,
      "loss": 0.3937,
      "step": 1515
    },
    {
      "epoch": 0.3483455882352941,
      "grad_norm": 1.6588554382324219,
      "learning_rate": 6.962316176470589e-06,
      "loss": 0.4209,
      "step": 1516
    },
    {
      "epoch": 0.3485753676470588,
      "grad_norm": 1.5198438167572021,
      "learning_rate": 6.966911764705883e-06,
      "loss": 0.4267,
      "step": 1517
    },
    {
      "epoch": 0.34880514705882354,
      "grad_norm": 1.5448575019836426,
      "learning_rate": 6.971507352941177e-06,
      "loss": 0.4074,
      "step": 1518
    },
    {
      "epoch": 0.34903492647058826,
      "grad_norm": 1.874836802482605,
      "learning_rate": 6.976102941176471e-06,
      "loss": 0.5457,
      "step": 1519
    },
    {
      "epoch": 0.3492647058823529,
      "grad_norm": 1.5433648824691772,
      "learning_rate": 6.980698529411766e-06,
      "loss": 0.4796,
      "step": 1520
    },
    {
      "epoch": 0.34949448529411764,
      "grad_norm": 1.6099885702133179,
      "learning_rate": 6.985294117647059e-06,
      "loss": 0.4686,
      "step": 1521
    },
    {
      "epoch": 0.34972426470588236,
      "grad_norm": 1.6765766143798828,
      "learning_rate": 6.989889705882353e-06,
      "loss": 0.443,
      "step": 1522
    },
    {
      "epoch": 0.3499540441176471,
      "grad_norm": 1.9017661809921265,
      "learning_rate": 6.994485294117648e-06,
      "loss": 0.5216,
      "step": 1523
    },
    {
      "epoch": 0.35018382352941174,
      "grad_norm": 1.4353437423706055,
      "learning_rate": 6.999080882352942e-06,
      "loss": 0.4366,
      "step": 1524
    },
    {
      "epoch": 0.35041360294117646,
      "grad_norm": 1.4883368015289307,
      "learning_rate": 7.0036764705882355e-06,
      "loss": 0.4722,
      "step": 1525
    },
    {
      "epoch": 0.3506433823529412,
      "grad_norm": 1.679172396659851,
      "learning_rate": 7.00827205882353e-06,
      "loss": 0.468,
      "step": 1526
    },
    {
      "epoch": 0.3508731617647059,
      "grad_norm": 1.480535864830017,
      "learning_rate": 7.012867647058824e-06,
      "loss": 0.4339,
      "step": 1527
    },
    {
      "epoch": 0.35110294117647056,
      "grad_norm": 1.5253918170928955,
      "learning_rate": 7.0174632352941185e-06,
      "loss": 0.444,
      "step": 1528
    },
    {
      "epoch": 0.3513327205882353,
      "grad_norm": 1.666520595550537,
      "learning_rate": 7.022058823529412e-06,
      "loss": 0.4442,
      "step": 1529
    },
    {
      "epoch": 0.3515625,
      "grad_norm": 1.3306174278259277,
      "learning_rate": 7.026654411764706e-06,
      "loss": 0.4308,
      "step": 1530
    },
    {
      "epoch": 0.3517922794117647,
      "grad_norm": 1.4627150297164917,
      "learning_rate": 7.031250000000001e-06,
      "loss": 0.4057,
      "step": 1531
    },
    {
      "epoch": 0.35202205882352944,
      "grad_norm": 1.433371901512146,
      "learning_rate": 7.035845588235295e-06,
      "loss": 0.421,
      "step": 1532
    },
    {
      "epoch": 0.3522518382352941,
      "grad_norm": 1.7463676929473877,
      "learning_rate": 7.040441176470589e-06,
      "loss": 0.5271,
      "step": 1533
    },
    {
      "epoch": 0.3524816176470588,
      "grad_norm": 1.4827916622161865,
      "learning_rate": 7.045036764705883e-06,
      "loss": 0.497,
      "step": 1534
    },
    {
      "epoch": 0.35271139705882354,
      "grad_norm": 1.5223771333694458,
      "learning_rate": 7.049632352941177e-06,
      "loss": 0.4374,
      "step": 1535
    },
    {
      "epoch": 0.35294117647058826,
      "grad_norm": 1.7040996551513672,
      "learning_rate": 7.0542279411764715e-06,
      "loss": 0.523,
      "step": 1536
    },
    {
      "epoch": 0.3531709558823529,
      "grad_norm": 1.5360552072525024,
      "learning_rate": 7.058823529411766e-06,
      "loss": 0.4418,
      "step": 1537
    },
    {
      "epoch": 0.35340073529411764,
      "grad_norm": 1.6995518207550049,
      "learning_rate": 7.063419117647059e-06,
      "loss": 0.4092,
      "step": 1538
    },
    {
      "epoch": 0.35363051470588236,
      "grad_norm": 1.5979597568511963,
      "learning_rate": 7.068014705882354e-06,
      "loss": 0.5062,
      "step": 1539
    },
    {
      "epoch": 0.3538602941176471,
      "grad_norm": 1.7691099643707275,
      "learning_rate": 7.072610294117648e-06,
      "loss": 0.4027,
      "step": 1540
    },
    {
      "epoch": 0.35409007352941174,
      "grad_norm": 1.8954908847808838,
      "learning_rate": 7.077205882352942e-06,
      "loss": 0.526,
      "step": 1541
    },
    {
      "epoch": 0.35431985294117646,
      "grad_norm": 2.042300224304199,
      "learning_rate": 7.081801470588236e-06,
      "loss": 0.5365,
      "step": 1542
    },
    {
      "epoch": 0.3545496323529412,
      "grad_norm": 1.9607253074645996,
      "learning_rate": 7.08639705882353e-06,
      "loss": 0.435,
      "step": 1543
    },
    {
      "epoch": 0.3547794117647059,
      "grad_norm": 1.432225227355957,
      "learning_rate": 7.090992647058824e-06,
      "loss": 0.3901,
      "step": 1544
    },
    {
      "epoch": 0.35500919117647056,
      "grad_norm": 1.5591005086898804,
      "learning_rate": 7.095588235294119e-06,
      "loss": 0.427,
      "step": 1545
    },
    {
      "epoch": 0.3552389705882353,
      "grad_norm": 1.8255833387374878,
      "learning_rate": 7.100183823529412e-06,
      "loss": 0.4098,
      "step": 1546
    },
    {
      "epoch": 0.35546875,
      "grad_norm": 1.487412691116333,
      "learning_rate": 7.1047794117647065e-06,
      "loss": 0.45,
      "step": 1547
    },
    {
      "epoch": 0.3556985294117647,
      "grad_norm": 1.4639836549758911,
      "learning_rate": 7.109375000000001e-06,
      "loss": 0.4742,
      "step": 1548
    },
    {
      "epoch": 0.35592830882352944,
      "grad_norm": 1.4748148918151855,
      "learning_rate": 7.113970588235295e-06,
      "loss": 0.4095,
      "step": 1549
    },
    {
      "epoch": 0.3561580882352941,
      "grad_norm": 1.302425742149353,
      "learning_rate": 7.1185661764705895e-06,
      "loss": 0.4619,
      "step": 1550
    },
    {
      "epoch": 0.3563878676470588,
      "grad_norm": 1.6551661491394043,
      "learning_rate": 7.123161764705883e-06,
      "loss": 0.4781,
      "step": 1551
    },
    {
      "epoch": 0.35661764705882354,
      "grad_norm": 1.4902812242507935,
      "learning_rate": 7.127757352941177e-06,
      "loss": 0.4794,
      "step": 1552
    },
    {
      "epoch": 0.35684742647058826,
      "grad_norm": 1.813664197921753,
      "learning_rate": 7.132352941176472e-06,
      "loss": 0.4362,
      "step": 1553
    },
    {
      "epoch": 0.3570772058823529,
      "grad_norm": 1.6905996799468994,
      "learning_rate": 7.136948529411766e-06,
      "loss": 0.4566,
      "step": 1554
    },
    {
      "epoch": 0.35730698529411764,
      "grad_norm": 1.273128628730774,
      "learning_rate": 7.141544117647059e-06,
      "loss": 0.4617,
      "step": 1555
    },
    {
      "epoch": 0.35753676470588236,
      "grad_norm": 1.401623249053955,
      "learning_rate": 7.146139705882354e-06,
      "loss": 0.4354,
      "step": 1556
    },
    {
      "epoch": 0.3577665441176471,
      "grad_norm": 1.422613263130188,
      "learning_rate": 7.150735294117648e-06,
      "loss": 0.4081,
      "step": 1557
    },
    {
      "epoch": 0.35799632352941174,
      "grad_norm": 1.8490060567855835,
      "learning_rate": 7.1553308823529425e-06,
      "loss": 0.4523,
      "step": 1558
    },
    {
      "epoch": 0.35822610294117646,
      "grad_norm": 1.3749297857284546,
      "learning_rate": 7.159926470588235e-06,
      "loss": 0.5076,
      "step": 1559
    },
    {
      "epoch": 0.3584558823529412,
      "grad_norm": 1.6337603330612183,
      "learning_rate": 7.164522058823529e-06,
      "loss": 0.429,
      "step": 1560
    },
    {
      "epoch": 0.3586856617647059,
      "grad_norm": 1.7464946508407593,
      "learning_rate": 7.169117647058825e-06,
      "loss": 0.4994,
      "step": 1561
    },
    {
      "epoch": 0.35891544117647056,
      "grad_norm": 1.900750756263733,
      "learning_rate": 7.173713235294119e-06,
      "loss": 0.458,
      "step": 1562
    },
    {
      "epoch": 0.3591452205882353,
      "grad_norm": 2.178896427154541,
      "learning_rate": 7.1783088235294116e-06,
      "loss": 0.5223,
      "step": 1563
    },
    {
      "epoch": 0.359375,
      "grad_norm": 1.6749509572982788,
      "learning_rate": 7.182904411764706e-06,
      "loss": 0.4104,
      "step": 1564
    },
    {
      "epoch": 0.3596047794117647,
      "grad_norm": 1.6884567737579346,
      "learning_rate": 7.1875e-06,
      "loss": 0.4957,
      "step": 1565
    },
    {
      "epoch": 0.35983455882352944,
      "grad_norm": 1.436244249343872,
      "learning_rate": 7.1920955882352945e-06,
      "loss": 0.4048,
      "step": 1566
    },
    {
      "epoch": 0.3600643382352941,
      "grad_norm": 1.7006769180297852,
      "learning_rate": 7.19669117647059e-06,
      "loss": 0.4005,
      "step": 1567
    },
    {
      "epoch": 0.3602941176470588,
      "grad_norm": 1.3440685272216797,
      "learning_rate": 7.201286764705882e-06,
      "loss": 0.4654,
      "step": 1568
    },
    {
      "epoch": 0.36052389705882354,
      "grad_norm": 1.6225318908691406,
      "learning_rate": 7.205882352941177e-06,
      "loss": 0.4919,
      "step": 1569
    },
    {
      "epoch": 0.36075367647058826,
      "grad_norm": 1.8413200378417969,
      "learning_rate": 7.210477941176471e-06,
      "loss": 0.5128,
      "step": 1570
    },
    {
      "epoch": 0.3609834558823529,
      "grad_norm": 1.961473822593689,
      "learning_rate": 7.215073529411765e-06,
      "loss": 0.4629,
      "step": 1571
    },
    {
      "epoch": 0.36121323529411764,
      "grad_norm": 1.815395712852478,
      "learning_rate": 7.219669117647059e-06,
      "loss": 0.4847,
      "step": 1572
    },
    {
      "epoch": 0.36144301470588236,
      "grad_norm": 1.7090001106262207,
      "learning_rate": 7.224264705882353e-06,
      "loss": 0.5168,
      "step": 1573
    },
    {
      "epoch": 0.3616727941176471,
      "grad_norm": 1.458178162574768,
      "learning_rate": 7.2288602941176475e-06,
      "loss": 0.4127,
      "step": 1574
    },
    {
      "epoch": 0.36190257352941174,
      "grad_norm": 1.5418773889541626,
      "learning_rate": 7.233455882352942e-06,
      "loss": 0.5308,
      "step": 1575
    },
    {
      "epoch": 0.36213235294117646,
      "grad_norm": 1.698352575302124,
      "learning_rate": 7.238051470588235e-06,
      "loss": 0.4852,
      "step": 1576
    },
    {
      "epoch": 0.3623621323529412,
      "grad_norm": 1.4310990571975708,
      "learning_rate": 7.24264705882353e-06,
      "loss": 0.3978,
      "step": 1577
    },
    {
      "epoch": 0.3625919117647059,
      "grad_norm": 1.6908961534500122,
      "learning_rate": 7.247242647058824e-06,
      "loss": 0.4711,
      "step": 1578
    },
    {
      "epoch": 0.36282169117647056,
      "grad_norm": 1.6021333932876587,
      "learning_rate": 7.251838235294118e-06,
      "loss": 0.4051,
      "step": 1579
    },
    {
      "epoch": 0.3630514705882353,
      "grad_norm": 1.4314415454864502,
      "learning_rate": 7.256433823529412e-06,
      "loss": 0.3889,
      "step": 1580
    },
    {
      "epoch": 0.36328125,
      "grad_norm": 1.5690391063690186,
      "learning_rate": 7.261029411764706e-06,
      "loss": 0.3995,
      "step": 1581
    },
    {
      "epoch": 0.3635110294117647,
      "grad_norm": 1.3207672834396362,
      "learning_rate": 7.265625e-06,
      "loss": 0.4557,
      "step": 1582
    },
    {
      "epoch": 0.36374080882352944,
      "grad_norm": 1.6341793537139893,
      "learning_rate": 7.270220588235295e-06,
      "loss": 0.3829,
      "step": 1583
    },
    {
      "epoch": 0.3639705882352941,
      "grad_norm": 1.4621610641479492,
      "learning_rate": 7.274816176470589e-06,
      "loss": 0.4792,
      "step": 1584
    },
    {
      "epoch": 0.3642003676470588,
      "grad_norm": 1.5710885524749756,
      "learning_rate": 7.2794117647058826e-06,
      "loss": 0.402,
      "step": 1585
    },
    {
      "epoch": 0.36443014705882354,
      "grad_norm": 1.6855348348617554,
      "learning_rate": 7.284007352941177e-06,
      "loss": 0.4037,
      "step": 1586
    },
    {
      "epoch": 0.36465992647058826,
      "grad_norm": 1.5394926071166992,
      "learning_rate": 7.288602941176471e-06,
      "loss": 0.4384,
      "step": 1587
    },
    {
      "epoch": 0.3648897058823529,
      "grad_norm": 1.4957722425460815,
      "learning_rate": 7.2931985294117655e-06,
      "loss": 0.4124,
      "step": 1588
    },
    {
      "epoch": 0.36511948529411764,
      "grad_norm": 1.6139836311340332,
      "learning_rate": 7.297794117647059e-06,
      "loss": 0.4014,
      "step": 1589
    },
    {
      "epoch": 0.36534926470588236,
      "grad_norm": 1.6080259084701538,
      "learning_rate": 7.302389705882353e-06,
      "loss": 0.3894,
      "step": 1590
    },
    {
      "epoch": 0.3655790441176471,
      "grad_norm": 1.4939625263214111,
      "learning_rate": 7.306985294117648e-06,
      "loss": 0.4434,
      "step": 1591
    },
    {
      "epoch": 0.36580882352941174,
      "grad_norm": 1.756314754486084,
      "learning_rate": 7.311580882352942e-06,
      "loss": 0.47,
      "step": 1592
    },
    {
      "epoch": 0.36603860294117646,
      "grad_norm": 1.419265866279602,
      "learning_rate": 7.3161764705882355e-06,
      "loss": 0.4225,
      "step": 1593
    },
    {
      "epoch": 0.3662683823529412,
      "grad_norm": 1.4906126260757446,
      "learning_rate": 7.32077205882353e-06,
      "loss": 0.4449,
      "step": 1594
    },
    {
      "epoch": 0.3664981617647059,
      "grad_norm": 1.6667797565460205,
      "learning_rate": 7.325367647058824e-06,
      "loss": 0.4403,
      "step": 1595
    },
    {
      "epoch": 0.36672794117647056,
      "grad_norm": 1.9805546998977661,
      "learning_rate": 7.3299632352941185e-06,
      "loss": 0.5429,
      "step": 1596
    },
    {
      "epoch": 0.3669577205882353,
      "grad_norm": 1.284511923789978,
      "learning_rate": 7.334558823529412e-06,
      "loss": 0.4591,
      "step": 1597
    },
    {
      "epoch": 0.3671875,
      "grad_norm": 1.8720855712890625,
      "learning_rate": 7.339154411764706e-06,
      "loss": 0.5068,
      "step": 1598
    },
    {
      "epoch": 0.3674172794117647,
      "grad_norm": 1.5329418182373047,
      "learning_rate": 7.343750000000001e-06,
      "loss": 0.4931,
      "step": 1599
    },
    {
      "epoch": 0.36764705882352944,
      "grad_norm": 1.7192107439041138,
      "learning_rate": 7.348345588235295e-06,
      "loss": 0.4517,
      "step": 1600
    },
    {
      "epoch": 0.3678768382352941,
      "grad_norm": 1.610005497932434,
      "learning_rate": 7.352941176470589e-06,
      "loss": 0.4049,
      "step": 1601
    },
    {
      "epoch": 0.3681066176470588,
      "grad_norm": 2.0221939086914062,
      "learning_rate": 7.357536764705883e-06,
      "loss": 0.3971,
      "step": 1602
    },
    {
      "epoch": 0.36833639705882354,
      "grad_norm": 1.664108395576477,
      "learning_rate": 7.362132352941177e-06,
      "loss": 0.4731,
      "step": 1603
    },
    {
      "epoch": 0.36856617647058826,
      "grad_norm": 1.4434618949890137,
      "learning_rate": 7.3667279411764714e-06,
      "loss": 0.3735,
      "step": 1604
    },
    {
      "epoch": 0.3687959558823529,
      "grad_norm": 1.337484359741211,
      "learning_rate": 7.371323529411766e-06,
      "loss": 0.3794,
      "step": 1605
    },
    {
      "epoch": 0.36902573529411764,
      "grad_norm": 1.586765170097351,
      "learning_rate": 7.375919117647059e-06,
      "loss": 0.4483,
      "step": 1606
    },
    {
      "epoch": 0.36925551470588236,
      "grad_norm": 1.3823106288909912,
      "learning_rate": 7.3805147058823536e-06,
      "loss": 0.4527,
      "step": 1607
    },
    {
      "epoch": 0.3694852941176471,
      "grad_norm": 1.9415977001190186,
      "learning_rate": 7.385110294117648e-06,
      "loss": 0.3695,
      "step": 1608
    },
    {
      "epoch": 0.36971507352941174,
      "grad_norm": 2.0966339111328125,
      "learning_rate": 7.389705882352942e-06,
      "loss": 0.397,
      "step": 1609
    },
    {
      "epoch": 0.36994485294117646,
      "grad_norm": 1.6542978286743164,
      "learning_rate": 7.394301470588236e-06,
      "loss": 0.4419,
      "step": 1610
    },
    {
      "epoch": 0.3701746323529412,
      "grad_norm": 1.7615935802459717,
      "learning_rate": 7.39889705882353e-06,
      "loss": 0.4634,
      "step": 1611
    },
    {
      "epoch": 0.3704044117647059,
      "grad_norm": 1.6136797666549683,
      "learning_rate": 7.403492647058824e-06,
      "loss": 0.4234,
      "step": 1612
    },
    {
      "epoch": 0.37063419117647056,
      "grad_norm": 1.909619927406311,
      "learning_rate": 7.408088235294119e-06,
      "loss": 0.4059,
      "step": 1613
    },
    {
      "epoch": 0.3708639705882353,
      "grad_norm": 1.2649216651916504,
      "learning_rate": 7.412683823529412e-06,
      "loss": 0.3794,
      "step": 1614
    },
    {
      "epoch": 0.37109375,
      "grad_norm": 1.569555640220642,
      "learning_rate": 7.4172794117647065e-06,
      "loss": 0.3879,
      "step": 1615
    },
    {
      "epoch": 0.3713235294117647,
      "grad_norm": 1.5190098285675049,
      "learning_rate": 7.421875000000001e-06,
      "loss": 0.4858,
      "step": 1616
    },
    {
      "epoch": 0.37155330882352944,
      "grad_norm": 1.6318620443344116,
      "learning_rate": 7.426470588235295e-06,
      "loss": 0.4833,
      "step": 1617
    },
    {
      "epoch": 0.3717830882352941,
      "grad_norm": 1.4210946559906006,
      "learning_rate": 7.4310661764705895e-06,
      "loss": 0.4396,
      "step": 1618
    },
    {
      "epoch": 0.3720128676470588,
      "grad_norm": 1.674235224723816,
      "learning_rate": 7.435661764705883e-06,
      "loss": 0.3656,
      "step": 1619
    },
    {
      "epoch": 0.37224264705882354,
      "grad_norm": 1.8271759748458862,
      "learning_rate": 7.440257352941177e-06,
      "loss": 0.4865,
      "step": 1620
    },
    {
      "epoch": 0.37247242647058826,
      "grad_norm": 1.3476452827453613,
      "learning_rate": 7.444852941176472e-06,
      "loss": 0.4656,
      "step": 1621
    },
    {
      "epoch": 0.3727022058823529,
      "grad_norm": 1.7007535696029663,
      "learning_rate": 7.449448529411766e-06,
      "loss": 0.4163,
      "step": 1622
    },
    {
      "epoch": 0.37293198529411764,
      "grad_norm": 1.6258865594863892,
      "learning_rate": 7.4540441176470594e-06,
      "loss": 0.41,
      "step": 1623
    },
    {
      "epoch": 0.37316176470588236,
      "grad_norm": 1.2622517347335815,
      "learning_rate": 7.458639705882354e-06,
      "loss": 0.4236,
      "step": 1624
    },
    {
      "epoch": 0.3733915441176471,
      "grad_norm": 1.6150016784667969,
      "learning_rate": 7.463235294117648e-06,
      "loss": 0.4484,
      "step": 1625
    },
    {
      "epoch": 0.37362132352941174,
      "grad_norm": 1.7679011821746826,
      "learning_rate": 7.4678308823529424e-06,
      "loss": 0.446,
      "step": 1626
    },
    {
      "epoch": 0.37385110294117646,
      "grad_norm": 1.4136775732040405,
      "learning_rate": 7.472426470588235e-06,
      "loss": 0.386,
      "step": 1627
    },
    {
      "epoch": 0.3740808823529412,
      "grad_norm": 1.327069640159607,
      "learning_rate": 7.47702205882353e-06,
      "loss": 0.4109,
      "step": 1628
    },
    {
      "epoch": 0.3743106617647059,
      "grad_norm": 1.5906858444213867,
      "learning_rate": 7.4816176470588246e-06,
      "loss": 0.4408,
      "step": 1629
    },
    {
      "epoch": 0.37454044117647056,
      "grad_norm": 1.6051236391067505,
      "learning_rate": 7.486213235294119e-06,
      "loss": 0.4128,
      "step": 1630
    },
    {
      "epoch": 0.3747702205882353,
      "grad_norm": 1.453631043434143,
      "learning_rate": 7.4908088235294115e-06,
      "loss": 0.4273,
      "step": 1631
    },
    {
      "epoch": 0.375,
      "grad_norm": 1.593843698501587,
      "learning_rate": 7.495404411764706e-06,
      "loss": 0.4292,
      "step": 1632
    },
    {
      "epoch": 0.3752297794117647,
      "grad_norm": 1.503454566001892,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.4823,
      "step": 1633
    },
    {
      "epoch": 0.37545955882352944,
      "grad_norm": 1.7276440858840942,
      "learning_rate": 7.504595588235295e-06,
      "loss": 0.3659,
      "step": 1634
    },
    {
      "epoch": 0.3756893382352941,
      "grad_norm": 1.523011326789856,
      "learning_rate": 7.50919117647059e-06,
      "loss": 0.3723,
      "step": 1635
    },
    {
      "epoch": 0.3759191176470588,
      "grad_norm": 1.6724475622177124,
      "learning_rate": 7.513786764705882e-06,
      "loss": 0.4696,
      "step": 1636
    },
    {
      "epoch": 0.37614889705882354,
      "grad_norm": 1.4541404247283936,
      "learning_rate": 7.518382352941177e-06,
      "loss": 0.451,
      "step": 1637
    },
    {
      "epoch": 0.37637867647058826,
      "grad_norm": 1.558263897895813,
      "learning_rate": 7.522977941176471e-06,
      "loss": 0.4941,
      "step": 1638
    },
    {
      "epoch": 0.3766084558823529,
      "grad_norm": 1.6707834005355835,
      "learning_rate": 7.527573529411766e-06,
      "loss": 0.4321,
      "step": 1639
    },
    {
      "epoch": 0.37683823529411764,
      "grad_norm": 1.5530376434326172,
      "learning_rate": 7.532169117647059e-06,
      "loss": 0.4121,
      "step": 1640
    },
    {
      "epoch": 0.37706801470588236,
      "grad_norm": 2.0696396827697754,
      "learning_rate": 7.536764705882353e-06,
      "loss": 0.3229,
      "step": 1641
    },
    {
      "epoch": 0.3772977941176471,
      "grad_norm": 1.680188536643982,
      "learning_rate": 7.5413602941176475e-06,
      "loss": 0.4118,
      "step": 1642
    },
    {
      "epoch": 0.37752757352941174,
      "grad_norm": 1.623008131980896,
      "learning_rate": 7.545955882352942e-06,
      "loss": 0.3957,
      "step": 1643
    },
    {
      "epoch": 0.37775735294117646,
      "grad_norm": 1.9622080326080322,
      "learning_rate": 7.550551470588235e-06,
      "loss": 0.4142,
      "step": 1644
    },
    {
      "epoch": 0.3779871323529412,
      "grad_norm": 1.5477653741836548,
      "learning_rate": 7.55514705882353e-06,
      "loss": 0.3764,
      "step": 1645
    },
    {
      "epoch": 0.3782169117647059,
      "grad_norm": 1.4328516721725464,
      "learning_rate": 7.559742647058824e-06,
      "loss": 0.4181,
      "step": 1646
    },
    {
      "epoch": 0.37844669117647056,
      "grad_norm": 1.470009684562683,
      "learning_rate": 7.564338235294118e-06,
      "loss": 0.4315,
      "step": 1647
    },
    {
      "epoch": 0.3786764705882353,
      "grad_norm": 1.481760025024414,
      "learning_rate": 7.568933823529412e-06,
      "loss": 0.4137,
      "step": 1648
    },
    {
      "epoch": 0.37890625,
      "grad_norm": 1.4097234010696411,
      "learning_rate": 7.573529411764706e-06,
      "loss": 0.3986,
      "step": 1649
    },
    {
      "epoch": 0.3791360294117647,
      "grad_norm": 1.3193477392196655,
      "learning_rate": 7.578125e-06,
      "loss": 0.376,
      "step": 1650
    },
    {
      "epoch": 0.37936580882352944,
      "grad_norm": 1.483893632888794,
      "learning_rate": 7.582720588235295e-06,
      "loss": 0.3261,
      "step": 1651
    },
    {
      "epoch": 0.3795955882352941,
      "grad_norm": 1.829319953918457,
      "learning_rate": 7.587316176470589e-06,
      "loss": 0.4765,
      "step": 1652
    },
    {
      "epoch": 0.3798253676470588,
      "grad_norm": 1.3198695182800293,
      "learning_rate": 7.5919117647058825e-06,
      "loss": 0.3643,
      "step": 1653
    },
    {
      "epoch": 0.38005514705882354,
      "grad_norm": 1.777559518814087,
      "learning_rate": 7.596507352941177e-06,
      "loss": 0.3845,
      "step": 1654
    },
    {
      "epoch": 0.38028492647058826,
      "grad_norm": 1.5888266563415527,
      "learning_rate": 7.601102941176471e-06,
      "loss": 0.4282,
      "step": 1655
    },
    {
      "epoch": 0.3805147058823529,
      "grad_norm": 1.6925135850906372,
      "learning_rate": 7.6056985294117655e-06,
      "loss": 0.4343,
      "step": 1656
    },
    {
      "epoch": 0.38074448529411764,
      "grad_norm": 1.494311809539795,
      "learning_rate": 7.610294117647059e-06,
      "loss": 0.4528,
      "step": 1657
    },
    {
      "epoch": 0.38097426470588236,
      "grad_norm": 1.867295742034912,
      "learning_rate": 7.614889705882353e-06,
      "loss": 0.407,
      "step": 1658
    },
    {
      "epoch": 0.3812040441176471,
      "grad_norm": 1.5118260383605957,
      "learning_rate": 7.619485294117648e-06,
      "loss": 0.437,
      "step": 1659
    },
    {
      "epoch": 0.38143382352941174,
      "grad_norm": 1.8724639415740967,
      "learning_rate": 7.624080882352942e-06,
      "loss": 0.4785,
      "step": 1660
    },
    {
      "epoch": 0.38166360294117646,
      "grad_norm": 1.7594126462936401,
      "learning_rate": 7.6286764705882355e-06,
      "loss": 0.3105,
      "step": 1661
    },
    {
      "epoch": 0.3818933823529412,
      "grad_norm": 1.858856439590454,
      "learning_rate": 7.63327205882353e-06,
      "loss": 0.3423,
      "step": 1662
    },
    {
      "epoch": 0.3821231617647059,
      "grad_norm": 1.5263797044754028,
      "learning_rate": 7.637867647058824e-06,
      "loss": 0.4029,
      "step": 1663
    },
    {
      "epoch": 0.38235294117647056,
      "grad_norm": 2.0244877338409424,
      "learning_rate": 7.642463235294118e-06,
      "loss": 0.3982,
      "step": 1664
    },
    {
      "epoch": 0.3825827205882353,
      "grad_norm": 1.4346747398376465,
      "learning_rate": 7.647058823529411e-06,
      "loss": 0.3849,
      "step": 1665
    },
    {
      "epoch": 0.3828125,
      "grad_norm": 1.4609676599502563,
      "learning_rate": 7.651654411764705e-06,
      "loss": 0.4397,
      "step": 1666
    },
    {
      "epoch": 0.3830422794117647,
      "grad_norm": 1.61651611328125,
      "learning_rate": 7.656250000000001e-06,
      "loss": 0.3794,
      "step": 1667
    },
    {
      "epoch": 0.38327205882352944,
      "grad_norm": 1.514161229133606,
      "learning_rate": 7.660845588235296e-06,
      "loss": 0.4191,
      "step": 1668
    },
    {
      "epoch": 0.3835018382352941,
      "grad_norm": 1.465895175933838,
      "learning_rate": 7.66544117647059e-06,
      "loss": 0.3862,
      "step": 1669
    },
    {
      "epoch": 0.3837316176470588,
      "grad_norm": 1.4582117795944214,
      "learning_rate": 7.670036764705883e-06,
      "loss": 0.3923,
      "step": 1670
    },
    {
      "epoch": 0.38396139705882354,
      "grad_norm": 1.4396357536315918,
      "learning_rate": 7.674632352941177e-06,
      "loss": 0.435,
      "step": 1671
    },
    {
      "epoch": 0.38419117647058826,
      "grad_norm": 1.823920726776123,
      "learning_rate": 7.679227941176471e-06,
      "loss": 0.3728,
      "step": 1672
    },
    {
      "epoch": 0.3844209558823529,
      "grad_norm": 1.7076629400253296,
      "learning_rate": 7.683823529411766e-06,
      "loss": 0.4094,
      "step": 1673
    },
    {
      "epoch": 0.38465073529411764,
      "grad_norm": 1.6017030477523804,
      "learning_rate": 7.688419117647058e-06,
      "loss": 0.382,
      "step": 1674
    },
    {
      "epoch": 0.38488051470588236,
      "grad_norm": 1.8259549140930176,
      "learning_rate": 7.693014705882353e-06,
      "loss": 0.4527,
      "step": 1675
    },
    {
      "epoch": 0.3851102941176471,
      "grad_norm": 1.771371841430664,
      "learning_rate": 7.697610294117647e-06,
      "loss": 0.3932,
      "step": 1676
    },
    {
      "epoch": 0.38534007352941174,
      "grad_norm": 2.1047847270965576,
      "learning_rate": 7.702205882352943e-06,
      "loss": 0.3773,
      "step": 1677
    },
    {
      "epoch": 0.38556985294117646,
      "grad_norm": 1.4268378019332886,
      "learning_rate": 7.706801470588236e-06,
      "loss": 0.4202,
      "step": 1678
    },
    {
      "epoch": 0.3857996323529412,
      "grad_norm": 1.7693545818328857,
      "learning_rate": 7.71139705882353e-06,
      "loss": 0.3755,
      "step": 1679
    },
    {
      "epoch": 0.3860294117647059,
      "grad_norm": 1.472502589225769,
      "learning_rate": 7.715992647058824e-06,
      "loss": 0.3975,
      "step": 1680
    },
    {
      "epoch": 0.38625919117647056,
      "grad_norm": 1.837773323059082,
      "learning_rate": 7.720588235294119e-06,
      "loss": 0.3511,
      "step": 1681
    },
    {
      "epoch": 0.3864889705882353,
      "grad_norm": 1.3951057195663452,
      "learning_rate": 7.725183823529411e-06,
      "loss": 0.3772,
      "step": 1682
    },
    {
      "epoch": 0.38671875,
      "grad_norm": 2.0604264736175537,
      "learning_rate": 7.729779411764706e-06,
      "loss": 0.4285,
      "step": 1683
    },
    {
      "epoch": 0.3869485294117647,
      "grad_norm": 1.7523881196975708,
      "learning_rate": 7.734375e-06,
      "loss": 0.3799,
      "step": 1684
    },
    {
      "epoch": 0.38717830882352944,
      "grad_norm": 1.4538719654083252,
      "learning_rate": 7.738970588235294e-06,
      "loss": 0.3568,
      "step": 1685
    },
    {
      "epoch": 0.3874080882352941,
      "grad_norm": 1.7656038999557495,
      "learning_rate": 7.743566176470589e-06,
      "loss": 0.479,
      "step": 1686
    },
    {
      "epoch": 0.3876378676470588,
      "grad_norm": 1.8397283554077148,
      "learning_rate": 7.748161764705883e-06,
      "loss": 0.4422,
      "step": 1687
    },
    {
      "epoch": 0.38786764705882354,
      "grad_norm": 1.7269424200057983,
      "learning_rate": 7.752757352941177e-06,
      "loss": 0.37,
      "step": 1688
    },
    {
      "epoch": 0.38809742647058826,
      "grad_norm": 1.5864248275756836,
      "learning_rate": 7.757352941176472e-06,
      "loss": 0.3979,
      "step": 1689
    },
    {
      "epoch": 0.3883272058823529,
      "grad_norm": 1.4360315799713135,
      "learning_rate": 7.761948529411766e-06,
      "loss": 0.4035,
      "step": 1690
    },
    {
      "epoch": 0.38855698529411764,
      "grad_norm": 1.655123233795166,
      "learning_rate": 7.766544117647059e-06,
      "loss": 0.4251,
      "step": 1691
    },
    {
      "epoch": 0.38878676470588236,
      "grad_norm": 1.667230486869812,
      "learning_rate": 7.771139705882353e-06,
      "loss": 0.4831,
      "step": 1692
    },
    {
      "epoch": 0.3890165441176471,
      "grad_norm": 1.6469967365264893,
      "learning_rate": 7.775735294117647e-06,
      "loss": 0.4161,
      "step": 1693
    },
    {
      "epoch": 0.38924632352941174,
      "grad_norm": 1.883493185043335,
      "learning_rate": 7.780330882352942e-06,
      "loss": 0.4057,
      "step": 1694
    },
    {
      "epoch": 0.38947610294117646,
      "grad_norm": 1.7476786375045776,
      "learning_rate": 7.784926470588236e-06,
      "loss": 0.4097,
      "step": 1695
    },
    {
      "epoch": 0.3897058823529412,
      "grad_norm": 1.6239298582077026,
      "learning_rate": 7.78952205882353e-06,
      "loss": 0.4044,
      "step": 1696
    },
    {
      "epoch": 0.3899356617647059,
      "grad_norm": 1.9051507711410522,
      "learning_rate": 7.794117647058825e-06,
      "loss": 0.4291,
      "step": 1697
    },
    {
      "epoch": 0.39016544117647056,
      "grad_norm": 1.6379828453063965,
      "learning_rate": 7.798713235294119e-06,
      "loss": 0.4686,
      "step": 1698
    },
    {
      "epoch": 0.3903952205882353,
      "grad_norm": 2.077446222305298,
      "learning_rate": 7.803308823529412e-06,
      "loss": 0.39,
      "step": 1699
    },
    {
      "epoch": 0.390625,
      "grad_norm": 1.742782473564148,
      "learning_rate": 7.807904411764706e-06,
      "loss": 0.4518,
      "step": 1700
    },
    {
      "epoch": 0.3908547794117647,
      "grad_norm": 1.6004433631896973,
      "learning_rate": 7.8125e-06,
      "loss": 0.4631,
      "step": 1701
    },
    {
      "epoch": 0.39108455882352944,
      "grad_norm": 1.5255473852157593,
      "learning_rate": 7.817095588235294e-06,
      "loss": 0.3787,
      "step": 1702
    },
    {
      "epoch": 0.3913143382352941,
      "grad_norm": 1.533432960510254,
      "learning_rate": 7.821691176470589e-06,
      "loss": 0.4235,
      "step": 1703
    },
    {
      "epoch": 0.3915441176470588,
      "grad_norm": 1.5987728834152222,
      "learning_rate": 7.826286764705883e-06,
      "loss": 0.3522,
      "step": 1704
    },
    {
      "epoch": 0.39177389705882354,
      "grad_norm": 1.8157124519348145,
      "learning_rate": 7.830882352941177e-06,
      "loss": 0.3977,
      "step": 1705
    },
    {
      "epoch": 0.39200367647058826,
      "grad_norm": 1.5875542163848877,
      "learning_rate": 7.835477941176472e-06,
      "loss": 0.3269,
      "step": 1706
    },
    {
      "epoch": 0.3922334558823529,
      "grad_norm": 1.477384090423584,
      "learning_rate": 7.840073529411766e-06,
      "loss": 0.4414,
      "step": 1707
    },
    {
      "epoch": 0.39246323529411764,
      "grad_norm": 1.6180062294006348,
      "learning_rate": 7.844669117647059e-06,
      "loss": 0.4235,
      "step": 1708
    },
    {
      "epoch": 0.39269301470588236,
      "grad_norm": 1.2784638404846191,
      "learning_rate": 7.849264705882353e-06,
      "loss": 0.4143,
      "step": 1709
    },
    {
      "epoch": 0.3929227941176471,
      "grad_norm": 2.0106313228607178,
      "learning_rate": 7.853860294117647e-06,
      "loss": 0.39,
      "step": 1710
    },
    {
      "epoch": 0.39315257352941174,
      "grad_norm": 1.5501376390457153,
      "learning_rate": 7.858455882352942e-06,
      "loss": 0.4006,
      "step": 1711
    },
    {
      "epoch": 0.39338235294117646,
      "grad_norm": 1.4640899896621704,
      "learning_rate": 7.863051470588236e-06,
      "loss": 0.4202,
      "step": 1712
    },
    {
      "epoch": 0.3936121323529412,
      "grad_norm": 1.4828485250473022,
      "learning_rate": 7.86764705882353e-06,
      "loss": 0.3571,
      "step": 1713
    },
    {
      "epoch": 0.3938419117647059,
      "grad_norm": 1.7106895446777344,
      "learning_rate": 7.872242647058825e-06,
      "loss": 0.403,
      "step": 1714
    },
    {
      "epoch": 0.39407169117647056,
      "grad_norm": 1.6277273893356323,
      "learning_rate": 7.876838235294119e-06,
      "loss": 0.3733,
      "step": 1715
    },
    {
      "epoch": 0.3943014705882353,
      "grad_norm": 1.6846522092819214,
      "learning_rate": 7.881433823529412e-06,
      "loss": 0.3905,
      "step": 1716
    },
    {
      "epoch": 0.39453125,
      "grad_norm": 1.505588412284851,
      "learning_rate": 7.886029411764706e-06,
      "loss": 0.4427,
      "step": 1717
    },
    {
      "epoch": 0.3947610294117647,
      "grad_norm": 1.3615530729293823,
      "learning_rate": 7.890625e-06,
      "loss": 0.3653,
      "step": 1718
    },
    {
      "epoch": 0.39499080882352944,
      "grad_norm": 1.7366712093353271,
      "learning_rate": 7.895220588235295e-06,
      "loss": 0.4197,
      "step": 1719
    },
    {
      "epoch": 0.3952205882352941,
      "grad_norm": 1.5400257110595703,
      "learning_rate": 7.899816176470589e-06,
      "loss": 0.3458,
      "step": 1720
    },
    {
      "epoch": 0.3954503676470588,
      "grad_norm": 1.6478800773620605,
      "learning_rate": 7.904411764705883e-06,
      "loss": 0.3556,
      "step": 1721
    },
    {
      "epoch": 0.39568014705882354,
      "grad_norm": 1.79155695438385,
      "learning_rate": 7.909007352941178e-06,
      "loss": 0.3887,
      "step": 1722
    },
    {
      "epoch": 0.39590992647058826,
      "grad_norm": 1.7639338970184326,
      "learning_rate": 7.913602941176472e-06,
      "loss": 0.3933,
      "step": 1723
    },
    {
      "epoch": 0.3961397058823529,
      "grad_norm": 1.7379850149154663,
      "learning_rate": 7.918198529411766e-06,
      "loss": 0.3406,
      "step": 1724
    },
    {
      "epoch": 0.39636948529411764,
      "grad_norm": 1.9898173809051514,
      "learning_rate": 7.922794117647059e-06,
      "loss": 0.4777,
      "step": 1725
    },
    {
      "epoch": 0.39659926470588236,
      "grad_norm": 1.7088658809661865,
      "learning_rate": 7.927389705882353e-06,
      "loss": 0.3966,
      "step": 1726
    },
    {
      "epoch": 0.3968290441176471,
      "grad_norm": 1.6704038381576538,
      "learning_rate": 7.931985294117648e-06,
      "loss": 0.3991,
      "step": 1727
    },
    {
      "epoch": 0.39705882352941174,
      "grad_norm": 1.4504741430282593,
      "learning_rate": 7.936580882352942e-06,
      "loss": 0.3308,
      "step": 1728
    },
    {
      "epoch": 0.39728860294117646,
      "grad_norm": 1.6104261875152588,
      "learning_rate": 7.941176470588236e-06,
      "loss": 0.406,
      "step": 1729
    },
    {
      "epoch": 0.3975183823529412,
      "grad_norm": 1.7093476057052612,
      "learning_rate": 7.94577205882353e-06,
      "loss": 0.4312,
      "step": 1730
    },
    {
      "epoch": 0.3977481617647059,
      "grad_norm": 1.6708287000656128,
      "learning_rate": 7.950367647058825e-06,
      "loss": 0.3885,
      "step": 1731
    },
    {
      "epoch": 0.39797794117647056,
      "grad_norm": 1.7292407751083374,
      "learning_rate": 7.95496323529412e-06,
      "loss": 0.3775,
      "step": 1732
    },
    {
      "epoch": 0.3982077205882353,
      "grad_norm": 1.7131019830703735,
      "learning_rate": 7.959558823529412e-06,
      "loss": 0.4562,
      "step": 1733
    },
    {
      "epoch": 0.3984375,
      "grad_norm": 1.8245331048965454,
      "learning_rate": 7.964154411764706e-06,
      "loss": 0.3893,
      "step": 1734
    },
    {
      "epoch": 0.3986672794117647,
      "grad_norm": 1.6133809089660645,
      "learning_rate": 7.96875e-06,
      "loss": 0.4066,
      "step": 1735
    },
    {
      "epoch": 0.39889705882352944,
      "grad_norm": 1.6551477909088135,
      "learning_rate": 7.973345588235295e-06,
      "loss": 0.3672,
      "step": 1736
    },
    {
      "epoch": 0.3991268382352941,
      "grad_norm": 1.3436123132705688,
      "learning_rate": 7.97794117647059e-06,
      "loss": 0.3744,
      "step": 1737
    },
    {
      "epoch": 0.3993566176470588,
      "grad_norm": 1.7773388624191284,
      "learning_rate": 7.982536764705882e-06,
      "loss": 0.365,
      "step": 1738
    },
    {
      "epoch": 0.39958639705882354,
      "grad_norm": 1.6136863231658936,
      "learning_rate": 7.987132352941178e-06,
      "loss": 0.3948,
      "step": 1739
    },
    {
      "epoch": 0.39981617647058826,
      "grad_norm": 1.585347294807434,
      "learning_rate": 7.991727941176472e-06,
      "loss": 0.3932,
      "step": 1740
    },
    {
      "epoch": 0.4000459558823529,
      "grad_norm": 1.6870125532150269,
      "learning_rate": 7.996323529411767e-06,
      "loss": 0.4252,
      "step": 1741
    },
    {
      "epoch": 0.40027573529411764,
      "grad_norm": 1.590043544769287,
      "learning_rate": 8.00091911764706e-06,
      "loss": 0.4006,
      "step": 1742
    },
    {
      "epoch": 0.40050551470588236,
      "grad_norm": 1.5030267238616943,
      "learning_rate": 8.005514705882354e-06,
      "loss": 0.3706,
      "step": 1743
    },
    {
      "epoch": 0.4007352941176471,
      "grad_norm": 1.6462550163269043,
      "learning_rate": 8.010110294117648e-06,
      "loss": 0.3712,
      "step": 1744
    },
    {
      "epoch": 0.40096507352941174,
      "grad_norm": 1.6091042757034302,
      "learning_rate": 8.014705882352942e-06,
      "loss": 0.362,
      "step": 1745
    },
    {
      "epoch": 0.40119485294117646,
      "grad_norm": 1.8039294481277466,
      "learning_rate": 8.019301470588235e-06,
      "loss": 0.3742,
      "step": 1746
    },
    {
      "epoch": 0.4014246323529412,
      "grad_norm": 2.156829595565796,
      "learning_rate": 8.023897058823529e-06,
      "loss": 0.4202,
      "step": 1747
    },
    {
      "epoch": 0.4016544117647059,
      "grad_norm": 1.4138132333755493,
      "learning_rate": 8.028492647058823e-06,
      "loss": 0.4058,
      "step": 1748
    },
    {
      "epoch": 0.40188419117647056,
      "grad_norm": 2.3966290950775146,
      "learning_rate": 8.033088235294118e-06,
      "loss": 0.4047,
      "step": 1749
    },
    {
      "epoch": 0.4021139705882353,
      "grad_norm": 1.5083773136138916,
      "learning_rate": 8.037683823529412e-06,
      "loss": 0.4196,
      "step": 1750
    },
    {
      "epoch": 0.40234375,
      "grad_norm": 1.481977105140686,
      "learning_rate": 8.042279411764706e-06,
      "loss": 0.4214,
      "step": 1751
    },
    {
      "epoch": 0.4025735294117647,
      "grad_norm": 1.5034912824630737,
      "learning_rate": 8.046875e-06,
      "loss": 0.3638,
      "step": 1752
    },
    {
      "epoch": 0.40280330882352944,
      "grad_norm": 1.588551640510559,
      "learning_rate": 8.051470588235295e-06,
      "loss": 0.3075,
      "step": 1753
    },
    {
      "epoch": 0.4030330882352941,
      "grad_norm": 1.295883297920227,
      "learning_rate": 8.05606617647059e-06,
      "loss": 0.4099,
      "step": 1754
    },
    {
      "epoch": 0.4032628676470588,
      "grad_norm": 1.6140192747116089,
      "learning_rate": 8.060661764705882e-06,
      "loss": 0.3185,
      "step": 1755
    },
    {
      "epoch": 0.40349264705882354,
      "grad_norm": 1.8269238471984863,
      "learning_rate": 8.065257352941176e-06,
      "loss": 0.2877,
      "step": 1756
    },
    {
      "epoch": 0.40372242647058826,
      "grad_norm": 1.3969804048538208,
      "learning_rate": 8.06985294117647e-06,
      "loss": 0.3571,
      "step": 1757
    },
    {
      "epoch": 0.4039522058823529,
      "grad_norm": 1.4891417026519775,
      "learning_rate": 8.074448529411765e-06,
      "loss": 0.3595,
      "step": 1758
    },
    {
      "epoch": 0.40418198529411764,
      "grad_norm": 1.303857684135437,
      "learning_rate": 8.07904411764706e-06,
      "loss": 0.3444,
      "step": 1759
    },
    {
      "epoch": 0.40441176470588236,
      "grad_norm": 1.7701207399368286,
      "learning_rate": 8.083639705882354e-06,
      "loss": 0.3932,
      "step": 1760
    },
    {
      "epoch": 0.4046415441176471,
      "grad_norm": 1.7681185007095337,
      "learning_rate": 8.088235294117648e-06,
      "loss": 0.3937,
      "step": 1761
    },
    {
      "epoch": 0.40487132352941174,
      "grad_norm": 1.4107229709625244,
      "learning_rate": 8.092830882352942e-06,
      "loss": 0.3743,
      "step": 1762
    },
    {
      "epoch": 0.40510110294117646,
      "grad_norm": 1.7074387073516846,
      "learning_rate": 8.097426470588235e-06,
      "loss": 0.3534,
      "step": 1763
    },
    {
      "epoch": 0.4053308823529412,
      "grad_norm": 1.642343521118164,
      "learning_rate": 8.10202205882353e-06,
      "loss": 0.4057,
      "step": 1764
    },
    {
      "epoch": 0.4055606617647059,
      "grad_norm": 1.8716100454330444,
      "learning_rate": 8.106617647058824e-06,
      "loss": 0.4492,
      "step": 1765
    },
    {
      "epoch": 0.40579044117647056,
      "grad_norm": 1.9598621129989624,
      "learning_rate": 8.111213235294118e-06,
      "loss": 0.4342,
      "step": 1766
    },
    {
      "epoch": 0.4060202205882353,
      "grad_norm": 1.5819231271743774,
      "learning_rate": 8.115808823529412e-06,
      "loss": 0.3407,
      "step": 1767
    },
    {
      "epoch": 0.40625,
      "grad_norm": 1.5218106508255005,
      "learning_rate": 8.120404411764707e-06,
      "loss": 0.2889,
      "step": 1768
    },
    {
      "epoch": 0.4064797794117647,
      "grad_norm": 1.4532967805862427,
      "learning_rate": 8.125000000000001e-06,
      "loss": 0.4115,
      "step": 1769
    },
    {
      "epoch": 0.40670955882352944,
      "grad_norm": 1.4185997247695923,
      "learning_rate": 8.129595588235295e-06,
      "loss": 0.2802,
      "step": 1770
    },
    {
      "epoch": 0.4069393382352941,
      "grad_norm": 1.6973339319229126,
      "learning_rate": 8.13419117647059e-06,
      "loss": 0.3805,
      "step": 1771
    },
    {
      "epoch": 0.4071691176470588,
      "grad_norm": 1.638858437538147,
      "learning_rate": 8.138786764705882e-06,
      "loss": 0.3866,
      "step": 1772
    },
    {
      "epoch": 0.40739889705882354,
      "grad_norm": 1.4359068870544434,
      "learning_rate": 8.143382352941177e-06,
      "loss": 0.4274,
      "step": 1773
    },
    {
      "epoch": 0.40762867647058826,
      "grad_norm": 1.3693861961364746,
      "learning_rate": 8.147977941176471e-06,
      "loss": 0.3608,
      "step": 1774
    },
    {
      "epoch": 0.4078584558823529,
      "grad_norm": 1.7762149572372437,
      "learning_rate": 8.152573529411765e-06,
      "loss": 0.3302,
      "step": 1775
    },
    {
      "epoch": 0.40808823529411764,
      "grad_norm": 1.6438679695129395,
      "learning_rate": 8.15716911764706e-06,
      "loss": 0.4213,
      "step": 1776
    },
    {
      "epoch": 0.40831801470588236,
      "grad_norm": 1.6731294393539429,
      "learning_rate": 8.161764705882354e-06,
      "loss": 0.4201,
      "step": 1777
    },
    {
      "epoch": 0.4085477941176471,
      "grad_norm": 1.5435945987701416,
      "learning_rate": 8.166360294117648e-06,
      "loss": 0.3746,
      "step": 1778
    },
    {
      "epoch": 0.40877757352941174,
      "grad_norm": 1.780115008354187,
      "learning_rate": 8.170955882352943e-06,
      "loss": 0.3658,
      "step": 1779
    },
    {
      "epoch": 0.40900735294117646,
      "grad_norm": 1.7334657907485962,
      "learning_rate": 8.175551470588235e-06,
      "loss": 0.3769,
      "step": 1780
    },
    {
      "epoch": 0.4092371323529412,
      "grad_norm": 1.4699594974517822,
      "learning_rate": 8.18014705882353e-06,
      "loss": 0.3806,
      "step": 1781
    },
    {
      "epoch": 0.4094669117647059,
      "grad_norm": 2.113771915435791,
      "learning_rate": 8.184742647058824e-06,
      "loss": 0.402,
      "step": 1782
    },
    {
      "epoch": 0.40969669117647056,
      "grad_norm": 2.327350378036499,
      "learning_rate": 8.189338235294118e-06,
      "loss": 0.4641,
      "step": 1783
    },
    {
      "epoch": 0.4099264705882353,
      "grad_norm": 1.4663960933685303,
      "learning_rate": 8.193933823529413e-06,
      "loss": 0.3627,
      "step": 1784
    },
    {
      "epoch": 0.41015625,
      "grad_norm": 1.8229058980941772,
      "learning_rate": 8.198529411764707e-06,
      "loss": 0.4132,
      "step": 1785
    },
    {
      "epoch": 0.4103860294117647,
      "grad_norm": 1.7551788091659546,
      "learning_rate": 8.203125000000001e-06,
      "loss": 0.3896,
      "step": 1786
    },
    {
      "epoch": 0.41061580882352944,
      "grad_norm": 1.4065520763397217,
      "learning_rate": 8.207720588235296e-06,
      "loss": 0.3263,
      "step": 1787
    },
    {
      "epoch": 0.4108455882352941,
      "grad_norm": 1.7022894620895386,
      "learning_rate": 8.21231617647059e-06,
      "loss": 0.3202,
      "step": 1788
    },
    {
      "epoch": 0.4110753676470588,
      "grad_norm": 1.8207921981811523,
      "learning_rate": 8.216911764705882e-06,
      "loss": 0.4175,
      "step": 1789
    },
    {
      "epoch": 0.41130514705882354,
      "grad_norm": 1.5260653495788574,
      "learning_rate": 8.221507352941177e-06,
      "loss": 0.3663,
      "step": 1790
    },
    {
      "epoch": 0.41153492647058826,
      "grad_norm": 1.4448037147521973,
      "learning_rate": 8.226102941176471e-06,
      "loss": 0.354,
      "step": 1791
    },
    {
      "epoch": 0.4117647058823529,
      "grad_norm": 1.5403306484222412,
      "learning_rate": 8.230698529411765e-06,
      "loss": 0.3963,
      "step": 1792
    },
    {
      "epoch": 0.41199448529411764,
      "grad_norm": 1.4772882461547852,
      "learning_rate": 8.23529411764706e-06,
      "loss": 0.3308,
      "step": 1793
    },
    {
      "epoch": 0.41222426470588236,
      "grad_norm": 1.666274905204773,
      "learning_rate": 8.239889705882354e-06,
      "loss": 0.4169,
      "step": 1794
    },
    {
      "epoch": 0.4124540441176471,
      "grad_norm": 2.42348313331604,
      "learning_rate": 8.244485294117648e-06,
      "loss": 0.3757,
      "step": 1795
    },
    {
      "epoch": 0.41268382352941174,
      "grad_norm": 1.4541699886322021,
      "learning_rate": 8.249080882352943e-06,
      "loss": 0.3791,
      "step": 1796
    },
    {
      "epoch": 0.41291360294117646,
      "grad_norm": 1.736795425415039,
      "learning_rate": 8.253676470588235e-06,
      "loss": 0.4027,
      "step": 1797
    },
    {
      "epoch": 0.4131433823529412,
      "grad_norm": 1.824877381324768,
      "learning_rate": 8.25827205882353e-06,
      "loss": 0.3292,
      "step": 1798
    },
    {
      "epoch": 0.4133731617647059,
      "grad_norm": 1.6618404388427734,
      "learning_rate": 8.262867647058824e-06,
      "loss": 0.3874,
      "step": 1799
    },
    {
      "epoch": 0.41360294117647056,
      "grad_norm": 1.6771571636199951,
      "learning_rate": 8.267463235294118e-06,
      "loss": 0.3267,
      "step": 1800
    },
    {
      "epoch": 0.4138327205882353,
      "grad_norm": 1.5057554244995117,
      "learning_rate": 8.272058823529413e-06,
      "loss": 0.3319,
      "step": 1801
    },
    {
      "epoch": 0.4140625,
      "grad_norm": 1.3164335489273071,
      "learning_rate": 8.276654411764707e-06,
      "loss": 0.3576,
      "step": 1802
    },
    {
      "epoch": 0.4142922794117647,
      "grad_norm": 1.5547504425048828,
      "learning_rate": 8.281250000000001e-06,
      "loss": 0.4084,
      "step": 1803
    },
    {
      "epoch": 0.41452205882352944,
      "grad_norm": 1.4886484146118164,
      "learning_rate": 8.285845588235296e-06,
      "loss": 0.3097,
      "step": 1804
    },
    {
      "epoch": 0.4147518382352941,
      "grad_norm": 1.5845586061477661,
      "learning_rate": 8.29044117647059e-06,
      "loss": 0.3777,
      "step": 1805
    },
    {
      "epoch": 0.4149816176470588,
      "grad_norm": 1.7135798931121826,
      "learning_rate": 8.295036764705883e-06,
      "loss": 0.3453,
      "step": 1806
    },
    {
      "epoch": 0.41521139705882354,
      "grad_norm": 2.209733486175537,
      "learning_rate": 8.299632352941177e-06,
      "loss": 0.362,
      "step": 1807
    },
    {
      "epoch": 0.41544117647058826,
      "grad_norm": 1.804955244064331,
      "learning_rate": 8.304227941176471e-06,
      "loss": 0.3583,
      "step": 1808
    },
    {
      "epoch": 0.4156709558823529,
      "grad_norm": 1.718245506286621,
      "learning_rate": 8.308823529411766e-06,
      "loss": 0.4359,
      "step": 1809
    },
    {
      "epoch": 0.41590073529411764,
      "grad_norm": 1.4520652294158936,
      "learning_rate": 8.313419117647058e-06,
      "loss": 0.3764,
      "step": 1810
    },
    {
      "epoch": 0.41613051470588236,
      "grad_norm": 1.6255017518997192,
      "learning_rate": 8.318014705882354e-06,
      "loss": 0.3804,
      "step": 1811
    },
    {
      "epoch": 0.4163602941176471,
      "grad_norm": 1.5388078689575195,
      "learning_rate": 8.322610294117649e-06,
      "loss": 0.3566,
      "step": 1812
    },
    {
      "epoch": 0.41659007352941174,
      "grad_norm": 1.6456565856933594,
      "learning_rate": 8.327205882352943e-06,
      "loss": 0.353,
      "step": 1813
    },
    {
      "epoch": 0.41681985294117646,
      "grad_norm": 1.6532050371170044,
      "learning_rate": 8.331801470588236e-06,
      "loss": 0.2723,
      "step": 1814
    },
    {
      "epoch": 0.4170496323529412,
      "grad_norm": 1.210847020149231,
      "learning_rate": 8.33639705882353e-06,
      "loss": 0.2832,
      "step": 1815
    },
    {
      "epoch": 0.4172794117647059,
      "grad_norm": 1.6664563417434692,
      "learning_rate": 8.340992647058824e-06,
      "loss": 0.36,
      "step": 1816
    },
    {
      "epoch": 0.41750919117647056,
      "grad_norm": 1.8558611869812012,
      "learning_rate": 8.345588235294119e-06,
      "loss": 0.3733,
      "step": 1817
    },
    {
      "epoch": 0.4177389705882353,
      "grad_norm": 1.7433795928955078,
      "learning_rate": 8.350183823529411e-06,
      "loss": 0.3697,
      "step": 1818
    },
    {
      "epoch": 0.41796875,
      "grad_norm": 1.7788752317428589,
      "learning_rate": 8.354779411764706e-06,
      "loss": 0.3674,
      "step": 1819
    },
    {
      "epoch": 0.4181985294117647,
      "grad_norm": 1.6178196668624878,
      "learning_rate": 8.359375e-06,
      "loss": 0.3537,
      "step": 1820
    },
    {
      "epoch": 0.41842830882352944,
      "grad_norm": 1.512468934059143,
      "learning_rate": 8.363970588235294e-06,
      "loss": 0.3623,
      "step": 1821
    },
    {
      "epoch": 0.4186580882352941,
      "grad_norm": 1.7548222541809082,
      "learning_rate": 8.36856617647059e-06,
      "loss": 0.3629,
      "step": 1822
    },
    {
      "epoch": 0.4188878676470588,
      "grad_norm": 2.2388172149658203,
      "learning_rate": 8.373161764705883e-06,
      "loss": 0.3371,
      "step": 1823
    },
    {
      "epoch": 0.41911764705882354,
      "grad_norm": 1.3684643507003784,
      "learning_rate": 8.377757352941177e-06,
      "loss": 0.3137,
      "step": 1824
    },
    {
      "epoch": 0.41934742647058826,
      "grad_norm": 1.9410459995269775,
      "learning_rate": 8.382352941176472e-06,
      "loss": 0.3593,
      "step": 1825
    },
    {
      "epoch": 0.4195772058823529,
      "grad_norm": 1.4381568431854248,
      "learning_rate": 8.386948529411766e-06,
      "loss": 0.3842,
      "step": 1826
    },
    {
      "epoch": 0.41980698529411764,
      "grad_norm": 1.6456674337387085,
      "learning_rate": 8.391544117647059e-06,
      "loss": 0.3689,
      "step": 1827
    },
    {
      "epoch": 0.42003676470588236,
      "grad_norm": 1.4548693895339966,
      "learning_rate": 8.396139705882353e-06,
      "loss": 0.3939,
      "step": 1828
    },
    {
      "epoch": 0.4202665441176471,
      "grad_norm": 1.4751917123794556,
      "learning_rate": 8.400735294117647e-06,
      "loss": 0.3961,
      "step": 1829
    },
    {
      "epoch": 0.42049632352941174,
      "grad_norm": 1.5837198495864868,
      "learning_rate": 8.405330882352941e-06,
      "loss": 0.4271,
      "step": 1830
    },
    {
      "epoch": 0.42072610294117646,
      "grad_norm": 1.2985949516296387,
      "learning_rate": 8.409926470588236e-06,
      "loss": 0.3687,
      "step": 1831
    },
    {
      "epoch": 0.4209558823529412,
      "grad_norm": 2.147214651107788,
      "learning_rate": 8.41452205882353e-06,
      "loss": 0.3685,
      "step": 1832
    },
    {
      "epoch": 0.4211856617647059,
      "grad_norm": 1.5081615447998047,
      "learning_rate": 8.419117647058824e-06,
      "loss": 0.3241,
      "step": 1833
    },
    {
      "epoch": 0.42141544117647056,
      "grad_norm": 1.6820064783096313,
      "learning_rate": 8.423713235294119e-06,
      "loss": 0.361,
      "step": 1834
    },
    {
      "epoch": 0.4216452205882353,
      "grad_norm": 2.109973669052124,
      "learning_rate": 8.428308823529411e-06,
      "loss": 0.3803,
      "step": 1835
    },
    {
      "epoch": 0.421875,
      "grad_norm": 1.8020718097686768,
      "learning_rate": 8.432904411764706e-06,
      "loss": 0.3621,
      "step": 1836
    },
    {
      "epoch": 0.4221047794117647,
      "grad_norm": 1.4168461561203003,
      "learning_rate": 8.4375e-06,
      "loss": 0.3449,
      "step": 1837
    },
    {
      "epoch": 0.42233455882352944,
      "grad_norm": 1.6461838483810425,
      "learning_rate": 8.442095588235294e-06,
      "loss": 0.295,
      "step": 1838
    },
    {
      "epoch": 0.4225643382352941,
      "grad_norm": 2.449883222579956,
      "learning_rate": 8.446691176470589e-06,
      "loss": 0.3457,
      "step": 1839
    },
    {
      "epoch": 0.4227941176470588,
      "grad_norm": 1.6902104616165161,
      "learning_rate": 8.451286764705883e-06,
      "loss": 0.3607,
      "step": 1840
    },
    {
      "epoch": 0.42302389705882354,
      "grad_norm": 2.196117639541626,
      "learning_rate": 8.455882352941177e-06,
      "loss": 0.3729,
      "step": 1841
    },
    {
      "epoch": 0.42325367647058826,
      "grad_norm": 1.631534457206726,
      "learning_rate": 8.460477941176472e-06,
      "loss": 0.3222,
      "step": 1842
    },
    {
      "epoch": 0.4234834558823529,
      "grad_norm": 1.7382769584655762,
      "learning_rate": 8.465073529411766e-06,
      "loss": 0.3542,
      "step": 1843
    },
    {
      "epoch": 0.42371323529411764,
      "grad_norm": 1.8656736612319946,
      "learning_rate": 8.469669117647059e-06,
      "loss": 0.4015,
      "step": 1844
    },
    {
      "epoch": 0.42394301470588236,
      "grad_norm": 1.5107767581939697,
      "learning_rate": 8.474264705882353e-06,
      "loss": 0.3781,
      "step": 1845
    },
    {
      "epoch": 0.4241727941176471,
      "grad_norm": 1.5371731519699097,
      "learning_rate": 8.478860294117647e-06,
      "loss": 0.331,
      "step": 1846
    },
    {
      "epoch": 0.42440257352941174,
      "grad_norm": 1.8380699157714844,
      "learning_rate": 8.483455882352942e-06,
      "loss": 0.3214,
      "step": 1847
    },
    {
      "epoch": 0.42463235294117646,
      "grad_norm": 1.7486350536346436,
      "learning_rate": 8.488051470588236e-06,
      "loss": 0.3543,
      "step": 1848
    },
    {
      "epoch": 0.4248621323529412,
      "grad_norm": 1.4927611351013184,
      "learning_rate": 8.49264705882353e-06,
      "loss": 0.3572,
      "step": 1849
    },
    {
      "epoch": 0.4250919117647059,
      "grad_norm": 1.9324671030044556,
      "learning_rate": 8.497242647058825e-06,
      "loss": 0.3754,
      "step": 1850
    },
    {
      "epoch": 0.42532169117647056,
      "grad_norm": 1.725325584411621,
      "learning_rate": 8.501838235294119e-06,
      "loss": 0.3462,
      "step": 1851
    },
    {
      "epoch": 0.4255514705882353,
      "grad_norm": 1.8981062173843384,
      "learning_rate": 8.506433823529412e-06,
      "loss": 0.3085,
      "step": 1852
    },
    {
      "epoch": 0.42578125,
      "grad_norm": 1.8966450691223145,
      "learning_rate": 8.511029411764706e-06,
      "loss": 0.4002,
      "step": 1853
    },
    {
      "epoch": 0.4260110294117647,
      "grad_norm": 1.6218345165252686,
      "learning_rate": 8.515625e-06,
      "loss": 0.3509,
      "step": 1854
    },
    {
      "epoch": 0.42624080882352944,
      "grad_norm": 1.4463250637054443,
      "learning_rate": 8.520220588235295e-06,
      "loss": 0.3031,
      "step": 1855
    },
    {
      "epoch": 0.4264705882352941,
      "grad_norm": 1.484358787536621,
      "learning_rate": 8.524816176470589e-06,
      "loss": 0.338,
      "step": 1856
    },
    {
      "epoch": 0.4267003676470588,
      "grad_norm": 1.4428534507751465,
      "learning_rate": 8.529411764705883e-06,
      "loss": 0.3738,
      "step": 1857
    },
    {
      "epoch": 0.42693014705882354,
      "grad_norm": 1.7382965087890625,
      "learning_rate": 8.534007352941178e-06,
      "loss": 0.4346,
      "step": 1858
    },
    {
      "epoch": 0.42715992647058826,
      "grad_norm": 2.466723680496216,
      "learning_rate": 8.538602941176472e-06,
      "loss": 0.3678,
      "step": 1859
    },
    {
      "epoch": 0.4273897058823529,
      "grad_norm": 2.1147549152374268,
      "learning_rate": 8.543198529411766e-06,
      "loss": 0.3468,
      "step": 1860
    },
    {
      "epoch": 0.42761948529411764,
      "grad_norm": 1.6433978080749512,
      "learning_rate": 8.547794117647059e-06,
      "loss": 0.3112,
      "step": 1861
    },
    {
      "epoch": 0.42784926470588236,
      "grad_norm": 1.702472448348999,
      "learning_rate": 8.552389705882353e-06,
      "loss": 0.4094,
      "step": 1862
    },
    {
      "epoch": 0.4280790441176471,
      "grad_norm": 1.68217134475708,
      "learning_rate": 8.556985294117648e-06,
      "loss": 0.3658,
      "step": 1863
    },
    {
      "epoch": 0.42830882352941174,
      "grad_norm": 1.6574227809906006,
      "learning_rate": 8.561580882352942e-06,
      "loss": 0.3353,
      "step": 1864
    },
    {
      "epoch": 0.42853860294117646,
      "grad_norm": 2.032116413116455,
      "learning_rate": 8.566176470588236e-06,
      "loss": 0.3525,
      "step": 1865
    },
    {
      "epoch": 0.4287683823529412,
      "grad_norm": 1.5422836542129517,
      "learning_rate": 8.57077205882353e-06,
      "loss": 0.3963,
      "step": 1866
    },
    {
      "epoch": 0.4289981617647059,
      "grad_norm": 1.628855586051941,
      "learning_rate": 8.575367647058825e-06,
      "loss": 0.3841,
      "step": 1867
    },
    {
      "epoch": 0.42922794117647056,
      "grad_norm": 1.7748382091522217,
      "learning_rate": 8.57996323529412e-06,
      "loss": 0.3683,
      "step": 1868
    },
    {
      "epoch": 0.4294577205882353,
      "grad_norm": 1.8315778970718384,
      "learning_rate": 8.584558823529412e-06,
      "loss": 0.3276,
      "step": 1869
    },
    {
      "epoch": 0.4296875,
      "grad_norm": 1.6549595594406128,
      "learning_rate": 8.589154411764706e-06,
      "loss": 0.3507,
      "step": 1870
    },
    {
      "epoch": 0.4299172794117647,
      "grad_norm": 1.703050971031189,
      "learning_rate": 8.59375e-06,
      "loss": 0.2971,
      "step": 1871
    },
    {
      "epoch": 0.43014705882352944,
      "grad_norm": 1.8625969886779785,
      "learning_rate": 8.598345588235295e-06,
      "loss": 0.3465,
      "step": 1872
    },
    {
      "epoch": 0.4303768382352941,
      "grad_norm": 1.5956803560256958,
      "learning_rate": 8.60294117647059e-06,
      "loss": 0.3947,
      "step": 1873
    },
    {
      "epoch": 0.4306066176470588,
      "grad_norm": 1.6569799184799194,
      "learning_rate": 8.607536764705884e-06,
      "loss": 0.4002,
      "step": 1874
    },
    {
      "epoch": 0.43083639705882354,
      "grad_norm": 1.4683613777160645,
      "learning_rate": 8.612132352941178e-06,
      "loss": 0.3096,
      "step": 1875
    },
    {
      "epoch": 0.43106617647058826,
      "grad_norm": 1.8521456718444824,
      "learning_rate": 8.616727941176472e-06,
      "loss": 0.305,
      "step": 1876
    },
    {
      "epoch": 0.4312959558823529,
      "grad_norm": 1.7875615358352661,
      "learning_rate": 8.621323529411766e-06,
      "loss": 0.3761,
      "step": 1877
    },
    {
      "epoch": 0.43152573529411764,
      "grad_norm": 1.5529394149780273,
      "learning_rate": 8.625919117647059e-06,
      "loss": 0.3362,
      "step": 1878
    },
    {
      "epoch": 0.43175551470588236,
      "grad_norm": 1.4690412282943726,
      "learning_rate": 8.630514705882353e-06,
      "loss": 0.3125,
      "step": 1879
    },
    {
      "epoch": 0.4319852941176471,
      "grad_norm": 1.6519641876220703,
      "learning_rate": 8.635110294117648e-06,
      "loss": 0.3774,
      "step": 1880
    },
    {
      "epoch": 0.43221507352941174,
      "grad_norm": 1.6945213079452515,
      "learning_rate": 8.639705882352942e-06,
      "loss": 0.3832,
      "step": 1881
    },
    {
      "epoch": 0.43244485294117646,
      "grad_norm": 1.9647548198699951,
      "learning_rate": 8.644301470588235e-06,
      "loss": 0.344,
      "step": 1882
    },
    {
      "epoch": 0.4326746323529412,
      "grad_norm": 1.449894666671753,
      "learning_rate": 8.648897058823529e-06,
      "loss": 0.3604,
      "step": 1883
    },
    {
      "epoch": 0.4329044117647059,
      "grad_norm": 1.6529483795166016,
      "learning_rate": 8.653492647058825e-06,
      "loss": 0.2914,
      "step": 1884
    },
    {
      "epoch": 0.43313419117647056,
      "grad_norm": 1.6337714195251465,
      "learning_rate": 8.65808823529412e-06,
      "loss": 0.3325,
      "step": 1885
    },
    {
      "epoch": 0.4333639705882353,
      "grad_norm": 1.626769781112671,
      "learning_rate": 8.662683823529412e-06,
      "loss": 0.3445,
      "step": 1886
    },
    {
      "epoch": 0.43359375,
      "grad_norm": 1.799547553062439,
      "learning_rate": 8.667279411764706e-06,
      "loss": 0.3715,
      "step": 1887
    },
    {
      "epoch": 0.4338235294117647,
      "grad_norm": 1.8969762325286865,
      "learning_rate": 8.671875e-06,
      "loss": 0.4107,
      "step": 1888
    },
    {
      "epoch": 0.43405330882352944,
      "grad_norm": 1.255619764328003,
      "learning_rate": 8.676470588235295e-06,
      "loss": 0.3371,
      "step": 1889
    },
    {
      "epoch": 0.4342830882352941,
      "grad_norm": 1.6223026514053345,
      "learning_rate": 8.68106617647059e-06,
      "loss": 0.2769,
      "step": 1890
    },
    {
      "epoch": 0.4345128676470588,
      "grad_norm": 2.335503101348877,
      "learning_rate": 8.685661764705882e-06,
      "loss": 0.3449,
      "step": 1891
    },
    {
      "epoch": 0.43474264705882354,
      "grad_norm": 2.256028652191162,
      "learning_rate": 8.690257352941176e-06,
      "loss": 0.3372,
      "step": 1892
    },
    {
      "epoch": 0.43497242647058826,
      "grad_norm": 1.6429816484451294,
      "learning_rate": 8.69485294117647e-06,
      "loss": 0.3054,
      "step": 1893
    },
    {
      "epoch": 0.4352022058823529,
      "grad_norm": 1.5491433143615723,
      "learning_rate": 8.699448529411767e-06,
      "loss": 0.3274,
      "step": 1894
    },
    {
      "epoch": 0.43543198529411764,
      "grad_norm": 1.5966265201568604,
      "learning_rate": 8.70404411764706e-06,
      "loss": 0.3202,
      "step": 1895
    },
    {
      "epoch": 0.43566176470588236,
      "grad_norm": 1.5306293964385986,
      "learning_rate": 8.708639705882354e-06,
      "loss": 0.3209,
      "step": 1896
    },
    {
      "epoch": 0.4358915441176471,
      "grad_norm": 1.8647428750991821,
      "learning_rate": 8.713235294117648e-06,
      "loss": 0.3513,
      "step": 1897
    },
    {
      "epoch": 0.43612132352941174,
      "grad_norm": 1.4988844394683838,
      "learning_rate": 8.717830882352942e-06,
      "loss": 0.3065,
      "step": 1898
    },
    {
      "epoch": 0.43635110294117646,
      "grad_norm": 1.323822021484375,
      "learning_rate": 8.722426470588235e-06,
      "loss": 0.2685,
      "step": 1899
    },
    {
      "epoch": 0.4365808823529412,
      "grad_norm": 1.270090937614441,
      "learning_rate": 8.72702205882353e-06,
      "loss": 0.3145,
      "step": 1900
    },
    {
      "epoch": 0.4368106617647059,
      "grad_norm": 2.808438539505005,
      "learning_rate": 8.731617647058824e-06,
      "loss": 0.4448,
      "step": 1901
    },
    {
      "epoch": 0.43704044117647056,
      "grad_norm": 1.9299510717391968,
      "learning_rate": 8.736213235294118e-06,
      "loss": 0.3758,
      "step": 1902
    },
    {
      "epoch": 0.4372702205882353,
      "grad_norm": 2.0659894943237305,
      "learning_rate": 8.740808823529412e-06,
      "loss": 0.37,
      "step": 1903
    },
    {
      "epoch": 0.4375,
      "grad_norm": 1.8915594816207886,
      "learning_rate": 8.745404411764707e-06,
      "loss": 0.3213,
      "step": 1904
    },
    {
      "epoch": 0.4377297794117647,
      "grad_norm": 1.6067978143692017,
      "learning_rate": 8.750000000000001e-06,
      "loss": 0.2929,
      "step": 1905
    },
    {
      "epoch": 0.43795955882352944,
      "grad_norm": 1.7841483354568481,
      "learning_rate": 8.754595588235295e-06,
      "loss": 0.3599,
      "step": 1906
    },
    {
      "epoch": 0.4381893382352941,
      "grad_norm": 2.3205692768096924,
      "learning_rate": 8.75919117647059e-06,
      "loss": 0.3894,
      "step": 1907
    },
    {
      "epoch": 0.4384191176470588,
      "grad_norm": 1.6325407028198242,
      "learning_rate": 8.763786764705882e-06,
      "loss": 0.3503,
      "step": 1908
    },
    {
      "epoch": 0.43864889705882354,
      "grad_norm": 1.6504583358764648,
      "learning_rate": 8.768382352941177e-06,
      "loss": 0.3104,
      "step": 1909
    },
    {
      "epoch": 0.43887867647058826,
      "grad_norm": 2.009117841720581,
      "learning_rate": 8.772977941176471e-06,
      "loss": 0.2767,
      "step": 1910
    },
    {
      "epoch": 0.4391084558823529,
      "grad_norm": 1.8904727697372437,
      "learning_rate": 8.777573529411765e-06,
      "loss": 0.3174,
      "step": 1911
    },
    {
      "epoch": 0.43933823529411764,
      "grad_norm": 1.4769026041030884,
      "learning_rate": 8.78216911764706e-06,
      "loss": 0.3739,
      "step": 1912
    },
    {
      "epoch": 0.43956801470588236,
      "grad_norm": 2.0319697856903076,
      "learning_rate": 8.786764705882354e-06,
      "loss": 0.3629,
      "step": 1913
    },
    {
      "epoch": 0.4397977941176471,
      "grad_norm": 1.7067859172821045,
      "learning_rate": 8.791360294117648e-06,
      "loss": 0.3506,
      "step": 1914
    },
    {
      "epoch": 0.44002757352941174,
      "grad_norm": 1.9820444583892822,
      "learning_rate": 8.795955882352943e-06,
      "loss": 0.2896,
      "step": 1915
    },
    {
      "epoch": 0.44025735294117646,
      "grad_norm": 1.9197261333465576,
      "learning_rate": 8.800551470588235e-06,
      "loss": 0.3719,
      "step": 1916
    },
    {
      "epoch": 0.4404871323529412,
      "grad_norm": 1.9174538850784302,
      "learning_rate": 8.80514705882353e-06,
      "loss": 0.3764,
      "step": 1917
    },
    {
      "epoch": 0.4407169117647059,
      "grad_norm": 1.724123477935791,
      "learning_rate": 8.809742647058824e-06,
      "loss": 0.3188,
      "step": 1918
    },
    {
      "epoch": 0.44094669117647056,
      "grad_norm": 1.3821887969970703,
      "learning_rate": 8.814338235294118e-06,
      "loss": 0.2995,
      "step": 1919
    },
    {
      "epoch": 0.4411764705882353,
      "grad_norm": 1.8244119882583618,
      "learning_rate": 8.818933823529412e-06,
      "loss": 0.3642,
      "step": 1920
    },
    {
      "epoch": 0.44140625,
      "grad_norm": 1.5970368385314941,
      "learning_rate": 8.823529411764707e-06,
      "loss": 0.3021,
      "step": 1921
    },
    {
      "epoch": 0.4416360294117647,
      "grad_norm": 1.9337409734725952,
      "learning_rate": 8.828125000000001e-06,
      "loss": 0.4032,
      "step": 1922
    },
    {
      "epoch": 0.44186580882352944,
      "grad_norm": 1.5547279119491577,
      "learning_rate": 8.832720588235295e-06,
      "loss": 0.3902,
      "step": 1923
    },
    {
      "epoch": 0.4420955882352941,
      "grad_norm": 1.5683022737503052,
      "learning_rate": 8.83731617647059e-06,
      "loss": 0.3059,
      "step": 1924
    },
    {
      "epoch": 0.4423253676470588,
      "grad_norm": 1.8536567687988281,
      "learning_rate": 8.841911764705882e-06,
      "loss": 0.3325,
      "step": 1925
    },
    {
      "epoch": 0.44255514705882354,
      "grad_norm": 1.3881195783615112,
      "learning_rate": 8.846507352941177e-06,
      "loss": 0.3849,
      "step": 1926
    },
    {
      "epoch": 0.44278492647058826,
      "grad_norm": 1.7977763414382935,
      "learning_rate": 8.851102941176471e-06,
      "loss": 0.3477,
      "step": 1927
    },
    {
      "epoch": 0.4430147058823529,
      "grad_norm": 1.7271450757980347,
      "learning_rate": 8.855698529411765e-06,
      "loss": 0.3972,
      "step": 1928
    },
    {
      "epoch": 0.44324448529411764,
      "grad_norm": 2.003994941711426,
      "learning_rate": 8.86029411764706e-06,
      "loss": 0.2711,
      "step": 1929
    },
    {
      "epoch": 0.44347426470588236,
      "grad_norm": 1.9435230493545532,
      "learning_rate": 8.864889705882354e-06,
      "loss": 0.3304,
      "step": 1930
    },
    {
      "epoch": 0.4437040441176471,
      "grad_norm": 1.5466066598892212,
      "learning_rate": 8.869485294117648e-06,
      "loss": 0.388,
      "step": 1931
    },
    {
      "epoch": 0.44393382352941174,
      "grad_norm": 1.5202648639678955,
      "learning_rate": 8.874080882352943e-06,
      "loss": 0.3541,
      "step": 1932
    },
    {
      "epoch": 0.44416360294117646,
      "grad_norm": 1.7022724151611328,
      "learning_rate": 8.878676470588235e-06,
      "loss": 0.3117,
      "step": 1933
    },
    {
      "epoch": 0.4443933823529412,
      "grad_norm": 1.7989596128463745,
      "learning_rate": 8.88327205882353e-06,
      "loss": 0.3802,
      "step": 1934
    },
    {
      "epoch": 0.4446231617647059,
      "grad_norm": 1.6023350954055786,
      "learning_rate": 8.887867647058824e-06,
      "loss": 0.4652,
      "step": 1935
    },
    {
      "epoch": 0.44485294117647056,
      "grad_norm": 1.457127332687378,
      "learning_rate": 8.892463235294118e-06,
      "loss": 0.3629,
      "step": 1936
    },
    {
      "epoch": 0.4450827205882353,
      "grad_norm": 1.8296260833740234,
      "learning_rate": 8.897058823529413e-06,
      "loss": 0.3751,
      "step": 1937
    },
    {
      "epoch": 0.4453125,
      "grad_norm": 1.6689363718032837,
      "learning_rate": 8.901654411764707e-06,
      "loss": 0.3774,
      "step": 1938
    },
    {
      "epoch": 0.4455422794117647,
      "grad_norm": 1.7036771774291992,
      "learning_rate": 8.906250000000001e-06,
      "loss": 0.3128,
      "step": 1939
    },
    {
      "epoch": 0.44577205882352944,
      "grad_norm": 2.1709766387939453,
      "learning_rate": 8.910845588235296e-06,
      "loss": 0.3294,
      "step": 1940
    },
    {
      "epoch": 0.4460018382352941,
      "grad_norm": 1.355352759361267,
      "learning_rate": 8.91544117647059e-06,
      "loss": 0.3077,
      "step": 1941
    },
    {
      "epoch": 0.4462316176470588,
      "grad_norm": 1.5715841054916382,
      "learning_rate": 8.920036764705883e-06,
      "loss": 0.3889,
      "step": 1942
    },
    {
      "epoch": 0.44646139705882354,
      "grad_norm": 2.058528184890747,
      "learning_rate": 8.924632352941177e-06,
      "loss": 0.355,
      "step": 1943
    },
    {
      "epoch": 0.44669117647058826,
      "grad_norm": 1.863903284072876,
      "learning_rate": 8.929227941176471e-06,
      "loss": 0.3243,
      "step": 1944
    },
    {
      "epoch": 0.4469209558823529,
      "grad_norm": 1.6631990671157837,
      "learning_rate": 8.933823529411766e-06,
      "loss": 0.3862,
      "step": 1945
    },
    {
      "epoch": 0.44715073529411764,
      "grad_norm": 1.5539616346359253,
      "learning_rate": 8.93841911764706e-06,
      "loss": 0.3274,
      "step": 1946
    },
    {
      "epoch": 0.44738051470588236,
      "grad_norm": 1.437970757484436,
      "learning_rate": 8.943014705882354e-06,
      "loss": 0.3214,
      "step": 1947
    },
    {
      "epoch": 0.4476102941176471,
      "grad_norm": 2.185214042663574,
      "learning_rate": 8.947610294117649e-06,
      "loss": 0.3573,
      "step": 1948
    },
    {
      "epoch": 0.44784007352941174,
      "grad_norm": 2.0294456481933594,
      "learning_rate": 8.952205882352943e-06,
      "loss": 0.398,
      "step": 1949
    },
    {
      "epoch": 0.44806985294117646,
      "grad_norm": 1.695654034614563,
      "learning_rate": 8.956801470588236e-06,
      "loss": 0.3315,
      "step": 1950
    },
    {
      "epoch": 0.4482996323529412,
      "grad_norm": 1.3422578573226929,
      "learning_rate": 8.96139705882353e-06,
      "loss": 0.3218,
      "step": 1951
    },
    {
      "epoch": 0.4485294117647059,
      "grad_norm": 1.5578737258911133,
      "learning_rate": 8.965992647058824e-06,
      "loss": 0.3497,
      "step": 1952
    },
    {
      "epoch": 0.44875919117647056,
      "grad_norm": 1.2278845310211182,
      "learning_rate": 8.970588235294119e-06,
      "loss": 0.3333,
      "step": 1953
    },
    {
      "epoch": 0.4489889705882353,
      "grad_norm": 2.2034153938293457,
      "learning_rate": 8.975183823529411e-06,
      "loss": 0.3365,
      "step": 1954
    },
    {
      "epoch": 0.44921875,
      "grad_norm": 1.6113921403884888,
      "learning_rate": 8.979779411764706e-06,
      "loss": 0.3628,
      "step": 1955
    },
    {
      "epoch": 0.4494485294117647,
      "grad_norm": 1.5043567419052124,
      "learning_rate": 8.984375000000002e-06,
      "loss": 0.2784,
      "step": 1956
    },
    {
      "epoch": 0.44967830882352944,
      "grad_norm": 1.5582176446914673,
      "learning_rate": 8.988970588235296e-06,
      "loss": 0.3555,
      "step": 1957
    },
    {
      "epoch": 0.4499080882352941,
      "grad_norm": 1.7105647325515747,
      "learning_rate": 8.99356617647059e-06,
      "loss": 0.3712,
      "step": 1958
    },
    {
      "epoch": 0.4501378676470588,
      "grad_norm": 1.5413753986358643,
      "learning_rate": 8.998161764705883e-06,
      "loss": 0.3398,
      "step": 1959
    },
    {
      "epoch": 0.45036764705882354,
      "grad_norm": 1.6671698093414307,
      "learning_rate": 9.002757352941177e-06,
      "loss": 0.287,
      "step": 1960
    },
    {
      "epoch": 0.45059742647058826,
      "grad_norm": 1.7168654203414917,
      "learning_rate": 9.007352941176471e-06,
      "loss": 0.3624,
      "step": 1961
    },
    {
      "epoch": 0.4508272058823529,
      "grad_norm": 1.4141985177993774,
      "learning_rate": 9.011948529411766e-06,
      "loss": 0.3506,
      "step": 1962
    },
    {
      "epoch": 0.45105698529411764,
      "grad_norm": 1.9384673833847046,
      "learning_rate": 9.016544117647058e-06,
      "loss": 0.3827,
      "step": 1963
    },
    {
      "epoch": 0.45128676470588236,
      "grad_norm": 1.9731472730636597,
      "learning_rate": 9.021139705882353e-06,
      "loss": 0.4565,
      "step": 1964
    },
    {
      "epoch": 0.4515165441176471,
      "grad_norm": 1.8928864002227783,
      "learning_rate": 9.025735294117647e-06,
      "loss": 0.3096,
      "step": 1965
    },
    {
      "epoch": 0.45174632352941174,
      "grad_norm": 1.7925243377685547,
      "learning_rate": 9.030330882352943e-06,
      "loss": 0.3794,
      "step": 1966
    },
    {
      "epoch": 0.45197610294117646,
      "grad_norm": 1.542910099029541,
      "learning_rate": 9.034926470588236e-06,
      "loss": 0.3018,
      "step": 1967
    },
    {
      "epoch": 0.4522058823529412,
      "grad_norm": 2.2364745140075684,
      "learning_rate": 9.03952205882353e-06,
      "loss": 0.3908,
      "step": 1968
    },
    {
      "epoch": 0.4524356617647059,
      "grad_norm": 1.680428385734558,
      "learning_rate": 9.044117647058824e-06,
      "loss": 0.3812,
      "step": 1969
    },
    {
      "epoch": 0.45266544117647056,
      "grad_norm": 1.5791672468185425,
      "learning_rate": 9.048713235294119e-06,
      "loss": 0.3357,
      "step": 1970
    },
    {
      "epoch": 0.4528952205882353,
      "grad_norm": 1.3864023685455322,
      "learning_rate": 9.053308823529411e-06,
      "loss": 0.3158,
      "step": 1971
    },
    {
      "epoch": 0.453125,
      "grad_norm": 1.6013602018356323,
      "learning_rate": 9.057904411764706e-06,
      "loss": 0.3437,
      "step": 1972
    },
    {
      "epoch": 0.4533547794117647,
      "grad_norm": 1.5996452569961548,
      "learning_rate": 9.0625e-06,
      "loss": 0.27,
      "step": 1973
    },
    {
      "epoch": 0.45358455882352944,
      "grad_norm": 1.2819558382034302,
      "learning_rate": 9.067095588235294e-06,
      "loss": 0.2701,
      "step": 1974
    },
    {
      "epoch": 0.4538143382352941,
      "grad_norm": 1.9828397035598755,
      "learning_rate": 9.071691176470589e-06,
      "loss": 0.3908,
      "step": 1975
    },
    {
      "epoch": 0.4540441176470588,
      "grad_norm": 1.5850481986999512,
      "learning_rate": 9.076286764705883e-06,
      "loss": 0.3896,
      "step": 1976
    },
    {
      "epoch": 0.45427389705882354,
      "grad_norm": 1.4819328784942627,
      "learning_rate": 9.080882352941177e-06,
      "loss": 0.3309,
      "step": 1977
    },
    {
      "epoch": 0.45450367647058826,
      "grad_norm": 1.6315600872039795,
      "learning_rate": 9.085477941176472e-06,
      "loss": 0.3181,
      "step": 1978
    },
    {
      "epoch": 0.4547334558823529,
      "grad_norm": 1.5690248012542725,
      "learning_rate": 9.090073529411766e-06,
      "loss": 0.3683,
      "step": 1979
    },
    {
      "epoch": 0.45496323529411764,
      "grad_norm": 1.6955451965332031,
      "learning_rate": 9.094669117647059e-06,
      "loss": 0.345,
      "step": 1980
    },
    {
      "epoch": 0.45519301470588236,
      "grad_norm": 1.6097090244293213,
      "learning_rate": 9.099264705882353e-06,
      "loss": 0.2609,
      "step": 1981
    },
    {
      "epoch": 0.4554227941176471,
      "grad_norm": 1.9276657104492188,
      "learning_rate": 9.103860294117647e-06,
      "loss": 0.3898,
      "step": 1982
    },
    {
      "epoch": 0.45565257352941174,
      "grad_norm": 2.1336405277252197,
      "learning_rate": 9.108455882352942e-06,
      "loss": 0.3263,
      "step": 1983
    },
    {
      "epoch": 0.45588235294117646,
      "grad_norm": 1.7062755823135376,
      "learning_rate": 9.113051470588236e-06,
      "loss": 0.3618,
      "step": 1984
    },
    {
      "epoch": 0.4561121323529412,
      "grad_norm": 1.6495139598846436,
      "learning_rate": 9.11764705882353e-06,
      "loss": 0.3197,
      "step": 1985
    },
    {
      "epoch": 0.4563419117647059,
      "grad_norm": 1.627614140510559,
      "learning_rate": 9.122242647058825e-06,
      "loss": 0.2879,
      "step": 1986
    },
    {
      "epoch": 0.45657169117647056,
      "grad_norm": 1.5316524505615234,
      "learning_rate": 9.126838235294119e-06,
      "loss": 0.3034,
      "step": 1987
    },
    {
      "epoch": 0.4568014705882353,
      "grad_norm": 1.5855920314788818,
      "learning_rate": 9.131433823529412e-06,
      "loss": 0.3778,
      "step": 1988
    },
    {
      "epoch": 0.45703125,
      "grad_norm": 1.621646523475647,
      "learning_rate": 9.136029411764706e-06,
      "loss": 0.3502,
      "step": 1989
    },
    {
      "epoch": 0.4572610294117647,
      "grad_norm": 1.610316276550293,
      "learning_rate": 9.140625e-06,
      "loss": 0.3236,
      "step": 1990
    },
    {
      "epoch": 0.45749080882352944,
      "grad_norm": 1.6541521549224854,
      "learning_rate": 9.145220588235295e-06,
      "loss": 0.2928,
      "step": 1991
    },
    {
      "epoch": 0.4577205882352941,
      "grad_norm": 1.6127666234970093,
      "learning_rate": 9.149816176470589e-06,
      "loss": 0.291,
      "step": 1992
    },
    {
      "epoch": 0.4579503676470588,
      "grad_norm": 1.6212937831878662,
      "learning_rate": 9.154411764705883e-06,
      "loss": 0.3378,
      "step": 1993
    },
    {
      "epoch": 0.45818014705882354,
      "grad_norm": 1.4792410135269165,
      "learning_rate": 9.159007352941178e-06,
      "loss": 0.3095,
      "step": 1994
    },
    {
      "epoch": 0.45840992647058826,
      "grad_norm": 1.4931272268295288,
      "learning_rate": 9.163602941176472e-06,
      "loss": 0.33,
      "step": 1995
    },
    {
      "epoch": 0.4586397058823529,
      "grad_norm": 1.8855247497558594,
      "learning_rate": 9.168198529411766e-06,
      "loss": 0.3751,
      "step": 1996
    },
    {
      "epoch": 0.45886948529411764,
      "grad_norm": 1.586180567741394,
      "learning_rate": 9.172794117647059e-06,
      "loss": 0.336,
      "step": 1997
    },
    {
      "epoch": 0.45909926470588236,
      "grad_norm": 1.7302181720733643,
      "learning_rate": 9.177389705882353e-06,
      "loss": 0.3622,
      "step": 1998
    },
    {
      "epoch": 0.4593290441176471,
      "grad_norm": 1.4395946264266968,
      "learning_rate": 9.181985294117648e-06,
      "loss": 0.3816,
      "step": 1999
    },
    {
      "epoch": 0.45955882352941174,
      "grad_norm": 2.01061749458313,
      "learning_rate": 9.186580882352942e-06,
      "loss": 0.3066,
      "step": 2000
    },
    {
      "epoch": 0.45955882352941174,
      "eval_loss": 0.32276636362075806,
      "eval_runtime": 420.966,
      "eval_samples_per_second": 21.156,
      "eval_steps_per_second": 10.578,
      "step": 2000
    },
    {
      "epoch": 0.45978860294117646,
      "grad_norm": 1.749809741973877,
      "learning_rate": 9.191176470588236e-06,
      "loss": 0.327,
      "step": 2001
    },
    {
      "epoch": 0.4600183823529412,
      "grad_norm": 1.5249099731445312,
      "learning_rate": 9.19577205882353e-06,
      "loss": 0.4151,
      "step": 2002
    },
    {
      "epoch": 0.4602481617647059,
      "grad_norm": 1.9899953603744507,
      "learning_rate": 9.200367647058825e-06,
      "loss": 0.432,
      "step": 2003
    },
    {
      "epoch": 0.46047794117647056,
      "grad_norm": 1.5196490287780762,
      "learning_rate": 9.20496323529412e-06,
      "loss": 0.3032,
      "step": 2004
    },
    {
      "epoch": 0.4607077205882353,
      "grad_norm": 1.4219332933425903,
      "learning_rate": 9.209558823529412e-06,
      "loss": 0.3627,
      "step": 2005
    },
    {
      "epoch": 0.4609375,
      "grad_norm": 1.4839110374450684,
      "learning_rate": 9.214154411764706e-06,
      "loss": 0.3532,
      "step": 2006
    },
    {
      "epoch": 0.4611672794117647,
      "grad_norm": 1.6315863132476807,
      "learning_rate": 9.21875e-06,
      "loss": 0.3049,
      "step": 2007
    },
    {
      "epoch": 0.46139705882352944,
      "grad_norm": 1.9441288709640503,
      "learning_rate": 9.223345588235295e-06,
      "loss": 0.2661,
      "step": 2008
    },
    {
      "epoch": 0.4616268382352941,
      "grad_norm": 1.4007331132888794,
      "learning_rate": 9.227941176470589e-06,
      "loss": 0.3275,
      "step": 2009
    },
    {
      "epoch": 0.4618566176470588,
      "grad_norm": 1.7287538051605225,
      "learning_rate": 9.232536764705883e-06,
      "loss": 0.3418,
      "step": 2010
    },
    {
      "epoch": 0.46208639705882354,
      "grad_norm": 1.708172082901001,
      "learning_rate": 9.237132352941178e-06,
      "loss": 0.395,
      "step": 2011
    },
    {
      "epoch": 0.46231617647058826,
      "grad_norm": 1.753495693206787,
      "learning_rate": 9.241727941176472e-06,
      "loss": 0.321,
      "step": 2012
    },
    {
      "epoch": 0.4625459558823529,
      "grad_norm": 2.010347604751587,
      "learning_rate": 9.246323529411766e-06,
      "loss": 0.3173,
      "step": 2013
    },
    {
      "epoch": 0.46277573529411764,
      "grad_norm": 1.914222002029419,
      "learning_rate": 9.250919117647059e-06,
      "loss": 0.3879,
      "step": 2014
    },
    {
      "epoch": 0.46300551470588236,
      "grad_norm": 1.618393898010254,
      "learning_rate": 9.255514705882353e-06,
      "loss": 0.3082,
      "step": 2015
    },
    {
      "epoch": 0.4632352941176471,
      "grad_norm": 1.5183038711547852,
      "learning_rate": 9.260110294117648e-06,
      "loss": 0.3187,
      "step": 2016
    },
    {
      "epoch": 0.46346507352941174,
      "grad_norm": 1.5223037004470825,
      "learning_rate": 9.264705882352942e-06,
      "loss": 0.3091,
      "step": 2017
    },
    {
      "epoch": 0.46369485294117646,
      "grad_norm": 2.0420567989349365,
      "learning_rate": 9.269301470588236e-06,
      "loss": 0.3283,
      "step": 2018
    },
    {
      "epoch": 0.4639246323529412,
      "grad_norm": 1.7140631675720215,
      "learning_rate": 9.27389705882353e-06,
      "loss": 0.3674,
      "step": 2019
    },
    {
      "epoch": 0.4641544117647059,
      "grad_norm": 1.5260496139526367,
      "learning_rate": 9.278492647058825e-06,
      "loss": 0.2732,
      "step": 2020
    },
    {
      "epoch": 0.46438419117647056,
      "grad_norm": 1.6768543720245361,
      "learning_rate": 9.28308823529412e-06,
      "loss": 0.2934,
      "step": 2021
    },
    {
      "epoch": 0.4646139705882353,
      "grad_norm": 2.0530598163604736,
      "learning_rate": 9.287683823529412e-06,
      "loss": 0.3315,
      "step": 2022
    },
    {
      "epoch": 0.46484375,
      "grad_norm": 1.4970529079437256,
      "learning_rate": 9.292279411764706e-06,
      "loss": 0.3379,
      "step": 2023
    },
    {
      "epoch": 0.4650735294117647,
      "grad_norm": 1.588739275932312,
      "learning_rate": 9.296875e-06,
      "loss": 0.2855,
      "step": 2024
    },
    {
      "epoch": 0.46530330882352944,
      "grad_norm": 1.9457433223724365,
      "learning_rate": 9.301470588235295e-06,
      "loss": 0.3784,
      "step": 2025
    },
    {
      "epoch": 0.4655330882352941,
      "grad_norm": 1.5686004161834717,
      "learning_rate": 9.30606617647059e-06,
      "loss": 0.3283,
      "step": 2026
    },
    {
      "epoch": 0.4657628676470588,
      "grad_norm": 1.370578646659851,
      "learning_rate": 9.310661764705882e-06,
      "loss": 0.3004,
      "step": 2027
    },
    {
      "epoch": 0.46599264705882354,
      "grad_norm": 1.6239110231399536,
      "learning_rate": 9.315257352941178e-06,
      "loss": 0.2681,
      "step": 2028
    },
    {
      "epoch": 0.46622242647058826,
      "grad_norm": 1.9137433767318726,
      "learning_rate": 9.319852941176472e-06,
      "loss": 0.2999,
      "step": 2029
    },
    {
      "epoch": 0.4664522058823529,
      "grad_norm": 1.3720886707305908,
      "learning_rate": 9.324448529411767e-06,
      "loss": 0.3195,
      "step": 2030
    },
    {
      "epoch": 0.46668198529411764,
      "grad_norm": 1.7314082384109497,
      "learning_rate": 9.32904411764706e-06,
      "loss": 0.4201,
      "step": 2031
    },
    {
      "epoch": 0.46691176470588236,
      "grad_norm": 1.5854344367980957,
      "learning_rate": 9.333639705882354e-06,
      "loss": 0.2606,
      "step": 2032
    },
    {
      "epoch": 0.4671415441176471,
      "grad_norm": 1.679517388343811,
      "learning_rate": 9.338235294117648e-06,
      "loss": 0.2883,
      "step": 2033
    },
    {
      "epoch": 0.46737132352941174,
      "grad_norm": 1.7899912595748901,
      "learning_rate": 9.342830882352942e-06,
      "loss": 0.3605,
      "step": 2034
    },
    {
      "epoch": 0.46760110294117646,
      "grad_norm": 2.1435794830322266,
      "learning_rate": 9.347426470588235e-06,
      "loss": 0.3618,
      "step": 2035
    },
    {
      "epoch": 0.4678308823529412,
      "grad_norm": 1.7379673719406128,
      "learning_rate": 9.35202205882353e-06,
      "loss": 0.3222,
      "step": 2036
    },
    {
      "epoch": 0.4680606617647059,
      "grad_norm": 1.8982110023498535,
      "learning_rate": 9.356617647058824e-06,
      "loss": 0.3071,
      "step": 2037
    },
    {
      "epoch": 0.46829044117647056,
      "grad_norm": 1.5170944929122925,
      "learning_rate": 9.36121323529412e-06,
      "loss": 0.252,
      "step": 2038
    },
    {
      "epoch": 0.4685202205882353,
      "grad_norm": 1.8481699228286743,
      "learning_rate": 9.365808823529412e-06,
      "loss": 0.2948,
      "step": 2039
    },
    {
      "epoch": 0.46875,
      "grad_norm": 1.856737732887268,
      "learning_rate": 9.370404411764707e-06,
      "loss": 0.2905,
      "step": 2040
    },
    {
      "epoch": 0.4689797794117647,
      "grad_norm": 1.5566761493682861,
      "learning_rate": 9.375000000000001e-06,
      "loss": 0.2997,
      "step": 2041
    },
    {
      "epoch": 0.46920955882352944,
      "grad_norm": 1.3276519775390625,
      "learning_rate": 9.379595588235295e-06,
      "loss": 0.3609,
      "step": 2042
    },
    {
      "epoch": 0.4694393382352941,
      "grad_norm": 1.5488359928131104,
      "learning_rate": 9.38419117647059e-06,
      "loss": 0.3441,
      "step": 2043
    },
    {
      "epoch": 0.4696691176470588,
      "grad_norm": 1.55442214012146,
      "learning_rate": 9.388786764705882e-06,
      "loss": 0.3233,
      "step": 2044
    },
    {
      "epoch": 0.46989889705882354,
      "grad_norm": 1.7386292219161987,
      "learning_rate": 9.393382352941176e-06,
      "loss": 0.3374,
      "step": 2045
    },
    {
      "epoch": 0.47012867647058826,
      "grad_norm": 1.543092966079712,
      "learning_rate": 9.39797794117647e-06,
      "loss": 0.284,
      "step": 2046
    },
    {
      "epoch": 0.4703584558823529,
      "grad_norm": 2.1927359104156494,
      "learning_rate": 9.402573529411765e-06,
      "loss": 0.3171,
      "step": 2047
    },
    {
      "epoch": 0.47058823529411764,
      "grad_norm": 2.0204131603240967,
      "learning_rate": 9.40716911764706e-06,
      "loss": 0.3818,
      "step": 2048
    },
    {
      "epoch": 0.47081801470588236,
      "grad_norm": 1.5140568017959595,
      "learning_rate": 9.411764705882354e-06,
      "loss": 0.3112,
      "step": 2049
    },
    {
      "epoch": 0.4710477941176471,
      "grad_norm": 1.922666311264038,
      "learning_rate": 9.416360294117648e-06,
      "loss": 0.3016,
      "step": 2050
    },
    {
      "epoch": 0.47127757352941174,
      "grad_norm": 1.6732769012451172,
      "learning_rate": 9.420955882352942e-06,
      "loss": 0.2822,
      "step": 2051
    },
    {
      "epoch": 0.47150735294117646,
      "grad_norm": 1.597446322441101,
      "learning_rate": 9.425551470588235e-06,
      "loss": 0.4113,
      "step": 2052
    },
    {
      "epoch": 0.4717371323529412,
      "grad_norm": 1.7664673328399658,
      "learning_rate": 9.43014705882353e-06,
      "loss": 0.3213,
      "step": 2053
    },
    {
      "epoch": 0.4719669117647059,
      "grad_norm": 1.6185314655303955,
      "learning_rate": 9.434742647058824e-06,
      "loss": 0.3369,
      "step": 2054
    },
    {
      "epoch": 0.47219669117647056,
      "grad_norm": 1.8262380361557007,
      "learning_rate": 9.439338235294118e-06,
      "loss": 0.3219,
      "step": 2055
    },
    {
      "epoch": 0.4724264705882353,
      "grad_norm": 1.6433720588684082,
      "learning_rate": 9.443933823529412e-06,
      "loss": 0.2443,
      "step": 2056
    },
    {
      "epoch": 0.47265625,
      "grad_norm": 1.856757402420044,
      "learning_rate": 9.448529411764707e-06,
      "loss": 0.3436,
      "step": 2057
    },
    {
      "epoch": 0.4728860294117647,
      "grad_norm": 1.6036176681518555,
      "learning_rate": 9.453125000000001e-06,
      "loss": 0.3283,
      "step": 2058
    },
    {
      "epoch": 0.47311580882352944,
      "grad_norm": 1.841081976890564,
      "learning_rate": 9.457720588235295e-06,
      "loss": 0.3063,
      "step": 2059
    },
    {
      "epoch": 0.4733455882352941,
      "grad_norm": 1.4104124307632446,
      "learning_rate": 9.46231617647059e-06,
      "loss": 0.3349,
      "step": 2060
    },
    {
      "epoch": 0.4735753676470588,
      "grad_norm": 1.5898921489715576,
      "learning_rate": 9.466911764705882e-06,
      "loss": 0.3297,
      "step": 2061
    },
    {
      "epoch": 0.47380514705882354,
      "grad_norm": 1.7907246351242065,
      "learning_rate": 9.471507352941177e-06,
      "loss": 0.294,
      "step": 2062
    },
    {
      "epoch": 0.47403492647058826,
      "grad_norm": 1.6968073844909668,
      "learning_rate": 9.476102941176471e-06,
      "loss": 0.2873,
      "step": 2063
    },
    {
      "epoch": 0.4742647058823529,
      "grad_norm": 1.5132179260253906,
      "learning_rate": 9.480698529411765e-06,
      "loss": 0.2754,
      "step": 2064
    },
    {
      "epoch": 0.47449448529411764,
      "grad_norm": 1.5705435276031494,
      "learning_rate": 9.48529411764706e-06,
      "loss": 0.3018,
      "step": 2065
    },
    {
      "epoch": 0.47472426470588236,
      "grad_norm": 1.564730167388916,
      "learning_rate": 9.489889705882354e-06,
      "loss": 0.2764,
      "step": 2066
    },
    {
      "epoch": 0.4749540441176471,
      "grad_norm": 2.1314971446990967,
      "learning_rate": 9.494485294117648e-06,
      "loss": 0.3585,
      "step": 2067
    },
    {
      "epoch": 0.47518382352941174,
      "grad_norm": 1.766707181930542,
      "learning_rate": 9.499080882352943e-06,
      "loss": 0.3221,
      "step": 2068
    },
    {
      "epoch": 0.47541360294117646,
      "grad_norm": 1.6081981658935547,
      "learning_rate": 9.503676470588235e-06,
      "loss": 0.345,
      "step": 2069
    },
    {
      "epoch": 0.4756433823529412,
      "grad_norm": 1.7547026872634888,
      "learning_rate": 9.50827205882353e-06,
      "loss": 0.2823,
      "step": 2070
    },
    {
      "epoch": 0.4758731617647059,
      "grad_norm": 1.5049084424972534,
      "learning_rate": 9.512867647058824e-06,
      "loss": 0.3105,
      "step": 2071
    },
    {
      "epoch": 0.47610294117647056,
      "grad_norm": 1.756437063217163,
      "learning_rate": 9.517463235294118e-06,
      "loss": 0.3453,
      "step": 2072
    },
    {
      "epoch": 0.4763327205882353,
      "grad_norm": 1.7779687643051147,
      "learning_rate": 9.522058823529413e-06,
      "loss": 0.3765,
      "step": 2073
    },
    {
      "epoch": 0.4765625,
      "grad_norm": 1.806570291519165,
      "learning_rate": 9.526654411764707e-06,
      "loss": 0.297,
      "step": 2074
    },
    {
      "epoch": 0.4767922794117647,
      "grad_norm": 1.8549737930297852,
      "learning_rate": 9.531250000000001e-06,
      "loss": 0.2926,
      "step": 2075
    },
    {
      "epoch": 0.47702205882352944,
      "grad_norm": 1.4634168148040771,
      "learning_rate": 9.535845588235296e-06,
      "loss": 0.2931,
      "step": 2076
    },
    {
      "epoch": 0.4772518382352941,
      "grad_norm": 1.346726417541504,
      "learning_rate": 9.54044117647059e-06,
      "loss": 0.3084,
      "step": 2077
    },
    {
      "epoch": 0.4774816176470588,
      "grad_norm": 1.9285967350006104,
      "learning_rate": 9.545036764705883e-06,
      "loss": 0.2688,
      "step": 2078
    },
    {
      "epoch": 0.47771139705882354,
      "grad_norm": 1.9210537672042847,
      "learning_rate": 9.549632352941177e-06,
      "loss": 0.3269,
      "step": 2079
    },
    {
      "epoch": 0.47794117647058826,
      "grad_norm": 1.3127155303955078,
      "learning_rate": 9.554227941176471e-06,
      "loss": 0.2554,
      "step": 2080
    },
    {
      "epoch": 0.4781709558823529,
      "grad_norm": 1.7374151945114136,
      "learning_rate": 9.558823529411766e-06,
      "loss": 0.3148,
      "step": 2081
    },
    {
      "epoch": 0.47840073529411764,
      "grad_norm": 1.894939661026001,
      "learning_rate": 9.56341911764706e-06,
      "loss": 0.2775,
      "step": 2082
    },
    {
      "epoch": 0.47863051470588236,
      "grad_norm": 1.703145980834961,
      "learning_rate": 9.568014705882354e-06,
      "loss": 0.3131,
      "step": 2083
    },
    {
      "epoch": 0.4788602941176471,
      "grad_norm": 1.5096476078033447,
      "learning_rate": 9.572610294117649e-06,
      "loss": 0.3071,
      "step": 2084
    },
    {
      "epoch": 0.47909007352941174,
      "grad_norm": 1.8807024955749512,
      "learning_rate": 9.577205882352943e-06,
      "loss": 0.3886,
      "step": 2085
    },
    {
      "epoch": 0.47931985294117646,
      "grad_norm": 1.7242869138717651,
      "learning_rate": 9.581801470588236e-06,
      "loss": 0.3476,
      "step": 2086
    },
    {
      "epoch": 0.4795496323529412,
      "grad_norm": 1.5690985918045044,
      "learning_rate": 9.58639705882353e-06,
      "loss": 0.3588,
      "step": 2087
    },
    {
      "epoch": 0.4797794117647059,
      "grad_norm": 2.0134291648864746,
      "learning_rate": 9.590992647058824e-06,
      "loss": 0.362,
      "step": 2088
    },
    {
      "epoch": 0.48000919117647056,
      "grad_norm": 1.921799659729004,
      "learning_rate": 9.595588235294119e-06,
      "loss": 0.3796,
      "step": 2089
    },
    {
      "epoch": 0.4802389705882353,
      "grad_norm": 2.2066705226898193,
      "learning_rate": 9.600183823529413e-06,
      "loss": 0.4044,
      "step": 2090
    },
    {
      "epoch": 0.48046875,
      "grad_norm": 1.317794919013977,
      "learning_rate": 9.604779411764707e-06,
      "loss": 0.3497,
      "step": 2091
    },
    {
      "epoch": 0.4806985294117647,
      "grad_norm": 1.4846408367156982,
      "learning_rate": 9.609375000000001e-06,
      "loss": 0.2719,
      "step": 2092
    },
    {
      "epoch": 0.48092830882352944,
      "grad_norm": 1.7496734857559204,
      "learning_rate": 9.613970588235296e-06,
      "loss": 0.2897,
      "step": 2093
    },
    {
      "epoch": 0.4811580882352941,
      "grad_norm": 1.465268850326538,
      "learning_rate": 9.61856617647059e-06,
      "loss": 0.3184,
      "step": 2094
    },
    {
      "epoch": 0.4813878676470588,
      "grad_norm": 1.60343337059021,
      "learning_rate": 9.623161764705883e-06,
      "loss": 0.3472,
      "step": 2095
    },
    {
      "epoch": 0.48161764705882354,
      "grad_norm": 1.5438262224197388,
      "learning_rate": 9.627757352941177e-06,
      "loss": 0.3431,
      "step": 2096
    },
    {
      "epoch": 0.48184742647058826,
      "grad_norm": 1.3919776678085327,
      "learning_rate": 9.632352941176471e-06,
      "loss": 0.2276,
      "step": 2097
    },
    {
      "epoch": 0.4820772058823529,
      "grad_norm": 1.5394402742385864,
      "learning_rate": 9.636948529411766e-06,
      "loss": 0.2484,
      "step": 2098
    },
    {
      "epoch": 0.48230698529411764,
      "grad_norm": 1.7510672807693481,
      "learning_rate": 9.641544117647058e-06,
      "loss": 0.2796,
      "step": 2099
    },
    {
      "epoch": 0.48253676470588236,
      "grad_norm": 1.442308783531189,
      "learning_rate": 9.646139705882354e-06,
      "loss": 0.285,
      "step": 2100
    },
    {
      "epoch": 0.4827665441176471,
      "grad_norm": 1.826988697052002,
      "learning_rate": 9.650735294117649e-06,
      "loss": 0.323,
      "step": 2101
    },
    {
      "epoch": 0.48299632352941174,
      "grad_norm": 1.8189011812210083,
      "learning_rate": 9.655330882352943e-06,
      "loss": 0.3207,
      "step": 2102
    },
    {
      "epoch": 0.48322610294117646,
      "grad_norm": 1.6842148303985596,
      "learning_rate": 9.659926470588236e-06,
      "loss": 0.3442,
      "step": 2103
    },
    {
      "epoch": 0.4834558823529412,
      "grad_norm": 1.4776345491409302,
      "learning_rate": 9.66452205882353e-06,
      "loss": 0.2881,
      "step": 2104
    },
    {
      "epoch": 0.4836856617647059,
      "grad_norm": 1.3071340322494507,
      "learning_rate": 9.669117647058824e-06,
      "loss": 0.2705,
      "step": 2105
    },
    {
      "epoch": 0.48391544117647056,
      "grad_norm": 1.6221617460250854,
      "learning_rate": 9.673713235294119e-06,
      "loss": 0.3003,
      "step": 2106
    },
    {
      "epoch": 0.4841452205882353,
      "grad_norm": 1.5233858823776245,
      "learning_rate": 9.678308823529411e-06,
      "loss": 0.3046,
      "step": 2107
    },
    {
      "epoch": 0.484375,
      "grad_norm": 1.4489153623580933,
      "learning_rate": 9.682904411764706e-06,
      "loss": 0.2586,
      "step": 2108
    },
    {
      "epoch": 0.4846047794117647,
      "grad_norm": 2.007415294647217,
      "learning_rate": 9.6875e-06,
      "loss": 0.3162,
      "step": 2109
    },
    {
      "epoch": 0.48483455882352944,
      "grad_norm": 1.8253792524337769,
      "learning_rate": 9.692095588235294e-06,
      "loss": 0.3276,
      "step": 2110
    },
    {
      "epoch": 0.4850643382352941,
      "grad_norm": 1.7340214252471924,
      "learning_rate": 9.69669117647059e-06,
      "loss": 0.2252,
      "step": 2111
    },
    {
      "epoch": 0.4852941176470588,
      "grad_norm": 1.303561806678772,
      "learning_rate": 9.701286764705883e-06,
      "loss": 0.3215,
      "step": 2112
    },
    {
      "epoch": 0.48552389705882354,
      "grad_norm": 1.460868239402771,
      "learning_rate": 9.705882352941177e-06,
      "loss": 0.3068,
      "step": 2113
    },
    {
      "epoch": 0.48575367647058826,
      "grad_norm": 1.9681392908096313,
      "learning_rate": 9.710477941176472e-06,
      "loss": 0.3087,
      "step": 2114
    },
    {
      "epoch": 0.4859834558823529,
      "grad_norm": 1.5310263633728027,
      "learning_rate": 9.715073529411766e-06,
      "loss": 0.2225,
      "step": 2115
    },
    {
      "epoch": 0.48621323529411764,
      "grad_norm": 1.384673833847046,
      "learning_rate": 9.719669117647059e-06,
      "loss": 0.2714,
      "step": 2116
    },
    {
      "epoch": 0.48644301470588236,
      "grad_norm": 1.354842185974121,
      "learning_rate": 9.724264705882353e-06,
      "loss": 0.3086,
      "step": 2117
    },
    {
      "epoch": 0.4866727941176471,
      "grad_norm": 1.7213122844696045,
      "learning_rate": 9.728860294117647e-06,
      "loss": 0.3025,
      "step": 2118
    },
    {
      "epoch": 0.48690257352941174,
      "grad_norm": 1.7995175123214722,
      "learning_rate": 9.733455882352942e-06,
      "loss": 0.3375,
      "step": 2119
    },
    {
      "epoch": 0.48713235294117646,
      "grad_norm": 1.7825636863708496,
      "learning_rate": 9.738051470588236e-06,
      "loss": 0.2577,
      "step": 2120
    },
    {
      "epoch": 0.4873621323529412,
      "grad_norm": 1.6769704818725586,
      "learning_rate": 9.74264705882353e-06,
      "loss": 0.2776,
      "step": 2121
    },
    {
      "epoch": 0.4875919117647059,
      "grad_norm": 2.236018180847168,
      "learning_rate": 9.747242647058825e-06,
      "loss": 0.3509,
      "step": 2122
    },
    {
      "epoch": 0.48782169117647056,
      "grad_norm": 1.7779377698898315,
      "learning_rate": 9.751838235294119e-06,
      "loss": 0.3547,
      "step": 2123
    },
    {
      "epoch": 0.4880514705882353,
      "grad_norm": 1.6975892782211304,
      "learning_rate": 9.756433823529412e-06,
      "loss": 0.2977,
      "step": 2124
    },
    {
      "epoch": 0.48828125,
      "grad_norm": 1.412003755569458,
      "learning_rate": 9.761029411764706e-06,
      "loss": 0.3126,
      "step": 2125
    },
    {
      "epoch": 0.4885110294117647,
      "grad_norm": 1.6737143993377686,
      "learning_rate": 9.765625e-06,
      "loss": 0.2634,
      "step": 2126
    },
    {
      "epoch": 0.48874080882352944,
      "grad_norm": 1.4285261631011963,
      "learning_rate": 9.770220588235295e-06,
      "loss": 0.2702,
      "step": 2127
    },
    {
      "epoch": 0.4889705882352941,
      "grad_norm": 1.6937081813812256,
      "learning_rate": 9.774816176470589e-06,
      "loss": 0.3165,
      "step": 2128
    },
    {
      "epoch": 0.4892003676470588,
      "grad_norm": 1.7498058080673218,
      "learning_rate": 9.779411764705883e-06,
      "loss": 0.2813,
      "step": 2129
    },
    {
      "epoch": 0.48943014705882354,
      "grad_norm": 1.7853713035583496,
      "learning_rate": 9.784007352941178e-06,
      "loss": 0.2794,
      "step": 2130
    },
    {
      "epoch": 0.48965992647058826,
      "grad_norm": 1.7899984121322632,
      "learning_rate": 9.788602941176472e-06,
      "loss": 0.311,
      "step": 2131
    },
    {
      "epoch": 0.4898897058823529,
      "grad_norm": 1.6488271951675415,
      "learning_rate": 9.793198529411766e-06,
      "loss": 0.3539,
      "step": 2132
    },
    {
      "epoch": 0.49011948529411764,
      "grad_norm": 1.469415307044983,
      "learning_rate": 9.797794117647059e-06,
      "loss": 0.2766,
      "step": 2133
    },
    {
      "epoch": 0.49034926470588236,
      "grad_norm": 1.6300023794174194,
      "learning_rate": 9.802389705882353e-06,
      "loss": 0.3477,
      "step": 2134
    },
    {
      "epoch": 0.4905790441176471,
      "grad_norm": 1.8679805994033813,
      "learning_rate": 9.806985294117647e-06,
      "loss": 0.2669,
      "step": 2135
    },
    {
      "epoch": 0.49080882352941174,
      "grad_norm": 1.6226948499679565,
      "learning_rate": 9.811580882352942e-06,
      "loss": 0.3033,
      "step": 2136
    },
    {
      "epoch": 0.49103860294117646,
      "grad_norm": 1.3768107891082764,
      "learning_rate": 9.816176470588236e-06,
      "loss": 0.2661,
      "step": 2137
    },
    {
      "epoch": 0.4912683823529412,
      "grad_norm": 1.356113314628601,
      "learning_rate": 9.82077205882353e-06,
      "loss": 0.2864,
      "step": 2138
    },
    {
      "epoch": 0.4914981617647059,
      "grad_norm": 1.761418104171753,
      "learning_rate": 9.825367647058825e-06,
      "loss": 0.2463,
      "step": 2139
    },
    {
      "epoch": 0.49172794117647056,
      "grad_norm": 2.0976803302764893,
      "learning_rate": 9.829963235294119e-06,
      "loss": 0.2854,
      "step": 2140
    },
    {
      "epoch": 0.4919577205882353,
      "grad_norm": 1.7747387886047363,
      "learning_rate": 9.834558823529412e-06,
      "loss": 0.2404,
      "step": 2141
    },
    {
      "epoch": 0.4921875,
      "grad_norm": 2.3722195625305176,
      "learning_rate": 9.839154411764706e-06,
      "loss": 0.3299,
      "step": 2142
    },
    {
      "epoch": 0.4924172794117647,
      "grad_norm": 1.6711856126785278,
      "learning_rate": 9.84375e-06,
      "loss": 0.2787,
      "step": 2143
    },
    {
      "epoch": 0.49264705882352944,
      "grad_norm": 1.7531273365020752,
      "learning_rate": 9.848345588235295e-06,
      "loss": 0.2858,
      "step": 2144
    },
    {
      "epoch": 0.4928768382352941,
      "grad_norm": 1.505681037902832,
      "learning_rate": 9.852941176470589e-06,
      "loss": 0.3061,
      "step": 2145
    },
    {
      "epoch": 0.4931066176470588,
      "grad_norm": 1.7378253936767578,
      "learning_rate": 9.857536764705883e-06,
      "loss": 0.2683,
      "step": 2146
    },
    {
      "epoch": 0.49333639705882354,
      "grad_norm": 2.035578489303589,
      "learning_rate": 9.862132352941178e-06,
      "loss": 0.3124,
      "step": 2147
    },
    {
      "epoch": 0.49356617647058826,
      "grad_norm": 1.615267276763916,
      "learning_rate": 9.866727941176472e-06,
      "loss": 0.3014,
      "step": 2148
    },
    {
      "epoch": 0.4937959558823529,
      "grad_norm": 2.0308644771575928,
      "learning_rate": 9.871323529411766e-06,
      "loss": 0.2983,
      "step": 2149
    },
    {
      "epoch": 0.49402573529411764,
      "grad_norm": 1.4538826942443848,
      "learning_rate": 9.875919117647059e-06,
      "loss": 0.3395,
      "step": 2150
    },
    {
      "epoch": 0.49425551470588236,
      "grad_norm": 1.7877283096313477,
      "learning_rate": 9.880514705882353e-06,
      "loss": 0.3459,
      "step": 2151
    },
    {
      "epoch": 0.4944852941176471,
      "grad_norm": 1.9036824703216553,
      "learning_rate": 9.885110294117648e-06,
      "loss": 0.2532,
      "step": 2152
    },
    {
      "epoch": 0.49471507352941174,
      "grad_norm": 1.6528321504592896,
      "learning_rate": 9.889705882352942e-06,
      "loss": 0.3488,
      "step": 2153
    },
    {
      "epoch": 0.49494485294117646,
      "grad_norm": 1.6862140893936157,
      "learning_rate": 9.894301470588236e-06,
      "loss": 0.3308,
      "step": 2154
    },
    {
      "epoch": 0.4951746323529412,
      "grad_norm": 1.52009117603302,
      "learning_rate": 9.89889705882353e-06,
      "loss": 0.3238,
      "step": 2155
    },
    {
      "epoch": 0.4954044117647059,
      "grad_norm": 1.5623434782028198,
      "learning_rate": 9.903492647058825e-06,
      "loss": 0.3044,
      "step": 2156
    },
    {
      "epoch": 0.49563419117647056,
      "grad_norm": 1.5943117141723633,
      "learning_rate": 9.90808823529412e-06,
      "loss": 0.2889,
      "step": 2157
    },
    {
      "epoch": 0.4958639705882353,
      "grad_norm": 1.495349407196045,
      "learning_rate": 9.912683823529412e-06,
      "loss": 0.2461,
      "step": 2158
    },
    {
      "epoch": 0.49609375,
      "grad_norm": 1.4122905731201172,
      "learning_rate": 9.917279411764706e-06,
      "loss": 0.3105,
      "step": 2159
    },
    {
      "epoch": 0.4963235294117647,
      "grad_norm": 1.4584236145019531,
      "learning_rate": 9.921875e-06,
      "loss": 0.2876,
      "step": 2160
    },
    {
      "epoch": 0.49655330882352944,
      "grad_norm": 1.4327462911605835,
      "learning_rate": 9.926470588235295e-06,
      "loss": 0.3117,
      "step": 2161
    },
    {
      "epoch": 0.4967830882352941,
      "grad_norm": 1.9628814458847046,
      "learning_rate": 9.93106617647059e-06,
      "loss": 0.3267,
      "step": 2162
    },
    {
      "epoch": 0.4970128676470588,
      "grad_norm": 2.180107593536377,
      "learning_rate": 9.935661764705884e-06,
      "loss": 0.299,
      "step": 2163
    },
    {
      "epoch": 0.49724264705882354,
      "grad_norm": 1.5736738443374634,
      "learning_rate": 9.940257352941178e-06,
      "loss": 0.3131,
      "step": 2164
    },
    {
      "epoch": 0.49747242647058826,
      "grad_norm": 1.7404069900512695,
      "learning_rate": 9.944852941176472e-06,
      "loss": 0.3326,
      "step": 2165
    },
    {
      "epoch": 0.4977022058823529,
      "grad_norm": 1.426373839378357,
      "learning_rate": 9.949448529411767e-06,
      "loss": 0.3137,
      "step": 2166
    },
    {
      "epoch": 0.49793198529411764,
      "grad_norm": 2.4148435592651367,
      "learning_rate": 9.95404411764706e-06,
      "loss": 0.2814,
      "step": 2167
    },
    {
      "epoch": 0.49816176470588236,
      "grad_norm": 1.72091805934906,
      "learning_rate": 9.958639705882354e-06,
      "loss": 0.3153,
      "step": 2168
    },
    {
      "epoch": 0.4983915441176471,
      "grad_norm": 1.846122145652771,
      "learning_rate": 9.963235294117648e-06,
      "loss": 0.2578,
      "step": 2169
    },
    {
      "epoch": 0.49862132352941174,
      "grad_norm": 1.6974859237670898,
      "learning_rate": 9.967830882352942e-06,
      "loss": 0.2718,
      "step": 2170
    },
    {
      "epoch": 0.49885110294117646,
      "grad_norm": 1.4192712306976318,
      "learning_rate": 9.972426470588235e-06,
      "loss": 0.2971,
      "step": 2171
    },
    {
      "epoch": 0.4990808823529412,
      "grad_norm": 1.387095332145691,
      "learning_rate": 9.977022058823531e-06,
      "loss": 0.2691,
      "step": 2172
    },
    {
      "epoch": 0.4993106617647059,
      "grad_norm": 1.3215605020523071,
      "learning_rate": 9.981617647058825e-06,
      "loss": 0.2346,
      "step": 2173
    },
    {
      "epoch": 0.49954044117647056,
      "grad_norm": 1.7340724468231201,
      "learning_rate": 9.98621323529412e-06,
      "loss": 0.3118,
      "step": 2174
    },
    {
      "epoch": 0.4997702205882353,
      "grad_norm": 1.6721807718276978,
      "learning_rate": 9.990808823529412e-06,
      "loss": 0.3337,
      "step": 2175
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.01967453956604,
      "learning_rate": 9.995404411764706e-06,
      "loss": 0.299,
      "step": 2176
    },
    {
      "epoch": 0.5002297794117647,
      "grad_norm": 2.0952279567718506,
      "learning_rate": 1e-05,
      "loss": 0.3184,
      "step": 2177
    },
    {
      "epoch": 0.5004595588235294,
      "grad_norm": 2.0231404304504395,
      "learning_rate": 9.999489379084969e-06,
      "loss": 0.3426,
      "step": 2178
    },
    {
      "epoch": 0.5006893382352942,
      "grad_norm": 1.395497441291809,
      "learning_rate": 9.998978758169935e-06,
      "loss": 0.2355,
      "step": 2179
    },
    {
      "epoch": 0.5009191176470589,
      "grad_norm": 1.654529094696045,
      "learning_rate": 9.998468137254903e-06,
      "loss": 0.2563,
      "step": 2180
    },
    {
      "epoch": 0.5011488970588235,
      "grad_norm": 1.5796464681625366,
      "learning_rate": 9.99795751633987e-06,
      "loss": 0.2668,
      "step": 2181
    },
    {
      "epoch": 0.5013786764705882,
      "grad_norm": 1.7344112396240234,
      "learning_rate": 9.997446895424837e-06,
      "loss": 0.3291,
      "step": 2182
    },
    {
      "epoch": 0.5016084558823529,
      "grad_norm": 1.813571572303772,
      "learning_rate": 9.996936274509805e-06,
      "loss": 0.2707,
      "step": 2183
    },
    {
      "epoch": 0.5018382352941176,
      "grad_norm": 1.6851003170013428,
      "learning_rate": 9.996425653594772e-06,
      "loss": 0.2721,
      "step": 2184
    },
    {
      "epoch": 0.5020680147058824,
      "grad_norm": 1.6453843116760254,
      "learning_rate": 9.995915032679739e-06,
      "loss": 0.278,
      "step": 2185
    },
    {
      "epoch": 0.5022977941176471,
      "grad_norm": 1.3365899324417114,
      "learning_rate": 9.995404411764706e-06,
      "loss": 0.2292,
      "step": 2186
    },
    {
      "epoch": 0.5025275735294118,
      "grad_norm": 1.4692922830581665,
      "learning_rate": 9.994893790849673e-06,
      "loss": 0.2498,
      "step": 2187
    },
    {
      "epoch": 0.5027573529411765,
      "grad_norm": 1.6026276350021362,
      "learning_rate": 9.994383169934642e-06,
      "loss": 0.3011,
      "step": 2188
    },
    {
      "epoch": 0.5029871323529411,
      "grad_norm": 1.6140673160552979,
      "learning_rate": 9.993872549019608e-06,
      "loss": 0.3148,
      "step": 2189
    },
    {
      "epoch": 0.5032169117647058,
      "grad_norm": 1.4053094387054443,
      "learning_rate": 9.993361928104576e-06,
      "loss": 0.2988,
      "step": 2190
    },
    {
      "epoch": 0.5034466911764706,
      "grad_norm": 1.6954030990600586,
      "learning_rate": 9.992851307189542e-06,
      "loss": 0.218,
      "step": 2191
    },
    {
      "epoch": 0.5036764705882353,
      "grad_norm": 1.7695201635360718,
      "learning_rate": 9.99234068627451e-06,
      "loss": 0.3769,
      "step": 2192
    },
    {
      "epoch": 0.50390625,
      "grad_norm": 1.8631105422973633,
      "learning_rate": 9.991830065359478e-06,
      "loss": 0.3499,
      "step": 2193
    },
    {
      "epoch": 0.5041360294117647,
      "grad_norm": 1.9285061359405518,
      "learning_rate": 9.991319444444444e-06,
      "loss": 0.3228,
      "step": 2194
    },
    {
      "epoch": 0.5043658088235294,
      "grad_norm": 1.835985541343689,
      "learning_rate": 9.990808823529412e-06,
      "loss": 0.3314,
      "step": 2195
    },
    {
      "epoch": 0.5045955882352942,
      "grad_norm": 1.338973879814148,
      "learning_rate": 9.99029820261438e-06,
      "loss": 0.2382,
      "step": 2196
    },
    {
      "epoch": 0.5048253676470589,
      "grad_norm": 1.8011131286621094,
      "learning_rate": 9.989787581699348e-06,
      "loss": 0.2758,
      "step": 2197
    },
    {
      "epoch": 0.5050551470588235,
      "grad_norm": 2.2082016468048096,
      "learning_rate": 9.989276960784314e-06,
      "loss": 0.2632,
      "step": 2198
    },
    {
      "epoch": 0.5052849264705882,
      "grad_norm": 1.6118547916412354,
      "learning_rate": 9.988766339869282e-06,
      "loss": 0.2884,
      "step": 2199
    },
    {
      "epoch": 0.5055147058823529,
      "grad_norm": 1.4245072603225708,
      "learning_rate": 9.98825571895425e-06,
      "loss": 0.2942,
      "step": 2200
    },
    {
      "epoch": 0.5057444852941176,
      "grad_norm": 1.4001152515411377,
      "learning_rate": 9.987745098039216e-06,
      "loss": 0.2717,
      "step": 2201
    },
    {
      "epoch": 0.5059742647058824,
      "grad_norm": 1.7628228664398193,
      "learning_rate": 9.987234477124184e-06,
      "loss": 0.265,
      "step": 2202
    },
    {
      "epoch": 0.5062040441176471,
      "grad_norm": 1.6669490337371826,
      "learning_rate": 9.98672385620915e-06,
      "loss": 0.3198,
      "step": 2203
    },
    {
      "epoch": 0.5064338235294118,
      "grad_norm": 2.039616584777832,
      "learning_rate": 9.98621323529412e-06,
      "loss": 0.2777,
      "step": 2204
    },
    {
      "epoch": 0.5066636029411765,
      "grad_norm": 1.498040795326233,
      "learning_rate": 9.985702614379086e-06,
      "loss": 0.2434,
      "step": 2205
    },
    {
      "epoch": 0.5068933823529411,
      "grad_norm": 1.6303945779800415,
      "learning_rate": 9.985191993464054e-06,
      "loss": 0.3118,
      "step": 2206
    },
    {
      "epoch": 0.5071231617647058,
      "grad_norm": 1.885778784751892,
      "learning_rate": 9.98468137254902e-06,
      "loss": 0.3691,
      "step": 2207
    },
    {
      "epoch": 0.5073529411764706,
      "grad_norm": 2.0163886547088623,
      "learning_rate": 9.984170751633988e-06,
      "loss": 0.3443,
      "step": 2208
    },
    {
      "epoch": 0.5075827205882353,
      "grad_norm": 1.7831916809082031,
      "learning_rate": 9.983660130718955e-06,
      "loss": 0.2967,
      "step": 2209
    },
    {
      "epoch": 0.5078125,
      "grad_norm": 1.724448800086975,
      "learning_rate": 9.983149509803922e-06,
      "loss": 0.2915,
      "step": 2210
    },
    {
      "epoch": 0.5080422794117647,
      "grad_norm": 1.7824372053146362,
      "learning_rate": 9.98263888888889e-06,
      "loss": 0.3126,
      "step": 2211
    },
    {
      "epoch": 0.5082720588235294,
      "grad_norm": 2.0036849975585938,
      "learning_rate": 9.982128267973857e-06,
      "loss": 0.3148,
      "step": 2212
    },
    {
      "epoch": 0.5085018382352942,
      "grad_norm": 1.7379158735275269,
      "learning_rate": 9.981617647058825e-06,
      "loss": 0.2788,
      "step": 2213
    },
    {
      "epoch": 0.5087316176470589,
      "grad_norm": 1.7219051122665405,
      "learning_rate": 9.981107026143791e-06,
      "loss": 0.2614,
      "step": 2214
    },
    {
      "epoch": 0.5089613970588235,
      "grad_norm": 1.409630537033081,
      "learning_rate": 9.98059640522876e-06,
      "loss": 0.3028,
      "step": 2215
    },
    {
      "epoch": 0.5091911764705882,
      "grad_norm": 1.733567237854004,
      "learning_rate": 9.980085784313727e-06,
      "loss": 0.1954,
      "step": 2216
    },
    {
      "epoch": 0.5094209558823529,
      "grad_norm": 1.7074779272079468,
      "learning_rate": 9.979575163398693e-06,
      "loss": 0.2966,
      "step": 2217
    },
    {
      "epoch": 0.5096507352941176,
      "grad_norm": 1.4492419958114624,
      "learning_rate": 9.979064542483661e-06,
      "loss": 0.2956,
      "step": 2218
    },
    {
      "epoch": 0.5098805147058824,
      "grad_norm": 1.872588038444519,
      "learning_rate": 9.978553921568627e-06,
      "loss": 0.3238,
      "step": 2219
    },
    {
      "epoch": 0.5101102941176471,
      "grad_norm": 1.844228744506836,
      "learning_rate": 9.978043300653595e-06,
      "loss": 0.2698,
      "step": 2220
    },
    {
      "epoch": 0.5103400735294118,
      "grad_norm": 1.7682275772094727,
      "learning_rate": 9.977532679738563e-06,
      "loss": 0.2123,
      "step": 2221
    },
    {
      "epoch": 0.5105698529411765,
      "grad_norm": 2.1113944053649902,
      "learning_rate": 9.977022058823531e-06,
      "loss": 0.3254,
      "step": 2222
    },
    {
      "epoch": 0.5107996323529411,
      "grad_norm": 1.3635919094085693,
      "learning_rate": 9.976511437908497e-06,
      "loss": 0.2885,
      "step": 2223
    },
    {
      "epoch": 0.5110294117647058,
      "grad_norm": 1.593670129776001,
      "learning_rate": 9.976000816993465e-06,
      "loss": 0.2876,
      "step": 2224
    },
    {
      "epoch": 0.5112591911764706,
      "grad_norm": 2.145542621612549,
      "learning_rate": 9.975490196078433e-06,
      "loss": 0.2637,
      "step": 2225
    },
    {
      "epoch": 0.5114889705882353,
      "grad_norm": 1.5124868154525757,
      "learning_rate": 9.974979575163399e-06,
      "loss": 0.2766,
      "step": 2226
    },
    {
      "epoch": 0.51171875,
      "grad_norm": 1.7793309688568115,
      "learning_rate": 9.974468954248367e-06,
      "loss": 0.2263,
      "step": 2227
    },
    {
      "epoch": 0.5119485294117647,
      "grad_norm": 1.9740813970565796,
      "learning_rate": 9.973958333333335e-06,
      "loss": 0.2928,
      "step": 2228
    },
    {
      "epoch": 0.5121783088235294,
      "grad_norm": 1.4885871410369873,
      "learning_rate": 9.9734477124183e-06,
      "loss": 0.2486,
      "step": 2229
    },
    {
      "epoch": 0.5124080882352942,
      "grad_norm": 1.6649330854415894,
      "learning_rate": 9.972937091503269e-06,
      "loss": 0.2705,
      "step": 2230
    },
    {
      "epoch": 0.5126378676470589,
      "grad_norm": 1.5382874011993408,
      "learning_rate": 9.972426470588235e-06,
      "loss": 0.2329,
      "step": 2231
    },
    {
      "epoch": 0.5128676470588235,
      "grad_norm": 1.8354958295822144,
      "learning_rate": 9.971915849673204e-06,
      "loss": 0.289,
      "step": 2232
    },
    {
      "epoch": 0.5130974264705882,
      "grad_norm": 1.7035222053527832,
      "learning_rate": 9.97140522875817e-06,
      "loss": 0.2873,
      "step": 2233
    },
    {
      "epoch": 0.5133272058823529,
      "grad_norm": 1.999540090560913,
      "learning_rate": 9.970894607843138e-06,
      "loss": 0.2849,
      "step": 2234
    },
    {
      "epoch": 0.5135569852941176,
      "grad_norm": 1.6294339895248413,
      "learning_rate": 9.970383986928105e-06,
      "loss": 0.2947,
      "step": 2235
    },
    {
      "epoch": 0.5137867647058824,
      "grad_norm": 1.8110295534133911,
      "learning_rate": 9.969873366013072e-06,
      "loss": 0.305,
      "step": 2236
    },
    {
      "epoch": 0.5140165441176471,
      "grad_norm": 1.821232795715332,
      "learning_rate": 9.96936274509804e-06,
      "loss": 0.3211,
      "step": 2237
    },
    {
      "epoch": 0.5142463235294118,
      "grad_norm": 1.800527572631836,
      "learning_rate": 9.968852124183006e-06,
      "loss": 0.2342,
      "step": 2238
    },
    {
      "epoch": 0.5144761029411765,
      "grad_norm": 1.9830728769302368,
      "learning_rate": 9.968341503267974e-06,
      "loss": 0.3535,
      "step": 2239
    },
    {
      "epoch": 0.5147058823529411,
      "grad_norm": 1.592718243598938,
      "learning_rate": 9.967830882352942e-06,
      "loss": 0.2079,
      "step": 2240
    },
    {
      "epoch": 0.5149356617647058,
      "grad_norm": 1.6629910469055176,
      "learning_rate": 9.96732026143791e-06,
      "loss": 0.2697,
      "step": 2241
    },
    {
      "epoch": 0.5151654411764706,
      "grad_norm": 2.4063074588775635,
      "learning_rate": 9.966809640522876e-06,
      "loss": 0.3092,
      "step": 2242
    },
    {
      "epoch": 0.5153952205882353,
      "grad_norm": 1.6535955667495728,
      "learning_rate": 9.966299019607844e-06,
      "loss": 0.2391,
      "step": 2243
    },
    {
      "epoch": 0.515625,
      "grad_norm": 2.094829559326172,
      "learning_rate": 9.965788398692812e-06,
      "loss": 0.2738,
      "step": 2244
    },
    {
      "epoch": 0.5158547794117647,
      "grad_norm": 1.8418630361557007,
      "learning_rate": 9.965277777777778e-06,
      "loss": 0.2516,
      "step": 2245
    },
    {
      "epoch": 0.5160845588235294,
      "grad_norm": 1.7262324094772339,
      "learning_rate": 9.964767156862746e-06,
      "loss": 0.2426,
      "step": 2246
    },
    {
      "epoch": 0.5163143382352942,
      "grad_norm": 1.556793212890625,
      "learning_rate": 9.964256535947712e-06,
      "loss": 0.2905,
      "step": 2247
    },
    {
      "epoch": 0.5165441176470589,
      "grad_norm": 1.903579592704773,
      "learning_rate": 9.963745915032682e-06,
      "loss": 0.2767,
      "step": 2248
    },
    {
      "epoch": 0.5167738970588235,
      "grad_norm": 1.5685948133468628,
      "learning_rate": 9.963235294117648e-06,
      "loss": 0.2102,
      "step": 2249
    },
    {
      "epoch": 0.5170036764705882,
      "grad_norm": 1.2648380994796753,
      "learning_rate": 9.962724673202616e-06,
      "loss": 0.2322,
      "step": 2250
    },
    {
      "epoch": 0.5172334558823529,
      "grad_norm": 2.0702662467956543,
      "learning_rate": 9.962214052287582e-06,
      "loss": 0.3191,
      "step": 2251
    },
    {
      "epoch": 0.5174632352941176,
      "grad_norm": 1.7542155981063843,
      "learning_rate": 9.96170343137255e-06,
      "loss": 0.2808,
      "step": 2252
    },
    {
      "epoch": 0.5176930147058824,
      "grad_norm": 2.617175817489624,
      "learning_rate": 9.961192810457518e-06,
      "loss": 0.3349,
      "step": 2253
    },
    {
      "epoch": 0.5179227941176471,
      "grad_norm": 1.647476315498352,
      "learning_rate": 9.960682189542484e-06,
      "loss": 0.259,
      "step": 2254
    },
    {
      "epoch": 0.5181525735294118,
      "grad_norm": 1.6924539804458618,
      "learning_rate": 9.960171568627452e-06,
      "loss": 0.2764,
      "step": 2255
    },
    {
      "epoch": 0.5183823529411765,
      "grad_norm": 1.5157198905944824,
      "learning_rate": 9.95966094771242e-06,
      "loss": 0.2644,
      "step": 2256
    },
    {
      "epoch": 0.5186121323529411,
      "grad_norm": 1.7259318828582764,
      "learning_rate": 9.959150326797387e-06,
      "loss": 0.2406,
      "step": 2257
    },
    {
      "epoch": 0.5188419117647058,
      "grad_norm": 2.4836082458496094,
      "learning_rate": 9.958639705882354e-06,
      "loss": 0.3837,
      "step": 2258
    },
    {
      "epoch": 0.5190716911764706,
      "grad_norm": 1.8820618391036987,
      "learning_rate": 9.958129084967321e-06,
      "loss": 0.258,
      "step": 2259
    },
    {
      "epoch": 0.5193014705882353,
      "grad_norm": 1.9239271879196167,
      "learning_rate": 9.95761846405229e-06,
      "loss": 0.3037,
      "step": 2260
    },
    {
      "epoch": 0.51953125,
      "grad_norm": 1.718639612197876,
      "learning_rate": 9.957107843137255e-06,
      "loss": 0.2669,
      "step": 2261
    },
    {
      "epoch": 0.5197610294117647,
      "grad_norm": 2.162663459777832,
      "learning_rate": 9.956597222222223e-06,
      "loss": 0.3295,
      "step": 2262
    },
    {
      "epoch": 0.5199908088235294,
      "grad_norm": 1.3461694717407227,
      "learning_rate": 9.95608660130719e-06,
      "loss": 0.2707,
      "step": 2263
    },
    {
      "epoch": 0.5202205882352942,
      "grad_norm": 1.4434833526611328,
      "learning_rate": 9.955575980392157e-06,
      "loss": 0.3075,
      "step": 2264
    },
    {
      "epoch": 0.5204503676470589,
      "grad_norm": 1.8066240549087524,
      "learning_rate": 9.955065359477125e-06,
      "loss": 0.3586,
      "step": 2265
    },
    {
      "epoch": 0.5206801470588235,
      "grad_norm": 2.314923048019409,
      "learning_rate": 9.954554738562091e-06,
      "loss": 0.2385,
      "step": 2266
    },
    {
      "epoch": 0.5209099264705882,
      "grad_norm": 1.9774096012115479,
      "learning_rate": 9.95404411764706e-06,
      "loss": 0.2876,
      "step": 2267
    },
    {
      "epoch": 0.5211397058823529,
      "grad_norm": 1.550783634185791,
      "learning_rate": 9.953533496732027e-06,
      "loss": 0.2508,
      "step": 2268
    },
    {
      "epoch": 0.5213694852941176,
      "grad_norm": 1.6692811250686646,
      "learning_rate": 9.953022875816995e-06,
      "loss": 0.2812,
      "step": 2269
    },
    {
      "epoch": 0.5215992647058824,
      "grad_norm": 1.8044822216033936,
      "learning_rate": 9.952512254901961e-06,
      "loss": 0.2299,
      "step": 2270
    },
    {
      "epoch": 0.5218290441176471,
      "grad_norm": 1.6279469728469849,
      "learning_rate": 9.952001633986929e-06,
      "loss": 0.2414,
      "step": 2271
    },
    {
      "epoch": 0.5220588235294118,
      "grad_norm": 1.5544159412384033,
      "learning_rate": 9.951491013071897e-06,
      "loss": 0.2627,
      "step": 2272
    },
    {
      "epoch": 0.5222886029411765,
      "grad_norm": 1.621254801750183,
      "learning_rate": 9.950980392156863e-06,
      "loss": 0.2634,
      "step": 2273
    },
    {
      "epoch": 0.5225183823529411,
      "grad_norm": 1.3859875202178955,
      "learning_rate": 9.950469771241831e-06,
      "loss": 0.2346,
      "step": 2274
    },
    {
      "epoch": 0.5227481617647058,
      "grad_norm": 1.9107227325439453,
      "learning_rate": 9.949959150326797e-06,
      "loss": 0.3823,
      "step": 2275
    },
    {
      "epoch": 0.5229779411764706,
      "grad_norm": 1.7888535261154175,
      "learning_rate": 9.949448529411767e-06,
      "loss": 0.2754,
      "step": 2276
    },
    {
      "epoch": 0.5232077205882353,
      "grad_norm": 1.7805081605911255,
      "learning_rate": 9.948937908496733e-06,
      "loss": 0.2554,
      "step": 2277
    },
    {
      "epoch": 0.5234375,
      "grad_norm": 1.9328943490982056,
      "learning_rate": 9.9484272875817e-06,
      "loss": 0.3085,
      "step": 2278
    },
    {
      "epoch": 0.5236672794117647,
      "grad_norm": 2.019085168838501,
      "learning_rate": 9.947916666666667e-06,
      "loss": 0.2975,
      "step": 2279
    },
    {
      "epoch": 0.5238970588235294,
      "grad_norm": 1.7135909795761108,
      "learning_rate": 9.947406045751635e-06,
      "loss": 0.2938,
      "step": 2280
    },
    {
      "epoch": 0.5241268382352942,
      "grad_norm": 1.348557710647583,
      "learning_rate": 9.946895424836603e-06,
      "loss": 0.2498,
      "step": 2281
    },
    {
      "epoch": 0.5243566176470589,
      "grad_norm": 1.150131344795227,
      "learning_rate": 9.946384803921569e-06,
      "loss": 0.2303,
      "step": 2282
    },
    {
      "epoch": 0.5245863970588235,
      "grad_norm": 1.931786298751831,
      "learning_rate": 9.945874183006537e-06,
      "loss": 0.3504,
      "step": 2283
    },
    {
      "epoch": 0.5248161764705882,
      "grad_norm": 1.7331712245941162,
      "learning_rate": 9.945363562091504e-06,
      "loss": 0.274,
      "step": 2284
    },
    {
      "epoch": 0.5250459558823529,
      "grad_norm": 1.7241283655166626,
      "learning_rate": 9.944852941176472e-06,
      "loss": 0.2458,
      "step": 2285
    },
    {
      "epoch": 0.5252757352941176,
      "grad_norm": 1.8353750705718994,
      "learning_rate": 9.944342320261438e-06,
      "loss": 0.3172,
      "step": 2286
    },
    {
      "epoch": 0.5255055147058824,
      "grad_norm": 1.5018872022628784,
      "learning_rate": 9.943831699346406e-06,
      "loss": 0.263,
      "step": 2287
    },
    {
      "epoch": 0.5257352941176471,
      "grad_norm": 1.5197813510894775,
      "learning_rate": 9.943321078431374e-06,
      "loss": 0.327,
      "step": 2288
    },
    {
      "epoch": 0.5259650735294118,
      "grad_norm": 1.7404038906097412,
      "learning_rate": 9.94281045751634e-06,
      "loss": 0.2208,
      "step": 2289
    },
    {
      "epoch": 0.5261948529411765,
      "grad_norm": 1.6622519493103027,
      "learning_rate": 9.942299836601308e-06,
      "loss": 0.2096,
      "step": 2290
    },
    {
      "epoch": 0.5264246323529411,
      "grad_norm": 1.915299892425537,
      "learning_rate": 9.941789215686274e-06,
      "loss": 0.2955,
      "step": 2291
    },
    {
      "epoch": 0.5266544117647058,
      "grad_norm": 1.7408201694488525,
      "learning_rate": 9.941278594771244e-06,
      "loss": 0.3071,
      "step": 2292
    },
    {
      "epoch": 0.5268841911764706,
      "grad_norm": 1.4355922937393188,
      "learning_rate": 9.94076797385621e-06,
      "loss": 0.2801,
      "step": 2293
    },
    {
      "epoch": 0.5271139705882353,
      "grad_norm": 1.3939732313156128,
      "learning_rate": 9.940257352941178e-06,
      "loss": 0.2649,
      "step": 2294
    },
    {
      "epoch": 0.52734375,
      "grad_norm": 1.5808606147766113,
      "learning_rate": 9.939746732026144e-06,
      "loss": 0.3028,
      "step": 2295
    },
    {
      "epoch": 0.5275735294117647,
      "grad_norm": 1.9092656373977661,
      "learning_rate": 9.939236111111112e-06,
      "loss": 0.2434,
      "step": 2296
    },
    {
      "epoch": 0.5278033088235294,
      "grad_norm": 1.9387210607528687,
      "learning_rate": 9.93872549019608e-06,
      "loss": 0.3624,
      "step": 2297
    },
    {
      "epoch": 0.5280330882352942,
      "grad_norm": 1.831290602684021,
      "learning_rate": 9.938214869281046e-06,
      "loss": 0.2913,
      "step": 2298
    },
    {
      "epoch": 0.5282628676470589,
      "grad_norm": 1.3980826139450073,
      "learning_rate": 9.937704248366014e-06,
      "loss": 0.2363,
      "step": 2299
    },
    {
      "epoch": 0.5284926470588235,
      "grad_norm": 1.7011668682098389,
      "learning_rate": 9.937193627450982e-06,
      "loss": 0.2337,
      "step": 2300
    },
    {
      "epoch": 0.5287224264705882,
      "grad_norm": 1.6764757633209229,
      "learning_rate": 9.93668300653595e-06,
      "loss": 0.2398,
      "step": 2301
    },
    {
      "epoch": 0.5289522058823529,
      "grad_norm": 1.2622274160385132,
      "learning_rate": 9.936172385620916e-06,
      "loss": 0.2296,
      "step": 2302
    },
    {
      "epoch": 0.5291819852941176,
      "grad_norm": 1.5928682088851929,
      "learning_rate": 9.935661764705884e-06,
      "loss": 0.3098,
      "step": 2303
    },
    {
      "epoch": 0.5294117647058824,
      "grad_norm": 1.8013596534729004,
      "learning_rate": 9.935151143790851e-06,
      "loss": 0.2983,
      "step": 2304
    },
    {
      "epoch": 0.5296415441176471,
      "grad_norm": 2.005115270614624,
      "learning_rate": 9.934640522875818e-06,
      "loss": 0.3076,
      "step": 2305
    },
    {
      "epoch": 0.5298713235294118,
      "grad_norm": 1.725211501121521,
      "learning_rate": 9.934129901960785e-06,
      "loss": 0.2584,
      "step": 2306
    },
    {
      "epoch": 0.5301011029411765,
      "grad_norm": 1.6853716373443604,
      "learning_rate": 9.933619281045752e-06,
      "loss": 0.2388,
      "step": 2307
    },
    {
      "epoch": 0.5303308823529411,
      "grad_norm": 1.766597867012024,
      "learning_rate": 9.93310866013072e-06,
      "loss": 0.2785,
      "step": 2308
    },
    {
      "epoch": 0.5305606617647058,
      "grad_norm": 1.7066800594329834,
      "learning_rate": 9.932598039215687e-06,
      "loss": 0.2926,
      "step": 2309
    },
    {
      "epoch": 0.5307904411764706,
      "grad_norm": 2.1936709880828857,
      "learning_rate": 9.932087418300654e-06,
      "loss": 0.2432,
      "step": 2310
    },
    {
      "epoch": 0.5310202205882353,
      "grad_norm": 1.568679928779602,
      "learning_rate": 9.931576797385621e-06,
      "loss": 0.2343,
      "step": 2311
    },
    {
      "epoch": 0.53125,
      "grad_norm": 1.8895131349563599,
      "learning_rate": 9.93106617647059e-06,
      "loss": 0.2751,
      "step": 2312
    },
    {
      "epoch": 0.5314797794117647,
      "grad_norm": 1.9084564447402954,
      "learning_rate": 9.930555555555557e-06,
      "loss": 0.263,
      "step": 2313
    },
    {
      "epoch": 0.5317095588235294,
      "grad_norm": 1.6404907703399658,
      "learning_rate": 9.930044934640523e-06,
      "loss": 0.2865,
      "step": 2314
    },
    {
      "epoch": 0.5319393382352942,
      "grad_norm": 1.5426288843154907,
      "learning_rate": 9.929534313725491e-06,
      "loss": 0.2658,
      "step": 2315
    },
    {
      "epoch": 0.5321691176470589,
      "grad_norm": 2.093719959259033,
      "learning_rate": 9.929023692810459e-06,
      "loss": 0.2663,
      "step": 2316
    },
    {
      "epoch": 0.5323988970588235,
      "grad_norm": 1.7842999696731567,
      "learning_rate": 9.928513071895425e-06,
      "loss": 0.3472,
      "step": 2317
    },
    {
      "epoch": 0.5326286764705882,
      "grad_norm": 1.5333534479141235,
      "learning_rate": 9.928002450980393e-06,
      "loss": 0.2976,
      "step": 2318
    },
    {
      "epoch": 0.5328584558823529,
      "grad_norm": 1.4272360801696777,
      "learning_rate": 9.92749183006536e-06,
      "loss": 0.3022,
      "step": 2319
    },
    {
      "epoch": 0.5330882352941176,
      "grad_norm": 1.723246693611145,
      "learning_rate": 9.926981209150329e-06,
      "loss": 0.2311,
      "step": 2320
    },
    {
      "epoch": 0.5333180147058824,
      "grad_norm": 1.668016791343689,
      "learning_rate": 9.926470588235295e-06,
      "loss": 0.2844,
      "step": 2321
    },
    {
      "epoch": 0.5335477941176471,
      "grad_norm": 2.0740420818328857,
      "learning_rate": 9.925959967320263e-06,
      "loss": 0.2639,
      "step": 2322
    },
    {
      "epoch": 0.5337775735294118,
      "grad_norm": 1.5508265495300293,
      "learning_rate": 9.925449346405229e-06,
      "loss": 0.3241,
      "step": 2323
    },
    {
      "epoch": 0.5340073529411765,
      "grad_norm": 1.6920123100280762,
      "learning_rate": 9.924938725490197e-06,
      "loss": 0.2638,
      "step": 2324
    },
    {
      "epoch": 0.5342371323529411,
      "grad_norm": 1.5601495504379272,
      "learning_rate": 9.924428104575165e-06,
      "loss": 0.2553,
      "step": 2325
    },
    {
      "epoch": 0.5344669117647058,
      "grad_norm": 1.7756037712097168,
      "learning_rate": 9.923917483660131e-06,
      "loss": 0.2737,
      "step": 2326
    },
    {
      "epoch": 0.5346966911764706,
      "grad_norm": 1.692198395729065,
      "learning_rate": 9.923406862745099e-06,
      "loss": 0.2582,
      "step": 2327
    },
    {
      "epoch": 0.5349264705882353,
      "grad_norm": 1.4027446508407593,
      "learning_rate": 9.922896241830067e-06,
      "loss": 0.2071,
      "step": 2328
    },
    {
      "epoch": 0.53515625,
      "grad_norm": 1.5446059703826904,
      "learning_rate": 9.922385620915034e-06,
      "loss": 0.2727,
      "step": 2329
    },
    {
      "epoch": 0.5353860294117647,
      "grad_norm": 1.3872052431106567,
      "learning_rate": 9.921875e-06,
      "loss": 0.2298,
      "step": 2330
    },
    {
      "epoch": 0.5356158088235294,
      "grad_norm": 1.4449352025985718,
      "learning_rate": 9.921364379084968e-06,
      "loss": 0.2323,
      "step": 2331
    },
    {
      "epoch": 0.5358455882352942,
      "grad_norm": 1.277430534362793,
      "learning_rate": 9.920853758169935e-06,
      "loss": 0.2283,
      "step": 2332
    },
    {
      "epoch": 0.5360753676470589,
      "grad_norm": 1.6686127185821533,
      "learning_rate": 9.920343137254903e-06,
      "loss": 0.2987,
      "step": 2333
    },
    {
      "epoch": 0.5363051470588235,
      "grad_norm": 1.731314778327942,
      "learning_rate": 9.91983251633987e-06,
      "loss": 0.3373,
      "step": 2334
    },
    {
      "epoch": 0.5365349264705882,
      "grad_norm": 1.837289810180664,
      "learning_rate": 9.919321895424837e-06,
      "loss": 0.2596,
      "step": 2335
    },
    {
      "epoch": 0.5367647058823529,
      "grad_norm": 1.7544022798538208,
      "learning_rate": 9.918811274509804e-06,
      "loss": 0.2859,
      "step": 2336
    },
    {
      "epoch": 0.5369944852941176,
      "grad_norm": 1.5936263799667358,
      "learning_rate": 9.918300653594772e-06,
      "loss": 0.2668,
      "step": 2337
    },
    {
      "epoch": 0.5372242647058824,
      "grad_norm": 1.7740172147750854,
      "learning_rate": 9.91779003267974e-06,
      "loss": 0.2836,
      "step": 2338
    },
    {
      "epoch": 0.5374540441176471,
      "grad_norm": 2.0472216606140137,
      "learning_rate": 9.917279411764706e-06,
      "loss": 0.2711,
      "step": 2339
    },
    {
      "epoch": 0.5376838235294118,
      "grad_norm": 1.5757309198379517,
      "learning_rate": 9.916768790849674e-06,
      "loss": 0.2148,
      "step": 2340
    },
    {
      "epoch": 0.5379136029411765,
      "grad_norm": 1.9136433601379395,
      "learning_rate": 9.916258169934642e-06,
      "loss": 0.2466,
      "step": 2341
    },
    {
      "epoch": 0.5381433823529411,
      "grad_norm": 1.442154049873352,
      "learning_rate": 9.915747549019608e-06,
      "loss": 0.2185,
      "step": 2342
    },
    {
      "epoch": 0.5383731617647058,
      "grad_norm": 1.99030601978302,
      "learning_rate": 9.915236928104576e-06,
      "loss": 0.2687,
      "step": 2343
    },
    {
      "epoch": 0.5386029411764706,
      "grad_norm": 1.6582393646240234,
      "learning_rate": 9.914726307189542e-06,
      "loss": 0.3407,
      "step": 2344
    },
    {
      "epoch": 0.5388327205882353,
      "grad_norm": 2.287741184234619,
      "learning_rate": 9.914215686274512e-06,
      "loss": 0.3547,
      "step": 2345
    },
    {
      "epoch": 0.5390625,
      "grad_norm": 1.6325576305389404,
      "learning_rate": 9.913705065359478e-06,
      "loss": 0.3538,
      "step": 2346
    },
    {
      "epoch": 0.5392922794117647,
      "grad_norm": 1.6530060768127441,
      "learning_rate": 9.913194444444446e-06,
      "loss": 0.2557,
      "step": 2347
    },
    {
      "epoch": 0.5395220588235294,
      "grad_norm": 1.5836100578308105,
      "learning_rate": 9.912683823529412e-06,
      "loss": 0.3002,
      "step": 2348
    },
    {
      "epoch": 0.5397518382352942,
      "grad_norm": 1.2877370119094849,
      "learning_rate": 9.91217320261438e-06,
      "loss": 0.2255,
      "step": 2349
    },
    {
      "epoch": 0.5399816176470589,
      "grad_norm": 2.0715088844299316,
      "learning_rate": 9.911662581699348e-06,
      "loss": 0.3292,
      "step": 2350
    },
    {
      "epoch": 0.5402113970588235,
      "grad_norm": 1.3985615968704224,
      "learning_rate": 9.911151960784314e-06,
      "loss": 0.2499,
      "step": 2351
    },
    {
      "epoch": 0.5404411764705882,
      "grad_norm": 1.3054004907608032,
      "learning_rate": 9.910641339869282e-06,
      "loss": 0.2478,
      "step": 2352
    },
    {
      "epoch": 0.5406709558823529,
      "grad_norm": 1.936136245727539,
      "learning_rate": 9.91013071895425e-06,
      "loss": 0.3737,
      "step": 2353
    },
    {
      "epoch": 0.5409007352941176,
      "grad_norm": 2.040034055709839,
      "learning_rate": 9.909620098039216e-06,
      "loss": 0.2831,
      "step": 2354
    },
    {
      "epoch": 0.5411305147058824,
      "grad_norm": 1.5485970973968506,
      "learning_rate": 9.909109477124184e-06,
      "loss": 0.2858,
      "step": 2355
    },
    {
      "epoch": 0.5413602941176471,
      "grad_norm": 1.9302464723587036,
      "learning_rate": 9.908598856209151e-06,
      "loss": 0.2823,
      "step": 2356
    },
    {
      "epoch": 0.5415900735294118,
      "grad_norm": 1.552367925643921,
      "learning_rate": 9.90808823529412e-06,
      "loss": 0.2562,
      "step": 2357
    },
    {
      "epoch": 0.5418198529411765,
      "grad_norm": 1.452507495880127,
      "learning_rate": 9.907577614379085e-06,
      "loss": 0.2531,
      "step": 2358
    },
    {
      "epoch": 0.5420496323529411,
      "grad_norm": 1.58048415184021,
      "learning_rate": 9.907066993464053e-06,
      "loss": 0.2236,
      "step": 2359
    },
    {
      "epoch": 0.5422794117647058,
      "grad_norm": 2.3793909549713135,
      "learning_rate": 9.90655637254902e-06,
      "loss": 0.2555,
      "step": 2360
    },
    {
      "epoch": 0.5425091911764706,
      "grad_norm": 2.1980793476104736,
      "learning_rate": 9.906045751633987e-06,
      "loss": 0.2732,
      "step": 2361
    },
    {
      "epoch": 0.5427389705882353,
      "grad_norm": 1.5249272584915161,
      "learning_rate": 9.905535130718955e-06,
      "loss": 0.2842,
      "step": 2362
    },
    {
      "epoch": 0.54296875,
      "grad_norm": 1.4714690446853638,
      "learning_rate": 9.905024509803921e-06,
      "loss": 0.2483,
      "step": 2363
    },
    {
      "epoch": 0.5431985294117647,
      "grad_norm": 2.3657848834991455,
      "learning_rate": 9.90451388888889e-06,
      "loss": 0.3006,
      "step": 2364
    },
    {
      "epoch": 0.5434283088235294,
      "grad_norm": 1.9495333433151245,
      "learning_rate": 9.904003267973857e-06,
      "loss": 0.3069,
      "step": 2365
    },
    {
      "epoch": 0.5436580882352942,
      "grad_norm": 1.6917970180511475,
      "learning_rate": 9.903492647058825e-06,
      "loss": 0.1813,
      "step": 2366
    },
    {
      "epoch": 0.5438878676470589,
      "grad_norm": 1.362792730331421,
      "learning_rate": 9.902982026143791e-06,
      "loss": 0.2641,
      "step": 2367
    },
    {
      "epoch": 0.5441176470588235,
      "grad_norm": 1.5582094192504883,
      "learning_rate": 9.902471405228759e-06,
      "loss": 0.217,
      "step": 2368
    },
    {
      "epoch": 0.5443474264705882,
      "grad_norm": 1.8719593286514282,
      "learning_rate": 9.901960784313727e-06,
      "loss": 0.2572,
      "step": 2369
    },
    {
      "epoch": 0.5445772058823529,
      "grad_norm": 2.158479928970337,
      "learning_rate": 9.901450163398693e-06,
      "loss": 0.332,
      "step": 2370
    },
    {
      "epoch": 0.5448069852941176,
      "grad_norm": 1.6943602561950684,
      "learning_rate": 9.900939542483661e-06,
      "loss": 0.2923,
      "step": 2371
    },
    {
      "epoch": 0.5450367647058824,
      "grad_norm": 1.433519721031189,
      "learning_rate": 9.900428921568627e-06,
      "loss": 0.2933,
      "step": 2372
    },
    {
      "epoch": 0.5452665441176471,
      "grad_norm": 1.9392833709716797,
      "learning_rate": 9.899918300653597e-06,
      "loss": 0.3136,
      "step": 2373
    },
    {
      "epoch": 0.5454963235294118,
      "grad_norm": 1.529255747795105,
      "learning_rate": 9.899407679738563e-06,
      "loss": 0.2718,
      "step": 2374
    },
    {
      "epoch": 0.5457261029411765,
      "grad_norm": 1.7289347648620605,
      "learning_rate": 9.89889705882353e-06,
      "loss": 0.2393,
      "step": 2375
    },
    {
      "epoch": 0.5459558823529411,
      "grad_norm": 1.6161874532699585,
      "learning_rate": 9.898386437908497e-06,
      "loss": 0.2879,
      "step": 2376
    },
    {
      "epoch": 0.5461856617647058,
      "grad_norm": 1.7542613744735718,
      "learning_rate": 9.897875816993465e-06,
      "loss": 0.2857,
      "step": 2377
    },
    {
      "epoch": 0.5464154411764706,
      "grad_norm": 1.414829969406128,
      "learning_rate": 9.897365196078433e-06,
      "loss": 0.1948,
      "step": 2378
    },
    {
      "epoch": 0.5466452205882353,
      "grad_norm": 2.1303787231445312,
      "learning_rate": 9.896854575163399e-06,
      "loss": 0.3077,
      "step": 2379
    },
    {
      "epoch": 0.546875,
      "grad_norm": 2.1733596324920654,
      "learning_rate": 9.896343954248367e-06,
      "loss": 0.2479,
      "step": 2380
    },
    {
      "epoch": 0.5471047794117647,
      "grad_norm": 1.7315397262573242,
      "learning_rate": 9.895833333333334e-06,
      "loss": 0.2456,
      "step": 2381
    },
    {
      "epoch": 0.5473345588235294,
      "grad_norm": 1.3410202264785767,
      "learning_rate": 9.895322712418302e-06,
      "loss": 0.1961,
      "step": 2382
    },
    {
      "epoch": 0.5475643382352942,
      "grad_norm": 2.1386656761169434,
      "learning_rate": 9.894812091503268e-06,
      "loss": 0.3363,
      "step": 2383
    },
    {
      "epoch": 0.5477941176470589,
      "grad_norm": 2.0614335536956787,
      "learning_rate": 9.894301470588236e-06,
      "loss": 0.4023,
      "step": 2384
    },
    {
      "epoch": 0.5480238970588235,
      "grad_norm": 1.8398141860961914,
      "learning_rate": 9.893790849673204e-06,
      "loss": 0.2626,
      "step": 2385
    },
    {
      "epoch": 0.5482536764705882,
      "grad_norm": 2.0857903957366943,
      "learning_rate": 9.89328022875817e-06,
      "loss": 0.3254,
      "step": 2386
    },
    {
      "epoch": 0.5484834558823529,
      "grad_norm": 1.5456948280334473,
      "learning_rate": 9.892769607843138e-06,
      "loss": 0.21,
      "step": 2387
    },
    {
      "epoch": 0.5487132352941176,
      "grad_norm": 1.7779176235198975,
      "learning_rate": 9.892258986928104e-06,
      "loss": 0.3375,
      "step": 2388
    },
    {
      "epoch": 0.5489430147058824,
      "grad_norm": 1.915164828300476,
      "learning_rate": 9.891748366013072e-06,
      "loss": 0.2935,
      "step": 2389
    },
    {
      "epoch": 0.5491727941176471,
      "grad_norm": 1.6938977241516113,
      "learning_rate": 9.89123774509804e-06,
      "loss": 0.2764,
      "step": 2390
    },
    {
      "epoch": 0.5494025735294118,
      "grad_norm": 1.4666600227355957,
      "learning_rate": 9.890727124183008e-06,
      "loss": 0.2216,
      "step": 2391
    },
    {
      "epoch": 0.5496323529411765,
      "grad_norm": 1.9048755168914795,
      "learning_rate": 9.890216503267974e-06,
      "loss": 0.2333,
      "step": 2392
    },
    {
      "epoch": 0.5498621323529411,
      "grad_norm": 2.0037038326263428,
      "learning_rate": 9.889705882352942e-06,
      "loss": 0.2701,
      "step": 2393
    },
    {
      "epoch": 0.5500919117647058,
      "grad_norm": 1.8844314813613892,
      "learning_rate": 9.88919526143791e-06,
      "loss": 0.308,
      "step": 2394
    },
    {
      "epoch": 0.5503216911764706,
      "grad_norm": 1.9524425268173218,
      "learning_rate": 9.888684640522876e-06,
      "loss": 0.2472,
      "step": 2395
    },
    {
      "epoch": 0.5505514705882353,
      "grad_norm": 1.8032091856002808,
      "learning_rate": 9.888174019607844e-06,
      "loss": 0.2449,
      "step": 2396
    },
    {
      "epoch": 0.55078125,
      "grad_norm": 1.8868895769119263,
      "learning_rate": 9.887663398692812e-06,
      "loss": 0.2555,
      "step": 2397
    },
    {
      "epoch": 0.5510110294117647,
      "grad_norm": 1.5974862575531006,
      "learning_rate": 9.887152777777778e-06,
      "loss": 0.2339,
      "step": 2398
    },
    {
      "epoch": 0.5512408088235294,
      "grad_norm": 2.17795467376709,
      "learning_rate": 9.886642156862746e-06,
      "loss": 0.2602,
      "step": 2399
    },
    {
      "epoch": 0.5514705882352942,
      "grad_norm": 2.020163059234619,
      "learning_rate": 9.886131535947712e-06,
      "loss": 0.3087,
      "step": 2400
    },
    {
      "epoch": 0.5517003676470589,
      "grad_norm": 1.913581132888794,
      "learning_rate": 9.885620915032682e-06,
      "loss": 0.2527,
      "step": 2401
    },
    {
      "epoch": 0.5519301470588235,
      "grad_norm": 1.8474253416061401,
      "learning_rate": 9.885110294117648e-06,
      "loss": 0.28,
      "step": 2402
    },
    {
      "epoch": 0.5521599264705882,
      "grad_norm": 1.9878653287887573,
      "learning_rate": 9.884599673202616e-06,
      "loss": 0.2572,
      "step": 2403
    },
    {
      "epoch": 0.5523897058823529,
      "grad_norm": 1.5251973867416382,
      "learning_rate": 9.884089052287582e-06,
      "loss": 0.2378,
      "step": 2404
    },
    {
      "epoch": 0.5526194852941176,
      "grad_norm": 1.507328748703003,
      "learning_rate": 9.88357843137255e-06,
      "loss": 0.2526,
      "step": 2405
    },
    {
      "epoch": 0.5528492647058824,
      "grad_norm": 1.4974470138549805,
      "learning_rate": 9.883067810457517e-06,
      "loss": 0.2319,
      "step": 2406
    },
    {
      "epoch": 0.5530790441176471,
      "grad_norm": 1.5046935081481934,
      "learning_rate": 9.882557189542484e-06,
      "loss": 0.2627,
      "step": 2407
    },
    {
      "epoch": 0.5533088235294118,
      "grad_norm": 1.720831036567688,
      "learning_rate": 9.882046568627451e-06,
      "loss": 0.2748,
      "step": 2408
    },
    {
      "epoch": 0.5535386029411765,
      "grad_norm": 1.4110826253890991,
      "learning_rate": 9.88153594771242e-06,
      "loss": 0.2337,
      "step": 2409
    },
    {
      "epoch": 0.5537683823529411,
      "grad_norm": 1.4572280645370483,
      "learning_rate": 9.881025326797387e-06,
      "loss": 0.2254,
      "step": 2410
    },
    {
      "epoch": 0.5539981617647058,
      "grad_norm": 1.5771288871765137,
      "learning_rate": 9.880514705882353e-06,
      "loss": 0.3026,
      "step": 2411
    },
    {
      "epoch": 0.5542279411764706,
      "grad_norm": 1.6137325763702393,
      "learning_rate": 9.880004084967321e-06,
      "loss": 0.2039,
      "step": 2412
    },
    {
      "epoch": 0.5544577205882353,
      "grad_norm": 1.9418368339538574,
      "learning_rate": 9.879493464052289e-06,
      "loss": 0.2673,
      "step": 2413
    },
    {
      "epoch": 0.5546875,
      "grad_norm": 1.4092581272125244,
      "learning_rate": 9.878982843137255e-06,
      "loss": 0.2346,
      "step": 2414
    },
    {
      "epoch": 0.5549172794117647,
      "grad_norm": 1.648865818977356,
      "learning_rate": 9.878472222222223e-06,
      "loss": 0.1915,
      "step": 2415
    },
    {
      "epoch": 0.5551470588235294,
      "grad_norm": 2.5204057693481445,
      "learning_rate": 9.87796160130719e-06,
      "loss": 0.2681,
      "step": 2416
    },
    {
      "epoch": 0.5553768382352942,
      "grad_norm": 1.429043173789978,
      "learning_rate": 9.877450980392159e-06,
      "loss": 0.2483,
      "step": 2417
    },
    {
      "epoch": 0.5556066176470589,
      "grad_norm": 1.8136544227600098,
      "learning_rate": 9.876940359477125e-06,
      "loss": 0.2421,
      "step": 2418
    },
    {
      "epoch": 0.5558363970588235,
      "grad_norm": 1.4976868629455566,
      "learning_rate": 9.876429738562093e-06,
      "loss": 0.2847,
      "step": 2419
    },
    {
      "epoch": 0.5560661764705882,
      "grad_norm": 1.5511311292648315,
      "learning_rate": 9.875919117647059e-06,
      "loss": 0.2566,
      "step": 2420
    },
    {
      "epoch": 0.5562959558823529,
      "grad_norm": 1.5185261964797974,
      "learning_rate": 9.875408496732027e-06,
      "loss": 0.2278,
      "step": 2421
    },
    {
      "epoch": 0.5565257352941176,
      "grad_norm": 1.8112502098083496,
      "learning_rate": 9.874897875816995e-06,
      "loss": 0.2617,
      "step": 2422
    },
    {
      "epoch": 0.5567555147058824,
      "grad_norm": 1.9627536535263062,
      "learning_rate": 9.874387254901961e-06,
      "loss": 0.2596,
      "step": 2423
    },
    {
      "epoch": 0.5569852941176471,
      "grad_norm": 1.8899712562561035,
      "learning_rate": 9.873876633986929e-06,
      "loss": 0.2345,
      "step": 2424
    },
    {
      "epoch": 0.5572150735294118,
      "grad_norm": 2.170008897781372,
      "learning_rate": 9.873366013071897e-06,
      "loss": 0.3099,
      "step": 2425
    },
    {
      "epoch": 0.5574448529411765,
      "grad_norm": 1.9107025861740112,
      "learning_rate": 9.872855392156864e-06,
      "loss": 0.2301,
      "step": 2426
    },
    {
      "epoch": 0.5576746323529411,
      "grad_norm": 1.5641595125198364,
      "learning_rate": 9.87234477124183e-06,
      "loss": 0.2554,
      "step": 2427
    },
    {
      "epoch": 0.5579044117647058,
      "grad_norm": 1.7623478174209595,
      "learning_rate": 9.871834150326799e-06,
      "loss": 0.2121,
      "step": 2428
    },
    {
      "epoch": 0.5581341911764706,
      "grad_norm": 1.9626657962799072,
      "learning_rate": 9.871323529411766e-06,
      "loss": 0.3019,
      "step": 2429
    },
    {
      "epoch": 0.5583639705882353,
      "grad_norm": 1.966686487197876,
      "learning_rate": 9.870812908496733e-06,
      "loss": 0.3066,
      "step": 2430
    },
    {
      "epoch": 0.55859375,
      "grad_norm": 1.7867732048034668,
      "learning_rate": 9.8703022875817e-06,
      "loss": 0.2617,
      "step": 2431
    },
    {
      "epoch": 0.5588235294117647,
      "grad_norm": 1.6400071382522583,
      "learning_rate": 9.869791666666667e-06,
      "loss": 0.2079,
      "step": 2432
    },
    {
      "epoch": 0.5590533088235294,
      "grad_norm": 1.4118962287902832,
      "learning_rate": 9.869281045751634e-06,
      "loss": 0.2181,
      "step": 2433
    },
    {
      "epoch": 0.5592830882352942,
      "grad_norm": 1.3621675968170166,
      "learning_rate": 9.868770424836602e-06,
      "loss": 0.242,
      "step": 2434
    },
    {
      "epoch": 0.5595128676470589,
      "grad_norm": 1.788453459739685,
      "learning_rate": 9.86825980392157e-06,
      "loss": 0.2764,
      "step": 2435
    },
    {
      "epoch": 0.5597426470588235,
      "grad_norm": 1.9735580682754517,
      "learning_rate": 9.867749183006536e-06,
      "loss": 0.2672,
      "step": 2436
    },
    {
      "epoch": 0.5599724264705882,
      "grad_norm": 1.8338720798492432,
      "learning_rate": 9.867238562091504e-06,
      "loss": 0.2285,
      "step": 2437
    },
    {
      "epoch": 0.5602022058823529,
      "grad_norm": 1.4883098602294922,
      "learning_rate": 9.866727941176472e-06,
      "loss": 0.2122,
      "step": 2438
    },
    {
      "epoch": 0.5604319852941176,
      "grad_norm": 2.250145435333252,
      "learning_rate": 9.866217320261438e-06,
      "loss": 0.2984,
      "step": 2439
    },
    {
      "epoch": 0.5606617647058824,
      "grad_norm": 1.9625517129898071,
      "learning_rate": 9.865706699346406e-06,
      "loss": 0.2902,
      "step": 2440
    },
    {
      "epoch": 0.5608915441176471,
      "grad_norm": 1.5382764339447021,
      "learning_rate": 9.865196078431374e-06,
      "loss": 0.2626,
      "step": 2441
    },
    {
      "epoch": 0.5611213235294118,
      "grad_norm": 1.7862374782562256,
      "learning_rate": 9.86468545751634e-06,
      "loss": 0.2676,
      "step": 2442
    },
    {
      "epoch": 0.5613511029411765,
      "grad_norm": 1.795509934425354,
      "learning_rate": 9.864174836601308e-06,
      "loss": 0.2529,
      "step": 2443
    },
    {
      "epoch": 0.5615808823529411,
      "grad_norm": 1.6399377584457397,
      "learning_rate": 9.863664215686274e-06,
      "loss": 0.2393,
      "step": 2444
    },
    {
      "epoch": 0.5618106617647058,
      "grad_norm": 1.7506237030029297,
      "learning_rate": 9.863153594771244e-06,
      "loss": 0.2496,
      "step": 2445
    },
    {
      "epoch": 0.5620404411764706,
      "grad_norm": 2.060370445251465,
      "learning_rate": 9.86264297385621e-06,
      "loss": 0.2601,
      "step": 2446
    },
    {
      "epoch": 0.5622702205882353,
      "grad_norm": 1.6344082355499268,
      "learning_rate": 9.862132352941178e-06,
      "loss": 0.2216,
      "step": 2447
    },
    {
      "epoch": 0.5625,
      "grad_norm": 1.5202581882476807,
      "learning_rate": 9.861621732026144e-06,
      "loss": 0.2551,
      "step": 2448
    },
    {
      "epoch": 0.5627297794117647,
      "grad_norm": 1.767126202583313,
      "learning_rate": 9.861111111111112e-06,
      "loss": 0.2911,
      "step": 2449
    },
    {
      "epoch": 0.5629595588235294,
      "grad_norm": 1.768097996711731,
      "learning_rate": 9.86060049019608e-06,
      "loss": 0.2361,
      "step": 2450
    },
    {
      "epoch": 0.5631893382352942,
      "grad_norm": 1.4628846645355225,
      "learning_rate": 9.860089869281046e-06,
      "loss": 0.227,
      "step": 2451
    },
    {
      "epoch": 0.5634191176470589,
      "grad_norm": 1.5782470703125,
      "learning_rate": 9.859579248366014e-06,
      "loss": 0.2444,
      "step": 2452
    },
    {
      "epoch": 0.5636488970588235,
      "grad_norm": 1.3020758628845215,
      "learning_rate": 9.859068627450982e-06,
      "loss": 0.2749,
      "step": 2453
    },
    {
      "epoch": 0.5638786764705882,
      "grad_norm": 1.8977634906768799,
      "learning_rate": 9.85855800653595e-06,
      "loss": 0.2558,
      "step": 2454
    },
    {
      "epoch": 0.5641084558823529,
      "grad_norm": 1.3839246034622192,
      "learning_rate": 9.858047385620916e-06,
      "loss": 0.2155,
      "step": 2455
    },
    {
      "epoch": 0.5643382352941176,
      "grad_norm": 1.8029125928878784,
      "learning_rate": 9.857536764705883e-06,
      "loss": 0.287,
      "step": 2456
    },
    {
      "epoch": 0.5645680147058824,
      "grad_norm": 1.9574573040008545,
      "learning_rate": 9.857026143790851e-06,
      "loss": 0.29,
      "step": 2457
    },
    {
      "epoch": 0.5647977941176471,
      "grad_norm": 1.573524832725525,
      "learning_rate": 9.856515522875817e-06,
      "loss": 0.2607,
      "step": 2458
    },
    {
      "epoch": 0.5650275735294118,
      "grad_norm": 1.6660773754119873,
      "learning_rate": 9.856004901960785e-06,
      "loss": 0.2347,
      "step": 2459
    },
    {
      "epoch": 0.5652573529411765,
      "grad_norm": 1.3535984754562378,
      "learning_rate": 9.855494281045751e-06,
      "loss": 0.2508,
      "step": 2460
    },
    {
      "epoch": 0.5654871323529411,
      "grad_norm": Infinity,
      "learning_rate": 9.854983660130721e-06,
      "loss": 0.3957,
      "step": 2461
    },
    {
      "epoch": 0.5657169117647058,
      "grad_norm": 1.8742057085037231,
      "learning_rate": 9.854983660130721e-06,
      "loss": 0.2195,
      "step": 2462
    },
    {
      "epoch": 0.5659466911764706,
      "grad_norm": 1.6926699876785278,
      "learning_rate": 9.854473039215687e-06,
      "loss": 0.2616,
      "step": 2463
    },
    {
      "epoch": 0.5661764705882353,
      "grad_norm": 1.406986951828003,
      "learning_rate": 9.853962418300655e-06,
      "loss": 0.2396,
      "step": 2464
    },
    {
      "epoch": 0.56640625,
      "grad_norm": 1.559895396232605,
      "learning_rate": 9.853451797385621e-06,
      "loss": 0.2645,
      "step": 2465
    },
    {
      "epoch": 0.5666360294117647,
      "grad_norm": 1.8961186408996582,
      "learning_rate": 9.852941176470589e-06,
      "loss": 0.2726,
      "step": 2466
    },
    {
      "epoch": 0.5668658088235294,
      "grad_norm": 1.8181426525115967,
      "learning_rate": 9.852430555555557e-06,
      "loss": 0.1879,
      "step": 2467
    },
    {
      "epoch": 0.5670955882352942,
      "grad_norm": 1.3744027614593506,
      "learning_rate": 9.851919934640523e-06,
      "loss": 0.2662,
      "step": 2468
    },
    {
      "epoch": 0.5673253676470589,
      "grad_norm": 1.4952061176300049,
      "learning_rate": 9.851409313725491e-06,
      "loss": 0.2571,
      "step": 2469
    },
    {
      "epoch": 0.5675551470588235,
      "grad_norm": 1.2818870544433594,
      "learning_rate": 9.850898692810459e-06,
      "loss": 0.2547,
      "step": 2470
    },
    {
      "epoch": 0.5677849264705882,
      "grad_norm": 1.5173821449279785,
      "learning_rate": 9.850388071895427e-06,
      "loss": 0.256,
      "step": 2471
    },
    {
      "epoch": 0.5680147058823529,
      "grad_norm": 1.6855496168136597,
      "learning_rate": 9.849877450980393e-06,
      "loss": 0.2533,
      "step": 2472
    },
    {
      "epoch": 0.5682444852941176,
      "grad_norm": 1.5231417417526245,
      "learning_rate": 9.84936683006536e-06,
      "loss": 0.2304,
      "step": 2473
    },
    {
      "epoch": 0.5684742647058824,
      "grad_norm": 2.099562644958496,
      "learning_rate": 9.848856209150329e-06,
      "loss": 0.2643,
      "step": 2474
    },
    {
      "epoch": 0.5687040441176471,
      "grad_norm": 1.5934683084487915,
      "learning_rate": 9.848345588235295e-06,
      "loss": 0.2487,
      "step": 2475
    },
    {
      "epoch": 0.5689338235294118,
      "grad_norm": 1.4882532358169556,
      "learning_rate": 9.847834967320263e-06,
      "loss": 0.2499,
      "step": 2476
    },
    {
      "epoch": 0.5691636029411765,
      "grad_norm": 1.6169447898864746,
      "learning_rate": 9.847324346405229e-06,
      "loss": 0.2376,
      "step": 2477
    },
    {
      "epoch": 0.5693933823529411,
      "grad_norm": 1.5473229885101318,
      "learning_rate": 9.846813725490197e-06,
      "loss": 0.2833,
      "step": 2478
    },
    {
      "epoch": 0.5696231617647058,
      "grad_norm": 1.7625356912612915,
      "learning_rate": 9.846303104575164e-06,
      "loss": 0.2655,
      "step": 2479
    },
    {
      "epoch": 0.5698529411764706,
      "grad_norm": 1.8248045444488525,
      "learning_rate": 9.845792483660132e-06,
      "loss": 0.3126,
      "step": 2480
    },
    {
      "epoch": 0.5700827205882353,
      "grad_norm": 1.5794384479522705,
      "learning_rate": 9.845281862745099e-06,
      "loss": 0.2223,
      "step": 2481
    },
    {
      "epoch": 0.5703125,
      "grad_norm": 1.558327078819275,
      "learning_rate": 9.844771241830066e-06,
      "loss": 0.2536,
      "step": 2482
    },
    {
      "epoch": 0.5705422794117647,
      "grad_norm": 1.615431785583496,
      "learning_rate": 9.844260620915034e-06,
      "loss": 0.2299,
      "step": 2483
    },
    {
      "epoch": 0.5707720588235294,
      "grad_norm": 1.8654468059539795,
      "learning_rate": 9.84375e-06,
      "loss": 0.2229,
      "step": 2484
    },
    {
      "epoch": 0.5710018382352942,
      "grad_norm": 1.3525346517562866,
      "learning_rate": 9.843239379084968e-06,
      "loss": 0.279,
      "step": 2485
    },
    {
      "epoch": 0.5712316176470589,
      "grad_norm": 2.0255000591278076,
      "learning_rate": 9.842728758169934e-06,
      "loss": 0.2445,
      "step": 2486
    },
    {
      "epoch": 0.5714613970588235,
      "grad_norm": 1.5838979482650757,
      "learning_rate": 9.842218137254902e-06,
      "loss": 0.1925,
      "step": 2487
    },
    {
      "epoch": 0.5716911764705882,
      "grad_norm": 1.3432472944259644,
      "learning_rate": 9.84170751633987e-06,
      "loss": 0.2184,
      "step": 2488
    },
    {
      "epoch": 0.5719209558823529,
      "grad_norm": 1.9816007614135742,
      "learning_rate": 9.841196895424836e-06,
      "loss": 0.2618,
      "step": 2489
    },
    {
      "epoch": 0.5721507352941176,
      "grad_norm": 1.6502854824066162,
      "learning_rate": 9.840686274509804e-06,
      "loss": 0.233,
      "step": 2490
    },
    {
      "epoch": 0.5723805147058824,
      "grad_norm": 1.4802448749542236,
      "learning_rate": 9.840175653594772e-06,
      "loss": 0.2581,
      "step": 2491
    },
    {
      "epoch": 0.5726102941176471,
      "grad_norm": 1.5471923351287842,
      "learning_rate": 9.83966503267974e-06,
      "loss": 0.176,
      "step": 2492
    },
    {
      "epoch": 0.5728400735294118,
      "grad_norm": 1.7284876108169556,
      "learning_rate": 9.839154411764706e-06,
      "loss": 0.2687,
      "step": 2493
    },
    {
      "epoch": 0.5730698529411765,
      "grad_norm": 1.808228611946106,
      "learning_rate": 9.838643790849674e-06,
      "loss": 0.2673,
      "step": 2494
    },
    {
      "epoch": 0.5732996323529411,
      "grad_norm": 1.5197056531906128,
      "learning_rate": 9.838133169934642e-06,
      "loss": 0.2441,
      "step": 2495
    },
    {
      "epoch": 0.5735294117647058,
      "grad_norm": 1.3677022457122803,
      "learning_rate": 9.837622549019608e-06,
      "loss": 0.2977,
      "step": 2496
    },
    {
      "epoch": 0.5737591911764706,
      "grad_norm": 2.005206346511841,
      "learning_rate": 9.837111928104576e-06,
      "loss": 0.2761,
      "step": 2497
    },
    {
      "epoch": 0.5739889705882353,
      "grad_norm": 1.7596203088760376,
      "learning_rate": 9.836601307189542e-06,
      "loss": 0.2303,
      "step": 2498
    },
    {
      "epoch": 0.57421875,
      "grad_norm": 1.7113009691238403,
      "learning_rate": 9.836090686274512e-06,
      "loss": 0.2495,
      "step": 2499
    },
    {
      "epoch": 0.5744485294117647,
      "grad_norm": 1.7684049606323242,
      "learning_rate": 9.835580065359478e-06,
      "loss": 0.2593,
      "step": 2500
    },
    {
      "epoch": 0.5744485294117647,
      "eval_loss": 0.2511299252510071,
      "eval_runtime": 419.4788,
      "eval_samples_per_second": 21.231,
      "eval_steps_per_second": 10.616,
      "step": 2500
    },
    {
      "epoch": 0.5746783088235294,
      "grad_norm": 1.9966098070144653,
      "learning_rate": 9.835069444444446e-06,
      "loss": 0.2159,
      "step": 2501
    },
    {
      "epoch": 0.5749080882352942,
      "grad_norm": 1.708077311515808,
      "learning_rate": 9.834558823529412e-06,
      "loss": 0.2547,
      "step": 2502
    },
    {
      "epoch": 0.5751378676470589,
      "grad_norm": 1.9327887296676636,
      "learning_rate": 9.83404820261438e-06,
      "loss": 0.3152,
      "step": 2503
    },
    {
      "epoch": 0.5753676470588235,
      "grad_norm": 1.506218433380127,
      "learning_rate": 9.833537581699347e-06,
      "loss": 0.2096,
      "step": 2504
    },
    {
      "epoch": 0.5755974264705882,
      "grad_norm": 1.8157470226287842,
      "learning_rate": 9.833026960784314e-06,
      "loss": 0.2835,
      "step": 2505
    },
    {
      "epoch": 0.5758272058823529,
      "grad_norm": 1.4419883489608765,
      "learning_rate": 9.832516339869282e-06,
      "loss": 0.2305,
      "step": 2506
    },
    {
      "epoch": 0.5760569852941176,
      "grad_norm": 2.8404200077056885,
      "learning_rate": 9.83200571895425e-06,
      "loss": 0.181,
      "step": 2507
    },
    {
      "epoch": 0.5762867647058824,
      "grad_norm": 1.8882020711898804,
      "learning_rate": 9.831495098039217e-06,
      "loss": 0.292,
      "step": 2508
    },
    {
      "epoch": 0.5765165441176471,
      "grad_norm": 1.6793358325958252,
      "learning_rate": 9.830984477124183e-06,
      "loss": 0.2478,
      "step": 2509
    },
    {
      "epoch": 0.5767463235294118,
      "grad_norm": 1.5306270122528076,
      "learning_rate": 9.830473856209151e-06,
      "loss": 0.2415,
      "step": 2510
    },
    {
      "epoch": 0.5769761029411765,
      "grad_norm": 1.6289480924606323,
      "learning_rate": 9.829963235294119e-06,
      "loss": 0.2709,
      "step": 2511
    },
    {
      "epoch": 0.5772058823529411,
      "grad_norm": 1.5318570137023926,
      "learning_rate": 9.829452614379085e-06,
      "loss": 0.2672,
      "step": 2512
    },
    {
      "epoch": 0.5774356617647058,
      "grad_norm": 1.8116512298583984,
      "learning_rate": 9.828941993464053e-06,
      "loss": 0.2346,
      "step": 2513
    },
    {
      "epoch": 0.5776654411764706,
      "grad_norm": 1.9314931631088257,
      "learning_rate": 9.82843137254902e-06,
      "loss": 0.2275,
      "step": 2514
    },
    {
      "epoch": 0.5778952205882353,
      "grad_norm": 1.7246969938278198,
      "learning_rate": 9.827920751633989e-06,
      "loss": 0.2297,
      "step": 2515
    },
    {
      "epoch": 0.578125,
      "grad_norm": 1.6639786958694458,
      "learning_rate": 9.827410130718955e-06,
      "loss": 0.3007,
      "step": 2516
    },
    {
      "epoch": 0.5783547794117647,
      "grad_norm": 1.704404592514038,
      "learning_rate": 9.826899509803923e-06,
      "loss": 0.2507,
      "step": 2517
    },
    {
      "epoch": 0.5785845588235294,
      "grad_norm": 1.4432249069213867,
      "learning_rate": 9.826388888888889e-06,
      "loss": 0.255,
      "step": 2518
    },
    {
      "epoch": 0.5788143382352942,
      "grad_norm": 2.0792672634124756,
      "learning_rate": 9.825878267973857e-06,
      "loss": 0.325,
      "step": 2519
    },
    {
      "epoch": 0.5790441176470589,
      "grad_norm": 1.3922350406646729,
      "learning_rate": 9.825367647058825e-06,
      "loss": 0.2064,
      "step": 2520
    },
    {
      "epoch": 0.5792738970588235,
      "grad_norm": 1.2767090797424316,
      "learning_rate": 9.824857026143791e-06,
      "loss": 0.2543,
      "step": 2521
    },
    {
      "epoch": 0.5795036764705882,
      "grad_norm": 2.0844013690948486,
      "learning_rate": 9.824346405228759e-06,
      "loss": 0.2175,
      "step": 2522
    },
    {
      "epoch": 0.5797334558823529,
      "grad_norm": 2.4356279373168945,
      "learning_rate": 9.823835784313727e-06,
      "loss": 0.2937,
      "step": 2523
    },
    {
      "epoch": 0.5799632352941176,
      "grad_norm": 1.6091400384902954,
      "learning_rate": 9.823325163398693e-06,
      "loss": 0.2477,
      "step": 2524
    },
    {
      "epoch": 0.5801930147058824,
      "grad_norm": 1.6783480644226074,
      "learning_rate": 9.82281454248366e-06,
      "loss": 0.2562,
      "step": 2525
    },
    {
      "epoch": 0.5804227941176471,
      "grad_norm": 1.6920537948608398,
      "learning_rate": 9.822303921568629e-06,
      "loss": 0.2889,
      "step": 2526
    },
    {
      "epoch": 0.5806525735294118,
      "grad_norm": 1.6945050954818726,
      "learning_rate": 9.821793300653596e-06,
      "loss": 0.25,
      "step": 2527
    },
    {
      "epoch": 0.5808823529411765,
      "grad_norm": 1.8404382467269897,
      "learning_rate": 9.821282679738563e-06,
      "loss": 0.2402,
      "step": 2528
    },
    {
      "epoch": 0.5811121323529411,
      "grad_norm": 1.4480351209640503,
      "learning_rate": 9.82077205882353e-06,
      "loss": 0.1842,
      "step": 2529
    },
    {
      "epoch": 0.5813419117647058,
      "grad_norm": 1.516181230545044,
      "learning_rate": 9.820261437908497e-06,
      "loss": 0.2478,
      "step": 2530
    },
    {
      "epoch": 0.5815716911764706,
      "grad_norm": 1.8839956521987915,
      "learning_rate": 9.819750816993464e-06,
      "loss": 0.3036,
      "step": 2531
    },
    {
      "epoch": 0.5818014705882353,
      "grad_norm": 1.3826847076416016,
      "learning_rate": 9.819240196078432e-06,
      "loss": 0.2618,
      "step": 2532
    },
    {
      "epoch": 0.58203125,
      "grad_norm": 2.061284303665161,
      "learning_rate": 9.818729575163399e-06,
      "loss": 0.2645,
      "step": 2533
    },
    {
      "epoch": 0.5822610294117647,
      "grad_norm": 1.4639544486999512,
      "learning_rate": 9.818218954248366e-06,
      "loss": 0.3181,
      "step": 2534
    },
    {
      "epoch": 0.5824908088235294,
      "grad_norm": 1.7542247772216797,
      "learning_rate": 9.817708333333334e-06,
      "loss": 0.2868,
      "step": 2535
    },
    {
      "epoch": 0.5827205882352942,
      "grad_norm": 1.5603201389312744,
      "learning_rate": 9.817197712418302e-06,
      "loss": 0.2686,
      "step": 2536
    },
    {
      "epoch": 0.5829503676470589,
      "grad_norm": 1.6889569759368896,
      "learning_rate": 9.816687091503268e-06,
      "loss": 0.223,
      "step": 2537
    },
    {
      "epoch": 0.5831801470588235,
      "grad_norm": 1.7901906967163086,
      "learning_rate": 9.816176470588236e-06,
      "loss": 0.2504,
      "step": 2538
    },
    {
      "epoch": 0.5834099264705882,
      "grad_norm": 1.6903681755065918,
      "learning_rate": 9.815665849673204e-06,
      "loss": 0.1918,
      "step": 2539
    },
    {
      "epoch": 0.5836397058823529,
      "grad_norm": 2.1904261112213135,
      "learning_rate": 9.81515522875817e-06,
      "loss": 0.2784,
      "step": 2540
    },
    {
      "epoch": 0.5838694852941176,
      "grad_norm": 1.7886416912078857,
      "learning_rate": 9.814644607843138e-06,
      "loss": 0.2344,
      "step": 2541
    },
    {
      "epoch": 0.5840992647058824,
      "grad_norm": 1.9519087076187134,
      "learning_rate": 9.814133986928104e-06,
      "loss": 0.2847,
      "step": 2542
    },
    {
      "epoch": 0.5843290441176471,
      "grad_norm": 1.8099929094314575,
      "learning_rate": 9.813623366013074e-06,
      "loss": 0.2456,
      "step": 2543
    },
    {
      "epoch": 0.5845588235294118,
      "grad_norm": 1.8501430749893188,
      "learning_rate": 9.81311274509804e-06,
      "loss": 0.253,
      "step": 2544
    },
    {
      "epoch": 0.5847886029411765,
      "grad_norm": 1.7652643918991089,
      "learning_rate": 9.812602124183008e-06,
      "loss": 0.2187,
      "step": 2545
    },
    {
      "epoch": 0.5850183823529411,
      "grad_norm": 1.8563839197158813,
      "learning_rate": 9.812091503267974e-06,
      "loss": 0.2411,
      "step": 2546
    },
    {
      "epoch": 0.5852481617647058,
      "grad_norm": 2.404386520385742,
      "learning_rate": 9.811580882352942e-06,
      "loss": 0.2836,
      "step": 2547
    },
    {
      "epoch": 0.5854779411764706,
      "grad_norm": 1.6612416505813599,
      "learning_rate": 9.81107026143791e-06,
      "loss": 0.2025,
      "step": 2548
    },
    {
      "epoch": 0.5857077205882353,
      "grad_norm": 1.558718204498291,
      "learning_rate": 9.810559640522876e-06,
      "loss": 0.2112,
      "step": 2549
    },
    {
      "epoch": 0.5859375,
      "grad_norm": 1.8215152025222778,
      "learning_rate": 9.810049019607844e-06,
      "loss": 0.2106,
      "step": 2550
    },
    {
      "epoch": 0.5861672794117647,
      "grad_norm": 2.128919839859009,
      "learning_rate": 9.809538398692812e-06,
      "loss": 0.1837,
      "step": 2551
    },
    {
      "epoch": 0.5863970588235294,
      "grad_norm": 1.9387415647506714,
      "learning_rate": 9.80902777777778e-06,
      "loss": 0.2364,
      "step": 2552
    },
    {
      "epoch": 0.5866268382352942,
      "grad_norm": 1.6160876750946045,
      "learning_rate": 9.808517156862746e-06,
      "loss": 0.2527,
      "step": 2553
    },
    {
      "epoch": 0.5868566176470589,
      "grad_norm": 1.6606628894805908,
      "learning_rate": 9.808006535947713e-06,
      "loss": 0.2102,
      "step": 2554
    },
    {
      "epoch": 0.5870863970588235,
      "grad_norm": 1.8288370370864868,
      "learning_rate": 9.807495915032681e-06,
      "loss": 0.2402,
      "step": 2555
    },
    {
      "epoch": 0.5873161764705882,
      "grad_norm": 1.7334096431732178,
      "learning_rate": 9.806985294117647e-06,
      "loss": 0.1985,
      "step": 2556
    },
    {
      "epoch": 0.5875459558823529,
      "grad_norm": 2.0745720863342285,
      "learning_rate": 9.806474673202615e-06,
      "loss": 0.2259,
      "step": 2557
    },
    {
      "epoch": 0.5877757352941176,
      "grad_norm": 2.1406683921813965,
      "learning_rate": 9.805964052287581e-06,
      "loss": 0.2523,
      "step": 2558
    },
    {
      "epoch": 0.5880055147058824,
      "grad_norm": 1.7890126705169678,
      "learning_rate": 9.805453431372551e-06,
      "loss": 0.2978,
      "step": 2559
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 2.273144483566284,
      "learning_rate": 9.804942810457517e-06,
      "loss": 0.2802,
      "step": 2560
    },
    {
      "epoch": 0.5884650735294118,
      "grad_norm": 1.6566334962844849,
      "learning_rate": 9.804432189542485e-06,
      "loss": 0.2775,
      "step": 2561
    },
    {
      "epoch": 0.5886948529411765,
      "grad_norm": 1.8560956716537476,
      "learning_rate": 9.803921568627451e-06,
      "loss": 0.2988,
      "step": 2562
    },
    {
      "epoch": 0.5889246323529411,
      "grad_norm": 1.9255186319351196,
      "learning_rate": 9.803410947712419e-06,
      "loss": 0.2652,
      "step": 2563
    },
    {
      "epoch": 0.5891544117647058,
      "grad_norm": 1.8959635496139526,
      "learning_rate": 9.802900326797387e-06,
      "loss": 0.314,
      "step": 2564
    },
    {
      "epoch": 0.5893841911764706,
      "grad_norm": 1.7618846893310547,
      "learning_rate": 9.802389705882353e-06,
      "loss": 0.2042,
      "step": 2565
    },
    {
      "epoch": 0.5896139705882353,
      "grad_norm": 1.6968342065811157,
      "learning_rate": 9.801879084967321e-06,
      "loss": 0.1683,
      "step": 2566
    },
    {
      "epoch": 0.58984375,
      "grad_norm": 1.9800878763198853,
      "learning_rate": 9.801368464052289e-06,
      "loss": 0.2722,
      "step": 2567
    },
    {
      "epoch": 0.5900735294117647,
      "grad_norm": 2.542322874069214,
      "learning_rate": 9.800857843137255e-06,
      "loss": 0.2799,
      "step": 2568
    },
    {
      "epoch": 0.5903033088235294,
      "grad_norm": 1.4697920083999634,
      "learning_rate": 9.800347222222223e-06,
      "loss": 0.2444,
      "step": 2569
    },
    {
      "epoch": 0.5905330882352942,
      "grad_norm": 1.6261168718338013,
      "learning_rate": 9.79983660130719e-06,
      "loss": 0.2106,
      "step": 2570
    },
    {
      "epoch": 0.5907628676470589,
      "grad_norm": 1.466088056564331,
      "learning_rate": 9.799325980392159e-06,
      "loss": 0.2221,
      "step": 2571
    },
    {
      "epoch": 0.5909926470588235,
      "grad_norm": 1.5269309282302856,
      "learning_rate": 9.798815359477125e-06,
      "loss": 0.2817,
      "step": 2572
    },
    {
      "epoch": 0.5912224264705882,
      "grad_norm": 1.879244089126587,
      "learning_rate": 9.798304738562093e-06,
      "loss": 0.2692,
      "step": 2573
    },
    {
      "epoch": 0.5914522058823529,
      "grad_norm": 1.762953519821167,
      "learning_rate": 9.797794117647059e-06,
      "loss": 0.2234,
      "step": 2574
    },
    {
      "epoch": 0.5916819852941176,
      "grad_norm": 1.9034273624420166,
      "learning_rate": 9.797283496732027e-06,
      "loss": 0.2353,
      "step": 2575
    },
    {
      "epoch": 0.5919117647058824,
      "grad_norm": 2.3780338764190674,
      "learning_rate": 9.796772875816995e-06,
      "loss": 0.2833,
      "step": 2576
    },
    {
      "epoch": 0.5921415441176471,
      "grad_norm": 2.0048599243164062,
      "learning_rate": 9.79626225490196e-06,
      "loss": 0.2993,
      "step": 2577
    },
    {
      "epoch": 0.5923713235294118,
      "grad_norm": 1.679610013961792,
      "learning_rate": 9.795751633986929e-06,
      "loss": 0.2297,
      "step": 2578
    },
    {
      "epoch": 0.5926011029411765,
      "grad_norm": 1.6248466968536377,
      "learning_rate": 9.795241013071896e-06,
      "loss": 0.4082,
      "step": 2579
    },
    {
      "epoch": 0.5928308823529411,
      "grad_norm": 1.4400092363357544,
      "learning_rate": 9.794730392156864e-06,
      "loss": 0.2429,
      "step": 2580
    },
    {
      "epoch": 0.5930606617647058,
      "grad_norm": 1.6306174993515015,
      "learning_rate": 9.79421977124183e-06,
      "loss": 0.2288,
      "step": 2581
    },
    {
      "epoch": 0.5932904411764706,
      "grad_norm": 2.101294994354248,
      "learning_rate": 9.793709150326798e-06,
      "loss": 0.223,
      "step": 2582
    },
    {
      "epoch": 0.5935202205882353,
      "grad_norm": 1.579574465751648,
      "learning_rate": 9.793198529411766e-06,
      "loss": 0.244,
      "step": 2583
    },
    {
      "epoch": 0.59375,
      "grad_norm": 1.708277702331543,
      "learning_rate": 9.792687908496732e-06,
      "loss": 0.2514,
      "step": 2584
    },
    {
      "epoch": 0.5939797794117647,
      "grad_norm": 1.3772594928741455,
      "learning_rate": 9.7921772875817e-06,
      "loss": 0.2047,
      "step": 2585
    },
    {
      "epoch": 0.5942095588235294,
      "grad_norm": 1.5501362085342407,
      "learning_rate": 9.791666666666666e-06,
      "loss": 0.2804,
      "step": 2586
    },
    {
      "epoch": 0.5944393382352942,
      "grad_norm": 1.619057536125183,
      "learning_rate": 9.791156045751636e-06,
      "loss": 0.2448,
      "step": 2587
    },
    {
      "epoch": 0.5946691176470589,
      "grad_norm": 1.3854225873947144,
      "learning_rate": 9.790645424836602e-06,
      "loss": 0.228,
      "step": 2588
    },
    {
      "epoch": 0.5948988970588235,
      "grad_norm": 1.5169222354888916,
      "learning_rate": 9.79013480392157e-06,
      "loss": 0.2445,
      "step": 2589
    },
    {
      "epoch": 0.5951286764705882,
      "grad_norm": 1.9586244821548462,
      "learning_rate": 9.789624183006536e-06,
      "loss": 0.2434,
      "step": 2590
    },
    {
      "epoch": 0.5953584558823529,
      "grad_norm": 1.3351879119873047,
      "learning_rate": 9.789113562091504e-06,
      "loss": 0.2554,
      "step": 2591
    },
    {
      "epoch": 0.5955882352941176,
      "grad_norm": 1.4999850988388062,
      "learning_rate": 9.788602941176472e-06,
      "loss": 0.2205,
      "step": 2592
    },
    {
      "epoch": 0.5958180147058824,
      "grad_norm": 2.1462135314941406,
      "learning_rate": 9.788092320261438e-06,
      "loss": 0.2717,
      "step": 2593
    },
    {
      "epoch": 0.5960477941176471,
      "grad_norm": 2.005484104156494,
      "learning_rate": 9.787581699346406e-06,
      "loss": 0.2647,
      "step": 2594
    },
    {
      "epoch": 0.5962775735294118,
      "grad_norm": 1.4822674989700317,
      "learning_rate": 9.787071078431374e-06,
      "loss": 0.2244,
      "step": 2595
    },
    {
      "epoch": 0.5965073529411765,
      "grad_norm": 1.4264155626296997,
      "learning_rate": 9.786560457516342e-06,
      "loss": 0.2247,
      "step": 2596
    },
    {
      "epoch": 0.5967371323529411,
      "grad_norm": 1.6966440677642822,
      "learning_rate": 9.786049836601308e-06,
      "loss": 0.2402,
      "step": 2597
    },
    {
      "epoch": 0.5969669117647058,
      "grad_norm": 1.7510539293289185,
      "learning_rate": 9.785539215686276e-06,
      "loss": 0.2826,
      "step": 2598
    },
    {
      "epoch": 0.5971966911764706,
      "grad_norm": 1.726855993270874,
      "learning_rate": 9.785028594771243e-06,
      "loss": 0.2758,
      "step": 2599
    },
    {
      "epoch": 0.5974264705882353,
      "grad_norm": 1.714791178703308,
      "learning_rate": 9.78451797385621e-06,
      "loss": 0.2796,
      "step": 2600
    },
    {
      "epoch": 0.59765625,
      "grad_norm": 1.5167714357376099,
      "learning_rate": 9.784007352941178e-06,
      "loss": 0.2217,
      "step": 2601
    },
    {
      "epoch": 0.5978860294117647,
      "grad_norm": 1.5561274290084839,
      "learning_rate": 9.783496732026144e-06,
      "loss": 0.2051,
      "step": 2602
    },
    {
      "epoch": 0.5981158088235294,
      "grad_norm": 1.4682737588882446,
      "learning_rate": 9.782986111111113e-06,
      "loss": 0.2668,
      "step": 2603
    },
    {
      "epoch": 0.5983455882352942,
      "grad_norm": 1.9144459962844849,
      "learning_rate": 9.78247549019608e-06,
      "loss": 0.2847,
      "step": 2604
    },
    {
      "epoch": 0.5985753676470589,
      "grad_norm": 2.066848039627075,
      "learning_rate": 9.781964869281047e-06,
      "loss": 0.2487,
      "step": 2605
    },
    {
      "epoch": 0.5988051470588235,
      "grad_norm": 1.8078855276107788,
      "learning_rate": 9.781454248366013e-06,
      "loss": 0.2411,
      "step": 2606
    },
    {
      "epoch": 0.5990349264705882,
      "grad_norm": 1.6827008724212646,
      "learning_rate": 9.780943627450981e-06,
      "loss": 0.2261,
      "step": 2607
    },
    {
      "epoch": 0.5992647058823529,
      "grad_norm": 1.492344856262207,
      "learning_rate": 9.78043300653595e-06,
      "loss": 0.2021,
      "step": 2608
    },
    {
      "epoch": 0.5994944852941176,
      "grad_norm": 1.8479890823364258,
      "learning_rate": 9.779922385620915e-06,
      "loss": 0.2381,
      "step": 2609
    },
    {
      "epoch": 0.5997242647058824,
      "grad_norm": 1.8044184446334839,
      "learning_rate": 9.779411764705883e-06,
      "loss": 0.1971,
      "step": 2610
    },
    {
      "epoch": 0.5999540441176471,
      "grad_norm": 1.4616013765335083,
      "learning_rate": 9.778901143790851e-06,
      "loss": 0.2268,
      "step": 2611
    },
    {
      "epoch": 0.6001838235294118,
      "grad_norm": 1.5119946002960205,
      "learning_rate": 9.778390522875817e-06,
      "loss": 0.2506,
      "step": 2612
    },
    {
      "epoch": 0.6004136029411765,
      "grad_norm": 1.8584880828857422,
      "learning_rate": 9.777879901960785e-06,
      "loss": 0.2549,
      "step": 2613
    },
    {
      "epoch": 0.6006433823529411,
      "grad_norm": 1.4172208309173584,
      "learning_rate": 9.777369281045753e-06,
      "loss": 0.1789,
      "step": 2614
    },
    {
      "epoch": 0.6008731617647058,
      "grad_norm": 2.061133623123169,
      "learning_rate": 9.77685866013072e-06,
      "loss": 0.2572,
      "step": 2615
    },
    {
      "epoch": 0.6011029411764706,
      "grad_norm": 1.5257948637008667,
      "learning_rate": 9.776348039215687e-06,
      "loss": 0.1905,
      "step": 2616
    },
    {
      "epoch": 0.6013327205882353,
      "grad_norm": 1.5565662384033203,
      "learning_rate": 9.775837418300655e-06,
      "loss": 0.2404,
      "step": 2617
    },
    {
      "epoch": 0.6015625,
      "grad_norm": 1.6297028064727783,
      "learning_rate": 9.775326797385621e-06,
      "loss": 0.249,
      "step": 2618
    },
    {
      "epoch": 0.6017922794117647,
      "grad_norm": 1.9134763479232788,
      "learning_rate": 9.774816176470589e-06,
      "loss": 0.2425,
      "step": 2619
    },
    {
      "epoch": 0.6020220588235294,
      "grad_norm": 1.2902746200561523,
      "learning_rate": 9.774305555555557e-06,
      "loss": 0.2442,
      "step": 2620
    },
    {
      "epoch": 0.6022518382352942,
      "grad_norm": 1.8575671911239624,
      "learning_rate": 9.773794934640523e-06,
      "loss": 0.2279,
      "step": 2621
    },
    {
      "epoch": 0.6024816176470589,
      "grad_norm": 1.6038864850997925,
      "learning_rate": 9.77328431372549e-06,
      "loss": 0.2485,
      "step": 2622
    },
    {
      "epoch": 0.6027113970588235,
      "grad_norm": 1.774688720703125,
      "learning_rate": 9.772773692810459e-06,
      "loss": 0.2185,
      "step": 2623
    },
    {
      "epoch": 0.6029411764705882,
      "grad_norm": 1.498372197151184,
      "learning_rate": 9.772263071895426e-06,
      "loss": 0.2105,
      "step": 2624
    },
    {
      "epoch": 0.6031709558823529,
      "grad_norm": 1.3968538045883179,
      "learning_rate": 9.771752450980393e-06,
      "loss": 0.2187,
      "step": 2625
    },
    {
      "epoch": 0.6034007352941176,
      "grad_norm": 1.4256731271743774,
      "learning_rate": 9.77124183006536e-06,
      "loss": 0.2331,
      "step": 2626
    },
    {
      "epoch": 0.6036305147058824,
      "grad_norm": 1.9285659790039062,
      "learning_rate": 9.770731209150328e-06,
      "loss": 0.2623,
      "step": 2627
    },
    {
      "epoch": 0.6038602941176471,
      "grad_norm": 2.0367815494537354,
      "learning_rate": 9.770220588235295e-06,
      "loss": 0.284,
      "step": 2628
    },
    {
      "epoch": 0.6040900735294118,
      "grad_norm": 1.7701244354248047,
      "learning_rate": 9.769709967320262e-06,
      "loss": 0.201,
      "step": 2629
    },
    {
      "epoch": 0.6043198529411765,
      "grad_norm": 1.8320039510726929,
      "learning_rate": 9.769199346405229e-06,
      "loss": 0.2285,
      "step": 2630
    },
    {
      "epoch": 0.6045496323529411,
      "grad_norm": 1.581994652748108,
      "learning_rate": 9.768688725490198e-06,
      "loss": 0.2527,
      "step": 2631
    },
    {
      "epoch": 0.6047794117647058,
      "grad_norm": 1.3763301372528076,
      "learning_rate": 9.768178104575164e-06,
      "loss": 0.2477,
      "step": 2632
    },
    {
      "epoch": 0.6050091911764706,
      "grad_norm": 1.6748119592666626,
      "learning_rate": 9.767667483660132e-06,
      "loss": 0.2363,
      "step": 2633
    },
    {
      "epoch": 0.6052389705882353,
      "grad_norm": 1.703489899635315,
      "learning_rate": 9.767156862745098e-06,
      "loss": 0.1963,
      "step": 2634
    },
    {
      "epoch": 0.60546875,
      "grad_norm": 1.5743778944015503,
      "learning_rate": 9.766646241830066e-06,
      "loss": 0.2348,
      "step": 2635
    },
    {
      "epoch": 0.6056985294117647,
      "grad_norm": 2.0134146213531494,
      "learning_rate": 9.766135620915034e-06,
      "loss": 0.2713,
      "step": 2636
    },
    {
      "epoch": 0.6059283088235294,
      "grad_norm": 1.8730430603027344,
      "learning_rate": 9.765625e-06,
      "loss": 0.3126,
      "step": 2637
    },
    {
      "epoch": 0.6061580882352942,
      "grad_norm": 1.7677568197250366,
      "learning_rate": 9.765114379084968e-06,
      "loss": 0.1774,
      "step": 2638
    },
    {
      "epoch": 0.6063878676470589,
      "grad_norm": 1.4459656476974487,
      "learning_rate": 9.764603758169934e-06,
      "loss": 0.2664,
      "step": 2639
    },
    {
      "epoch": 0.6066176470588235,
      "grad_norm": 1.8405468463897705,
      "learning_rate": 9.764093137254904e-06,
      "loss": 0.2469,
      "step": 2640
    },
    {
      "epoch": 0.6068474264705882,
      "grad_norm": 1.5453004837036133,
      "learning_rate": 9.76358251633987e-06,
      "loss": 0.2431,
      "step": 2641
    },
    {
      "epoch": 0.6070772058823529,
      "grad_norm": 1.7336608171463013,
      "learning_rate": 9.763071895424838e-06,
      "loss": 0.2531,
      "step": 2642
    },
    {
      "epoch": 0.6073069852941176,
      "grad_norm": 1.7669676542282104,
      "learning_rate": 9.762561274509804e-06,
      "loss": 0.229,
      "step": 2643
    },
    {
      "epoch": 0.6075367647058824,
      "grad_norm": 1.321494221687317,
      "learning_rate": 9.762050653594772e-06,
      "loss": 0.2455,
      "step": 2644
    },
    {
      "epoch": 0.6077665441176471,
      "grad_norm": 2.0073635578155518,
      "learning_rate": 9.76154003267974e-06,
      "loss": 0.3098,
      "step": 2645
    },
    {
      "epoch": 0.6079963235294118,
      "grad_norm": 1.7449102401733398,
      "learning_rate": 9.761029411764706e-06,
      "loss": 0.1949,
      "step": 2646
    },
    {
      "epoch": 0.6082261029411765,
      "grad_norm": 1.889375925064087,
      "learning_rate": 9.760518790849674e-06,
      "loss": 0.2461,
      "step": 2647
    },
    {
      "epoch": 0.6084558823529411,
      "grad_norm": 1.8048776388168335,
      "learning_rate": 9.760008169934642e-06,
      "loss": 0.2557,
      "step": 2648
    },
    {
      "epoch": 0.6086856617647058,
      "grad_norm": 1.6181998252868652,
      "learning_rate": 9.75949754901961e-06,
      "loss": 0.2578,
      "step": 2649
    },
    {
      "epoch": 0.6089154411764706,
      "grad_norm": 1.6613554954528809,
      "learning_rate": 9.758986928104576e-06,
      "loss": 0.2431,
      "step": 2650
    },
    {
      "epoch": 0.6091452205882353,
      "grad_norm": 1.759635090827942,
      "learning_rate": 9.758476307189543e-06,
      "loss": 0.2452,
      "step": 2651
    },
    {
      "epoch": 0.609375,
      "grad_norm": 1.6884843111038208,
      "learning_rate": 9.757965686274511e-06,
      "loss": 0.2129,
      "step": 2652
    },
    {
      "epoch": 0.6096047794117647,
      "grad_norm": 2.185634136199951,
      "learning_rate": 9.757455065359478e-06,
      "loss": 0.2536,
      "step": 2653
    },
    {
      "epoch": 0.6098345588235294,
      "grad_norm": 1.928469181060791,
      "learning_rate": 9.756944444444445e-06,
      "loss": 0.2484,
      "step": 2654
    },
    {
      "epoch": 0.6100643382352942,
      "grad_norm": 1.7493776082992554,
      "learning_rate": 9.756433823529412e-06,
      "loss": 0.2175,
      "step": 2655
    },
    {
      "epoch": 0.6102941176470589,
      "grad_norm": 1.732118844985962,
      "learning_rate": 9.75592320261438e-06,
      "loss": 0.252,
      "step": 2656
    },
    {
      "epoch": 0.6105238970588235,
      "grad_norm": 2.4531590938568115,
      "learning_rate": 9.755412581699347e-06,
      "loss": 0.3596,
      "step": 2657
    },
    {
      "epoch": 0.6107536764705882,
      "grad_norm": 2.4539554119110107,
      "learning_rate": 9.754901960784315e-06,
      "loss": 0.2693,
      "step": 2658
    },
    {
      "epoch": 0.6109834558823529,
      "grad_norm": 1.619699478149414,
      "learning_rate": 9.754391339869281e-06,
      "loss": 0.1991,
      "step": 2659
    },
    {
      "epoch": 0.6112132352941176,
      "grad_norm": 1.6194950342178345,
      "learning_rate": 9.75388071895425e-06,
      "loss": 0.2228,
      "step": 2660
    },
    {
      "epoch": 0.6114430147058824,
      "grad_norm": 1.8100299835205078,
      "learning_rate": 9.753370098039217e-06,
      "loss": 0.2481,
      "step": 2661
    },
    {
      "epoch": 0.6116727941176471,
      "grad_norm": 1.6922800540924072,
      "learning_rate": 9.752859477124183e-06,
      "loss": 0.1798,
      "step": 2662
    },
    {
      "epoch": 0.6119025735294118,
      "grad_norm": 2.3276968002319336,
      "learning_rate": 9.752348856209151e-06,
      "loss": 0.2765,
      "step": 2663
    },
    {
      "epoch": 0.6121323529411765,
      "grad_norm": 1.5210992097854614,
      "learning_rate": 9.751838235294119e-06,
      "loss": 0.2388,
      "step": 2664
    },
    {
      "epoch": 0.6123621323529411,
      "grad_norm": 2.351994752883911,
      "learning_rate": 9.751327614379085e-06,
      "loss": 0.2328,
      "step": 2665
    },
    {
      "epoch": 0.6125919117647058,
      "grad_norm": 1.5858932733535767,
      "learning_rate": 9.750816993464053e-06,
      "loss": 0.2545,
      "step": 2666
    },
    {
      "epoch": 0.6128216911764706,
      "grad_norm": 1.651920199394226,
      "learning_rate": 9.750306372549019e-06,
      "loss": 0.2773,
      "step": 2667
    },
    {
      "epoch": 0.6130514705882353,
      "grad_norm": 1.5799460411071777,
      "learning_rate": 9.749795751633989e-06,
      "loss": 0.2688,
      "step": 2668
    },
    {
      "epoch": 0.61328125,
      "grad_norm": 1.8652427196502686,
      "learning_rate": 9.749285130718955e-06,
      "loss": 0.248,
      "step": 2669
    },
    {
      "epoch": 0.6135110294117647,
      "grad_norm": 1.590218424797058,
      "learning_rate": 9.748774509803923e-06,
      "loss": 0.1737,
      "step": 2670
    },
    {
      "epoch": 0.6137408088235294,
      "grad_norm": 1.8269249200820923,
      "learning_rate": 9.748263888888889e-06,
      "loss": 0.2522,
      "step": 2671
    },
    {
      "epoch": 0.6139705882352942,
      "grad_norm": 2.3661229610443115,
      "learning_rate": 9.747753267973857e-06,
      "loss": 0.2747,
      "step": 2672
    },
    {
      "epoch": 0.6142003676470589,
      "grad_norm": 1.8280850648880005,
      "learning_rate": 9.747242647058825e-06,
      "loss": 0.2242,
      "step": 2673
    },
    {
      "epoch": 0.6144301470588235,
      "grad_norm": 1.7625634670257568,
      "learning_rate": 9.74673202614379e-06,
      "loss": 0.1889,
      "step": 2674
    },
    {
      "epoch": 0.6146599264705882,
      "grad_norm": 1.6841753721237183,
      "learning_rate": 9.746221405228759e-06,
      "loss": 0.2015,
      "step": 2675
    },
    {
      "epoch": 0.6148897058823529,
      "grad_norm": 1.6628425121307373,
      "learning_rate": 9.745710784313726e-06,
      "loss": 0.1946,
      "step": 2676
    },
    {
      "epoch": 0.6151194852941176,
      "grad_norm": 1.8350913524627686,
      "learning_rate": 9.745200163398694e-06,
      "loss": 0.2754,
      "step": 2677
    },
    {
      "epoch": 0.6153492647058824,
      "grad_norm": 2.1390984058380127,
      "learning_rate": 9.74468954248366e-06,
      "loss": 0.2891,
      "step": 2678
    },
    {
      "epoch": 0.6155790441176471,
      "grad_norm": 1.4775893688201904,
      "learning_rate": 9.744178921568628e-06,
      "loss": 0.2218,
      "step": 2679
    },
    {
      "epoch": 0.6158088235294118,
      "grad_norm": 1.641646385192871,
      "learning_rate": 9.743668300653596e-06,
      "loss": 0.1862,
      "step": 2680
    },
    {
      "epoch": 0.6160386029411765,
      "grad_norm": 1.921012282371521,
      "learning_rate": 9.743157679738562e-06,
      "loss": 0.2413,
      "step": 2681
    },
    {
      "epoch": 0.6162683823529411,
      "grad_norm": 1.4937056303024292,
      "learning_rate": 9.74264705882353e-06,
      "loss": 0.2158,
      "step": 2682
    },
    {
      "epoch": 0.6164981617647058,
      "grad_norm": 1.4727931022644043,
      "learning_rate": 9.742136437908496e-06,
      "loss": 0.2236,
      "step": 2683
    },
    {
      "epoch": 0.6167279411764706,
      "grad_norm": 1.4311319589614868,
      "learning_rate": 9.741625816993466e-06,
      "loss": 0.2034,
      "step": 2684
    },
    {
      "epoch": 0.6169577205882353,
      "grad_norm": 1.7641233205795288,
      "learning_rate": 9.741115196078432e-06,
      "loss": 0.2041,
      "step": 2685
    },
    {
      "epoch": 0.6171875,
      "grad_norm": 1.7347800731658936,
      "learning_rate": 9.7406045751634e-06,
      "loss": 0.2102,
      "step": 2686
    },
    {
      "epoch": 0.6174172794117647,
      "grad_norm": 1.8907856941223145,
      "learning_rate": 9.740093954248366e-06,
      "loss": 0.2531,
      "step": 2687
    },
    {
      "epoch": 0.6176470588235294,
      "grad_norm": 1.5849597454071045,
      "learning_rate": 9.739583333333334e-06,
      "loss": 0.1899,
      "step": 2688
    },
    {
      "epoch": 0.6178768382352942,
      "grad_norm": 1.8343592882156372,
      "learning_rate": 9.739072712418302e-06,
      "loss": 0.1981,
      "step": 2689
    },
    {
      "epoch": 0.6181066176470589,
      "grad_norm": 1.79147469997406,
      "learning_rate": 9.738562091503268e-06,
      "loss": 0.2563,
      "step": 2690
    },
    {
      "epoch": 0.6183363970588235,
      "grad_norm": 1.9320344924926758,
      "learning_rate": 9.738051470588236e-06,
      "loss": 0.2488,
      "step": 2691
    },
    {
      "epoch": 0.6185661764705882,
      "grad_norm": 1.5633244514465332,
      "learning_rate": 9.737540849673204e-06,
      "loss": 0.1928,
      "step": 2692
    },
    {
      "epoch": 0.6187959558823529,
      "grad_norm": 1.7064907550811768,
      "learning_rate": 9.737030228758172e-06,
      "loss": 0.2521,
      "step": 2693
    },
    {
      "epoch": 0.6190257352941176,
      "grad_norm": 2.089186668395996,
      "learning_rate": 9.736519607843138e-06,
      "loss": 0.2486,
      "step": 2694
    },
    {
      "epoch": 0.6192555147058824,
      "grad_norm": 1.4731136560440063,
      "learning_rate": 9.736008986928106e-06,
      "loss": 0.2155,
      "step": 2695
    },
    {
      "epoch": 0.6194852941176471,
      "grad_norm": 1.7133246660232544,
      "learning_rate": 9.735498366013074e-06,
      "loss": 0.2153,
      "step": 2696
    },
    {
      "epoch": 0.6197150735294118,
      "grad_norm": 1.6731722354888916,
      "learning_rate": 9.73498774509804e-06,
      "loss": 0.2258,
      "step": 2697
    },
    {
      "epoch": 0.6199448529411765,
      "grad_norm": 1.8796336650848389,
      "learning_rate": 9.734477124183008e-06,
      "loss": 0.2677,
      "step": 2698
    },
    {
      "epoch": 0.6201746323529411,
      "grad_norm": 1.6929341554641724,
      "learning_rate": 9.733966503267974e-06,
      "loss": 0.2299,
      "step": 2699
    },
    {
      "epoch": 0.6204044117647058,
      "grad_norm": 1.4837433099746704,
      "learning_rate": 9.733455882352942e-06,
      "loss": 0.2458,
      "step": 2700
    },
    {
      "epoch": 0.6206341911764706,
      "grad_norm": 1.670107364654541,
      "learning_rate": 9.73294526143791e-06,
      "loss": 0.2904,
      "step": 2701
    },
    {
      "epoch": 0.6208639705882353,
      "grad_norm": 1.6675697565078735,
      "learning_rate": 9.732434640522876e-06,
      "loss": 0.2343,
      "step": 2702
    },
    {
      "epoch": 0.62109375,
      "grad_norm": 2.7064056396484375,
      "learning_rate": 9.731924019607843e-06,
      "loss": 0.2619,
      "step": 2703
    },
    {
      "epoch": 0.6213235294117647,
      "grad_norm": 1.6810059547424316,
      "learning_rate": 9.731413398692811e-06,
      "loss": 0.2051,
      "step": 2704
    },
    {
      "epoch": 0.6215533088235294,
      "grad_norm": 1.70405912399292,
      "learning_rate": 9.73090277777778e-06,
      "loss": 0.1946,
      "step": 2705
    },
    {
      "epoch": 0.6217830882352942,
      "grad_norm": 1.5969659090042114,
      "learning_rate": 9.730392156862745e-06,
      "loss": 0.2015,
      "step": 2706
    },
    {
      "epoch": 0.6220128676470589,
      "grad_norm": 1.7639973163604736,
      "learning_rate": 9.729881535947713e-06,
      "loss": 0.1877,
      "step": 2707
    },
    {
      "epoch": 0.6222426470588235,
      "grad_norm": 1.9160568714141846,
      "learning_rate": 9.729370915032681e-06,
      "loss": 0.2619,
      "step": 2708
    },
    {
      "epoch": 0.6224724264705882,
      "grad_norm": 1.4811595678329468,
      "learning_rate": 9.728860294117647e-06,
      "loss": 0.2113,
      "step": 2709
    },
    {
      "epoch": 0.6227022058823529,
      "grad_norm": 1.6305339336395264,
      "learning_rate": 9.728349673202615e-06,
      "loss": 0.2567,
      "step": 2710
    },
    {
      "epoch": 0.6229319852941176,
      "grad_norm": 1.9521926641464233,
      "learning_rate": 9.727839052287581e-06,
      "loss": 0.2072,
      "step": 2711
    },
    {
      "epoch": 0.6231617647058824,
      "grad_norm": 1.697717308998108,
      "learning_rate": 9.727328431372551e-06,
      "loss": 0.2406,
      "step": 2712
    },
    {
      "epoch": 0.6233915441176471,
      "grad_norm": 1.6554851531982422,
      "learning_rate": 9.726817810457517e-06,
      "loss": 0.2212,
      "step": 2713
    },
    {
      "epoch": 0.6236213235294118,
      "grad_norm": 1.635208010673523,
      "learning_rate": 9.726307189542485e-06,
      "loss": 0.1428,
      "step": 2714
    },
    {
      "epoch": 0.6238511029411765,
      "grad_norm": 1.4572408199310303,
      "learning_rate": 9.725796568627451e-06,
      "loss": 0.2362,
      "step": 2715
    },
    {
      "epoch": 0.6240808823529411,
      "grad_norm": 1.7119543552398682,
      "learning_rate": 9.725285947712419e-06,
      "loss": 0.26,
      "step": 2716
    },
    {
      "epoch": 0.6243106617647058,
      "grad_norm": 1.5803533792495728,
      "learning_rate": 9.724775326797387e-06,
      "loss": 0.2178,
      "step": 2717
    },
    {
      "epoch": 0.6245404411764706,
      "grad_norm": 1.7466566562652588,
      "learning_rate": 9.724264705882353e-06,
      "loss": 0.2641,
      "step": 2718
    },
    {
      "epoch": 0.6247702205882353,
      "grad_norm": 1.305985927581787,
      "learning_rate": 9.72375408496732e-06,
      "loss": 0.2573,
      "step": 2719
    },
    {
      "epoch": 0.625,
      "grad_norm": 1.4343335628509521,
      "learning_rate": 9.723243464052289e-06,
      "loss": 0.2511,
      "step": 2720
    },
    {
      "epoch": 0.6252297794117647,
      "grad_norm": 1.4631181955337524,
      "learning_rate": 9.722732843137257e-06,
      "loss": 0.2512,
      "step": 2721
    },
    {
      "epoch": 0.6254595588235294,
      "grad_norm": 1.8556891679763794,
      "learning_rate": 9.722222222222223e-06,
      "loss": 0.2974,
      "step": 2722
    },
    {
      "epoch": 0.6256893382352942,
      "grad_norm": 1.6046191453933716,
      "learning_rate": 9.72171160130719e-06,
      "loss": 0.2473,
      "step": 2723
    },
    {
      "epoch": 0.6259191176470589,
      "grad_norm": 2.0384371280670166,
      "learning_rate": 9.721200980392158e-06,
      "loss": 0.2331,
      "step": 2724
    },
    {
      "epoch": 0.6261488970588235,
      "grad_norm": 1.8462899923324585,
      "learning_rate": 9.720690359477125e-06,
      "loss": 0.2458,
      "step": 2725
    },
    {
      "epoch": 0.6263786764705882,
      "grad_norm": 2.047565460205078,
      "learning_rate": 9.720179738562092e-06,
      "loss": 0.227,
      "step": 2726
    },
    {
      "epoch": 0.6266084558823529,
      "grad_norm": 1.5835920572280884,
      "learning_rate": 9.719669117647059e-06,
      "loss": 0.2486,
      "step": 2727
    },
    {
      "epoch": 0.6268382352941176,
      "grad_norm": 1.7611497640609741,
      "learning_rate": 9.719158496732028e-06,
      "loss": 0.2174,
      "step": 2728
    },
    {
      "epoch": 0.6270680147058824,
      "grad_norm": 1.8192157745361328,
      "learning_rate": 9.718647875816994e-06,
      "loss": 0.2709,
      "step": 2729
    },
    {
      "epoch": 0.6272977941176471,
      "grad_norm": 1.8273587226867676,
      "learning_rate": 9.718137254901962e-06,
      "loss": 0.2469,
      "step": 2730
    },
    {
      "epoch": 0.6275275735294118,
      "grad_norm": 1.8327654600143433,
      "learning_rate": 9.717626633986928e-06,
      "loss": 0.2336,
      "step": 2731
    },
    {
      "epoch": 0.6277573529411765,
      "grad_norm": 1.6058984994888306,
      "learning_rate": 9.717116013071896e-06,
      "loss": 0.2165,
      "step": 2732
    },
    {
      "epoch": 0.6279871323529411,
      "grad_norm": 1.1476351022720337,
      "learning_rate": 9.716605392156864e-06,
      "loss": 0.1748,
      "step": 2733
    },
    {
      "epoch": 0.6282169117647058,
      "grad_norm": 1.778479814529419,
      "learning_rate": 9.71609477124183e-06,
      "loss": 0.1969,
      "step": 2734
    },
    {
      "epoch": 0.6284466911764706,
      "grad_norm": 1.568969964981079,
      "learning_rate": 9.715584150326798e-06,
      "loss": 0.198,
      "step": 2735
    },
    {
      "epoch": 0.6286764705882353,
      "grad_norm": 1.6807039976119995,
      "learning_rate": 9.715073529411766e-06,
      "loss": 0.2443,
      "step": 2736
    },
    {
      "epoch": 0.62890625,
      "grad_norm": 1.8962637186050415,
      "learning_rate": 9.714562908496734e-06,
      "loss": 0.2405,
      "step": 2737
    },
    {
      "epoch": 0.6291360294117647,
      "grad_norm": 1.9066879749298096,
      "learning_rate": 9.7140522875817e-06,
      "loss": 0.2172,
      "step": 2738
    },
    {
      "epoch": 0.6293658088235294,
      "grad_norm": 1.500161051750183,
      "learning_rate": 9.713541666666668e-06,
      "loss": 0.2149,
      "step": 2739
    },
    {
      "epoch": 0.6295955882352942,
      "grad_norm": 1.463432788848877,
      "learning_rate": 9.713031045751636e-06,
      "loss": 0.1942,
      "step": 2740
    },
    {
      "epoch": 0.6298253676470589,
      "grad_norm": 1.8492120504379272,
      "learning_rate": 9.712520424836602e-06,
      "loss": 0.3113,
      "step": 2741
    },
    {
      "epoch": 0.6300551470588235,
      "grad_norm": 1.2488949298858643,
      "learning_rate": 9.71200980392157e-06,
      "loss": 0.2036,
      "step": 2742
    },
    {
      "epoch": 0.6302849264705882,
      "grad_norm": 2.122567653656006,
      "learning_rate": 9.711499183006536e-06,
      "loss": 0.2988,
      "step": 2743
    },
    {
      "epoch": 0.6305147058823529,
      "grad_norm": 1.7366849184036255,
      "learning_rate": 9.710988562091504e-06,
      "loss": 0.2816,
      "step": 2744
    },
    {
      "epoch": 0.6307444852941176,
      "grad_norm": 1.5990256071090698,
      "learning_rate": 9.710477941176472e-06,
      "loss": 0.2476,
      "step": 2745
    },
    {
      "epoch": 0.6309742647058824,
      "grad_norm": 1.6188913583755493,
      "learning_rate": 9.709967320261438e-06,
      "loss": 0.218,
      "step": 2746
    },
    {
      "epoch": 0.6312040441176471,
      "grad_norm": 1.5066845417022705,
      "learning_rate": 9.709456699346406e-06,
      "loss": 0.1982,
      "step": 2747
    },
    {
      "epoch": 0.6314338235294118,
      "grad_norm": 1.9130278825759888,
      "learning_rate": 9.708946078431374e-06,
      "loss": 0.2434,
      "step": 2748
    },
    {
      "epoch": 0.6316636029411765,
      "grad_norm": 1.517277717590332,
      "learning_rate": 9.708435457516341e-06,
      "loss": 0.2507,
      "step": 2749
    },
    {
      "epoch": 0.6318933823529411,
      "grad_norm": 1.3442097902297974,
      "learning_rate": 9.707924836601308e-06,
      "loss": 0.2,
      "step": 2750
    },
    {
      "epoch": 0.6321231617647058,
      "grad_norm": 2.202596664428711,
      "learning_rate": 9.707414215686275e-06,
      "loss": 0.2715,
      "step": 2751
    },
    {
      "epoch": 0.6323529411764706,
      "grad_norm": 1.4045450687408447,
      "learning_rate": 9.706903594771243e-06,
      "loss": 0.2173,
      "step": 2752
    },
    {
      "epoch": 0.6325827205882353,
      "grad_norm": 1.6435996294021606,
      "learning_rate": 9.70639297385621e-06,
      "loss": 0.2052,
      "step": 2753
    },
    {
      "epoch": 0.6328125,
      "grad_norm": 1.7315319776535034,
      "learning_rate": 9.705882352941177e-06,
      "loss": 0.273,
      "step": 2754
    },
    {
      "epoch": 0.6330422794117647,
      "grad_norm": 1.970940351486206,
      "learning_rate": 9.705371732026143e-06,
      "loss": 0.2559,
      "step": 2755
    },
    {
      "epoch": 0.6332720588235294,
      "grad_norm": 2.0366811752319336,
      "learning_rate": 9.704861111111113e-06,
      "loss": 0.2934,
      "step": 2756
    },
    {
      "epoch": 0.6335018382352942,
      "grad_norm": 1.9998142719268799,
      "learning_rate": 9.70435049019608e-06,
      "loss": 0.2261,
      "step": 2757
    },
    {
      "epoch": 0.6337316176470589,
      "grad_norm": 1.8666496276855469,
      "learning_rate": 9.703839869281047e-06,
      "loss": 0.2549,
      "step": 2758
    },
    {
      "epoch": 0.6339613970588235,
      "grad_norm": 1.8582154512405396,
      "learning_rate": 9.703329248366013e-06,
      "loss": 0.2397,
      "step": 2759
    },
    {
      "epoch": 0.6341911764705882,
      "grad_norm": 1.5154486894607544,
      "learning_rate": 9.702818627450981e-06,
      "loss": 0.2175,
      "step": 2760
    },
    {
      "epoch": 0.6344209558823529,
      "grad_norm": 1.8142402172088623,
      "learning_rate": 9.702308006535949e-06,
      "loss": 0.2635,
      "step": 2761
    },
    {
      "epoch": 0.6346507352941176,
      "grad_norm": 1.5090508460998535,
      "learning_rate": 9.701797385620915e-06,
      "loss": 0.2066,
      "step": 2762
    },
    {
      "epoch": 0.6348805147058824,
      "grad_norm": 1.6010323762893677,
      "learning_rate": 9.701286764705883e-06,
      "loss": 0.206,
      "step": 2763
    },
    {
      "epoch": 0.6351102941176471,
      "grad_norm": 2.0217339992523193,
      "learning_rate": 9.70077614379085e-06,
      "loss": 0.2271,
      "step": 2764
    },
    {
      "epoch": 0.6353400735294118,
      "grad_norm": 1.6711974143981934,
      "learning_rate": 9.700265522875819e-06,
      "loss": 0.1958,
      "step": 2765
    },
    {
      "epoch": 0.6355698529411765,
      "grad_norm": 1.4993600845336914,
      "learning_rate": 9.699754901960785e-06,
      "loss": 0.2016,
      "step": 2766
    },
    {
      "epoch": 0.6357996323529411,
      "grad_norm": 1.7663888931274414,
      "learning_rate": 9.699244281045753e-06,
      "loss": 0.2026,
      "step": 2767
    },
    {
      "epoch": 0.6360294117647058,
      "grad_norm": 1.3136980533599854,
      "learning_rate": 9.69873366013072e-06,
      "loss": 0.1896,
      "step": 2768
    },
    {
      "epoch": 0.6362591911764706,
      "grad_norm": 1.8470004796981812,
      "learning_rate": 9.698223039215687e-06,
      "loss": 0.2195,
      "step": 2769
    },
    {
      "epoch": 0.6364889705882353,
      "grad_norm": 1.5668894052505493,
      "learning_rate": 9.697712418300655e-06,
      "loss": 0.2064,
      "step": 2770
    },
    {
      "epoch": 0.63671875,
      "grad_norm": 1.6395083665847778,
      "learning_rate": 9.69720179738562e-06,
      "loss": 0.2587,
      "step": 2771
    },
    {
      "epoch": 0.6369485294117647,
      "grad_norm": 1.9482684135437012,
      "learning_rate": 9.69669117647059e-06,
      "loss": 0.2182,
      "step": 2772
    },
    {
      "epoch": 0.6371783088235294,
      "grad_norm": 1.9590421915054321,
      "learning_rate": 9.696180555555557e-06,
      "loss": 0.2431,
      "step": 2773
    },
    {
      "epoch": 0.6374080882352942,
      "grad_norm": 1.9833811521530151,
      "learning_rate": 9.695669934640524e-06,
      "loss": 0.2136,
      "step": 2774
    },
    {
      "epoch": 0.6376378676470589,
      "grad_norm": 1.6551052331924438,
      "learning_rate": 9.69515931372549e-06,
      "loss": 0.2384,
      "step": 2775
    },
    {
      "epoch": 0.6378676470588235,
      "grad_norm": 1.6915193796157837,
      "learning_rate": 9.694648692810458e-06,
      "loss": 0.2164,
      "step": 2776
    },
    {
      "epoch": 0.6380974264705882,
      "grad_norm": 1.898797631263733,
      "learning_rate": 9.694138071895426e-06,
      "loss": 0.1847,
      "step": 2777
    },
    {
      "epoch": 0.6383272058823529,
      "grad_norm": 1.6700055599212646,
      "learning_rate": 9.693627450980392e-06,
      "loss": 0.2093,
      "step": 2778
    },
    {
      "epoch": 0.6385569852941176,
      "grad_norm": 1.5886943340301514,
      "learning_rate": 9.69311683006536e-06,
      "loss": 0.2361,
      "step": 2779
    },
    {
      "epoch": 0.6387867647058824,
      "grad_norm": 1.4318969249725342,
      "learning_rate": 9.692606209150328e-06,
      "loss": 0.1988,
      "step": 2780
    },
    {
      "epoch": 0.6390165441176471,
      "grad_norm": 1.9920676946640015,
      "learning_rate": 9.692095588235294e-06,
      "loss": 0.2551,
      "step": 2781
    },
    {
      "epoch": 0.6392463235294118,
      "grad_norm": 1.6972931623458862,
      "learning_rate": 9.691584967320262e-06,
      "loss": 0.2343,
      "step": 2782
    },
    {
      "epoch": 0.6394761029411765,
      "grad_norm": 1.7009353637695312,
      "learning_rate": 9.69107434640523e-06,
      "loss": 0.2589,
      "step": 2783
    },
    {
      "epoch": 0.6397058823529411,
      "grad_norm": 2.0553462505340576,
      "learning_rate": 9.690563725490198e-06,
      "loss": 0.2462,
      "step": 2784
    },
    {
      "epoch": 0.6399356617647058,
      "grad_norm": 1.7014344930648804,
      "learning_rate": 9.690053104575164e-06,
      "loss": 0.218,
      "step": 2785
    },
    {
      "epoch": 0.6401654411764706,
      "grad_norm": 1.3224916458129883,
      "learning_rate": 9.689542483660132e-06,
      "loss": 0.2397,
      "step": 2786
    },
    {
      "epoch": 0.6403952205882353,
      "grad_norm": 1.4540494680404663,
      "learning_rate": 9.689031862745098e-06,
      "loss": 0.2025,
      "step": 2787
    },
    {
      "epoch": 0.640625,
      "grad_norm": 1.6260753870010376,
      "learning_rate": 9.688521241830066e-06,
      "loss": 0.2342,
      "step": 2788
    },
    {
      "epoch": 0.6408547794117647,
      "grad_norm": 2.0445635318756104,
      "learning_rate": 9.688010620915034e-06,
      "loss": 0.2525,
      "step": 2789
    },
    {
      "epoch": 0.6410845588235294,
      "grad_norm": 1.9253323078155518,
      "learning_rate": 9.6875e-06,
      "loss": 0.2203,
      "step": 2790
    },
    {
      "epoch": 0.6413143382352942,
      "grad_norm": 1.5555391311645508,
      "learning_rate": 9.686989379084968e-06,
      "loss": 0.2164,
      "step": 2791
    },
    {
      "epoch": 0.6415441176470589,
      "grad_norm": 1.8668029308319092,
      "learning_rate": 9.686478758169936e-06,
      "loss": 0.1816,
      "step": 2792
    },
    {
      "epoch": 0.6417738970588235,
      "grad_norm": 1.5325642824172974,
      "learning_rate": 9.685968137254904e-06,
      "loss": 0.2088,
      "step": 2793
    },
    {
      "epoch": 0.6420036764705882,
      "grad_norm": 1.7653402090072632,
      "learning_rate": 9.68545751633987e-06,
      "loss": 0.253,
      "step": 2794
    },
    {
      "epoch": 0.6422334558823529,
      "grad_norm": 1.5880792140960693,
      "learning_rate": 9.684946895424838e-06,
      "loss": 0.1719,
      "step": 2795
    },
    {
      "epoch": 0.6424632352941176,
      "grad_norm": 1.4427272081375122,
      "learning_rate": 9.684436274509804e-06,
      "loss": 0.2196,
      "step": 2796
    },
    {
      "epoch": 0.6426930147058824,
      "grad_norm": 1.9255905151367188,
      "learning_rate": 9.683925653594772e-06,
      "loss": 0.2823,
      "step": 2797
    },
    {
      "epoch": 0.6429227941176471,
      "grad_norm": 1.5216155052185059,
      "learning_rate": 9.68341503267974e-06,
      "loss": 0.2113,
      "step": 2798
    },
    {
      "epoch": 0.6431525735294118,
      "grad_norm": 1.4253981113433838,
      "learning_rate": 9.682904411764706e-06,
      "loss": 0.2359,
      "step": 2799
    },
    {
      "epoch": 0.6433823529411765,
      "grad_norm": 1.700452446937561,
      "learning_rate": 9.682393790849674e-06,
      "loss": 0.2424,
      "step": 2800
    },
    {
      "epoch": 0.6436121323529411,
      "grad_norm": 1.4594160318374634,
      "learning_rate": 9.681883169934641e-06,
      "loss": 0.2391,
      "step": 2801
    },
    {
      "epoch": 0.6438419117647058,
      "grad_norm": 1.717443823814392,
      "learning_rate": 9.68137254901961e-06,
      "loss": 0.2277,
      "step": 2802
    },
    {
      "epoch": 0.6440716911764706,
      "grad_norm": 1.7015113830566406,
      "learning_rate": 9.680861928104575e-06,
      "loss": 0.1579,
      "step": 2803
    },
    {
      "epoch": 0.6443014705882353,
      "grad_norm": 2.1309356689453125,
      "learning_rate": 9.680351307189543e-06,
      "loss": 0.1966,
      "step": 2804
    },
    {
      "epoch": 0.64453125,
      "grad_norm": 2.2011044025421143,
      "learning_rate": 9.679840686274511e-06,
      "loss": 0.2102,
      "step": 2805
    },
    {
      "epoch": 0.6447610294117647,
      "grad_norm": 2.0443108081817627,
      "learning_rate": 9.679330065359477e-06,
      "loss": 0.2875,
      "step": 2806
    },
    {
      "epoch": 0.6449908088235294,
      "grad_norm": 1.7985944747924805,
      "learning_rate": 9.678819444444445e-06,
      "loss": 0.2483,
      "step": 2807
    },
    {
      "epoch": 0.6452205882352942,
      "grad_norm": 1.6469658613204956,
      "learning_rate": 9.678308823529411e-06,
      "loss": 0.2123,
      "step": 2808
    },
    {
      "epoch": 0.6454503676470589,
      "grad_norm": 1.9489434957504272,
      "learning_rate": 9.677798202614381e-06,
      "loss": 0.2334,
      "step": 2809
    },
    {
      "epoch": 0.6456801470588235,
      "grad_norm": 2.155787467956543,
      "learning_rate": 9.677287581699347e-06,
      "loss": 0.225,
      "step": 2810
    },
    {
      "epoch": 0.6459099264705882,
      "grad_norm": 1.8391999006271362,
      "learning_rate": 9.676776960784315e-06,
      "loss": 0.2159,
      "step": 2811
    },
    {
      "epoch": 0.6461397058823529,
      "grad_norm": 1.9842352867126465,
      "learning_rate": 9.676266339869281e-06,
      "loss": 0.2092,
      "step": 2812
    },
    {
      "epoch": 0.6463694852941176,
      "grad_norm": 1.7354837656021118,
      "learning_rate": 9.675755718954249e-06,
      "loss": 0.2363,
      "step": 2813
    },
    {
      "epoch": 0.6465992647058824,
      "grad_norm": 1.6944297552108765,
      "learning_rate": 9.675245098039217e-06,
      "loss": 0.1886,
      "step": 2814
    },
    {
      "epoch": 0.6468290441176471,
      "grad_norm": 2.1049084663391113,
      "learning_rate": 9.674734477124183e-06,
      "loss": 0.1926,
      "step": 2815
    },
    {
      "epoch": 0.6470588235294118,
      "grad_norm": 1.7441987991333008,
      "learning_rate": 9.67422385620915e-06,
      "loss": 0.1871,
      "step": 2816
    },
    {
      "epoch": 0.6472886029411765,
      "grad_norm": 1.615020751953125,
      "learning_rate": 9.673713235294119e-06,
      "loss": 0.2151,
      "step": 2817
    },
    {
      "epoch": 0.6475183823529411,
      "grad_norm": 1.404362440109253,
      "learning_rate": 9.673202614379087e-06,
      "loss": 0.169,
      "step": 2818
    },
    {
      "epoch": 0.6477481617647058,
      "grad_norm": 1.6823718547821045,
      "learning_rate": 9.672691993464053e-06,
      "loss": 0.1973,
      "step": 2819
    },
    {
      "epoch": 0.6479779411764706,
      "grad_norm": 1.884140968322754,
      "learning_rate": 9.67218137254902e-06,
      "loss": 0.2011,
      "step": 2820
    },
    {
      "epoch": 0.6482077205882353,
      "grad_norm": 1.7414191961288452,
      "learning_rate": 9.671670751633988e-06,
      "loss": 0.1674,
      "step": 2821
    },
    {
      "epoch": 0.6484375,
      "grad_norm": 1.59730064868927,
      "learning_rate": 9.671160130718955e-06,
      "loss": 0.2512,
      "step": 2822
    },
    {
      "epoch": 0.6486672794117647,
      "grad_norm": 1.4705893993377686,
      "learning_rate": 9.670649509803922e-06,
      "loss": 0.2144,
      "step": 2823
    },
    {
      "epoch": 0.6488970588235294,
      "grad_norm": 1.8157328367233276,
      "learning_rate": 9.670138888888889e-06,
      "loss": 0.2472,
      "step": 2824
    },
    {
      "epoch": 0.6491268382352942,
      "grad_norm": 1.6775741577148438,
      "learning_rate": 9.669628267973857e-06,
      "loss": 0.2299,
      "step": 2825
    },
    {
      "epoch": 0.6493566176470589,
      "grad_norm": 1.6039795875549316,
      "learning_rate": 9.669117647058824e-06,
      "loss": 0.2214,
      "step": 2826
    },
    {
      "epoch": 0.6495863970588235,
      "grad_norm": 1.4379220008850098,
      "learning_rate": 9.668607026143792e-06,
      "loss": 0.1915,
      "step": 2827
    },
    {
      "epoch": 0.6498161764705882,
      "grad_norm": 1.8121893405914307,
      "learning_rate": 9.668096405228758e-06,
      "loss": 0.2638,
      "step": 2828
    },
    {
      "epoch": 0.6500459558823529,
      "grad_norm": 1.5829436779022217,
      "learning_rate": 9.667585784313726e-06,
      "loss": 0.1582,
      "step": 2829
    },
    {
      "epoch": 0.6502757352941176,
      "grad_norm": 1.538140058517456,
      "learning_rate": 9.667075163398694e-06,
      "loss": 0.2027,
      "step": 2830
    },
    {
      "epoch": 0.6505055147058824,
      "grad_norm": 1.5161782503128052,
      "learning_rate": 9.66656454248366e-06,
      "loss": 0.1917,
      "step": 2831
    },
    {
      "epoch": 0.6507352941176471,
      "grad_norm": 2.034311532974243,
      "learning_rate": 9.666053921568628e-06,
      "loss": 0.269,
      "step": 2832
    },
    {
      "epoch": 0.6509650735294118,
      "grad_norm": 1.7030187845230103,
      "learning_rate": 9.665543300653596e-06,
      "loss": 0.2141,
      "step": 2833
    },
    {
      "epoch": 0.6511948529411765,
      "grad_norm": 2.0235440731048584,
      "learning_rate": 9.665032679738562e-06,
      "loss": 0.2403,
      "step": 2834
    },
    {
      "epoch": 0.6514246323529411,
      "grad_norm": 1.919152855873108,
      "learning_rate": 9.66452205882353e-06,
      "loss": 0.1988,
      "step": 2835
    },
    {
      "epoch": 0.6516544117647058,
      "grad_norm": 1.7399897575378418,
      "learning_rate": 9.664011437908496e-06,
      "loss": 0.2017,
      "step": 2836
    },
    {
      "epoch": 0.6518841911764706,
      "grad_norm": 1.6720293760299683,
      "learning_rate": 9.663500816993466e-06,
      "loss": 0.2101,
      "step": 2837
    },
    {
      "epoch": 0.6521139705882353,
      "grad_norm": 1.5902302265167236,
      "learning_rate": 9.662990196078432e-06,
      "loss": 0.2649,
      "step": 2838
    },
    {
      "epoch": 0.65234375,
      "grad_norm": 2.183107852935791,
      "learning_rate": 9.6624795751634e-06,
      "loss": 0.2766,
      "step": 2839
    },
    {
      "epoch": 0.6525735294117647,
      "grad_norm": 1.4461772441864014,
      "learning_rate": 9.661968954248366e-06,
      "loss": 0.1995,
      "step": 2840
    },
    {
      "epoch": 0.6528033088235294,
      "grad_norm": 1.7760272026062012,
      "learning_rate": 9.661458333333334e-06,
      "loss": 0.1642,
      "step": 2841
    },
    {
      "epoch": 0.6530330882352942,
      "grad_norm": 1.3112927675247192,
      "learning_rate": 9.660947712418302e-06,
      "loss": 0.2046,
      "step": 2842
    },
    {
      "epoch": 0.6532628676470589,
      "grad_norm": 1.4842658042907715,
      "learning_rate": 9.660437091503268e-06,
      "loss": 0.1992,
      "step": 2843
    },
    {
      "epoch": 0.6534926470588235,
      "grad_norm": 2.084031343460083,
      "learning_rate": 9.659926470588236e-06,
      "loss": 0.2567,
      "step": 2844
    },
    {
      "epoch": 0.6537224264705882,
      "grad_norm": 1.99703049659729,
      "learning_rate": 9.659415849673204e-06,
      "loss": 0.2371,
      "step": 2845
    },
    {
      "epoch": 0.6539522058823529,
      "grad_norm": 1.9908082485198975,
      "learning_rate": 9.658905228758171e-06,
      "loss": 0.2226,
      "step": 2846
    },
    {
      "epoch": 0.6541819852941176,
      "grad_norm": 1.977665662765503,
      "learning_rate": 9.658394607843138e-06,
      "loss": 0.1941,
      "step": 2847
    },
    {
      "epoch": 0.6544117647058824,
      "grad_norm": 2.0657057762145996,
      "learning_rate": 9.657883986928105e-06,
      "loss": 0.2041,
      "step": 2848
    },
    {
      "epoch": 0.6546415441176471,
      "grad_norm": 1.8479278087615967,
      "learning_rate": 9.657373366013073e-06,
      "loss": 0.2144,
      "step": 2849
    },
    {
      "epoch": 0.6548713235294118,
      "grad_norm": 1.6636364459991455,
      "learning_rate": 9.65686274509804e-06,
      "loss": 0.2169,
      "step": 2850
    },
    {
      "epoch": 0.6551011029411765,
      "grad_norm": 1.8215599060058594,
      "learning_rate": 9.656352124183007e-06,
      "loss": 0.2092,
      "step": 2851
    },
    {
      "epoch": 0.6553308823529411,
      "grad_norm": 1.7118570804595947,
      "learning_rate": 9.655841503267974e-06,
      "loss": 0.2054,
      "step": 2852
    },
    {
      "epoch": 0.6555606617647058,
      "grad_norm": 1.918149709701538,
      "learning_rate": 9.655330882352943e-06,
      "loss": 0.1986,
      "step": 2853
    },
    {
      "epoch": 0.6557904411764706,
      "grad_norm": 1.6998658180236816,
      "learning_rate": 9.65482026143791e-06,
      "loss": 0.2479,
      "step": 2854
    },
    {
      "epoch": 0.6560202205882353,
      "grad_norm": 1.4568936824798584,
      "learning_rate": 9.654309640522877e-06,
      "loss": 0.265,
      "step": 2855
    },
    {
      "epoch": 0.65625,
      "grad_norm": 1.3269692659378052,
      "learning_rate": 9.653799019607843e-06,
      "loss": 0.1915,
      "step": 2856
    },
    {
      "epoch": 0.6564797794117647,
      "grad_norm": 2.128962516784668,
      "learning_rate": 9.653288398692811e-06,
      "loss": 0.2112,
      "step": 2857
    },
    {
      "epoch": 0.6567095588235294,
      "grad_norm": 1.815634846687317,
      "learning_rate": 9.652777777777779e-06,
      "loss": 0.2037,
      "step": 2858
    },
    {
      "epoch": 0.6569393382352942,
      "grad_norm": 1.909662127494812,
      "learning_rate": 9.652267156862745e-06,
      "loss": 0.2502,
      "step": 2859
    },
    {
      "epoch": 0.6571691176470589,
      "grad_norm": 1.9275825023651123,
      "learning_rate": 9.651756535947713e-06,
      "loss": 0.2198,
      "step": 2860
    },
    {
      "epoch": 0.6573988970588235,
      "grad_norm": 1.4165698289871216,
      "learning_rate": 9.651245915032681e-06,
      "loss": 0.1777,
      "step": 2861
    },
    {
      "epoch": 0.6576286764705882,
      "grad_norm": 1.5941909551620483,
      "learning_rate": 9.650735294117649e-06,
      "loss": 0.2255,
      "step": 2862
    },
    {
      "epoch": 0.6578584558823529,
      "grad_norm": 1.5085281133651733,
      "learning_rate": 9.650224673202615e-06,
      "loss": 0.1967,
      "step": 2863
    },
    {
      "epoch": 0.6580882352941176,
      "grad_norm": 2.087705373764038,
      "learning_rate": 9.649714052287583e-06,
      "loss": 0.2175,
      "step": 2864
    },
    {
      "epoch": 0.6583180147058824,
      "grad_norm": 1.6482648849487305,
      "learning_rate": 9.64920343137255e-06,
      "loss": 0.1982,
      "step": 2865
    },
    {
      "epoch": 0.6585477941176471,
      "grad_norm": 1.7269611358642578,
      "learning_rate": 9.648692810457517e-06,
      "loss": 0.2245,
      "step": 2866
    },
    {
      "epoch": 0.6587775735294118,
      "grad_norm": 1.553652286529541,
      "learning_rate": 9.648182189542485e-06,
      "loss": 0.2463,
      "step": 2867
    },
    {
      "epoch": 0.6590073529411765,
      "grad_norm": 2.0095858573913574,
      "learning_rate": 9.64767156862745e-06,
      "loss": 0.2681,
      "step": 2868
    },
    {
      "epoch": 0.6592371323529411,
      "grad_norm": 1.1088619232177734,
      "learning_rate": 9.647160947712419e-06,
      "loss": 0.1762,
      "step": 2869
    },
    {
      "epoch": 0.6594669117647058,
      "grad_norm": 1.548664927482605,
      "learning_rate": 9.646650326797387e-06,
      "loss": 0.2253,
      "step": 2870
    },
    {
      "epoch": 0.6596966911764706,
      "grad_norm": 1.6326165199279785,
      "learning_rate": 9.646139705882354e-06,
      "loss": 0.2093,
      "step": 2871
    },
    {
      "epoch": 0.6599264705882353,
      "grad_norm": 1.324143886566162,
      "learning_rate": 9.64562908496732e-06,
      "loss": 0.157,
      "step": 2872
    },
    {
      "epoch": 0.66015625,
      "grad_norm": 1.8867151737213135,
      "learning_rate": 9.645118464052288e-06,
      "loss": 0.2108,
      "step": 2873
    },
    {
      "epoch": 0.6603860294117647,
      "grad_norm": 1.7592488527297974,
      "learning_rate": 9.644607843137256e-06,
      "loss": 0.1909,
      "step": 2874
    },
    {
      "epoch": 0.6606158088235294,
      "grad_norm": 1.7360033988952637,
      "learning_rate": 9.644097222222222e-06,
      "loss": 0.2204,
      "step": 2875
    },
    {
      "epoch": 0.6608455882352942,
      "grad_norm": 1.8300663232803345,
      "learning_rate": 9.64358660130719e-06,
      "loss": 0.2282,
      "step": 2876
    },
    {
      "epoch": 0.6610753676470589,
      "grad_norm": 1.9589531421661377,
      "learning_rate": 9.643075980392158e-06,
      "loss": 0.2669,
      "step": 2877
    },
    {
      "epoch": 0.6613051470588235,
      "grad_norm": 1.8777883052825928,
      "learning_rate": 9.642565359477124e-06,
      "loss": 0.2764,
      "step": 2878
    },
    {
      "epoch": 0.6615349264705882,
      "grad_norm": 1.6298586130142212,
      "learning_rate": 9.642054738562092e-06,
      "loss": 0.1732,
      "step": 2879
    },
    {
      "epoch": 0.6617647058823529,
      "grad_norm": 2.141343116760254,
      "learning_rate": 9.641544117647058e-06,
      "loss": 0.2796,
      "step": 2880
    },
    {
      "epoch": 0.6619944852941176,
      "grad_norm": 1.5987210273742676,
      "learning_rate": 9.641033496732028e-06,
      "loss": 0.2088,
      "step": 2881
    },
    {
      "epoch": 0.6622242647058824,
      "grad_norm": 1.561462163925171,
      "learning_rate": 9.640522875816994e-06,
      "loss": 0.1776,
      "step": 2882
    },
    {
      "epoch": 0.6624540441176471,
      "grad_norm": 2.130173921585083,
      "learning_rate": 9.640012254901962e-06,
      "loss": 0.2542,
      "step": 2883
    },
    {
      "epoch": 0.6626838235294118,
      "grad_norm": 2.0247812271118164,
      "learning_rate": 9.639501633986928e-06,
      "loss": 0.1627,
      "step": 2884
    },
    {
      "epoch": 0.6629136029411765,
      "grad_norm": 2.0047998428344727,
      "learning_rate": 9.638991013071896e-06,
      "loss": 0.2227,
      "step": 2885
    },
    {
      "epoch": 0.6631433823529411,
      "grad_norm": 1.8971788883209229,
      "learning_rate": 9.638480392156864e-06,
      "loss": 0.223,
      "step": 2886
    },
    {
      "epoch": 0.6633731617647058,
      "grad_norm": 1.7505567073822021,
      "learning_rate": 9.63796977124183e-06,
      "loss": 0.2261,
      "step": 2887
    },
    {
      "epoch": 0.6636029411764706,
      "grad_norm": 2.08744215965271,
      "learning_rate": 9.637459150326798e-06,
      "loss": 0.2063,
      "step": 2888
    },
    {
      "epoch": 0.6638327205882353,
      "grad_norm": 1.6958792209625244,
      "learning_rate": 9.636948529411766e-06,
      "loss": 0.1757,
      "step": 2889
    },
    {
      "epoch": 0.6640625,
      "grad_norm": 1.445640206336975,
      "learning_rate": 9.636437908496734e-06,
      "loss": 0.1736,
      "step": 2890
    },
    {
      "epoch": 0.6642922794117647,
      "grad_norm": 1.212610125541687,
      "learning_rate": 9.6359272875817e-06,
      "loss": 0.1712,
      "step": 2891
    },
    {
      "epoch": 0.6645220588235294,
      "grad_norm": 2.192626953125,
      "learning_rate": 9.635416666666668e-06,
      "loss": 0.2724,
      "step": 2892
    },
    {
      "epoch": 0.6647518382352942,
      "grad_norm": 1.5810010433197021,
      "learning_rate": 9.634906045751636e-06,
      "loss": 0.246,
      "step": 2893
    },
    {
      "epoch": 0.6649816176470589,
      "grad_norm": 1.646026849746704,
      "learning_rate": 9.634395424836602e-06,
      "loss": 0.1854,
      "step": 2894
    },
    {
      "epoch": 0.6652113970588235,
      "grad_norm": 1.9176260232925415,
      "learning_rate": 9.63388480392157e-06,
      "loss": 0.2356,
      "step": 2895
    },
    {
      "epoch": 0.6654411764705882,
      "grad_norm": 1.6302986145019531,
      "learning_rate": 9.633374183006536e-06,
      "loss": 0.2403,
      "step": 2896
    },
    {
      "epoch": 0.6656709558823529,
      "grad_norm": 2.1919198036193848,
      "learning_rate": 9.632863562091505e-06,
      "loss": 0.2066,
      "step": 2897
    },
    {
      "epoch": 0.6659007352941176,
      "grad_norm": 1.519987940788269,
      "learning_rate": 9.632352941176471e-06,
      "loss": 0.2097,
      "step": 2898
    },
    {
      "epoch": 0.6661305147058824,
      "grad_norm": 1.5004717111587524,
      "learning_rate": 9.63184232026144e-06,
      "loss": 0.2228,
      "step": 2899
    },
    {
      "epoch": 0.6663602941176471,
      "grad_norm": 1.7918599843978882,
      "learning_rate": 9.631331699346405e-06,
      "loss": 0.159,
      "step": 2900
    },
    {
      "epoch": 0.6665900735294118,
      "grad_norm": 1.7579166889190674,
      "learning_rate": 9.630821078431373e-06,
      "loss": 0.2008,
      "step": 2901
    },
    {
      "epoch": 0.6668198529411765,
      "grad_norm": 1.9869800806045532,
      "learning_rate": 9.630310457516341e-06,
      "loss": 0.2871,
      "step": 2902
    },
    {
      "epoch": 0.6670496323529411,
      "grad_norm": 1.7296805381774902,
      "learning_rate": 9.629799836601307e-06,
      "loss": 0.1929,
      "step": 2903
    },
    {
      "epoch": 0.6672794117647058,
      "grad_norm": 1.7499125003814697,
      "learning_rate": 9.629289215686275e-06,
      "loss": 0.2162,
      "step": 2904
    },
    {
      "epoch": 0.6675091911764706,
      "grad_norm": 1.9775657653808594,
      "learning_rate": 9.628778594771243e-06,
      "loss": 0.2274,
      "step": 2905
    },
    {
      "epoch": 0.6677389705882353,
      "grad_norm": 1.6327418088912964,
      "learning_rate": 9.628267973856211e-06,
      "loss": 0.1731,
      "step": 2906
    },
    {
      "epoch": 0.66796875,
      "grad_norm": 1.8124903440475464,
      "learning_rate": 9.627757352941177e-06,
      "loss": 0.1894,
      "step": 2907
    },
    {
      "epoch": 0.6681985294117647,
      "grad_norm": 1.7631862163543701,
      "learning_rate": 9.627246732026145e-06,
      "loss": 0.2414,
      "step": 2908
    },
    {
      "epoch": 0.6684283088235294,
      "grad_norm": 1.432729721069336,
      "learning_rate": 9.626736111111113e-06,
      "loss": 0.2432,
      "step": 2909
    },
    {
      "epoch": 0.6686580882352942,
      "grad_norm": 1.4053504467010498,
      "learning_rate": 9.626225490196079e-06,
      "loss": 0.1783,
      "step": 2910
    },
    {
      "epoch": 0.6688878676470589,
      "grad_norm": 1.6273672580718994,
      "learning_rate": 9.625714869281047e-06,
      "loss": 0.1911,
      "step": 2911
    },
    {
      "epoch": 0.6691176470588235,
      "grad_norm": 1.885939598083496,
      "learning_rate": 9.625204248366013e-06,
      "loss": 0.2867,
      "step": 2912
    },
    {
      "epoch": 0.6693474264705882,
      "grad_norm": 1.8363733291625977,
      "learning_rate": 9.624693627450981e-06,
      "loss": 0.2025,
      "step": 2913
    },
    {
      "epoch": 0.6695772058823529,
      "grad_norm": 1.61516535282135,
      "learning_rate": 9.624183006535949e-06,
      "loss": 0.2595,
      "step": 2914
    },
    {
      "epoch": 0.6698069852941176,
      "grad_norm": 1.5652159452438354,
      "learning_rate": 9.623672385620917e-06,
      "loss": 0.2392,
      "step": 2915
    },
    {
      "epoch": 0.6700367647058824,
      "grad_norm": 1.7355995178222656,
      "learning_rate": 9.623161764705883e-06,
      "loss": 0.1791,
      "step": 2916
    },
    {
      "epoch": 0.6702665441176471,
      "grad_norm": 1.7980467081069946,
      "learning_rate": 9.62265114379085e-06,
      "loss": 0.2454,
      "step": 2917
    },
    {
      "epoch": 0.6704963235294118,
      "grad_norm": 1.5380911827087402,
      "learning_rate": 9.622140522875819e-06,
      "loss": 0.2328,
      "step": 2918
    },
    {
      "epoch": 0.6707261029411765,
      "grad_norm": 1.3579329252243042,
      "learning_rate": 9.621629901960785e-06,
      "loss": 0.2224,
      "step": 2919
    },
    {
      "epoch": 0.6709558823529411,
      "grad_norm": 1.3931756019592285,
      "learning_rate": 9.621119281045753e-06,
      "loss": 0.1683,
      "step": 2920
    },
    {
      "epoch": 0.6711856617647058,
      "grad_norm": 1.7423229217529297,
      "learning_rate": 9.62060866013072e-06,
      "loss": 0.2385,
      "step": 2921
    },
    {
      "epoch": 0.6714154411764706,
      "grad_norm": 2.4023189544677734,
      "learning_rate": 9.620098039215687e-06,
      "loss": 0.2075,
      "step": 2922
    },
    {
      "epoch": 0.6716452205882353,
      "grad_norm": 1.8208682537078857,
      "learning_rate": 9.619587418300654e-06,
      "loss": 0.1994,
      "step": 2923
    },
    {
      "epoch": 0.671875,
      "grad_norm": 1.7760298252105713,
      "learning_rate": 9.61907679738562e-06,
      "loss": 0.1734,
      "step": 2924
    },
    {
      "epoch": 0.6721047794117647,
      "grad_norm": 2.2332324981689453,
      "learning_rate": 9.61856617647059e-06,
      "loss": 0.3035,
      "step": 2925
    },
    {
      "epoch": 0.6723345588235294,
      "grad_norm": 1.5566030740737915,
      "learning_rate": 9.618055555555556e-06,
      "loss": 0.2938,
      "step": 2926
    },
    {
      "epoch": 0.6725643382352942,
      "grad_norm": 1.7053335905075073,
      "learning_rate": 9.617544934640524e-06,
      "loss": 0.2325,
      "step": 2927
    },
    {
      "epoch": 0.6727941176470589,
      "grad_norm": 1.3519232273101807,
      "learning_rate": 9.61703431372549e-06,
      "loss": 0.1757,
      "step": 2928
    },
    {
      "epoch": 0.6730238970588235,
      "grad_norm": 1.8625410795211792,
      "learning_rate": 9.616523692810458e-06,
      "loss": 0.2184,
      "step": 2929
    },
    {
      "epoch": 0.6732536764705882,
      "grad_norm": 2.411170482635498,
      "learning_rate": 9.616013071895426e-06,
      "loss": 0.2135,
      "step": 2930
    },
    {
      "epoch": 0.6734834558823529,
      "grad_norm": 1.9296866655349731,
      "learning_rate": 9.615502450980392e-06,
      "loss": 0.1513,
      "step": 2931
    },
    {
      "epoch": 0.6737132352941176,
      "grad_norm": 1.5009673833847046,
      "learning_rate": 9.61499183006536e-06,
      "loss": 0.2413,
      "step": 2932
    },
    {
      "epoch": 0.6739430147058824,
      "grad_norm": 1.459601640701294,
      "learning_rate": 9.614481209150328e-06,
      "loss": 0.217,
      "step": 2933
    },
    {
      "epoch": 0.6741727941176471,
      "grad_norm": 1.5924205780029297,
      "learning_rate": 9.613970588235296e-06,
      "loss": 0.2948,
      "step": 2934
    },
    {
      "epoch": 0.6744025735294118,
      "grad_norm": 1.7345412969589233,
      "learning_rate": 9.613459967320262e-06,
      "loss": 0.2743,
      "step": 2935
    },
    {
      "epoch": 0.6746323529411765,
      "grad_norm": 1.2818189859390259,
      "learning_rate": 9.61294934640523e-06,
      "loss": 0.176,
      "step": 2936
    },
    {
      "epoch": 0.6748621323529411,
      "grad_norm": 1.5186095237731934,
      "learning_rate": 9.612438725490198e-06,
      "loss": 0.1779,
      "step": 2937
    },
    {
      "epoch": 0.6750919117647058,
      "grad_norm": 2.106959819793701,
      "learning_rate": 9.611928104575164e-06,
      "loss": 0.2046,
      "step": 2938
    },
    {
      "epoch": 0.6753216911764706,
      "grad_norm": 2.2022604942321777,
      "learning_rate": 9.611417483660132e-06,
      "loss": 0.2277,
      "step": 2939
    },
    {
      "epoch": 0.6755514705882353,
      "grad_norm": 1.6529914140701294,
      "learning_rate": 9.610906862745098e-06,
      "loss": 0.2157,
      "step": 2940
    },
    {
      "epoch": 0.67578125,
      "grad_norm": 1.615386962890625,
      "learning_rate": 9.610396241830067e-06,
      "loss": 0.1905,
      "step": 2941
    },
    {
      "epoch": 0.6760110294117647,
      "grad_norm": 1.4736677408218384,
      "learning_rate": 9.609885620915034e-06,
      "loss": 0.2494,
      "step": 2942
    },
    {
      "epoch": 0.6762408088235294,
      "grad_norm": 1.8320354223251343,
      "learning_rate": 9.609375000000001e-06,
      "loss": 0.1808,
      "step": 2943
    },
    {
      "epoch": 0.6764705882352942,
      "grad_norm": 2.265197992324829,
      "learning_rate": 9.608864379084968e-06,
      "loss": 0.2522,
      "step": 2944
    },
    {
      "epoch": 0.6767003676470589,
      "grad_norm": 1.5774450302124023,
      "learning_rate": 9.608353758169936e-06,
      "loss": 0.2084,
      "step": 2945
    },
    {
      "epoch": 0.6769301470588235,
      "grad_norm": 1.719847321510315,
      "learning_rate": 9.607843137254903e-06,
      "loss": 0.2251,
      "step": 2946
    },
    {
      "epoch": 0.6771599264705882,
      "grad_norm": 1.6855953931808472,
      "learning_rate": 9.60733251633987e-06,
      "loss": 0.1779,
      "step": 2947
    },
    {
      "epoch": 0.6773897058823529,
      "grad_norm": 1.8005025386810303,
      "learning_rate": 9.606821895424837e-06,
      "loss": 0.1751,
      "step": 2948
    },
    {
      "epoch": 0.6776194852941176,
      "grad_norm": 1.5162265300750732,
      "learning_rate": 9.606311274509804e-06,
      "loss": 0.203,
      "step": 2949
    },
    {
      "epoch": 0.6778492647058824,
      "grad_norm": 1.6682168245315552,
      "learning_rate": 9.605800653594773e-06,
      "loss": 0.2374,
      "step": 2950
    },
    {
      "epoch": 0.6780790441176471,
      "grad_norm": 1.5762159824371338,
      "learning_rate": 9.60529003267974e-06,
      "loss": 0.2268,
      "step": 2951
    },
    {
      "epoch": 0.6783088235294118,
      "grad_norm": 1.4975301027297974,
      "learning_rate": 9.604779411764707e-06,
      "loss": 0.2252,
      "step": 2952
    },
    {
      "epoch": 0.6785386029411765,
      "grad_norm": 1.8942527770996094,
      "learning_rate": 9.604268790849673e-06,
      "loss": 0.2045,
      "step": 2953
    },
    {
      "epoch": 0.6787683823529411,
      "grad_norm": 1.7342643737792969,
      "learning_rate": 9.603758169934641e-06,
      "loss": 0.1696,
      "step": 2954
    },
    {
      "epoch": 0.6789981617647058,
      "grad_norm": 1.5998772382736206,
      "learning_rate": 9.603247549019609e-06,
      "loss": 0.1914,
      "step": 2955
    },
    {
      "epoch": 0.6792279411764706,
      "grad_norm": 1.7208712100982666,
      "learning_rate": 9.602736928104575e-06,
      "loss": 0.2315,
      "step": 2956
    },
    {
      "epoch": 0.6794577205882353,
      "grad_norm": 1.8802685737609863,
      "learning_rate": 9.602226307189543e-06,
      "loss": 0.2471,
      "step": 2957
    },
    {
      "epoch": 0.6796875,
      "grad_norm": 1.8389469385147095,
      "learning_rate": 9.601715686274511e-06,
      "loss": 0.2117,
      "step": 2958
    },
    {
      "epoch": 0.6799172794117647,
      "grad_norm": 1.5564227104187012,
      "learning_rate": 9.601205065359477e-06,
      "loss": 0.2153,
      "step": 2959
    },
    {
      "epoch": 0.6801470588235294,
      "grad_norm": 1.7292262315750122,
      "learning_rate": 9.600694444444445e-06,
      "loss": 0.2668,
      "step": 2960
    },
    {
      "epoch": 0.6803768382352942,
      "grad_norm": 1.6102358102798462,
      "learning_rate": 9.600183823529413e-06,
      "loss": 0.1704,
      "step": 2961
    },
    {
      "epoch": 0.6806066176470589,
      "grad_norm": 1.9357072114944458,
      "learning_rate": 9.59967320261438e-06,
      "loss": 0.2344,
      "step": 2962
    },
    {
      "epoch": 0.6808363970588235,
      "grad_norm": 1.8123621940612793,
      "learning_rate": 9.599162581699347e-06,
      "loss": 0.1932,
      "step": 2963
    },
    {
      "epoch": 0.6810661764705882,
      "grad_norm": 1.8972535133361816,
      "learning_rate": 9.598651960784315e-06,
      "loss": 0.2059,
      "step": 2964
    },
    {
      "epoch": 0.6812959558823529,
      "grad_norm": 1.7773762941360474,
      "learning_rate": 9.598141339869281e-06,
      "loss": 0.2588,
      "step": 2965
    },
    {
      "epoch": 0.6815257352941176,
      "grad_norm": 2.193007469177246,
      "learning_rate": 9.597630718954249e-06,
      "loss": 0.265,
      "step": 2966
    },
    {
      "epoch": 0.6817555147058824,
      "grad_norm": 1.5898027420043945,
      "learning_rate": 9.597120098039217e-06,
      "loss": 0.1701,
      "step": 2967
    },
    {
      "epoch": 0.6819852941176471,
      "grad_norm": 1.8089402914047241,
      "learning_rate": 9.596609477124183e-06,
      "loss": 0.2528,
      "step": 2968
    },
    {
      "epoch": 0.6822150735294118,
      "grad_norm": 1.6171326637268066,
      "learning_rate": 9.59609885620915e-06,
      "loss": 0.2252,
      "step": 2969
    },
    {
      "epoch": 0.6824448529411765,
      "grad_norm": 1.6772922277450562,
      "learning_rate": 9.595588235294119e-06,
      "loss": 0.2585,
      "step": 2970
    },
    {
      "epoch": 0.6826746323529411,
      "grad_norm": 1.4185023307800293,
      "learning_rate": 9.595077614379086e-06,
      "loss": 0.2458,
      "step": 2971
    },
    {
      "epoch": 0.6829044117647058,
      "grad_norm": 1.7993173599243164,
      "learning_rate": 9.594566993464053e-06,
      "loss": 0.1961,
      "step": 2972
    },
    {
      "epoch": 0.6831341911764706,
      "grad_norm": 1.97123122215271,
      "learning_rate": 9.59405637254902e-06,
      "loss": 0.2411,
      "step": 2973
    },
    {
      "epoch": 0.6833639705882353,
      "grad_norm": 1.840259075164795,
      "learning_rate": 9.593545751633988e-06,
      "loss": 0.1965,
      "step": 2974
    },
    {
      "epoch": 0.68359375,
      "grad_norm": 2.1449246406555176,
      "learning_rate": 9.593035130718954e-06,
      "loss": 0.2255,
      "step": 2975
    },
    {
      "epoch": 0.6838235294117647,
      "grad_norm": 1.537867784500122,
      "learning_rate": 9.592524509803922e-06,
      "loss": 0.1827,
      "step": 2976
    },
    {
      "epoch": 0.6840533088235294,
      "grad_norm": 1.4655754566192627,
      "learning_rate": 9.592013888888888e-06,
      "loss": 0.1876,
      "step": 2977
    },
    {
      "epoch": 0.6842830882352942,
      "grad_norm": 1.6559174060821533,
      "learning_rate": 9.591503267973858e-06,
      "loss": 0.1952,
      "step": 2978
    },
    {
      "epoch": 0.6845128676470589,
      "grad_norm": 1.8548040390014648,
      "learning_rate": 9.590992647058824e-06,
      "loss": 0.2097,
      "step": 2979
    },
    {
      "epoch": 0.6847426470588235,
      "grad_norm": 1.524735689163208,
      "learning_rate": 9.590482026143792e-06,
      "loss": 0.2084,
      "step": 2980
    },
    {
      "epoch": 0.6849724264705882,
      "grad_norm": 1.7934681177139282,
      "learning_rate": 9.589971405228758e-06,
      "loss": 0.199,
      "step": 2981
    },
    {
      "epoch": 0.6852022058823529,
      "grad_norm": 2.06559681892395,
      "learning_rate": 9.589460784313726e-06,
      "loss": 0.1926,
      "step": 2982
    },
    {
      "epoch": 0.6854319852941176,
      "grad_norm": 1.6554887294769287,
      "learning_rate": 9.588950163398694e-06,
      "loss": 0.1897,
      "step": 2983
    },
    {
      "epoch": 0.6856617647058824,
      "grad_norm": 1.5457104444503784,
      "learning_rate": 9.58843954248366e-06,
      "loss": 0.2051,
      "step": 2984
    },
    {
      "epoch": 0.6858915441176471,
      "grad_norm": 1.771082878112793,
      "learning_rate": 9.587928921568628e-06,
      "loss": 0.2369,
      "step": 2985
    },
    {
      "epoch": 0.6861213235294118,
      "grad_norm": 1.7775423526763916,
      "learning_rate": 9.587418300653596e-06,
      "loss": 0.2059,
      "step": 2986
    },
    {
      "epoch": 0.6863511029411765,
      "grad_norm": 2.217611312866211,
      "learning_rate": 9.586907679738564e-06,
      "loss": 0.2361,
      "step": 2987
    },
    {
      "epoch": 0.6865808823529411,
      "grad_norm": 1.462397575378418,
      "learning_rate": 9.58639705882353e-06,
      "loss": 0.1949,
      "step": 2988
    },
    {
      "epoch": 0.6868106617647058,
      "grad_norm": 1.5691041946411133,
      "learning_rate": 9.585886437908498e-06,
      "loss": 0.1903,
      "step": 2989
    },
    {
      "epoch": 0.6870404411764706,
      "grad_norm": 1.5143386125564575,
      "learning_rate": 9.585375816993466e-06,
      "loss": 0.1972,
      "step": 2990
    },
    {
      "epoch": 0.6872702205882353,
      "grad_norm": 2.1597838401794434,
      "learning_rate": 9.584865196078432e-06,
      "loss": 0.1779,
      "step": 2991
    },
    {
      "epoch": 0.6875,
      "grad_norm": 1.937680721282959,
      "learning_rate": 9.5843545751634e-06,
      "loss": 0.223,
      "step": 2992
    },
    {
      "epoch": 0.6877297794117647,
      "grad_norm": 1.688900113105774,
      "learning_rate": 9.583843954248366e-06,
      "loss": 0.2224,
      "step": 2993
    },
    {
      "epoch": 0.6879595588235294,
      "grad_norm": 1.489621639251709,
      "learning_rate": 9.583333333333335e-06,
      "loss": 0.152,
      "step": 2994
    },
    {
      "epoch": 0.6881893382352942,
      "grad_norm": 1.4520865678787231,
      "learning_rate": 9.582822712418301e-06,
      "loss": 0.1983,
      "step": 2995
    },
    {
      "epoch": 0.6884191176470589,
      "grad_norm": 1.5108404159545898,
      "learning_rate": 9.58231209150327e-06,
      "loss": 0.1757,
      "step": 2996
    },
    {
      "epoch": 0.6886488970588235,
      "grad_norm": 2.0342118740081787,
      "learning_rate": 9.581801470588236e-06,
      "loss": 0.2412,
      "step": 2997
    },
    {
      "epoch": 0.6888786764705882,
      "grad_norm": 1.642804741859436,
      "learning_rate": 9.581290849673203e-06,
      "loss": 0.2124,
      "step": 2998
    },
    {
      "epoch": 0.6891084558823529,
      "grad_norm": 2.0856828689575195,
      "learning_rate": 9.580780228758171e-06,
      "loss": 0.2274,
      "step": 2999
    },
    {
      "epoch": 0.6893382352941176,
      "grad_norm": 1.7117347717285156,
      "learning_rate": 9.580269607843137e-06,
      "loss": 0.1929,
      "step": 3000
    },
    {
      "epoch": 0.6893382352941176,
      "eval_loss": 0.21192356944084167,
      "eval_runtime": 420.3468,
      "eval_samples_per_second": 21.187,
      "eval_steps_per_second": 10.594,
      "step": 3000
    },
    {
      "epoch": 0.6895680147058824,
      "grad_norm": 1.8445706367492676,
      "learning_rate": 9.579758986928105e-06,
      "loss": 0.2161,
      "step": 3001
    },
    {
      "epoch": 0.6897977941176471,
      "grad_norm": 1.8830145597457886,
      "learning_rate": 9.579248366013073e-06,
      "loss": 0.239,
      "step": 3002
    },
    {
      "epoch": 0.6900275735294118,
      "grad_norm": 1.5945065021514893,
      "learning_rate": 9.57873774509804e-06,
      "loss": 0.2113,
      "step": 3003
    },
    {
      "epoch": 0.6902573529411765,
      "grad_norm": 1.9660675525665283,
      "learning_rate": 9.578227124183007e-06,
      "loss": 0.2128,
      "step": 3004
    },
    {
      "epoch": 0.6904871323529411,
      "grad_norm": 1.6731761693954468,
      "learning_rate": 9.577716503267975e-06,
      "loss": 0.2282,
      "step": 3005
    },
    {
      "epoch": 0.6907169117647058,
      "grad_norm": 1.6925016641616821,
      "learning_rate": 9.577205882352943e-06,
      "loss": 0.2447,
      "step": 3006
    },
    {
      "epoch": 0.6909466911764706,
      "grad_norm": 1.7001302242279053,
      "learning_rate": 9.576695261437909e-06,
      "loss": 0.223,
      "step": 3007
    },
    {
      "epoch": 0.6911764705882353,
      "grad_norm": 1.9874029159545898,
      "learning_rate": 9.576184640522877e-06,
      "loss": 0.1927,
      "step": 3008
    },
    {
      "epoch": 0.69140625,
      "grad_norm": 2.411057949066162,
      "learning_rate": 9.575674019607843e-06,
      "loss": 0.2502,
      "step": 3009
    },
    {
      "epoch": 0.6916360294117647,
      "grad_norm": 1.941177487373352,
      "learning_rate": 9.575163398692811e-06,
      "loss": 0.1733,
      "step": 3010
    },
    {
      "epoch": 0.6918658088235294,
      "grad_norm": 1.783487319946289,
      "learning_rate": 9.574652777777779e-06,
      "loss": 0.2162,
      "step": 3011
    },
    {
      "epoch": 0.6920955882352942,
      "grad_norm": 1.9078876972198486,
      "learning_rate": 9.574142156862745e-06,
      "loss": 0.2225,
      "step": 3012
    },
    {
      "epoch": 0.6923253676470589,
      "grad_norm": 1.4931257963180542,
      "learning_rate": 9.573631535947713e-06,
      "loss": 0.2244,
      "step": 3013
    },
    {
      "epoch": 0.6925551470588235,
      "grad_norm": 1.7870107889175415,
      "learning_rate": 9.57312091503268e-06,
      "loss": 0.2457,
      "step": 3014
    },
    {
      "epoch": 0.6927849264705882,
      "grad_norm": 1.754129409790039,
      "learning_rate": 9.572610294117649e-06,
      "loss": 0.1917,
      "step": 3015
    },
    {
      "epoch": 0.6930147058823529,
      "grad_norm": 1.6815109252929688,
      "learning_rate": 9.572099673202615e-06,
      "loss": 0.1599,
      "step": 3016
    },
    {
      "epoch": 0.6932444852941176,
      "grad_norm": 2.055628538131714,
      "learning_rate": 9.571589052287583e-06,
      "loss": 0.2466,
      "step": 3017
    },
    {
      "epoch": 0.6934742647058824,
      "grad_norm": 2.232903480529785,
      "learning_rate": 9.57107843137255e-06,
      "loss": 0.2185,
      "step": 3018
    },
    {
      "epoch": 0.6937040441176471,
      "grad_norm": 1.5395547151565552,
      "learning_rate": 9.570567810457517e-06,
      "loss": 0.2209,
      "step": 3019
    },
    {
      "epoch": 0.6939338235294118,
      "grad_norm": 1.9679521322250366,
      "learning_rate": 9.570057189542484e-06,
      "loss": 0.1697,
      "step": 3020
    },
    {
      "epoch": 0.6941636029411765,
      "grad_norm": 1.545312523841858,
      "learning_rate": 9.56954656862745e-06,
      "loss": 0.2189,
      "step": 3021
    },
    {
      "epoch": 0.6943933823529411,
      "grad_norm": 1.6124058961868286,
      "learning_rate": 9.56903594771242e-06,
      "loss": 0.2067,
      "step": 3022
    },
    {
      "epoch": 0.6946231617647058,
      "grad_norm": 1.603251576423645,
      "learning_rate": 9.568525326797386e-06,
      "loss": 0.2574,
      "step": 3023
    },
    {
      "epoch": 0.6948529411764706,
      "grad_norm": 1.7847694158554077,
      "learning_rate": 9.568014705882354e-06,
      "loss": 0.1876,
      "step": 3024
    },
    {
      "epoch": 0.6950827205882353,
      "grad_norm": 1.77516770362854,
      "learning_rate": 9.56750408496732e-06,
      "loss": 0.2346,
      "step": 3025
    },
    {
      "epoch": 0.6953125,
      "grad_norm": 1.6218591928482056,
      "learning_rate": 9.566993464052288e-06,
      "loss": 0.1987,
      "step": 3026
    },
    {
      "epoch": 0.6955422794117647,
      "grad_norm": 2.0321648120880127,
      "learning_rate": 9.566482843137256e-06,
      "loss": 0.2061,
      "step": 3027
    },
    {
      "epoch": 0.6957720588235294,
      "grad_norm": 2.100371837615967,
      "learning_rate": 9.565972222222222e-06,
      "loss": 0.294,
      "step": 3028
    },
    {
      "epoch": 0.6960018382352942,
      "grad_norm": 2.0750715732574463,
      "learning_rate": 9.56546160130719e-06,
      "loss": 0.2629,
      "step": 3029
    },
    {
      "epoch": 0.6962316176470589,
      "grad_norm": 1.5990608930587769,
      "learning_rate": 9.564950980392158e-06,
      "loss": 0.1799,
      "step": 3030
    },
    {
      "epoch": 0.6964613970588235,
      "grad_norm": 2.08689022064209,
      "learning_rate": 9.564440359477126e-06,
      "loss": 0.184,
      "step": 3031
    },
    {
      "epoch": 0.6966911764705882,
      "grad_norm": 1.9048335552215576,
      "learning_rate": 9.563929738562092e-06,
      "loss": 0.2587,
      "step": 3032
    },
    {
      "epoch": 0.6969209558823529,
      "grad_norm": 1.9504212141036987,
      "learning_rate": 9.56341911764706e-06,
      "loss": 0.2289,
      "step": 3033
    },
    {
      "epoch": 0.6971507352941176,
      "grad_norm": 1.9882066249847412,
      "learning_rate": 9.562908496732028e-06,
      "loss": 0.2056,
      "step": 3034
    },
    {
      "epoch": 0.6973805147058824,
      "grad_norm": 1.6993627548217773,
      "learning_rate": 9.562397875816994e-06,
      "loss": 0.1882,
      "step": 3035
    },
    {
      "epoch": 0.6976102941176471,
      "grad_norm": 1.7443634271621704,
      "learning_rate": 9.561887254901962e-06,
      "loss": 0.2028,
      "step": 3036
    },
    {
      "epoch": 0.6978400735294118,
      "grad_norm": 2.0794765949249268,
      "learning_rate": 9.561376633986928e-06,
      "loss": 0.2128,
      "step": 3037
    },
    {
      "epoch": 0.6980698529411765,
      "grad_norm": 1.9174941778182983,
      "learning_rate": 9.560866013071896e-06,
      "loss": 0.2661,
      "step": 3038
    },
    {
      "epoch": 0.6982996323529411,
      "grad_norm": 1.4345265626907349,
      "learning_rate": 9.560355392156864e-06,
      "loss": 0.161,
      "step": 3039
    },
    {
      "epoch": 0.6985294117647058,
      "grad_norm": 1.6003198623657227,
      "learning_rate": 9.559844771241832e-06,
      "loss": 0.2327,
      "step": 3040
    },
    {
      "epoch": 0.6987591911764706,
      "grad_norm": 2.2399110794067383,
      "learning_rate": 9.559334150326798e-06,
      "loss": 0.2101,
      "step": 3041
    },
    {
      "epoch": 0.6989889705882353,
      "grad_norm": 1.4346705675125122,
      "learning_rate": 9.558823529411766e-06,
      "loss": 0.1919,
      "step": 3042
    },
    {
      "epoch": 0.69921875,
      "grad_norm": 1.2889419794082642,
      "learning_rate": 9.558312908496733e-06,
      "loss": 0.1817,
      "step": 3043
    },
    {
      "epoch": 0.6994485294117647,
      "grad_norm": 2.234050989151001,
      "learning_rate": 9.5578022875817e-06,
      "loss": 0.1946,
      "step": 3044
    },
    {
      "epoch": 0.6996783088235294,
      "grad_norm": 1.999664068222046,
      "learning_rate": 9.557291666666667e-06,
      "loss": 0.2211,
      "step": 3045
    },
    {
      "epoch": 0.6999080882352942,
      "grad_norm": 1.546859860420227,
      "learning_rate": 9.556781045751635e-06,
      "loss": 0.2557,
      "step": 3046
    },
    {
      "epoch": 0.7001378676470589,
      "grad_norm": 1.894026517868042,
      "learning_rate": 9.556270424836601e-06,
      "loss": 0.1933,
      "step": 3047
    },
    {
      "epoch": 0.7003676470588235,
      "grad_norm": 1.6923567056655884,
      "learning_rate": 9.55575980392157e-06,
      "loss": 0.1569,
      "step": 3048
    },
    {
      "epoch": 0.7005974264705882,
      "grad_norm": 2.0901267528533936,
      "learning_rate": 9.555249183006537e-06,
      "loss": 0.217,
      "step": 3049
    },
    {
      "epoch": 0.7008272058823529,
      "grad_norm": 1.4641191959381104,
      "learning_rate": 9.554738562091505e-06,
      "loss": 0.1675,
      "step": 3050
    },
    {
      "epoch": 0.7010569852941176,
      "grad_norm": 1.5560708045959473,
      "learning_rate": 9.554227941176471e-06,
      "loss": 0.1583,
      "step": 3051
    },
    {
      "epoch": 0.7012867647058824,
      "grad_norm": 1.8280739784240723,
      "learning_rate": 9.553717320261439e-06,
      "loss": 0.2036,
      "step": 3052
    },
    {
      "epoch": 0.7015165441176471,
      "grad_norm": 2.0600671768188477,
      "learning_rate": 9.553206699346405e-06,
      "loss": 0.1868,
      "step": 3053
    },
    {
      "epoch": 0.7017463235294118,
      "grad_norm": 2.1026768684387207,
      "learning_rate": 9.552696078431373e-06,
      "loss": 0.212,
      "step": 3054
    },
    {
      "epoch": 0.7019761029411765,
      "grad_norm": 1.6132994890213013,
      "learning_rate": 9.552185457516341e-06,
      "loss": 0.2173,
      "step": 3055
    },
    {
      "epoch": 0.7022058823529411,
      "grad_norm": 1.612501621246338,
      "learning_rate": 9.551674836601307e-06,
      "loss": 0.1626,
      "step": 3056
    },
    {
      "epoch": 0.7024356617647058,
      "grad_norm": 1.7593401670455933,
      "learning_rate": 9.551164215686275e-06,
      "loss": 0.1734,
      "step": 3057
    },
    {
      "epoch": 0.7026654411764706,
      "grad_norm": 1.9449743032455444,
      "learning_rate": 9.550653594771243e-06,
      "loss": 0.2024,
      "step": 3058
    },
    {
      "epoch": 0.7028952205882353,
      "grad_norm": 2.3350908756256104,
      "learning_rate": 9.55014297385621e-06,
      "loss": 0.221,
      "step": 3059
    },
    {
      "epoch": 0.703125,
      "grad_norm": 1.8640953302383423,
      "learning_rate": 9.549632352941177e-06,
      "loss": 0.2224,
      "step": 3060
    },
    {
      "epoch": 0.7033547794117647,
      "grad_norm": 1.8597739934921265,
      "learning_rate": 9.549121732026145e-06,
      "loss": 0.2416,
      "step": 3061
    },
    {
      "epoch": 0.7035845588235294,
      "grad_norm": 1.7994047403335571,
      "learning_rate": 9.548611111111113e-06,
      "loss": 0.2477,
      "step": 3062
    },
    {
      "epoch": 0.7038143382352942,
      "grad_norm": 1.4900809526443481,
      "learning_rate": 9.548100490196079e-06,
      "loss": 0.1793,
      "step": 3063
    },
    {
      "epoch": 0.7040441176470589,
      "grad_norm": 1.4136037826538086,
      "learning_rate": 9.547589869281047e-06,
      "loss": 0.2062,
      "step": 3064
    },
    {
      "epoch": 0.7042738970588235,
      "grad_norm": 1.6368111371994019,
      "learning_rate": 9.547079248366013e-06,
      "loss": 0.2444,
      "step": 3065
    },
    {
      "epoch": 0.7045036764705882,
      "grad_norm": 2.3055121898651123,
      "learning_rate": 9.546568627450982e-06,
      "loss": 0.2232,
      "step": 3066
    },
    {
      "epoch": 0.7047334558823529,
      "grad_norm": 1.9892960786819458,
      "learning_rate": 9.546058006535949e-06,
      "loss": 0.2086,
      "step": 3067
    },
    {
      "epoch": 0.7049632352941176,
      "grad_norm": 2.008556365966797,
      "learning_rate": 9.545547385620916e-06,
      "loss": 0.1843,
      "step": 3068
    },
    {
      "epoch": 0.7051930147058824,
      "grad_norm": 1.8220769166946411,
      "learning_rate": 9.545036764705883e-06,
      "loss": 0.2119,
      "step": 3069
    },
    {
      "epoch": 0.7054227941176471,
      "grad_norm": 1.6773581504821777,
      "learning_rate": 9.54452614379085e-06,
      "loss": 0.1607,
      "step": 3070
    },
    {
      "epoch": 0.7056525735294118,
      "grad_norm": 1.724843978881836,
      "learning_rate": 9.544015522875818e-06,
      "loss": 0.1563,
      "step": 3071
    },
    {
      "epoch": 0.7058823529411765,
      "grad_norm": 1.6946779489517212,
      "learning_rate": 9.543504901960784e-06,
      "loss": 0.2343,
      "step": 3072
    },
    {
      "epoch": 0.7061121323529411,
      "grad_norm": 1.992173671722412,
      "learning_rate": 9.542994281045752e-06,
      "loss": 0.1594,
      "step": 3073
    },
    {
      "epoch": 0.7063419117647058,
      "grad_norm": 1.4477806091308594,
      "learning_rate": 9.54248366013072e-06,
      "loss": 0.2059,
      "step": 3074
    },
    {
      "epoch": 0.7065716911764706,
      "grad_norm": 1.654212474822998,
      "learning_rate": 9.541973039215688e-06,
      "loss": 0.1769,
      "step": 3075
    },
    {
      "epoch": 0.7068014705882353,
      "grad_norm": 1.6982402801513672,
      "learning_rate": 9.541462418300654e-06,
      "loss": 0.2053,
      "step": 3076
    },
    {
      "epoch": 0.70703125,
      "grad_norm": 1.9417308568954468,
      "learning_rate": 9.540951797385622e-06,
      "loss": 0.1616,
      "step": 3077
    },
    {
      "epoch": 0.7072610294117647,
      "grad_norm": 1.769800066947937,
      "learning_rate": 9.54044117647059e-06,
      "loss": 0.1735,
      "step": 3078
    },
    {
      "epoch": 0.7074908088235294,
      "grad_norm": 1.301574945449829,
      "learning_rate": 9.539930555555556e-06,
      "loss": 0.1788,
      "step": 3079
    },
    {
      "epoch": 0.7077205882352942,
      "grad_norm": 1.4791131019592285,
      "learning_rate": 9.539419934640524e-06,
      "loss": 0.2049,
      "step": 3080
    },
    {
      "epoch": 0.7079503676470589,
      "grad_norm": 1.8078559637069702,
      "learning_rate": 9.53890931372549e-06,
      "loss": 0.234,
      "step": 3081
    },
    {
      "epoch": 0.7081801470588235,
      "grad_norm": 1.9729979038238525,
      "learning_rate": 9.538398692810458e-06,
      "loss": 0.2222,
      "step": 3082
    },
    {
      "epoch": 0.7084099264705882,
      "grad_norm": 1.8491257429122925,
      "learning_rate": 9.537888071895426e-06,
      "loss": 0.2694,
      "step": 3083
    },
    {
      "epoch": 0.7086397058823529,
      "grad_norm": 2.2137160301208496,
      "learning_rate": 9.537377450980394e-06,
      "loss": 0.276,
      "step": 3084
    },
    {
      "epoch": 0.7088694852941176,
      "grad_norm": 2.029921531677246,
      "learning_rate": 9.53686683006536e-06,
      "loss": 0.2014,
      "step": 3085
    },
    {
      "epoch": 0.7090992647058824,
      "grad_norm": 1.2064003944396973,
      "learning_rate": 9.536356209150328e-06,
      "loss": 0.1755,
      "step": 3086
    },
    {
      "epoch": 0.7093290441176471,
      "grad_norm": 1.9005001783370972,
      "learning_rate": 9.535845588235296e-06,
      "loss": 0.2475,
      "step": 3087
    },
    {
      "epoch": 0.7095588235294118,
      "grad_norm": 1.4655622243881226,
      "learning_rate": 9.535334967320262e-06,
      "loss": 0.1487,
      "step": 3088
    },
    {
      "epoch": 0.7097886029411765,
      "grad_norm": 1.4231960773468018,
      "learning_rate": 9.53482434640523e-06,
      "loss": 0.1884,
      "step": 3089
    },
    {
      "epoch": 0.7100183823529411,
      "grad_norm": 1.5668145418167114,
      "learning_rate": 9.534313725490198e-06,
      "loss": 0.1824,
      "step": 3090
    },
    {
      "epoch": 0.7102481617647058,
      "grad_norm": 1.9726999998092651,
      "learning_rate": 9.533803104575164e-06,
      "loss": 0.3018,
      "step": 3091
    },
    {
      "epoch": 0.7104779411764706,
      "grad_norm": 1.5263396501541138,
      "learning_rate": 9.533292483660132e-06,
      "loss": 0.2022,
      "step": 3092
    },
    {
      "epoch": 0.7107077205882353,
      "grad_norm": 1.960737943649292,
      "learning_rate": 9.532781862745098e-06,
      "loss": 0.1821,
      "step": 3093
    },
    {
      "epoch": 0.7109375,
      "grad_norm": 2.2473413944244385,
      "learning_rate": 9.532271241830067e-06,
      "loss": 0.1942,
      "step": 3094
    },
    {
      "epoch": 0.7111672794117647,
      "grad_norm": 1.7958096265792847,
      "learning_rate": 9.531760620915033e-06,
      "loss": 0.2039,
      "step": 3095
    },
    {
      "epoch": 0.7113970588235294,
      "grad_norm": 1.4602479934692383,
      "learning_rate": 9.531250000000001e-06,
      "loss": 0.2289,
      "step": 3096
    },
    {
      "epoch": 0.7116268382352942,
      "grad_norm": 1.376654863357544,
      "learning_rate": 9.530739379084967e-06,
      "loss": 0.1914,
      "step": 3097
    },
    {
      "epoch": 0.7118566176470589,
      "grad_norm": 1.6439145803451538,
      "learning_rate": 9.530228758169935e-06,
      "loss": 0.196,
      "step": 3098
    },
    {
      "epoch": 0.7120863970588235,
      "grad_norm": 1.5014710426330566,
      "learning_rate": 9.529718137254903e-06,
      "loss": 0.1512,
      "step": 3099
    },
    {
      "epoch": 0.7123161764705882,
      "grad_norm": 1.661763072013855,
      "learning_rate": 9.52920751633987e-06,
      "loss": 0.1929,
      "step": 3100
    },
    {
      "epoch": 0.7125459558823529,
      "grad_norm": 1.864698886871338,
      "learning_rate": 9.528696895424837e-06,
      "loss": 0.1884,
      "step": 3101
    },
    {
      "epoch": 0.7127757352941176,
      "grad_norm": 1.81575608253479,
      "learning_rate": 9.528186274509803e-06,
      "loss": 0.2002,
      "step": 3102
    },
    {
      "epoch": 0.7130055147058824,
      "grad_norm": 1.5488018989562988,
      "learning_rate": 9.527675653594773e-06,
      "loss": 0.181,
      "step": 3103
    },
    {
      "epoch": 0.7132352941176471,
      "grad_norm": 1.736042857170105,
      "learning_rate": 9.527165032679739e-06,
      "loss": 0.298,
      "step": 3104
    },
    {
      "epoch": 0.7134650735294118,
      "grad_norm": 1.445574402809143,
      "learning_rate": 9.526654411764707e-06,
      "loss": 0.1798,
      "step": 3105
    },
    {
      "epoch": 0.7136948529411765,
      "grad_norm": 1.7233009338378906,
      "learning_rate": 9.526143790849673e-06,
      "loss": 0.2074,
      "step": 3106
    },
    {
      "epoch": 0.7139246323529411,
      "grad_norm": 1.7504055500030518,
      "learning_rate": 9.525633169934641e-06,
      "loss": 0.1478,
      "step": 3107
    },
    {
      "epoch": 0.7141544117647058,
      "grad_norm": 1.5820329189300537,
      "learning_rate": 9.525122549019609e-06,
      "loss": 0.2224,
      "step": 3108
    },
    {
      "epoch": 0.7143841911764706,
      "grad_norm": 1.640787124633789,
      "learning_rate": 9.524611928104575e-06,
      "loss": 0.1927,
      "step": 3109
    },
    {
      "epoch": 0.7146139705882353,
      "grad_norm": 1.906353235244751,
      "learning_rate": 9.524101307189543e-06,
      "loss": 0.197,
      "step": 3110
    },
    {
      "epoch": 0.71484375,
      "grad_norm": 1.9701855182647705,
      "learning_rate": 9.52359068627451e-06,
      "loss": 0.2081,
      "step": 3111
    },
    {
      "epoch": 0.7150735294117647,
      "grad_norm": 1.8858669996261597,
      "learning_rate": 9.523080065359479e-06,
      "loss": 0.1946,
      "step": 3112
    },
    {
      "epoch": 0.7153033088235294,
      "grad_norm": 1.9678205251693726,
      "learning_rate": 9.522569444444445e-06,
      "loss": 0.2674,
      "step": 3113
    },
    {
      "epoch": 0.7155330882352942,
      "grad_norm": 1.8132593631744385,
      "learning_rate": 9.522058823529413e-06,
      "loss": 0.1734,
      "step": 3114
    },
    {
      "epoch": 0.7157628676470589,
      "grad_norm": 1.551748275756836,
      "learning_rate": 9.52154820261438e-06,
      "loss": 0.2191,
      "step": 3115
    },
    {
      "epoch": 0.7159926470588235,
      "grad_norm": 1.8692996501922607,
      "learning_rate": 9.521037581699347e-06,
      "loss": 0.2048,
      "step": 3116
    },
    {
      "epoch": 0.7162224264705882,
      "grad_norm": 1.6729620695114136,
      "learning_rate": 9.520526960784315e-06,
      "loss": 0.1933,
      "step": 3117
    },
    {
      "epoch": 0.7164522058823529,
      "grad_norm": 1.7572526931762695,
      "learning_rate": 9.52001633986928e-06,
      "loss": 0.1994,
      "step": 3118
    },
    {
      "epoch": 0.7166819852941176,
      "grad_norm": 1.4963059425354004,
      "learning_rate": 9.51950571895425e-06,
      "loss": 0.2252,
      "step": 3119
    },
    {
      "epoch": 0.7169117647058824,
      "grad_norm": 1.6969530582427979,
      "learning_rate": 9.518995098039216e-06,
      "loss": 0.212,
      "step": 3120
    },
    {
      "epoch": 0.7171415441176471,
      "grad_norm": 1.495124340057373,
      "learning_rate": 9.518484477124184e-06,
      "loss": 0.1917,
      "step": 3121
    },
    {
      "epoch": 0.7173713235294118,
      "grad_norm": 1.7883350849151611,
      "learning_rate": 9.51797385620915e-06,
      "loss": 0.1884,
      "step": 3122
    },
    {
      "epoch": 0.7176011029411765,
      "grad_norm": 1.7347187995910645,
      "learning_rate": 9.517463235294118e-06,
      "loss": 0.2078,
      "step": 3123
    },
    {
      "epoch": 0.7178308823529411,
      "grad_norm": 1.9013792276382446,
      "learning_rate": 9.516952614379086e-06,
      "loss": 0.1909,
      "step": 3124
    },
    {
      "epoch": 0.7180606617647058,
      "grad_norm": 1.5614969730377197,
      "learning_rate": 9.516441993464052e-06,
      "loss": 0.2189,
      "step": 3125
    },
    {
      "epoch": 0.7182904411764706,
      "grad_norm": 1.554783821105957,
      "learning_rate": 9.51593137254902e-06,
      "loss": 0.1674,
      "step": 3126
    },
    {
      "epoch": 0.7185202205882353,
      "grad_norm": 1.795667052268982,
      "learning_rate": 9.515420751633988e-06,
      "loss": 0.2257,
      "step": 3127
    },
    {
      "epoch": 0.71875,
      "grad_norm": 1.7343555688858032,
      "learning_rate": 9.514910130718956e-06,
      "loss": 0.2292,
      "step": 3128
    },
    {
      "epoch": 0.7189797794117647,
      "grad_norm": 1.4737370014190674,
      "learning_rate": 9.514399509803922e-06,
      "loss": 0.2229,
      "step": 3129
    },
    {
      "epoch": 0.7192095588235294,
      "grad_norm": 1.4347270727157593,
      "learning_rate": 9.51388888888889e-06,
      "loss": 0.229,
      "step": 3130
    },
    {
      "epoch": 0.7194393382352942,
      "grad_norm": 1.5745140314102173,
      "learning_rate": 9.513378267973858e-06,
      "loss": 0.1916,
      "step": 3131
    },
    {
      "epoch": 0.7196691176470589,
      "grad_norm": 2.041015863418579,
      "learning_rate": 9.512867647058824e-06,
      "loss": 0.2246,
      "step": 3132
    },
    {
      "epoch": 0.7198988970588235,
      "grad_norm": 1.7878397703170776,
      "learning_rate": 9.512357026143792e-06,
      "loss": 0.2742,
      "step": 3133
    },
    {
      "epoch": 0.7201286764705882,
      "grad_norm": 1.5898159742355347,
      "learning_rate": 9.511846405228758e-06,
      "loss": 0.2114,
      "step": 3134
    },
    {
      "epoch": 0.7203584558823529,
      "grad_norm": 1.265088677406311,
      "learning_rate": 9.511335784313726e-06,
      "loss": 0.1286,
      "step": 3135
    },
    {
      "epoch": 0.7205882352941176,
      "grad_norm": 1.5138722658157349,
      "learning_rate": 9.510825163398694e-06,
      "loss": 0.1871,
      "step": 3136
    },
    {
      "epoch": 0.7208180147058824,
      "grad_norm": 1.5512443780899048,
      "learning_rate": 9.51031454248366e-06,
      "loss": 0.2276,
      "step": 3137
    },
    {
      "epoch": 0.7210477941176471,
      "grad_norm": 1.3286073207855225,
      "learning_rate": 9.509803921568628e-06,
      "loss": 0.1831,
      "step": 3138
    },
    {
      "epoch": 0.7212775735294118,
      "grad_norm": 1.854729413986206,
      "learning_rate": 9.509293300653596e-06,
      "loss": 0.205,
      "step": 3139
    },
    {
      "epoch": 0.7215073529411765,
      "grad_norm": 1.5041707754135132,
      "learning_rate": 9.508782679738563e-06,
      "loss": 0.1986,
      "step": 3140
    },
    {
      "epoch": 0.7217371323529411,
      "grad_norm": 1.6287823915481567,
      "learning_rate": 9.50827205882353e-06,
      "loss": 0.2286,
      "step": 3141
    },
    {
      "epoch": 0.7219669117647058,
      "grad_norm": 1.5994901657104492,
      "learning_rate": 9.507761437908497e-06,
      "loss": 0.1811,
      "step": 3142
    },
    {
      "epoch": 0.7221966911764706,
      "grad_norm": 1.582156777381897,
      "learning_rate": 9.507250816993465e-06,
      "loss": 0.1767,
      "step": 3143
    },
    {
      "epoch": 0.7224264705882353,
      "grad_norm": 1.8565536737442017,
      "learning_rate": 9.506740196078432e-06,
      "loss": 0.2231,
      "step": 3144
    },
    {
      "epoch": 0.72265625,
      "grad_norm": 1.3155415058135986,
      "learning_rate": 9.5062295751634e-06,
      "loss": 0.1483,
      "step": 3145
    },
    {
      "epoch": 0.7228860294117647,
      "grad_norm": 1.9171379804611206,
      "learning_rate": 9.505718954248366e-06,
      "loss": 0.2055,
      "step": 3146
    },
    {
      "epoch": 0.7231158088235294,
      "grad_norm": 1.8391331434249878,
      "learning_rate": 9.505208333333335e-06,
      "loss": 0.1961,
      "step": 3147
    },
    {
      "epoch": 0.7233455882352942,
      "grad_norm": 2.072995901107788,
      "learning_rate": 9.504697712418301e-06,
      "loss": 0.2413,
      "step": 3148
    },
    {
      "epoch": 0.7235753676470589,
      "grad_norm": 1.6848373413085938,
      "learning_rate": 9.504187091503269e-06,
      "loss": 0.1901,
      "step": 3149
    },
    {
      "epoch": 0.7238051470588235,
      "grad_norm": 1.710379719734192,
      "learning_rate": 9.503676470588235e-06,
      "loss": 0.1813,
      "step": 3150
    },
    {
      "epoch": 0.7240349264705882,
      "grad_norm": 1.609013319015503,
      "learning_rate": 9.503165849673203e-06,
      "loss": 0.1843,
      "step": 3151
    },
    {
      "epoch": 0.7242647058823529,
      "grad_norm": 2.138397216796875,
      "learning_rate": 9.502655228758171e-06,
      "loss": 0.2621,
      "step": 3152
    },
    {
      "epoch": 0.7244944852941176,
      "grad_norm": 2.173454999923706,
      "learning_rate": 9.502144607843137e-06,
      "loss": 0.2309,
      "step": 3153
    },
    {
      "epoch": 0.7247242647058824,
      "grad_norm": 1.8208129405975342,
      "learning_rate": 9.501633986928105e-06,
      "loss": 0.1879,
      "step": 3154
    },
    {
      "epoch": 0.7249540441176471,
      "grad_norm": 2.0091898441314697,
      "learning_rate": 9.501123366013073e-06,
      "loss": 0.1821,
      "step": 3155
    },
    {
      "epoch": 0.7251838235294118,
      "grad_norm": 1.8715100288391113,
      "learning_rate": 9.50061274509804e-06,
      "loss": 0.1962,
      "step": 3156
    },
    {
      "epoch": 0.7254136029411765,
      "grad_norm": 1.508439302444458,
      "learning_rate": 9.500102124183007e-06,
      "loss": 0.1807,
      "step": 3157
    },
    {
      "epoch": 0.7256433823529411,
      "grad_norm": 2.3327224254608154,
      "learning_rate": 9.499591503267975e-06,
      "loss": 0.2198,
      "step": 3158
    },
    {
      "epoch": 0.7258731617647058,
      "grad_norm": 1.5465993881225586,
      "learning_rate": 9.499080882352943e-06,
      "loss": 0.1998,
      "step": 3159
    },
    {
      "epoch": 0.7261029411764706,
      "grad_norm": 1.3449469804763794,
      "learning_rate": 9.498570261437909e-06,
      "loss": 0.1423,
      "step": 3160
    },
    {
      "epoch": 0.7263327205882353,
      "grad_norm": 1.5660364627838135,
      "learning_rate": 9.498059640522877e-06,
      "loss": 0.1768,
      "step": 3161
    },
    {
      "epoch": 0.7265625,
      "grad_norm": 1.6841353178024292,
      "learning_rate": 9.497549019607843e-06,
      "loss": 0.1614,
      "step": 3162
    },
    {
      "epoch": 0.7267922794117647,
      "grad_norm": 1.9808640480041504,
      "learning_rate": 9.497038398692812e-06,
      "loss": 0.2604,
      "step": 3163
    },
    {
      "epoch": 0.7270220588235294,
      "grad_norm": 1.6936984062194824,
      "learning_rate": 9.496527777777779e-06,
      "loss": 0.2469,
      "step": 3164
    },
    {
      "epoch": 0.7272518382352942,
      "grad_norm": 1.9914578199386597,
      "learning_rate": 9.496017156862746e-06,
      "loss": 0.2185,
      "step": 3165
    },
    {
      "epoch": 0.7274816176470589,
      "grad_norm": 1.8047621250152588,
      "learning_rate": 9.495506535947713e-06,
      "loss": 0.2446,
      "step": 3166
    },
    {
      "epoch": 0.7277113970588235,
      "grad_norm": 2.0451931953430176,
      "learning_rate": 9.49499591503268e-06,
      "loss": 0.1708,
      "step": 3167
    },
    {
      "epoch": 0.7279411764705882,
      "grad_norm": 1.6303681135177612,
      "learning_rate": 9.494485294117648e-06,
      "loss": 0.1781,
      "step": 3168
    },
    {
      "epoch": 0.7281709558823529,
      "grad_norm": 2.2032785415649414,
      "learning_rate": 9.493974673202615e-06,
      "loss": 0.2394,
      "step": 3169
    },
    {
      "epoch": 0.7284007352941176,
      "grad_norm": 1.6682536602020264,
      "learning_rate": 9.493464052287582e-06,
      "loss": 0.1819,
      "step": 3170
    },
    {
      "epoch": 0.7286305147058824,
      "grad_norm": 1.6734296083450317,
      "learning_rate": 9.49295343137255e-06,
      "loss": 0.1945,
      "step": 3171
    },
    {
      "epoch": 0.7288602941176471,
      "grad_norm": 2.149522542953491,
      "learning_rate": 9.492442810457518e-06,
      "loss": 0.2042,
      "step": 3172
    },
    {
      "epoch": 0.7290900735294118,
      "grad_norm": 1.7382365465164185,
      "learning_rate": 9.491932189542484e-06,
      "loss": 0.2032,
      "step": 3173
    },
    {
      "epoch": 0.7293198529411765,
      "grad_norm": 1.5358229875564575,
      "learning_rate": 9.491421568627452e-06,
      "loss": 0.1497,
      "step": 3174
    },
    {
      "epoch": 0.7295496323529411,
      "grad_norm": 1.4177815914154053,
      "learning_rate": 9.49091094771242e-06,
      "loss": 0.1815,
      "step": 3175
    },
    {
      "epoch": 0.7297794117647058,
      "grad_norm": 1.9564608335494995,
      "learning_rate": 9.490400326797386e-06,
      "loss": 0.2186,
      "step": 3176
    },
    {
      "epoch": 0.7300091911764706,
      "grad_norm": 1.7652643918991089,
      "learning_rate": 9.489889705882354e-06,
      "loss": 0.2181,
      "step": 3177
    },
    {
      "epoch": 0.7302389705882353,
      "grad_norm": 1.625935673713684,
      "learning_rate": 9.48937908496732e-06,
      "loss": 0.1766,
      "step": 3178
    },
    {
      "epoch": 0.73046875,
      "grad_norm": 2.4498579502105713,
      "learning_rate": 9.488868464052288e-06,
      "loss": 0.2437,
      "step": 3179
    },
    {
      "epoch": 0.7306985294117647,
      "grad_norm": 1.849725604057312,
      "learning_rate": 9.488357843137256e-06,
      "loss": 0.2446,
      "step": 3180
    },
    {
      "epoch": 0.7309283088235294,
      "grad_norm": 1.8879218101501465,
      "learning_rate": 9.487847222222222e-06,
      "loss": 0.1923,
      "step": 3181
    },
    {
      "epoch": 0.7311580882352942,
      "grad_norm": 2.0733327865600586,
      "learning_rate": 9.48733660130719e-06,
      "loss": 0.2197,
      "step": 3182
    },
    {
      "epoch": 0.7313878676470589,
      "grad_norm": 1.39226233959198,
      "learning_rate": 9.486825980392158e-06,
      "loss": 0.2258,
      "step": 3183
    },
    {
      "epoch": 0.7316176470588235,
      "grad_norm": 1.4646832942962646,
      "learning_rate": 9.486315359477126e-06,
      "loss": 0.2289,
      "step": 3184
    },
    {
      "epoch": 0.7318474264705882,
      "grad_norm": 2.092926502227783,
      "learning_rate": 9.485804738562092e-06,
      "loss": 0.2008,
      "step": 3185
    },
    {
      "epoch": 0.7320772058823529,
      "grad_norm": 1.899632453918457,
      "learning_rate": 9.48529411764706e-06,
      "loss": 0.2686,
      "step": 3186
    },
    {
      "epoch": 0.7323069852941176,
      "grad_norm": 1.533322811126709,
      "learning_rate": 9.484783496732028e-06,
      "loss": 0.215,
      "step": 3187
    },
    {
      "epoch": 0.7325367647058824,
      "grad_norm": 1.8109079599380493,
      "learning_rate": 9.484272875816994e-06,
      "loss": 0.2408,
      "step": 3188
    },
    {
      "epoch": 0.7327665441176471,
      "grad_norm": 1.8376071453094482,
      "learning_rate": 9.483762254901962e-06,
      "loss": 0.2056,
      "step": 3189
    },
    {
      "epoch": 0.7329963235294118,
      "grad_norm": 2.0671935081481934,
      "learning_rate": 9.483251633986928e-06,
      "loss": 0.2367,
      "step": 3190
    },
    {
      "epoch": 0.7332261029411765,
      "grad_norm": 1.7403939962387085,
      "learning_rate": 9.482741013071897e-06,
      "loss": 0.1869,
      "step": 3191
    },
    {
      "epoch": 0.7334558823529411,
      "grad_norm": 1.9185123443603516,
      "learning_rate": 9.482230392156863e-06,
      "loss": 0.2376,
      "step": 3192
    },
    {
      "epoch": 0.7336856617647058,
      "grad_norm": 1.3261147737503052,
      "learning_rate": 9.481719771241831e-06,
      "loss": 0.2375,
      "step": 3193
    },
    {
      "epoch": 0.7339154411764706,
      "grad_norm": 1.4471263885498047,
      "learning_rate": 9.481209150326797e-06,
      "loss": 0.2363,
      "step": 3194
    },
    {
      "epoch": 0.7341452205882353,
      "grad_norm": 1.4080742597579956,
      "learning_rate": 9.480698529411765e-06,
      "loss": 0.1773,
      "step": 3195
    },
    {
      "epoch": 0.734375,
      "grad_norm": 1.5467462539672852,
      "learning_rate": 9.480187908496733e-06,
      "loss": 0.1749,
      "step": 3196
    },
    {
      "epoch": 0.7346047794117647,
      "grad_norm": 1.972769021987915,
      "learning_rate": 9.4796772875817e-06,
      "loss": 0.1872,
      "step": 3197
    },
    {
      "epoch": 0.7348345588235294,
      "grad_norm": 1.7777626514434814,
      "learning_rate": 9.479166666666667e-06,
      "loss": 0.2371,
      "step": 3198
    },
    {
      "epoch": 0.7350643382352942,
      "grad_norm": 1.5613290071487427,
      "learning_rate": 9.478656045751635e-06,
      "loss": 0.1759,
      "step": 3199
    },
    {
      "epoch": 0.7352941176470589,
      "grad_norm": 1.540522813796997,
      "learning_rate": 9.478145424836603e-06,
      "loss": 0.1724,
      "step": 3200
    },
    {
      "epoch": 0.7355238970588235,
      "grad_norm": 1.677523136138916,
      "learning_rate": 9.477634803921569e-06,
      "loss": 0.2301,
      "step": 3201
    },
    {
      "epoch": 0.7357536764705882,
      "grad_norm": 2.278921604156494,
      "learning_rate": 9.477124183006537e-06,
      "loss": 0.1954,
      "step": 3202
    },
    {
      "epoch": 0.7359834558823529,
      "grad_norm": 1.2829524278640747,
      "learning_rate": 9.476613562091505e-06,
      "loss": 0.2025,
      "step": 3203
    },
    {
      "epoch": 0.7362132352941176,
      "grad_norm": 1.8604658842086792,
      "learning_rate": 9.476102941176471e-06,
      "loss": 0.1566,
      "step": 3204
    },
    {
      "epoch": 0.7364430147058824,
      "grad_norm": 1.5949537754058838,
      "learning_rate": 9.475592320261439e-06,
      "loss": 0.2264,
      "step": 3205
    },
    {
      "epoch": 0.7366727941176471,
      "grad_norm": 1.7599035501480103,
      "learning_rate": 9.475081699346405e-06,
      "loss": 0.1699,
      "step": 3206
    },
    {
      "epoch": 0.7369025735294118,
      "grad_norm": 1.9426180124282837,
      "learning_rate": 9.474571078431375e-06,
      "loss": 0.1792,
      "step": 3207
    },
    {
      "epoch": 0.7371323529411765,
      "grad_norm": 2.70394229888916,
      "learning_rate": 9.47406045751634e-06,
      "loss": 0.2033,
      "step": 3208
    },
    {
      "epoch": 0.7373621323529411,
      "grad_norm": 2.9565703868865967,
      "learning_rate": 9.473549836601309e-06,
      "loss": 0.2421,
      "step": 3209
    },
    {
      "epoch": 0.7375919117647058,
      "grad_norm": 1.6382392644882202,
      "learning_rate": 9.473039215686275e-06,
      "loss": 0.2054,
      "step": 3210
    },
    {
      "epoch": 0.7378216911764706,
      "grad_norm": 2.0134174823760986,
      "learning_rate": 9.472528594771243e-06,
      "loss": 0.1854,
      "step": 3211
    },
    {
      "epoch": 0.7380514705882353,
      "grad_norm": 2.237671136856079,
      "learning_rate": 9.47201797385621e-06,
      "loss": 0.2352,
      "step": 3212
    },
    {
      "epoch": 0.73828125,
      "grad_norm": 1.3756660223007202,
      "learning_rate": 9.471507352941177e-06,
      "loss": 0.1897,
      "step": 3213
    },
    {
      "epoch": 0.7385110294117647,
      "grad_norm": 1.8495843410491943,
      "learning_rate": 9.470996732026145e-06,
      "loss": 0.2099,
      "step": 3214
    },
    {
      "epoch": 0.7387408088235294,
      "grad_norm": 1.6836060285568237,
      "learning_rate": 9.470486111111112e-06,
      "loss": 0.2028,
      "step": 3215
    },
    {
      "epoch": 0.7389705882352942,
      "grad_norm": 1.7235206365585327,
      "learning_rate": 9.469975490196079e-06,
      "loss": 0.2248,
      "step": 3216
    },
    {
      "epoch": 0.7392003676470589,
      "grad_norm": 1.5322812795639038,
      "learning_rate": 9.469464869281046e-06,
      "loss": 0.1768,
      "step": 3217
    },
    {
      "epoch": 0.7394301470588235,
      "grad_norm": 2.0334370136260986,
      "learning_rate": 9.468954248366014e-06,
      "loss": 0.2511,
      "step": 3218
    },
    {
      "epoch": 0.7396599264705882,
      "grad_norm": 1.7009018659591675,
      "learning_rate": 9.468443627450982e-06,
      "loss": 0.2113,
      "step": 3219
    },
    {
      "epoch": 0.7398897058823529,
      "grad_norm": 1.6753093004226685,
      "learning_rate": 9.467933006535948e-06,
      "loss": 0.209,
      "step": 3220
    },
    {
      "epoch": 0.7401194852941176,
      "grad_norm": 1.493116855621338,
      "learning_rate": 9.467422385620916e-06,
      "loss": 0.1654,
      "step": 3221
    },
    {
      "epoch": 0.7403492647058824,
      "grad_norm": 1.690103530883789,
      "learning_rate": 9.466911764705882e-06,
      "loss": 0.1848,
      "step": 3222
    },
    {
      "epoch": 0.7405790441176471,
      "grad_norm": 1.8025308847427368,
      "learning_rate": 9.46640114379085e-06,
      "loss": 0.2088,
      "step": 3223
    },
    {
      "epoch": 0.7408088235294118,
      "grad_norm": 1.582896113395691,
      "learning_rate": 9.465890522875818e-06,
      "loss": 0.2155,
      "step": 3224
    },
    {
      "epoch": 0.7410386029411765,
      "grad_norm": 2.58609938621521,
      "learning_rate": 9.465379901960784e-06,
      "loss": 0.2793,
      "step": 3225
    },
    {
      "epoch": 0.7412683823529411,
      "grad_norm": 1.913463830947876,
      "learning_rate": 9.464869281045752e-06,
      "loss": 0.2628,
      "step": 3226
    },
    {
      "epoch": 0.7414981617647058,
      "grad_norm": 1.9312249422073364,
      "learning_rate": 9.46435866013072e-06,
      "loss": 0.1892,
      "step": 3227
    },
    {
      "epoch": 0.7417279411764706,
      "grad_norm": 2.2208051681518555,
      "learning_rate": 9.463848039215688e-06,
      "loss": 0.1994,
      "step": 3228
    },
    {
      "epoch": 0.7419577205882353,
      "grad_norm": 1.5239168405532837,
      "learning_rate": 9.463337418300654e-06,
      "loss": 0.2037,
      "step": 3229
    },
    {
      "epoch": 0.7421875,
      "grad_norm": 1.7090493440628052,
      "learning_rate": 9.462826797385622e-06,
      "loss": 0.2059,
      "step": 3230
    },
    {
      "epoch": 0.7424172794117647,
      "grad_norm": 1.5470058917999268,
      "learning_rate": 9.46231617647059e-06,
      "loss": 0.1619,
      "step": 3231
    },
    {
      "epoch": 0.7426470588235294,
      "grad_norm": 1.777698278427124,
      "learning_rate": 9.461805555555556e-06,
      "loss": 0.2057,
      "step": 3232
    },
    {
      "epoch": 0.7428768382352942,
      "grad_norm": 1.4302582740783691,
      "learning_rate": 9.461294934640524e-06,
      "loss": 0.1902,
      "step": 3233
    },
    {
      "epoch": 0.7431066176470589,
      "grad_norm": 1.7914365530014038,
      "learning_rate": 9.46078431372549e-06,
      "loss": 0.2045,
      "step": 3234
    },
    {
      "epoch": 0.7433363970588235,
      "grad_norm": 1.96394681930542,
      "learning_rate": 9.46027369281046e-06,
      "loss": 0.1977,
      "step": 3235
    },
    {
      "epoch": 0.7435661764705882,
      "grad_norm": 1.4864007234573364,
      "learning_rate": 9.459763071895426e-06,
      "loss": 0.1697,
      "step": 3236
    },
    {
      "epoch": 0.7437959558823529,
      "grad_norm": 1.6845827102661133,
      "learning_rate": 9.459252450980394e-06,
      "loss": 0.2219,
      "step": 3237
    },
    {
      "epoch": 0.7440257352941176,
      "grad_norm": 1.3333414793014526,
      "learning_rate": 9.45874183006536e-06,
      "loss": 0.195,
      "step": 3238
    },
    {
      "epoch": 0.7442555147058824,
      "grad_norm": 1.8336527347564697,
      "learning_rate": 9.458231209150328e-06,
      "loss": 0.2334,
      "step": 3239
    },
    {
      "epoch": 0.7444852941176471,
      "grad_norm": 1.659981369972229,
      "learning_rate": 9.457720588235295e-06,
      "loss": 0.1724,
      "step": 3240
    },
    {
      "epoch": 0.7447150735294118,
      "grad_norm": 1.5257463455200195,
      "learning_rate": 9.457209967320262e-06,
      "loss": 0.1916,
      "step": 3241
    },
    {
      "epoch": 0.7449448529411765,
      "grad_norm": 1.2817484140396118,
      "learning_rate": 9.45669934640523e-06,
      "loss": 0.1809,
      "step": 3242
    },
    {
      "epoch": 0.7451746323529411,
      "grad_norm": 1.827061414718628,
      "learning_rate": 9.456188725490197e-06,
      "loss": 0.2745,
      "step": 3243
    },
    {
      "epoch": 0.7454044117647058,
      "grad_norm": 2.4616527557373047,
      "learning_rate": 9.455678104575165e-06,
      "loss": 0.1919,
      "step": 3244
    },
    {
      "epoch": 0.7456341911764706,
      "grad_norm": 1.4250777959823608,
      "learning_rate": 9.455167483660131e-06,
      "loss": 0.1879,
      "step": 3245
    },
    {
      "epoch": 0.7458639705882353,
      "grad_norm": 1.639051914215088,
      "learning_rate": 9.4546568627451e-06,
      "loss": 0.2116,
      "step": 3246
    },
    {
      "epoch": 0.74609375,
      "grad_norm": 1.6220906972885132,
      "learning_rate": 9.454146241830067e-06,
      "loss": 0.1609,
      "step": 3247
    },
    {
      "epoch": 0.7463235294117647,
      "grad_norm": 1.3218412399291992,
      "learning_rate": 9.453635620915033e-06,
      "loss": 0.154,
      "step": 3248
    },
    {
      "epoch": 0.7465533088235294,
      "grad_norm": 1.3271591663360596,
      "learning_rate": 9.453125000000001e-06,
      "loss": 0.1838,
      "step": 3249
    },
    {
      "epoch": 0.7467830882352942,
      "grad_norm": 1.567873477935791,
      "learning_rate": 9.452614379084967e-06,
      "loss": 0.1733,
      "step": 3250
    },
    {
      "epoch": 0.7470128676470589,
      "grad_norm": 1.8189247846603394,
      "learning_rate": 9.452103758169935e-06,
      "loss": 0.2449,
      "step": 3251
    },
    {
      "epoch": 0.7472426470588235,
      "grad_norm": 2.20106840133667,
      "learning_rate": 9.451593137254903e-06,
      "loss": 0.1931,
      "step": 3252
    },
    {
      "epoch": 0.7474724264705882,
      "grad_norm": 1.5442832708358765,
      "learning_rate": 9.45108251633987e-06,
      "loss": 0.1567,
      "step": 3253
    },
    {
      "epoch": 0.7477022058823529,
      "grad_norm": 1.8013386726379395,
      "learning_rate": 9.450571895424837e-06,
      "loss": 0.1738,
      "step": 3254
    },
    {
      "epoch": 0.7479319852941176,
      "grad_norm": 1.7412762641906738,
      "learning_rate": 9.450061274509805e-06,
      "loss": 0.2135,
      "step": 3255
    },
    {
      "epoch": 0.7481617647058824,
      "grad_norm": 1.425172209739685,
      "learning_rate": 9.449550653594773e-06,
      "loss": 0.1421,
      "step": 3256
    },
    {
      "epoch": 0.7483915441176471,
      "grad_norm": 1.6535639762878418,
      "learning_rate": 9.449040032679739e-06,
      "loss": 0.1738,
      "step": 3257
    },
    {
      "epoch": 0.7486213235294118,
      "grad_norm": 1.8322954177856445,
      "learning_rate": 9.448529411764707e-06,
      "loss": 0.1755,
      "step": 3258
    },
    {
      "epoch": 0.7488511029411765,
      "grad_norm": 1.3361178636550903,
      "learning_rate": 9.448018790849673e-06,
      "loss": 0.1704,
      "step": 3259
    },
    {
      "epoch": 0.7490808823529411,
      "grad_norm": 1.884474515914917,
      "learning_rate": 9.44750816993464e-06,
      "loss": 0.2339,
      "step": 3260
    },
    {
      "epoch": 0.7493106617647058,
      "grad_norm": 2.0412049293518066,
      "learning_rate": 9.446997549019609e-06,
      "loss": 0.2006,
      "step": 3261
    },
    {
      "epoch": 0.7495404411764706,
      "grad_norm": 1.5528373718261719,
      "learning_rate": 9.446486928104577e-06,
      "loss": 0.2283,
      "step": 3262
    },
    {
      "epoch": 0.7497702205882353,
      "grad_norm": 1.481691837310791,
      "learning_rate": 9.445976307189543e-06,
      "loss": 0.202,
      "step": 3263
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.3202755451202393,
      "learning_rate": 9.44546568627451e-06,
      "loss": 0.2725,
      "step": 3264
    },
    {
      "epoch": 0.7502297794117647,
      "grad_norm": 1.4055078029632568,
      "learning_rate": 9.444955065359478e-06,
      "loss": 0.1431,
      "step": 3265
    },
    {
      "epoch": 0.7504595588235294,
      "grad_norm": 1.936674952507019,
      "learning_rate": 9.444444444444445e-06,
      "loss": 0.1963,
      "step": 3266
    },
    {
      "epoch": 0.7506893382352942,
      "grad_norm": 1.6953761577606201,
      "learning_rate": 9.443933823529412e-06,
      "loss": 0.2097,
      "step": 3267
    },
    {
      "epoch": 0.7509191176470589,
      "grad_norm": 1.3926432132720947,
      "learning_rate": 9.44342320261438e-06,
      "loss": 0.16,
      "step": 3268
    },
    {
      "epoch": 0.7511488970588235,
      "grad_norm": 1.8478977680206299,
      "learning_rate": 9.442912581699346e-06,
      "loss": 0.2136,
      "step": 3269
    },
    {
      "epoch": 0.7513786764705882,
      "grad_norm": 1.6414408683776855,
      "learning_rate": 9.442401960784314e-06,
      "loss": 0.178,
      "step": 3270
    },
    {
      "epoch": 0.7516084558823529,
      "grad_norm": 2.1416518688201904,
      "learning_rate": 9.44189133986928e-06,
      "loss": 0.2527,
      "step": 3271
    },
    {
      "epoch": 0.7518382352941176,
      "grad_norm": 1.6717568635940552,
      "learning_rate": 9.44138071895425e-06,
      "loss": 0.2135,
      "step": 3272
    },
    {
      "epoch": 0.7520680147058824,
      "grad_norm": 2.3980541229248047,
      "learning_rate": 9.440870098039216e-06,
      "loss": 0.1903,
      "step": 3273
    },
    {
      "epoch": 0.7522977941176471,
      "grad_norm": 1.6291325092315674,
      "learning_rate": 9.440359477124184e-06,
      "loss": 0.2011,
      "step": 3274
    },
    {
      "epoch": 0.7525275735294118,
      "grad_norm": 1.3541487455368042,
      "learning_rate": 9.43984885620915e-06,
      "loss": 0.1756,
      "step": 3275
    },
    {
      "epoch": 0.7527573529411765,
      "grad_norm": 1.2227040529251099,
      "learning_rate": 9.439338235294118e-06,
      "loss": 0.1292,
      "step": 3276
    },
    {
      "epoch": 0.7529871323529411,
      "grad_norm": 1.7466909885406494,
      "learning_rate": 9.438827614379086e-06,
      "loss": 0.205,
      "step": 3277
    },
    {
      "epoch": 0.7532169117647058,
      "grad_norm": 1.6371140480041504,
      "learning_rate": 9.438316993464052e-06,
      "loss": 0.2157,
      "step": 3278
    },
    {
      "epoch": 0.7534466911764706,
      "grad_norm": 1.8761036396026611,
      "learning_rate": 9.43780637254902e-06,
      "loss": 0.2387,
      "step": 3279
    },
    {
      "epoch": 0.7536764705882353,
      "grad_norm": 1.2821811437606812,
      "learning_rate": 9.437295751633988e-06,
      "loss": 0.1467,
      "step": 3280
    },
    {
      "epoch": 0.75390625,
      "grad_norm": 1.7856426239013672,
      "learning_rate": 9.436785130718956e-06,
      "loss": 0.1699,
      "step": 3281
    },
    {
      "epoch": 0.7541360294117647,
      "grad_norm": 2.020075559616089,
      "learning_rate": 9.436274509803922e-06,
      "loss": 0.1714,
      "step": 3282
    },
    {
      "epoch": 0.7543658088235294,
      "grad_norm": 1.7933403253555298,
      "learning_rate": 9.43576388888889e-06,
      "loss": 0.2334,
      "step": 3283
    },
    {
      "epoch": 0.7545955882352942,
      "grad_norm": 1.3166356086730957,
      "learning_rate": 9.435253267973858e-06,
      "loss": 0.1809,
      "step": 3284
    },
    {
      "epoch": 0.7548253676470589,
      "grad_norm": 1.379265546798706,
      "learning_rate": 9.434742647058824e-06,
      "loss": 0.1829,
      "step": 3285
    },
    {
      "epoch": 0.7550551470588235,
      "grad_norm": 1.578553557395935,
      "learning_rate": 9.434232026143792e-06,
      "loss": 0.1584,
      "step": 3286
    },
    {
      "epoch": 0.7552849264705882,
      "grad_norm": 1.8334506750106812,
      "learning_rate": 9.433721405228758e-06,
      "loss": 0.2104,
      "step": 3287
    },
    {
      "epoch": 0.7555147058823529,
      "grad_norm": 1.8215709924697876,
      "learning_rate": 9.433210784313727e-06,
      "loss": 0.1893,
      "step": 3288
    },
    {
      "epoch": 0.7557444852941176,
      "grad_norm": 1.5232278108596802,
      "learning_rate": 9.432700163398694e-06,
      "loss": 0.27,
      "step": 3289
    },
    {
      "epoch": 0.7559742647058824,
      "grad_norm": 1.5040247440338135,
      "learning_rate": 9.432189542483661e-06,
      "loss": 0.142,
      "step": 3290
    },
    {
      "epoch": 0.7562040441176471,
      "grad_norm": 1.5513218641281128,
      "learning_rate": 9.431678921568628e-06,
      "loss": 0.2195,
      "step": 3291
    },
    {
      "epoch": 0.7564338235294118,
      "grad_norm": 1.913421869277954,
      "learning_rate": 9.431168300653595e-06,
      "loss": 0.251,
      "step": 3292
    },
    {
      "epoch": 0.7566636029411765,
      "grad_norm": 1.6926594972610474,
      "learning_rate": 9.430657679738563e-06,
      "loss": 0.192,
      "step": 3293
    },
    {
      "epoch": 0.7568933823529411,
      "grad_norm": 1.9125515222549438,
      "learning_rate": 9.43014705882353e-06,
      "loss": 0.2022,
      "step": 3294
    },
    {
      "epoch": 0.7571231617647058,
      "grad_norm": 1.9996931552886963,
      "learning_rate": 9.429636437908497e-06,
      "loss": 0.2155,
      "step": 3295
    },
    {
      "epoch": 0.7573529411764706,
      "grad_norm": 1.5712755918502808,
      "learning_rate": 9.429125816993465e-06,
      "loss": 0.1414,
      "step": 3296
    },
    {
      "epoch": 0.7575827205882353,
      "grad_norm": 1.913805603981018,
      "learning_rate": 9.428615196078433e-06,
      "loss": 0.1556,
      "step": 3297
    },
    {
      "epoch": 0.7578125,
      "grad_norm": 1.5186630487442017,
      "learning_rate": 9.4281045751634e-06,
      "loss": 0.1287,
      "step": 3298
    },
    {
      "epoch": 0.7580422794117647,
      "grad_norm": 1.8354486227035522,
      "learning_rate": 9.427593954248367e-06,
      "loss": 0.2357,
      "step": 3299
    },
    {
      "epoch": 0.7582720588235294,
      "grad_norm": 1.8405476808547974,
      "learning_rate": 9.427083333333335e-06,
      "loss": 0.1469,
      "step": 3300
    },
    {
      "epoch": 0.7585018382352942,
      "grad_norm": 2.059570789337158,
      "learning_rate": 9.426572712418301e-06,
      "loss": 0.2067,
      "step": 3301
    },
    {
      "epoch": 0.7587316176470589,
      "grad_norm": 1.9497191905975342,
      "learning_rate": 9.426062091503269e-06,
      "loss": 0.2482,
      "step": 3302
    },
    {
      "epoch": 0.7589613970588235,
      "grad_norm": 2.36026668548584,
      "learning_rate": 9.425551470588235e-06,
      "loss": 0.2411,
      "step": 3303
    },
    {
      "epoch": 0.7591911764705882,
      "grad_norm": 1.4649325609207153,
      "learning_rate": 9.425040849673203e-06,
      "loss": 0.1835,
      "step": 3304
    },
    {
      "epoch": 0.7594209558823529,
      "grad_norm": 1.4181979894638062,
      "learning_rate": 9.42453022875817e-06,
      "loss": 0.143,
      "step": 3305
    },
    {
      "epoch": 0.7596507352941176,
      "grad_norm": 1.5878173112869263,
      "learning_rate": 9.424019607843139e-06,
      "loss": 0.2009,
      "step": 3306
    },
    {
      "epoch": 0.7598805147058824,
      "grad_norm": 1.559709072113037,
      "learning_rate": 9.423508986928105e-06,
      "loss": 0.1398,
      "step": 3307
    },
    {
      "epoch": 0.7601102941176471,
      "grad_norm": 1.730908989906311,
      "learning_rate": 9.422998366013073e-06,
      "loss": 0.2129,
      "step": 3308
    },
    {
      "epoch": 0.7603400735294118,
      "grad_norm": 1.8130371570587158,
      "learning_rate": 9.42248774509804e-06,
      "loss": 0.187,
      "step": 3309
    },
    {
      "epoch": 0.7605698529411765,
      "grad_norm": 1.4126726388931274,
      "learning_rate": 9.421977124183007e-06,
      "loss": 0.168,
      "step": 3310
    },
    {
      "epoch": 0.7607996323529411,
      "grad_norm": 1.3711360692977905,
      "learning_rate": 9.421466503267975e-06,
      "loss": 0.1931,
      "step": 3311
    },
    {
      "epoch": 0.7610294117647058,
      "grad_norm": 1.4716122150421143,
      "learning_rate": 9.420955882352942e-06,
      "loss": 0.2112,
      "step": 3312
    },
    {
      "epoch": 0.7612591911764706,
      "grad_norm": 1.5294616222381592,
      "learning_rate": 9.420445261437909e-06,
      "loss": 0.1846,
      "step": 3313
    },
    {
      "epoch": 0.7614889705882353,
      "grad_norm": 1.335581660270691,
      "learning_rate": 9.419934640522876e-06,
      "loss": 0.1933,
      "step": 3314
    },
    {
      "epoch": 0.76171875,
      "grad_norm": 1.7682485580444336,
      "learning_rate": 9.419424019607843e-06,
      "loss": 0.2352,
      "step": 3315
    },
    {
      "epoch": 0.7619485294117647,
      "grad_norm": 1.397308588027954,
      "learning_rate": 9.418913398692812e-06,
      "loss": 0.1674,
      "step": 3316
    },
    {
      "epoch": 0.7621783088235294,
      "grad_norm": 1.7500680685043335,
      "learning_rate": 9.418402777777778e-06,
      "loss": 0.1558,
      "step": 3317
    },
    {
      "epoch": 0.7624080882352942,
      "grad_norm": 1.8130029439926147,
      "learning_rate": 9.417892156862746e-06,
      "loss": 0.1919,
      "step": 3318
    },
    {
      "epoch": 0.7626378676470589,
      "grad_norm": 1.687332272529602,
      "learning_rate": 9.417381535947712e-06,
      "loss": 0.1408,
      "step": 3319
    },
    {
      "epoch": 0.7628676470588235,
      "grad_norm": 1.9032329320907593,
      "learning_rate": 9.41687091503268e-06,
      "loss": 0.1855,
      "step": 3320
    },
    {
      "epoch": 0.7630974264705882,
      "grad_norm": 2.1231417655944824,
      "learning_rate": 9.416360294117648e-06,
      "loss": 0.3024,
      "step": 3321
    },
    {
      "epoch": 0.7633272058823529,
      "grad_norm": 1.498488426208496,
      "learning_rate": 9.415849673202614e-06,
      "loss": 0.1936,
      "step": 3322
    },
    {
      "epoch": 0.7635569852941176,
      "grad_norm": 1.9349011182785034,
      "learning_rate": 9.415339052287582e-06,
      "loss": 0.2292,
      "step": 3323
    },
    {
      "epoch": 0.7637867647058824,
      "grad_norm": 1.7315239906311035,
      "learning_rate": 9.41482843137255e-06,
      "loss": 0.206,
      "step": 3324
    },
    {
      "epoch": 0.7640165441176471,
      "grad_norm": 1.6327496767044067,
      "learning_rate": 9.414317810457518e-06,
      "loss": 0.2251,
      "step": 3325
    },
    {
      "epoch": 0.7642463235294118,
      "grad_norm": 2.246993064880371,
      "learning_rate": 9.413807189542484e-06,
      "loss": 0.2783,
      "step": 3326
    },
    {
      "epoch": 0.7644761029411765,
      "grad_norm": 2.3588180541992188,
      "learning_rate": 9.413296568627452e-06,
      "loss": 0.1943,
      "step": 3327
    },
    {
      "epoch": 0.7647058823529411,
      "grad_norm": 1.8439399003982544,
      "learning_rate": 9.41278594771242e-06,
      "loss": 0.2115,
      "step": 3328
    },
    {
      "epoch": 0.7649356617647058,
      "grad_norm": 1.8108197450637817,
      "learning_rate": 9.412275326797386e-06,
      "loss": 0.1847,
      "step": 3329
    },
    {
      "epoch": 0.7651654411764706,
      "grad_norm": 1.7162070274353027,
      "learning_rate": 9.411764705882354e-06,
      "loss": 0.1794,
      "step": 3330
    },
    {
      "epoch": 0.7653952205882353,
      "grad_norm": 1.5096538066864014,
      "learning_rate": 9.41125408496732e-06,
      "loss": 0.1193,
      "step": 3331
    },
    {
      "epoch": 0.765625,
      "grad_norm": 2.1256659030914307,
      "learning_rate": 9.41074346405229e-06,
      "loss": 0.2575,
      "step": 3332
    },
    {
      "epoch": 0.7658547794117647,
      "grad_norm": 1.305049180984497,
      "learning_rate": 9.410232843137256e-06,
      "loss": 0.1873,
      "step": 3333
    },
    {
      "epoch": 0.7660845588235294,
      "grad_norm": 1.6645426750183105,
      "learning_rate": 9.409722222222224e-06,
      "loss": 0.2124,
      "step": 3334
    },
    {
      "epoch": 0.7663143382352942,
      "grad_norm": 1.727813720703125,
      "learning_rate": 9.40921160130719e-06,
      "loss": 0.2487,
      "step": 3335
    },
    {
      "epoch": 0.7665441176470589,
      "grad_norm": 1.7415130138397217,
      "learning_rate": 9.408700980392158e-06,
      "loss": 0.2173,
      "step": 3336
    },
    {
      "epoch": 0.7667738970588235,
      "grad_norm": 1.6036738157272339,
      "learning_rate": 9.408190359477125e-06,
      "loss": 0.1812,
      "step": 3337
    },
    {
      "epoch": 0.7670036764705882,
      "grad_norm": 1.7408767938613892,
      "learning_rate": 9.407679738562092e-06,
      "loss": 0.1962,
      "step": 3338
    },
    {
      "epoch": 0.7672334558823529,
      "grad_norm": 1.5296415090560913,
      "learning_rate": 9.40716911764706e-06,
      "loss": 0.1579,
      "step": 3339
    },
    {
      "epoch": 0.7674632352941176,
      "grad_norm": 1.4027806520462036,
      "learning_rate": 9.406658496732027e-06,
      "loss": 0.1678,
      "step": 3340
    },
    {
      "epoch": 0.7676930147058824,
      "grad_norm": 1.9668577909469604,
      "learning_rate": 9.406147875816995e-06,
      "loss": 0.2332,
      "step": 3341
    },
    {
      "epoch": 0.7679227941176471,
      "grad_norm": 1.4311898946762085,
      "learning_rate": 9.405637254901961e-06,
      "loss": 0.1707,
      "step": 3342
    },
    {
      "epoch": 0.7681525735294118,
      "grad_norm": 1.5875024795532227,
      "learning_rate": 9.40512663398693e-06,
      "loss": 0.2044,
      "step": 3343
    },
    {
      "epoch": 0.7683823529411765,
      "grad_norm": 1.5405020713806152,
      "learning_rate": 9.404616013071897e-06,
      "loss": 0.1621,
      "step": 3344
    },
    {
      "epoch": 0.7686121323529411,
      "grad_norm": 1.9313281774520874,
      "learning_rate": 9.404105392156863e-06,
      "loss": 0.2129,
      "step": 3345
    },
    {
      "epoch": 0.7688419117647058,
      "grad_norm": 1.5288540124893188,
      "learning_rate": 9.403594771241831e-06,
      "loss": 0.1504,
      "step": 3346
    },
    {
      "epoch": 0.7690716911764706,
      "grad_norm": 1.529354453086853,
      "learning_rate": 9.403084150326797e-06,
      "loss": 0.136,
      "step": 3347
    },
    {
      "epoch": 0.7693014705882353,
      "grad_norm": 1.6747355461120605,
      "learning_rate": 9.402573529411765e-06,
      "loss": 0.2311,
      "step": 3348
    },
    {
      "epoch": 0.76953125,
      "grad_norm": 1.9613898992538452,
      "learning_rate": 9.402062908496733e-06,
      "loss": 0.1887,
      "step": 3349
    },
    {
      "epoch": 0.7697610294117647,
      "grad_norm": 1.6145520210266113,
      "learning_rate": 9.4015522875817e-06,
      "loss": 0.186,
      "step": 3350
    },
    {
      "epoch": 0.7699908088235294,
      "grad_norm": 1.6739435195922852,
      "learning_rate": 9.401041666666667e-06,
      "loss": 0.1527,
      "step": 3351
    },
    {
      "epoch": 0.7702205882352942,
      "grad_norm": 2.589134693145752,
      "learning_rate": 9.400531045751635e-06,
      "loss": 0.2242,
      "step": 3352
    },
    {
      "epoch": 0.7704503676470589,
      "grad_norm": 1.53933584690094,
      "learning_rate": 9.400020424836603e-06,
      "loss": 0.1689,
      "step": 3353
    },
    {
      "epoch": 0.7706801470588235,
      "grad_norm": 1.8915164470672607,
      "learning_rate": 9.399509803921569e-06,
      "loss": 0.1809,
      "step": 3354
    },
    {
      "epoch": 0.7709099264705882,
      "grad_norm": 1.4520870447158813,
      "learning_rate": 9.398999183006537e-06,
      "loss": 0.1866,
      "step": 3355
    },
    {
      "epoch": 0.7711397058823529,
      "grad_norm": 2.5888795852661133,
      "learning_rate": 9.398488562091505e-06,
      "loss": 0.1942,
      "step": 3356
    },
    {
      "epoch": 0.7713694852941176,
      "grad_norm": 1.8872944116592407,
      "learning_rate": 9.39797794117647e-06,
      "loss": 0.1838,
      "step": 3357
    },
    {
      "epoch": 0.7715992647058824,
      "grad_norm": 2.0163145065307617,
      "learning_rate": 9.397467320261439e-06,
      "loss": 0.19,
      "step": 3358
    },
    {
      "epoch": 0.7718290441176471,
      "grad_norm": 2.078313112258911,
      "learning_rate": 9.396956699346405e-06,
      "loss": 0.2059,
      "step": 3359
    },
    {
      "epoch": 0.7720588235294118,
      "grad_norm": 2.5315756797790527,
      "learning_rate": 9.396446078431374e-06,
      "loss": 0.2261,
      "step": 3360
    },
    {
      "epoch": 0.7722886029411765,
      "grad_norm": 2.454469919204712,
      "learning_rate": 9.39593545751634e-06,
      "loss": 0.1461,
      "step": 3361
    },
    {
      "epoch": 0.7725183823529411,
      "grad_norm": 1.8963698148727417,
      "learning_rate": 9.395424836601308e-06,
      "loss": 0.1867,
      "step": 3362
    },
    {
      "epoch": 0.7727481617647058,
      "grad_norm": 1.6216511726379395,
      "learning_rate": 9.394914215686275e-06,
      "loss": 0.1929,
      "step": 3363
    },
    {
      "epoch": 0.7729779411764706,
      "grad_norm": 1.7255076169967651,
      "learning_rate": 9.394403594771242e-06,
      "loss": 0.1551,
      "step": 3364
    },
    {
      "epoch": 0.7732077205882353,
      "grad_norm": 1.9216516017913818,
      "learning_rate": 9.39389297385621e-06,
      "loss": 0.2298,
      "step": 3365
    },
    {
      "epoch": 0.7734375,
      "grad_norm": 1.6899032592773438,
      "learning_rate": 9.393382352941176e-06,
      "loss": 0.2534,
      "step": 3366
    },
    {
      "epoch": 0.7736672794117647,
      "grad_norm": 1.6463277339935303,
      "learning_rate": 9.392871732026144e-06,
      "loss": 0.1577,
      "step": 3367
    },
    {
      "epoch": 0.7738970588235294,
      "grad_norm": 2.0318944454193115,
      "learning_rate": 9.392361111111112e-06,
      "loss": 0.2026,
      "step": 3368
    },
    {
      "epoch": 0.7741268382352942,
      "grad_norm": 1.809903621673584,
      "learning_rate": 9.39185049019608e-06,
      "loss": 0.1487,
      "step": 3369
    },
    {
      "epoch": 0.7743566176470589,
      "grad_norm": 1.61953604221344,
      "learning_rate": 9.391339869281046e-06,
      "loss": 0.1354,
      "step": 3370
    },
    {
      "epoch": 0.7745863970588235,
      "grad_norm": 1.7451872825622559,
      "learning_rate": 9.390829248366014e-06,
      "loss": 0.1382,
      "step": 3371
    },
    {
      "epoch": 0.7748161764705882,
      "grad_norm": 1.6205610036849976,
      "learning_rate": 9.390318627450982e-06,
      "loss": 0.2445,
      "step": 3372
    },
    {
      "epoch": 0.7750459558823529,
      "grad_norm": 1.9260708093643188,
      "learning_rate": 9.389808006535948e-06,
      "loss": 0.2075,
      "step": 3373
    },
    {
      "epoch": 0.7752757352941176,
      "grad_norm": 1.727976679801941,
      "learning_rate": 9.389297385620916e-06,
      "loss": 0.1587,
      "step": 3374
    },
    {
      "epoch": 0.7755055147058824,
      "grad_norm": 1.4184848070144653,
      "learning_rate": 9.388786764705882e-06,
      "loss": 0.1386,
      "step": 3375
    },
    {
      "epoch": 0.7757352941176471,
      "grad_norm": 2.2041332721710205,
      "learning_rate": 9.388276143790852e-06,
      "loss": 0.2245,
      "step": 3376
    },
    {
      "epoch": 0.7759650735294118,
      "grad_norm": 2.141233444213867,
      "learning_rate": 9.387765522875818e-06,
      "loss": 0.2098,
      "step": 3377
    },
    {
      "epoch": 0.7761948529411765,
      "grad_norm": 1.9096696376800537,
      "learning_rate": 9.387254901960786e-06,
      "loss": 0.1846,
      "step": 3378
    },
    {
      "epoch": 0.7764246323529411,
      "grad_norm": 1.476041316986084,
      "learning_rate": 9.386744281045752e-06,
      "loss": 0.1965,
      "step": 3379
    },
    {
      "epoch": 0.7766544117647058,
      "grad_norm": 1.8641655445098877,
      "learning_rate": 9.38623366013072e-06,
      "loss": 0.2473,
      "step": 3380
    },
    {
      "epoch": 0.7768841911764706,
      "grad_norm": 1.6469988822937012,
      "learning_rate": 9.385723039215688e-06,
      "loss": 0.1955,
      "step": 3381
    },
    {
      "epoch": 0.7771139705882353,
      "grad_norm": 1.37273371219635,
      "learning_rate": 9.385212418300654e-06,
      "loss": 0.1701,
      "step": 3382
    },
    {
      "epoch": 0.77734375,
      "grad_norm": 1.8311244249343872,
      "learning_rate": 9.384701797385622e-06,
      "loss": 0.1575,
      "step": 3383
    },
    {
      "epoch": 0.7775735294117647,
      "grad_norm": 1.5654023885726929,
      "learning_rate": 9.38419117647059e-06,
      "loss": 0.193,
      "step": 3384
    },
    {
      "epoch": 0.7778033088235294,
      "grad_norm": 1.187598705291748,
      "learning_rate": 9.383680555555557e-06,
      "loss": 0.167,
      "step": 3385
    },
    {
      "epoch": 0.7780330882352942,
      "grad_norm": 1.6080394983291626,
      "learning_rate": 9.383169934640524e-06,
      "loss": 0.1887,
      "step": 3386
    },
    {
      "epoch": 0.7782628676470589,
      "grad_norm": 1.666121482849121,
      "learning_rate": 9.382659313725491e-06,
      "loss": 0.1769,
      "step": 3387
    },
    {
      "epoch": 0.7784926470588235,
      "grad_norm": 1.9478603601455688,
      "learning_rate": 9.38214869281046e-06,
      "loss": 0.1574,
      "step": 3388
    },
    {
      "epoch": 0.7787224264705882,
      "grad_norm": 2.480240821838379,
      "learning_rate": 9.381638071895425e-06,
      "loss": 0.2276,
      "step": 3389
    },
    {
      "epoch": 0.7789522058823529,
      "grad_norm": 1.462739109992981,
      "learning_rate": 9.381127450980393e-06,
      "loss": 0.1852,
      "step": 3390
    },
    {
      "epoch": 0.7791819852941176,
      "grad_norm": 1.5368741750717163,
      "learning_rate": 9.38061683006536e-06,
      "loss": 0.1731,
      "step": 3391
    },
    {
      "epoch": 0.7794117647058824,
      "grad_norm": 2.1613669395446777,
      "learning_rate": 9.380106209150327e-06,
      "loss": 0.2511,
      "step": 3392
    },
    {
      "epoch": 0.7796415441176471,
      "grad_norm": 1.9155839681625366,
      "learning_rate": 9.379595588235295e-06,
      "loss": 0.1937,
      "step": 3393
    },
    {
      "epoch": 0.7798713235294118,
      "grad_norm": 2.1653661727905273,
      "learning_rate": 9.379084967320261e-06,
      "loss": 0.2083,
      "step": 3394
    },
    {
      "epoch": 0.7801011029411765,
      "grad_norm": 1.9259092807769775,
      "learning_rate": 9.37857434640523e-06,
      "loss": 0.2174,
      "step": 3395
    },
    {
      "epoch": 0.7803308823529411,
      "grad_norm": 1.4910544157028198,
      "learning_rate": 9.378063725490197e-06,
      "loss": 0.189,
      "step": 3396
    },
    {
      "epoch": 0.7805606617647058,
      "grad_norm": 2.097625255584717,
      "learning_rate": 9.377553104575165e-06,
      "loss": 0.1558,
      "step": 3397
    },
    {
      "epoch": 0.7807904411764706,
      "grad_norm": 1.6178138256072998,
      "learning_rate": 9.377042483660131e-06,
      "loss": 0.1913,
      "step": 3398
    },
    {
      "epoch": 0.7810202205882353,
      "grad_norm": 1.8604627847671509,
      "learning_rate": 9.376531862745099e-06,
      "loss": 0.1872,
      "step": 3399
    },
    {
      "epoch": 0.78125,
      "grad_norm": 1.6980620622634888,
      "learning_rate": 9.376021241830067e-06,
      "loss": 0.1893,
      "step": 3400
    },
    {
      "epoch": 0.7814797794117647,
      "grad_norm": 1.4765442609786987,
      "learning_rate": 9.375510620915033e-06,
      "loss": 0.1697,
      "step": 3401
    },
    {
      "epoch": 0.7817095588235294,
      "grad_norm": 1.5141805410385132,
      "learning_rate": 9.375000000000001e-06,
      "loss": 0.1846,
      "step": 3402
    },
    {
      "epoch": 0.7819393382352942,
      "grad_norm": 1.3327232599258423,
      "learning_rate": 9.374489379084967e-06,
      "loss": 0.1809,
      "step": 3403
    },
    {
      "epoch": 0.7821691176470589,
      "grad_norm": 1.637894868850708,
      "learning_rate": 9.373978758169935e-06,
      "loss": 0.171,
      "step": 3404
    },
    {
      "epoch": 0.7823988970588235,
      "grad_norm": 1.848511815071106,
      "learning_rate": 9.373468137254903e-06,
      "loss": 0.1797,
      "step": 3405
    },
    {
      "epoch": 0.7826286764705882,
      "grad_norm": 1.8844692707061768,
      "learning_rate": 9.37295751633987e-06,
      "loss": 0.1923,
      "step": 3406
    },
    {
      "epoch": 0.7828584558823529,
      "grad_norm": 1.718265414237976,
      "learning_rate": 9.372446895424837e-06,
      "loss": 0.1343,
      "step": 3407
    },
    {
      "epoch": 0.7830882352941176,
      "grad_norm": 1.4617364406585693,
      "learning_rate": 9.371936274509805e-06,
      "loss": 0.1803,
      "step": 3408
    },
    {
      "epoch": 0.7833180147058824,
      "grad_norm": 1.7947683334350586,
      "learning_rate": 9.371425653594773e-06,
      "loss": 0.212,
      "step": 3409
    },
    {
      "epoch": 0.7835477941176471,
      "grad_norm": 1.8278738260269165,
      "learning_rate": 9.370915032679739e-06,
      "loss": 0.1751,
      "step": 3410
    },
    {
      "epoch": 0.7837775735294118,
      "grad_norm": 1.6454969644546509,
      "learning_rate": 9.370404411764707e-06,
      "loss": 0.2044,
      "step": 3411
    },
    {
      "epoch": 0.7840073529411765,
      "grad_norm": 2.1943347454071045,
      "learning_rate": 9.369893790849673e-06,
      "loss": 0.2736,
      "step": 3412
    },
    {
      "epoch": 0.7842371323529411,
      "grad_norm": 1.8938294649124146,
      "learning_rate": 9.369383169934642e-06,
      "loss": 0.1473,
      "step": 3413
    },
    {
      "epoch": 0.7844669117647058,
      "grad_norm": 1.9500854015350342,
      "learning_rate": 9.368872549019608e-06,
      "loss": 0.1891,
      "step": 3414
    },
    {
      "epoch": 0.7846966911764706,
      "grad_norm": 1.6301143169403076,
      "learning_rate": 9.368361928104576e-06,
      "loss": 0.2525,
      "step": 3415
    },
    {
      "epoch": 0.7849264705882353,
      "grad_norm": 1.7449421882629395,
      "learning_rate": 9.367851307189542e-06,
      "loss": 0.2026,
      "step": 3416
    },
    {
      "epoch": 0.78515625,
      "grad_norm": 1.4451557397842407,
      "learning_rate": 9.36734068627451e-06,
      "loss": 0.1998,
      "step": 3417
    },
    {
      "epoch": 0.7853860294117647,
      "grad_norm": 1.8217439651489258,
      "learning_rate": 9.366830065359478e-06,
      "loss": 0.2098,
      "step": 3418
    },
    {
      "epoch": 0.7856158088235294,
      "grad_norm": 1.4450984001159668,
      "learning_rate": 9.366319444444444e-06,
      "loss": 0.2083,
      "step": 3419
    },
    {
      "epoch": 0.7858455882352942,
      "grad_norm": 1.1761878728866577,
      "learning_rate": 9.365808823529412e-06,
      "loss": 0.1824,
      "step": 3420
    },
    {
      "epoch": 0.7860753676470589,
      "grad_norm": 1.7486562728881836,
      "learning_rate": 9.36529820261438e-06,
      "loss": 0.1941,
      "step": 3421
    },
    {
      "epoch": 0.7863051470588235,
      "grad_norm": 1.627756953239441,
      "learning_rate": 9.364787581699348e-06,
      "loss": 0.1741,
      "step": 3422
    },
    {
      "epoch": 0.7865349264705882,
      "grad_norm": 1.438538908958435,
      "learning_rate": 9.364276960784314e-06,
      "loss": 0.1854,
      "step": 3423
    },
    {
      "epoch": 0.7867647058823529,
      "grad_norm": 1.5968793630599976,
      "learning_rate": 9.363766339869282e-06,
      "loss": 0.1928,
      "step": 3424
    },
    {
      "epoch": 0.7869944852941176,
      "grad_norm": 1.616062045097351,
      "learning_rate": 9.36325571895425e-06,
      "loss": 0.1459,
      "step": 3425
    },
    {
      "epoch": 0.7872242647058824,
      "grad_norm": 2.0174856185913086,
      "learning_rate": 9.362745098039216e-06,
      "loss": 0.1866,
      "step": 3426
    },
    {
      "epoch": 0.7874540441176471,
      "grad_norm": 2.3012301921844482,
      "learning_rate": 9.362234477124184e-06,
      "loss": 0.2647,
      "step": 3427
    },
    {
      "epoch": 0.7876838235294118,
      "grad_norm": 1.8107529878616333,
      "learning_rate": 9.36172385620915e-06,
      "loss": 0.1804,
      "step": 3428
    },
    {
      "epoch": 0.7879136029411765,
      "grad_norm": 1.787716031074524,
      "learning_rate": 9.36121323529412e-06,
      "loss": 0.1291,
      "step": 3429
    },
    {
      "epoch": 0.7881433823529411,
      "grad_norm": 1.6523535251617432,
      "learning_rate": 9.360702614379086e-06,
      "loss": 0.1607,
      "step": 3430
    },
    {
      "epoch": 0.7883731617647058,
      "grad_norm": 1.7410355806350708,
      "learning_rate": 9.360191993464054e-06,
      "loss": 0.1957,
      "step": 3431
    },
    {
      "epoch": 0.7886029411764706,
      "grad_norm": 1.4040096998214722,
      "learning_rate": 9.35968137254902e-06,
      "loss": 0.1442,
      "step": 3432
    },
    {
      "epoch": 0.7888327205882353,
      "grad_norm": 1.8538638353347778,
      "learning_rate": 9.359170751633988e-06,
      "loss": 0.2212,
      "step": 3433
    },
    {
      "epoch": 0.7890625,
      "grad_norm": 1.4206172227859497,
      "learning_rate": 9.358660130718955e-06,
      "loss": 0.1475,
      "step": 3434
    },
    {
      "epoch": 0.7892922794117647,
      "grad_norm": 1.8026643991470337,
      "learning_rate": 9.358149509803922e-06,
      "loss": 0.2082,
      "step": 3435
    },
    {
      "epoch": 0.7895220588235294,
      "grad_norm": 1.2577099800109863,
      "learning_rate": 9.35763888888889e-06,
      "loss": 0.1817,
      "step": 3436
    },
    {
      "epoch": 0.7897518382352942,
      "grad_norm": 1.6769366264343262,
      "learning_rate": 9.357128267973857e-06,
      "loss": 0.1855,
      "step": 3437
    },
    {
      "epoch": 0.7899816176470589,
      "grad_norm": 1.4405289888381958,
      "learning_rate": 9.356617647058824e-06,
      "loss": 0.2096,
      "step": 3438
    },
    {
      "epoch": 0.7902113970588235,
      "grad_norm": 1.3566983938217163,
      "learning_rate": 9.356107026143791e-06,
      "loss": 0.167,
      "step": 3439
    },
    {
      "epoch": 0.7904411764705882,
      "grad_norm": 1.797149658203125,
      "learning_rate": 9.35559640522876e-06,
      "loss": 0.1296,
      "step": 3440
    },
    {
      "epoch": 0.7906709558823529,
      "grad_norm": 1.4080065488815308,
      "learning_rate": 9.355085784313727e-06,
      "loss": 0.1935,
      "step": 3441
    },
    {
      "epoch": 0.7909007352941176,
      "grad_norm": 1.7759591341018677,
      "learning_rate": 9.354575163398693e-06,
      "loss": 0.1684,
      "step": 3442
    },
    {
      "epoch": 0.7911305147058824,
      "grad_norm": 1.7592535018920898,
      "learning_rate": 9.354064542483661e-06,
      "loss": 0.1954,
      "step": 3443
    },
    {
      "epoch": 0.7913602941176471,
      "grad_norm": 1.6716006994247437,
      "learning_rate": 9.353553921568627e-06,
      "loss": 0.183,
      "step": 3444
    },
    {
      "epoch": 0.7915900735294118,
      "grad_norm": 1.7354350090026855,
      "learning_rate": 9.353043300653595e-06,
      "loss": 0.2099,
      "step": 3445
    },
    {
      "epoch": 0.7918198529411765,
      "grad_norm": 1.7801493406295776,
      "learning_rate": 9.352532679738563e-06,
      "loss": 0.1697,
      "step": 3446
    },
    {
      "epoch": 0.7920496323529411,
      "grad_norm": 1.5636699199676514,
      "learning_rate": 9.35202205882353e-06,
      "loss": 0.1876,
      "step": 3447
    },
    {
      "epoch": 0.7922794117647058,
      "grad_norm": 2.091930389404297,
      "learning_rate": 9.351511437908497e-06,
      "loss": 0.2394,
      "step": 3448
    },
    {
      "epoch": 0.7925091911764706,
      "grad_norm": 1.8490533828735352,
      "learning_rate": 9.351000816993465e-06,
      "loss": 0.1874,
      "step": 3449
    },
    {
      "epoch": 0.7927389705882353,
      "grad_norm": 1.4983139038085938,
      "learning_rate": 9.350490196078433e-06,
      "loss": 0.1644,
      "step": 3450
    },
    {
      "epoch": 0.79296875,
      "grad_norm": 1.641403317451477,
      "learning_rate": 9.349979575163399e-06,
      "loss": 0.18,
      "step": 3451
    },
    {
      "epoch": 0.7931985294117647,
      "grad_norm": 1.837813138961792,
      "learning_rate": 9.349468954248367e-06,
      "loss": 0.2044,
      "step": 3452
    },
    {
      "epoch": 0.7934283088235294,
      "grad_norm": 1.5943466424942017,
      "learning_rate": 9.348958333333335e-06,
      "loss": 0.1847,
      "step": 3453
    },
    {
      "epoch": 0.7936580882352942,
      "grad_norm": 1.6503597497940063,
      "learning_rate": 9.348447712418301e-06,
      "loss": 0.1607,
      "step": 3454
    },
    {
      "epoch": 0.7938878676470589,
      "grad_norm": 2.024502754211426,
      "learning_rate": 9.347937091503269e-06,
      "loss": 0.2464,
      "step": 3455
    },
    {
      "epoch": 0.7941176470588235,
      "grad_norm": 1.6057981252670288,
      "learning_rate": 9.347426470588235e-06,
      "loss": 0.1371,
      "step": 3456
    },
    {
      "epoch": 0.7943474264705882,
      "grad_norm": 1.522667646408081,
      "learning_rate": 9.346915849673204e-06,
      "loss": 0.1823,
      "step": 3457
    },
    {
      "epoch": 0.7945772058823529,
      "grad_norm": 1.3146039247512817,
      "learning_rate": 9.34640522875817e-06,
      "loss": 0.1121,
      "step": 3458
    },
    {
      "epoch": 0.7948069852941176,
      "grad_norm": 2.1341309547424316,
      "learning_rate": 9.345894607843138e-06,
      "loss": 0.1812,
      "step": 3459
    },
    {
      "epoch": 0.7950367647058824,
      "grad_norm": 1.437103509902954,
      "learning_rate": 9.345383986928105e-06,
      "loss": 0.1529,
      "step": 3460
    },
    {
      "epoch": 0.7952665441176471,
      "grad_norm": 2.069082260131836,
      "learning_rate": 9.344873366013073e-06,
      "loss": 0.2455,
      "step": 3461
    },
    {
      "epoch": 0.7954963235294118,
      "grad_norm": 1.568640947341919,
      "learning_rate": 9.34436274509804e-06,
      "loss": 0.1432,
      "step": 3462
    },
    {
      "epoch": 0.7957261029411765,
      "grad_norm": 1.9195183515548706,
      "learning_rate": 9.343852124183007e-06,
      "loss": 0.2265,
      "step": 3463
    },
    {
      "epoch": 0.7959558823529411,
      "grad_norm": 1.6627874374389648,
      "learning_rate": 9.343341503267974e-06,
      "loss": 0.2078,
      "step": 3464
    },
    {
      "epoch": 0.7961856617647058,
      "grad_norm": 1.577718734741211,
      "learning_rate": 9.342830882352942e-06,
      "loss": 0.1731,
      "step": 3465
    },
    {
      "epoch": 0.7964154411764706,
      "grad_norm": 1.790752649307251,
      "learning_rate": 9.34232026143791e-06,
      "loss": 0.1924,
      "step": 3466
    },
    {
      "epoch": 0.7966452205882353,
      "grad_norm": 1.777077555656433,
      "learning_rate": 9.341809640522876e-06,
      "loss": 0.1794,
      "step": 3467
    },
    {
      "epoch": 0.796875,
      "grad_norm": 1.3767149448394775,
      "learning_rate": 9.341299019607844e-06,
      "loss": 0.1504,
      "step": 3468
    },
    {
      "epoch": 0.7971047794117647,
      "grad_norm": 1.5684200525283813,
      "learning_rate": 9.340788398692812e-06,
      "loss": 0.1758,
      "step": 3469
    },
    {
      "epoch": 0.7973345588235294,
      "grad_norm": 1.8464809656143188,
      "learning_rate": 9.340277777777778e-06,
      "loss": 0.197,
      "step": 3470
    },
    {
      "epoch": 0.7975643382352942,
      "grad_norm": 1.6372325420379639,
      "learning_rate": 9.339767156862746e-06,
      "loss": 0.141,
      "step": 3471
    },
    {
      "epoch": 0.7977941176470589,
      "grad_norm": 1.5758075714111328,
      "learning_rate": 9.339256535947712e-06,
      "loss": 0.2023,
      "step": 3472
    },
    {
      "epoch": 0.7980238970588235,
      "grad_norm": 2.1177706718444824,
      "learning_rate": 9.33874591503268e-06,
      "loss": 0.1891,
      "step": 3473
    },
    {
      "epoch": 0.7982536764705882,
      "grad_norm": 2.141031265258789,
      "learning_rate": 9.338235294117648e-06,
      "loss": 0.2003,
      "step": 3474
    },
    {
      "epoch": 0.7984834558823529,
      "grad_norm": 1.613951563835144,
      "learning_rate": 9.337724673202616e-06,
      "loss": 0.1943,
      "step": 3475
    },
    {
      "epoch": 0.7987132352941176,
      "grad_norm": 1.5547034740447998,
      "learning_rate": 9.337214052287582e-06,
      "loss": 0.2213,
      "step": 3476
    },
    {
      "epoch": 0.7989430147058824,
      "grad_norm": 1.95732581615448,
      "learning_rate": 9.33670343137255e-06,
      "loss": 0.2035,
      "step": 3477
    },
    {
      "epoch": 0.7991727941176471,
      "grad_norm": 1.7062714099884033,
      "learning_rate": 9.336192810457518e-06,
      "loss": 0.2695,
      "step": 3478
    },
    {
      "epoch": 0.7994025735294118,
      "grad_norm": 1.2942960262298584,
      "learning_rate": 9.335682189542484e-06,
      "loss": 0.1963,
      "step": 3479
    },
    {
      "epoch": 0.7996323529411765,
      "grad_norm": 1.7500444650650024,
      "learning_rate": 9.335171568627452e-06,
      "loss": 0.1853,
      "step": 3480
    },
    {
      "epoch": 0.7998621323529411,
      "grad_norm": 1.4303970336914062,
      "learning_rate": 9.33466094771242e-06,
      "loss": 0.156,
      "step": 3481
    },
    {
      "epoch": 0.8000919117647058,
      "grad_norm": 1.6145846843719482,
      "learning_rate": 9.334150326797386e-06,
      "loss": 0.1449,
      "step": 3482
    },
    {
      "epoch": 0.8003216911764706,
      "grad_norm": 1.4869744777679443,
      "learning_rate": 9.333639705882354e-06,
      "loss": 0.1879,
      "step": 3483
    },
    {
      "epoch": 0.8005514705882353,
      "grad_norm": 1.5194379091262817,
      "learning_rate": 9.33312908496732e-06,
      "loss": 0.1922,
      "step": 3484
    },
    {
      "epoch": 0.80078125,
      "grad_norm": 1.8687214851379395,
      "learning_rate": 9.33261846405229e-06,
      "loss": 0.2381,
      "step": 3485
    },
    {
      "epoch": 0.8010110294117647,
      "grad_norm": 1.3247660398483276,
      "learning_rate": 9.332107843137255e-06,
      "loss": 0.1463,
      "step": 3486
    },
    {
      "epoch": 0.8012408088235294,
      "grad_norm": 1.7652419805526733,
      "learning_rate": 9.331597222222223e-06,
      "loss": 0.1787,
      "step": 3487
    },
    {
      "epoch": 0.8014705882352942,
      "grad_norm": 2.013953685760498,
      "learning_rate": 9.33108660130719e-06,
      "loss": 0.2283,
      "step": 3488
    },
    {
      "epoch": 0.8017003676470589,
      "grad_norm": 1.7608098983764648,
      "learning_rate": 9.330575980392157e-06,
      "loss": 0.1982,
      "step": 3489
    },
    {
      "epoch": 0.8019301470588235,
      "grad_norm": 2.156277656555176,
      "learning_rate": 9.330065359477125e-06,
      "loss": 0.1914,
      "step": 3490
    },
    {
      "epoch": 0.8021599264705882,
      "grad_norm": 1.6453969478607178,
      "learning_rate": 9.329554738562091e-06,
      "loss": 0.1931,
      "step": 3491
    },
    {
      "epoch": 0.8023897058823529,
      "grad_norm": 1.9652000665664673,
      "learning_rate": 9.32904411764706e-06,
      "loss": 0.2268,
      "step": 3492
    },
    {
      "epoch": 0.8026194852941176,
      "grad_norm": 1.7814521789550781,
      "learning_rate": 9.328533496732027e-06,
      "loss": 0.2283,
      "step": 3493
    },
    {
      "epoch": 0.8028492647058824,
      "grad_norm": 1.8134535551071167,
      "learning_rate": 9.328022875816995e-06,
      "loss": 0.2622,
      "step": 3494
    },
    {
      "epoch": 0.8030790441176471,
      "grad_norm": 1.5216586589813232,
      "learning_rate": 9.327512254901961e-06,
      "loss": 0.1663,
      "step": 3495
    },
    {
      "epoch": 0.8033088235294118,
      "grad_norm": 1.6553691625595093,
      "learning_rate": 9.327001633986929e-06,
      "loss": 0.1882,
      "step": 3496
    },
    {
      "epoch": 0.8035386029411765,
      "grad_norm": 1.576497197151184,
      "learning_rate": 9.326491013071897e-06,
      "loss": 0.1534,
      "step": 3497
    },
    {
      "epoch": 0.8037683823529411,
      "grad_norm": 1.5712132453918457,
      "learning_rate": 9.325980392156863e-06,
      "loss": 0.1715,
      "step": 3498
    },
    {
      "epoch": 0.8039981617647058,
      "grad_norm": 1.8746225833892822,
      "learning_rate": 9.325469771241831e-06,
      "loss": 0.2478,
      "step": 3499
    },
    {
      "epoch": 0.8042279411764706,
      "grad_norm": 1.5684700012207031,
      "learning_rate": 9.324959150326797e-06,
      "loss": 0.2006,
      "step": 3500
    },
    {
      "epoch": 0.8042279411764706,
      "eval_loss": 0.1876710057258606,
      "eval_runtime": 419.9129,
      "eval_samples_per_second": 21.209,
      "eval_steps_per_second": 10.605,
      "step": 3500
    },
    {
      "epoch": 0.8044577205882353,
      "grad_norm": 1.716350793838501,
      "learning_rate": 9.324448529411767e-06,
      "loss": 0.1762,
      "step": 3501
    },
    {
      "epoch": 0.8046875,
      "grad_norm": 1.7919535636901855,
      "learning_rate": 9.323937908496733e-06,
      "loss": 0.1687,
      "step": 3502
    },
    {
      "epoch": 0.8049172794117647,
      "grad_norm": 2.266542911529541,
      "learning_rate": 9.3234272875817e-06,
      "loss": 0.1704,
      "step": 3503
    },
    {
      "epoch": 0.8051470588235294,
      "grad_norm": 1.5505635738372803,
      "learning_rate": 9.322916666666667e-06,
      "loss": 0.1511,
      "step": 3504
    },
    {
      "epoch": 0.8053768382352942,
      "grad_norm": 2.368170976638794,
      "learning_rate": 9.322406045751635e-06,
      "loss": 0.1789,
      "step": 3505
    },
    {
      "epoch": 0.8056066176470589,
      "grad_norm": 1.9354968070983887,
      "learning_rate": 9.321895424836603e-06,
      "loss": 0.2409,
      "step": 3506
    },
    {
      "epoch": 0.8058363970588235,
      "grad_norm": 1.6424188613891602,
      "learning_rate": 9.321384803921569e-06,
      "loss": 0.1676,
      "step": 3507
    },
    {
      "epoch": 0.8060661764705882,
      "grad_norm": 1.4233084917068481,
      "learning_rate": 9.320874183006537e-06,
      "loss": 0.1772,
      "step": 3508
    },
    {
      "epoch": 0.8062959558823529,
      "grad_norm": 1.3471418619155884,
      "learning_rate": 9.320363562091504e-06,
      "loss": 0.1638,
      "step": 3509
    },
    {
      "epoch": 0.8065257352941176,
      "grad_norm": 1.4663137197494507,
      "learning_rate": 9.319852941176472e-06,
      "loss": 0.173,
      "step": 3510
    },
    {
      "epoch": 0.8067555147058824,
      "grad_norm": 1.5585612058639526,
      "learning_rate": 9.319342320261438e-06,
      "loss": 0.1762,
      "step": 3511
    },
    {
      "epoch": 0.8069852941176471,
      "grad_norm": 1.4450676441192627,
      "learning_rate": 9.318831699346406e-06,
      "loss": 0.1688,
      "step": 3512
    },
    {
      "epoch": 0.8072150735294118,
      "grad_norm": 1.613216519355774,
      "learning_rate": 9.318321078431374e-06,
      "loss": 0.1594,
      "step": 3513
    },
    {
      "epoch": 0.8074448529411765,
      "grad_norm": 2.707122325897217,
      "learning_rate": 9.31781045751634e-06,
      "loss": 0.2397,
      "step": 3514
    },
    {
      "epoch": 0.8076746323529411,
      "grad_norm": 1.7897067070007324,
      "learning_rate": 9.317299836601308e-06,
      "loss": 0.1752,
      "step": 3515
    },
    {
      "epoch": 0.8079044117647058,
      "grad_norm": 1.8773013353347778,
      "learning_rate": 9.316789215686274e-06,
      "loss": 0.166,
      "step": 3516
    },
    {
      "epoch": 0.8081341911764706,
      "grad_norm": 2.101266860961914,
      "learning_rate": 9.316278594771242e-06,
      "loss": 0.2151,
      "step": 3517
    },
    {
      "epoch": 0.8083639705882353,
      "grad_norm": 2.2509498596191406,
      "learning_rate": 9.31576797385621e-06,
      "loss": 0.2289,
      "step": 3518
    },
    {
      "epoch": 0.80859375,
      "grad_norm": 1.5746780633926392,
      "learning_rate": 9.315257352941178e-06,
      "loss": 0.1712,
      "step": 3519
    },
    {
      "epoch": 0.8088235294117647,
      "grad_norm": 1.7405986785888672,
      "learning_rate": 9.314746732026144e-06,
      "loss": 0.1974,
      "step": 3520
    },
    {
      "epoch": 0.8090533088235294,
      "grad_norm": 1.6300486326217651,
      "learning_rate": 9.314236111111112e-06,
      "loss": 0.1576,
      "step": 3521
    },
    {
      "epoch": 0.8092830882352942,
      "grad_norm": 1.4786012172698975,
      "learning_rate": 9.31372549019608e-06,
      "loss": 0.1591,
      "step": 3522
    },
    {
      "epoch": 0.8095128676470589,
      "grad_norm": 1.7949351072311401,
      "learning_rate": 9.313214869281046e-06,
      "loss": 0.1494,
      "step": 3523
    },
    {
      "epoch": 0.8097426470588235,
      "grad_norm": 2.3464410305023193,
      "learning_rate": 9.312704248366014e-06,
      "loss": 0.236,
      "step": 3524
    },
    {
      "epoch": 0.8099724264705882,
      "grad_norm": 1.2278470993041992,
      "learning_rate": 9.312193627450982e-06,
      "loss": 0.147,
      "step": 3525
    },
    {
      "epoch": 0.8102022058823529,
      "grad_norm": 2.174049139022827,
      "learning_rate": 9.311683006535948e-06,
      "loss": 0.2394,
      "step": 3526
    },
    {
      "epoch": 0.8104319852941176,
      "grad_norm": 1.473151683807373,
      "learning_rate": 9.311172385620916e-06,
      "loss": 0.1887,
      "step": 3527
    },
    {
      "epoch": 0.8106617647058824,
      "grad_norm": 1.9809190034866333,
      "learning_rate": 9.310661764705882e-06,
      "loss": 0.194,
      "step": 3528
    },
    {
      "epoch": 0.8108915441176471,
      "grad_norm": 1.6689722537994385,
      "learning_rate": 9.310151143790852e-06,
      "loss": 0.206,
      "step": 3529
    },
    {
      "epoch": 0.8111213235294118,
      "grad_norm": 1.263020396232605,
      "learning_rate": 9.309640522875818e-06,
      "loss": 0.0984,
      "step": 3530
    },
    {
      "epoch": 0.8113511029411765,
      "grad_norm": 1.7745927572250366,
      "learning_rate": 9.309129901960786e-06,
      "loss": 0.2372,
      "step": 3531
    },
    {
      "epoch": 0.8115808823529411,
      "grad_norm": 1.671565055847168,
      "learning_rate": 9.308619281045752e-06,
      "loss": 0.16,
      "step": 3532
    },
    {
      "epoch": 0.8118106617647058,
      "grad_norm": 1.529232382774353,
      "learning_rate": 9.30810866013072e-06,
      "loss": 0.1458,
      "step": 3533
    },
    {
      "epoch": 0.8120404411764706,
      "grad_norm": 1.7720755338668823,
      "learning_rate": 9.307598039215687e-06,
      "loss": 0.1698,
      "step": 3534
    },
    {
      "epoch": 0.8122702205882353,
      "grad_norm": 1.1536420583724976,
      "learning_rate": 9.307087418300654e-06,
      "loss": 0.1677,
      "step": 3535
    },
    {
      "epoch": 0.8125,
      "grad_norm": 1.7746278047561646,
      "learning_rate": 9.306576797385621e-06,
      "loss": 0.1501,
      "step": 3536
    },
    {
      "epoch": 0.8127297794117647,
      "grad_norm": 2.064411163330078,
      "learning_rate": 9.30606617647059e-06,
      "loss": 0.2419,
      "step": 3537
    },
    {
      "epoch": 0.8129595588235294,
      "grad_norm": 1.6476984024047852,
      "learning_rate": 9.305555555555557e-06,
      "loss": 0.1914,
      "step": 3538
    },
    {
      "epoch": 0.8131893382352942,
      "grad_norm": 2.08962345123291,
      "learning_rate": 9.305044934640523e-06,
      "loss": 0.1639,
      "step": 3539
    },
    {
      "epoch": 0.8134191176470589,
      "grad_norm": 1.2620692253112793,
      "learning_rate": 9.304534313725491e-06,
      "loss": 0.1553,
      "step": 3540
    },
    {
      "epoch": 0.8136488970588235,
      "grad_norm": 1.398398518562317,
      "learning_rate": 9.304023692810459e-06,
      "loss": 0.1776,
      "step": 3541
    },
    {
      "epoch": 0.8138786764705882,
      "grad_norm": 1.2801727056503296,
      "learning_rate": 9.303513071895425e-06,
      "loss": 0.1367,
      "step": 3542
    },
    {
      "epoch": 0.8141084558823529,
      "grad_norm": 1.4602566957473755,
      "learning_rate": 9.303002450980393e-06,
      "loss": 0.1818,
      "step": 3543
    },
    {
      "epoch": 0.8143382352941176,
      "grad_norm": 1.7061243057250977,
      "learning_rate": 9.30249183006536e-06,
      "loss": 0.1673,
      "step": 3544
    },
    {
      "epoch": 0.8145680147058824,
      "grad_norm": 1.6952366828918457,
      "learning_rate": 9.301981209150329e-06,
      "loss": 0.1534,
      "step": 3545
    },
    {
      "epoch": 0.8147977941176471,
      "grad_norm": 1.6924080848693848,
      "learning_rate": 9.301470588235295e-06,
      "loss": 0.1729,
      "step": 3546
    },
    {
      "epoch": 0.8150275735294118,
      "grad_norm": 1.4078277349472046,
      "learning_rate": 9.300959967320263e-06,
      "loss": 0.1709,
      "step": 3547
    },
    {
      "epoch": 0.8152573529411765,
      "grad_norm": 1.9037234783172607,
      "learning_rate": 9.300449346405229e-06,
      "loss": 0.1802,
      "step": 3548
    },
    {
      "epoch": 0.8154871323529411,
      "grad_norm": 1.5460283756256104,
      "learning_rate": 9.299938725490197e-06,
      "loss": 0.1995,
      "step": 3549
    },
    {
      "epoch": 0.8157169117647058,
      "grad_norm": 1.4432990550994873,
      "learning_rate": 9.299428104575165e-06,
      "loss": 0.1544,
      "step": 3550
    },
    {
      "epoch": 0.8159466911764706,
      "grad_norm": 2.1496453285217285,
      "learning_rate": 9.298917483660131e-06,
      "loss": 0.2015,
      "step": 3551
    },
    {
      "epoch": 0.8161764705882353,
      "grad_norm": 2.245391368865967,
      "learning_rate": 9.298406862745099e-06,
      "loss": 0.1787,
      "step": 3552
    },
    {
      "epoch": 0.81640625,
      "grad_norm": 1.2830722332000732,
      "learning_rate": 9.297896241830067e-06,
      "loss": 0.1565,
      "step": 3553
    },
    {
      "epoch": 0.8166360294117647,
      "grad_norm": 1.5501844882965088,
      "learning_rate": 9.297385620915035e-06,
      "loss": 0.1658,
      "step": 3554
    },
    {
      "epoch": 0.8168658088235294,
      "grad_norm": 2.4604907035827637,
      "learning_rate": 9.296875e-06,
      "loss": 0.2092,
      "step": 3555
    },
    {
      "epoch": 0.8170955882352942,
      "grad_norm": 1.7670809030532837,
      "learning_rate": 9.296364379084969e-06,
      "loss": 0.1439,
      "step": 3556
    },
    {
      "epoch": 0.8173253676470589,
      "grad_norm": 1.9174047708511353,
      "learning_rate": 9.295853758169935e-06,
      "loss": 0.1876,
      "step": 3557
    },
    {
      "epoch": 0.8175551470588235,
      "grad_norm": 2.4662230014801025,
      "learning_rate": 9.295343137254903e-06,
      "loss": 0.1524,
      "step": 3558
    },
    {
      "epoch": 0.8177849264705882,
      "grad_norm": 2.5505714416503906,
      "learning_rate": 9.29483251633987e-06,
      "loss": 0.1973,
      "step": 3559
    },
    {
      "epoch": 0.8180147058823529,
      "grad_norm": 1.8504356145858765,
      "learning_rate": 9.294321895424837e-06,
      "loss": 0.16,
      "step": 3560
    },
    {
      "epoch": 0.8182444852941176,
      "grad_norm": 1.8965890407562256,
      "learning_rate": 9.293811274509804e-06,
      "loss": 0.1894,
      "step": 3561
    },
    {
      "epoch": 0.8184742647058824,
      "grad_norm": 1.5555171966552734,
      "learning_rate": 9.293300653594772e-06,
      "loss": 0.1402,
      "step": 3562
    },
    {
      "epoch": 0.8187040441176471,
      "grad_norm": 1.528327226638794,
      "learning_rate": 9.29279003267974e-06,
      "loss": 0.1509,
      "step": 3563
    },
    {
      "epoch": 0.8189338235294118,
      "grad_norm": 1.5533403158187866,
      "learning_rate": 9.292279411764706e-06,
      "loss": 0.1814,
      "step": 3564
    },
    {
      "epoch": 0.8191636029411765,
      "grad_norm": 1.9383447170257568,
      "learning_rate": 9.291768790849674e-06,
      "loss": 0.2077,
      "step": 3565
    },
    {
      "epoch": 0.8193933823529411,
      "grad_norm": 2.0583913326263428,
      "learning_rate": 9.291258169934642e-06,
      "loss": 0.2253,
      "step": 3566
    },
    {
      "epoch": 0.8196231617647058,
      "grad_norm": 1.857358455657959,
      "learning_rate": 9.290747549019608e-06,
      "loss": 0.1777,
      "step": 3567
    },
    {
      "epoch": 0.8198529411764706,
      "grad_norm": 1.5200573205947876,
      "learning_rate": 9.290236928104576e-06,
      "loss": 0.1939,
      "step": 3568
    },
    {
      "epoch": 0.8200827205882353,
      "grad_norm": 2.0996906757354736,
      "learning_rate": 9.289726307189542e-06,
      "loss": 0.2251,
      "step": 3569
    },
    {
      "epoch": 0.8203125,
      "grad_norm": 2.021547794342041,
      "learning_rate": 9.28921568627451e-06,
      "loss": 0.2364,
      "step": 3570
    },
    {
      "epoch": 0.8205422794117647,
      "grad_norm": 2.2607920169830322,
      "learning_rate": 9.288705065359478e-06,
      "loss": 0.2037,
      "step": 3571
    },
    {
      "epoch": 0.8207720588235294,
      "grad_norm": 2.595355987548828,
      "learning_rate": 9.288194444444444e-06,
      "loss": 0.2272,
      "step": 3572
    },
    {
      "epoch": 0.8210018382352942,
      "grad_norm": 1.758620023727417,
      "learning_rate": 9.287683823529412e-06,
      "loss": 0.2261,
      "step": 3573
    },
    {
      "epoch": 0.8212316176470589,
      "grad_norm": 1.7511712312698364,
      "learning_rate": 9.28717320261438e-06,
      "loss": 0.149,
      "step": 3574
    },
    {
      "epoch": 0.8214613970588235,
      "grad_norm": 1.8116726875305176,
      "learning_rate": 9.286662581699348e-06,
      "loss": 0.1566,
      "step": 3575
    },
    {
      "epoch": 0.8216911764705882,
      "grad_norm": 2.075862169265747,
      "learning_rate": 9.286151960784314e-06,
      "loss": 0.1735,
      "step": 3576
    },
    {
      "epoch": 0.8219209558823529,
      "grad_norm": 1.6698424816131592,
      "learning_rate": 9.285641339869282e-06,
      "loss": 0.1851,
      "step": 3577
    },
    {
      "epoch": 0.8221507352941176,
      "grad_norm": 2.3554394245147705,
      "learning_rate": 9.28513071895425e-06,
      "loss": 0.2199,
      "step": 3578
    },
    {
      "epoch": 0.8223805147058824,
      "grad_norm": 1.5921897888183594,
      "learning_rate": 9.284620098039216e-06,
      "loss": 0.1346,
      "step": 3579
    },
    {
      "epoch": 0.8226102941176471,
      "grad_norm": 1.6240733861923218,
      "learning_rate": 9.284109477124184e-06,
      "loss": 0.1577,
      "step": 3580
    },
    {
      "epoch": 0.8228400735294118,
      "grad_norm": 1.7867509126663208,
      "learning_rate": 9.28359885620915e-06,
      "loss": 0.1369,
      "step": 3581
    },
    {
      "epoch": 0.8230698529411765,
      "grad_norm": 1.6424517631530762,
      "learning_rate": 9.28308823529412e-06,
      "loss": 0.1679,
      "step": 3582
    },
    {
      "epoch": 0.8232996323529411,
      "grad_norm": 1.8292081356048584,
      "learning_rate": 9.282577614379086e-06,
      "loss": 0.1481,
      "step": 3583
    },
    {
      "epoch": 0.8235294117647058,
      "grad_norm": 1.6015446186065674,
      "learning_rate": 9.282066993464053e-06,
      "loss": 0.2327,
      "step": 3584
    },
    {
      "epoch": 0.8237591911764706,
      "grad_norm": 1.9523015022277832,
      "learning_rate": 9.28155637254902e-06,
      "loss": 0.1933,
      "step": 3585
    },
    {
      "epoch": 0.8239889705882353,
      "grad_norm": 1.6341053247451782,
      "learning_rate": 9.281045751633987e-06,
      "loss": 0.2184,
      "step": 3586
    },
    {
      "epoch": 0.82421875,
      "grad_norm": 2.3444418907165527,
      "learning_rate": 9.280535130718955e-06,
      "loss": 0.1972,
      "step": 3587
    },
    {
      "epoch": 0.8244485294117647,
      "grad_norm": 1.9764316082000732,
      "learning_rate": 9.280024509803921e-06,
      "loss": 0.1924,
      "step": 3588
    },
    {
      "epoch": 0.8246783088235294,
      "grad_norm": 1.9710801839828491,
      "learning_rate": 9.27951388888889e-06,
      "loss": 0.1911,
      "step": 3589
    },
    {
      "epoch": 0.8249080882352942,
      "grad_norm": 1.5162588357925415,
      "learning_rate": 9.279003267973857e-06,
      "loss": 0.2234,
      "step": 3590
    },
    {
      "epoch": 0.8251378676470589,
      "grad_norm": 1.5643813610076904,
      "learning_rate": 9.278492647058825e-06,
      "loss": 0.2249,
      "step": 3591
    },
    {
      "epoch": 0.8253676470588235,
      "grad_norm": 1.9577045440673828,
      "learning_rate": 9.277982026143791e-06,
      "loss": 0.1473,
      "step": 3592
    },
    {
      "epoch": 0.8255974264705882,
      "grad_norm": 1.5211009979248047,
      "learning_rate": 9.277471405228759e-06,
      "loss": 0.1666,
      "step": 3593
    },
    {
      "epoch": 0.8258272058823529,
      "grad_norm": 1.5976886749267578,
      "learning_rate": 9.276960784313727e-06,
      "loss": 0.1652,
      "step": 3594
    },
    {
      "epoch": 0.8260569852941176,
      "grad_norm": 2.2312655448913574,
      "learning_rate": 9.276450163398693e-06,
      "loss": 0.2012,
      "step": 3595
    },
    {
      "epoch": 0.8262867647058824,
      "grad_norm": 1.9560447931289673,
      "learning_rate": 9.275939542483661e-06,
      "loss": 0.2203,
      "step": 3596
    },
    {
      "epoch": 0.8265165441176471,
      "grad_norm": 1.7009737491607666,
      "learning_rate": 9.275428921568627e-06,
      "loss": 0.1636,
      "step": 3597
    },
    {
      "epoch": 0.8267463235294118,
      "grad_norm": 2.2101118564605713,
      "learning_rate": 9.274918300653597e-06,
      "loss": 0.2738,
      "step": 3598
    },
    {
      "epoch": 0.8269761029411765,
      "grad_norm": 1.6715627908706665,
      "learning_rate": 9.274407679738563e-06,
      "loss": 0.1649,
      "step": 3599
    },
    {
      "epoch": 0.8272058823529411,
      "grad_norm": 1.5818732976913452,
      "learning_rate": 9.27389705882353e-06,
      "loss": 0.1357,
      "step": 3600
    },
    {
      "epoch": 0.8274356617647058,
      "grad_norm": 2.5690793991088867,
      "learning_rate": 9.273386437908497e-06,
      "loss": 0.1712,
      "step": 3601
    },
    {
      "epoch": 0.8276654411764706,
      "grad_norm": 1.4506715536117554,
      "learning_rate": 9.272875816993465e-06,
      "loss": 0.1341,
      "step": 3602
    },
    {
      "epoch": 0.8278952205882353,
      "grad_norm": 1.5912083387374878,
      "learning_rate": 9.272365196078433e-06,
      "loss": 0.1999,
      "step": 3603
    },
    {
      "epoch": 0.828125,
      "grad_norm": 1.9299452304840088,
      "learning_rate": 9.271854575163399e-06,
      "loss": 0.1804,
      "step": 3604
    },
    {
      "epoch": 0.8283547794117647,
      "grad_norm": 2.162484884262085,
      "learning_rate": 9.271343954248367e-06,
      "loss": 0.2263,
      "step": 3605
    },
    {
      "epoch": 0.8285845588235294,
      "grad_norm": 1.7613604068756104,
      "learning_rate": 9.270833333333334e-06,
      "loss": 0.1877,
      "step": 3606
    },
    {
      "epoch": 0.8288143382352942,
      "grad_norm": 1.790846347808838,
      "learning_rate": 9.2703227124183e-06,
      "loss": 0.1673,
      "step": 3607
    },
    {
      "epoch": 0.8290441176470589,
      "grad_norm": 2.142688274383545,
      "learning_rate": 9.269812091503269e-06,
      "loss": 0.1703,
      "step": 3608
    },
    {
      "epoch": 0.8292738970588235,
      "grad_norm": 2.003812074661255,
      "learning_rate": 9.269301470588236e-06,
      "loss": 0.1957,
      "step": 3609
    },
    {
      "epoch": 0.8295036764705882,
      "grad_norm": 1.856489658355713,
      "learning_rate": 9.268790849673204e-06,
      "loss": 0.1736,
      "step": 3610
    },
    {
      "epoch": 0.8297334558823529,
      "grad_norm": 1.5246082544326782,
      "learning_rate": 9.26828022875817e-06,
      "loss": 0.2237,
      "step": 3611
    },
    {
      "epoch": 0.8299632352941176,
      "grad_norm": 1.8063163757324219,
      "learning_rate": 9.267769607843138e-06,
      "loss": 0.1525,
      "step": 3612
    },
    {
      "epoch": 0.8301930147058824,
      "grad_norm": 1.82444429397583,
      "learning_rate": 9.267258986928104e-06,
      "loss": 0.1808,
      "step": 3613
    },
    {
      "epoch": 0.8304227941176471,
      "grad_norm": 1.6324797868728638,
      "learning_rate": 9.266748366013072e-06,
      "loss": 0.1758,
      "step": 3614
    },
    {
      "epoch": 0.8306525735294118,
      "grad_norm": 1.6811240911483765,
      "learning_rate": 9.26623774509804e-06,
      "loss": 0.1887,
      "step": 3615
    },
    {
      "epoch": 0.8308823529411765,
      "grad_norm": 2.0283143520355225,
      "learning_rate": 9.265727124183006e-06,
      "loss": 0.1519,
      "step": 3616
    },
    {
      "epoch": 0.8311121323529411,
      "grad_norm": 1.2753973007202148,
      "learning_rate": 9.265216503267974e-06,
      "loss": 0.138,
      "step": 3617
    },
    {
      "epoch": 0.8313419117647058,
      "grad_norm": 1.2815566062927246,
      "learning_rate": 9.264705882352942e-06,
      "loss": 0.1075,
      "step": 3618
    },
    {
      "epoch": 0.8315716911764706,
      "grad_norm": 1.8118212223052979,
      "learning_rate": 9.26419526143791e-06,
      "loss": 0.1858,
      "step": 3619
    },
    {
      "epoch": 0.8318014705882353,
      "grad_norm": 2.209658622741699,
      "learning_rate": 9.263684640522876e-06,
      "loss": 0.1655,
      "step": 3620
    },
    {
      "epoch": 0.83203125,
      "grad_norm": 1.6301414966583252,
      "learning_rate": 9.263174019607844e-06,
      "loss": 0.1912,
      "step": 3621
    },
    {
      "epoch": 0.8322610294117647,
      "grad_norm": 1.6544793844223022,
      "learning_rate": 9.262663398692812e-06,
      "loss": 0.1866,
      "step": 3622
    },
    {
      "epoch": 0.8324908088235294,
      "grad_norm": 1.9798915386199951,
      "learning_rate": 9.262152777777778e-06,
      "loss": 0.1599,
      "step": 3623
    },
    {
      "epoch": 0.8327205882352942,
      "grad_norm": 1.6295578479766846,
      "learning_rate": 9.261642156862746e-06,
      "loss": 0.179,
      "step": 3624
    },
    {
      "epoch": 0.8329503676470589,
      "grad_norm": 1.779807209968567,
      "learning_rate": 9.261131535947712e-06,
      "loss": 0.1758,
      "step": 3625
    },
    {
      "epoch": 0.8331801470588235,
      "grad_norm": 1.5572915077209473,
      "learning_rate": 9.260620915032682e-06,
      "loss": 0.1775,
      "step": 3626
    },
    {
      "epoch": 0.8334099264705882,
      "grad_norm": 1.6228594779968262,
      "learning_rate": 9.260110294117648e-06,
      "loss": 0.1671,
      "step": 3627
    },
    {
      "epoch": 0.8336397058823529,
      "grad_norm": 1.6166033744812012,
      "learning_rate": 9.259599673202616e-06,
      "loss": 0.1558,
      "step": 3628
    },
    {
      "epoch": 0.8338694852941176,
      "grad_norm": 1.5256330966949463,
      "learning_rate": 9.259089052287582e-06,
      "loss": 0.1782,
      "step": 3629
    },
    {
      "epoch": 0.8340992647058824,
      "grad_norm": 1.430745244026184,
      "learning_rate": 9.25857843137255e-06,
      "loss": 0.1766,
      "step": 3630
    },
    {
      "epoch": 0.8343290441176471,
      "grad_norm": 1.9219670295715332,
      "learning_rate": 9.258067810457517e-06,
      "loss": 0.1732,
      "step": 3631
    },
    {
      "epoch": 0.8345588235294118,
      "grad_norm": 1.319272518157959,
      "learning_rate": 9.257557189542484e-06,
      "loss": 0.1914,
      "step": 3632
    },
    {
      "epoch": 0.8347886029411765,
      "grad_norm": 1.533138394355774,
      "learning_rate": 9.257046568627452e-06,
      "loss": 0.204,
      "step": 3633
    },
    {
      "epoch": 0.8350183823529411,
      "grad_norm": 1.5301921367645264,
      "learning_rate": 9.25653594771242e-06,
      "loss": 0.1402,
      "step": 3634
    },
    {
      "epoch": 0.8352481617647058,
      "grad_norm": 1.747113823890686,
      "learning_rate": 9.256025326797387e-06,
      "loss": 0.151,
      "step": 3635
    },
    {
      "epoch": 0.8354779411764706,
      "grad_norm": 1.9947535991668701,
      "learning_rate": 9.255514705882353e-06,
      "loss": 0.2103,
      "step": 3636
    },
    {
      "epoch": 0.8357077205882353,
      "grad_norm": 1.6814666986465454,
      "learning_rate": 9.255004084967321e-06,
      "loss": 0.1712,
      "step": 3637
    },
    {
      "epoch": 0.8359375,
      "grad_norm": 1.6794353723526,
      "learning_rate": 9.254493464052289e-06,
      "loss": 0.2093,
      "step": 3638
    },
    {
      "epoch": 0.8361672794117647,
      "grad_norm": 2.0076217651367188,
      "learning_rate": 9.253982843137255e-06,
      "loss": 0.2208,
      "step": 3639
    },
    {
      "epoch": 0.8363970588235294,
      "grad_norm": 2.1045053005218506,
      "learning_rate": 9.253472222222223e-06,
      "loss": 0.1651,
      "step": 3640
    },
    {
      "epoch": 0.8366268382352942,
      "grad_norm": 1.626238465309143,
      "learning_rate": 9.25296160130719e-06,
      "loss": 0.1893,
      "step": 3641
    },
    {
      "epoch": 0.8368566176470589,
      "grad_norm": 1.6035765409469604,
      "learning_rate": 9.252450980392159e-06,
      "loss": 0.1659,
      "step": 3642
    },
    {
      "epoch": 0.8370863970588235,
      "grad_norm": 1.787291169166565,
      "learning_rate": 9.251940359477125e-06,
      "loss": 0.1413,
      "step": 3643
    },
    {
      "epoch": 0.8373161764705882,
      "grad_norm": 1.4109209775924683,
      "learning_rate": 9.251429738562093e-06,
      "loss": 0.1786,
      "step": 3644
    },
    {
      "epoch": 0.8375459558823529,
      "grad_norm": 1.2909226417541504,
      "learning_rate": 9.250919117647059e-06,
      "loss": 0.1393,
      "step": 3645
    },
    {
      "epoch": 0.8377757352941176,
      "grad_norm": 1.4563360214233398,
      "learning_rate": 9.250408496732027e-06,
      "loss": 0.194,
      "step": 3646
    },
    {
      "epoch": 0.8380055147058824,
      "grad_norm": 1.6214752197265625,
      "learning_rate": 9.249897875816995e-06,
      "loss": 0.1835,
      "step": 3647
    },
    {
      "epoch": 0.8382352941176471,
      "grad_norm": 1.754328966140747,
      "learning_rate": 9.249387254901961e-06,
      "loss": 0.1763,
      "step": 3648
    },
    {
      "epoch": 0.8384650735294118,
      "grad_norm": 1.5535324811935425,
      "learning_rate": 9.248876633986929e-06,
      "loss": 0.1816,
      "step": 3649
    },
    {
      "epoch": 0.8386948529411765,
      "grad_norm": 1.8485937118530273,
      "learning_rate": 9.248366013071897e-06,
      "loss": 0.2187,
      "step": 3650
    },
    {
      "epoch": 0.8389246323529411,
      "grad_norm": 2.1904895305633545,
      "learning_rate": 9.247855392156863e-06,
      "loss": 0.2511,
      "step": 3651
    },
    {
      "epoch": 0.8391544117647058,
      "grad_norm": 1.5954818725585938,
      "learning_rate": 9.24734477124183e-06,
      "loss": 0.1489,
      "step": 3652
    },
    {
      "epoch": 0.8393841911764706,
      "grad_norm": 1.6807572841644287,
      "learning_rate": 9.246834150326799e-06,
      "loss": 0.1572,
      "step": 3653
    },
    {
      "epoch": 0.8396139705882353,
      "grad_norm": 1.3921431303024292,
      "learning_rate": 9.246323529411766e-06,
      "loss": 0.1325,
      "step": 3654
    },
    {
      "epoch": 0.83984375,
      "grad_norm": 1.6680222749710083,
      "learning_rate": 9.245812908496733e-06,
      "loss": 0.1853,
      "step": 3655
    },
    {
      "epoch": 0.8400735294117647,
      "grad_norm": 1.6925815343856812,
      "learning_rate": 9.2453022875817e-06,
      "loss": 0.1689,
      "step": 3656
    },
    {
      "epoch": 0.8403033088235294,
      "grad_norm": 1.470314383506775,
      "learning_rate": 9.244791666666667e-06,
      "loss": 0.1766,
      "step": 3657
    },
    {
      "epoch": 0.8405330882352942,
      "grad_norm": 2.1236960887908936,
      "learning_rate": 9.244281045751634e-06,
      "loss": 0.2153,
      "step": 3658
    },
    {
      "epoch": 0.8407628676470589,
      "grad_norm": 1.599891185760498,
      "learning_rate": 9.243770424836602e-06,
      "loss": 0.1684,
      "step": 3659
    },
    {
      "epoch": 0.8409926470588235,
      "grad_norm": 1.8121498823165894,
      "learning_rate": 9.243259803921569e-06,
      "loss": 0.2201,
      "step": 3660
    },
    {
      "epoch": 0.8412224264705882,
      "grad_norm": 1.8316954374313354,
      "learning_rate": 9.242749183006536e-06,
      "loss": 0.2372,
      "step": 3661
    },
    {
      "epoch": 0.8414522058823529,
      "grad_norm": 1.4965137243270874,
      "learning_rate": 9.242238562091504e-06,
      "loss": 0.1861,
      "step": 3662
    },
    {
      "epoch": 0.8416819852941176,
      "grad_norm": 1.7830119132995605,
      "learning_rate": 9.241727941176472e-06,
      "loss": 0.1681,
      "step": 3663
    },
    {
      "epoch": 0.8419117647058824,
      "grad_norm": 1.3264491558074951,
      "learning_rate": 9.241217320261438e-06,
      "loss": 0.1789,
      "step": 3664
    },
    {
      "epoch": 0.8421415441176471,
      "grad_norm": 1.935958981513977,
      "learning_rate": 9.240706699346406e-06,
      "loss": 0.1637,
      "step": 3665
    },
    {
      "epoch": 0.8423713235294118,
      "grad_norm": 1.3767914772033691,
      "learning_rate": 9.240196078431374e-06,
      "loss": 0.1398,
      "step": 3666
    },
    {
      "epoch": 0.8426011029411765,
      "grad_norm": 1.5445618629455566,
      "learning_rate": 9.23968545751634e-06,
      "loss": 0.142,
      "step": 3667
    },
    {
      "epoch": 0.8428308823529411,
      "grad_norm": 1.9028806686401367,
      "learning_rate": 9.239174836601308e-06,
      "loss": 0.2317,
      "step": 3668
    },
    {
      "epoch": 0.8430606617647058,
      "grad_norm": 1.7185684442520142,
      "learning_rate": 9.238664215686274e-06,
      "loss": 0.195,
      "step": 3669
    },
    {
      "epoch": 0.8432904411764706,
      "grad_norm": 1.598138689994812,
      "learning_rate": 9.238153594771244e-06,
      "loss": 0.2267,
      "step": 3670
    },
    {
      "epoch": 0.8435202205882353,
      "grad_norm": 1.3643425703048706,
      "learning_rate": 9.23764297385621e-06,
      "loss": 0.1428,
      "step": 3671
    },
    {
      "epoch": 0.84375,
      "grad_norm": 1.6215564012527466,
      "learning_rate": 9.237132352941178e-06,
      "loss": 0.1663,
      "step": 3672
    },
    {
      "epoch": 0.8439797794117647,
      "grad_norm": 1.612857460975647,
      "learning_rate": 9.236621732026144e-06,
      "loss": 0.1859,
      "step": 3673
    },
    {
      "epoch": 0.8442095588235294,
      "grad_norm": 1.5711957216262817,
      "learning_rate": 9.236111111111112e-06,
      "loss": 0.1714,
      "step": 3674
    },
    {
      "epoch": 0.8444393382352942,
      "grad_norm": 1.852615237236023,
      "learning_rate": 9.23560049019608e-06,
      "loss": 0.2196,
      "step": 3675
    },
    {
      "epoch": 0.8446691176470589,
      "grad_norm": 2.1709179878234863,
      "learning_rate": 9.235089869281046e-06,
      "loss": 0.1813,
      "step": 3676
    },
    {
      "epoch": 0.8448988970588235,
      "grad_norm": 1.8195197582244873,
      "learning_rate": 9.234579248366014e-06,
      "loss": 0.1592,
      "step": 3677
    },
    {
      "epoch": 0.8451286764705882,
      "grad_norm": 2.208383798599243,
      "learning_rate": 9.234068627450982e-06,
      "loss": 0.2285,
      "step": 3678
    },
    {
      "epoch": 0.8453584558823529,
      "grad_norm": 1.6277498006820679,
      "learning_rate": 9.23355800653595e-06,
      "loss": 0.1692,
      "step": 3679
    },
    {
      "epoch": 0.8455882352941176,
      "grad_norm": 1.8669369220733643,
      "learning_rate": 9.233047385620916e-06,
      "loss": 0.1837,
      "step": 3680
    },
    {
      "epoch": 0.8458180147058824,
      "grad_norm": 1.6011428833007812,
      "learning_rate": 9.232536764705883e-06,
      "loss": 0.2051,
      "step": 3681
    },
    {
      "epoch": 0.8460477941176471,
      "grad_norm": 2.2334821224212646,
      "learning_rate": 9.232026143790851e-06,
      "loss": 0.2462,
      "step": 3682
    },
    {
      "epoch": 0.8462775735294118,
      "grad_norm": 1.4059923887252808,
      "learning_rate": 9.231515522875817e-06,
      "loss": 0.1936,
      "step": 3683
    },
    {
      "epoch": 0.8465073529411765,
      "grad_norm": 2.096818208694458,
      "learning_rate": 9.231004901960785e-06,
      "loss": 0.1988,
      "step": 3684
    },
    {
      "epoch": 0.8467371323529411,
      "grad_norm": 1.5019481182098389,
      "learning_rate": 9.230494281045752e-06,
      "loss": 0.1769,
      "step": 3685
    },
    {
      "epoch": 0.8469669117647058,
      "grad_norm": 1.375562310218811,
      "learning_rate": 9.229983660130721e-06,
      "loss": 0.1844,
      "step": 3686
    },
    {
      "epoch": 0.8471966911764706,
      "grad_norm": 1.8938504457473755,
      "learning_rate": 9.229473039215687e-06,
      "loss": 0.161,
      "step": 3687
    },
    {
      "epoch": 0.8474264705882353,
      "grad_norm": 1.628469705581665,
      "learning_rate": 9.228962418300655e-06,
      "loss": 0.1608,
      "step": 3688
    },
    {
      "epoch": 0.84765625,
      "grad_norm": 1.8916072845458984,
      "learning_rate": 9.228451797385621e-06,
      "loss": 0.1482,
      "step": 3689
    },
    {
      "epoch": 0.8478860294117647,
      "grad_norm": 1.2732715606689453,
      "learning_rate": 9.227941176470589e-06,
      "loss": 0.1444,
      "step": 3690
    },
    {
      "epoch": 0.8481158088235294,
      "grad_norm": 1.9798282384872437,
      "learning_rate": 9.227430555555557e-06,
      "loss": 0.1743,
      "step": 3691
    },
    {
      "epoch": 0.8483455882352942,
      "grad_norm": 1.8428884744644165,
      "learning_rate": 9.226919934640523e-06,
      "loss": 0.1482,
      "step": 3692
    },
    {
      "epoch": 0.8485753676470589,
      "grad_norm": 1.6139345169067383,
      "learning_rate": 9.226409313725491e-06,
      "loss": 0.1885,
      "step": 3693
    },
    {
      "epoch": 0.8488051470588235,
      "grad_norm": 2.430683135986328,
      "learning_rate": 9.225898692810459e-06,
      "loss": 0.2091,
      "step": 3694
    },
    {
      "epoch": 0.8490349264705882,
      "grad_norm": 4.226546287536621,
      "learning_rate": 9.225388071895425e-06,
      "loss": 0.3635,
      "step": 3695
    },
    {
      "epoch": 0.8492647058823529,
      "grad_norm": 1.7923991680145264,
      "learning_rate": 9.224877450980393e-06,
      "loss": 0.2417,
      "step": 3696
    },
    {
      "epoch": 0.8494944852941176,
      "grad_norm": 1.3576658964157104,
      "learning_rate": 9.22436683006536e-06,
      "loss": 0.1326,
      "step": 3697
    },
    {
      "epoch": 0.8497242647058824,
      "grad_norm": 1.6799695491790771,
      "learning_rate": 9.223856209150329e-06,
      "loss": 0.1743,
      "step": 3698
    },
    {
      "epoch": 0.8499540441176471,
      "grad_norm": 1.4772311449050903,
      "learning_rate": 9.223345588235295e-06,
      "loss": 0.1653,
      "step": 3699
    },
    {
      "epoch": 0.8501838235294118,
      "grad_norm": 1.3870532512664795,
      "learning_rate": 9.222834967320263e-06,
      "loss": 0.1397,
      "step": 3700
    },
    {
      "epoch": 0.8504136029411765,
      "grad_norm": 1.7080553770065308,
      "learning_rate": 9.222324346405229e-06,
      "loss": 0.196,
      "step": 3701
    },
    {
      "epoch": 0.8506433823529411,
      "grad_norm": 1.4844223260879517,
      "learning_rate": 9.221813725490197e-06,
      "loss": 0.15,
      "step": 3702
    },
    {
      "epoch": 0.8508731617647058,
      "grad_norm": 1.6057851314544678,
      "learning_rate": 9.221303104575165e-06,
      "loss": 0.1833,
      "step": 3703
    },
    {
      "epoch": 0.8511029411764706,
      "grad_norm": 1.764978289604187,
      "learning_rate": 9.22079248366013e-06,
      "loss": 0.1651,
      "step": 3704
    },
    {
      "epoch": 0.8513327205882353,
      "grad_norm": 1.8967251777648926,
      "learning_rate": 9.220281862745099e-06,
      "loss": 0.1459,
      "step": 3705
    },
    {
      "epoch": 0.8515625,
      "grad_norm": 1.612533688545227,
      "learning_rate": 9.219771241830066e-06,
      "loss": 0.1391,
      "step": 3706
    },
    {
      "epoch": 0.8517922794117647,
      "grad_norm": 1.6442110538482666,
      "learning_rate": 9.219260620915034e-06,
      "loss": 0.1727,
      "step": 3707
    },
    {
      "epoch": 0.8520220588235294,
      "grad_norm": 1.8742637634277344,
      "learning_rate": 9.21875e-06,
      "loss": 0.1614,
      "step": 3708
    },
    {
      "epoch": 0.8522518382352942,
      "grad_norm": 1.3210580348968506,
      "learning_rate": 9.218239379084968e-06,
      "loss": 0.153,
      "step": 3709
    },
    {
      "epoch": 0.8524816176470589,
      "grad_norm": 1.521054744720459,
      "learning_rate": 9.217728758169934e-06,
      "loss": 0.1422,
      "step": 3710
    },
    {
      "epoch": 0.8527113970588235,
      "grad_norm": 1.6232222318649292,
      "learning_rate": 9.217218137254902e-06,
      "loss": 0.1668,
      "step": 3711
    },
    {
      "epoch": 0.8529411764705882,
      "grad_norm": 1.3050403594970703,
      "learning_rate": 9.21670751633987e-06,
      "loss": 0.1711,
      "step": 3712
    },
    {
      "epoch": 0.8531709558823529,
      "grad_norm": 1.5824060440063477,
      "learning_rate": 9.216196895424836e-06,
      "loss": 0.1831,
      "step": 3713
    },
    {
      "epoch": 0.8534007352941176,
      "grad_norm": 1.8925750255584717,
      "learning_rate": 9.215686274509804e-06,
      "loss": 0.1722,
      "step": 3714
    },
    {
      "epoch": 0.8536305147058824,
      "grad_norm": 1.7184752225875854,
      "learning_rate": 9.215175653594772e-06,
      "loss": 0.1919,
      "step": 3715
    },
    {
      "epoch": 0.8538602941176471,
      "grad_norm": 1.4457670450210571,
      "learning_rate": 9.21466503267974e-06,
      "loss": 0.2211,
      "step": 3716
    },
    {
      "epoch": 0.8540900735294118,
      "grad_norm": 1.6421090364456177,
      "learning_rate": 9.214154411764706e-06,
      "loss": 0.2325,
      "step": 3717
    },
    {
      "epoch": 0.8543198529411765,
      "grad_norm": 3.085369825363159,
      "learning_rate": 9.213643790849674e-06,
      "loss": 0.219,
      "step": 3718
    },
    {
      "epoch": 0.8545496323529411,
      "grad_norm": 1.9593658447265625,
      "learning_rate": 9.213133169934642e-06,
      "loss": 0.207,
      "step": 3719
    },
    {
      "epoch": 0.8547794117647058,
      "grad_norm": 1.803139567375183,
      "learning_rate": 9.212622549019608e-06,
      "loss": 0.163,
      "step": 3720
    },
    {
      "epoch": 0.8550091911764706,
      "grad_norm": 1.7252752780914307,
      "learning_rate": 9.212111928104576e-06,
      "loss": 0.1337,
      "step": 3721
    },
    {
      "epoch": 0.8552389705882353,
      "grad_norm": 2.2500224113464355,
      "learning_rate": 9.211601307189542e-06,
      "loss": 0.1989,
      "step": 3722
    },
    {
      "epoch": 0.85546875,
      "grad_norm": 1.729697346687317,
      "learning_rate": 9.211090686274512e-06,
      "loss": 0.166,
      "step": 3723
    },
    {
      "epoch": 0.8556985294117647,
      "grad_norm": 1.7379337549209595,
      "learning_rate": 9.210580065359478e-06,
      "loss": 0.1856,
      "step": 3724
    },
    {
      "epoch": 0.8559283088235294,
      "grad_norm": 1.7933425903320312,
      "learning_rate": 9.210069444444446e-06,
      "loss": 0.2097,
      "step": 3725
    },
    {
      "epoch": 0.8561580882352942,
      "grad_norm": 1.7610195875167847,
      "learning_rate": 9.209558823529412e-06,
      "loss": 0.2011,
      "step": 3726
    },
    {
      "epoch": 0.8563878676470589,
      "grad_norm": 1.6001746654510498,
      "learning_rate": 9.20904820261438e-06,
      "loss": 0.1994,
      "step": 3727
    },
    {
      "epoch": 0.8566176470588235,
      "grad_norm": 1.9623045921325684,
      "learning_rate": 9.208537581699348e-06,
      "loss": 0.1912,
      "step": 3728
    },
    {
      "epoch": 0.8568474264705882,
      "grad_norm": 2.3283798694610596,
      "learning_rate": 9.208026960784314e-06,
      "loss": 0.2307,
      "step": 3729
    },
    {
      "epoch": 0.8570772058823529,
      "grad_norm": 2.536663055419922,
      "learning_rate": 9.207516339869282e-06,
      "loss": 0.2392,
      "step": 3730
    },
    {
      "epoch": 0.8573069852941176,
      "grad_norm": 2.020773410797119,
      "learning_rate": 9.20700571895425e-06,
      "loss": 0.202,
      "step": 3731
    },
    {
      "epoch": 0.8575367647058824,
      "grad_norm": 1.7246237993240356,
      "learning_rate": 9.206495098039217e-06,
      "loss": 0.2112,
      "step": 3732
    },
    {
      "epoch": 0.8577665441176471,
      "grad_norm": 1.9109132289886475,
      "learning_rate": 9.205984477124183e-06,
      "loss": 0.2202,
      "step": 3733
    },
    {
      "epoch": 0.8579963235294118,
      "grad_norm": 1.9857536554336548,
      "learning_rate": 9.205473856209151e-06,
      "loss": 0.1859,
      "step": 3734
    },
    {
      "epoch": 0.8582261029411765,
      "grad_norm": 1.968660831451416,
      "learning_rate": 9.20496323529412e-06,
      "loss": 0.196,
      "step": 3735
    },
    {
      "epoch": 0.8584558823529411,
      "grad_norm": 1.7060357332229614,
      "learning_rate": 9.204452614379085e-06,
      "loss": 0.1664,
      "step": 3736
    },
    {
      "epoch": 0.8586856617647058,
      "grad_norm": 1.690779447555542,
      "learning_rate": 9.203941993464053e-06,
      "loss": 0.2026,
      "step": 3737
    },
    {
      "epoch": 0.8589154411764706,
      "grad_norm": 1.562646746635437,
      "learning_rate": 9.20343137254902e-06,
      "loss": 0.1357,
      "step": 3738
    },
    {
      "epoch": 0.8591452205882353,
      "grad_norm": 1.8693509101867676,
      "learning_rate": 9.202920751633987e-06,
      "loss": 0.2027,
      "step": 3739
    },
    {
      "epoch": 0.859375,
      "grad_norm": 1.7677394151687622,
      "learning_rate": 9.202410130718955e-06,
      "loss": 0.1308,
      "step": 3740
    },
    {
      "epoch": 0.8596047794117647,
      "grad_norm": 1.5875333547592163,
      "learning_rate": 9.201899509803923e-06,
      "loss": 0.1773,
      "step": 3741
    },
    {
      "epoch": 0.8598345588235294,
      "grad_norm": 1.5473603010177612,
      "learning_rate": 9.201388888888889e-06,
      "loss": 0.1814,
      "step": 3742
    },
    {
      "epoch": 0.8600643382352942,
      "grad_norm": 2.096181631088257,
      "learning_rate": 9.200878267973857e-06,
      "loss": 0.1259,
      "step": 3743
    },
    {
      "epoch": 0.8602941176470589,
      "grad_norm": 1.5450880527496338,
      "learning_rate": 9.200367647058825e-06,
      "loss": 0.1664,
      "step": 3744
    },
    {
      "epoch": 0.8605238970588235,
      "grad_norm": 1.9028112888336182,
      "learning_rate": 9.199857026143791e-06,
      "loss": 0.1067,
      "step": 3745
    },
    {
      "epoch": 0.8607536764705882,
      "grad_norm": 1.4940763711929321,
      "learning_rate": 9.199346405228759e-06,
      "loss": 0.1623,
      "step": 3746
    },
    {
      "epoch": 0.8609834558823529,
      "grad_norm": 1.6195652484893799,
      "learning_rate": 9.198835784313727e-06,
      "loss": 0.1913,
      "step": 3747
    },
    {
      "epoch": 0.8612132352941176,
      "grad_norm": 1.345506191253662,
      "learning_rate": 9.198325163398693e-06,
      "loss": 0.171,
      "step": 3748
    },
    {
      "epoch": 0.8614430147058824,
      "grad_norm": 1.7631596326828003,
      "learning_rate": 9.19781454248366e-06,
      "loss": 0.1904,
      "step": 3749
    },
    {
      "epoch": 0.8616727941176471,
      "grad_norm": 1.6907142400741577,
      "learning_rate": 9.197303921568627e-06,
      "loss": 0.15,
      "step": 3750
    },
    {
      "epoch": 0.8619025735294118,
      "grad_norm": 1.6485469341278076,
      "learning_rate": 9.196793300653596e-06,
      "loss": 0.1465,
      "step": 3751
    },
    {
      "epoch": 0.8621323529411765,
      "grad_norm": 1.5308773517608643,
      "learning_rate": 9.196282679738563e-06,
      "loss": 0.1393,
      "step": 3752
    },
    {
      "epoch": 0.8623621323529411,
      "grad_norm": 1.7797846794128418,
      "learning_rate": 9.19577205882353e-06,
      "loss": 0.1748,
      "step": 3753
    },
    {
      "epoch": 0.8625919117647058,
      "grad_norm": 2.53058123588562,
      "learning_rate": 9.195261437908497e-06,
      "loss": 0.2065,
      "step": 3754
    },
    {
      "epoch": 0.8628216911764706,
      "grad_norm": 1.6234722137451172,
      "learning_rate": 9.194750816993465e-06,
      "loss": 0.1163,
      "step": 3755
    },
    {
      "epoch": 0.8630514705882353,
      "grad_norm": 1.752170205116272,
      "learning_rate": 9.194240196078432e-06,
      "loss": 0.2211,
      "step": 3756
    },
    {
      "epoch": 0.86328125,
      "grad_norm": 1.4149659872055054,
      "learning_rate": 9.193729575163399e-06,
      "loss": 0.1729,
      "step": 3757
    },
    {
      "epoch": 0.8635110294117647,
      "grad_norm": 1.9112541675567627,
      "learning_rate": 9.193218954248366e-06,
      "loss": 0.1879,
      "step": 3758
    },
    {
      "epoch": 0.8637408088235294,
      "grad_norm": 1.876104474067688,
      "learning_rate": 9.192708333333334e-06,
      "loss": 0.1981,
      "step": 3759
    },
    {
      "epoch": 0.8639705882352942,
      "grad_norm": 1.6542094945907593,
      "learning_rate": 9.192197712418302e-06,
      "loss": 0.1667,
      "step": 3760
    },
    {
      "epoch": 0.8642003676470589,
      "grad_norm": 1.5267951488494873,
      "learning_rate": 9.191687091503268e-06,
      "loss": 0.1661,
      "step": 3761
    },
    {
      "epoch": 0.8644301470588235,
      "grad_norm": 1.6746931076049805,
      "learning_rate": 9.191176470588236e-06,
      "loss": 0.1903,
      "step": 3762
    },
    {
      "epoch": 0.8646599264705882,
      "grad_norm": 1.948502540588379,
      "learning_rate": 9.190665849673204e-06,
      "loss": 0.1358,
      "step": 3763
    },
    {
      "epoch": 0.8648897058823529,
      "grad_norm": 1.9883334636688232,
      "learning_rate": 9.19015522875817e-06,
      "loss": 0.1416,
      "step": 3764
    },
    {
      "epoch": 0.8651194852941176,
      "grad_norm": 1.738924503326416,
      "learning_rate": 9.189644607843138e-06,
      "loss": 0.1844,
      "step": 3765
    },
    {
      "epoch": 0.8653492647058824,
      "grad_norm": 1.9254634380340576,
      "learning_rate": 9.189133986928104e-06,
      "loss": 0.1453,
      "step": 3766
    },
    {
      "epoch": 0.8655790441176471,
      "grad_norm": 1.5630099773406982,
      "learning_rate": 9.188623366013074e-06,
      "loss": 0.1807,
      "step": 3767
    },
    {
      "epoch": 0.8658088235294118,
      "grad_norm": 1.6318928003311157,
      "learning_rate": 9.18811274509804e-06,
      "loss": 0.1581,
      "step": 3768
    },
    {
      "epoch": 0.8660386029411765,
      "grad_norm": 1.3778877258300781,
      "learning_rate": 9.187602124183008e-06,
      "loss": 0.1371,
      "step": 3769
    },
    {
      "epoch": 0.8662683823529411,
      "grad_norm": 1.9079113006591797,
      "learning_rate": 9.187091503267974e-06,
      "loss": 0.1474,
      "step": 3770
    },
    {
      "epoch": 0.8664981617647058,
      "grad_norm": 1.939603567123413,
      "learning_rate": 9.186580882352942e-06,
      "loss": 0.199,
      "step": 3771
    },
    {
      "epoch": 0.8667279411764706,
      "grad_norm": 1.6386903524398804,
      "learning_rate": 9.18607026143791e-06,
      "loss": 0.2018,
      "step": 3772
    },
    {
      "epoch": 0.8669577205882353,
      "grad_norm": 1.7184087038040161,
      "learning_rate": 9.185559640522876e-06,
      "loss": 0.147,
      "step": 3773
    },
    {
      "epoch": 0.8671875,
      "grad_norm": 1.8279426097869873,
      "learning_rate": 9.185049019607844e-06,
      "loss": 0.1638,
      "step": 3774
    },
    {
      "epoch": 0.8674172794117647,
      "grad_norm": 1.7204818725585938,
      "learning_rate": 9.184538398692812e-06,
      "loss": 0.2214,
      "step": 3775
    },
    {
      "epoch": 0.8676470588235294,
      "grad_norm": 2.1780436038970947,
      "learning_rate": 9.18402777777778e-06,
      "loss": 0.2158,
      "step": 3776
    },
    {
      "epoch": 0.8678768382352942,
      "grad_norm": 1.589147686958313,
      "learning_rate": 9.183517156862746e-06,
      "loss": 0.1259,
      "step": 3777
    },
    {
      "epoch": 0.8681066176470589,
      "grad_norm": 1.7390655279159546,
      "learning_rate": 9.183006535947713e-06,
      "loss": 0.1579,
      "step": 3778
    },
    {
      "epoch": 0.8683363970588235,
      "grad_norm": 1.6536427736282349,
      "learning_rate": 9.182495915032681e-06,
      "loss": 0.1497,
      "step": 3779
    },
    {
      "epoch": 0.8685661764705882,
      "grad_norm": 2.3804686069488525,
      "learning_rate": 9.181985294117648e-06,
      "loss": 0.1973,
      "step": 3780
    },
    {
      "epoch": 0.8687959558823529,
      "grad_norm": 2.7115423679351807,
      "learning_rate": 9.181474673202615e-06,
      "loss": 0.2066,
      "step": 3781
    },
    {
      "epoch": 0.8690257352941176,
      "grad_norm": 1.9593313932418823,
      "learning_rate": 9.180964052287582e-06,
      "loss": 0.1621,
      "step": 3782
    },
    {
      "epoch": 0.8692555147058824,
      "grad_norm": 1.781806230545044,
      "learning_rate": 9.18045343137255e-06,
      "loss": 0.1803,
      "step": 3783
    },
    {
      "epoch": 0.8694852941176471,
      "grad_norm": 1.5758863687515259,
      "learning_rate": 9.179942810457517e-06,
      "loss": 0.1447,
      "step": 3784
    },
    {
      "epoch": 0.8697150735294118,
      "grad_norm": 1.4773054122924805,
      "learning_rate": 9.179432189542483e-06,
      "loss": 0.1638,
      "step": 3785
    },
    {
      "epoch": 0.8699448529411765,
      "grad_norm": 1.7901947498321533,
      "learning_rate": 9.178921568627451e-06,
      "loss": 0.1676,
      "step": 3786
    },
    {
      "epoch": 0.8701746323529411,
      "grad_norm": 1.5001025199890137,
      "learning_rate": 9.17841094771242e-06,
      "loss": 0.1449,
      "step": 3787
    },
    {
      "epoch": 0.8704044117647058,
      "grad_norm": 1.8140852451324463,
      "learning_rate": 9.177900326797387e-06,
      "loss": 0.1594,
      "step": 3788
    },
    {
      "epoch": 0.8706341911764706,
      "grad_norm": 1.7221808433532715,
      "learning_rate": 9.177389705882353e-06,
      "loss": 0.1943,
      "step": 3789
    },
    {
      "epoch": 0.8708639705882353,
      "grad_norm": 1.6404480934143066,
      "learning_rate": 9.176879084967321e-06,
      "loss": 0.1853,
      "step": 3790
    },
    {
      "epoch": 0.87109375,
      "grad_norm": 1.4951539039611816,
      "learning_rate": 9.176368464052289e-06,
      "loss": 0.124,
      "step": 3791
    },
    {
      "epoch": 0.8713235294117647,
      "grad_norm": 2.2532453536987305,
      "learning_rate": 9.175857843137255e-06,
      "loss": 0.222,
      "step": 3792
    },
    {
      "epoch": 0.8715533088235294,
      "grad_norm": 1.2908023595809937,
      "learning_rate": 9.175347222222223e-06,
      "loss": 0.1675,
      "step": 3793
    },
    {
      "epoch": 0.8717830882352942,
      "grad_norm": 1.4754518270492554,
      "learning_rate": 9.174836601307189e-06,
      "loss": 0.1748,
      "step": 3794
    },
    {
      "epoch": 0.8720128676470589,
      "grad_norm": 1.4418506622314453,
      "learning_rate": 9.174325980392159e-06,
      "loss": 0.1559,
      "step": 3795
    },
    {
      "epoch": 0.8722426470588235,
      "grad_norm": 1.6147501468658447,
      "learning_rate": 9.173815359477125e-06,
      "loss": 0.2043,
      "step": 3796
    },
    {
      "epoch": 0.8724724264705882,
      "grad_norm": 2.1058573722839355,
      "learning_rate": 9.173304738562093e-06,
      "loss": 0.1574,
      "step": 3797
    },
    {
      "epoch": 0.8727022058823529,
      "grad_norm": 1.7286347150802612,
      "learning_rate": 9.172794117647059e-06,
      "loss": 0.1752,
      "step": 3798
    },
    {
      "epoch": 0.8729319852941176,
      "grad_norm": 1.3547496795654297,
      "learning_rate": 9.172283496732027e-06,
      "loss": 0.148,
      "step": 3799
    },
    {
      "epoch": 0.8731617647058824,
      "grad_norm": 1.4689031839370728,
      "learning_rate": 9.171772875816995e-06,
      "loss": 0.1502,
      "step": 3800
    },
    {
      "epoch": 0.8733915441176471,
      "grad_norm": 1.7375715970993042,
      "learning_rate": 9.17126225490196e-06,
      "loss": 0.2242,
      "step": 3801
    },
    {
      "epoch": 0.8736213235294118,
      "grad_norm": 1.4329575300216675,
      "learning_rate": 9.170751633986929e-06,
      "loss": 0.1611,
      "step": 3802
    },
    {
      "epoch": 0.8738511029411765,
      "grad_norm": 1.7007901668548584,
      "learning_rate": 9.170241013071896e-06,
      "loss": 0.1792,
      "step": 3803
    },
    {
      "epoch": 0.8740808823529411,
      "grad_norm": 1.3528987169265747,
      "learning_rate": 9.169730392156864e-06,
      "loss": 0.1884,
      "step": 3804
    },
    {
      "epoch": 0.8743106617647058,
      "grad_norm": 1.6864354610443115,
      "learning_rate": 9.16921977124183e-06,
      "loss": 0.2131,
      "step": 3805
    },
    {
      "epoch": 0.8745404411764706,
      "grad_norm": 1.7723028659820557,
      "learning_rate": 9.168709150326798e-06,
      "loss": 0.1472,
      "step": 3806
    },
    {
      "epoch": 0.8747702205882353,
      "grad_norm": 1.7709083557128906,
      "learning_rate": 9.168198529411766e-06,
      "loss": 0.2706,
      "step": 3807
    },
    {
      "epoch": 0.875,
      "grad_norm": 1.882330060005188,
      "learning_rate": 9.167687908496732e-06,
      "loss": 0.1951,
      "step": 3808
    },
    {
      "epoch": 0.8752297794117647,
      "grad_norm": 1.8765114545822144,
      "learning_rate": 9.1671772875817e-06,
      "loss": 0.1698,
      "step": 3809
    },
    {
      "epoch": 0.8754595588235294,
      "grad_norm": 2.349884033203125,
      "learning_rate": 9.166666666666666e-06,
      "loss": 0.2048,
      "step": 3810
    },
    {
      "epoch": 0.8756893382352942,
      "grad_norm": 1.6429566144943237,
      "learning_rate": 9.166156045751636e-06,
      "loss": 0.209,
      "step": 3811
    },
    {
      "epoch": 0.8759191176470589,
      "grad_norm": 1.7469826936721802,
      "learning_rate": 9.165645424836602e-06,
      "loss": 0.1687,
      "step": 3812
    },
    {
      "epoch": 0.8761488970588235,
      "grad_norm": 1.6149359941482544,
      "learning_rate": 9.16513480392157e-06,
      "loss": 0.1922,
      "step": 3813
    },
    {
      "epoch": 0.8763786764705882,
      "grad_norm": 1.8339048624038696,
      "learning_rate": 9.164624183006536e-06,
      "loss": 0.1632,
      "step": 3814
    },
    {
      "epoch": 0.8766084558823529,
      "grad_norm": 1.447974681854248,
      "learning_rate": 9.164113562091504e-06,
      "loss": 0.1771,
      "step": 3815
    },
    {
      "epoch": 0.8768382352941176,
      "grad_norm": 1.459571361541748,
      "learning_rate": 9.163602941176472e-06,
      "loss": 0.1969,
      "step": 3816
    },
    {
      "epoch": 0.8770680147058824,
      "grad_norm": 1.6406569480895996,
      "learning_rate": 9.163092320261438e-06,
      "loss": 0.148,
      "step": 3817
    },
    {
      "epoch": 0.8772977941176471,
      "grad_norm": 1.529645562171936,
      "learning_rate": 9.162581699346406e-06,
      "loss": 0.178,
      "step": 3818
    },
    {
      "epoch": 0.8775275735294118,
      "grad_norm": 1.6646348237991333,
      "learning_rate": 9.162071078431374e-06,
      "loss": 0.1878,
      "step": 3819
    },
    {
      "epoch": 0.8777573529411765,
      "grad_norm": 1.8718336820602417,
      "learning_rate": 9.161560457516342e-06,
      "loss": 0.1646,
      "step": 3820
    },
    {
      "epoch": 0.8779871323529411,
      "grad_norm": 2.4748973846435547,
      "learning_rate": 9.161049836601308e-06,
      "loss": 0.193,
      "step": 3821
    },
    {
      "epoch": 0.8782169117647058,
      "grad_norm": 1.7126749753952026,
      "learning_rate": 9.160539215686276e-06,
      "loss": 0.1411,
      "step": 3822
    },
    {
      "epoch": 0.8784466911764706,
      "grad_norm": 1.5170363187789917,
      "learning_rate": 9.160028594771244e-06,
      "loss": 0.1725,
      "step": 3823
    },
    {
      "epoch": 0.8786764705882353,
      "grad_norm": 1.6515116691589355,
      "learning_rate": 9.15951797385621e-06,
      "loss": 0.1459,
      "step": 3824
    },
    {
      "epoch": 0.87890625,
      "grad_norm": 1.3750578165054321,
      "learning_rate": 9.159007352941178e-06,
      "loss": 0.1101,
      "step": 3825
    },
    {
      "epoch": 0.8791360294117647,
      "grad_norm": 1.6132493019104004,
      "learning_rate": 9.158496732026144e-06,
      "loss": 0.1953,
      "step": 3826
    },
    {
      "epoch": 0.8793658088235294,
      "grad_norm": 1.523550033569336,
      "learning_rate": 9.157986111111112e-06,
      "loss": 0.1659,
      "step": 3827
    },
    {
      "epoch": 0.8795955882352942,
      "grad_norm": 1.8967154026031494,
      "learning_rate": 9.15747549019608e-06,
      "loss": 0.1878,
      "step": 3828
    },
    {
      "epoch": 0.8798253676470589,
      "grad_norm": 1.7808488607406616,
      "learning_rate": 9.156964869281046e-06,
      "loss": 0.1539,
      "step": 3829
    },
    {
      "epoch": 0.8800551470588235,
      "grad_norm": 1.3925954103469849,
      "learning_rate": 9.156454248366013e-06,
      "loss": 0.1488,
      "step": 3830
    },
    {
      "epoch": 0.8802849264705882,
      "grad_norm": 1.6332249641418457,
      "learning_rate": 9.155943627450981e-06,
      "loss": 0.1454,
      "step": 3831
    },
    {
      "epoch": 0.8805147058823529,
      "grad_norm": 1.7379182577133179,
      "learning_rate": 9.15543300653595e-06,
      "loss": 0.1699,
      "step": 3832
    },
    {
      "epoch": 0.8807444852941176,
      "grad_norm": 1.7903592586517334,
      "learning_rate": 9.154922385620915e-06,
      "loss": 0.1928,
      "step": 3833
    },
    {
      "epoch": 0.8809742647058824,
      "grad_norm": 1.8389952182769775,
      "learning_rate": 9.154411764705883e-06,
      "loss": 0.1951,
      "step": 3834
    },
    {
      "epoch": 0.8812040441176471,
      "grad_norm": 1.6482418775558472,
      "learning_rate": 9.153901143790851e-06,
      "loss": 0.1476,
      "step": 3835
    },
    {
      "epoch": 0.8814338235294118,
      "grad_norm": 1.4960739612579346,
      "learning_rate": 9.153390522875817e-06,
      "loss": 0.1858,
      "step": 3836
    },
    {
      "epoch": 0.8816636029411765,
      "grad_norm": 1.4924774169921875,
      "learning_rate": 9.152879901960785e-06,
      "loss": 0.1456,
      "step": 3837
    },
    {
      "epoch": 0.8818933823529411,
      "grad_norm": 1.783667802810669,
      "learning_rate": 9.152369281045751e-06,
      "loss": 0.172,
      "step": 3838
    },
    {
      "epoch": 0.8821231617647058,
      "grad_norm": 1.5993314981460571,
      "learning_rate": 9.151858660130721e-06,
      "loss": 0.2062,
      "step": 3839
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 2.4124844074249268,
      "learning_rate": 9.151348039215687e-06,
      "loss": 0.1905,
      "step": 3840
    },
    {
      "epoch": 0.8825827205882353,
      "grad_norm": 2.0108141899108887,
      "learning_rate": 9.150837418300655e-06,
      "loss": 0.227,
      "step": 3841
    },
    {
      "epoch": 0.8828125,
      "grad_norm": 1.8222174644470215,
      "learning_rate": 9.150326797385621e-06,
      "loss": 0.1772,
      "step": 3842
    },
    {
      "epoch": 0.8830422794117647,
      "grad_norm": 1.8769623041152954,
      "learning_rate": 9.149816176470589e-06,
      "loss": 0.1968,
      "step": 3843
    },
    {
      "epoch": 0.8832720588235294,
      "grad_norm": 1.8194835186004639,
      "learning_rate": 9.149305555555557e-06,
      "loss": 0.1519,
      "step": 3844
    },
    {
      "epoch": 0.8835018382352942,
      "grad_norm": 1.74849271774292,
      "learning_rate": 9.148794934640523e-06,
      "loss": 0.2234,
      "step": 3845
    },
    {
      "epoch": 0.8837316176470589,
      "grad_norm": 1.6880167722702026,
      "learning_rate": 9.14828431372549e-06,
      "loss": 0.1847,
      "step": 3846
    },
    {
      "epoch": 0.8839613970588235,
      "grad_norm": 1.3414337635040283,
      "learning_rate": 9.147773692810459e-06,
      "loss": 0.1325,
      "step": 3847
    },
    {
      "epoch": 0.8841911764705882,
      "grad_norm": 1.9762018918991089,
      "learning_rate": 9.147263071895427e-06,
      "loss": 0.2449,
      "step": 3848
    },
    {
      "epoch": 0.8844209558823529,
      "grad_norm": 1.814327597618103,
      "learning_rate": 9.146752450980393e-06,
      "loss": 0.1898,
      "step": 3849
    },
    {
      "epoch": 0.8846507352941176,
      "grad_norm": 1.5104705095291138,
      "learning_rate": 9.14624183006536e-06,
      "loss": 0.1885,
      "step": 3850
    },
    {
      "epoch": 0.8848805147058824,
      "grad_norm": 1.6836223602294922,
      "learning_rate": 9.145731209150328e-06,
      "loss": 0.1824,
      "step": 3851
    },
    {
      "epoch": 0.8851102941176471,
      "grad_norm": 1.715206265449524,
      "learning_rate": 9.145220588235295e-06,
      "loss": 0.174,
      "step": 3852
    },
    {
      "epoch": 0.8853400735294118,
      "grad_norm": 1.5255025625228882,
      "learning_rate": 9.144709967320262e-06,
      "loss": 0.1584,
      "step": 3853
    },
    {
      "epoch": 0.8855698529411765,
      "grad_norm": 1.7242811918258667,
      "learning_rate": 9.144199346405229e-06,
      "loss": 0.1762,
      "step": 3854
    },
    {
      "epoch": 0.8857996323529411,
      "grad_norm": 1.6031646728515625,
      "learning_rate": 9.143688725490198e-06,
      "loss": 0.2296,
      "step": 3855
    },
    {
      "epoch": 0.8860294117647058,
      "grad_norm": 1.79840087890625,
      "learning_rate": 9.143178104575164e-06,
      "loss": 0.199,
      "step": 3856
    },
    {
      "epoch": 0.8862591911764706,
      "grad_norm": 1.5527911186218262,
      "learning_rate": 9.142667483660132e-06,
      "loss": 0.152,
      "step": 3857
    },
    {
      "epoch": 0.8864889705882353,
      "grad_norm": 1.6983790397644043,
      "learning_rate": 9.142156862745098e-06,
      "loss": 0.2343,
      "step": 3858
    },
    {
      "epoch": 0.88671875,
      "grad_norm": 1.7423712015151978,
      "learning_rate": 9.141646241830066e-06,
      "loss": 0.1697,
      "step": 3859
    },
    {
      "epoch": 0.8869485294117647,
      "grad_norm": 1.9521619081497192,
      "learning_rate": 9.141135620915034e-06,
      "loss": 0.1807,
      "step": 3860
    },
    {
      "epoch": 0.8871783088235294,
      "grad_norm": 1.688675045967102,
      "learning_rate": 9.140625e-06,
      "loss": 0.1356,
      "step": 3861
    },
    {
      "epoch": 0.8874080882352942,
      "grad_norm": 1.6392085552215576,
      "learning_rate": 9.140114379084968e-06,
      "loss": 0.1022,
      "step": 3862
    },
    {
      "epoch": 0.8876378676470589,
      "grad_norm": 1.58011794090271,
      "learning_rate": 9.139603758169934e-06,
      "loss": 0.1504,
      "step": 3863
    },
    {
      "epoch": 0.8878676470588235,
      "grad_norm": 1.9377038478851318,
      "learning_rate": 9.139093137254902e-06,
      "loss": 0.215,
      "step": 3864
    },
    {
      "epoch": 0.8880974264705882,
      "grad_norm": 1.951059103012085,
      "learning_rate": 9.13858251633987e-06,
      "loss": 0.1874,
      "step": 3865
    },
    {
      "epoch": 0.8883272058823529,
      "grad_norm": 1.882670283317566,
      "learning_rate": 9.138071895424838e-06,
      "loss": 0.1451,
      "step": 3866
    },
    {
      "epoch": 0.8885569852941176,
      "grad_norm": 2.096306562423706,
      "learning_rate": 9.137561274509804e-06,
      "loss": 0.2243,
      "step": 3867
    },
    {
      "epoch": 0.8887867647058824,
      "grad_norm": 1.8824357986450195,
      "learning_rate": 9.137050653594772e-06,
      "loss": 0.1447,
      "step": 3868
    },
    {
      "epoch": 0.8890165441176471,
      "grad_norm": 1.9441872835159302,
      "learning_rate": 9.13654003267974e-06,
      "loss": 0.1452,
      "step": 3869
    },
    {
      "epoch": 0.8892463235294118,
      "grad_norm": 1.9162691831588745,
      "learning_rate": 9.136029411764706e-06,
      "loss": 0.1678,
      "step": 3870
    },
    {
      "epoch": 0.8894761029411765,
      "grad_norm": 1.754140019416809,
      "learning_rate": 9.135518790849674e-06,
      "loss": 0.1637,
      "step": 3871
    },
    {
      "epoch": 0.8897058823529411,
      "grad_norm": 1.415770173072815,
      "learning_rate": 9.135008169934642e-06,
      "loss": 0.1451,
      "step": 3872
    },
    {
      "epoch": 0.8899356617647058,
      "grad_norm": 2.0727651119232178,
      "learning_rate": 9.134497549019608e-06,
      "loss": 0.1298,
      "step": 3873
    },
    {
      "epoch": 0.8901654411764706,
      "grad_norm": 2.067814350128174,
      "learning_rate": 9.133986928104576e-06,
      "loss": 0.1911,
      "step": 3874
    },
    {
      "epoch": 0.8903952205882353,
      "grad_norm": 1.8361632823944092,
      "learning_rate": 9.133476307189544e-06,
      "loss": 0.137,
      "step": 3875
    },
    {
      "epoch": 0.890625,
      "grad_norm": 1.5924866199493408,
      "learning_rate": 9.132965686274511e-06,
      "loss": 0.1495,
      "step": 3876
    },
    {
      "epoch": 0.8908547794117647,
      "grad_norm": 1.962648630142212,
      "learning_rate": 9.132455065359478e-06,
      "loss": 0.1505,
      "step": 3877
    },
    {
      "epoch": 0.8910845588235294,
      "grad_norm": 1.7692995071411133,
      "learning_rate": 9.131944444444445e-06,
      "loss": 0.1807,
      "step": 3878
    },
    {
      "epoch": 0.8913143382352942,
      "grad_norm": 1.853822946548462,
      "learning_rate": 9.131433823529412e-06,
      "loss": 0.2418,
      "step": 3879
    },
    {
      "epoch": 0.8915441176470589,
      "grad_norm": 1.6752983331680298,
      "learning_rate": 9.13092320261438e-06,
      "loss": 0.1099,
      "step": 3880
    },
    {
      "epoch": 0.8917738970588235,
      "grad_norm": 2.0641841888427734,
      "learning_rate": 9.130412581699347e-06,
      "loss": 0.186,
      "step": 3881
    },
    {
      "epoch": 0.8920036764705882,
      "grad_norm": 1.7318791151046753,
      "learning_rate": 9.129901960784313e-06,
      "loss": 0.1424,
      "step": 3882
    },
    {
      "epoch": 0.8922334558823529,
      "grad_norm": 2.069643497467041,
      "learning_rate": 9.129391339869281e-06,
      "loss": 0.1906,
      "step": 3883
    },
    {
      "epoch": 0.8924632352941176,
      "grad_norm": 1.2078672647476196,
      "learning_rate": 9.12888071895425e-06,
      "loss": 0.1337,
      "step": 3884
    },
    {
      "epoch": 0.8926930147058824,
      "grad_norm": 1.4883720874786377,
      "learning_rate": 9.128370098039217e-06,
      "loss": 0.1928,
      "step": 3885
    },
    {
      "epoch": 0.8929227941176471,
      "grad_norm": 2.0076351165771484,
      "learning_rate": 9.127859477124183e-06,
      "loss": 0.2121,
      "step": 3886
    },
    {
      "epoch": 0.8931525735294118,
      "grad_norm": 1.3396165370941162,
      "learning_rate": 9.127348856209151e-06,
      "loss": 0.152,
      "step": 3887
    },
    {
      "epoch": 0.8933823529411765,
      "grad_norm": 2.3758156299591064,
      "learning_rate": 9.126838235294119e-06,
      "loss": 0.2091,
      "step": 3888
    },
    {
      "epoch": 0.8936121323529411,
      "grad_norm": 1.5928059816360474,
      "learning_rate": 9.126327614379085e-06,
      "loss": 0.1383,
      "step": 3889
    },
    {
      "epoch": 0.8938419117647058,
      "grad_norm": 2.2479467391967773,
      "learning_rate": 9.125816993464053e-06,
      "loss": 0.2146,
      "step": 3890
    },
    {
      "epoch": 0.8940716911764706,
      "grad_norm": 1.7880641222000122,
      "learning_rate": 9.12530637254902e-06,
      "loss": 0.1958,
      "step": 3891
    },
    {
      "epoch": 0.8943014705882353,
      "grad_norm": 2.0080480575561523,
      "learning_rate": 9.124795751633989e-06,
      "loss": 0.1801,
      "step": 3892
    },
    {
      "epoch": 0.89453125,
      "grad_norm": 1.9113861322402954,
      "learning_rate": 9.124285130718955e-06,
      "loss": 0.1839,
      "step": 3893
    },
    {
      "epoch": 0.8947610294117647,
      "grad_norm": 2.207491636276245,
      "learning_rate": 9.123774509803923e-06,
      "loss": 0.2122,
      "step": 3894
    },
    {
      "epoch": 0.8949908088235294,
      "grad_norm": 1.641097068786621,
      "learning_rate": 9.123263888888889e-06,
      "loss": 0.1739,
      "step": 3895
    },
    {
      "epoch": 0.8952205882352942,
      "grad_norm": 1.3029471635818481,
      "learning_rate": 9.122753267973857e-06,
      "loss": 0.1407,
      "step": 3896
    },
    {
      "epoch": 0.8954503676470589,
      "grad_norm": 1.5549931526184082,
      "learning_rate": 9.122242647058825e-06,
      "loss": 0.1453,
      "step": 3897
    },
    {
      "epoch": 0.8956801470588235,
      "grad_norm": 2.1280834674835205,
      "learning_rate": 9.12173202614379e-06,
      "loss": 0.1594,
      "step": 3898
    },
    {
      "epoch": 0.8959099264705882,
      "grad_norm": 1.8403866291046143,
      "learning_rate": 9.121221405228759e-06,
      "loss": 0.178,
      "step": 3899
    },
    {
      "epoch": 0.8961397058823529,
      "grad_norm": 1.6183656454086304,
      "learning_rate": 9.120710784313727e-06,
      "loss": 0.1531,
      "step": 3900
    },
    {
      "epoch": 0.8963694852941176,
      "grad_norm": 1.6050034761428833,
      "learning_rate": 9.120200163398694e-06,
      "loss": 0.1572,
      "step": 3901
    },
    {
      "epoch": 0.8965992647058824,
      "grad_norm": 1.8808141946792603,
      "learning_rate": 9.11968954248366e-06,
      "loss": 0.1881,
      "step": 3902
    },
    {
      "epoch": 0.8968290441176471,
      "grad_norm": 1.8623359203338623,
      "learning_rate": 9.119178921568628e-06,
      "loss": 0.1807,
      "step": 3903
    },
    {
      "epoch": 0.8970588235294118,
      "grad_norm": 1.6582902669906616,
      "learning_rate": 9.118668300653596e-06,
      "loss": 0.1614,
      "step": 3904
    },
    {
      "epoch": 0.8972886029411765,
      "grad_norm": 1.5014986991882324,
      "learning_rate": 9.118157679738562e-06,
      "loss": 0.1605,
      "step": 3905
    },
    {
      "epoch": 0.8975183823529411,
      "grad_norm": 1.5005559921264648,
      "learning_rate": 9.11764705882353e-06,
      "loss": 0.1353,
      "step": 3906
    },
    {
      "epoch": 0.8977481617647058,
      "grad_norm": 1.6738471984863281,
      "learning_rate": 9.117136437908496e-06,
      "loss": 0.1628,
      "step": 3907
    },
    {
      "epoch": 0.8979779411764706,
      "grad_norm": 1.9893683195114136,
      "learning_rate": 9.116625816993464e-06,
      "loss": 0.1528,
      "step": 3908
    },
    {
      "epoch": 0.8982077205882353,
      "grad_norm": 1.5714763402938843,
      "learning_rate": 9.116115196078432e-06,
      "loss": 0.1674,
      "step": 3909
    },
    {
      "epoch": 0.8984375,
      "grad_norm": 2.2597105503082275,
      "learning_rate": 9.1156045751634e-06,
      "loss": 0.2143,
      "step": 3910
    },
    {
      "epoch": 0.8986672794117647,
      "grad_norm": 1.7786990404129028,
      "learning_rate": 9.115093954248366e-06,
      "loss": 0.1879,
      "step": 3911
    },
    {
      "epoch": 0.8988970588235294,
      "grad_norm": 1.6785211563110352,
      "learning_rate": 9.114583333333334e-06,
      "loss": 0.1734,
      "step": 3912
    },
    {
      "epoch": 0.8991268382352942,
      "grad_norm": 1.5396407842636108,
      "learning_rate": 9.114072712418302e-06,
      "loss": 0.1556,
      "step": 3913
    },
    {
      "epoch": 0.8993566176470589,
      "grad_norm": 1.6921920776367188,
      "learning_rate": 9.113562091503268e-06,
      "loss": 0.2007,
      "step": 3914
    },
    {
      "epoch": 0.8995863970588235,
      "grad_norm": 1.9771286249160767,
      "learning_rate": 9.113051470588236e-06,
      "loss": 0.1827,
      "step": 3915
    },
    {
      "epoch": 0.8998161764705882,
      "grad_norm": 1.7888747453689575,
      "learning_rate": 9.112540849673204e-06,
      "loss": 0.2142,
      "step": 3916
    },
    {
      "epoch": 0.9000459558823529,
      "grad_norm": 1.9445164203643799,
      "learning_rate": 9.11203022875817e-06,
      "loss": 0.1916,
      "step": 3917
    },
    {
      "epoch": 0.9002757352941176,
      "grad_norm": 1.813934564590454,
      "learning_rate": 9.111519607843138e-06,
      "loss": 0.1813,
      "step": 3918
    },
    {
      "epoch": 0.9005055147058824,
      "grad_norm": 1.509172797203064,
      "learning_rate": 9.111008986928104e-06,
      "loss": 0.2266,
      "step": 3919
    },
    {
      "epoch": 0.9007352941176471,
      "grad_norm": 1.6689906120300293,
      "learning_rate": 9.110498366013074e-06,
      "loss": 0.1982,
      "step": 3920
    },
    {
      "epoch": 0.9009650735294118,
      "grad_norm": 2.568265914916992,
      "learning_rate": 9.10998774509804e-06,
      "loss": 0.1535,
      "step": 3921
    },
    {
      "epoch": 0.9011948529411765,
      "grad_norm": 1.660548448562622,
      "learning_rate": 9.109477124183008e-06,
      "loss": 0.1761,
      "step": 3922
    },
    {
      "epoch": 0.9014246323529411,
      "grad_norm": 1.7319234609603882,
      "learning_rate": 9.108966503267974e-06,
      "loss": 0.1568,
      "step": 3923
    },
    {
      "epoch": 0.9016544117647058,
      "grad_norm": 2.198065996170044,
      "learning_rate": 9.108455882352942e-06,
      "loss": 0.1608,
      "step": 3924
    },
    {
      "epoch": 0.9018841911764706,
      "grad_norm": 1.5575631856918335,
      "learning_rate": 9.10794526143791e-06,
      "loss": 0.1447,
      "step": 3925
    },
    {
      "epoch": 0.9021139705882353,
      "grad_norm": 1.421239972114563,
      "learning_rate": 9.107434640522876e-06,
      "loss": 0.1615,
      "step": 3926
    },
    {
      "epoch": 0.90234375,
      "grad_norm": 1.704930305480957,
      "learning_rate": 9.106924019607844e-06,
      "loss": 0.1679,
      "step": 3927
    },
    {
      "epoch": 0.9025735294117647,
      "grad_norm": 2.4173460006713867,
      "learning_rate": 9.106413398692811e-06,
      "loss": 0.2799,
      "step": 3928
    },
    {
      "epoch": 0.9028033088235294,
      "grad_norm": 1.6206960678100586,
      "learning_rate": 9.10590277777778e-06,
      "loss": 0.1604,
      "step": 3929
    },
    {
      "epoch": 0.9030330882352942,
      "grad_norm": 2.1965372562408447,
      "learning_rate": 9.105392156862745e-06,
      "loss": 0.1881,
      "step": 3930
    },
    {
      "epoch": 0.9032628676470589,
      "grad_norm": 1.4297325611114502,
      "learning_rate": 9.104881535947713e-06,
      "loss": 0.1552,
      "step": 3931
    },
    {
      "epoch": 0.9034926470588235,
      "grad_norm": 1.8218250274658203,
      "learning_rate": 9.104370915032681e-06,
      "loss": 0.1796,
      "step": 3932
    },
    {
      "epoch": 0.9037224264705882,
      "grad_norm": 1.6727445125579834,
      "learning_rate": 9.103860294117647e-06,
      "loss": 0.1954,
      "step": 3933
    },
    {
      "epoch": 0.9039522058823529,
      "grad_norm": 1.8116211891174316,
      "learning_rate": 9.103349673202615e-06,
      "loss": 0.2272,
      "step": 3934
    },
    {
      "epoch": 0.9041819852941176,
      "grad_norm": 1.8528448343276978,
      "learning_rate": 9.102839052287581e-06,
      "loss": 0.1595,
      "step": 3935
    },
    {
      "epoch": 0.9044117647058824,
      "grad_norm": 1.9124139547348022,
      "learning_rate": 9.102328431372551e-06,
      "loss": 0.1518,
      "step": 3936
    },
    {
      "epoch": 0.9046415441176471,
      "grad_norm": 1.797001838684082,
      "learning_rate": 9.101817810457517e-06,
      "loss": 0.18,
      "step": 3937
    },
    {
      "epoch": 0.9048713235294118,
      "grad_norm": 2.0089635848999023,
      "learning_rate": 9.101307189542485e-06,
      "loss": 0.1877,
      "step": 3938
    },
    {
      "epoch": 0.9051011029411765,
      "grad_norm": 1.56576669216156,
      "learning_rate": 9.100796568627451e-06,
      "loss": 0.1998,
      "step": 3939
    },
    {
      "epoch": 0.9053308823529411,
      "grad_norm": 1.1374858617782593,
      "learning_rate": 9.100285947712419e-06,
      "loss": 0.1215,
      "step": 3940
    },
    {
      "epoch": 0.9055606617647058,
      "grad_norm": 1.9302942752838135,
      "learning_rate": 9.099775326797387e-06,
      "loss": 0.1609,
      "step": 3941
    },
    {
      "epoch": 0.9057904411764706,
      "grad_norm": 1.7850232124328613,
      "learning_rate": 9.099264705882353e-06,
      "loss": 0.1871,
      "step": 3942
    },
    {
      "epoch": 0.9060202205882353,
      "grad_norm": 1.590320110321045,
      "learning_rate": 9.098754084967321e-06,
      "loss": 0.1639,
      "step": 3943
    },
    {
      "epoch": 0.90625,
      "grad_norm": 1.710516095161438,
      "learning_rate": 9.098243464052289e-06,
      "loss": 0.1851,
      "step": 3944
    },
    {
      "epoch": 0.9064797794117647,
      "grad_norm": 1.951181173324585,
      "learning_rate": 9.097732843137257e-06,
      "loss": 0.1827,
      "step": 3945
    },
    {
      "epoch": 0.9067095588235294,
      "grad_norm": 1.4457000494003296,
      "learning_rate": 9.097222222222223e-06,
      "loss": 0.1526,
      "step": 3946
    },
    {
      "epoch": 0.9069393382352942,
      "grad_norm": 1.80024254322052,
      "learning_rate": 9.09671160130719e-06,
      "loss": 0.2011,
      "step": 3947
    },
    {
      "epoch": 0.9071691176470589,
      "grad_norm": 1.8870530128479004,
      "learning_rate": 9.096200980392158e-06,
      "loss": 0.1758,
      "step": 3948
    },
    {
      "epoch": 0.9073988970588235,
      "grad_norm": 1.7701690196990967,
      "learning_rate": 9.095690359477125e-06,
      "loss": 0.1676,
      "step": 3949
    },
    {
      "epoch": 0.9076286764705882,
      "grad_norm": 2.0693516731262207,
      "learning_rate": 9.095179738562092e-06,
      "loss": 0.1541,
      "step": 3950
    },
    {
      "epoch": 0.9078584558823529,
      "grad_norm": 1.7599881887435913,
      "learning_rate": 9.094669117647059e-06,
      "loss": 0.157,
      "step": 3951
    },
    {
      "epoch": 0.9080882352941176,
      "grad_norm": 1.7028995752334595,
      "learning_rate": 9.094158496732027e-06,
      "loss": 0.1749,
      "step": 3952
    },
    {
      "epoch": 0.9083180147058824,
      "grad_norm": 1.5912911891937256,
      "learning_rate": 9.093647875816994e-06,
      "loss": 0.1598,
      "step": 3953
    },
    {
      "epoch": 0.9085477941176471,
      "grad_norm": 1.6080410480499268,
      "learning_rate": 9.093137254901962e-06,
      "loss": 0.1509,
      "step": 3954
    },
    {
      "epoch": 0.9087775735294118,
      "grad_norm": 1.4446715116500854,
      "learning_rate": 9.092626633986928e-06,
      "loss": 0.1679,
      "step": 3955
    },
    {
      "epoch": 0.9090073529411765,
      "grad_norm": 1.5108212232589722,
      "learning_rate": 9.092116013071896e-06,
      "loss": 0.1638,
      "step": 3956
    },
    {
      "epoch": 0.9092371323529411,
      "grad_norm": 1.677544116973877,
      "learning_rate": 9.091605392156864e-06,
      "loss": 0.1364,
      "step": 3957
    },
    {
      "epoch": 0.9094669117647058,
      "grad_norm": 1.6689035892486572,
      "learning_rate": 9.09109477124183e-06,
      "loss": 0.1792,
      "step": 3958
    },
    {
      "epoch": 0.9096966911764706,
      "grad_norm": 1.620408535003662,
      "learning_rate": 9.090584150326798e-06,
      "loss": 0.2141,
      "step": 3959
    },
    {
      "epoch": 0.9099264705882353,
      "grad_norm": 2.2228474617004395,
      "learning_rate": 9.090073529411766e-06,
      "loss": 0.1651,
      "step": 3960
    },
    {
      "epoch": 0.91015625,
      "grad_norm": 2.2303764820098877,
      "learning_rate": 9.089562908496732e-06,
      "loss": 0.218,
      "step": 3961
    },
    {
      "epoch": 0.9103860294117647,
      "grad_norm": 2.053847551345825,
      "learning_rate": 9.0890522875817e-06,
      "loss": 0.1421,
      "step": 3962
    },
    {
      "epoch": 0.9106158088235294,
      "grad_norm": 1.8345807790756226,
      "learning_rate": 9.088541666666666e-06,
      "loss": 0.1761,
      "step": 3963
    },
    {
      "epoch": 0.9108455882352942,
      "grad_norm": 1.4879176616668701,
      "learning_rate": 9.088031045751636e-06,
      "loss": 0.2008,
      "step": 3964
    },
    {
      "epoch": 0.9110753676470589,
      "grad_norm": 2.1223573684692383,
      "learning_rate": 9.087520424836602e-06,
      "loss": 0.1785,
      "step": 3965
    },
    {
      "epoch": 0.9113051470588235,
      "grad_norm": 1.7844743728637695,
      "learning_rate": 9.08700980392157e-06,
      "loss": 0.1872,
      "step": 3966
    },
    {
      "epoch": 0.9115349264705882,
      "grad_norm": 1.7081286907196045,
      "learning_rate": 9.086499183006536e-06,
      "loss": 0.2019,
      "step": 3967
    },
    {
      "epoch": 0.9117647058823529,
      "grad_norm": 1.5999835729599,
      "learning_rate": 9.085988562091504e-06,
      "loss": 0.1388,
      "step": 3968
    },
    {
      "epoch": 0.9119944852941176,
      "grad_norm": 1.4474751949310303,
      "learning_rate": 9.085477941176472e-06,
      "loss": 0.1697,
      "step": 3969
    },
    {
      "epoch": 0.9122242647058824,
      "grad_norm": 1.695085048675537,
      "learning_rate": 9.084967320261438e-06,
      "loss": 0.172,
      "step": 3970
    },
    {
      "epoch": 0.9124540441176471,
      "grad_norm": 1.7595391273498535,
      "learning_rate": 9.084456699346406e-06,
      "loss": 0.1776,
      "step": 3971
    },
    {
      "epoch": 0.9126838235294118,
      "grad_norm": 1.699917197227478,
      "learning_rate": 9.083946078431374e-06,
      "loss": 0.1889,
      "step": 3972
    },
    {
      "epoch": 0.9129136029411765,
      "grad_norm": 1.6411114931106567,
      "learning_rate": 9.083435457516341e-06,
      "loss": 0.1437,
      "step": 3973
    },
    {
      "epoch": 0.9131433823529411,
      "grad_norm": 1.7861813306808472,
      "learning_rate": 9.082924836601308e-06,
      "loss": 0.1787,
      "step": 3974
    },
    {
      "epoch": 0.9133731617647058,
      "grad_norm": 1.8240349292755127,
      "learning_rate": 9.082414215686275e-06,
      "loss": 0.2341,
      "step": 3975
    },
    {
      "epoch": 0.9136029411764706,
      "grad_norm": 1.8485255241394043,
      "learning_rate": 9.081903594771243e-06,
      "loss": 0.1865,
      "step": 3976
    },
    {
      "epoch": 0.9138327205882353,
      "grad_norm": 1.6831326484680176,
      "learning_rate": 9.08139297385621e-06,
      "loss": 0.1665,
      "step": 3977
    },
    {
      "epoch": 0.9140625,
      "grad_norm": 1.6477998495101929,
      "learning_rate": 9.080882352941177e-06,
      "loss": 0.1613,
      "step": 3978
    },
    {
      "epoch": 0.9142922794117647,
      "grad_norm": 1.9377782344818115,
      "learning_rate": 9.080371732026144e-06,
      "loss": 0.1886,
      "step": 3979
    },
    {
      "epoch": 0.9145220588235294,
      "grad_norm": 1.9808112382888794,
      "learning_rate": 9.079861111111113e-06,
      "loss": 0.2022,
      "step": 3980
    },
    {
      "epoch": 0.9147518382352942,
      "grad_norm": 1.4056954383850098,
      "learning_rate": 9.07935049019608e-06,
      "loss": 0.1493,
      "step": 3981
    },
    {
      "epoch": 0.9149816176470589,
      "grad_norm": 1.6792716979980469,
      "learning_rate": 9.078839869281047e-06,
      "loss": 0.184,
      "step": 3982
    },
    {
      "epoch": 0.9152113970588235,
      "grad_norm": 1.3136714696884155,
      "learning_rate": 9.078329248366013e-06,
      "loss": 0.1426,
      "step": 3983
    },
    {
      "epoch": 0.9154411764705882,
      "grad_norm": 1.4494290351867676,
      "learning_rate": 9.077818627450981e-06,
      "loss": 0.1262,
      "step": 3984
    },
    {
      "epoch": 0.9156709558823529,
      "grad_norm": 2.0090599060058594,
      "learning_rate": 9.077308006535949e-06,
      "loss": 0.1924,
      "step": 3985
    },
    {
      "epoch": 0.9159007352941176,
      "grad_norm": 1.4903416633605957,
      "learning_rate": 9.076797385620915e-06,
      "loss": 0.1326,
      "step": 3986
    },
    {
      "epoch": 0.9161305147058824,
      "grad_norm": 1.9722787141799927,
      "learning_rate": 9.076286764705883e-06,
      "loss": 0.2428,
      "step": 3987
    },
    {
      "epoch": 0.9163602941176471,
      "grad_norm": 1.9793996810913086,
      "learning_rate": 9.075776143790851e-06,
      "loss": 0.1331,
      "step": 3988
    },
    {
      "epoch": 0.9165900735294118,
      "grad_norm": 2.1116840839385986,
      "learning_rate": 9.075265522875819e-06,
      "loss": 0.1886,
      "step": 3989
    },
    {
      "epoch": 0.9168198529411765,
      "grad_norm": 1.4458935260772705,
      "learning_rate": 9.074754901960785e-06,
      "loss": 0.1681,
      "step": 3990
    },
    {
      "epoch": 0.9170496323529411,
      "grad_norm": 1.488125205039978,
      "learning_rate": 9.074244281045753e-06,
      "loss": 0.131,
      "step": 3991
    },
    {
      "epoch": 0.9172794117647058,
      "grad_norm": 1.7681167125701904,
      "learning_rate": 9.07373366013072e-06,
      "loss": 0.1903,
      "step": 3992
    },
    {
      "epoch": 0.9175091911764706,
      "grad_norm": 1.5228725671768188,
      "learning_rate": 9.073223039215687e-06,
      "loss": 0.1727,
      "step": 3993
    },
    {
      "epoch": 0.9177389705882353,
      "grad_norm": 1.970003604888916,
      "learning_rate": 9.072712418300655e-06,
      "loss": 0.1914,
      "step": 3994
    },
    {
      "epoch": 0.91796875,
      "grad_norm": 1.7447614669799805,
      "learning_rate": 9.072201797385621e-06,
      "loss": 0.1549,
      "step": 3995
    },
    {
      "epoch": 0.9181985294117647,
      "grad_norm": 1.7701810598373413,
      "learning_rate": 9.071691176470589e-06,
      "loss": 0.1969,
      "step": 3996
    },
    {
      "epoch": 0.9184283088235294,
      "grad_norm": 1.3986320495605469,
      "learning_rate": 9.071180555555557e-06,
      "loss": 0.146,
      "step": 3997
    },
    {
      "epoch": 0.9186580882352942,
      "grad_norm": 1.9067082405090332,
      "learning_rate": 9.070669934640524e-06,
      "loss": 0.179,
      "step": 3998
    },
    {
      "epoch": 0.9188878676470589,
      "grad_norm": 1.9062087535858154,
      "learning_rate": 9.07015931372549e-06,
      "loss": 0.1508,
      "step": 3999
    },
    {
      "epoch": 0.9191176470588235,
      "grad_norm": 1.7785993814468384,
      "learning_rate": 9.069648692810458e-06,
      "loss": 0.1882,
      "step": 4000
    },
    {
      "epoch": 0.9191176470588235,
      "eval_loss": 0.16914492845535278,
      "eval_runtime": 434.4848,
      "eval_samples_per_second": 20.498,
      "eval_steps_per_second": 10.249,
      "step": 4000
    },
    {
      "epoch": 0.9193474264705882,
      "grad_norm": 1.4162185192108154,
      "learning_rate": 9.069138071895426e-06,
      "loss": 0.1616,
      "step": 4001
    },
    {
      "epoch": 0.9195772058823529,
      "grad_norm": 1.297577977180481,
      "learning_rate": 9.068627450980392e-06,
      "loss": 0.1892,
      "step": 4002
    },
    {
      "epoch": 0.9198069852941176,
      "grad_norm": 1.8211236000061035,
      "learning_rate": 9.06811683006536e-06,
      "loss": 0.1846,
      "step": 4003
    },
    {
      "epoch": 0.9200367647058824,
      "grad_norm": 1.7450681924819946,
      "learning_rate": 9.067606209150328e-06,
      "loss": 0.1557,
      "step": 4004
    },
    {
      "epoch": 0.9202665441176471,
      "grad_norm": 1.9925541877746582,
      "learning_rate": 9.067095588235294e-06,
      "loss": 0.2053,
      "step": 4005
    },
    {
      "epoch": 0.9204963235294118,
      "grad_norm": 1.543535590171814,
      "learning_rate": 9.066584967320262e-06,
      "loss": 0.131,
      "step": 4006
    },
    {
      "epoch": 0.9207261029411765,
      "grad_norm": 2.221092939376831,
      "learning_rate": 9.066074346405228e-06,
      "loss": 0.1851,
      "step": 4007
    },
    {
      "epoch": 0.9209558823529411,
      "grad_norm": 1.4138293266296387,
      "learning_rate": 9.065563725490198e-06,
      "loss": 0.1522,
      "step": 4008
    },
    {
      "epoch": 0.9211856617647058,
      "grad_norm": 1.4746317863464355,
      "learning_rate": 9.065053104575164e-06,
      "loss": 0.1819,
      "step": 4009
    },
    {
      "epoch": 0.9214154411764706,
      "grad_norm": 1.5705121755599976,
      "learning_rate": 9.064542483660132e-06,
      "loss": 0.141,
      "step": 4010
    },
    {
      "epoch": 0.9216452205882353,
      "grad_norm": 1.567357063293457,
      "learning_rate": 9.064031862745098e-06,
      "loss": 0.1328,
      "step": 4011
    },
    {
      "epoch": 0.921875,
      "grad_norm": 1.7474898099899292,
      "learning_rate": 9.063521241830066e-06,
      "loss": 0.1628,
      "step": 4012
    },
    {
      "epoch": 0.9221047794117647,
      "grad_norm": 2.0592081546783447,
      "learning_rate": 9.063010620915034e-06,
      "loss": 0.1858,
      "step": 4013
    },
    {
      "epoch": 0.9223345588235294,
      "grad_norm": 1.6760574579238892,
      "learning_rate": 9.0625e-06,
      "loss": 0.2206,
      "step": 4014
    },
    {
      "epoch": 0.9225643382352942,
      "grad_norm": 1.6845346689224243,
      "learning_rate": 9.061989379084968e-06,
      "loss": 0.1873,
      "step": 4015
    },
    {
      "epoch": 0.9227941176470589,
      "grad_norm": 1.613531470298767,
      "learning_rate": 9.061478758169934e-06,
      "loss": 0.1711,
      "step": 4016
    },
    {
      "epoch": 0.9230238970588235,
      "grad_norm": 1.9376622438430786,
      "learning_rate": 9.060968137254904e-06,
      "loss": 0.1793,
      "step": 4017
    },
    {
      "epoch": 0.9232536764705882,
      "grad_norm": 2.2467880249023438,
      "learning_rate": 9.06045751633987e-06,
      "loss": 0.147,
      "step": 4018
    },
    {
      "epoch": 0.9234834558823529,
      "grad_norm": 1.548530101776123,
      "learning_rate": 9.059946895424838e-06,
      "loss": 0.1507,
      "step": 4019
    },
    {
      "epoch": 0.9237132352941176,
      "grad_norm": 1.593817949295044,
      "learning_rate": 9.059436274509804e-06,
      "loss": 0.1478,
      "step": 4020
    },
    {
      "epoch": 0.9239430147058824,
      "grad_norm": 1.9725565910339355,
      "learning_rate": 9.058925653594772e-06,
      "loss": 0.2151,
      "step": 4021
    },
    {
      "epoch": 0.9241727941176471,
      "grad_norm": 1.903804898262024,
      "learning_rate": 9.05841503267974e-06,
      "loss": 0.1286,
      "step": 4022
    },
    {
      "epoch": 0.9244025735294118,
      "grad_norm": 1.4442365169525146,
      "learning_rate": 9.057904411764706e-06,
      "loss": 0.1691,
      "step": 4023
    },
    {
      "epoch": 0.9246323529411765,
      "grad_norm": 1.7607531547546387,
      "learning_rate": 9.057393790849674e-06,
      "loss": 0.1817,
      "step": 4024
    },
    {
      "epoch": 0.9248621323529411,
      "grad_norm": 2.0097618103027344,
      "learning_rate": 9.056883169934641e-06,
      "loss": 0.1922,
      "step": 4025
    },
    {
      "epoch": 0.9250919117647058,
      "grad_norm": 2.0454041957855225,
      "learning_rate": 9.05637254901961e-06,
      "loss": 0.1959,
      "step": 4026
    },
    {
      "epoch": 0.9253216911764706,
      "grad_norm": 1.7384459972381592,
      "learning_rate": 9.055861928104575e-06,
      "loss": 0.1498,
      "step": 4027
    },
    {
      "epoch": 0.9255514705882353,
      "grad_norm": 1.3595097064971924,
      "learning_rate": 9.055351307189543e-06,
      "loss": 0.1596,
      "step": 4028
    },
    {
      "epoch": 0.92578125,
      "grad_norm": 1.9939806461334229,
      "learning_rate": 9.054840686274511e-06,
      "loss": 0.1756,
      "step": 4029
    },
    {
      "epoch": 0.9260110294117647,
      "grad_norm": 1.7721189260482788,
      "learning_rate": 9.054330065359477e-06,
      "loss": 0.1444,
      "step": 4030
    },
    {
      "epoch": 0.9262408088235294,
      "grad_norm": 1.5496623516082764,
      "learning_rate": 9.053819444444445e-06,
      "loss": 0.1486,
      "step": 4031
    },
    {
      "epoch": 0.9264705882352942,
      "grad_norm": 1.7262475490570068,
      "learning_rate": 9.053308823529411e-06,
      "loss": 0.1068,
      "step": 4032
    },
    {
      "epoch": 0.9267003676470589,
      "grad_norm": 1.984061598777771,
      "learning_rate": 9.052798202614381e-06,
      "loss": 0.1833,
      "step": 4033
    },
    {
      "epoch": 0.9269301470588235,
      "grad_norm": 1.5468796491622925,
      "learning_rate": 9.052287581699347e-06,
      "loss": 0.1607,
      "step": 4034
    },
    {
      "epoch": 0.9271599264705882,
      "grad_norm": 1.1770906448364258,
      "learning_rate": 9.051776960784315e-06,
      "loss": 0.1488,
      "step": 4035
    },
    {
      "epoch": 0.9273897058823529,
      "grad_norm": 1.5742260217666626,
      "learning_rate": 9.051266339869281e-06,
      "loss": 0.1914,
      "step": 4036
    },
    {
      "epoch": 0.9276194852941176,
      "grad_norm": 1.6590412855148315,
      "learning_rate": 9.050755718954249e-06,
      "loss": 0.1677,
      "step": 4037
    },
    {
      "epoch": 0.9278492647058824,
      "grad_norm": 1.556504487991333,
      "learning_rate": 9.050245098039217e-06,
      "loss": 0.1137,
      "step": 4038
    },
    {
      "epoch": 0.9280790441176471,
      "grad_norm": 1.6678227186203003,
      "learning_rate": 9.049734477124183e-06,
      "loss": 0.166,
      "step": 4039
    },
    {
      "epoch": 0.9283088235294118,
      "grad_norm": 1.7559168338775635,
      "learning_rate": 9.049223856209151e-06,
      "loss": 0.1502,
      "step": 4040
    },
    {
      "epoch": 0.9285386029411765,
      "grad_norm": 1.8324699401855469,
      "learning_rate": 9.048713235294119e-06,
      "loss": 0.1807,
      "step": 4041
    },
    {
      "epoch": 0.9287683823529411,
      "grad_norm": 1.78606379032135,
      "learning_rate": 9.048202614379085e-06,
      "loss": 0.1503,
      "step": 4042
    },
    {
      "epoch": 0.9289981617647058,
      "grad_norm": 1.494225025177002,
      "learning_rate": 9.047691993464053e-06,
      "loss": 0.1595,
      "step": 4043
    },
    {
      "epoch": 0.9292279411764706,
      "grad_norm": 1.8164280652999878,
      "learning_rate": 9.04718137254902e-06,
      "loss": 0.183,
      "step": 4044
    },
    {
      "epoch": 0.9294577205882353,
      "grad_norm": 2.198653221130371,
      "learning_rate": 9.046670751633989e-06,
      "loss": 0.1983,
      "step": 4045
    },
    {
      "epoch": 0.9296875,
      "grad_norm": 1.652942419052124,
      "learning_rate": 9.046160130718955e-06,
      "loss": 0.2032,
      "step": 4046
    },
    {
      "epoch": 0.9299172794117647,
      "grad_norm": 1.6111648082733154,
      "learning_rate": 9.045649509803923e-06,
      "loss": 0.165,
      "step": 4047
    },
    {
      "epoch": 0.9301470588235294,
      "grad_norm": 1.6426070928573608,
      "learning_rate": 9.045138888888889e-06,
      "loss": 0.1445,
      "step": 4048
    },
    {
      "epoch": 0.9303768382352942,
      "grad_norm": 2.0812838077545166,
      "learning_rate": 9.044628267973857e-06,
      "loss": 0.2412,
      "step": 4049
    },
    {
      "epoch": 0.9306066176470589,
      "grad_norm": 1.4901999235153198,
      "learning_rate": 9.044117647058824e-06,
      "loss": 0.1413,
      "step": 4050
    },
    {
      "epoch": 0.9308363970588235,
      "grad_norm": 2.1707992553710938,
      "learning_rate": 9.04360702614379e-06,
      "loss": 0.1849,
      "step": 4051
    },
    {
      "epoch": 0.9310661764705882,
      "grad_norm": 1.6619607210159302,
      "learning_rate": 9.043096405228758e-06,
      "loss": 0.1443,
      "step": 4052
    },
    {
      "epoch": 0.9312959558823529,
      "grad_norm": 1.6017277240753174,
      "learning_rate": 9.042585784313726e-06,
      "loss": 0.1431,
      "step": 4053
    },
    {
      "epoch": 0.9315257352941176,
      "grad_norm": 2.069117784500122,
      "learning_rate": 9.042075163398694e-06,
      "loss": 0.2188,
      "step": 4054
    },
    {
      "epoch": 0.9317555147058824,
      "grad_norm": 1.7489476203918457,
      "learning_rate": 9.04156454248366e-06,
      "loss": 0.2051,
      "step": 4055
    },
    {
      "epoch": 0.9319852941176471,
      "grad_norm": 1.511171579360962,
      "learning_rate": 9.041053921568628e-06,
      "loss": 0.1473,
      "step": 4056
    },
    {
      "epoch": 0.9322150735294118,
      "grad_norm": 1.5830844640731812,
      "learning_rate": 9.040543300653596e-06,
      "loss": 0.1694,
      "step": 4057
    },
    {
      "epoch": 0.9324448529411765,
      "grad_norm": 1.9329235553741455,
      "learning_rate": 9.040032679738562e-06,
      "loss": 0.1794,
      "step": 4058
    },
    {
      "epoch": 0.9326746323529411,
      "grad_norm": 1.4067503213882446,
      "learning_rate": 9.03952205882353e-06,
      "loss": 0.1448,
      "step": 4059
    },
    {
      "epoch": 0.9329044117647058,
      "grad_norm": 2.3030524253845215,
      "learning_rate": 9.039011437908496e-06,
      "loss": 0.2054,
      "step": 4060
    },
    {
      "epoch": 0.9331341911764706,
      "grad_norm": 1.6457844972610474,
      "learning_rate": 9.038500816993466e-06,
      "loss": 0.1768,
      "step": 4061
    },
    {
      "epoch": 0.9333639705882353,
      "grad_norm": 1.9661662578582764,
      "learning_rate": 9.037990196078432e-06,
      "loss": 0.1798,
      "step": 4062
    },
    {
      "epoch": 0.93359375,
      "grad_norm": 1.4745633602142334,
      "learning_rate": 9.0374795751634e-06,
      "loss": 0.1307,
      "step": 4063
    },
    {
      "epoch": 0.9338235294117647,
      "grad_norm": 1.764635682106018,
      "learning_rate": 9.036968954248366e-06,
      "loss": 0.1756,
      "step": 4064
    },
    {
      "epoch": 0.9340533088235294,
      "grad_norm": 2.100222110748291,
      "learning_rate": 9.036458333333334e-06,
      "loss": 0.1744,
      "step": 4065
    },
    {
      "epoch": 0.9342830882352942,
      "grad_norm": 2.223731517791748,
      "learning_rate": 9.035947712418302e-06,
      "loss": 0.2398,
      "step": 4066
    },
    {
      "epoch": 0.9345128676470589,
      "grad_norm": 1.75464928150177,
      "learning_rate": 9.035437091503268e-06,
      "loss": 0.1676,
      "step": 4067
    },
    {
      "epoch": 0.9347426470588235,
      "grad_norm": 1.5459542274475098,
      "learning_rate": 9.034926470588236e-06,
      "loss": 0.1528,
      "step": 4068
    },
    {
      "epoch": 0.9349724264705882,
      "grad_norm": 1.9313973188400269,
      "learning_rate": 9.034415849673204e-06,
      "loss": 0.1882,
      "step": 4069
    },
    {
      "epoch": 0.9352022058823529,
      "grad_norm": 2.093665361404419,
      "learning_rate": 9.033905228758171e-06,
      "loss": 0.1983,
      "step": 4070
    },
    {
      "epoch": 0.9354319852941176,
      "grad_norm": 1.3587408065795898,
      "learning_rate": 9.033394607843138e-06,
      "loss": 0.1869,
      "step": 4071
    },
    {
      "epoch": 0.9356617647058824,
      "grad_norm": 1.9023640155792236,
      "learning_rate": 9.032883986928106e-06,
      "loss": 0.1616,
      "step": 4072
    },
    {
      "epoch": 0.9358915441176471,
      "grad_norm": 2.190140724182129,
      "learning_rate": 9.032373366013073e-06,
      "loss": 0.1789,
      "step": 4073
    },
    {
      "epoch": 0.9361213235294118,
      "grad_norm": 1.93583345413208,
      "learning_rate": 9.03186274509804e-06,
      "loss": 0.2056,
      "step": 4074
    },
    {
      "epoch": 0.9363511029411765,
      "grad_norm": 1.7911500930786133,
      "learning_rate": 9.031352124183007e-06,
      "loss": 0.1971,
      "step": 4075
    },
    {
      "epoch": 0.9365808823529411,
      "grad_norm": 1.3096727132797241,
      "learning_rate": 9.030841503267974e-06,
      "loss": 0.1636,
      "step": 4076
    },
    {
      "epoch": 0.9368106617647058,
      "grad_norm": 1.8933695554733276,
      "learning_rate": 9.030330882352943e-06,
      "loss": 0.1647,
      "step": 4077
    },
    {
      "epoch": 0.9370404411764706,
      "grad_norm": 1.7059552669525146,
      "learning_rate": 9.02982026143791e-06,
      "loss": 0.1519,
      "step": 4078
    },
    {
      "epoch": 0.9372702205882353,
      "grad_norm": 2.021970748901367,
      "learning_rate": 9.029309640522877e-06,
      "loss": 0.157,
      "step": 4079
    },
    {
      "epoch": 0.9375,
      "grad_norm": 1.5828043222427368,
      "learning_rate": 9.028799019607843e-06,
      "loss": 0.1677,
      "step": 4080
    },
    {
      "epoch": 0.9377297794117647,
      "grad_norm": 1.6189241409301758,
      "learning_rate": 9.028288398692811e-06,
      "loss": 0.1574,
      "step": 4081
    },
    {
      "epoch": 0.9379595588235294,
      "grad_norm": 1.4865546226501465,
      "learning_rate": 9.027777777777779e-06,
      "loss": 0.1687,
      "step": 4082
    },
    {
      "epoch": 0.9381893382352942,
      "grad_norm": 2.6332573890686035,
      "learning_rate": 9.027267156862745e-06,
      "loss": 0.2548,
      "step": 4083
    },
    {
      "epoch": 0.9384191176470589,
      "grad_norm": 1.2967185974121094,
      "learning_rate": 9.026756535947713e-06,
      "loss": 0.1368,
      "step": 4084
    },
    {
      "epoch": 0.9386488970588235,
      "grad_norm": 1.8711587190628052,
      "learning_rate": 9.026245915032681e-06,
      "loss": 0.2151,
      "step": 4085
    },
    {
      "epoch": 0.9388786764705882,
      "grad_norm": 2.0371153354644775,
      "learning_rate": 9.025735294117647e-06,
      "loss": 0.1827,
      "step": 4086
    },
    {
      "epoch": 0.9391084558823529,
      "grad_norm": 1.605420470237732,
      "learning_rate": 9.025224673202615e-06,
      "loss": 0.1575,
      "step": 4087
    },
    {
      "epoch": 0.9393382352941176,
      "grad_norm": 1.51217520236969,
      "learning_rate": 9.024714052287583e-06,
      "loss": 0.1577,
      "step": 4088
    },
    {
      "epoch": 0.9395680147058824,
      "grad_norm": 1.4898900985717773,
      "learning_rate": 9.02420343137255e-06,
      "loss": 0.178,
      "step": 4089
    },
    {
      "epoch": 0.9397977941176471,
      "grad_norm": 1.8859658241271973,
      "learning_rate": 9.023692810457517e-06,
      "loss": 0.1574,
      "step": 4090
    },
    {
      "epoch": 0.9400275735294118,
      "grad_norm": 1.5539569854736328,
      "learning_rate": 9.023182189542485e-06,
      "loss": 0.1692,
      "step": 4091
    },
    {
      "epoch": 0.9402573529411765,
      "grad_norm": 1.850653052330017,
      "learning_rate": 9.022671568627451e-06,
      "loss": 0.1855,
      "step": 4092
    },
    {
      "epoch": 0.9404871323529411,
      "grad_norm": 2.0425755977630615,
      "learning_rate": 9.022160947712419e-06,
      "loss": 0.2101,
      "step": 4093
    },
    {
      "epoch": 0.9407169117647058,
      "grad_norm": 1.5457665920257568,
      "learning_rate": 9.021650326797387e-06,
      "loss": 0.1794,
      "step": 4094
    },
    {
      "epoch": 0.9409466911764706,
      "grad_norm": 2.08949875831604,
      "learning_rate": 9.021139705882353e-06,
      "loss": 0.1718,
      "step": 4095
    },
    {
      "epoch": 0.9411764705882353,
      "grad_norm": 1.7849127054214478,
      "learning_rate": 9.02062908496732e-06,
      "loss": 0.1562,
      "step": 4096
    },
    {
      "epoch": 0.94140625,
      "grad_norm": 1.4150339365005493,
      "learning_rate": 9.020118464052289e-06,
      "loss": 0.1344,
      "step": 4097
    },
    {
      "epoch": 0.9416360294117647,
      "grad_norm": 1.48399817943573,
      "learning_rate": 9.019607843137256e-06,
      "loss": 0.1667,
      "step": 4098
    },
    {
      "epoch": 0.9418658088235294,
      "grad_norm": 1.8826197385787964,
      "learning_rate": 9.019097222222223e-06,
      "loss": 0.1384,
      "step": 4099
    },
    {
      "epoch": 0.9420955882352942,
      "grad_norm": 1.6986738443374634,
      "learning_rate": 9.01858660130719e-06,
      "loss": 0.2323,
      "step": 4100
    },
    {
      "epoch": 0.9423253676470589,
      "grad_norm": 1.495446801185608,
      "learning_rate": 9.018075980392158e-06,
      "loss": 0.1756,
      "step": 4101
    },
    {
      "epoch": 0.9425551470588235,
      "grad_norm": 1.5535635948181152,
      "learning_rate": 9.017565359477124e-06,
      "loss": 0.1496,
      "step": 4102
    },
    {
      "epoch": 0.9427849264705882,
      "grad_norm": 1.6615592241287231,
      "learning_rate": 9.017054738562092e-06,
      "loss": 0.1698,
      "step": 4103
    },
    {
      "epoch": 0.9430147058823529,
      "grad_norm": 1.8941471576690674,
      "learning_rate": 9.016544117647058e-06,
      "loss": 0.1478,
      "step": 4104
    },
    {
      "epoch": 0.9432444852941176,
      "grad_norm": 1.3431830406188965,
      "learning_rate": 9.016033496732028e-06,
      "loss": 0.1496,
      "step": 4105
    },
    {
      "epoch": 0.9434742647058824,
      "grad_norm": 1.4968339204788208,
      "learning_rate": 9.015522875816994e-06,
      "loss": 0.1795,
      "step": 4106
    },
    {
      "epoch": 0.9437040441176471,
      "grad_norm": 1.20907723903656,
      "learning_rate": 9.015012254901962e-06,
      "loss": 0.1279,
      "step": 4107
    },
    {
      "epoch": 0.9439338235294118,
      "grad_norm": 1.940769910812378,
      "learning_rate": 9.014501633986928e-06,
      "loss": 0.2347,
      "step": 4108
    },
    {
      "epoch": 0.9441636029411765,
      "grad_norm": 1.4602556228637695,
      "learning_rate": 9.013991013071896e-06,
      "loss": 0.1401,
      "step": 4109
    },
    {
      "epoch": 0.9443933823529411,
      "grad_norm": 1.7735790014266968,
      "learning_rate": 9.013480392156864e-06,
      "loss": 0.158,
      "step": 4110
    },
    {
      "epoch": 0.9446231617647058,
      "grad_norm": 1.9015134572982788,
      "learning_rate": 9.01296977124183e-06,
      "loss": 0.1744,
      "step": 4111
    },
    {
      "epoch": 0.9448529411764706,
      "grad_norm": 1.9062851667404175,
      "learning_rate": 9.012459150326798e-06,
      "loss": 0.1287,
      "step": 4112
    },
    {
      "epoch": 0.9450827205882353,
      "grad_norm": 1.6776217222213745,
      "learning_rate": 9.011948529411766e-06,
      "loss": 0.1678,
      "step": 4113
    },
    {
      "epoch": 0.9453125,
      "grad_norm": 1.5345301628112793,
      "learning_rate": 9.011437908496734e-06,
      "loss": 0.1413,
      "step": 4114
    },
    {
      "epoch": 0.9455422794117647,
      "grad_norm": 1.6303811073303223,
      "learning_rate": 9.0109272875817e-06,
      "loss": 0.1624,
      "step": 4115
    },
    {
      "epoch": 0.9457720588235294,
      "grad_norm": 1.7459917068481445,
      "learning_rate": 9.010416666666668e-06,
      "loss": 0.1791,
      "step": 4116
    },
    {
      "epoch": 0.9460018382352942,
      "grad_norm": 1.6465061902999878,
      "learning_rate": 9.009906045751636e-06,
      "loss": 0.1752,
      "step": 4117
    },
    {
      "epoch": 0.9462316176470589,
      "grad_norm": 1.4230973720550537,
      "learning_rate": 9.009395424836602e-06,
      "loss": 0.0854,
      "step": 4118
    },
    {
      "epoch": 0.9464613970588235,
      "grad_norm": 1.7957862615585327,
      "learning_rate": 9.00888480392157e-06,
      "loss": 0.197,
      "step": 4119
    },
    {
      "epoch": 0.9466911764705882,
      "grad_norm": 1.5190962553024292,
      "learning_rate": 9.008374183006536e-06,
      "loss": 0.1534,
      "step": 4120
    },
    {
      "epoch": 0.9469209558823529,
      "grad_norm": 1.7519888877868652,
      "learning_rate": 9.007863562091504e-06,
      "loss": 0.2048,
      "step": 4121
    },
    {
      "epoch": 0.9471507352941176,
      "grad_norm": 1.6169610023498535,
      "learning_rate": 9.007352941176471e-06,
      "loss": 0.1331,
      "step": 4122
    },
    {
      "epoch": 0.9473805147058824,
      "grad_norm": 1.7720873355865479,
      "learning_rate": 9.00684232026144e-06,
      "loss": 0.1858,
      "step": 4123
    },
    {
      "epoch": 0.9476102941176471,
      "grad_norm": 1.755690574645996,
      "learning_rate": 9.006331699346406e-06,
      "loss": 0.1531,
      "step": 4124
    },
    {
      "epoch": 0.9478400735294118,
      "grad_norm": 1.5395135879516602,
      "learning_rate": 9.005821078431373e-06,
      "loss": 0.1621,
      "step": 4125
    },
    {
      "epoch": 0.9480698529411765,
      "grad_norm": 1.4596024751663208,
      "learning_rate": 9.005310457516341e-06,
      "loss": 0.1305,
      "step": 4126
    },
    {
      "epoch": 0.9482996323529411,
      "grad_norm": 2.0421082973480225,
      "learning_rate": 9.004799836601307e-06,
      "loss": 0.1894,
      "step": 4127
    },
    {
      "epoch": 0.9485294117647058,
      "grad_norm": 1.784408450126648,
      "learning_rate": 9.004289215686275e-06,
      "loss": 0.1957,
      "step": 4128
    },
    {
      "epoch": 0.9487591911764706,
      "grad_norm": 1.9783189296722412,
      "learning_rate": 9.003778594771243e-06,
      "loss": 0.1372,
      "step": 4129
    },
    {
      "epoch": 0.9489889705882353,
      "grad_norm": 1.7724508047103882,
      "learning_rate": 9.00326797385621e-06,
      "loss": 0.1524,
      "step": 4130
    },
    {
      "epoch": 0.94921875,
      "grad_norm": 1.8976846933364868,
      "learning_rate": 9.002757352941177e-06,
      "loss": 0.1817,
      "step": 4131
    },
    {
      "epoch": 0.9494485294117647,
      "grad_norm": 1.5318485498428345,
      "learning_rate": 9.002246732026145e-06,
      "loss": 0.1723,
      "step": 4132
    },
    {
      "epoch": 0.9496783088235294,
      "grad_norm": 2.336026191711426,
      "learning_rate": 9.001736111111113e-06,
      "loss": 0.1753,
      "step": 4133
    },
    {
      "epoch": 0.9499080882352942,
      "grad_norm": 1.4222326278686523,
      "learning_rate": 9.001225490196079e-06,
      "loss": 0.1421,
      "step": 4134
    },
    {
      "epoch": 0.9501378676470589,
      "grad_norm": 1.4829049110412598,
      "learning_rate": 9.000714869281047e-06,
      "loss": 0.1869,
      "step": 4135
    },
    {
      "epoch": 0.9503676470588235,
      "grad_norm": 1.6952801942825317,
      "learning_rate": 9.000204248366013e-06,
      "loss": 0.1811,
      "step": 4136
    },
    {
      "epoch": 0.9505974264705882,
      "grad_norm": 1.4062831401824951,
      "learning_rate": 8.999693627450981e-06,
      "loss": 0.1435,
      "step": 4137
    },
    {
      "epoch": 0.9508272058823529,
      "grad_norm": 2.5858819484710693,
      "learning_rate": 8.999183006535949e-06,
      "loss": 0.1902,
      "step": 4138
    },
    {
      "epoch": 0.9510569852941176,
      "grad_norm": 1.8407536745071411,
      "learning_rate": 8.998672385620915e-06,
      "loss": 0.1623,
      "step": 4139
    },
    {
      "epoch": 0.9512867647058824,
      "grad_norm": 1.9421930313110352,
      "learning_rate": 8.998161764705883e-06,
      "loss": 0.1878,
      "step": 4140
    },
    {
      "epoch": 0.9515165441176471,
      "grad_norm": 1.5749791860580444,
      "learning_rate": 8.99765114379085e-06,
      "loss": 0.1763,
      "step": 4141
    },
    {
      "epoch": 0.9517463235294118,
      "grad_norm": 1.8307524919509888,
      "learning_rate": 8.997140522875819e-06,
      "loss": 0.1692,
      "step": 4142
    },
    {
      "epoch": 0.9519761029411765,
      "grad_norm": 2.1348142623901367,
      "learning_rate": 8.996629901960785e-06,
      "loss": 0.1608,
      "step": 4143
    },
    {
      "epoch": 0.9522058823529411,
      "grad_norm": 1.5291086435317993,
      "learning_rate": 8.996119281045753e-06,
      "loss": 0.1572,
      "step": 4144
    },
    {
      "epoch": 0.9524356617647058,
      "grad_norm": 1.5646462440490723,
      "learning_rate": 8.99560866013072e-06,
      "loss": 0.211,
      "step": 4145
    },
    {
      "epoch": 0.9526654411764706,
      "grad_norm": 2.0508153438568115,
      "learning_rate": 8.995098039215687e-06,
      "loss": 0.1557,
      "step": 4146
    },
    {
      "epoch": 0.9528952205882353,
      "grad_norm": 1.9374791383743286,
      "learning_rate": 8.994587418300654e-06,
      "loss": 0.1207,
      "step": 4147
    },
    {
      "epoch": 0.953125,
      "grad_norm": 1.5577449798583984,
      "learning_rate": 8.99407679738562e-06,
      "loss": 0.1514,
      "step": 4148
    },
    {
      "epoch": 0.9533547794117647,
      "grad_norm": 2.0760498046875,
      "learning_rate": 8.99356617647059e-06,
      "loss": 0.1465,
      "step": 4149
    },
    {
      "epoch": 0.9535845588235294,
      "grad_norm": 1.5797808170318604,
      "learning_rate": 8.993055555555556e-06,
      "loss": 0.1426,
      "step": 4150
    },
    {
      "epoch": 0.9538143382352942,
      "grad_norm": 1.3788634538650513,
      "learning_rate": 8.992544934640524e-06,
      "loss": 0.1299,
      "step": 4151
    },
    {
      "epoch": 0.9540441176470589,
      "grad_norm": 1.581510305404663,
      "learning_rate": 8.99203431372549e-06,
      "loss": 0.1961,
      "step": 4152
    },
    {
      "epoch": 0.9542738970588235,
      "grad_norm": 1.5691708326339722,
      "learning_rate": 8.991523692810458e-06,
      "loss": 0.1285,
      "step": 4153
    },
    {
      "epoch": 0.9545036764705882,
      "grad_norm": 2.067409038543701,
      "learning_rate": 8.991013071895426e-06,
      "loss": 0.1921,
      "step": 4154
    },
    {
      "epoch": 0.9547334558823529,
      "grad_norm": 1.9363166093826294,
      "learning_rate": 8.990502450980392e-06,
      "loss": 0.2392,
      "step": 4155
    },
    {
      "epoch": 0.9549632352941176,
      "grad_norm": 1.7921278476715088,
      "learning_rate": 8.98999183006536e-06,
      "loss": 0.2376,
      "step": 4156
    },
    {
      "epoch": 0.9551930147058824,
      "grad_norm": 1.7542718648910522,
      "learning_rate": 8.989481209150328e-06,
      "loss": 0.1931,
      "step": 4157
    },
    {
      "epoch": 0.9554227941176471,
      "grad_norm": 1.5421136617660522,
      "learning_rate": 8.988970588235296e-06,
      "loss": 0.1396,
      "step": 4158
    },
    {
      "epoch": 0.9556525735294118,
      "grad_norm": 1.8466293811798096,
      "learning_rate": 8.988459967320262e-06,
      "loss": 0.1375,
      "step": 4159
    },
    {
      "epoch": 0.9558823529411765,
      "grad_norm": 1.2270584106445312,
      "learning_rate": 8.98794934640523e-06,
      "loss": 0.151,
      "step": 4160
    },
    {
      "epoch": 0.9561121323529411,
      "grad_norm": 1.589857816696167,
      "learning_rate": 8.987438725490198e-06,
      "loss": 0.1373,
      "step": 4161
    },
    {
      "epoch": 0.9563419117647058,
      "grad_norm": 1.7474756240844727,
      "learning_rate": 8.986928104575164e-06,
      "loss": 0.1686,
      "step": 4162
    },
    {
      "epoch": 0.9565716911764706,
      "grad_norm": 1.5788064002990723,
      "learning_rate": 8.986417483660132e-06,
      "loss": 0.195,
      "step": 4163
    },
    {
      "epoch": 0.9568014705882353,
      "grad_norm": 1.5893489122390747,
      "learning_rate": 8.985906862745098e-06,
      "loss": 0.1186,
      "step": 4164
    },
    {
      "epoch": 0.95703125,
      "grad_norm": 1.7260401248931885,
      "learning_rate": 8.985396241830066e-06,
      "loss": 0.1975,
      "step": 4165
    },
    {
      "epoch": 0.9572610294117647,
      "grad_norm": 1.8355616331100464,
      "learning_rate": 8.984885620915034e-06,
      "loss": 0.1964,
      "step": 4166
    },
    {
      "epoch": 0.9574908088235294,
      "grad_norm": 1.52665376663208,
      "learning_rate": 8.984375000000002e-06,
      "loss": 0.1303,
      "step": 4167
    },
    {
      "epoch": 0.9577205882352942,
      "grad_norm": 1.7474088668823242,
      "learning_rate": 8.983864379084968e-06,
      "loss": 0.1974,
      "step": 4168
    },
    {
      "epoch": 0.9579503676470589,
      "grad_norm": 1.453627586364746,
      "learning_rate": 8.983353758169936e-06,
      "loss": 0.1488,
      "step": 4169
    },
    {
      "epoch": 0.9581801470588235,
      "grad_norm": 1.8085874319076538,
      "learning_rate": 8.982843137254903e-06,
      "loss": 0.1888,
      "step": 4170
    },
    {
      "epoch": 0.9584099264705882,
      "grad_norm": 1.6400938034057617,
      "learning_rate": 8.98233251633987e-06,
      "loss": 0.1644,
      "step": 4171
    },
    {
      "epoch": 0.9586397058823529,
      "grad_norm": 1.4621676206588745,
      "learning_rate": 8.981821895424837e-06,
      "loss": 0.1283,
      "step": 4172
    },
    {
      "epoch": 0.9588694852941176,
      "grad_norm": 1.9803574085235596,
      "learning_rate": 8.981311274509804e-06,
      "loss": 0.2032,
      "step": 4173
    },
    {
      "epoch": 0.9590992647058824,
      "grad_norm": 1.7773364782333374,
      "learning_rate": 8.980800653594771e-06,
      "loss": 0.1536,
      "step": 4174
    },
    {
      "epoch": 0.9593290441176471,
      "grad_norm": 1.9225940704345703,
      "learning_rate": 8.98029003267974e-06,
      "loss": 0.158,
      "step": 4175
    },
    {
      "epoch": 0.9595588235294118,
      "grad_norm": 1.5163906812667847,
      "learning_rate": 8.979779411764706e-06,
      "loss": 0.1314,
      "step": 4176
    },
    {
      "epoch": 0.9597886029411765,
      "grad_norm": 1.8547531366348267,
      "learning_rate": 8.979268790849673e-06,
      "loss": 0.1959,
      "step": 4177
    },
    {
      "epoch": 0.9600183823529411,
      "grad_norm": 2.554352045059204,
      "learning_rate": 8.978758169934641e-06,
      "loss": 0.1875,
      "step": 4178
    },
    {
      "epoch": 0.9602481617647058,
      "grad_norm": 2.2382161617279053,
      "learning_rate": 8.978247549019609e-06,
      "loss": 0.1686,
      "step": 4179
    },
    {
      "epoch": 0.9604779411764706,
      "grad_norm": 1.4505929946899414,
      "learning_rate": 8.977736928104575e-06,
      "loss": 0.1477,
      "step": 4180
    },
    {
      "epoch": 0.9607077205882353,
      "grad_norm": 2.0456349849700928,
      "learning_rate": 8.977226307189543e-06,
      "loss": 0.1676,
      "step": 4181
    },
    {
      "epoch": 0.9609375,
      "grad_norm": 1.6227470636367798,
      "learning_rate": 8.976715686274511e-06,
      "loss": 0.1927,
      "step": 4182
    },
    {
      "epoch": 0.9611672794117647,
      "grad_norm": 1.747166633605957,
      "learning_rate": 8.976205065359477e-06,
      "loss": 0.137,
      "step": 4183
    },
    {
      "epoch": 0.9613970588235294,
      "grad_norm": 1.4638135433197021,
      "learning_rate": 8.975694444444445e-06,
      "loss": 0.1497,
      "step": 4184
    },
    {
      "epoch": 0.9616268382352942,
      "grad_norm": 1.431433916091919,
      "learning_rate": 8.975183823529411e-06,
      "loss": 0.122,
      "step": 4185
    },
    {
      "epoch": 0.9618566176470589,
      "grad_norm": 1.3140254020690918,
      "learning_rate": 8.97467320261438e-06,
      "loss": 0.1602,
      "step": 4186
    },
    {
      "epoch": 0.9620863970588235,
      "grad_norm": 1.690291404724121,
      "learning_rate": 8.974162581699347e-06,
      "loss": 0.1563,
      "step": 4187
    },
    {
      "epoch": 0.9623161764705882,
      "grad_norm": 1.6134774684906006,
      "learning_rate": 8.973651960784315e-06,
      "loss": 0.1764,
      "step": 4188
    },
    {
      "epoch": 0.9625459558823529,
      "grad_norm": 1.438072919845581,
      "learning_rate": 8.973141339869281e-06,
      "loss": 0.1793,
      "step": 4189
    },
    {
      "epoch": 0.9627757352941176,
      "grad_norm": 1.8179584741592407,
      "learning_rate": 8.972630718954249e-06,
      "loss": 0.19,
      "step": 4190
    },
    {
      "epoch": 0.9630055147058824,
      "grad_norm": 1.6694279909133911,
      "learning_rate": 8.972120098039217e-06,
      "loss": 0.1512,
      "step": 4191
    },
    {
      "epoch": 0.9632352941176471,
      "grad_norm": 2.2007882595062256,
      "learning_rate": 8.971609477124183e-06,
      "loss": 0.1584,
      "step": 4192
    },
    {
      "epoch": 0.9634650735294118,
      "grad_norm": 1.6269779205322266,
      "learning_rate": 8.97109885620915e-06,
      "loss": 0.1375,
      "step": 4193
    },
    {
      "epoch": 0.9636948529411765,
      "grad_norm": 1.58406400680542,
      "learning_rate": 8.970588235294119e-06,
      "loss": 0.157,
      "step": 4194
    },
    {
      "epoch": 0.9639246323529411,
      "grad_norm": 1.5093967914581299,
      "learning_rate": 8.970077614379086e-06,
      "loss": 0.1376,
      "step": 4195
    },
    {
      "epoch": 0.9641544117647058,
      "grad_norm": 1.6481578350067139,
      "learning_rate": 8.969566993464053e-06,
      "loss": 0.1383,
      "step": 4196
    },
    {
      "epoch": 0.9643841911764706,
      "grad_norm": 1.8872960805892944,
      "learning_rate": 8.96905637254902e-06,
      "loss": 0.1544,
      "step": 4197
    },
    {
      "epoch": 0.9646139705882353,
      "grad_norm": 1.6323939561843872,
      "learning_rate": 8.968545751633988e-06,
      "loss": 0.1794,
      "step": 4198
    },
    {
      "epoch": 0.96484375,
      "grad_norm": 1.5083980560302734,
      "learning_rate": 8.968035130718954e-06,
      "loss": 0.1342,
      "step": 4199
    },
    {
      "epoch": 0.9650735294117647,
      "grad_norm": 1.9807806015014648,
      "learning_rate": 8.967524509803922e-06,
      "loss": 0.1769,
      "step": 4200
    },
    {
      "epoch": 0.9653033088235294,
      "grad_norm": 1.2550960779190063,
      "learning_rate": 8.967013888888889e-06,
      "loss": 0.1162,
      "step": 4201
    },
    {
      "epoch": 0.9655330882352942,
      "grad_norm": 1.4807233810424805,
      "learning_rate": 8.966503267973858e-06,
      "loss": 0.1428,
      "step": 4202
    },
    {
      "epoch": 0.9657628676470589,
      "grad_norm": 1.6875916719436646,
      "learning_rate": 8.965992647058824e-06,
      "loss": 0.214,
      "step": 4203
    },
    {
      "epoch": 0.9659926470588235,
      "grad_norm": 1.6050047874450684,
      "learning_rate": 8.965482026143792e-06,
      "loss": 0.1367,
      "step": 4204
    },
    {
      "epoch": 0.9662224264705882,
      "grad_norm": 1.4139734506607056,
      "learning_rate": 8.964971405228758e-06,
      "loss": 0.1354,
      "step": 4205
    },
    {
      "epoch": 0.9664522058823529,
      "grad_norm": 1.4755300283432007,
      "learning_rate": 8.964460784313726e-06,
      "loss": 0.127,
      "step": 4206
    },
    {
      "epoch": 0.9666819852941176,
      "grad_norm": 1.8941799402236938,
      "learning_rate": 8.963950163398694e-06,
      "loss": 0.1876,
      "step": 4207
    },
    {
      "epoch": 0.9669117647058824,
      "grad_norm": 1.7742019891738892,
      "learning_rate": 8.96343954248366e-06,
      "loss": 0.1572,
      "step": 4208
    },
    {
      "epoch": 0.9671415441176471,
      "grad_norm": 2.1227781772613525,
      "learning_rate": 8.962928921568628e-06,
      "loss": 0.1913,
      "step": 4209
    },
    {
      "epoch": 0.9673713235294118,
      "grad_norm": 2.3909213542938232,
      "learning_rate": 8.962418300653596e-06,
      "loss": 0.1899,
      "step": 4210
    },
    {
      "epoch": 0.9676011029411765,
      "grad_norm": 2.320753335952759,
      "learning_rate": 8.961907679738564e-06,
      "loss": 0.228,
      "step": 4211
    },
    {
      "epoch": 0.9678308823529411,
      "grad_norm": 1.7384628057479858,
      "learning_rate": 8.96139705882353e-06,
      "loss": 0.1649,
      "step": 4212
    },
    {
      "epoch": 0.9680606617647058,
      "grad_norm": 1.705897331237793,
      "learning_rate": 8.960886437908498e-06,
      "loss": 0.165,
      "step": 4213
    },
    {
      "epoch": 0.9682904411764706,
      "grad_norm": 1.645235300064087,
      "learning_rate": 8.960375816993466e-06,
      "loss": 0.1464,
      "step": 4214
    },
    {
      "epoch": 0.9685202205882353,
      "grad_norm": 1.5186471939086914,
      "learning_rate": 8.959865196078432e-06,
      "loss": 0.176,
      "step": 4215
    },
    {
      "epoch": 0.96875,
      "grad_norm": 2.315338373184204,
      "learning_rate": 8.9593545751634e-06,
      "loss": 0.2024,
      "step": 4216
    },
    {
      "epoch": 0.9689797794117647,
      "grad_norm": 1.8125027418136597,
      "learning_rate": 8.958843954248366e-06,
      "loss": 0.1892,
      "step": 4217
    },
    {
      "epoch": 0.9692095588235294,
      "grad_norm": 1.93960702419281,
      "learning_rate": 8.958333333333334e-06,
      "loss": 0.1967,
      "step": 4218
    },
    {
      "epoch": 0.9694393382352942,
      "grad_norm": 1.852388858795166,
      "learning_rate": 8.957822712418302e-06,
      "loss": 0.1743,
      "step": 4219
    },
    {
      "epoch": 0.9696691176470589,
      "grad_norm": 2.318784713745117,
      "learning_rate": 8.957312091503268e-06,
      "loss": 0.2328,
      "step": 4220
    },
    {
      "epoch": 0.9698988970588235,
      "grad_norm": 1.7032705545425415,
      "learning_rate": 8.956801470588236e-06,
      "loss": 0.1499,
      "step": 4221
    },
    {
      "epoch": 0.9701286764705882,
      "grad_norm": 1.945051908493042,
      "learning_rate": 8.956290849673203e-06,
      "loss": 0.1645,
      "step": 4222
    },
    {
      "epoch": 0.9703584558823529,
      "grad_norm": 1.668897271156311,
      "learning_rate": 8.955780228758171e-06,
      "loss": 0.1515,
      "step": 4223
    },
    {
      "epoch": 0.9705882352941176,
      "grad_norm": 1.635752558708191,
      "learning_rate": 8.955269607843137e-06,
      "loss": 0.1522,
      "step": 4224
    },
    {
      "epoch": 0.9708180147058824,
      "grad_norm": 1.3281738758087158,
      "learning_rate": 8.954758986928105e-06,
      "loss": 0.1557,
      "step": 4225
    },
    {
      "epoch": 0.9710477941176471,
      "grad_norm": 1.306512713432312,
      "learning_rate": 8.954248366013073e-06,
      "loss": 0.1327,
      "step": 4226
    },
    {
      "epoch": 0.9712775735294118,
      "grad_norm": 1.4295216798782349,
      "learning_rate": 8.95373774509804e-06,
      "loss": 0.134,
      "step": 4227
    },
    {
      "epoch": 0.9715073529411765,
      "grad_norm": 1.6795614957809448,
      "learning_rate": 8.953227124183007e-06,
      "loss": 0.1791,
      "step": 4228
    },
    {
      "epoch": 0.9717371323529411,
      "grad_norm": 1.9557175636291504,
      "learning_rate": 8.952716503267973e-06,
      "loss": 0.1318,
      "step": 4229
    },
    {
      "epoch": 0.9719669117647058,
      "grad_norm": 1.895100474357605,
      "learning_rate": 8.952205882352943e-06,
      "loss": 0.1415,
      "step": 4230
    },
    {
      "epoch": 0.9721966911764706,
      "grad_norm": 1.9154093265533447,
      "learning_rate": 8.951695261437909e-06,
      "loss": 0.1648,
      "step": 4231
    },
    {
      "epoch": 0.9724264705882353,
      "grad_norm": 2.542966604232788,
      "learning_rate": 8.951184640522877e-06,
      "loss": 0.1915,
      "step": 4232
    },
    {
      "epoch": 0.97265625,
      "grad_norm": 2.104172468185425,
      "learning_rate": 8.950674019607843e-06,
      "loss": 0.1776,
      "step": 4233
    },
    {
      "epoch": 0.9728860294117647,
      "grad_norm": 2.0007121562957764,
      "learning_rate": 8.950163398692811e-06,
      "loss": 0.1739,
      "step": 4234
    },
    {
      "epoch": 0.9731158088235294,
      "grad_norm": 1.8665064573287964,
      "learning_rate": 8.949652777777779e-06,
      "loss": 0.1747,
      "step": 4235
    },
    {
      "epoch": 0.9733455882352942,
      "grad_norm": 1.374557375907898,
      "learning_rate": 8.949142156862745e-06,
      "loss": 0.1274,
      "step": 4236
    },
    {
      "epoch": 0.9735753676470589,
      "grad_norm": 1.6057738065719604,
      "learning_rate": 8.948631535947713e-06,
      "loss": 0.1019,
      "step": 4237
    },
    {
      "epoch": 0.9738051470588235,
      "grad_norm": 1.8417518138885498,
      "learning_rate": 8.94812091503268e-06,
      "loss": 0.227,
      "step": 4238
    },
    {
      "epoch": 0.9740349264705882,
      "grad_norm": 2.2444849014282227,
      "learning_rate": 8.947610294117649e-06,
      "loss": 0.1549,
      "step": 4239
    },
    {
      "epoch": 0.9742647058823529,
      "grad_norm": 1.814292073249817,
      "learning_rate": 8.947099673202615e-06,
      "loss": 0.1622,
      "step": 4240
    },
    {
      "epoch": 0.9744944852941176,
      "grad_norm": 1.8580635786056519,
      "learning_rate": 8.946589052287583e-06,
      "loss": 0.2061,
      "step": 4241
    },
    {
      "epoch": 0.9747242647058824,
      "grad_norm": 1.5798367261886597,
      "learning_rate": 8.94607843137255e-06,
      "loss": 0.1749,
      "step": 4242
    },
    {
      "epoch": 0.9749540441176471,
      "grad_norm": 1.7369451522827148,
      "learning_rate": 8.945567810457517e-06,
      "loss": 0.1804,
      "step": 4243
    },
    {
      "epoch": 0.9751838235294118,
      "grad_norm": 1.9279457330703735,
      "learning_rate": 8.945057189542485e-06,
      "loss": 0.144,
      "step": 4244
    },
    {
      "epoch": 0.9754136029411765,
      "grad_norm": 2.3493165969848633,
      "learning_rate": 8.94454656862745e-06,
      "loss": 0.2357,
      "step": 4245
    },
    {
      "epoch": 0.9756433823529411,
      "grad_norm": 1.5230425596237183,
      "learning_rate": 8.94403594771242e-06,
      "loss": 0.1664,
      "step": 4246
    },
    {
      "epoch": 0.9758731617647058,
      "grad_norm": 1.5879356861114502,
      "learning_rate": 8.943525326797386e-06,
      "loss": 0.1407,
      "step": 4247
    },
    {
      "epoch": 0.9761029411764706,
      "grad_norm": 1.2928578853607178,
      "learning_rate": 8.943014705882354e-06,
      "loss": 0.1439,
      "step": 4248
    },
    {
      "epoch": 0.9763327205882353,
      "grad_norm": 1.516679048538208,
      "learning_rate": 8.94250408496732e-06,
      "loss": 0.1724,
      "step": 4249
    },
    {
      "epoch": 0.9765625,
      "grad_norm": 2.231621503829956,
      "learning_rate": 8.941993464052288e-06,
      "loss": 0.1929,
      "step": 4250
    },
    {
      "epoch": 0.9767922794117647,
      "grad_norm": 1.304979920387268,
      "learning_rate": 8.941482843137256e-06,
      "loss": 0.18,
      "step": 4251
    },
    {
      "epoch": 0.9770220588235294,
      "grad_norm": 1.4999006986618042,
      "learning_rate": 8.940972222222222e-06,
      "loss": 0.16,
      "step": 4252
    },
    {
      "epoch": 0.9772518382352942,
      "grad_norm": 1.6159104108810425,
      "learning_rate": 8.94046160130719e-06,
      "loss": 0.124,
      "step": 4253
    },
    {
      "epoch": 0.9774816176470589,
      "grad_norm": 1.8313404321670532,
      "learning_rate": 8.939950980392158e-06,
      "loss": 0.1588,
      "step": 4254
    },
    {
      "epoch": 0.9777113970588235,
      "grad_norm": 1.4438610076904297,
      "learning_rate": 8.939440359477126e-06,
      "loss": 0.1861,
      "step": 4255
    },
    {
      "epoch": 0.9779411764705882,
      "grad_norm": 1.6623202562332153,
      "learning_rate": 8.938929738562092e-06,
      "loss": 0.1575,
      "step": 4256
    },
    {
      "epoch": 0.9781709558823529,
      "grad_norm": 1.7623684406280518,
      "learning_rate": 8.93841911764706e-06,
      "loss": 0.1847,
      "step": 4257
    },
    {
      "epoch": 0.9784007352941176,
      "grad_norm": 1.418855905532837,
      "learning_rate": 8.937908496732028e-06,
      "loss": 0.1192,
      "step": 4258
    },
    {
      "epoch": 0.9786305147058824,
      "grad_norm": 1.7157644033432007,
      "learning_rate": 8.937397875816994e-06,
      "loss": 0.202,
      "step": 4259
    },
    {
      "epoch": 0.9788602941176471,
      "grad_norm": 1.6843241453170776,
      "learning_rate": 8.936887254901962e-06,
      "loss": 0.1855,
      "step": 4260
    },
    {
      "epoch": 0.9790900735294118,
      "grad_norm": 1.3499268293380737,
      "learning_rate": 8.936376633986928e-06,
      "loss": 0.1605,
      "step": 4261
    },
    {
      "epoch": 0.9793198529411765,
      "grad_norm": 1.6443837881088257,
      "learning_rate": 8.935866013071896e-06,
      "loss": 0.161,
      "step": 4262
    },
    {
      "epoch": 0.9795496323529411,
      "grad_norm": 1.8824175596237183,
      "learning_rate": 8.935355392156864e-06,
      "loss": 0.1358,
      "step": 4263
    },
    {
      "epoch": 0.9797794117647058,
      "grad_norm": 1.696366786956787,
      "learning_rate": 8.93484477124183e-06,
      "loss": 0.1398,
      "step": 4264
    },
    {
      "epoch": 0.9800091911764706,
      "grad_norm": 1.6972932815551758,
      "learning_rate": 8.934334150326798e-06,
      "loss": 0.136,
      "step": 4265
    },
    {
      "epoch": 0.9802389705882353,
      "grad_norm": 1.8723098039627075,
      "learning_rate": 8.933823529411766e-06,
      "loss": 0.1762,
      "step": 4266
    },
    {
      "epoch": 0.98046875,
      "grad_norm": 1.9191468954086304,
      "learning_rate": 8.933312908496733e-06,
      "loss": 0.1178,
      "step": 4267
    },
    {
      "epoch": 0.9806985294117647,
      "grad_norm": 2.2051773071289062,
      "learning_rate": 8.9328022875817e-06,
      "loss": 0.1649,
      "step": 4268
    },
    {
      "epoch": 0.9809283088235294,
      "grad_norm": 1.9004607200622559,
      "learning_rate": 8.932291666666668e-06,
      "loss": 0.1713,
      "step": 4269
    },
    {
      "epoch": 0.9811580882352942,
      "grad_norm": 1.3661075830459595,
      "learning_rate": 8.931781045751635e-06,
      "loss": 0.1532,
      "step": 4270
    },
    {
      "epoch": 0.9813878676470589,
      "grad_norm": 1.790079116821289,
      "learning_rate": 8.931270424836602e-06,
      "loss": 0.1755,
      "step": 4271
    },
    {
      "epoch": 0.9816176470588235,
      "grad_norm": 1.613946795463562,
      "learning_rate": 8.93075980392157e-06,
      "loss": 0.1407,
      "step": 4272
    },
    {
      "epoch": 0.9818474264705882,
      "grad_norm": 1.2436531782150269,
      "learning_rate": 8.930249183006536e-06,
      "loss": 0.1294,
      "step": 4273
    },
    {
      "epoch": 0.9820772058823529,
      "grad_norm": 1.738389015197754,
      "learning_rate": 8.929738562091505e-06,
      "loss": 0.1854,
      "step": 4274
    },
    {
      "epoch": 0.9823069852941176,
      "grad_norm": 1.4732658863067627,
      "learning_rate": 8.929227941176471e-06,
      "loss": 0.1357,
      "step": 4275
    },
    {
      "epoch": 0.9825367647058824,
      "grad_norm": 2.1249122619628906,
      "learning_rate": 8.928717320261439e-06,
      "loss": 0.2087,
      "step": 4276
    },
    {
      "epoch": 0.9827665441176471,
      "grad_norm": 2.378173828125,
      "learning_rate": 8.928206699346405e-06,
      "loss": 0.1369,
      "step": 4277
    },
    {
      "epoch": 0.9829963235294118,
      "grad_norm": 1.4025228023529053,
      "learning_rate": 8.927696078431373e-06,
      "loss": 0.1339,
      "step": 4278
    },
    {
      "epoch": 0.9832261029411765,
      "grad_norm": 1.606704592704773,
      "learning_rate": 8.927185457516341e-06,
      "loss": 0.1725,
      "step": 4279
    },
    {
      "epoch": 0.9834558823529411,
      "grad_norm": 1.5393034219741821,
      "learning_rate": 8.926674836601307e-06,
      "loss": 0.1383,
      "step": 4280
    },
    {
      "epoch": 0.9836856617647058,
      "grad_norm": 1.689975380897522,
      "learning_rate": 8.926164215686275e-06,
      "loss": 0.1327,
      "step": 4281
    },
    {
      "epoch": 0.9839154411764706,
      "grad_norm": 1.9078428745269775,
      "learning_rate": 8.925653594771243e-06,
      "loss": 0.175,
      "step": 4282
    },
    {
      "epoch": 0.9841452205882353,
      "grad_norm": 1.804304838180542,
      "learning_rate": 8.92514297385621e-06,
      "loss": 0.1307,
      "step": 4283
    },
    {
      "epoch": 0.984375,
      "grad_norm": 1.4722490310668945,
      "learning_rate": 8.924632352941177e-06,
      "loss": 0.1416,
      "step": 4284
    },
    {
      "epoch": 0.9846047794117647,
      "grad_norm": 1.7555104494094849,
      "learning_rate": 8.924121732026145e-06,
      "loss": 0.1569,
      "step": 4285
    },
    {
      "epoch": 0.9848345588235294,
      "grad_norm": 2.4330356121063232,
      "learning_rate": 8.923611111111113e-06,
      "loss": 0.1664,
      "step": 4286
    },
    {
      "epoch": 0.9850643382352942,
      "grad_norm": 1.5268446207046509,
      "learning_rate": 8.923100490196079e-06,
      "loss": 0.1471,
      "step": 4287
    },
    {
      "epoch": 0.9852941176470589,
      "grad_norm": 1.324812889099121,
      "learning_rate": 8.922589869281047e-06,
      "loss": 0.1117,
      "step": 4288
    },
    {
      "epoch": 0.9855238970588235,
      "grad_norm": 1.5644938945770264,
      "learning_rate": 8.922079248366013e-06,
      "loss": 0.1583,
      "step": 4289
    },
    {
      "epoch": 0.9857536764705882,
      "grad_norm": 1.4583313465118408,
      "learning_rate": 8.921568627450982e-06,
      "loss": 0.1543,
      "step": 4290
    },
    {
      "epoch": 0.9859834558823529,
      "grad_norm": 1.8798309564590454,
      "learning_rate": 8.921058006535949e-06,
      "loss": 0.1983,
      "step": 4291
    },
    {
      "epoch": 0.9862132352941176,
      "grad_norm": 1.734788417816162,
      "learning_rate": 8.920547385620916e-06,
      "loss": 0.1565,
      "step": 4292
    },
    {
      "epoch": 0.9864430147058824,
      "grad_norm": 1.619598388671875,
      "learning_rate": 8.920036764705883e-06,
      "loss": 0.1376,
      "step": 4293
    },
    {
      "epoch": 0.9866727941176471,
      "grad_norm": 1.6526880264282227,
      "learning_rate": 8.91952614379085e-06,
      "loss": 0.1356,
      "step": 4294
    },
    {
      "epoch": 0.9869025735294118,
      "grad_norm": 1.8865419626235962,
      "learning_rate": 8.919015522875818e-06,
      "loss": 0.1698,
      "step": 4295
    },
    {
      "epoch": 0.9871323529411765,
      "grad_norm": 1.2362842559814453,
      "learning_rate": 8.918504901960785e-06,
      "loss": 0.1087,
      "step": 4296
    },
    {
      "epoch": 0.9873621323529411,
      "grad_norm": 1.3523943424224854,
      "learning_rate": 8.917994281045752e-06,
      "loss": 0.1608,
      "step": 4297
    },
    {
      "epoch": 0.9875919117647058,
      "grad_norm": 1.5183227062225342,
      "learning_rate": 8.91748366013072e-06,
      "loss": 0.1267,
      "step": 4298
    },
    {
      "epoch": 0.9878216911764706,
      "grad_norm": 1.8280316591262817,
      "learning_rate": 8.916973039215686e-06,
      "loss": 0.1743,
      "step": 4299
    },
    {
      "epoch": 0.9880514705882353,
      "grad_norm": 1.681562066078186,
      "learning_rate": 8.916462418300654e-06,
      "loss": 0.1487,
      "step": 4300
    },
    {
      "epoch": 0.98828125,
      "grad_norm": 1.8687891960144043,
      "learning_rate": 8.915951797385622e-06,
      "loss": 0.1474,
      "step": 4301
    },
    {
      "epoch": 0.9885110294117647,
      "grad_norm": 1.764574408531189,
      "learning_rate": 8.91544117647059e-06,
      "loss": 0.2231,
      "step": 4302
    },
    {
      "epoch": 0.9887408088235294,
      "grad_norm": 1.9167993068695068,
      "learning_rate": 8.914930555555556e-06,
      "loss": 0.1747,
      "step": 4303
    },
    {
      "epoch": 0.9889705882352942,
      "grad_norm": 2.212118148803711,
      "learning_rate": 8.914419934640524e-06,
      "loss": 0.2033,
      "step": 4304
    },
    {
      "epoch": 0.9892003676470589,
      "grad_norm": 2.0570876598358154,
      "learning_rate": 8.91390931372549e-06,
      "loss": 0.1791,
      "step": 4305
    },
    {
      "epoch": 0.9894301470588235,
      "grad_norm": 1.3536041975021362,
      "learning_rate": 8.913398692810458e-06,
      "loss": 0.125,
      "step": 4306
    },
    {
      "epoch": 0.9896599264705882,
      "grad_norm": 1.7124625444412231,
      "learning_rate": 8.912888071895426e-06,
      "loss": 0.1142,
      "step": 4307
    },
    {
      "epoch": 0.9898897058823529,
      "grad_norm": 1.6762847900390625,
      "learning_rate": 8.912377450980392e-06,
      "loss": 0.1748,
      "step": 4308
    },
    {
      "epoch": 0.9901194852941176,
      "grad_norm": 2.1750004291534424,
      "learning_rate": 8.91186683006536e-06,
      "loss": 0.1419,
      "step": 4309
    },
    {
      "epoch": 0.9903492647058824,
      "grad_norm": 1.5057544708251953,
      "learning_rate": 8.911356209150328e-06,
      "loss": 0.1138,
      "step": 4310
    },
    {
      "epoch": 0.9905790441176471,
      "grad_norm": 2.101536273956299,
      "learning_rate": 8.910845588235296e-06,
      "loss": 0.1811,
      "step": 4311
    },
    {
      "epoch": 0.9908088235294118,
      "grad_norm": 1.7695882320404053,
      "learning_rate": 8.910334967320262e-06,
      "loss": 0.1346,
      "step": 4312
    },
    {
      "epoch": 0.9910386029411765,
      "grad_norm": 2.1958184242248535,
      "learning_rate": 8.90982434640523e-06,
      "loss": 0.2149,
      "step": 4313
    },
    {
      "epoch": 0.9912683823529411,
      "grad_norm": 2.326512098312378,
      "learning_rate": 8.909313725490198e-06,
      "loss": 0.2043,
      "step": 4314
    },
    {
      "epoch": 0.9914981617647058,
      "grad_norm": 2.16361927986145,
      "learning_rate": 8.908803104575164e-06,
      "loss": 0.1757,
      "step": 4315
    },
    {
      "epoch": 0.9917279411764706,
      "grad_norm": 1.6026328802108765,
      "learning_rate": 8.908292483660132e-06,
      "loss": 0.1515,
      "step": 4316
    },
    {
      "epoch": 0.9919577205882353,
      "grad_norm": 1.843369960784912,
      "learning_rate": 8.907781862745098e-06,
      "loss": 0.1514,
      "step": 4317
    },
    {
      "epoch": 0.9921875,
      "grad_norm": 1.4690325260162354,
      "learning_rate": 8.907271241830067e-06,
      "loss": 0.1483,
      "step": 4318
    },
    {
      "epoch": 0.9924172794117647,
      "grad_norm": 1.4263557195663452,
      "learning_rate": 8.906760620915033e-06,
      "loss": 0.1521,
      "step": 4319
    },
    {
      "epoch": 0.9926470588235294,
      "grad_norm": 1.70691978931427,
      "learning_rate": 8.906250000000001e-06,
      "loss": 0.1573,
      "step": 4320
    },
    {
      "epoch": 0.9928768382352942,
      "grad_norm": 1.674460530281067,
      "learning_rate": 8.905739379084968e-06,
      "loss": 0.1509,
      "step": 4321
    },
    {
      "epoch": 0.9931066176470589,
      "grad_norm": 1.6511212587356567,
      "learning_rate": 8.905228758169935e-06,
      "loss": 0.1626,
      "step": 4322
    },
    {
      "epoch": 0.9933363970588235,
      "grad_norm": 1.8100444078445435,
      "learning_rate": 8.904718137254903e-06,
      "loss": 0.1594,
      "step": 4323
    },
    {
      "epoch": 0.9935661764705882,
      "grad_norm": 1.8618073463439941,
      "learning_rate": 8.90420751633987e-06,
      "loss": 0.1624,
      "step": 4324
    },
    {
      "epoch": 0.9937959558823529,
      "grad_norm": 1.8901457786560059,
      "learning_rate": 8.903696895424837e-06,
      "loss": 0.178,
      "step": 4325
    },
    {
      "epoch": 0.9940257352941176,
      "grad_norm": 1.8289968967437744,
      "learning_rate": 8.903186274509803e-06,
      "loss": 0.172,
      "step": 4326
    },
    {
      "epoch": 0.9942555147058824,
      "grad_norm": 1.8248496055603027,
      "learning_rate": 8.902675653594773e-06,
      "loss": 0.158,
      "step": 4327
    },
    {
      "epoch": 0.9944852941176471,
      "grad_norm": 1.6582130193710327,
      "learning_rate": 8.902165032679739e-06,
      "loss": 0.1694,
      "step": 4328
    },
    {
      "epoch": 0.9947150735294118,
      "grad_norm": 2.1083688735961914,
      "learning_rate": 8.901654411764707e-06,
      "loss": 0.2009,
      "step": 4329
    },
    {
      "epoch": 0.9949448529411765,
      "grad_norm": 2.1815855503082275,
      "learning_rate": 8.901143790849673e-06,
      "loss": 0.1792,
      "step": 4330
    },
    {
      "epoch": 0.9951746323529411,
      "grad_norm": 2.279217481613159,
      "learning_rate": 8.900633169934641e-06,
      "loss": 0.1944,
      "step": 4331
    },
    {
      "epoch": 0.9954044117647058,
      "grad_norm": 1.4899450540542603,
      "learning_rate": 8.900122549019609e-06,
      "loss": 0.202,
      "step": 4332
    },
    {
      "epoch": 0.9956341911764706,
      "grad_norm": 1.293023705482483,
      "learning_rate": 8.899611928104575e-06,
      "loss": 0.1601,
      "step": 4333
    },
    {
      "epoch": 0.9958639705882353,
      "grad_norm": 1.5268001556396484,
      "learning_rate": 8.899101307189543e-06,
      "loss": 0.1396,
      "step": 4334
    },
    {
      "epoch": 0.99609375,
      "grad_norm": 1.520196557044983,
      "learning_rate": 8.89859068627451e-06,
      "loss": 0.137,
      "step": 4335
    },
    {
      "epoch": 0.9963235294117647,
      "grad_norm": 1.8059083223342896,
      "learning_rate": 8.898080065359479e-06,
      "loss": 0.1179,
      "step": 4336
    },
    {
      "epoch": 0.9965533088235294,
      "grad_norm": 1.570125937461853,
      "learning_rate": 8.897569444444445e-06,
      "loss": 0.1517,
      "step": 4337
    },
    {
      "epoch": 0.9967830882352942,
      "grad_norm": 1.7999308109283447,
      "learning_rate": 8.897058823529413e-06,
      "loss": 0.1674,
      "step": 4338
    },
    {
      "epoch": 0.9970128676470589,
      "grad_norm": 1.9670072793960571,
      "learning_rate": 8.89654820261438e-06,
      "loss": 0.1778,
      "step": 4339
    },
    {
      "epoch": 0.9972426470588235,
      "grad_norm": 1.882402777671814,
      "learning_rate": 8.896037581699347e-06,
      "loss": 0.1488,
      "step": 4340
    },
    {
      "epoch": 0.9974724264705882,
      "grad_norm": 2.0269734859466553,
      "learning_rate": 8.895526960784315e-06,
      "loss": 0.1652,
      "step": 4341
    },
    {
      "epoch": 0.9977022058823529,
      "grad_norm": 1.329728364944458,
      "learning_rate": 8.89501633986928e-06,
      "loss": 0.1501,
      "step": 4342
    },
    {
      "epoch": 0.9979319852941176,
      "grad_norm": 2.165597677230835,
      "learning_rate": 8.894505718954249e-06,
      "loss": 0.2031,
      "step": 4343
    },
    {
      "epoch": 0.9981617647058824,
      "grad_norm": 1.8301209211349487,
      "learning_rate": 8.893995098039216e-06,
      "loss": 0.1937,
      "step": 4344
    },
    {
      "epoch": 0.9983915441176471,
      "grad_norm": 1.7276214361190796,
      "learning_rate": 8.893484477124184e-06,
      "loss": 0.1658,
      "step": 4345
    },
    {
      "epoch": 0.9986213235294118,
      "grad_norm": 2.140040636062622,
      "learning_rate": 8.89297385620915e-06,
      "loss": 0.1463,
      "step": 4346
    },
    {
      "epoch": 0.9988511029411765,
      "grad_norm": 1.5782721042633057,
      "learning_rate": 8.892463235294118e-06,
      "loss": 0.1592,
      "step": 4347
    },
    {
      "epoch": 0.9990808823529411,
      "grad_norm": 1.9028215408325195,
      "learning_rate": 8.891952614379086e-06,
      "loss": 0.1772,
      "step": 4348
    },
    {
      "epoch": 0.9993106617647058,
      "grad_norm": 1.774807333946228,
      "learning_rate": 8.891441993464052e-06,
      "loss": 0.1725,
      "step": 4349
    },
    {
      "epoch": 0.9995404411764706,
      "grad_norm": 2.118492364883423,
      "learning_rate": 8.89093137254902e-06,
      "loss": 0.1809,
      "step": 4350
    },
    {
      "epoch": 0.9997702205882353,
      "grad_norm": 2.0642507076263428,
      "learning_rate": 8.890420751633988e-06,
      "loss": 0.1424,
      "step": 4351
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.9063607454299927,
      "learning_rate": 8.889910130718954e-06,
      "loss": 0.1297,
      "step": 4352
    },
    {
      "epoch": 1.0002297794117647,
      "grad_norm": 1.7616733312606812,
      "learning_rate": 8.889399509803922e-06,
      "loss": 0.1346,
      "step": 4353
    },
    {
      "epoch": 1.0004595588235294,
      "grad_norm": 1.427812099456787,
      "learning_rate": 8.888888888888888e-06,
      "loss": 0.1537,
      "step": 4354
    },
    {
      "epoch": 1.0006893382352942,
      "grad_norm": 1.8164610862731934,
      "learning_rate": 8.888378267973858e-06,
      "loss": 0.1161,
      "step": 4355
    },
    {
      "epoch": 1.0009191176470589,
      "grad_norm": 1.6912435293197632,
      "learning_rate": 8.887867647058824e-06,
      "loss": 0.147,
      "step": 4356
    },
    {
      "epoch": 1.0011488970588236,
      "grad_norm": 1.5898360013961792,
      "learning_rate": 8.887357026143792e-06,
      "loss": 0.1303,
      "step": 4357
    },
    {
      "epoch": 1.0013786764705883,
      "grad_norm": 2.0586068630218506,
      "learning_rate": 8.886846405228758e-06,
      "loss": 0.1625,
      "step": 4358
    },
    {
      "epoch": 1.001608455882353,
      "grad_norm": 1.6438504457473755,
      "learning_rate": 8.886335784313726e-06,
      "loss": 0.2077,
      "step": 4359
    },
    {
      "epoch": 1.0018382352941178,
      "grad_norm": 1.6109628677368164,
      "learning_rate": 8.885825163398694e-06,
      "loss": 0.1708,
      "step": 4360
    },
    {
      "epoch": 1.0020680147058822,
      "grad_norm": 1.5325437784194946,
      "learning_rate": 8.88531454248366e-06,
      "loss": 0.1501,
      "step": 4361
    },
    {
      "epoch": 1.002297794117647,
      "grad_norm": 2.011629581451416,
      "learning_rate": 8.884803921568628e-06,
      "loss": 0.1586,
      "step": 4362
    },
    {
      "epoch": 1.0025275735294117,
      "grad_norm": 1.6891437768936157,
      "learning_rate": 8.884293300653596e-06,
      "loss": 0.1469,
      "step": 4363
    },
    {
      "epoch": 1.0027573529411764,
      "grad_norm": 1.8188629150390625,
      "learning_rate": 8.883782679738564e-06,
      "loss": 0.1708,
      "step": 4364
    },
    {
      "epoch": 1.0029871323529411,
      "grad_norm": 2.07800555229187,
      "learning_rate": 8.88327205882353e-06,
      "loss": 0.1366,
      "step": 4365
    },
    {
      "epoch": 1.0032169117647058,
      "grad_norm": 1.979429006576538,
      "learning_rate": 8.882761437908498e-06,
      "loss": 0.1972,
      "step": 4366
    },
    {
      "epoch": 1.0034466911764706,
      "grad_norm": 1.7045049667358398,
      "learning_rate": 8.882250816993465e-06,
      "loss": 0.1848,
      "step": 4367
    },
    {
      "epoch": 1.0036764705882353,
      "grad_norm": 1.7347843647003174,
      "learning_rate": 8.881740196078432e-06,
      "loss": 0.1317,
      "step": 4368
    },
    {
      "epoch": 1.00390625,
      "grad_norm": 1.413783311843872,
      "learning_rate": 8.8812295751634e-06,
      "loss": 0.1579,
      "step": 4369
    },
    {
      "epoch": 1.0041360294117647,
      "grad_norm": 1.8299100399017334,
      "learning_rate": 8.880718954248366e-06,
      "loss": 0.174,
      "step": 4370
    },
    {
      "epoch": 1.0043658088235294,
      "grad_norm": 1.5808954238891602,
      "learning_rate": 8.880208333333335e-06,
      "loss": 0.1674,
      "step": 4371
    },
    {
      "epoch": 1.0045955882352942,
      "grad_norm": 1.3769915103912354,
      "learning_rate": 8.879697712418301e-06,
      "loss": 0.1452,
      "step": 4372
    },
    {
      "epoch": 1.0048253676470589,
      "grad_norm": 1.7718613147735596,
      "learning_rate": 8.87918709150327e-06,
      "loss": 0.198,
      "step": 4373
    },
    {
      "epoch": 1.0050551470588236,
      "grad_norm": 1.770371437072754,
      "learning_rate": 8.878676470588235e-06,
      "loss": 0.1842,
      "step": 4374
    },
    {
      "epoch": 1.0052849264705883,
      "grad_norm": 1.6851084232330322,
      "learning_rate": 8.878165849673203e-06,
      "loss": 0.1491,
      "step": 4375
    },
    {
      "epoch": 1.005514705882353,
      "grad_norm": 1.6555898189544678,
      "learning_rate": 8.877655228758171e-06,
      "loss": 0.1741,
      "step": 4376
    },
    {
      "epoch": 1.0057444852941178,
      "grad_norm": 2.119227886199951,
      "learning_rate": 8.877144607843137e-06,
      "loss": 0.1242,
      "step": 4377
    },
    {
      "epoch": 1.0059742647058822,
      "grad_norm": 1.8004854917526245,
      "learning_rate": 8.876633986928105e-06,
      "loss": 0.1383,
      "step": 4378
    },
    {
      "epoch": 1.006204044117647,
      "grad_norm": 1.811553955078125,
      "learning_rate": 8.876123366013073e-06,
      "loss": 0.2048,
      "step": 4379
    },
    {
      "epoch": 1.0064338235294117,
      "grad_norm": 1.5742151737213135,
      "learning_rate": 8.87561274509804e-06,
      "loss": 0.1101,
      "step": 4380
    },
    {
      "epoch": 1.0066636029411764,
      "grad_norm": 1.925850749015808,
      "learning_rate": 8.875102124183007e-06,
      "loss": 0.1771,
      "step": 4381
    },
    {
      "epoch": 1.0068933823529411,
      "grad_norm": 1.6164827346801758,
      "learning_rate": 8.874591503267975e-06,
      "loss": 0.1435,
      "step": 4382
    },
    {
      "epoch": 1.0071231617647058,
      "grad_norm": 1.7855335474014282,
      "learning_rate": 8.874080882352943e-06,
      "loss": 0.1653,
      "step": 4383
    },
    {
      "epoch": 1.0073529411764706,
      "grad_norm": 2.0375654697418213,
      "learning_rate": 8.873570261437909e-06,
      "loss": 0.1624,
      "step": 4384
    },
    {
      "epoch": 1.0075827205882353,
      "grad_norm": 1.8177605867385864,
      "learning_rate": 8.873059640522877e-06,
      "loss": 0.1565,
      "step": 4385
    },
    {
      "epoch": 1.0078125,
      "grad_norm": 1.522186517715454,
      "learning_rate": 8.872549019607843e-06,
      "loss": 0.1585,
      "step": 4386
    },
    {
      "epoch": 1.0080422794117647,
      "grad_norm": 1.954134464263916,
      "learning_rate": 8.87203839869281e-06,
      "loss": 0.1423,
      "step": 4387
    },
    {
      "epoch": 1.0082720588235294,
      "grad_norm": 1.5515577793121338,
      "learning_rate": 8.871527777777779e-06,
      "loss": 0.147,
      "step": 4388
    },
    {
      "epoch": 1.0085018382352942,
      "grad_norm": 1.3379888534545898,
      "learning_rate": 8.871017156862747e-06,
      "loss": 0.1217,
      "step": 4389
    },
    {
      "epoch": 1.0087316176470589,
      "grad_norm": 1.5871789455413818,
      "learning_rate": 8.870506535947713e-06,
      "loss": 0.167,
      "step": 4390
    },
    {
      "epoch": 1.0089613970588236,
      "grad_norm": 1.4036064147949219,
      "learning_rate": 8.86999591503268e-06,
      "loss": 0.1097,
      "step": 4391
    },
    {
      "epoch": 1.0091911764705883,
      "grad_norm": 1.7971761226654053,
      "learning_rate": 8.869485294117648e-06,
      "loss": 0.1277,
      "step": 4392
    },
    {
      "epoch": 1.009420955882353,
      "grad_norm": 1.7015899419784546,
      "learning_rate": 8.868974673202615e-06,
      "loss": 0.1355,
      "step": 4393
    },
    {
      "epoch": 1.0096507352941178,
      "grad_norm": 1.5602213144302368,
      "learning_rate": 8.868464052287582e-06,
      "loss": 0.1784,
      "step": 4394
    },
    {
      "epoch": 1.0098805147058822,
      "grad_norm": 1.512747049331665,
      "learning_rate": 8.86795343137255e-06,
      "loss": 0.1635,
      "step": 4395
    },
    {
      "epoch": 1.010110294117647,
      "grad_norm": 2.3295199871063232,
      "learning_rate": 8.867442810457516e-06,
      "loss": 0.1856,
      "step": 4396
    },
    {
      "epoch": 1.0103400735294117,
      "grad_norm": 1.5364434719085693,
      "learning_rate": 8.866932189542484e-06,
      "loss": 0.1154,
      "step": 4397
    },
    {
      "epoch": 1.0105698529411764,
      "grad_norm": 1.391957402229309,
      "learning_rate": 8.86642156862745e-06,
      "loss": 0.1425,
      "step": 4398
    },
    {
      "epoch": 1.0107996323529411,
      "grad_norm": 1.3130698204040527,
      "learning_rate": 8.86591094771242e-06,
      "loss": 0.1049,
      "step": 4399
    },
    {
      "epoch": 1.0110294117647058,
      "grad_norm": 1.8230037689208984,
      "learning_rate": 8.865400326797386e-06,
      "loss": 0.1489,
      "step": 4400
    },
    {
      "epoch": 1.0112591911764706,
      "grad_norm": 1.9843642711639404,
      "learning_rate": 8.864889705882354e-06,
      "loss": 0.1329,
      "step": 4401
    },
    {
      "epoch": 1.0114889705882353,
      "grad_norm": 1.7265431880950928,
      "learning_rate": 8.86437908496732e-06,
      "loss": 0.1548,
      "step": 4402
    },
    {
      "epoch": 1.01171875,
      "grad_norm": 1.7777392864227295,
      "learning_rate": 8.863868464052288e-06,
      "loss": 0.1808,
      "step": 4403
    },
    {
      "epoch": 1.0119485294117647,
      "grad_norm": 1.671276569366455,
      "learning_rate": 8.863357843137256e-06,
      "loss": 0.1321,
      "step": 4404
    },
    {
      "epoch": 1.0121783088235294,
      "grad_norm": 2.1734678745269775,
      "learning_rate": 8.862847222222222e-06,
      "loss": 0.1714,
      "step": 4405
    },
    {
      "epoch": 1.0124080882352942,
      "grad_norm": 1.309194803237915,
      "learning_rate": 8.86233660130719e-06,
      "loss": 0.1321,
      "step": 4406
    },
    {
      "epoch": 1.0126378676470589,
      "grad_norm": 2.1976428031921387,
      "learning_rate": 8.861825980392158e-06,
      "loss": 0.1803,
      "step": 4407
    },
    {
      "epoch": 1.0128676470588236,
      "grad_norm": 1.8189839124679565,
      "learning_rate": 8.861315359477126e-06,
      "loss": 0.1623,
      "step": 4408
    },
    {
      "epoch": 1.0130974264705883,
      "grad_norm": 2.1772310733795166,
      "learning_rate": 8.860804738562092e-06,
      "loss": 0.1648,
      "step": 4409
    },
    {
      "epoch": 1.013327205882353,
      "grad_norm": 1.614425778388977,
      "learning_rate": 8.86029411764706e-06,
      "loss": 0.1595,
      "step": 4410
    },
    {
      "epoch": 1.0135569852941178,
      "grad_norm": 1.7794654369354248,
      "learning_rate": 8.859783496732028e-06,
      "loss": 0.1867,
      "step": 4411
    },
    {
      "epoch": 1.0137867647058822,
      "grad_norm": 1.27073335647583,
      "learning_rate": 8.859272875816994e-06,
      "loss": 0.1068,
      "step": 4412
    },
    {
      "epoch": 1.014016544117647,
      "grad_norm": 1.334779977798462,
      "learning_rate": 8.858762254901962e-06,
      "loss": 0.1405,
      "step": 4413
    },
    {
      "epoch": 1.0142463235294117,
      "grad_norm": 1.6973398923873901,
      "learning_rate": 8.858251633986928e-06,
      "loss": 0.1687,
      "step": 4414
    },
    {
      "epoch": 1.0144761029411764,
      "grad_norm": 1.901624083518982,
      "learning_rate": 8.857741013071897e-06,
      "loss": 0.1754,
      "step": 4415
    },
    {
      "epoch": 1.0147058823529411,
      "grad_norm": 1.9974244832992554,
      "learning_rate": 8.857230392156864e-06,
      "loss": 0.16,
      "step": 4416
    },
    {
      "epoch": 1.0149356617647058,
      "grad_norm": 1.943235158920288,
      "learning_rate": 8.856719771241831e-06,
      "loss": 0.172,
      "step": 4417
    },
    {
      "epoch": 1.0151654411764706,
      "grad_norm": 1.6184639930725098,
      "learning_rate": 8.856209150326798e-06,
      "loss": 0.1312,
      "step": 4418
    },
    {
      "epoch": 1.0153952205882353,
      "grad_norm": 1.7571748495101929,
      "learning_rate": 8.855698529411765e-06,
      "loss": 0.1872,
      "step": 4419
    },
    {
      "epoch": 1.015625,
      "grad_norm": 1.6923668384552002,
      "learning_rate": 8.855187908496733e-06,
      "loss": 0.1552,
      "step": 4420
    },
    {
      "epoch": 1.0158547794117647,
      "grad_norm": 1.5239195823669434,
      "learning_rate": 8.8546772875817e-06,
      "loss": 0.1598,
      "step": 4421
    },
    {
      "epoch": 1.0160845588235294,
      "grad_norm": 1.8294713497161865,
      "learning_rate": 8.854166666666667e-06,
      "loss": 0.1443,
      "step": 4422
    },
    {
      "epoch": 1.0163143382352942,
      "grad_norm": 2.017827033996582,
      "learning_rate": 8.853656045751635e-06,
      "loss": 0.1587,
      "step": 4423
    },
    {
      "epoch": 1.0165441176470589,
      "grad_norm": 2.2432429790496826,
      "learning_rate": 8.853145424836603e-06,
      "loss": 0.1501,
      "step": 4424
    },
    {
      "epoch": 1.0167738970588236,
      "grad_norm": 1.5708394050598145,
      "learning_rate": 8.85263480392157e-06,
      "loss": 0.1109,
      "step": 4425
    },
    {
      "epoch": 1.0170036764705883,
      "grad_norm": 1.7411168813705444,
      "learning_rate": 8.852124183006537e-06,
      "loss": 0.161,
      "step": 4426
    },
    {
      "epoch": 1.017233455882353,
      "grad_norm": 2.4811172485351562,
      "learning_rate": 8.851613562091505e-06,
      "loss": 0.2258,
      "step": 4427
    },
    {
      "epoch": 1.0174632352941178,
      "grad_norm": 2.0647048950195312,
      "learning_rate": 8.851102941176471e-06,
      "loss": 0.1915,
      "step": 4428
    },
    {
      "epoch": 1.0176930147058822,
      "grad_norm": 1.587624192237854,
      "learning_rate": 8.850592320261439e-06,
      "loss": 0.1535,
      "step": 4429
    },
    {
      "epoch": 1.017922794117647,
      "grad_norm": 1.769993782043457,
      "learning_rate": 8.850081699346405e-06,
      "loss": 0.149,
      "step": 4430
    },
    {
      "epoch": 1.0181525735294117,
      "grad_norm": 1.377109408378601,
      "learning_rate": 8.849571078431373e-06,
      "loss": 0.1,
      "step": 4431
    },
    {
      "epoch": 1.0183823529411764,
      "grad_norm": 1.679216742515564,
      "learning_rate": 8.84906045751634e-06,
      "loss": 0.1499,
      "step": 4432
    },
    {
      "epoch": 1.0186121323529411,
      "grad_norm": 1.6047426462173462,
      "learning_rate": 8.848549836601307e-06,
      "loss": 0.1403,
      "step": 4433
    },
    {
      "epoch": 1.0188419117647058,
      "grad_norm": 1.8243298530578613,
      "learning_rate": 8.848039215686275e-06,
      "loss": 0.158,
      "step": 4434
    },
    {
      "epoch": 1.0190716911764706,
      "grad_norm": 1.4324930906295776,
      "learning_rate": 8.847528594771243e-06,
      "loss": 0.1801,
      "step": 4435
    },
    {
      "epoch": 1.0193014705882353,
      "grad_norm": 1.4360679388046265,
      "learning_rate": 8.84701797385621e-06,
      "loss": 0.113,
      "step": 4436
    },
    {
      "epoch": 1.01953125,
      "grad_norm": 1.3596954345703125,
      "learning_rate": 8.846507352941177e-06,
      "loss": 0.1286,
      "step": 4437
    },
    {
      "epoch": 1.0197610294117647,
      "grad_norm": 1.6326218843460083,
      "learning_rate": 8.845996732026145e-06,
      "loss": 0.1249,
      "step": 4438
    },
    {
      "epoch": 1.0199908088235294,
      "grad_norm": 1.7307640314102173,
      "learning_rate": 8.845486111111112e-06,
      "loss": 0.1922,
      "step": 4439
    },
    {
      "epoch": 1.0202205882352942,
      "grad_norm": 1.428034782409668,
      "learning_rate": 8.844975490196079e-06,
      "loss": 0.1239,
      "step": 4440
    },
    {
      "epoch": 1.0204503676470589,
      "grad_norm": 1.4258452653884888,
      "learning_rate": 8.844464869281047e-06,
      "loss": 0.1709,
      "step": 4441
    },
    {
      "epoch": 1.0206801470588236,
      "grad_norm": 2.015483856201172,
      "learning_rate": 8.843954248366013e-06,
      "loss": 0.1663,
      "step": 4442
    },
    {
      "epoch": 1.0209099264705883,
      "grad_norm": 1.5583451986312866,
      "learning_rate": 8.843443627450982e-06,
      "loss": 0.1419,
      "step": 4443
    },
    {
      "epoch": 1.021139705882353,
      "grad_norm": 1.3296555280685425,
      "learning_rate": 8.842933006535948e-06,
      "loss": 0.1482,
      "step": 4444
    },
    {
      "epoch": 1.0213694852941178,
      "grad_norm": 1.5907576084136963,
      "learning_rate": 8.842422385620916e-06,
      "loss": 0.1101,
      "step": 4445
    },
    {
      "epoch": 1.0215992647058822,
      "grad_norm": 1.4082679748535156,
      "learning_rate": 8.841911764705882e-06,
      "loss": 0.1075,
      "step": 4446
    },
    {
      "epoch": 1.021829044117647,
      "grad_norm": 1.2284727096557617,
      "learning_rate": 8.84140114379085e-06,
      "loss": 0.1107,
      "step": 4447
    },
    {
      "epoch": 1.0220588235294117,
      "grad_norm": 1.6514613628387451,
      "learning_rate": 8.840890522875818e-06,
      "loss": 0.1316,
      "step": 4448
    },
    {
      "epoch": 1.0222886029411764,
      "grad_norm": 1.6143882274627686,
      "learning_rate": 8.840379901960784e-06,
      "loss": 0.1562,
      "step": 4449
    },
    {
      "epoch": 1.0225183823529411,
      "grad_norm": 1.5861821174621582,
      "learning_rate": 8.839869281045752e-06,
      "loss": 0.1589,
      "step": 4450
    },
    {
      "epoch": 1.0227481617647058,
      "grad_norm": 1.8684937953948975,
      "learning_rate": 8.83935866013072e-06,
      "loss": 0.1377,
      "step": 4451
    },
    {
      "epoch": 1.0229779411764706,
      "grad_norm": 2.384411573410034,
      "learning_rate": 8.838848039215688e-06,
      "loss": 0.1473,
      "step": 4452
    },
    {
      "epoch": 1.0232077205882353,
      "grad_norm": 1.7625014781951904,
      "learning_rate": 8.838337418300654e-06,
      "loss": 0.1495,
      "step": 4453
    },
    {
      "epoch": 1.0234375,
      "grad_norm": 1.9217326641082764,
      "learning_rate": 8.837826797385622e-06,
      "loss": 0.1745,
      "step": 4454
    },
    {
      "epoch": 1.0236672794117647,
      "grad_norm": 1.554761290550232,
      "learning_rate": 8.83731617647059e-06,
      "loss": 0.1435,
      "step": 4455
    },
    {
      "epoch": 1.0238970588235294,
      "grad_norm": 2.071770668029785,
      "learning_rate": 8.836805555555556e-06,
      "loss": 0.1725,
      "step": 4456
    },
    {
      "epoch": 1.0241268382352942,
      "grad_norm": 1.6008858680725098,
      "learning_rate": 8.836294934640524e-06,
      "loss": 0.1652,
      "step": 4457
    },
    {
      "epoch": 1.0243566176470589,
      "grad_norm": 1.9561272859573364,
      "learning_rate": 8.83578431372549e-06,
      "loss": 0.171,
      "step": 4458
    },
    {
      "epoch": 1.0245863970588236,
      "grad_norm": 1.6427154541015625,
      "learning_rate": 8.83527369281046e-06,
      "loss": 0.1378,
      "step": 4459
    },
    {
      "epoch": 1.0248161764705883,
      "grad_norm": 1.5363837480545044,
      "learning_rate": 8.834763071895426e-06,
      "loss": 0.1585,
      "step": 4460
    },
    {
      "epoch": 1.025045955882353,
      "grad_norm": 2.060312271118164,
      "learning_rate": 8.834252450980394e-06,
      "loss": 0.1773,
      "step": 4461
    },
    {
      "epoch": 1.0252757352941178,
      "grad_norm": 1.2868674993515015,
      "learning_rate": 8.83374183006536e-06,
      "loss": 0.1175,
      "step": 4462
    },
    {
      "epoch": 1.0255055147058822,
      "grad_norm": 1.751554250717163,
      "learning_rate": 8.833231209150328e-06,
      "loss": 0.1351,
      "step": 4463
    },
    {
      "epoch": 1.025735294117647,
      "grad_norm": 1.7691980600357056,
      "learning_rate": 8.832720588235295e-06,
      "loss": 0.1533,
      "step": 4464
    },
    {
      "epoch": 1.0259650735294117,
      "grad_norm": 1.4992265701293945,
      "learning_rate": 8.832209967320262e-06,
      "loss": 0.1338,
      "step": 4465
    },
    {
      "epoch": 1.0261948529411764,
      "grad_norm": 2.0034916400909424,
      "learning_rate": 8.83169934640523e-06,
      "loss": 0.1966,
      "step": 4466
    },
    {
      "epoch": 1.0264246323529411,
      "grad_norm": 1.5900418758392334,
      "learning_rate": 8.831188725490197e-06,
      "loss": 0.1196,
      "step": 4467
    },
    {
      "epoch": 1.0266544117647058,
      "grad_norm": 1.5774861574172974,
      "learning_rate": 8.830678104575165e-06,
      "loss": 0.1623,
      "step": 4468
    },
    {
      "epoch": 1.0268841911764706,
      "grad_norm": 1.8801671266555786,
      "learning_rate": 8.830167483660131e-06,
      "loss": 0.1669,
      "step": 4469
    },
    {
      "epoch": 1.0271139705882353,
      "grad_norm": 1.5260778665542603,
      "learning_rate": 8.8296568627451e-06,
      "loss": 0.1465,
      "step": 4470
    },
    {
      "epoch": 1.02734375,
      "grad_norm": 1.5242565870285034,
      "learning_rate": 8.829146241830067e-06,
      "loss": 0.1782,
      "step": 4471
    },
    {
      "epoch": 1.0275735294117647,
      "grad_norm": 1.8974803686141968,
      "learning_rate": 8.828635620915033e-06,
      "loss": 0.1441,
      "step": 4472
    },
    {
      "epoch": 1.0278033088235294,
      "grad_norm": 1.8128328323364258,
      "learning_rate": 8.828125000000001e-06,
      "loss": 0.1578,
      "step": 4473
    },
    {
      "epoch": 1.0280330882352942,
      "grad_norm": 1.8943822383880615,
      "learning_rate": 8.827614379084967e-06,
      "loss": 0.1642,
      "step": 4474
    },
    {
      "epoch": 1.0282628676470589,
      "grad_norm": 1.7620972394943237,
      "learning_rate": 8.827103758169935e-06,
      "loss": 0.1562,
      "step": 4475
    },
    {
      "epoch": 1.0284926470588236,
      "grad_norm": 2.7583084106445312,
      "learning_rate": 8.826593137254903e-06,
      "loss": 0.2343,
      "step": 4476
    },
    {
      "epoch": 1.0287224264705883,
      "grad_norm": 1.7106750011444092,
      "learning_rate": 8.82608251633987e-06,
      "loss": 0.1196,
      "step": 4477
    },
    {
      "epoch": 1.028952205882353,
      "grad_norm": 1.805351734161377,
      "learning_rate": 8.825571895424837e-06,
      "loss": 0.175,
      "step": 4478
    },
    {
      "epoch": 1.0291819852941178,
      "grad_norm": 1.8758312463760376,
      "learning_rate": 8.825061274509805e-06,
      "loss": 0.1497,
      "step": 4479
    },
    {
      "epoch": 1.0294117647058822,
      "grad_norm": 2.0024571418762207,
      "learning_rate": 8.824550653594773e-06,
      "loss": 0.1977,
      "step": 4480
    },
    {
      "epoch": 1.029641544117647,
      "grad_norm": 1.9973838329315186,
      "learning_rate": 8.824040032679739e-06,
      "loss": 0.1252,
      "step": 4481
    },
    {
      "epoch": 1.0298713235294117,
      "grad_norm": 1.642166256904602,
      "learning_rate": 8.823529411764707e-06,
      "loss": 0.1516,
      "step": 4482
    },
    {
      "epoch": 1.0301011029411764,
      "grad_norm": 1.3603014945983887,
      "learning_rate": 8.823018790849673e-06,
      "loss": 0.107,
      "step": 4483
    },
    {
      "epoch": 1.0303308823529411,
      "grad_norm": 1.663744568824768,
      "learning_rate": 8.82250816993464e-06,
      "loss": 0.1517,
      "step": 4484
    },
    {
      "epoch": 1.0305606617647058,
      "grad_norm": 1.5773777961730957,
      "learning_rate": 8.821997549019609e-06,
      "loss": 0.1268,
      "step": 4485
    },
    {
      "epoch": 1.0307904411764706,
      "grad_norm": 2.0127675533294678,
      "learning_rate": 8.821486928104575e-06,
      "loss": 0.2129,
      "step": 4486
    },
    {
      "epoch": 1.0310202205882353,
      "grad_norm": 2.425276517868042,
      "learning_rate": 8.820976307189543e-06,
      "loss": 0.1781,
      "step": 4487
    },
    {
      "epoch": 1.03125,
      "grad_norm": 1.5597978830337524,
      "learning_rate": 8.82046568627451e-06,
      "loss": 0.1529,
      "step": 4488
    },
    {
      "epoch": 1.0314797794117647,
      "grad_norm": 1.8158711194992065,
      "learning_rate": 8.819955065359478e-06,
      "loss": 0.1414,
      "step": 4489
    },
    {
      "epoch": 1.0317095588235294,
      "grad_norm": 1.7958656549453735,
      "learning_rate": 8.819444444444445e-06,
      "loss": 0.1859,
      "step": 4490
    },
    {
      "epoch": 1.0319393382352942,
      "grad_norm": 1.701783537864685,
      "learning_rate": 8.818933823529412e-06,
      "loss": 0.1408,
      "step": 4491
    },
    {
      "epoch": 1.0321691176470589,
      "grad_norm": 2.296570301055908,
      "learning_rate": 8.81842320261438e-06,
      "loss": 0.1605,
      "step": 4492
    },
    {
      "epoch": 1.0323988970588236,
      "grad_norm": 1.4553767442703247,
      "learning_rate": 8.817912581699347e-06,
      "loss": 0.1628,
      "step": 4493
    },
    {
      "epoch": 1.0326286764705883,
      "grad_norm": 1.9562634229660034,
      "learning_rate": 8.817401960784314e-06,
      "loss": 0.1393,
      "step": 4494
    },
    {
      "epoch": 1.032858455882353,
      "grad_norm": 1.469201683998108,
      "learning_rate": 8.81689133986928e-06,
      "loss": 0.1225,
      "step": 4495
    },
    {
      "epoch": 1.0330882352941178,
      "grad_norm": 1.8167983293533325,
      "learning_rate": 8.81638071895425e-06,
      "loss": 0.136,
      "step": 4496
    },
    {
      "epoch": 1.0333180147058822,
      "grad_norm": 1.4560517072677612,
      "learning_rate": 8.815870098039216e-06,
      "loss": 0.1619,
      "step": 4497
    },
    {
      "epoch": 1.033547794117647,
      "grad_norm": 1.2670838832855225,
      "learning_rate": 8.815359477124184e-06,
      "loss": 0.1545,
      "step": 4498
    },
    {
      "epoch": 1.0337775735294117,
      "grad_norm": 2.077587127685547,
      "learning_rate": 8.81484885620915e-06,
      "loss": 0.1606,
      "step": 4499
    },
    {
      "epoch": 1.0340073529411764,
      "grad_norm": 1.7512977123260498,
      "learning_rate": 8.814338235294118e-06,
      "loss": 0.1729,
      "step": 4500
    },
    {
      "epoch": 1.0340073529411764,
      "eval_loss": 0.15613923966884613,
      "eval_runtime": 420.266,
      "eval_samples_per_second": 21.191,
      "eval_steps_per_second": 10.596,
      "step": 4500
    },
    {
      "epoch": 1.0342371323529411,
      "grad_norm": 2.0293145179748535,
      "learning_rate": 8.813827614379086e-06,
      "loss": 0.1668,
      "step": 4501
    },
    {
      "epoch": 1.0344669117647058,
      "grad_norm": 1.68658447265625,
      "learning_rate": 8.813316993464052e-06,
      "loss": 0.1664,
      "step": 4502
    },
    {
      "epoch": 1.0346966911764706,
      "grad_norm": 1.906720519065857,
      "learning_rate": 8.81280637254902e-06,
      "loss": 0.1687,
      "step": 4503
    },
    {
      "epoch": 1.0349264705882353,
      "grad_norm": 1.9639419317245483,
      "learning_rate": 8.812295751633988e-06,
      "loss": 0.1433,
      "step": 4504
    },
    {
      "epoch": 1.03515625,
      "grad_norm": 1.4037301540374756,
      "learning_rate": 8.811785130718956e-06,
      "loss": 0.1422,
      "step": 4505
    },
    {
      "epoch": 1.0353860294117647,
      "grad_norm": 1.7743098735809326,
      "learning_rate": 8.811274509803922e-06,
      "loss": 0.1517,
      "step": 4506
    },
    {
      "epoch": 1.0356158088235294,
      "grad_norm": 1.444762945175171,
      "learning_rate": 8.81076388888889e-06,
      "loss": 0.1208,
      "step": 4507
    },
    {
      "epoch": 1.0358455882352942,
      "grad_norm": 1.7908003330230713,
      "learning_rate": 8.810253267973858e-06,
      "loss": 0.1192,
      "step": 4508
    },
    {
      "epoch": 1.0360753676470589,
      "grad_norm": 1.3806133270263672,
      "learning_rate": 8.809742647058824e-06,
      "loss": 0.1301,
      "step": 4509
    },
    {
      "epoch": 1.0363051470588236,
      "grad_norm": 1.4843569993972778,
      "learning_rate": 8.809232026143792e-06,
      "loss": 0.1254,
      "step": 4510
    },
    {
      "epoch": 1.0365349264705883,
      "grad_norm": 1.3528810739517212,
      "learning_rate": 8.808721405228758e-06,
      "loss": 0.1393,
      "step": 4511
    },
    {
      "epoch": 1.036764705882353,
      "grad_norm": 1.8021342754364014,
      "learning_rate": 8.808210784313727e-06,
      "loss": 0.1635,
      "step": 4512
    },
    {
      "epoch": 1.0369944852941178,
      "grad_norm": 1.5460693836212158,
      "learning_rate": 8.807700163398694e-06,
      "loss": 0.1394,
      "step": 4513
    },
    {
      "epoch": 1.0372242647058822,
      "grad_norm": 1.4415886402130127,
      "learning_rate": 8.807189542483661e-06,
      "loss": 0.1417,
      "step": 4514
    },
    {
      "epoch": 1.037454044117647,
      "grad_norm": 2.0411839485168457,
      "learning_rate": 8.806678921568628e-06,
      "loss": 0.1572,
      "step": 4515
    },
    {
      "epoch": 1.0376838235294117,
      "grad_norm": 2.2903547286987305,
      "learning_rate": 8.806168300653595e-06,
      "loss": 0.2062,
      "step": 4516
    },
    {
      "epoch": 1.0379136029411764,
      "grad_norm": 1.4403694868087769,
      "learning_rate": 8.805657679738563e-06,
      "loss": 0.1478,
      "step": 4517
    },
    {
      "epoch": 1.0381433823529411,
      "grad_norm": 1.7027904987335205,
      "learning_rate": 8.80514705882353e-06,
      "loss": 0.1889,
      "step": 4518
    },
    {
      "epoch": 1.0383731617647058,
      "grad_norm": 1.291640281677246,
      "learning_rate": 8.804636437908497e-06,
      "loss": 0.1654,
      "step": 4519
    },
    {
      "epoch": 1.0386029411764706,
      "grad_norm": 1.530036211013794,
      "learning_rate": 8.804125816993465e-06,
      "loss": 0.1288,
      "step": 4520
    },
    {
      "epoch": 1.0388327205882353,
      "grad_norm": 1.1093313694000244,
      "learning_rate": 8.803615196078431e-06,
      "loss": 0.1347,
      "step": 4521
    },
    {
      "epoch": 1.0390625,
      "grad_norm": 1.6823902130126953,
      "learning_rate": 8.8031045751634e-06,
      "loss": 0.1711,
      "step": 4522
    },
    {
      "epoch": 1.0392922794117647,
      "grad_norm": 1.5990172624588013,
      "learning_rate": 8.802593954248367e-06,
      "loss": 0.1526,
      "step": 4523
    },
    {
      "epoch": 1.0395220588235294,
      "grad_norm": 1.39716374874115,
      "learning_rate": 8.802083333333335e-06,
      "loss": 0.1532,
      "step": 4524
    },
    {
      "epoch": 1.0397518382352942,
      "grad_norm": 2.2429511547088623,
      "learning_rate": 8.801572712418301e-06,
      "loss": 0.1465,
      "step": 4525
    },
    {
      "epoch": 1.0399816176470589,
      "grad_norm": 1.651914119720459,
      "learning_rate": 8.801062091503269e-06,
      "loss": 0.1774,
      "step": 4526
    },
    {
      "epoch": 1.0402113970588236,
      "grad_norm": 1.4341294765472412,
      "learning_rate": 8.800551470588235e-06,
      "loss": 0.1539,
      "step": 4527
    },
    {
      "epoch": 1.0404411764705883,
      "grad_norm": 1.6218427419662476,
      "learning_rate": 8.800040849673203e-06,
      "loss": 0.1769,
      "step": 4528
    },
    {
      "epoch": 1.040670955882353,
      "grad_norm": 1.5699414014816284,
      "learning_rate": 8.799530228758171e-06,
      "loss": 0.1678,
      "step": 4529
    },
    {
      "epoch": 1.0409007352941178,
      "grad_norm": 1.7509108781814575,
      "learning_rate": 8.799019607843137e-06,
      "loss": 0.1511,
      "step": 4530
    },
    {
      "epoch": 1.0411305147058822,
      "grad_norm": 1.5875905752182007,
      "learning_rate": 8.798508986928105e-06,
      "loss": 0.1422,
      "step": 4531
    },
    {
      "epoch": 1.041360294117647,
      "grad_norm": 1.6526275873184204,
      "learning_rate": 8.797998366013073e-06,
      "loss": 0.1627,
      "step": 4532
    },
    {
      "epoch": 1.0415900735294117,
      "grad_norm": 1.8731319904327393,
      "learning_rate": 8.79748774509804e-06,
      "loss": 0.141,
      "step": 4533
    },
    {
      "epoch": 1.0418198529411764,
      "grad_norm": 1.662113070487976,
      "learning_rate": 8.796977124183007e-06,
      "loss": 0.1588,
      "step": 4534
    },
    {
      "epoch": 1.0420496323529411,
      "grad_norm": 1.5013858079910278,
      "learning_rate": 8.796466503267975e-06,
      "loss": 0.1551,
      "step": 4535
    },
    {
      "epoch": 1.0422794117647058,
      "grad_norm": 1.871755599975586,
      "learning_rate": 8.795955882352943e-06,
      "loss": 0.1568,
      "step": 4536
    },
    {
      "epoch": 1.0425091911764706,
      "grad_norm": 1.8478994369506836,
      "learning_rate": 8.795445261437909e-06,
      "loss": 0.1175,
      "step": 4537
    },
    {
      "epoch": 1.0427389705882353,
      "grad_norm": 1.4729795455932617,
      "learning_rate": 8.794934640522877e-06,
      "loss": 0.164,
      "step": 4538
    },
    {
      "epoch": 1.04296875,
      "grad_norm": 2.0292394161224365,
      "learning_rate": 8.794424019607843e-06,
      "loss": 0.1764,
      "step": 4539
    },
    {
      "epoch": 1.0431985294117647,
      "grad_norm": 1.8316653966903687,
      "learning_rate": 8.793913398692812e-06,
      "loss": 0.1358,
      "step": 4540
    },
    {
      "epoch": 1.0434283088235294,
      "grad_norm": 1.5261986255645752,
      "learning_rate": 8.793402777777778e-06,
      "loss": 0.1463,
      "step": 4541
    },
    {
      "epoch": 1.0436580882352942,
      "grad_norm": 1.225656270980835,
      "learning_rate": 8.792892156862746e-06,
      "loss": 0.1249,
      "step": 4542
    },
    {
      "epoch": 1.0438878676470589,
      "grad_norm": 1.4557021856307983,
      "learning_rate": 8.792381535947712e-06,
      "loss": 0.1538,
      "step": 4543
    },
    {
      "epoch": 1.0441176470588236,
      "grad_norm": 1.3241136074066162,
      "learning_rate": 8.79187091503268e-06,
      "loss": 0.121,
      "step": 4544
    },
    {
      "epoch": 1.0443474264705883,
      "grad_norm": 1.3726534843444824,
      "learning_rate": 8.791360294117648e-06,
      "loss": 0.1503,
      "step": 4545
    },
    {
      "epoch": 1.044577205882353,
      "grad_norm": 1.984018087387085,
      "learning_rate": 8.790849673202614e-06,
      "loss": 0.1329,
      "step": 4546
    },
    {
      "epoch": 1.0448069852941178,
      "grad_norm": 1.7024009227752686,
      "learning_rate": 8.790339052287582e-06,
      "loss": 0.1601,
      "step": 4547
    },
    {
      "epoch": 1.0450367647058822,
      "grad_norm": 1.820755124092102,
      "learning_rate": 8.78982843137255e-06,
      "loss": 0.1324,
      "step": 4548
    },
    {
      "epoch": 1.045266544117647,
      "grad_norm": 1.3660374879837036,
      "learning_rate": 8.789317810457518e-06,
      "loss": 0.1062,
      "step": 4549
    },
    {
      "epoch": 1.0454963235294117,
      "grad_norm": 1.6817896366119385,
      "learning_rate": 8.788807189542484e-06,
      "loss": 0.1367,
      "step": 4550
    },
    {
      "epoch": 1.0457261029411764,
      "grad_norm": 1.654844880104065,
      "learning_rate": 8.788296568627452e-06,
      "loss": 0.1673,
      "step": 4551
    },
    {
      "epoch": 1.0459558823529411,
      "grad_norm": 1.5659472942352295,
      "learning_rate": 8.78778594771242e-06,
      "loss": 0.1451,
      "step": 4552
    },
    {
      "epoch": 1.0461856617647058,
      "grad_norm": 1.8249890804290771,
      "learning_rate": 8.787275326797386e-06,
      "loss": 0.1447,
      "step": 4553
    },
    {
      "epoch": 1.0464154411764706,
      "grad_norm": 1.7008445262908936,
      "learning_rate": 8.786764705882354e-06,
      "loss": 0.1485,
      "step": 4554
    },
    {
      "epoch": 1.0466452205882353,
      "grad_norm": 1.6886241436004639,
      "learning_rate": 8.78625408496732e-06,
      "loss": 0.1257,
      "step": 4555
    },
    {
      "epoch": 1.046875,
      "grad_norm": 1.85317063331604,
      "learning_rate": 8.785743464052288e-06,
      "loss": 0.1605,
      "step": 4556
    },
    {
      "epoch": 1.0471047794117647,
      "grad_norm": 1.8331780433654785,
      "learning_rate": 8.785232843137256e-06,
      "loss": 0.1597,
      "step": 4557
    },
    {
      "epoch": 1.0473345588235294,
      "grad_norm": 1.8523961305618286,
      "learning_rate": 8.784722222222224e-06,
      "loss": 0.1355,
      "step": 4558
    },
    {
      "epoch": 1.0475643382352942,
      "grad_norm": 1.7661597728729248,
      "learning_rate": 8.78421160130719e-06,
      "loss": 0.1747,
      "step": 4559
    },
    {
      "epoch": 1.0477941176470589,
      "grad_norm": 1.7621614933013916,
      "learning_rate": 8.783700980392158e-06,
      "loss": 0.1469,
      "step": 4560
    },
    {
      "epoch": 1.0480238970588236,
      "grad_norm": 1.7858854532241821,
      "learning_rate": 8.783190359477126e-06,
      "loss": 0.168,
      "step": 4561
    },
    {
      "epoch": 1.0482536764705883,
      "grad_norm": 1.3955729007720947,
      "learning_rate": 8.782679738562092e-06,
      "loss": 0.1181,
      "step": 4562
    },
    {
      "epoch": 1.048483455882353,
      "grad_norm": 1.71657395362854,
      "learning_rate": 8.78216911764706e-06,
      "loss": 0.1136,
      "step": 4563
    },
    {
      "epoch": 1.0487132352941178,
      "grad_norm": 2.613326072692871,
      "learning_rate": 8.781658496732027e-06,
      "loss": 0.1589,
      "step": 4564
    },
    {
      "epoch": 1.0489430147058822,
      "grad_norm": 1.627501368522644,
      "learning_rate": 8.781147875816994e-06,
      "loss": 0.1197,
      "step": 4565
    },
    {
      "epoch": 1.049172794117647,
      "grad_norm": 1.7800662517547607,
      "learning_rate": 8.780637254901961e-06,
      "loss": 0.1257,
      "step": 4566
    },
    {
      "epoch": 1.0494025735294117,
      "grad_norm": 1.9000164270401,
      "learning_rate": 8.780126633986928e-06,
      "loss": 0.1645,
      "step": 4567
    },
    {
      "epoch": 1.0496323529411764,
      "grad_norm": 1.921940803527832,
      "learning_rate": 8.779616013071897e-06,
      "loss": 0.1573,
      "step": 4568
    },
    {
      "epoch": 1.0498621323529411,
      "grad_norm": 1.8417903184890747,
      "learning_rate": 8.779105392156863e-06,
      "loss": 0.1746,
      "step": 4569
    },
    {
      "epoch": 1.0500919117647058,
      "grad_norm": 2.004822254180908,
      "learning_rate": 8.778594771241831e-06,
      "loss": 0.1622,
      "step": 4570
    },
    {
      "epoch": 1.0503216911764706,
      "grad_norm": 1.8865225315093994,
      "learning_rate": 8.778084150326797e-06,
      "loss": 0.1602,
      "step": 4571
    },
    {
      "epoch": 1.0505514705882353,
      "grad_norm": 1.7164705991744995,
      "learning_rate": 8.777573529411765e-06,
      "loss": 0.1513,
      "step": 4572
    },
    {
      "epoch": 1.05078125,
      "grad_norm": 2.2091710567474365,
      "learning_rate": 8.777062908496733e-06,
      "loss": 0.1758,
      "step": 4573
    },
    {
      "epoch": 1.0510110294117647,
      "grad_norm": 1.3300880193710327,
      "learning_rate": 8.7765522875817e-06,
      "loss": 0.1606,
      "step": 4574
    },
    {
      "epoch": 1.0512408088235294,
      "grad_norm": 1.9578797817230225,
      "learning_rate": 8.776041666666667e-06,
      "loss": 0.1308,
      "step": 4575
    },
    {
      "epoch": 1.0514705882352942,
      "grad_norm": 2.0072031021118164,
      "learning_rate": 8.775531045751635e-06,
      "loss": 0.1466,
      "step": 4576
    },
    {
      "epoch": 1.0517003676470589,
      "grad_norm": 1.8110533952713013,
      "learning_rate": 8.775020424836603e-06,
      "loss": 0.1678,
      "step": 4577
    },
    {
      "epoch": 1.0519301470588236,
      "grad_norm": 1.8126933574676514,
      "learning_rate": 8.774509803921569e-06,
      "loss": 0.1553,
      "step": 4578
    },
    {
      "epoch": 1.0521599264705883,
      "grad_norm": 1.4876832962036133,
      "learning_rate": 8.773999183006537e-06,
      "loss": 0.1407,
      "step": 4579
    },
    {
      "epoch": 1.052389705882353,
      "grad_norm": 1.8269425630569458,
      "learning_rate": 8.773488562091505e-06,
      "loss": 0.1356,
      "step": 4580
    },
    {
      "epoch": 1.0526194852941178,
      "grad_norm": 1.7627341747283936,
      "learning_rate": 8.772977941176471e-06,
      "loss": 0.1668,
      "step": 4581
    },
    {
      "epoch": 1.0528492647058822,
      "grad_norm": 1.6121516227722168,
      "learning_rate": 8.772467320261439e-06,
      "loss": 0.133,
      "step": 4582
    },
    {
      "epoch": 1.053079044117647,
      "grad_norm": 1.6540030241012573,
      "learning_rate": 8.771956699346405e-06,
      "loss": 0.1514,
      "step": 4583
    },
    {
      "epoch": 1.0533088235294117,
      "grad_norm": 1.6850879192352295,
      "learning_rate": 8.771446078431374e-06,
      "loss": 0.1733,
      "step": 4584
    },
    {
      "epoch": 1.0535386029411764,
      "grad_norm": 1.8484466075897217,
      "learning_rate": 8.77093545751634e-06,
      "loss": 0.1436,
      "step": 4585
    },
    {
      "epoch": 1.0537683823529411,
      "grad_norm": 1.8033690452575684,
      "learning_rate": 8.770424836601308e-06,
      "loss": 0.1477,
      "step": 4586
    },
    {
      "epoch": 1.0539981617647058,
      "grad_norm": 1.345884084701538,
      "learning_rate": 8.769914215686275e-06,
      "loss": 0.1387,
      "step": 4587
    },
    {
      "epoch": 1.0542279411764706,
      "grad_norm": 1.6701486110687256,
      "learning_rate": 8.769403594771243e-06,
      "loss": 0.1315,
      "step": 4588
    },
    {
      "epoch": 1.0544577205882353,
      "grad_norm": 1.5798001289367676,
      "learning_rate": 8.76889297385621e-06,
      "loss": 0.1418,
      "step": 4589
    },
    {
      "epoch": 1.0546875,
      "grad_norm": 1.5616899728775024,
      "learning_rate": 8.768382352941177e-06,
      "loss": 0.1597,
      "step": 4590
    },
    {
      "epoch": 1.0549172794117647,
      "grad_norm": 1.3163397312164307,
      "learning_rate": 8.767871732026144e-06,
      "loss": 0.1114,
      "step": 4591
    },
    {
      "epoch": 1.0551470588235294,
      "grad_norm": 1.4213483333587646,
      "learning_rate": 8.767361111111112e-06,
      "loss": 0.1755,
      "step": 4592
    },
    {
      "epoch": 1.0553768382352942,
      "grad_norm": 1.7850579023361206,
      "learning_rate": 8.76685049019608e-06,
      "loss": 0.1615,
      "step": 4593
    },
    {
      "epoch": 1.0556066176470589,
      "grad_norm": 1.4574272632598877,
      "learning_rate": 8.766339869281046e-06,
      "loss": 0.1083,
      "step": 4594
    },
    {
      "epoch": 1.0558363970588236,
      "grad_norm": 1.5823973417282104,
      "learning_rate": 8.765829248366014e-06,
      "loss": 0.1467,
      "step": 4595
    },
    {
      "epoch": 1.0560661764705883,
      "grad_norm": 1.9523704051971436,
      "learning_rate": 8.765318627450982e-06,
      "loss": 0.1903,
      "step": 4596
    },
    {
      "epoch": 1.056295955882353,
      "grad_norm": 1.7168337106704712,
      "learning_rate": 8.764808006535948e-06,
      "loss": 0.1347,
      "step": 4597
    },
    {
      "epoch": 1.0565257352941178,
      "grad_norm": 2.458346128463745,
      "learning_rate": 8.764297385620916e-06,
      "loss": 0.1997,
      "step": 4598
    },
    {
      "epoch": 1.0567555147058822,
      "grad_norm": 1.515186071395874,
      "learning_rate": 8.763786764705882e-06,
      "loss": 0.1262,
      "step": 4599
    },
    {
      "epoch": 1.056985294117647,
      "grad_norm": 2.3079092502593994,
      "learning_rate": 8.76327614379085e-06,
      "loss": 0.1757,
      "step": 4600
    },
    {
      "epoch": 1.0572150735294117,
      "grad_norm": 1.6156870126724243,
      "learning_rate": 8.762765522875818e-06,
      "loss": 0.1259,
      "step": 4601
    },
    {
      "epoch": 1.0574448529411764,
      "grad_norm": 1.737514615058899,
      "learning_rate": 8.762254901960786e-06,
      "loss": 0.1661,
      "step": 4602
    },
    {
      "epoch": 1.0576746323529411,
      "grad_norm": 2.0039756298065186,
      "learning_rate": 8.761744281045752e-06,
      "loss": 0.1633,
      "step": 4603
    },
    {
      "epoch": 1.0579044117647058,
      "grad_norm": 1.3052029609680176,
      "learning_rate": 8.76123366013072e-06,
      "loss": 0.1354,
      "step": 4604
    },
    {
      "epoch": 1.0581341911764706,
      "grad_norm": 1.7314783334732056,
      "learning_rate": 8.760723039215688e-06,
      "loss": 0.1296,
      "step": 4605
    },
    {
      "epoch": 1.0583639705882353,
      "grad_norm": 1.2756184339523315,
      "learning_rate": 8.760212418300654e-06,
      "loss": 0.117,
      "step": 4606
    },
    {
      "epoch": 1.05859375,
      "grad_norm": 1.8109803199768066,
      "learning_rate": 8.759701797385622e-06,
      "loss": 0.1375,
      "step": 4607
    },
    {
      "epoch": 1.0588235294117647,
      "grad_norm": 2.200936794281006,
      "learning_rate": 8.75919117647059e-06,
      "loss": 0.1786,
      "step": 4608
    },
    {
      "epoch": 1.0590533088235294,
      "grad_norm": 1.4292917251586914,
      "learning_rate": 8.758680555555556e-06,
      "loss": 0.1175,
      "step": 4609
    },
    {
      "epoch": 1.0592830882352942,
      "grad_norm": 1.7220638990402222,
      "learning_rate": 8.758169934640524e-06,
      "loss": 0.1698,
      "step": 4610
    },
    {
      "epoch": 1.0595128676470589,
      "grad_norm": 1.758817434310913,
      "learning_rate": 8.75765931372549e-06,
      "loss": 0.143,
      "step": 4611
    },
    {
      "epoch": 1.0597426470588236,
      "grad_norm": 1.6393444538116455,
      "learning_rate": 8.75714869281046e-06,
      "loss": 0.1379,
      "step": 4612
    },
    {
      "epoch": 1.0599724264705883,
      "grad_norm": 1.6576213836669922,
      "learning_rate": 8.756638071895426e-06,
      "loss": 0.1425,
      "step": 4613
    },
    {
      "epoch": 1.060202205882353,
      "grad_norm": 1.6095372438430786,
      "learning_rate": 8.756127450980393e-06,
      "loss": 0.1457,
      "step": 4614
    },
    {
      "epoch": 1.0604319852941178,
      "grad_norm": 1.9924499988555908,
      "learning_rate": 8.75561683006536e-06,
      "loss": 0.2358,
      "step": 4615
    },
    {
      "epoch": 1.0606617647058822,
      "grad_norm": 1.4198250770568848,
      "learning_rate": 8.755106209150327e-06,
      "loss": 0.175,
      "step": 4616
    },
    {
      "epoch": 1.060891544117647,
      "grad_norm": 2.1577417850494385,
      "learning_rate": 8.754595588235295e-06,
      "loss": 0.1455,
      "step": 4617
    },
    {
      "epoch": 1.0611213235294117,
      "grad_norm": 2.653461456298828,
      "learning_rate": 8.754084967320261e-06,
      "loss": 0.1778,
      "step": 4618
    },
    {
      "epoch": 1.0613511029411764,
      "grad_norm": 1.5794034004211426,
      "learning_rate": 8.75357434640523e-06,
      "loss": 0.1667,
      "step": 4619
    },
    {
      "epoch": 1.0615808823529411,
      "grad_norm": 1.3045299053192139,
      "learning_rate": 8.753063725490197e-06,
      "loss": 0.1022,
      "step": 4620
    },
    {
      "epoch": 1.0618106617647058,
      "grad_norm": 1.741489291191101,
      "learning_rate": 8.752553104575165e-06,
      "loss": 0.1532,
      "step": 4621
    },
    {
      "epoch": 1.0620404411764706,
      "grad_norm": 1.3344439268112183,
      "learning_rate": 8.752042483660131e-06,
      "loss": 0.1374,
      "step": 4622
    },
    {
      "epoch": 1.0622702205882353,
      "grad_norm": 1.4802567958831787,
      "learning_rate": 8.751531862745099e-06,
      "loss": 0.1176,
      "step": 4623
    },
    {
      "epoch": 1.0625,
      "grad_norm": 1.3610584735870361,
      "learning_rate": 8.751021241830067e-06,
      "loss": 0.1092,
      "step": 4624
    },
    {
      "epoch": 1.0627297794117647,
      "grad_norm": 1.5181161165237427,
      "learning_rate": 8.750510620915033e-06,
      "loss": 0.1525,
      "step": 4625
    },
    {
      "epoch": 1.0629595588235294,
      "grad_norm": 1.3680458068847656,
      "learning_rate": 8.750000000000001e-06,
      "loss": 0.1025,
      "step": 4626
    },
    {
      "epoch": 1.0631893382352942,
      "grad_norm": 1.4960784912109375,
      "learning_rate": 8.749489379084967e-06,
      "loss": 0.1477,
      "step": 4627
    },
    {
      "epoch": 1.0634191176470589,
      "grad_norm": 1.7953202724456787,
      "learning_rate": 8.748978758169935e-06,
      "loss": 0.1425,
      "step": 4628
    },
    {
      "epoch": 1.0636488970588236,
      "grad_norm": 2.624861717224121,
      "learning_rate": 8.748468137254903e-06,
      "loss": 0.1787,
      "step": 4629
    },
    {
      "epoch": 1.0638786764705883,
      "grad_norm": 1.4212055206298828,
      "learning_rate": 8.74795751633987e-06,
      "loss": 0.1224,
      "step": 4630
    },
    {
      "epoch": 1.064108455882353,
      "grad_norm": 1.578969120979309,
      "learning_rate": 8.747446895424837e-06,
      "loss": 0.154,
      "step": 4631
    },
    {
      "epoch": 1.0643382352941178,
      "grad_norm": 1.6387301683425903,
      "learning_rate": 8.746936274509805e-06,
      "loss": 0.1604,
      "step": 4632
    },
    {
      "epoch": 1.0645680147058822,
      "grad_norm": 1.3705487251281738,
      "learning_rate": 8.746425653594773e-06,
      "loss": 0.1158,
      "step": 4633
    },
    {
      "epoch": 1.064797794117647,
      "grad_norm": 1.8772832155227661,
      "learning_rate": 8.745915032679739e-06,
      "loss": 0.2075,
      "step": 4634
    },
    {
      "epoch": 1.0650275735294117,
      "grad_norm": 1.6955928802490234,
      "learning_rate": 8.745404411764707e-06,
      "loss": 0.1258,
      "step": 4635
    },
    {
      "epoch": 1.0652573529411764,
      "grad_norm": 1.7651829719543457,
      "learning_rate": 8.744893790849673e-06,
      "loss": 0.1461,
      "step": 4636
    },
    {
      "epoch": 1.0654871323529411,
      "grad_norm": 1.5165044069290161,
      "learning_rate": 8.744383169934642e-06,
      "loss": 0.1014,
      "step": 4637
    },
    {
      "epoch": 1.0657169117647058,
      "grad_norm": 1.4958215951919556,
      "learning_rate": 8.743872549019608e-06,
      "loss": 0.1266,
      "step": 4638
    },
    {
      "epoch": 1.0659466911764706,
      "grad_norm": 1.6331387758255005,
      "learning_rate": 8.743361928104576e-06,
      "loss": 0.1609,
      "step": 4639
    },
    {
      "epoch": 1.0661764705882353,
      "grad_norm": 2.010723114013672,
      "learning_rate": 8.742851307189543e-06,
      "loss": 0.1808,
      "step": 4640
    },
    {
      "epoch": 1.06640625,
      "grad_norm": 1.9051226377487183,
      "learning_rate": 8.74234068627451e-06,
      "loss": 0.1821,
      "step": 4641
    },
    {
      "epoch": 1.0666360294117647,
      "grad_norm": 1.2553423643112183,
      "learning_rate": 8.741830065359478e-06,
      "loss": 0.1291,
      "step": 4642
    },
    {
      "epoch": 1.0668658088235294,
      "grad_norm": 1.4108754396438599,
      "learning_rate": 8.741319444444444e-06,
      "loss": 0.109,
      "step": 4643
    },
    {
      "epoch": 1.0670955882352942,
      "grad_norm": 1.8002372980117798,
      "learning_rate": 8.740808823529412e-06,
      "loss": 0.1841,
      "step": 4644
    },
    {
      "epoch": 1.0673253676470589,
      "grad_norm": 1.7774631977081299,
      "learning_rate": 8.74029820261438e-06,
      "loss": 0.1555,
      "step": 4645
    },
    {
      "epoch": 1.0675551470588236,
      "grad_norm": 1.6464375257492065,
      "learning_rate": 8.739787581699348e-06,
      "loss": 0.1455,
      "step": 4646
    },
    {
      "epoch": 1.0677849264705883,
      "grad_norm": 1.9490422010421753,
      "learning_rate": 8.739276960784314e-06,
      "loss": 0.1833,
      "step": 4647
    },
    {
      "epoch": 1.068014705882353,
      "grad_norm": 1.91175377368927,
      "learning_rate": 8.738766339869282e-06,
      "loss": 0.1297,
      "step": 4648
    },
    {
      "epoch": 1.0682444852941178,
      "grad_norm": 1.3853527307510376,
      "learning_rate": 8.73825571895425e-06,
      "loss": 0.1414,
      "step": 4649
    },
    {
      "epoch": 1.0684742647058822,
      "grad_norm": 1.5252175331115723,
      "learning_rate": 8.737745098039216e-06,
      "loss": 0.121,
      "step": 4650
    },
    {
      "epoch": 1.068704044117647,
      "grad_norm": 1.9975472688674927,
      "learning_rate": 8.737234477124184e-06,
      "loss": 0.1871,
      "step": 4651
    },
    {
      "epoch": 1.0689338235294117,
      "grad_norm": 1.7877726554870605,
      "learning_rate": 8.73672385620915e-06,
      "loss": 0.1341,
      "step": 4652
    },
    {
      "epoch": 1.0691636029411764,
      "grad_norm": 1.8232378959655762,
      "learning_rate": 8.736213235294118e-06,
      "loss": 0.1388,
      "step": 4653
    },
    {
      "epoch": 1.0693933823529411,
      "grad_norm": 1.5640610456466675,
      "learning_rate": 8.735702614379086e-06,
      "loss": 0.1484,
      "step": 4654
    },
    {
      "epoch": 1.0696231617647058,
      "grad_norm": 1.6421607732772827,
      "learning_rate": 8.735191993464052e-06,
      "loss": 0.1696,
      "step": 4655
    },
    {
      "epoch": 1.0698529411764706,
      "grad_norm": 1.5339094400405884,
      "learning_rate": 8.73468137254902e-06,
      "loss": 0.1966,
      "step": 4656
    },
    {
      "epoch": 1.0700827205882353,
      "grad_norm": 1.6675530672073364,
      "learning_rate": 8.734170751633988e-06,
      "loss": 0.1481,
      "step": 4657
    },
    {
      "epoch": 1.0703125,
      "grad_norm": 1.499820590019226,
      "learning_rate": 8.733660130718956e-06,
      "loss": 0.1605,
      "step": 4658
    },
    {
      "epoch": 1.0705422794117647,
      "grad_norm": 1.6360466480255127,
      "learning_rate": 8.733149509803922e-06,
      "loss": 0.1466,
      "step": 4659
    },
    {
      "epoch": 1.0707720588235294,
      "grad_norm": 1.4081804752349854,
      "learning_rate": 8.73263888888889e-06,
      "loss": 0.1223,
      "step": 4660
    },
    {
      "epoch": 1.0710018382352942,
      "grad_norm": 2.636087656021118,
      "learning_rate": 8.732128267973857e-06,
      "loss": 0.1966,
      "step": 4661
    },
    {
      "epoch": 1.0712316176470589,
      "grad_norm": 1.754561424255371,
      "learning_rate": 8.731617647058824e-06,
      "loss": 0.1427,
      "step": 4662
    },
    {
      "epoch": 1.0714613970588236,
      "grad_norm": 1.7305301427841187,
      "learning_rate": 8.731107026143791e-06,
      "loss": 0.1638,
      "step": 4663
    },
    {
      "epoch": 1.0716911764705883,
      "grad_norm": 1.7863954305648804,
      "learning_rate": 8.730596405228758e-06,
      "loss": 0.1761,
      "step": 4664
    },
    {
      "epoch": 1.071920955882353,
      "grad_norm": 1.7882217168807983,
      "learning_rate": 8.730085784313727e-06,
      "loss": 0.127,
      "step": 4665
    },
    {
      "epoch": 1.0721507352941178,
      "grad_norm": 1.6558024883270264,
      "learning_rate": 8.729575163398693e-06,
      "loss": 0.1322,
      "step": 4666
    },
    {
      "epoch": 1.0723805147058822,
      "grad_norm": 1.8886395692825317,
      "learning_rate": 8.729064542483661e-06,
      "loss": 0.1968,
      "step": 4667
    },
    {
      "epoch": 1.072610294117647,
      "grad_norm": 1.5277514457702637,
      "learning_rate": 8.728553921568627e-06,
      "loss": 0.1259,
      "step": 4668
    },
    {
      "epoch": 1.0728400735294117,
      "grad_norm": 1.5222889184951782,
      "learning_rate": 8.728043300653595e-06,
      "loss": 0.1206,
      "step": 4669
    },
    {
      "epoch": 1.0730698529411764,
      "grad_norm": 2.096329927444458,
      "learning_rate": 8.727532679738563e-06,
      "loss": 0.1508,
      "step": 4670
    },
    {
      "epoch": 1.0732996323529411,
      "grad_norm": 2.495516538619995,
      "learning_rate": 8.72702205882353e-06,
      "loss": 0.2313,
      "step": 4671
    },
    {
      "epoch": 1.0735294117647058,
      "grad_norm": 1.7140319347381592,
      "learning_rate": 8.726511437908497e-06,
      "loss": 0.1488,
      "step": 4672
    },
    {
      "epoch": 1.0737591911764706,
      "grad_norm": 1.749719500541687,
      "learning_rate": 8.726000816993465e-06,
      "loss": 0.162,
      "step": 4673
    },
    {
      "epoch": 1.0739889705882353,
      "grad_norm": 1.6577589511871338,
      "learning_rate": 8.725490196078433e-06,
      "loss": 0.1314,
      "step": 4674
    },
    {
      "epoch": 1.07421875,
      "grad_norm": 1.749321699142456,
      "learning_rate": 8.724979575163399e-06,
      "loss": 0.167,
      "step": 4675
    },
    {
      "epoch": 1.0744485294117647,
      "grad_norm": 1.5687284469604492,
      "learning_rate": 8.724468954248367e-06,
      "loss": 0.1402,
      "step": 4676
    },
    {
      "epoch": 1.0746783088235294,
      "grad_norm": 1.722168207168579,
      "learning_rate": 8.723958333333335e-06,
      "loss": 0.1459,
      "step": 4677
    },
    {
      "epoch": 1.0749080882352942,
      "grad_norm": 1.786832571029663,
      "learning_rate": 8.723447712418301e-06,
      "loss": 0.1456,
      "step": 4678
    },
    {
      "epoch": 1.0751378676470589,
      "grad_norm": 1.7063379287719727,
      "learning_rate": 8.722937091503269e-06,
      "loss": 0.123,
      "step": 4679
    },
    {
      "epoch": 1.0753676470588236,
      "grad_norm": 1.7486021518707275,
      "learning_rate": 8.722426470588235e-06,
      "loss": 0.1461,
      "step": 4680
    },
    {
      "epoch": 1.0755974264705883,
      "grad_norm": 1.695703148841858,
      "learning_rate": 8.721915849673205e-06,
      "loss": 0.1649,
      "step": 4681
    },
    {
      "epoch": 1.075827205882353,
      "grad_norm": 1.9088977575302124,
      "learning_rate": 8.72140522875817e-06,
      "loss": 0.1422,
      "step": 4682
    },
    {
      "epoch": 1.0760569852941178,
      "grad_norm": 1.5017513036727905,
      "learning_rate": 8.720894607843139e-06,
      "loss": 0.1518,
      "step": 4683
    },
    {
      "epoch": 1.0762867647058822,
      "grad_norm": 2.0225346088409424,
      "learning_rate": 8.720383986928105e-06,
      "loss": 0.1983,
      "step": 4684
    },
    {
      "epoch": 1.076516544117647,
      "grad_norm": 1.7547634840011597,
      "learning_rate": 8.719873366013073e-06,
      "loss": 0.1449,
      "step": 4685
    },
    {
      "epoch": 1.0767463235294117,
      "grad_norm": 1.8868075609207153,
      "learning_rate": 8.71936274509804e-06,
      "loss": 0.1322,
      "step": 4686
    },
    {
      "epoch": 1.0769761029411764,
      "grad_norm": 1.3501628637313843,
      "learning_rate": 8.718852124183007e-06,
      "loss": 0.1371,
      "step": 4687
    },
    {
      "epoch": 1.0772058823529411,
      "grad_norm": 2.3238186836242676,
      "learning_rate": 8.718341503267974e-06,
      "loss": 0.2042,
      "step": 4688
    },
    {
      "epoch": 1.0774356617647058,
      "grad_norm": 1.4368195533752441,
      "learning_rate": 8.717830882352942e-06,
      "loss": 0.1625,
      "step": 4689
    },
    {
      "epoch": 1.0776654411764706,
      "grad_norm": 1.6432304382324219,
      "learning_rate": 8.717320261437908e-06,
      "loss": 0.188,
      "step": 4690
    },
    {
      "epoch": 1.0778952205882353,
      "grad_norm": 1.7989046573638916,
      "learning_rate": 8.716809640522876e-06,
      "loss": 0.1831,
      "step": 4691
    },
    {
      "epoch": 1.078125,
      "grad_norm": 1.3618779182434082,
      "learning_rate": 8.716299019607844e-06,
      "loss": 0.1429,
      "step": 4692
    },
    {
      "epoch": 1.0783547794117647,
      "grad_norm": 1.542172908782959,
      "learning_rate": 8.715788398692812e-06,
      "loss": 0.1205,
      "step": 4693
    },
    {
      "epoch": 1.0785845588235294,
      "grad_norm": 1.6711492538452148,
      "learning_rate": 8.715277777777778e-06,
      "loss": 0.1458,
      "step": 4694
    },
    {
      "epoch": 1.0788143382352942,
      "grad_norm": 1.5184723138809204,
      "learning_rate": 8.714767156862746e-06,
      "loss": 0.1419,
      "step": 4695
    },
    {
      "epoch": 1.0790441176470589,
      "grad_norm": 1.3411624431610107,
      "learning_rate": 8.714256535947712e-06,
      "loss": 0.1361,
      "step": 4696
    },
    {
      "epoch": 1.0792738970588236,
      "grad_norm": 1.705675721168518,
      "learning_rate": 8.71374591503268e-06,
      "loss": 0.1111,
      "step": 4697
    },
    {
      "epoch": 1.0795036764705883,
      "grad_norm": 1.7642446756362915,
      "learning_rate": 8.713235294117648e-06,
      "loss": 0.174,
      "step": 4698
    },
    {
      "epoch": 1.079733455882353,
      "grad_norm": 1.4409562349319458,
      "learning_rate": 8.712724673202614e-06,
      "loss": 0.157,
      "step": 4699
    },
    {
      "epoch": 1.0799632352941178,
      "grad_norm": 1.5345350503921509,
      "learning_rate": 8.712214052287582e-06,
      "loss": 0.1753,
      "step": 4700
    },
    {
      "epoch": 1.0801930147058822,
      "grad_norm": 1.3445451259613037,
      "learning_rate": 8.71170343137255e-06,
      "loss": 0.1133,
      "step": 4701
    },
    {
      "epoch": 1.080422794117647,
      "grad_norm": 1.494449496269226,
      "learning_rate": 8.711192810457518e-06,
      "loss": 0.1579,
      "step": 4702
    },
    {
      "epoch": 1.0806525735294117,
      "grad_norm": 1.7763302326202393,
      "learning_rate": 8.710682189542484e-06,
      "loss": 0.1395,
      "step": 4703
    },
    {
      "epoch": 1.0808823529411764,
      "grad_norm": 1.951449990272522,
      "learning_rate": 8.710171568627452e-06,
      "loss": 0.1062,
      "step": 4704
    },
    {
      "epoch": 1.0811121323529411,
      "grad_norm": 1.7773513793945312,
      "learning_rate": 8.70966094771242e-06,
      "loss": 0.1461,
      "step": 4705
    },
    {
      "epoch": 1.0813419117647058,
      "grad_norm": 1.7494555711746216,
      "learning_rate": 8.709150326797386e-06,
      "loss": 0.1155,
      "step": 4706
    },
    {
      "epoch": 1.0815716911764706,
      "grad_norm": 1.2699573040008545,
      "learning_rate": 8.708639705882354e-06,
      "loss": 0.1441,
      "step": 4707
    },
    {
      "epoch": 1.0818014705882353,
      "grad_norm": 1.7138744592666626,
      "learning_rate": 8.70812908496732e-06,
      "loss": 0.1347,
      "step": 4708
    },
    {
      "epoch": 1.08203125,
      "grad_norm": 1.8777199983596802,
      "learning_rate": 8.70761846405229e-06,
      "loss": 0.1737,
      "step": 4709
    },
    {
      "epoch": 1.0822610294117647,
      "grad_norm": 1.514357089996338,
      "learning_rate": 8.707107843137256e-06,
      "loss": 0.1491,
      "step": 4710
    },
    {
      "epoch": 1.0824908088235294,
      "grad_norm": 2.0520565509796143,
      "learning_rate": 8.706597222222223e-06,
      "loss": 0.1511,
      "step": 4711
    },
    {
      "epoch": 1.0827205882352942,
      "grad_norm": 1.4058791399002075,
      "learning_rate": 8.70608660130719e-06,
      "loss": 0.1203,
      "step": 4712
    },
    {
      "epoch": 1.0829503676470589,
      "grad_norm": 1.5611647367477417,
      "learning_rate": 8.705575980392157e-06,
      "loss": 0.1482,
      "step": 4713
    },
    {
      "epoch": 1.0831801470588236,
      "grad_norm": 1.1683779954910278,
      "learning_rate": 8.705065359477125e-06,
      "loss": 0.1398,
      "step": 4714
    },
    {
      "epoch": 1.0834099264705883,
      "grad_norm": 1.4703497886657715,
      "learning_rate": 8.704554738562091e-06,
      "loss": 0.1567,
      "step": 4715
    },
    {
      "epoch": 1.083639705882353,
      "grad_norm": 1.6163861751556396,
      "learning_rate": 8.70404411764706e-06,
      "loss": 0.1121,
      "step": 4716
    },
    {
      "epoch": 1.0838694852941178,
      "grad_norm": 1.6254971027374268,
      "learning_rate": 8.703533496732027e-06,
      "loss": 0.1584,
      "step": 4717
    },
    {
      "epoch": 1.0840992647058822,
      "grad_norm": 1.7383360862731934,
      "learning_rate": 8.703022875816995e-06,
      "loss": 0.167,
      "step": 4718
    },
    {
      "epoch": 1.084329044117647,
      "grad_norm": 1.7993907928466797,
      "learning_rate": 8.702512254901961e-06,
      "loss": 0.1609,
      "step": 4719
    },
    {
      "epoch": 1.0845588235294117,
      "grad_norm": 2.4151158332824707,
      "learning_rate": 8.702001633986929e-06,
      "loss": 0.1719,
      "step": 4720
    },
    {
      "epoch": 1.0847886029411764,
      "grad_norm": 1.6618561744689941,
      "learning_rate": 8.701491013071897e-06,
      "loss": 0.1687,
      "step": 4721
    },
    {
      "epoch": 1.0850183823529411,
      "grad_norm": 2.591766119003296,
      "learning_rate": 8.700980392156863e-06,
      "loss": 0.1602,
      "step": 4722
    },
    {
      "epoch": 1.0852481617647058,
      "grad_norm": 1.5093046426773071,
      "learning_rate": 8.700469771241831e-06,
      "loss": 0.1513,
      "step": 4723
    },
    {
      "epoch": 1.0854779411764706,
      "grad_norm": 1.760537028312683,
      "learning_rate": 8.699959150326797e-06,
      "loss": 0.1692,
      "step": 4724
    },
    {
      "epoch": 1.0857077205882353,
      "grad_norm": 2.02374267578125,
      "learning_rate": 8.699448529411767e-06,
      "loss": 0.1535,
      "step": 4725
    },
    {
      "epoch": 1.0859375,
      "grad_norm": 1.5382335186004639,
      "learning_rate": 8.698937908496733e-06,
      "loss": 0.1467,
      "step": 4726
    },
    {
      "epoch": 1.0861672794117647,
      "grad_norm": 1.3751680850982666,
      "learning_rate": 8.6984272875817e-06,
      "loss": 0.1234,
      "step": 4727
    },
    {
      "epoch": 1.0863970588235294,
      "grad_norm": 1.7365105152130127,
      "learning_rate": 8.697916666666667e-06,
      "loss": 0.1222,
      "step": 4728
    },
    {
      "epoch": 1.0866268382352942,
      "grad_norm": 1.5877681970596313,
      "learning_rate": 8.697406045751635e-06,
      "loss": 0.157,
      "step": 4729
    },
    {
      "epoch": 1.0868566176470589,
      "grad_norm": 2.076720952987671,
      "learning_rate": 8.696895424836603e-06,
      "loss": 0.1745,
      "step": 4730
    },
    {
      "epoch": 1.0870863970588236,
      "grad_norm": 1.7103840112686157,
      "learning_rate": 8.696384803921569e-06,
      "loss": 0.145,
      "step": 4731
    },
    {
      "epoch": 1.0873161764705883,
      "grad_norm": 1.7421815395355225,
      "learning_rate": 8.695874183006537e-06,
      "loss": 0.1326,
      "step": 4732
    },
    {
      "epoch": 1.087545955882353,
      "grad_norm": 1.8845171928405762,
      "learning_rate": 8.695363562091505e-06,
      "loss": 0.1149,
      "step": 4733
    },
    {
      "epoch": 1.0877757352941178,
      "grad_norm": 1.842330813407898,
      "learning_rate": 8.69485294117647e-06,
      "loss": 0.1424,
      "step": 4734
    },
    {
      "epoch": 1.0880055147058822,
      "grad_norm": 1.4227676391601562,
      "learning_rate": 8.694342320261439e-06,
      "loss": 0.1615,
      "step": 4735
    },
    {
      "epoch": 1.088235294117647,
      "grad_norm": 1.925954818725586,
      "learning_rate": 8.693831699346406e-06,
      "loss": 0.1428,
      "step": 4736
    },
    {
      "epoch": 1.0884650735294117,
      "grad_norm": 1.4555490016937256,
      "learning_rate": 8.693321078431374e-06,
      "loss": 0.1016,
      "step": 4737
    },
    {
      "epoch": 1.0886948529411764,
      "grad_norm": 1.4881446361541748,
      "learning_rate": 8.69281045751634e-06,
      "loss": 0.1455,
      "step": 4738
    },
    {
      "epoch": 1.0889246323529411,
      "grad_norm": 1.5679779052734375,
      "learning_rate": 8.692299836601308e-06,
      "loss": 0.1527,
      "step": 4739
    },
    {
      "epoch": 1.0891544117647058,
      "grad_norm": 1.9148691892623901,
      "learning_rate": 8.691789215686274e-06,
      "loss": 0.1702,
      "step": 4740
    },
    {
      "epoch": 1.0893841911764706,
      "grad_norm": 1.8437151908874512,
      "learning_rate": 8.691278594771242e-06,
      "loss": 0.1283,
      "step": 4741
    },
    {
      "epoch": 1.0896139705882353,
      "grad_norm": 1.5735547542572021,
      "learning_rate": 8.69076797385621e-06,
      "loss": 0.1622,
      "step": 4742
    },
    {
      "epoch": 1.08984375,
      "grad_norm": 1.7210211753845215,
      "learning_rate": 8.690257352941176e-06,
      "loss": 0.1352,
      "step": 4743
    },
    {
      "epoch": 1.0900735294117647,
      "grad_norm": 1.7486995458602905,
      "learning_rate": 8.689746732026144e-06,
      "loss": 0.1518,
      "step": 4744
    },
    {
      "epoch": 1.0903033088235294,
      "grad_norm": 1.5810799598693848,
      "learning_rate": 8.689236111111112e-06,
      "loss": 0.1431,
      "step": 4745
    },
    {
      "epoch": 1.0905330882352942,
      "grad_norm": 2.275509834289551,
      "learning_rate": 8.68872549019608e-06,
      "loss": 0.2313,
      "step": 4746
    },
    {
      "epoch": 1.0907628676470589,
      "grad_norm": 1.7639687061309814,
      "learning_rate": 8.688214869281046e-06,
      "loss": 0.141,
      "step": 4747
    },
    {
      "epoch": 1.0909926470588236,
      "grad_norm": 1.9747921228408813,
      "learning_rate": 8.687704248366014e-06,
      "loss": 0.1525,
      "step": 4748
    },
    {
      "epoch": 1.0912224264705883,
      "grad_norm": 1.4119185209274292,
      "learning_rate": 8.687193627450982e-06,
      "loss": 0.116,
      "step": 4749
    },
    {
      "epoch": 1.091452205882353,
      "grad_norm": 1.4753285646438599,
      "learning_rate": 8.686683006535948e-06,
      "loss": 0.1906,
      "step": 4750
    },
    {
      "epoch": 1.0916819852941178,
      "grad_norm": 1.6794945001602173,
      "learning_rate": 8.686172385620916e-06,
      "loss": 0.1354,
      "step": 4751
    },
    {
      "epoch": 1.0919117647058822,
      "grad_norm": 1.407702088356018,
      "learning_rate": 8.685661764705882e-06,
      "loss": 0.1154,
      "step": 4752
    },
    {
      "epoch": 1.092141544117647,
      "grad_norm": 1.937757134437561,
      "learning_rate": 8.685151143790852e-06,
      "loss": 0.1325,
      "step": 4753
    },
    {
      "epoch": 1.0923713235294117,
      "grad_norm": 2.168372392654419,
      "learning_rate": 8.684640522875818e-06,
      "loss": 0.1468,
      "step": 4754
    },
    {
      "epoch": 1.0926011029411764,
      "grad_norm": 1.8400070667266846,
      "learning_rate": 8.684129901960786e-06,
      "loss": 0.1197,
      "step": 4755
    },
    {
      "epoch": 1.0928308823529411,
      "grad_norm": 1.4982595443725586,
      "learning_rate": 8.683619281045752e-06,
      "loss": 0.1514,
      "step": 4756
    },
    {
      "epoch": 1.0930606617647058,
      "grad_norm": 1.8898720741271973,
      "learning_rate": 8.68310866013072e-06,
      "loss": 0.1656,
      "step": 4757
    },
    {
      "epoch": 1.0932904411764706,
      "grad_norm": 1.6683028936386108,
      "learning_rate": 8.682598039215687e-06,
      "loss": 0.1631,
      "step": 4758
    },
    {
      "epoch": 1.0935202205882353,
      "grad_norm": 1.598228096961975,
      "learning_rate": 8.682087418300654e-06,
      "loss": 0.1292,
      "step": 4759
    },
    {
      "epoch": 1.09375,
      "grad_norm": 2.031447172164917,
      "learning_rate": 8.681576797385622e-06,
      "loss": 0.1471,
      "step": 4760
    },
    {
      "epoch": 1.0939797794117647,
      "grad_norm": 1.827945351600647,
      "learning_rate": 8.68106617647059e-06,
      "loss": 0.1588,
      "step": 4761
    },
    {
      "epoch": 1.0942095588235294,
      "grad_norm": 1.7160083055496216,
      "learning_rate": 8.680555555555557e-06,
      "loss": 0.1146,
      "step": 4762
    },
    {
      "epoch": 1.0944393382352942,
      "grad_norm": 2.727937698364258,
      "learning_rate": 8.680044934640523e-06,
      "loss": 0.1564,
      "step": 4763
    },
    {
      "epoch": 1.0946691176470589,
      "grad_norm": 1.666055679321289,
      "learning_rate": 8.679534313725491e-06,
      "loss": 0.134,
      "step": 4764
    },
    {
      "epoch": 1.0948988970588236,
      "grad_norm": 1.5884004831314087,
      "learning_rate": 8.679023692810459e-06,
      "loss": 0.1369,
      "step": 4765
    },
    {
      "epoch": 1.0951286764705883,
      "grad_norm": 1.6880784034729004,
      "learning_rate": 8.678513071895425e-06,
      "loss": 0.1381,
      "step": 4766
    },
    {
      "epoch": 1.095358455882353,
      "grad_norm": 1.723526120185852,
      "learning_rate": 8.678002450980393e-06,
      "loss": 0.1617,
      "step": 4767
    },
    {
      "epoch": 1.0955882352941178,
      "grad_norm": 2.139655590057373,
      "learning_rate": 8.67749183006536e-06,
      "loss": 0.1854,
      "step": 4768
    },
    {
      "epoch": 1.0958180147058822,
      "grad_norm": 1.387589931488037,
      "learning_rate": 8.676981209150329e-06,
      "loss": 0.1753,
      "step": 4769
    },
    {
      "epoch": 1.096047794117647,
      "grad_norm": 1.584144949913025,
      "learning_rate": 8.676470588235295e-06,
      "loss": 0.1225,
      "step": 4770
    },
    {
      "epoch": 1.0962775735294117,
      "grad_norm": 1.5759307146072388,
      "learning_rate": 8.675959967320263e-06,
      "loss": 0.0947,
      "step": 4771
    },
    {
      "epoch": 1.0965073529411764,
      "grad_norm": 2.289821147918701,
      "learning_rate": 8.675449346405229e-06,
      "loss": 0.1432,
      "step": 4772
    },
    {
      "epoch": 1.0967371323529411,
      "grad_norm": 1.7528817653656006,
      "learning_rate": 8.674938725490197e-06,
      "loss": 0.1364,
      "step": 4773
    },
    {
      "epoch": 1.0969669117647058,
      "grad_norm": 2.003690481185913,
      "learning_rate": 8.674428104575165e-06,
      "loss": 0.145,
      "step": 4774
    },
    {
      "epoch": 1.0971966911764706,
      "grad_norm": 1.7866164445877075,
      "learning_rate": 8.673917483660131e-06,
      "loss": 0.1488,
      "step": 4775
    },
    {
      "epoch": 1.0974264705882353,
      "grad_norm": 1.6474676132202148,
      "learning_rate": 8.673406862745099e-06,
      "loss": 0.1167,
      "step": 4776
    },
    {
      "epoch": 1.09765625,
      "grad_norm": 2.051098346710205,
      "learning_rate": 8.672896241830067e-06,
      "loss": 0.1594,
      "step": 4777
    },
    {
      "epoch": 1.0978860294117647,
      "grad_norm": 1.0732470750808716,
      "learning_rate": 8.672385620915033e-06,
      "loss": 0.1093,
      "step": 4778
    },
    {
      "epoch": 1.0981158088235294,
      "grad_norm": 2.2597153186798096,
      "learning_rate": 8.671875e-06,
      "loss": 0.2132,
      "step": 4779
    },
    {
      "epoch": 1.0983455882352942,
      "grad_norm": 1.5096579790115356,
      "learning_rate": 8.671364379084969e-06,
      "loss": 0.1169,
      "step": 4780
    },
    {
      "epoch": 1.0985753676470589,
      "grad_norm": 1.6225688457489014,
      "learning_rate": 8.670853758169935e-06,
      "loss": 0.1385,
      "step": 4781
    },
    {
      "epoch": 1.0988051470588236,
      "grad_norm": 1.1201156377792358,
      "learning_rate": 8.670343137254903e-06,
      "loss": 0.0996,
      "step": 4782
    },
    {
      "epoch": 1.0990349264705883,
      "grad_norm": 1.645883560180664,
      "learning_rate": 8.66983251633987e-06,
      "loss": 0.1644,
      "step": 4783
    },
    {
      "epoch": 1.099264705882353,
      "grad_norm": 1.772364854812622,
      "learning_rate": 8.669321895424837e-06,
      "loss": 0.1656,
      "step": 4784
    },
    {
      "epoch": 1.0994944852941178,
      "grad_norm": 2.7061784267425537,
      "learning_rate": 8.668811274509805e-06,
      "loss": 0.1444,
      "step": 4785
    },
    {
      "epoch": 1.0997242647058822,
      "grad_norm": 1.5878872871398926,
      "learning_rate": 8.668300653594772e-06,
      "loss": 0.1501,
      "step": 4786
    },
    {
      "epoch": 1.099954044117647,
      "grad_norm": 1.7014615535736084,
      "learning_rate": 8.667790032679739e-06,
      "loss": 0.1946,
      "step": 4787
    },
    {
      "epoch": 1.1001838235294117,
      "grad_norm": 1.5390729904174805,
      "learning_rate": 8.667279411764706e-06,
      "loss": 0.0988,
      "step": 4788
    },
    {
      "epoch": 1.1004136029411764,
      "grad_norm": 1.9417396783828735,
      "learning_rate": 8.666768790849673e-06,
      "loss": 0.1639,
      "step": 4789
    },
    {
      "epoch": 1.1006433823529411,
      "grad_norm": 1.8381052017211914,
      "learning_rate": 8.666258169934642e-06,
      "loss": 0.137,
      "step": 4790
    },
    {
      "epoch": 1.1008731617647058,
      "grad_norm": 1.4613498449325562,
      "learning_rate": 8.665747549019608e-06,
      "loss": 0.1253,
      "step": 4791
    },
    {
      "epoch": 1.1011029411764706,
      "grad_norm": 1.7650055885314941,
      "learning_rate": 8.665236928104576e-06,
      "loss": 0.1686,
      "step": 4792
    },
    {
      "epoch": 1.1013327205882353,
      "grad_norm": 1.5426994562149048,
      "learning_rate": 8.664726307189542e-06,
      "loss": 0.163,
      "step": 4793
    },
    {
      "epoch": 1.1015625,
      "grad_norm": 1.9968408346176147,
      "learning_rate": 8.66421568627451e-06,
      "loss": 0.1672,
      "step": 4794
    },
    {
      "epoch": 1.1017922794117647,
      "grad_norm": 1.9886301755905151,
      "learning_rate": 8.663705065359478e-06,
      "loss": 0.2051,
      "step": 4795
    },
    {
      "epoch": 1.1020220588235294,
      "grad_norm": 1.5120621919631958,
      "learning_rate": 8.663194444444444e-06,
      "loss": 0.1589,
      "step": 4796
    },
    {
      "epoch": 1.1022518382352942,
      "grad_norm": 1.5561509132385254,
      "learning_rate": 8.662683823529412e-06,
      "loss": 0.1293,
      "step": 4797
    },
    {
      "epoch": 1.1024816176470589,
      "grad_norm": 2.0801472663879395,
      "learning_rate": 8.66217320261438e-06,
      "loss": 0.1332,
      "step": 4798
    },
    {
      "epoch": 1.1027113970588236,
      "grad_norm": 1.6307231187820435,
      "learning_rate": 8.661662581699348e-06,
      "loss": 0.1453,
      "step": 4799
    },
    {
      "epoch": 1.1029411764705883,
      "grad_norm": 1.770755648612976,
      "learning_rate": 8.661151960784314e-06,
      "loss": 0.1134,
      "step": 4800
    },
    {
      "epoch": 1.103170955882353,
      "grad_norm": 2.0193309783935547,
      "learning_rate": 8.660641339869282e-06,
      "loss": 0.1587,
      "step": 4801
    },
    {
      "epoch": 1.1034007352941178,
      "grad_norm": 1.9605357646942139,
      "learning_rate": 8.66013071895425e-06,
      "loss": 0.1276,
      "step": 4802
    },
    {
      "epoch": 1.1036305147058822,
      "grad_norm": 2.1198434829711914,
      "learning_rate": 8.659620098039216e-06,
      "loss": 0.1793,
      "step": 4803
    },
    {
      "epoch": 1.103860294117647,
      "grad_norm": 1.8690191507339478,
      "learning_rate": 8.659109477124184e-06,
      "loss": 0.1388,
      "step": 4804
    },
    {
      "epoch": 1.1040900735294117,
      "grad_norm": 1.7872902154922485,
      "learning_rate": 8.65859885620915e-06,
      "loss": 0.1322,
      "step": 4805
    },
    {
      "epoch": 1.1043198529411764,
      "grad_norm": 1.97078275680542,
      "learning_rate": 8.65808823529412e-06,
      "loss": 0.1537,
      "step": 4806
    },
    {
      "epoch": 1.1045496323529411,
      "grad_norm": 1.7554043531417847,
      "learning_rate": 8.657577614379086e-06,
      "loss": 0.1274,
      "step": 4807
    },
    {
      "epoch": 1.1047794117647058,
      "grad_norm": 1.6322566270828247,
      "learning_rate": 8.657066993464053e-06,
      "loss": 0.0935,
      "step": 4808
    },
    {
      "epoch": 1.1050091911764706,
      "grad_norm": 1.662109136581421,
      "learning_rate": 8.65655637254902e-06,
      "loss": 0.1273,
      "step": 4809
    },
    {
      "epoch": 1.1052389705882353,
      "grad_norm": 1.492820143699646,
      "learning_rate": 8.656045751633987e-06,
      "loss": 0.16,
      "step": 4810
    },
    {
      "epoch": 1.10546875,
      "grad_norm": 2.2264604568481445,
      "learning_rate": 8.655535130718955e-06,
      "loss": 0.1591,
      "step": 4811
    },
    {
      "epoch": 1.1056985294117647,
      "grad_norm": 1.8835934400558472,
      "learning_rate": 8.655024509803922e-06,
      "loss": 0.1337,
      "step": 4812
    },
    {
      "epoch": 1.1059283088235294,
      "grad_norm": 1.4780266284942627,
      "learning_rate": 8.65451388888889e-06,
      "loss": 0.1491,
      "step": 4813
    },
    {
      "epoch": 1.1061580882352942,
      "grad_norm": 1.458534598350525,
      "learning_rate": 8.654003267973857e-06,
      "loss": 0.1183,
      "step": 4814
    },
    {
      "epoch": 1.1063878676470589,
      "grad_norm": 2.0957705974578857,
      "learning_rate": 8.653492647058825e-06,
      "loss": 0.1682,
      "step": 4815
    },
    {
      "epoch": 1.1066176470588236,
      "grad_norm": 1.7587610483169556,
      "learning_rate": 8.652982026143791e-06,
      "loss": 0.1458,
      "step": 4816
    },
    {
      "epoch": 1.1068474264705883,
      "grad_norm": 1.8659336566925049,
      "learning_rate": 8.652471405228759e-06,
      "loss": 0.1274,
      "step": 4817
    },
    {
      "epoch": 1.107077205882353,
      "grad_norm": 1.764526128768921,
      "learning_rate": 8.651960784313727e-06,
      "loss": 0.1458,
      "step": 4818
    },
    {
      "epoch": 1.1073069852941178,
      "grad_norm": 1.380614995956421,
      "learning_rate": 8.651450163398693e-06,
      "loss": 0.1058,
      "step": 4819
    },
    {
      "epoch": 1.1075367647058822,
      "grad_norm": 1.3327127695083618,
      "learning_rate": 8.650939542483661e-06,
      "loss": 0.1171,
      "step": 4820
    },
    {
      "epoch": 1.107766544117647,
      "grad_norm": 1.1849874258041382,
      "learning_rate": 8.650428921568627e-06,
      "loss": 0.1295,
      "step": 4821
    },
    {
      "epoch": 1.1079963235294117,
      "grad_norm": 2.2250261306762695,
      "learning_rate": 8.649918300653595e-06,
      "loss": 0.1459,
      "step": 4822
    },
    {
      "epoch": 1.1082261029411764,
      "grad_norm": 1.6010961532592773,
      "learning_rate": 8.649407679738563e-06,
      "loss": 0.1793,
      "step": 4823
    },
    {
      "epoch": 1.1084558823529411,
      "grad_norm": 1.5702612400054932,
      "learning_rate": 8.648897058823529e-06,
      "loss": 0.1254,
      "step": 4824
    },
    {
      "epoch": 1.1086856617647058,
      "grad_norm": 1.8919919729232788,
      "learning_rate": 8.648386437908497e-06,
      "loss": 0.18,
      "step": 4825
    },
    {
      "epoch": 1.1089154411764706,
      "grad_norm": 2.322697401046753,
      "learning_rate": 8.647875816993465e-06,
      "loss": 0.2143,
      "step": 4826
    },
    {
      "epoch": 1.1091452205882353,
      "grad_norm": 1.599083423614502,
      "learning_rate": 8.647365196078433e-06,
      "loss": 0.1494,
      "step": 4827
    },
    {
      "epoch": 1.109375,
      "grad_norm": 1.6062474250793457,
      "learning_rate": 8.646854575163399e-06,
      "loss": 0.1464,
      "step": 4828
    },
    {
      "epoch": 1.1096047794117647,
      "grad_norm": 1.6881941556930542,
      "learning_rate": 8.646343954248367e-06,
      "loss": 0.1358,
      "step": 4829
    },
    {
      "epoch": 1.1098345588235294,
      "grad_norm": 2.5972938537597656,
      "learning_rate": 8.645833333333335e-06,
      "loss": 0.1632,
      "step": 4830
    },
    {
      "epoch": 1.1100643382352942,
      "grad_norm": 1.9235445261001587,
      "learning_rate": 8.6453227124183e-06,
      "loss": 0.1653,
      "step": 4831
    },
    {
      "epoch": 1.1102941176470589,
      "grad_norm": 1.7596253156661987,
      "learning_rate": 8.644812091503269e-06,
      "loss": 0.1233,
      "step": 4832
    },
    {
      "epoch": 1.1105238970588236,
      "grad_norm": 1.7746355533599854,
      "learning_rate": 8.644301470588235e-06,
      "loss": 0.107,
      "step": 4833
    },
    {
      "epoch": 1.1107536764705883,
      "grad_norm": 1.7126911878585815,
      "learning_rate": 8.643790849673204e-06,
      "loss": 0.1498,
      "step": 4834
    },
    {
      "epoch": 1.110983455882353,
      "grad_norm": 2.0270912647247314,
      "learning_rate": 8.64328022875817e-06,
      "loss": 0.1256,
      "step": 4835
    },
    {
      "epoch": 1.1112132352941178,
      "grad_norm": 1.9020510911941528,
      "learning_rate": 8.642769607843138e-06,
      "loss": 0.1366,
      "step": 4836
    },
    {
      "epoch": 1.1114430147058822,
      "grad_norm": 1.8344300985336304,
      "learning_rate": 8.642258986928105e-06,
      "loss": 0.1425,
      "step": 4837
    },
    {
      "epoch": 1.111672794117647,
      "grad_norm": 1.7765756845474243,
      "learning_rate": 8.641748366013072e-06,
      "loss": 0.1535,
      "step": 4838
    },
    {
      "epoch": 1.1119025735294117,
      "grad_norm": 1.4010075330734253,
      "learning_rate": 8.64123774509804e-06,
      "loss": 0.1435,
      "step": 4839
    },
    {
      "epoch": 1.1121323529411764,
      "grad_norm": 1.619992971420288,
      "learning_rate": 8.640727124183006e-06,
      "loss": 0.1247,
      "step": 4840
    },
    {
      "epoch": 1.1123621323529411,
      "grad_norm": 1.9482578039169312,
      "learning_rate": 8.640216503267974e-06,
      "loss": 0.1451,
      "step": 4841
    },
    {
      "epoch": 1.1125919117647058,
      "grad_norm": 2.199697971343994,
      "learning_rate": 8.639705882352942e-06,
      "loss": 0.1809,
      "step": 4842
    },
    {
      "epoch": 1.1128216911764706,
      "grad_norm": 2.4273931980133057,
      "learning_rate": 8.63919526143791e-06,
      "loss": 0.1574,
      "step": 4843
    },
    {
      "epoch": 1.1130514705882353,
      "grad_norm": 1.5698603391647339,
      "learning_rate": 8.638684640522876e-06,
      "loss": 0.1324,
      "step": 4844
    },
    {
      "epoch": 1.11328125,
      "grad_norm": 1.7955130338668823,
      "learning_rate": 8.638174019607844e-06,
      "loss": 0.1438,
      "step": 4845
    },
    {
      "epoch": 1.1135110294117647,
      "grad_norm": 2.200890064239502,
      "learning_rate": 8.637663398692812e-06,
      "loss": 0.1678,
      "step": 4846
    },
    {
      "epoch": 1.1137408088235294,
      "grad_norm": 2.571072578430176,
      "learning_rate": 8.637152777777778e-06,
      "loss": 0.2139,
      "step": 4847
    },
    {
      "epoch": 1.1139705882352942,
      "grad_norm": 1.6176663637161255,
      "learning_rate": 8.636642156862746e-06,
      "loss": 0.1327,
      "step": 4848
    },
    {
      "epoch": 1.1142003676470589,
      "grad_norm": 1.4509344100952148,
      "learning_rate": 8.636131535947712e-06,
      "loss": 0.1337,
      "step": 4849
    },
    {
      "epoch": 1.1144301470588236,
      "grad_norm": 1.922435998916626,
      "learning_rate": 8.635620915032682e-06,
      "loss": 0.1731,
      "step": 4850
    },
    {
      "epoch": 1.1146599264705883,
      "grad_norm": 1.8169503211975098,
      "learning_rate": 8.635110294117648e-06,
      "loss": 0.1992,
      "step": 4851
    },
    {
      "epoch": 1.114889705882353,
      "grad_norm": 1.6957616806030273,
      "learning_rate": 8.634599673202616e-06,
      "loss": 0.1224,
      "step": 4852
    },
    {
      "epoch": 1.1151194852941178,
      "grad_norm": 1.6465954780578613,
      "learning_rate": 8.634089052287582e-06,
      "loss": 0.1324,
      "step": 4853
    },
    {
      "epoch": 1.1153492647058822,
      "grad_norm": 1.545508623123169,
      "learning_rate": 8.63357843137255e-06,
      "loss": 0.1535,
      "step": 4854
    },
    {
      "epoch": 1.115579044117647,
      "grad_norm": 1.3736488819122314,
      "learning_rate": 8.633067810457518e-06,
      "loss": 0.1315,
      "step": 4855
    },
    {
      "epoch": 1.1158088235294117,
      "grad_norm": 1.7524302005767822,
      "learning_rate": 8.632557189542484e-06,
      "loss": 0.1932,
      "step": 4856
    },
    {
      "epoch": 1.1160386029411764,
      "grad_norm": 1.6540510654449463,
      "learning_rate": 8.632046568627452e-06,
      "loss": 0.1633,
      "step": 4857
    },
    {
      "epoch": 1.1162683823529411,
      "grad_norm": 1.6020500659942627,
      "learning_rate": 8.63153594771242e-06,
      "loss": 0.1445,
      "step": 4858
    },
    {
      "epoch": 1.1164981617647058,
      "grad_norm": 1.64694082736969,
      "learning_rate": 8.631025326797387e-06,
      "loss": 0.1471,
      "step": 4859
    },
    {
      "epoch": 1.1167279411764706,
      "grad_norm": 1.6343662738800049,
      "learning_rate": 8.630514705882353e-06,
      "loss": 0.1322,
      "step": 4860
    },
    {
      "epoch": 1.1169577205882353,
      "grad_norm": 1.684073805809021,
      "learning_rate": 8.630004084967321e-06,
      "loss": 0.1749,
      "step": 4861
    },
    {
      "epoch": 1.1171875,
      "grad_norm": 1.7401491403579712,
      "learning_rate": 8.62949346405229e-06,
      "loss": 0.2042,
      "step": 4862
    },
    {
      "epoch": 1.1174172794117647,
      "grad_norm": 1.8658370971679688,
      "learning_rate": 8.628982843137255e-06,
      "loss": 0.1972,
      "step": 4863
    },
    {
      "epoch": 1.1176470588235294,
      "grad_norm": 1.155206561088562,
      "learning_rate": 8.628472222222223e-06,
      "loss": 0.1225,
      "step": 4864
    },
    {
      "epoch": 1.1178768382352942,
      "grad_norm": 1.5544023513793945,
      "learning_rate": 8.62796160130719e-06,
      "loss": 0.1399,
      "step": 4865
    },
    {
      "epoch": 1.1181066176470589,
      "grad_norm": 2.0740976333618164,
      "learning_rate": 8.627450980392157e-06,
      "loss": 0.1439,
      "step": 4866
    },
    {
      "epoch": 1.1183363970588236,
      "grad_norm": 1.7582876682281494,
      "learning_rate": 8.626940359477125e-06,
      "loss": 0.1543,
      "step": 4867
    },
    {
      "epoch": 1.1185661764705883,
      "grad_norm": 1.6305735111236572,
      "learning_rate": 8.626429738562091e-06,
      "loss": 0.1399,
      "step": 4868
    },
    {
      "epoch": 1.118795955882353,
      "grad_norm": 2.3389170169830322,
      "learning_rate": 8.625919117647059e-06,
      "loss": 0.2072,
      "step": 4869
    },
    {
      "epoch": 1.1190257352941178,
      "grad_norm": 1.4981908798217773,
      "learning_rate": 8.625408496732027e-06,
      "loss": 0.1671,
      "step": 4870
    },
    {
      "epoch": 1.1192555147058822,
      "grad_norm": 1.5897036790847778,
      "learning_rate": 8.624897875816995e-06,
      "loss": 0.1564,
      "step": 4871
    },
    {
      "epoch": 1.119485294117647,
      "grad_norm": 1.7806042432785034,
      "learning_rate": 8.624387254901961e-06,
      "loss": 0.1176,
      "step": 4872
    },
    {
      "epoch": 1.1197150735294117,
      "grad_norm": 1.8459618091583252,
      "learning_rate": 8.623876633986929e-06,
      "loss": 0.2184,
      "step": 4873
    },
    {
      "epoch": 1.1199448529411764,
      "grad_norm": 1.5561909675598145,
      "learning_rate": 8.623366013071897e-06,
      "loss": 0.1441,
      "step": 4874
    },
    {
      "epoch": 1.1201746323529411,
      "grad_norm": 1.6216984987258911,
      "learning_rate": 8.622855392156863e-06,
      "loss": 0.1186,
      "step": 4875
    },
    {
      "epoch": 1.1204044117647058,
      "grad_norm": 1.6013604402542114,
      "learning_rate": 8.62234477124183e-06,
      "loss": 0.1456,
      "step": 4876
    },
    {
      "epoch": 1.1206341911764706,
      "grad_norm": 1.4583505392074585,
      "learning_rate": 8.621834150326797e-06,
      "loss": 0.1285,
      "step": 4877
    },
    {
      "epoch": 1.1208639705882353,
      "grad_norm": 1.1943894624710083,
      "learning_rate": 8.621323529411766e-06,
      "loss": 0.1083,
      "step": 4878
    },
    {
      "epoch": 1.12109375,
      "grad_norm": 1.304166316986084,
      "learning_rate": 8.620812908496733e-06,
      "loss": 0.114,
      "step": 4879
    },
    {
      "epoch": 1.1213235294117647,
      "grad_norm": 1.3562837839126587,
      "learning_rate": 8.6203022875817e-06,
      "loss": 0.0967,
      "step": 4880
    },
    {
      "epoch": 1.1215533088235294,
      "grad_norm": 1.7444181442260742,
      "learning_rate": 8.619791666666667e-06,
      "loss": 0.1807,
      "step": 4881
    },
    {
      "epoch": 1.1217830882352942,
      "grad_norm": 1.7413322925567627,
      "learning_rate": 8.619281045751635e-06,
      "loss": 0.1874,
      "step": 4882
    },
    {
      "epoch": 1.1220128676470589,
      "grad_norm": 1.7333426475524902,
      "learning_rate": 8.618770424836602e-06,
      "loss": 0.1481,
      "step": 4883
    },
    {
      "epoch": 1.1222426470588236,
      "grad_norm": 1.5204994678497314,
      "learning_rate": 8.618259803921569e-06,
      "loss": 0.1837,
      "step": 4884
    },
    {
      "epoch": 1.1224724264705883,
      "grad_norm": 1.6716041564941406,
      "learning_rate": 8.617749183006536e-06,
      "loss": 0.1176,
      "step": 4885
    },
    {
      "epoch": 1.122702205882353,
      "grad_norm": 1.7397862672805786,
      "learning_rate": 8.617238562091504e-06,
      "loss": 0.1254,
      "step": 4886
    },
    {
      "epoch": 1.1229319852941178,
      "grad_norm": 1.485207438468933,
      "learning_rate": 8.616727941176472e-06,
      "loss": 0.1395,
      "step": 4887
    },
    {
      "epoch": 1.1231617647058822,
      "grad_norm": 1.6954134702682495,
      "learning_rate": 8.616217320261438e-06,
      "loss": 0.178,
      "step": 4888
    },
    {
      "epoch": 1.123391544117647,
      "grad_norm": 1.9249318838119507,
      "learning_rate": 8.615706699346406e-06,
      "loss": 0.1412,
      "step": 4889
    },
    {
      "epoch": 1.1236213235294117,
      "grad_norm": 1.478355050086975,
      "learning_rate": 8.615196078431374e-06,
      "loss": 0.14,
      "step": 4890
    },
    {
      "epoch": 1.1238511029411764,
      "grad_norm": 1.9010998010635376,
      "learning_rate": 8.61468545751634e-06,
      "loss": 0.1481,
      "step": 4891
    },
    {
      "epoch": 1.1240808823529411,
      "grad_norm": 1.742231845855713,
      "learning_rate": 8.614174836601308e-06,
      "loss": 0.1615,
      "step": 4892
    },
    {
      "epoch": 1.1243106617647058,
      "grad_norm": 1.5647515058517456,
      "learning_rate": 8.613664215686274e-06,
      "loss": 0.1603,
      "step": 4893
    },
    {
      "epoch": 1.1245404411764706,
      "grad_norm": 1.7223381996154785,
      "learning_rate": 8.613153594771244e-06,
      "loss": 0.1705,
      "step": 4894
    },
    {
      "epoch": 1.1247702205882353,
      "grad_norm": 1.6856598854064941,
      "learning_rate": 8.61264297385621e-06,
      "loss": 0.1556,
      "step": 4895
    },
    {
      "epoch": 1.125,
      "grad_norm": 1.592896580696106,
      "learning_rate": 8.612132352941178e-06,
      "loss": 0.1527,
      "step": 4896
    },
    {
      "epoch": 1.1252297794117647,
      "grad_norm": 1.7240755558013916,
      "learning_rate": 8.611621732026144e-06,
      "loss": 0.1793,
      "step": 4897
    },
    {
      "epoch": 1.1254595588235294,
      "grad_norm": 1.2969940900802612,
      "learning_rate": 8.611111111111112e-06,
      "loss": 0.1135,
      "step": 4898
    },
    {
      "epoch": 1.1256893382352942,
      "grad_norm": 1.900315761566162,
      "learning_rate": 8.61060049019608e-06,
      "loss": 0.1671,
      "step": 4899
    },
    {
      "epoch": 1.1259191176470589,
      "grad_norm": 1.6363447904586792,
      "learning_rate": 8.610089869281046e-06,
      "loss": 0.1428,
      "step": 4900
    },
    {
      "epoch": 1.1261488970588236,
      "grad_norm": 1.311728835105896,
      "learning_rate": 8.609579248366014e-06,
      "loss": 0.1312,
      "step": 4901
    },
    {
      "epoch": 1.1263786764705883,
      "grad_norm": 1.4300341606140137,
      "learning_rate": 8.609068627450982e-06,
      "loss": 0.0925,
      "step": 4902
    },
    {
      "epoch": 1.126608455882353,
      "grad_norm": 2.8123018741607666,
      "learning_rate": 8.60855800653595e-06,
      "loss": 0.1552,
      "step": 4903
    },
    {
      "epoch": 1.1268382352941178,
      "grad_norm": 2.0037901401519775,
      "learning_rate": 8.608047385620916e-06,
      "loss": 0.1724,
      "step": 4904
    },
    {
      "epoch": 1.1270680147058822,
      "grad_norm": 1.7593538761138916,
      "learning_rate": 8.607536764705884e-06,
      "loss": 0.1098,
      "step": 4905
    },
    {
      "epoch": 1.127297794117647,
      "grad_norm": 1.4045919179916382,
      "learning_rate": 8.607026143790851e-06,
      "loss": 0.1196,
      "step": 4906
    },
    {
      "epoch": 1.1275275735294117,
      "grad_norm": 1.333774209022522,
      "learning_rate": 8.606515522875818e-06,
      "loss": 0.1051,
      "step": 4907
    },
    {
      "epoch": 1.1277573529411764,
      "grad_norm": 1.1703038215637207,
      "learning_rate": 8.606004901960785e-06,
      "loss": 0.1179,
      "step": 4908
    },
    {
      "epoch": 1.1279871323529411,
      "grad_norm": 1.4248766899108887,
      "learning_rate": 8.605494281045752e-06,
      "loss": 0.1541,
      "step": 4909
    },
    {
      "epoch": 1.1282169117647058,
      "grad_norm": 1.4998337030410767,
      "learning_rate": 8.60498366013072e-06,
      "loss": 0.1714,
      "step": 4910
    },
    {
      "epoch": 1.1284466911764706,
      "grad_norm": 2.4664838314056396,
      "learning_rate": 8.604473039215687e-06,
      "loss": 0.1632,
      "step": 4911
    },
    {
      "epoch": 1.1286764705882353,
      "grad_norm": 2.146589756011963,
      "learning_rate": 8.603962418300653e-06,
      "loss": 0.1851,
      "step": 4912
    },
    {
      "epoch": 1.12890625,
      "grad_norm": 1.8541051149368286,
      "learning_rate": 8.603451797385621e-06,
      "loss": 0.1738,
      "step": 4913
    },
    {
      "epoch": 1.1291360294117647,
      "grad_norm": 1.5990835428237915,
      "learning_rate": 8.60294117647059e-06,
      "loss": 0.1225,
      "step": 4914
    },
    {
      "epoch": 1.1293658088235294,
      "grad_norm": 1.7304410934448242,
      "learning_rate": 8.602430555555557e-06,
      "loss": 0.127,
      "step": 4915
    },
    {
      "epoch": 1.1295955882352942,
      "grad_norm": 1.64418625831604,
      "learning_rate": 8.601919934640523e-06,
      "loss": 0.1315,
      "step": 4916
    },
    {
      "epoch": 1.1298253676470589,
      "grad_norm": 1.8063639402389526,
      "learning_rate": 8.601409313725491e-06,
      "loss": 0.1343,
      "step": 4917
    },
    {
      "epoch": 1.1300551470588236,
      "grad_norm": 1.5116640329360962,
      "learning_rate": 8.600898692810459e-06,
      "loss": 0.1377,
      "step": 4918
    },
    {
      "epoch": 1.1302849264705883,
      "grad_norm": 1.525040626525879,
      "learning_rate": 8.600388071895425e-06,
      "loss": 0.1177,
      "step": 4919
    },
    {
      "epoch": 1.130514705882353,
      "grad_norm": 1.3973088264465332,
      "learning_rate": 8.599877450980393e-06,
      "loss": 0.0991,
      "step": 4920
    },
    {
      "epoch": 1.1307444852941178,
      "grad_norm": 2.1280875205993652,
      "learning_rate": 8.599366830065359e-06,
      "loss": 0.139,
      "step": 4921
    },
    {
      "epoch": 1.1309742647058822,
      "grad_norm": 1.8421496152877808,
      "learning_rate": 8.598856209150329e-06,
      "loss": 0.1289,
      "step": 4922
    },
    {
      "epoch": 1.131204044117647,
      "grad_norm": 1.4424610137939453,
      "learning_rate": 8.598345588235295e-06,
      "loss": 0.137,
      "step": 4923
    },
    {
      "epoch": 1.1314338235294117,
      "grad_norm": 1.4546995162963867,
      "learning_rate": 8.597834967320263e-06,
      "loss": 0.1119,
      "step": 4924
    },
    {
      "epoch": 1.1316636029411764,
      "grad_norm": 1.5919477939605713,
      "learning_rate": 8.597324346405229e-06,
      "loss": 0.1576,
      "step": 4925
    },
    {
      "epoch": 1.1318933823529411,
      "grad_norm": 1.3890705108642578,
      "learning_rate": 8.596813725490197e-06,
      "loss": 0.1242,
      "step": 4926
    },
    {
      "epoch": 1.1321231617647058,
      "grad_norm": 1.6416674852371216,
      "learning_rate": 8.596303104575165e-06,
      "loss": 0.1344,
      "step": 4927
    },
    {
      "epoch": 1.1323529411764706,
      "grad_norm": 1.9567354917526245,
      "learning_rate": 8.59579248366013e-06,
      "loss": 0.1748,
      "step": 4928
    },
    {
      "epoch": 1.1325827205882353,
      "grad_norm": 1.3527708053588867,
      "learning_rate": 8.595281862745099e-06,
      "loss": 0.1218,
      "step": 4929
    },
    {
      "epoch": 1.1328125,
      "grad_norm": 1.3987619876861572,
      "learning_rate": 8.594771241830066e-06,
      "loss": 0.1096,
      "step": 4930
    },
    {
      "epoch": 1.1330422794117647,
      "grad_norm": 1.4480842351913452,
      "learning_rate": 8.594260620915034e-06,
      "loss": 0.1266,
      "step": 4931
    },
    {
      "epoch": 1.1332720588235294,
      "grad_norm": 2.2944111824035645,
      "learning_rate": 8.59375e-06,
      "loss": 0.1504,
      "step": 4932
    },
    {
      "epoch": 1.1335018382352942,
      "grad_norm": 1.9693394899368286,
      "learning_rate": 8.593239379084968e-06,
      "loss": 0.1747,
      "step": 4933
    },
    {
      "epoch": 1.1337316176470589,
      "grad_norm": 1.6478996276855469,
      "learning_rate": 8.592728758169935e-06,
      "loss": 0.1544,
      "step": 4934
    },
    {
      "epoch": 1.1339613970588236,
      "grad_norm": 2.0162956714630127,
      "learning_rate": 8.592218137254902e-06,
      "loss": 0.13,
      "step": 4935
    },
    {
      "epoch": 1.1341911764705883,
      "grad_norm": 1.8252149820327759,
      "learning_rate": 8.59170751633987e-06,
      "loss": 0.1589,
      "step": 4936
    },
    {
      "epoch": 1.134420955882353,
      "grad_norm": 1.5706449747085571,
      "learning_rate": 8.591196895424836e-06,
      "loss": 0.1587,
      "step": 4937
    },
    {
      "epoch": 1.1346507352941178,
      "grad_norm": 2.321298599243164,
      "learning_rate": 8.590686274509804e-06,
      "loss": 0.1406,
      "step": 4938
    },
    {
      "epoch": 1.1348805147058822,
      "grad_norm": 1.6291471719741821,
      "learning_rate": 8.590175653594772e-06,
      "loss": 0.1301,
      "step": 4939
    },
    {
      "epoch": 1.135110294117647,
      "grad_norm": 1.7769678831100464,
      "learning_rate": 8.58966503267974e-06,
      "loss": 0.1246,
      "step": 4940
    },
    {
      "epoch": 1.1353400735294117,
      "grad_norm": 2.3737637996673584,
      "learning_rate": 8.589154411764706e-06,
      "loss": 0.1587,
      "step": 4941
    },
    {
      "epoch": 1.1355698529411764,
      "grad_norm": 1.7554683685302734,
      "learning_rate": 8.588643790849674e-06,
      "loss": 0.136,
      "step": 4942
    },
    {
      "epoch": 1.1357996323529411,
      "grad_norm": 1.2813258171081543,
      "learning_rate": 8.588133169934642e-06,
      "loss": 0.1175,
      "step": 4943
    },
    {
      "epoch": 1.1360294117647058,
      "grad_norm": 1.7119005918502808,
      "learning_rate": 8.587622549019608e-06,
      "loss": 0.1492,
      "step": 4944
    },
    {
      "epoch": 1.1362591911764706,
      "grad_norm": 1.7930150032043457,
      "learning_rate": 8.587111928104576e-06,
      "loss": 0.1123,
      "step": 4945
    },
    {
      "epoch": 1.1364889705882353,
      "grad_norm": 1.2273528575897217,
      "learning_rate": 8.586601307189542e-06,
      "loss": 0.1567,
      "step": 4946
    },
    {
      "epoch": 1.13671875,
      "grad_norm": 1.8138755559921265,
      "learning_rate": 8.58609068627451e-06,
      "loss": 0.1303,
      "step": 4947
    },
    {
      "epoch": 1.1369485294117647,
      "grad_norm": 1.8229146003723145,
      "learning_rate": 8.585580065359478e-06,
      "loss": 0.1182,
      "step": 4948
    },
    {
      "epoch": 1.1371783088235294,
      "grad_norm": 1.7853623628616333,
      "learning_rate": 8.585069444444446e-06,
      "loss": 0.0993,
      "step": 4949
    },
    {
      "epoch": 1.1374080882352942,
      "grad_norm": 1.8566648960113525,
      "learning_rate": 8.584558823529412e-06,
      "loss": 0.15,
      "step": 4950
    },
    {
      "epoch": 1.1376378676470589,
      "grad_norm": 1.6551636457443237,
      "learning_rate": 8.58404820261438e-06,
      "loss": 0.1483,
      "step": 4951
    },
    {
      "epoch": 1.1378676470588236,
      "grad_norm": 2.3199472427368164,
      "learning_rate": 8.583537581699348e-06,
      "loss": 0.166,
      "step": 4952
    },
    {
      "epoch": 1.1380974264705883,
      "grad_norm": 1.3829236030578613,
      "learning_rate": 8.583026960784314e-06,
      "loss": 0.1766,
      "step": 4953
    },
    {
      "epoch": 1.138327205882353,
      "grad_norm": 1.6381402015686035,
      "learning_rate": 8.582516339869282e-06,
      "loss": 0.0906,
      "step": 4954
    },
    {
      "epoch": 1.1385569852941178,
      "grad_norm": 1.569321632385254,
      "learning_rate": 8.58200571895425e-06,
      "loss": 0.131,
      "step": 4955
    },
    {
      "epoch": 1.1387867647058822,
      "grad_norm": 1.8601678609848022,
      "learning_rate": 8.581495098039216e-06,
      "loss": 0.1621,
      "step": 4956
    },
    {
      "epoch": 1.139016544117647,
      "grad_norm": 1.796549677848816,
      "learning_rate": 8.580984477124184e-06,
      "loss": 0.1355,
      "step": 4957
    },
    {
      "epoch": 1.1392463235294117,
      "grad_norm": 1.2351281642913818,
      "learning_rate": 8.580473856209151e-06,
      "loss": 0.1406,
      "step": 4958
    },
    {
      "epoch": 1.1394761029411764,
      "grad_norm": 1.2359989881515503,
      "learning_rate": 8.57996323529412e-06,
      "loss": 0.1095,
      "step": 4959
    },
    {
      "epoch": 1.1397058823529411,
      "grad_norm": 1.283921718597412,
      "learning_rate": 8.579452614379085e-06,
      "loss": 0.1569,
      "step": 4960
    },
    {
      "epoch": 1.1399356617647058,
      "grad_norm": 1.4398159980773926,
      "learning_rate": 8.578941993464053e-06,
      "loss": 0.1233,
      "step": 4961
    },
    {
      "epoch": 1.1401654411764706,
      "grad_norm": 1.791866421699524,
      "learning_rate": 8.57843137254902e-06,
      "loss": 0.1808,
      "step": 4962
    },
    {
      "epoch": 1.1403952205882353,
      "grad_norm": 1.676006555557251,
      "learning_rate": 8.577920751633987e-06,
      "loss": 0.1521,
      "step": 4963
    },
    {
      "epoch": 1.140625,
      "grad_norm": 1.4812091588974,
      "learning_rate": 8.577410130718955e-06,
      "loss": 0.1172,
      "step": 4964
    },
    {
      "epoch": 1.1408547794117647,
      "grad_norm": 1.6452522277832031,
      "learning_rate": 8.576899509803921e-06,
      "loss": 0.1458,
      "step": 4965
    },
    {
      "epoch": 1.1410845588235294,
      "grad_norm": 1.6120554208755493,
      "learning_rate": 8.57638888888889e-06,
      "loss": 0.1254,
      "step": 4966
    },
    {
      "epoch": 1.1413143382352942,
      "grad_norm": 1.4296013116836548,
      "learning_rate": 8.575878267973857e-06,
      "loss": 0.1433,
      "step": 4967
    },
    {
      "epoch": 1.1415441176470589,
      "grad_norm": 1.727242112159729,
      "learning_rate": 8.575367647058825e-06,
      "loss": 0.1368,
      "step": 4968
    },
    {
      "epoch": 1.1417738970588236,
      "grad_norm": 2.200470209121704,
      "learning_rate": 8.574857026143791e-06,
      "loss": 0.1488,
      "step": 4969
    },
    {
      "epoch": 1.1420036764705883,
      "grad_norm": 1.7510035037994385,
      "learning_rate": 8.574346405228759e-06,
      "loss": 0.1567,
      "step": 4970
    },
    {
      "epoch": 1.142233455882353,
      "grad_norm": 2.486274242401123,
      "learning_rate": 8.573835784313727e-06,
      "loss": 0.2126,
      "step": 4971
    },
    {
      "epoch": 1.1424632352941178,
      "grad_norm": 1.9383306503295898,
      "learning_rate": 8.573325163398693e-06,
      "loss": 0.1625,
      "step": 4972
    },
    {
      "epoch": 1.1426930147058822,
      "grad_norm": 1.6667078733444214,
      "learning_rate": 8.57281454248366e-06,
      "loss": 0.1336,
      "step": 4973
    },
    {
      "epoch": 1.142922794117647,
      "grad_norm": 2.195450782775879,
      "learning_rate": 8.572303921568627e-06,
      "loss": 0.1972,
      "step": 4974
    },
    {
      "epoch": 1.1431525735294117,
      "grad_norm": 1.5325853824615479,
      "learning_rate": 8.571793300653597e-06,
      "loss": 0.1201,
      "step": 4975
    },
    {
      "epoch": 1.1433823529411764,
      "grad_norm": 1.300979495048523,
      "learning_rate": 8.571282679738563e-06,
      "loss": 0.1366,
      "step": 4976
    },
    {
      "epoch": 1.1436121323529411,
      "grad_norm": 1.7429879903793335,
      "learning_rate": 8.57077205882353e-06,
      "loss": 0.1249,
      "step": 4977
    },
    {
      "epoch": 1.1438419117647058,
      "grad_norm": 1.8690356016159058,
      "learning_rate": 8.570261437908497e-06,
      "loss": 0.1678,
      "step": 4978
    },
    {
      "epoch": 1.1440716911764706,
      "grad_norm": 1.483854055404663,
      "learning_rate": 8.569750816993465e-06,
      "loss": 0.14,
      "step": 4979
    },
    {
      "epoch": 1.1443014705882353,
      "grad_norm": 1.6643544435501099,
      "learning_rate": 8.569240196078432e-06,
      "loss": 0.1618,
      "step": 4980
    },
    {
      "epoch": 1.14453125,
      "grad_norm": 1.6539392471313477,
      "learning_rate": 8.568729575163399e-06,
      "loss": 0.1396,
      "step": 4981
    },
    {
      "epoch": 1.1447610294117647,
      "grad_norm": 1.5440179109573364,
      "learning_rate": 8.568218954248366e-06,
      "loss": 0.1507,
      "step": 4982
    },
    {
      "epoch": 1.1449908088235294,
      "grad_norm": 2.0720748901367188,
      "learning_rate": 8.567708333333334e-06,
      "loss": 0.1401,
      "step": 4983
    },
    {
      "epoch": 1.1452205882352942,
      "grad_norm": 1.7097042798995972,
      "learning_rate": 8.567197712418302e-06,
      "loss": 0.1517,
      "step": 4984
    },
    {
      "epoch": 1.1454503676470589,
      "grad_norm": 1.8951367139816284,
      "learning_rate": 8.566687091503268e-06,
      "loss": 0.1635,
      "step": 4985
    },
    {
      "epoch": 1.1456801470588236,
      "grad_norm": 1.5420048236846924,
      "learning_rate": 8.566176470588236e-06,
      "loss": 0.1536,
      "step": 4986
    },
    {
      "epoch": 1.1459099264705883,
      "grad_norm": 1.4524232149124146,
      "learning_rate": 8.565665849673204e-06,
      "loss": 0.1317,
      "step": 4987
    },
    {
      "epoch": 1.146139705882353,
      "grad_norm": 1.2595250606536865,
      "learning_rate": 8.56515522875817e-06,
      "loss": 0.1075,
      "step": 4988
    },
    {
      "epoch": 1.1463694852941178,
      "grad_norm": 1.6255006790161133,
      "learning_rate": 8.564644607843138e-06,
      "loss": 0.1494,
      "step": 4989
    },
    {
      "epoch": 1.1465992647058822,
      "grad_norm": 1.6565048694610596,
      "learning_rate": 8.564133986928104e-06,
      "loss": 0.1319,
      "step": 4990
    },
    {
      "epoch": 1.146829044117647,
      "grad_norm": 1.2893894910812378,
      "learning_rate": 8.563623366013072e-06,
      "loss": 0.1126,
      "step": 4991
    },
    {
      "epoch": 1.1470588235294117,
      "grad_norm": 1.9667043685913086,
      "learning_rate": 8.56311274509804e-06,
      "loss": 0.1554,
      "step": 4992
    },
    {
      "epoch": 1.1472886029411764,
      "grad_norm": 2.2308647632598877,
      "learning_rate": 8.562602124183008e-06,
      "loss": 0.1527,
      "step": 4993
    },
    {
      "epoch": 1.1475183823529411,
      "grad_norm": 1.4871670007705688,
      "learning_rate": 8.562091503267974e-06,
      "loss": 0.1202,
      "step": 4994
    },
    {
      "epoch": 1.1477481617647058,
      "grad_norm": 1.4137458801269531,
      "learning_rate": 8.561580882352942e-06,
      "loss": 0.1171,
      "step": 4995
    },
    {
      "epoch": 1.1479779411764706,
      "grad_norm": 1.6212931871414185,
      "learning_rate": 8.56107026143791e-06,
      "loss": 0.1332,
      "step": 4996
    },
    {
      "epoch": 1.1482077205882353,
      "grad_norm": 1.93958580493927,
      "learning_rate": 8.560559640522876e-06,
      "loss": 0.12,
      "step": 4997
    },
    {
      "epoch": 1.1484375,
      "grad_norm": 2.7702200412750244,
      "learning_rate": 8.560049019607844e-06,
      "loss": 0.1953,
      "step": 4998
    },
    {
      "epoch": 1.1486672794117647,
      "grad_norm": 1.9716908931732178,
      "learning_rate": 8.559538398692812e-06,
      "loss": 0.1611,
      "step": 4999
    },
    {
      "epoch": 1.1488970588235294,
      "grad_norm": 2.7059977054595947,
      "learning_rate": 8.559027777777778e-06,
      "loss": 0.2158,
      "step": 5000
    },
    {
      "epoch": 1.1488970588235294,
      "eval_loss": 0.14633046090602875,
      "eval_runtime": 421.0684,
      "eval_samples_per_second": 21.151,
      "eval_steps_per_second": 10.575,
      "step": 5000
    },
    {
      "epoch": 1.1491268382352942,
      "grad_norm": 1.554414987564087,
      "learning_rate": 8.558517156862746e-06,
      "loss": 0.1452,
      "step": 5001
    },
    {
      "epoch": 1.1493566176470589,
      "grad_norm": 1.6555455923080444,
      "learning_rate": 8.558006535947712e-06,
      "loss": 0.1527,
      "step": 5002
    },
    {
      "epoch": 1.1495863970588236,
      "grad_norm": 2.4787967205047607,
      "learning_rate": 8.557495915032681e-06,
      "loss": 0.1472,
      "step": 5003
    },
    {
      "epoch": 1.1498161764705883,
      "grad_norm": 2.1754560470581055,
      "learning_rate": 8.556985294117648e-06,
      "loss": 0.1378,
      "step": 5004
    },
    {
      "epoch": 1.150045955882353,
      "grad_norm": 1.9713542461395264,
      "learning_rate": 8.556474673202615e-06,
      "loss": 0.1795,
      "step": 5005
    },
    {
      "epoch": 1.1502757352941178,
      "grad_norm": 1.7510079145431519,
      "learning_rate": 8.555964052287582e-06,
      "loss": 0.1565,
      "step": 5006
    },
    {
      "epoch": 1.1505055147058822,
      "grad_norm": 1.5086078643798828,
      "learning_rate": 8.55545343137255e-06,
      "loss": 0.1351,
      "step": 5007
    },
    {
      "epoch": 1.150735294117647,
      "grad_norm": 1.588250994682312,
      "learning_rate": 8.554942810457517e-06,
      "loss": 0.1466,
      "step": 5008
    },
    {
      "epoch": 1.1509650735294117,
      "grad_norm": 1.761773705482483,
      "learning_rate": 8.554432189542483e-06,
      "loss": 0.1714,
      "step": 5009
    },
    {
      "epoch": 1.1511948529411764,
      "grad_norm": 1.5003911256790161,
      "learning_rate": 8.553921568627451e-06,
      "loss": 0.1231,
      "step": 5010
    },
    {
      "epoch": 1.1514246323529411,
      "grad_norm": 1.8736969232559204,
      "learning_rate": 8.55341094771242e-06,
      "loss": 0.1451,
      "step": 5011
    },
    {
      "epoch": 1.1516544117647058,
      "grad_norm": 1.6327463388442993,
      "learning_rate": 8.552900326797387e-06,
      "loss": 0.1322,
      "step": 5012
    },
    {
      "epoch": 1.1518841911764706,
      "grad_norm": 1.4516068696975708,
      "learning_rate": 8.552389705882353e-06,
      "loss": 0.1056,
      "step": 5013
    },
    {
      "epoch": 1.1521139705882353,
      "grad_norm": 1.4682817459106445,
      "learning_rate": 8.551879084967321e-06,
      "loss": 0.1188,
      "step": 5014
    },
    {
      "epoch": 1.15234375,
      "grad_norm": 1.3383898735046387,
      "learning_rate": 8.551368464052289e-06,
      "loss": 0.1367,
      "step": 5015
    },
    {
      "epoch": 1.1525735294117647,
      "grad_norm": 1.8366754055023193,
      "learning_rate": 8.550857843137255e-06,
      "loss": 0.143,
      "step": 5016
    },
    {
      "epoch": 1.1528033088235294,
      "grad_norm": 1.5679856538772583,
      "learning_rate": 8.550347222222223e-06,
      "loss": 0.1761,
      "step": 5017
    },
    {
      "epoch": 1.1530330882352942,
      "grad_norm": 2.0413167476654053,
      "learning_rate": 8.54983660130719e-06,
      "loss": 0.1158,
      "step": 5018
    },
    {
      "epoch": 1.1532628676470589,
      "grad_norm": 2.607337236404419,
      "learning_rate": 8.549325980392159e-06,
      "loss": 0.1486,
      "step": 5019
    },
    {
      "epoch": 1.1534926470588236,
      "grad_norm": 2.8300600051879883,
      "learning_rate": 8.548815359477125e-06,
      "loss": 0.1811,
      "step": 5020
    },
    {
      "epoch": 1.1537224264705883,
      "grad_norm": 1.7685437202453613,
      "learning_rate": 8.548304738562093e-06,
      "loss": 0.1276,
      "step": 5021
    },
    {
      "epoch": 1.153952205882353,
      "grad_norm": 1.5728557109832764,
      "learning_rate": 8.547794117647059e-06,
      "loss": 0.1167,
      "step": 5022
    },
    {
      "epoch": 1.1541819852941178,
      "grad_norm": 1.8530433177947998,
      "learning_rate": 8.547283496732027e-06,
      "loss": 0.1226,
      "step": 5023
    },
    {
      "epoch": 1.1544117647058822,
      "grad_norm": 2.6812245845794678,
      "learning_rate": 8.546772875816995e-06,
      "loss": 0.2031,
      "step": 5024
    },
    {
      "epoch": 1.154641544117647,
      "grad_norm": 1.4771835803985596,
      "learning_rate": 8.54626225490196e-06,
      "loss": 0.1649,
      "step": 5025
    },
    {
      "epoch": 1.1548713235294117,
      "grad_norm": 1.4748352766036987,
      "learning_rate": 8.545751633986929e-06,
      "loss": 0.1111,
      "step": 5026
    },
    {
      "epoch": 1.1551011029411764,
      "grad_norm": 1.7096151113510132,
      "learning_rate": 8.545241013071897e-06,
      "loss": 0.1233,
      "step": 5027
    },
    {
      "epoch": 1.1553308823529411,
      "grad_norm": 2.078371524810791,
      "learning_rate": 8.544730392156864e-06,
      "loss": 0.1681,
      "step": 5028
    },
    {
      "epoch": 1.1555606617647058,
      "grad_norm": 1.5237324237823486,
      "learning_rate": 8.54421977124183e-06,
      "loss": 0.0922,
      "step": 5029
    },
    {
      "epoch": 1.1557904411764706,
      "grad_norm": 2.216325521469116,
      "learning_rate": 8.543709150326798e-06,
      "loss": 0.1538,
      "step": 5030
    },
    {
      "epoch": 1.1560202205882353,
      "grad_norm": 1.3289127349853516,
      "learning_rate": 8.543198529411766e-06,
      "loss": 0.1312,
      "step": 5031
    },
    {
      "epoch": 1.15625,
      "grad_norm": 1.6936485767364502,
      "learning_rate": 8.542687908496732e-06,
      "loss": 0.0936,
      "step": 5032
    },
    {
      "epoch": 1.1564797794117647,
      "grad_norm": 1.7136833667755127,
      "learning_rate": 8.5421772875817e-06,
      "loss": 0.1591,
      "step": 5033
    },
    {
      "epoch": 1.1567095588235294,
      "grad_norm": 1.9113537073135376,
      "learning_rate": 8.541666666666666e-06,
      "loss": 0.112,
      "step": 5034
    },
    {
      "epoch": 1.1569393382352942,
      "grad_norm": 1.8099919557571411,
      "learning_rate": 8.541156045751634e-06,
      "loss": 0.1435,
      "step": 5035
    },
    {
      "epoch": 1.1571691176470589,
      "grad_norm": 2.1882755756378174,
      "learning_rate": 8.540645424836602e-06,
      "loss": 0.1414,
      "step": 5036
    },
    {
      "epoch": 1.1573988970588236,
      "grad_norm": 2.574435234069824,
      "learning_rate": 8.54013480392157e-06,
      "loss": 0.1599,
      "step": 5037
    },
    {
      "epoch": 1.1576286764705883,
      "grad_norm": 1.654962182044983,
      "learning_rate": 8.539624183006536e-06,
      "loss": 0.1315,
      "step": 5038
    },
    {
      "epoch": 1.157858455882353,
      "grad_norm": 1.8181849718093872,
      "learning_rate": 8.539113562091504e-06,
      "loss": 0.1496,
      "step": 5039
    },
    {
      "epoch": 1.1580882352941178,
      "grad_norm": 1.3218411207199097,
      "learning_rate": 8.538602941176472e-06,
      "loss": 0.1272,
      "step": 5040
    },
    {
      "epoch": 1.1583180147058822,
      "grad_norm": 1.776872158050537,
      "learning_rate": 8.538092320261438e-06,
      "loss": 0.1531,
      "step": 5041
    },
    {
      "epoch": 1.158547794117647,
      "grad_norm": 1.555726170539856,
      "learning_rate": 8.537581699346406e-06,
      "loss": 0.1473,
      "step": 5042
    },
    {
      "epoch": 1.1587775735294117,
      "grad_norm": 1.6198617219924927,
      "learning_rate": 8.537071078431374e-06,
      "loss": 0.1464,
      "step": 5043
    },
    {
      "epoch": 1.1590073529411764,
      "grad_norm": 1.5992423295974731,
      "learning_rate": 8.53656045751634e-06,
      "loss": 0.1428,
      "step": 5044
    },
    {
      "epoch": 1.1592371323529411,
      "grad_norm": 2.05566668510437,
      "learning_rate": 8.536049836601308e-06,
      "loss": 0.1294,
      "step": 5045
    },
    {
      "epoch": 1.1594669117647058,
      "grad_norm": 2.115222454071045,
      "learning_rate": 8.535539215686274e-06,
      "loss": 0.1181,
      "step": 5046
    },
    {
      "epoch": 1.1596966911764706,
      "grad_norm": 2.0496017932891846,
      "learning_rate": 8.535028594771244e-06,
      "loss": 0.1355,
      "step": 5047
    },
    {
      "epoch": 1.1599264705882353,
      "grad_norm": 1.8867241144180298,
      "learning_rate": 8.53451797385621e-06,
      "loss": 0.19,
      "step": 5048
    },
    {
      "epoch": 1.16015625,
      "grad_norm": 1.8699748516082764,
      "learning_rate": 8.534007352941178e-06,
      "loss": 0.209,
      "step": 5049
    },
    {
      "epoch": 1.1603860294117647,
      "grad_norm": 1.9154740571975708,
      "learning_rate": 8.533496732026144e-06,
      "loss": 0.1912,
      "step": 5050
    },
    {
      "epoch": 1.1606158088235294,
      "grad_norm": 1.7023303508758545,
      "learning_rate": 8.532986111111112e-06,
      "loss": 0.1521,
      "step": 5051
    },
    {
      "epoch": 1.1608455882352942,
      "grad_norm": 1.57431960105896,
      "learning_rate": 8.53247549019608e-06,
      "loss": 0.1616,
      "step": 5052
    },
    {
      "epoch": 1.1610753676470589,
      "grad_norm": 1.425970435142517,
      "learning_rate": 8.531964869281046e-06,
      "loss": 0.135,
      "step": 5053
    },
    {
      "epoch": 1.1613051470588236,
      "grad_norm": 1.465517282485962,
      "learning_rate": 8.531454248366014e-06,
      "loss": 0.1251,
      "step": 5054
    },
    {
      "epoch": 1.1615349264705883,
      "grad_norm": 2.0521597862243652,
      "learning_rate": 8.530943627450981e-06,
      "loss": 0.1559,
      "step": 5055
    },
    {
      "epoch": 1.161764705882353,
      "grad_norm": 1.8834545612335205,
      "learning_rate": 8.53043300653595e-06,
      "loss": 0.1699,
      "step": 5056
    },
    {
      "epoch": 1.1619944852941178,
      "grad_norm": 1.6107736825942993,
      "learning_rate": 8.529922385620915e-06,
      "loss": 0.1357,
      "step": 5057
    },
    {
      "epoch": 1.1622242647058822,
      "grad_norm": 1.1863126754760742,
      "learning_rate": 8.529411764705883e-06,
      "loss": 0.1137,
      "step": 5058
    },
    {
      "epoch": 1.162454044117647,
      "grad_norm": 1.459368348121643,
      "learning_rate": 8.528901143790851e-06,
      "loss": 0.1274,
      "step": 5059
    },
    {
      "epoch": 1.1626838235294117,
      "grad_norm": 2.42773175239563,
      "learning_rate": 8.528390522875817e-06,
      "loss": 0.1336,
      "step": 5060
    },
    {
      "epoch": 1.1629136029411764,
      "grad_norm": 1.6699801683425903,
      "learning_rate": 8.527879901960785e-06,
      "loss": 0.1833,
      "step": 5061
    },
    {
      "epoch": 1.1631433823529411,
      "grad_norm": 1.615394115447998,
      "learning_rate": 8.527369281045751e-06,
      "loss": 0.1214,
      "step": 5062
    },
    {
      "epoch": 1.1633731617647058,
      "grad_norm": 1.9777402877807617,
      "learning_rate": 8.526858660130721e-06,
      "loss": 0.2202,
      "step": 5063
    },
    {
      "epoch": 1.1636029411764706,
      "grad_norm": 1.5387518405914307,
      "learning_rate": 8.526348039215687e-06,
      "loss": 0.1454,
      "step": 5064
    },
    {
      "epoch": 1.1638327205882353,
      "grad_norm": 1.7016397714614868,
      "learning_rate": 8.525837418300655e-06,
      "loss": 0.1039,
      "step": 5065
    },
    {
      "epoch": 1.1640625,
      "grad_norm": 2.295074701309204,
      "learning_rate": 8.525326797385621e-06,
      "loss": 0.1132,
      "step": 5066
    },
    {
      "epoch": 1.1642922794117647,
      "grad_norm": 1.419507384300232,
      "learning_rate": 8.524816176470589e-06,
      "loss": 0.1262,
      "step": 5067
    },
    {
      "epoch": 1.1645220588235294,
      "grad_norm": 1.8876365423202515,
      "learning_rate": 8.524305555555557e-06,
      "loss": 0.148,
      "step": 5068
    },
    {
      "epoch": 1.1647518382352942,
      "grad_norm": 1.7033597230911255,
      "learning_rate": 8.523794934640523e-06,
      "loss": 0.1555,
      "step": 5069
    },
    {
      "epoch": 1.1649816176470589,
      "grad_norm": 1.8638309240341187,
      "learning_rate": 8.523284313725491e-06,
      "loss": 0.1405,
      "step": 5070
    },
    {
      "epoch": 1.1652113970588236,
      "grad_norm": 1.6640520095825195,
      "learning_rate": 8.522773692810459e-06,
      "loss": 0.1249,
      "step": 5071
    },
    {
      "epoch": 1.1654411764705883,
      "grad_norm": 1.5366604328155518,
      "learning_rate": 8.522263071895427e-06,
      "loss": 0.1283,
      "step": 5072
    },
    {
      "epoch": 1.165670955882353,
      "grad_norm": 1.5901007652282715,
      "learning_rate": 8.521752450980393e-06,
      "loss": 0.1635,
      "step": 5073
    },
    {
      "epoch": 1.1659007352941178,
      "grad_norm": 1.8896173238754272,
      "learning_rate": 8.52124183006536e-06,
      "loss": 0.1003,
      "step": 5074
    },
    {
      "epoch": 1.1661305147058822,
      "grad_norm": 1.4897218942642212,
      "learning_rate": 8.520731209150328e-06,
      "loss": 0.1374,
      "step": 5075
    },
    {
      "epoch": 1.166360294117647,
      "grad_norm": 1.1095771789550781,
      "learning_rate": 8.520220588235295e-06,
      "loss": 0.1199,
      "step": 5076
    },
    {
      "epoch": 1.1665900735294117,
      "grad_norm": 1.7363754510879517,
      "learning_rate": 8.519709967320263e-06,
      "loss": 0.1572,
      "step": 5077
    },
    {
      "epoch": 1.1668198529411764,
      "grad_norm": 1.8904763460159302,
      "learning_rate": 8.519199346405229e-06,
      "loss": 0.1912,
      "step": 5078
    },
    {
      "epoch": 1.1670496323529411,
      "grad_norm": 1.5942449569702148,
      "learning_rate": 8.518688725490197e-06,
      "loss": 0.1584,
      "step": 5079
    },
    {
      "epoch": 1.1672794117647058,
      "grad_norm": 1.7845667600631714,
      "learning_rate": 8.518178104575164e-06,
      "loss": 0.1703,
      "step": 5080
    },
    {
      "epoch": 1.1675091911764706,
      "grad_norm": 1.4689953327178955,
      "learning_rate": 8.517667483660132e-06,
      "loss": 0.1325,
      "step": 5081
    },
    {
      "epoch": 1.1677389705882353,
      "grad_norm": 1.7005449533462524,
      "learning_rate": 8.517156862745098e-06,
      "loss": 0.1543,
      "step": 5082
    },
    {
      "epoch": 1.16796875,
      "grad_norm": 1.8247114419937134,
      "learning_rate": 8.516646241830066e-06,
      "loss": 0.1414,
      "step": 5083
    },
    {
      "epoch": 1.1681985294117647,
      "grad_norm": 1.5137640237808228,
      "learning_rate": 8.516135620915034e-06,
      "loss": 0.1063,
      "step": 5084
    },
    {
      "epoch": 1.1684283088235294,
      "grad_norm": 1.7577418088912964,
      "learning_rate": 8.515625e-06,
      "loss": 0.1357,
      "step": 5085
    },
    {
      "epoch": 1.1686580882352942,
      "grad_norm": 1.2062652111053467,
      "learning_rate": 8.515114379084968e-06,
      "loss": 0.1059,
      "step": 5086
    },
    {
      "epoch": 1.1688878676470589,
      "grad_norm": 1.9977308511734009,
      "learning_rate": 8.514603758169934e-06,
      "loss": 0.1724,
      "step": 5087
    },
    {
      "epoch": 1.1691176470588236,
      "grad_norm": 1.68943452835083,
      "learning_rate": 8.514093137254902e-06,
      "loss": 0.1454,
      "step": 5088
    },
    {
      "epoch": 1.1693474264705883,
      "grad_norm": 1.6429502964019775,
      "learning_rate": 8.51358251633987e-06,
      "loss": 0.1373,
      "step": 5089
    },
    {
      "epoch": 1.169577205882353,
      "grad_norm": 1.3478039503097534,
      "learning_rate": 8.513071895424836e-06,
      "loss": 0.1122,
      "step": 5090
    },
    {
      "epoch": 1.1698069852941178,
      "grad_norm": 1.4684606790542603,
      "learning_rate": 8.512561274509804e-06,
      "loss": 0.1414,
      "step": 5091
    },
    {
      "epoch": 1.1700367647058822,
      "grad_norm": 1.936810851097107,
      "learning_rate": 8.512050653594772e-06,
      "loss": 0.1322,
      "step": 5092
    },
    {
      "epoch": 1.170266544117647,
      "grad_norm": 1.3554047346115112,
      "learning_rate": 8.51154003267974e-06,
      "loss": 0.1363,
      "step": 5093
    },
    {
      "epoch": 1.1704963235294117,
      "grad_norm": 1.8684422969818115,
      "learning_rate": 8.511029411764706e-06,
      "loss": 0.1663,
      "step": 5094
    },
    {
      "epoch": 1.1707261029411764,
      "grad_norm": 1.876746416091919,
      "learning_rate": 8.510518790849674e-06,
      "loss": 0.1394,
      "step": 5095
    },
    {
      "epoch": 1.1709558823529411,
      "grad_norm": 1.4475834369659424,
      "learning_rate": 8.510008169934642e-06,
      "loss": 0.1327,
      "step": 5096
    },
    {
      "epoch": 1.1711856617647058,
      "grad_norm": 1.7790824174880981,
      "learning_rate": 8.509497549019608e-06,
      "loss": 0.1213,
      "step": 5097
    },
    {
      "epoch": 1.1714154411764706,
      "grad_norm": 2.2150800228118896,
      "learning_rate": 8.508986928104576e-06,
      "loss": 0.1397,
      "step": 5098
    },
    {
      "epoch": 1.1716452205882353,
      "grad_norm": 1.5829007625579834,
      "learning_rate": 8.508476307189542e-06,
      "loss": 0.1352,
      "step": 5099
    },
    {
      "epoch": 1.171875,
      "grad_norm": 1.8105829954147339,
      "learning_rate": 8.507965686274511e-06,
      "loss": 0.1775,
      "step": 5100
    },
    {
      "epoch": 1.1721047794117647,
      "grad_norm": 1.519904375076294,
      "learning_rate": 8.507455065359478e-06,
      "loss": 0.1386,
      "step": 5101
    },
    {
      "epoch": 1.1723345588235294,
      "grad_norm": 1.4254156351089478,
      "learning_rate": 8.506944444444445e-06,
      "loss": 0.1556,
      "step": 5102
    },
    {
      "epoch": 1.1725643382352942,
      "grad_norm": 1.522861361503601,
      "learning_rate": 8.506433823529412e-06,
      "loss": 0.1199,
      "step": 5103
    },
    {
      "epoch": 1.1727941176470589,
      "grad_norm": 1.5907230377197266,
      "learning_rate": 8.50592320261438e-06,
      "loss": 0.1063,
      "step": 5104
    },
    {
      "epoch": 1.1730238970588236,
      "grad_norm": 1.468647837638855,
      "learning_rate": 8.505412581699347e-06,
      "loss": 0.1526,
      "step": 5105
    },
    {
      "epoch": 1.1732536764705883,
      "grad_norm": 1.4973978996276855,
      "learning_rate": 8.504901960784314e-06,
      "loss": 0.1177,
      "step": 5106
    },
    {
      "epoch": 1.173483455882353,
      "grad_norm": 1.755110263824463,
      "learning_rate": 8.504391339869281e-06,
      "loss": 0.1264,
      "step": 5107
    },
    {
      "epoch": 1.1737132352941178,
      "grad_norm": 1.729761004447937,
      "learning_rate": 8.50388071895425e-06,
      "loss": 0.1705,
      "step": 5108
    },
    {
      "epoch": 1.1739430147058822,
      "grad_norm": 1.7504788637161255,
      "learning_rate": 8.503370098039217e-06,
      "loss": 0.1616,
      "step": 5109
    },
    {
      "epoch": 1.174172794117647,
      "grad_norm": 1.592820644378662,
      "learning_rate": 8.502859477124183e-06,
      "loss": 0.167,
      "step": 5110
    },
    {
      "epoch": 1.1744025735294117,
      "grad_norm": 1.7785946130752563,
      "learning_rate": 8.502348856209151e-06,
      "loss": 0.1075,
      "step": 5111
    },
    {
      "epoch": 1.1746323529411764,
      "grad_norm": 1.801790475845337,
      "learning_rate": 8.501838235294119e-06,
      "loss": 0.1466,
      "step": 5112
    },
    {
      "epoch": 1.1748621323529411,
      "grad_norm": 1.4217346906661987,
      "learning_rate": 8.501327614379085e-06,
      "loss": 0.1329,
      "step": 5113
    },
    {
      "epoch": 1.1750919117647058,
      "grad_norm": 1.5856224298477173,
      "learning_rate": 8.500816993464053e-06,
      "loss": 0.1401,
      "step": 5114
    },
    {
      "epoch": 1.1753216911764706,
      "grad_norm": 1.6686712503433228,
      "learning_rate": 8.50030637254902e-06,
      "loss": 0.1637,
      "step": 5115
    },
    {
      "epoch": 1.1755514705882353,
      "grad_norm": 2.5244698524475098,
      "learning_rate": 8.499795751633989e-06,
      "loss": 0.1438,
      "step": 5116
    },
    {
      "epoch": 1.17578125,
      "grad_norm": 1.7763704061508179,
      "learning_rate": 8.499285130718955e-06,
      "loss": 0.1614,
      "step": 5117
    },
    {
      "epoch": 1.1760110294117647,
      "grad_norm": 1.8435980081558228,
      "learning_rate": 8.498774509803923e-06,
      "loss": 0.1585,
      "step": 5118
    },
    {
      "epoch": 1.1762408088235294,
      "grad_norm": 1.5767911672592163,
      "learning_rate": 8.498263888888889e-06,
      "loss": 0.1272,
      "step": 5119
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 2.10392689704895,
      "learning_rate": 8.497753267973857e-06,
      "loss": 0.1528,
      "step": 5120
    },
    {
      "epoch": 1.1767003676470589,
      "grad_norm": 2.1259074211120605,
      "learning_rate": 8.497242647058825e-06,
      "loss": 0.1662,
      "step": 5121
    },
    {
      "epoch": 1.1769301470588236,
      "grad_norm": 1.6636017560958862,
      "learning_rate": 8.496732026143791e-06,
      "loss": 0.1408,
      "step": 5122
    },
    {
      "epoch": 1.1771599264705883,
      "grad_norm": 1.6043012142181396,
      "learning_rate": 8.496221405228759e-06,
      "loss": 0.126,
      "step": 5123
    },
    {
      "epoch": 1.177389705882353,
      "grad_norm": 2.120457649230957,
      "learning_rate": 8.495710784313727e-06,
      "loss": 0.1423,
      "step": 5124
    },
    {
      "epoch": 1.1776194852941178,
      "grad_norm": 1.7735319137573242,
      "learning_rate": 8.495200163398693e-06,
      "loss": 0.1164,
      "step": 5125
    },
    {
      "epoch": 1.1778492647058822,
      "grad_norm": 1.9392648935317993,
      "learning_rate": 8.49468954248366e-06,
      "loss": 0.1552,
      "step": 5126
    },
    {
      "epoch": 1.178079044117647,
      "grad_norm": 1.435084581375122,
      "learning_rate": 8.494178921568628e-06,
      "loss": 0.1225,
      "step": 5127
    },
    {
      "epoch": 1.1783088235294117,
      "grad_norm": 2.2335426807403564,
      "learning_rate": 8.493668300653596e-06,
      "loss": 0.184,
      "step": 5128
    },
    {
      "epoch": 1.1785386029411764,
      "grad_norm": 2.08528208732605,
      "learning_rate": 8.493157679738563e-06,
      "loss": 0.1622,
      "step": 5129
    },
    {
      "epoch": 1.1787683823529411,
      "grad_norm": 1.6245758533477783,
      "learning_rate": 8.49264705882353e-06,
      "loss": 0.1226,
      "step": 5130
    },
    {
      "epoch": 1.1789981617647058,
      "grad_norm": 1.5261740684509277,
      "learning_rate": 8.492136437908497e-06,
      "loss": 0.1591,
      "step": 5131
    },
    {
      "epoch": 1.1792279411764706,
      "grad_norm": 1.5032373666763306,
      "learning_rate": 8.491625816993464e-06,
      "loss": 0.1208,
      "step": 5132
    },
    {
      "epoch": 1.1794577205882353,
      "grad_norm": 1.782714605331421,
      "learning_rate": 8.491115196078432e-06,
      "loss": 0.1455,
      "step": 5133
    },
    {
      "epoch": 1.1796875,
      "grad_norm": 1.7068897485733032,
      "learning_rate": 8.490604575163398e-06,
      "loss": 0.1257,
      "step": 5134
    },
    {
      "epoch": 1.1799172794117647,
      "grad_norm": 1.3992359638214111,
      "learning_rate": 8.490093954248366e-06,
      "loss": 0.1243,
      "step": 5135
    },
    {
      "epoch": 1.1801470588235294,
      "grad_norm": 1.6514452695846558,
      "learning_rate": 8.489583333333334e-06,
      "loss": 0.1408,
      "step": 5136
    },
    {
      "epoch": 1.1803768382352942,
      "grad_norm": 1.6478447914123535,
      "learning_rate": 8.489072712418302e-06,
      "loss": 0.114,
      "step": 5137
    },
    {
      "epoch": 1.1806066176470589,
      "grad_norm": 1.8923805952072144,
      "learning_rate": 8.488562091503268e-06,
      "loss": 0.155,
      "step": 5138
    },
    {
      "epoch": 1.1808363970588236,
      "grad_norm": 1.3689441680908203,
      "learning_rate": 8.488051470588236e-06,
      "loss": 0.0946,
      "step": 5139
    },
    {
      "epoch": 1.1810661764705883,
      "grad_norm": 1.5396900177001953,
      "learning_rate": 8.487540849673204e-06,
      "loss": 0.111,
      "step": 5140
    },
    {
      "epoch": 1.181295955882353,
      "grad_norm": 1.7298561334609985,
      "learning_rate": 8.48703022875817e-06,
      "loss": 0.1167,
      "step": 5141
    },
    {
      "epoch": 1.1815257352941178,
      "grad_norm": 1.8682761192321777,
      "learning_rate": 8.486519607843138e-06,
      "loss": 0.1351,
      "step": 5142
    },
    {
      "epoch": 1.1817555147058822,
      "grad_norm": 1.481377124786377,
      "learning_rate": 8.486008986928104e-06,
      "loss": 0.131,
      "step": 5143
    },
    {
      "epoch": 1.181985294117647,
      "grad_norm": 1.8213967084884644,
      "learning_rate": 8.485498366013074e-06,
      "loss": 0.1307,
      "step": 5144
    },
    {
      "epoch": 1.1822150735294117,
      "grad_norm": 1.5801429748535156,
      "learning_rate": 8.48498774509804e-06,
      "loss": 0.1287,
      "step": 5145
    },
    {
      "epoch": 1.1824448529411764,
      "grad_norm": 1.7513810396194458,
      "learning_rate": 8.484477124183008e-06,
      "loss": 0.142,
      "step": 5146
    },
    {
      "epoch": 1.1826746323529411,
      "grad_norm": 2.0578091144561768,
      "learning_rate": 8.483966503267974e-06,
      "loss": 0.1774,
      "step": 5147
    },
    {
      "epoch": 1.1829044117647058,
      "grad_norm": 1.180899977684021,
      "learning_rate": 8.483455882352942e-06,
      "loss": 0.1003,
      "step": 5148
    },
    {
      "epoch": 1.1831341911764706,
      "grad_norm": 2.1722521781921387,
      "learning_rate": 8.48294526143791e-06,
      "loss": 0.1725,
      "step": 5149
    },
    {
      "epoch": 1.1833639705882353,
      "grad_norm": 2.1461093425750732,
      "learning_rate": 8.482434640522876e-06,
      "loss": 0.1773,
      "step": 5150
    },
    {
      "epoch": 1.18359375,
      "grad_norm": 1.620452642440796,
      "learning_rate": 8.481924019607844e-06,
      "loss": 0.131,
      "step": 5151
    },
    {
      "epoch": 1.1838235294117647,
      "grad_norm": 2.4175169467926025,
      "learning_rate": 8.481413398692811e-06,
      "loss": 0.1694,
      "step": 5152
    },
    {
      "epoch": 1.1840533088235294,
      "grad_norm": 1.6806803941726685,
      "learning_rate": 8.48090277777778e-06,
      "loss": 0.128,
      "step": 5153
    },
    {
      "epoch": 1.1842830882352942,
      "grad_norm": 1.877507209777832,
      "learning_rate": 8.480392156862745e-06,
      "loss": 0.1558,
      "step": 5154
    },
    {
      "epoch": 1.1845128676470589,
      "grad_norm": 1.6188976764678955,
      "learning_rate": 8.479881535947713e-06,
      "loss": 0.1502,
      "step": 5155
    },
    {
      "epoch": 1.1847426470588236,
      "grad_norm": 1.5103696584701538,
      "learning_rate": 8.479370915032681e-06,
      "loss": 0.0994,
      "step": 5156
    },
    {
      "epoch": 1.1849724264705883,
      "grad_norm": 1.524481177330017,
      "learning_rate": 8.478860294117647e-06,
      "loss": 0.1547,
      "step": 5157
    },
    {
      "epoch": 1.185202205882353,
      "grad_norm": 1.9353463649749756,
      "learning_rate": 8.478349673202615e-06,
      "loss": 0.153,
      "step": 5158
    },
    {
      "epoch": 1.1854319852941178,
      "grad_norm": 2.1447579860687256,
      "learning_rate": 8.477839052287581e-06,
      "loss": 0.1731,
      "step": 5159
    },
    {
      "epoch": 1.1856617647058822,
      "grad_norm": 1.6895098686218262,
      "learning_rate": 8.477328431372551e-06,
      "loss": 0.1472,
      "step": 5160
    },
    {
      "epoch": 1.185891544117647,
      "grad_norm": 1.478471040725708,
      "learning_rate": 8.476817810457517e-06,
      "loss": 0.1345,
      "step": 5161
    },
    {
      "epoch": 1.1861213235294117,
      "grad_norm": 1.5961787700653076,
      "learning_rate": 8.476307189542485e-06,
      "loss": 0.1007,
      "step": 5162
    },
    {
      "epoch": 1.1863511029411764,
      "grad_norm": 1.615349531173706,
      "learning_rate": 8.475796568627451e-06,
      "loss": 0.1432,
      "step": 5163
    },
    {
      "epoch": 1.1865808823529411,
      "grad_norm": 1.8700065612792969,
      "learning_rate": 8.475285947712419e-06,
      "loss": 0.1601,
      "step": 5164
    },
    {
      "epoch": 1.1868106617647058,
      "grad_norm": 1.4342458248138428,
      "learning_rate": 8.474775326797387e-06,
      "loss": 0.1504,
      "step": 5165
    },
    {
      "epoch": 1.1870404411764706,
      "grad_norm": 1.5440644025802612,
      "learning_rate": 8.474264705882353e-06,
      "loss": 0.1738,
      "step": 5166
    },
    {
      "epoch": 1.1872702205882353,
      "grad_norm": 1.6866124868392944,
      "learning_rate": 8.473754084967321e-06,
      "loss": 0.1458,
      "step": 5167
    },
    {
      "epoch": 1.1875,
      "grad_norm": 1.7008243799209595,
      "learning_rate": 8.473243464052289e-06,
      "loss": 0.1494,
      "step": 5168
    },
    {
      "epoch": 1.1877297794117647,
      "grad_norm": 1.7291996479034424,
      "learning_rate": 8.472732843137255e-06,
      "loss": 0.1355,
      "step": 5169
    },
    {
      "epoch": 1.1879595588235294,
      "grad_norm": 1.4715256690979004,
      "learning_rate": 8.472222222222223e-06,
      "loss": 0.1387,
      "step": 5170
    },
    {
      "epoch": 1.1881893382352942,
      "grad_norm": 1.6196118593215942,
      "learning_rate": 8.47171160130719e-06,
      "loss": 0.1394,
      "step": 5171
    },
    {
      "epoch": 1.1884191176470589,
      "grad_norm": 1.869513750076294,
      "learning_rate": 8.471200980392159e-06,
      "loss": 0.1451,
      "step": 5172
    },
    {
      "epoch": 1.1886488970588236,
      "grad_norm": 2.0275521278381348,
      "learning_rate": 8.470690359477125e-06,
      "loss": 0.1633,
      "step": 5173
    },
    {
      "epoch": 1.1888786764705883,
      "grad_norm": 1.8479111194610596,
      "learning_rate": 8.470179738562093e-06,
      "loss": 0.1802,
      "step": 5174
    },
    {
      "epoch": 1.189108455882353,
      "grad_norm": 1.5775244235992432,
      "learning_rate": 8.469669117647059e-06,
      "loss": 0.1492,
      "step": 5175
    },
    {
      "epoch": 1.1893382352941178,
      "grad_norm": 2.072659730911255,
      "learning_rate": 8.469158496732027e-06,
      "loss": 0.1648,
      "step": 5176
    },
    {
      "epoch": 1.1895680147058822,
      "grad_norm": 1.568389892578125,
      "learning_rate": 8.468647875816994e-06,
      "loss": 0.1385,
      "step": 5177
    },
    {
      "epoch": 1.189797794117647,
      "grad_norm": 1.716999888420105,
      "learning_rate": 8.46813725490196e-06,
      "loss": 0.1234,
      "step": 5178
    },
    {
      "epoch": 1.1900275735294117,
      "grad_norm": 1.8373411893844604,
      "learning_rate": 8.467626633986928e-06,
      "loss": 0.1361,
      "step": 5179
    },
    {
      "epoch": 1.1902573529411764,
      "grad_norm": 1.6271356344223022,
      "learning_rate": 8.467116013071896e-06,
      "loss": 0.1066,
      "step": 5180
    },
    {
      "epoch": 1.1904871323529411,
      "grad_norm": 2.0092644691467285,
      "learning_rate": 8.466605392156864e-06,
      "loss": 0.174,
      "step": 5181
    },
    {
      "epoch": 1.1907169117647058,
      "grad_norm": 1.5664482116699219,
      "learning_rate": 8.46609477124183e-06,
      "loss": 0.1706,
      "step": 5182
    },
    {
      "epoch": 1.1909466911764706,
      "grad_norm": 1.497604250907898,
      "learning_rate": 8.465584150326798e-06,
      "loss": 0.1306,
      "step": 5183
    },
    {
      "epoch": 1.1911764705882353,
      "grad_norm": 2.0892975330352783,
      "learning_rate": 8.465073529411766e-06,
      "loss": 0.1346,
      "step": 5184
    },
    {
      "epoch": 1.19140625,
      "grad_norm": 2.0860462188720703,
      "learning_rate": 8.464562908496732e-06,
      "loss": 0.1651,
      "step": 5185
    },
    {
      "epoch": 1.1916360294117647,
      "grad_norm": 1.4962491989135742,
      "learning_rate": 8.4640522875817e-06,
      "loss": 0.1249,
      "step": 5186
    },
    {
      "epoch": 1.1918658088235294,
      "grad_norm": 1.3826298713684082,
      "learning_rate": 8.463541666666666e-06,
      "loss": 0.1417,
      "step": 5187
    },
    {
      "epoch": 1.1920955882352942,
      "grad_norm": 1.2473818063735962,
      "learning_rate": 8.463031045751636e-06,
      "loss": 0.1088,
      "step": 5188
    },
    {
      "epoch": 1.1923253676470589,
      "grad_norm": 1.6780648231506348,
      "learning_rate": 8.462520424836602e-06,
      "loss": 0.127,
      "step": 5189
    },
    {
      "epoch": 1.1925551470588236,
      "grad_norm": 1.1975226402282715,
      "learning_rate": 8.46200980392157e-06,
      "loss": 0.1047,
      "step": 5190
    },
    {
      "epoch": 1.1927849264705883,
      "grad_norm": 1.8667219877243042,
      "learning_rate": 8.461499183006536e-06,
      "loss": 0.1297,
      "step": 5191
    },
    {
      "epoch": 1.193014705882353,
      "grad_norm": 1.9065816402435303,
      "learning_rate": 8.460988562091504e-06,
      "loss": 0.1402,
      "step": 5192
    },
    {
      "epoch": 1.1932444852941178,
      "grad_norm": 1.6032845973968506,
      "learning_rate": 8.460477941176472e-06,
      "loss": 0.1104,
      "step": 5193
    },
    {
      "epoch": 1.1934742647058822,
      "grad_norm": 2.189887046813965,
      "learning_rate": 8.459967320261438e-06,
      "loss": 0.153,
      "step": 5194
    },
    {
      "epoch": 1.193704044117647,
      "grad_norm": 1.4136972427368164,
      "learning_rate": 8.459456699346406e-06,
      "loss": 0.1288,
      "step": 5195
    },
    {
      "epoch": 1.1939338235294117,
      "grad_norm": 1.4647678136825562,
      "learning_rate": 8.458946078431374e-06,
      "loss": 0.1121,
      "step": 5196
    },
    {
      "epoch": 1.1941636029411764,
      "grad_norm": 1.7110430002212524,
      "learning_rate": 8.458435457516342e-06,
      "loss": 0.128,
      "step": 5197
    },
    {
      "epoch": 1.1943933823529411,
      "grad_norm": 1.636928915977478,
      "learning_rate": 8.457924836601308e-06,
      "loss": 0.1397,
      "step": 5198
    },
    {
      "epoch": 1.1946231617647058,
      "grad_norm": 1.696055293083191,
      "learning_rate": 8.457414215686276e-06,
      "loss": 0.1179,
      "step": 5199
    },
    {
      "epoch": 1.1948529411764706,
      "grad_norm": 2.3429579734802246,
      "learning_rate": 8.456903594771243e-06,
      "loss": 0.211,
      "step": 5200
    },
    {
      "epoch": 1.1950827205882353,
      "grad_norm": 1.3535290956497192,
      "learning_rate": 8.45639297385621e-06,
      "loss": 0.1167,
      "step": 5201
    },
    {
      "epoch": 1.1953125,
      "grad_norm": 1.4781978130340576,
      "learning_rate": 8.455882352941177e-06,
      "loss": 0.1482,
      "step": 5202
    },
    {
      "epoch": 1.1955422794117647,
      "grad_norm": 1.4821194410324097,
      "learning_rate": 8.455371732026144e-06,
      "loss": 0.1385,
      "step": 5203
    },
    {
      "epoch": 1.1957720588235294,
      "grad_norm": 1.6827248334884644,
      "learning_rate": 8.454861111111111e-06,
      "loss": 0.1185,
      "step": 5204
    },
    {
      "epoch": 1.1960018382352942,
      "grad_norm": 1.674232840538025,
      "learning_rate": 8.45435049019608e-06,
      "loss": 0.1566,
      "step": 5205
    },
    {
      "epoch": 1.1962316176470589,
      "grad_norm": 1.3006248474121094,
      "learning_rate": 8.453839869281047e-06,
      "loss": 0.128,
      "step": 5206
    },
    {
      "epoch": 1.1964613970588236,
      "grad_norm": 2.118136405944824,
      "learning_rate": 8.453329248366013e-06,
      "loss": 0.1241,
      "step": 5207
    },
    {
      "epoch": 1.1966911764705883,
      "grad_norm": 1.5958188772201538,
      "learning_rate": 8.452818627450981e-06,
      "loss": 0.1527,
      "step": 5208
    },
    {
      "epoch": 1.196920955882353,
      "grad_norm": 1.4186222553253174,
      "learning_rate": 8.452308006535949e-06,
      "loss": 0.1144,
      "step": 5209
    },
    {
      "epoch": 1.1971507352941178,
      "grad_norm": 1.8672438859939575,
      "learning_rate": 8.451797385620915e-06,
      "loss": 0.1714,
      "step": 5210
    },
    {
      "epoch": 1.1973805147058822,
      "grad_norm": 1.9459376335144043,
      "learning_rate": 8.451286764705883e-06,
      "loss": 0.1666,
      "step": 5211
    },
    {
      "epoch": 1.197610294117647,
      "grad_norm": 2.163278818130493,
      "learning_rate": 8.450776143790851e-06,
      "loss": 0.1195,
      "step": 5212
    },
    {
      "epoch": 1.1978400735294117,
      "grad_norm": 1.63483464717865,
      "learning_rate": 8.450265522875817e-06,
      "loss": 0.1102,
      "step": 5213
    },
    {
      "epoch": 1.1980698529411764,
      "grad_norm": 1.9283355474472046,
      "learning_rate": 8.449754901960785e-06,
      "loss": 0.1151,
      "step": 5214
    },
    {
      "epoch": 1.1982996323529411,
      "grad_norm": 2.0498721599578857,
      "learning_rate": 8.449244281045753e-06,
      "loss": 0.1497,
      "step": 5215
    },
    {
      "epoch": 1.1985294117647058,
      "grad_norm": 1.452211856842041,
      "learning_rate": 8.44873366013072e-06,
      "loss": 0.1574,
      "step": 5216
    },
    {
      "epoch": 1.1987591911764706,
      "grad_norm": 1.6573700904846191,
      "learning_rate": 8.448223039215687e-06,
      "loss": 0.1397,
      "step": 5217
    },
    {
      "epoch": 1.1989889705882353,
      "grad_norm": 1.6626707315444946,
      "learning_rate": 8.447712418300655e-06,
      "loss": 0.1573,
      "step": 5218
    },
    {
      "epoch": 1.19921875,
      "grad_norm": 1.7961405515670776,
      "learning_rate": 8.447201797385621e-06,
      "loss": 0.1211,
      "step": 5219
    },
    {
      "epoch": 1.1994485294117647,
      "grad_norm": 1.733426809310913,
      "learning_rate": 8.446691176470589e-06,
      "loss": 0.1572,
      "step": 5220
    },
    {
      "epoch": 1.1996783088235294,
      "grad_norm": 2.035047769546509,
      "learning_rate": 8.446180555555557e-06,
      "loss": 0.1238,
      "step": 5221
    },
    {
      "epoch": 1.1999080882352942,
      "grad_norm": 1.7354202270507812,
      "learning_rate": 8.445669934640523e-06,
      "loss": 0.1351,
      "step": 5222
    },
    {
      "epoch": 1.2001378676470589,
      "grad_norm": 1.6171643733978271,
      "learning_rate": 8.44515931372549e-06,
      "loss": 0.1362,
      "step": 5223
    },
    {
      "epoch": 1.2003676470588236,
      "grad_norm": 2.259751796722412,
      "learning_rate": 8.444648692810459e-06,
      "loss": 0.1821,
      "step": 5224
    },
    {
      "epoch": 1.2005974264705883,
      "grad_norm": 1.5374897718429565,
      "learning_rate": 8.444138071895426e-06,
      "loss": 0.126,
      "step": 5225
    },
    {
      "epoch": 1.200827205882353,
      "grad_norm": 1.7918131351470947,
      "learning_rate": 8.443627450980393e-06,
      "loss": 0.154,
      "step": 5226
    },
    {
      "epoch": 1.2010569852941178,
      "grad_norm": 1.427629828453064,
      "learning_rate": 8.44311683006536e-06,
      "loss": 0.1176,
      "step": 5227
    },
    {
      "epoch": 1.2012867647058822,
      "grad_norm": 1.8371998071670532,
      "learning_rate": 8.442606209150328e-06,
      "loss": 0.1785,
      "step": 5228
    },
    {
      "epoch": 1.201516544117647,
      "grad_norm": 1.8075733184814453,
      "learning_rate": 8.442095588235294e-06,
      "loss": 0.1317,
      "step": 5229
    },
    {
      "epoch": 1.2017463235294117,
      "grad_norm": 1.3717325925827026,
      "learning_rate": 8.441584967320262e-06,
      "loss": 0.1281,
      "step": 5230
    },
    {
      "epoch": 1.2019761029411764,
      "grad_norm": 1.6486409902572632,
      "learning_rate": 8.441074346405228e-06,
      "loss": 0.1186,
      "step": 5231
    },
    {
      "epoch": 1.2022058823529411,
      "grad_norm": 2.019575595855713,
      "learning_rate": 8.440563725490198e-06,
      "loss": 0.2179,
      "step": 5232
    },
    {
      "epoch": 1.2024356617647058,
      "grad_norm": 1.172456979751587,
      "learning_rate": 8.440053104575164e-06,
      "loss": 0.1077,
      "step": 5233
    },
    {
      "epoch": 1.2026654411764706,
      "grad_norm": 2.070737600326538,
      "learning_rate": 8.439542483660132e-06,
      "loss": 0.1157,
      "step": 5234
    },
    {
      "epoch": 1.2028952205882353,
      "grad_norm": 1.4546310901641846,
      "learning_rate": 8.439031862745098e-06,
      "loss": 0.1208,
      "step": 5235
    },
    {
      "epoch": 1.203125,
      "grad_norm": 1.4732050895690918,
      "learning_rate": 8.438521241830066e-06,
      "loss": 0.114,
      "step": 5236
    },
    {
      "epoch": 1.2033547794117647,
      "grad_norm": 1.9142189025878906,
      "learning_rate": 8.438010620915034e-06,
      "loss": 0.1214,
      "step": 5237
    },
    {
      "epoch": 1.2035845588235294,
      "grad_norm": 1.3469018936157227,
      "learning_rate": 8.4375e-06,
      "loss": 0.1382,
      "step": 5238
    },
    {
      "epoch": 1.2038143382352942,
      "grad_norm": 1.592496395111084,
      "learning_rate": 8.436989379084968e-06,
      "loss": 0.1789,
      "step": 5239
    },
    {
      "epoch": 1.2040441176470589,
      "grad_norm": 1.5889288187026978,
      "learning_rate": 8.436478758169934e-06,
      "loss": 0.1158,
      "step": 5240
    },
    {
      "epoch": 1.2042738970588236,
      "grad_norm": 1.7690941095352173,
      "learning_rate": 8.435968137254904e-06,
      "loss": 0.1572,
      "step": 5241
    },
    {
      "epoch": 1.2045036764705883,
      "grad_norm": 1.3136718273162842,
      "learning_rate": 8.43545751633987e-06,
      "loss": 0.1365,
      "step": 5242
    },
    {
      "epoch": 1.204733455882353,
      "grad_norm": 1.7681597471237183,
      "learning_rate": 8.434946895424838e-06,
      "loss": 0.1338,
      "step": 5243
    },
    {
      "epoch": 1.2049632352941178,
      "grad_norm": 1.4514371156692505,
      "learning_rate": 8.434436274509804e-06,
      "loss": 0.1025,
      "step": 5244
    },
    {
      "epoch": 1.2051930147058822,
      "grad_norm": 1.417790174484253,
      "learning_rate": 8.433925653594772e-06,
      "loss": 0.1158,
      "step": 5245
    },
    {
      "epoch": 1.205422794117647,
      "grad_norm": 1.6313297748565674,
      "learning_rate": 8.43341503267974e-06,
      "loss": 0.1029,
      "step": 5246
    },
    {
      "epoch": 1.2056525735294117,
      "grad_norm": 2.1009984016418457,
      "learning_rate": 8.432904411764706e-06,
      "loss": 0.1219,
      "step": 5247
    },
    {
      "epoch": 1.2058823529411764,
      "grad_norm": 1.7567263841629028,
      "learning_rate": 8.432393790849674e-06,
      "loss": 0.1311,
      "step": 5248
    },
    {
      "epoch": 1.2061121323529411,
      "grad_norm": 1.550368070602417,
      "learning_rate": 8.431883169934642e-06,
      "loss": 0.1643,
      "step": 5249
    },
    {
      "epoch": 1.2063419117647058,
      "grad_norm": 1.4939671754837036,
      "learning_rate": 8.43137254901961e-06,
      "loss": 0.1233,
      "step": 5250
    },
    {
      "epoch": 1.2065716911764706,
      "grad_norm": 2.4715750217437744,
      "learning_rate": 8.430861928104576e-06,
      "loss": 0.1554,
      "step": 5251
    },
    {
      "epoch": 1.2068014705882353,
      "grad_norm": 2.1935417652130127,
      "learning_rate": 8.430351307189543e-06,
      "loss": 0.1046,
      "step": 5252
    },
    {
      "epoch": 1.20703125,
      "grad_norm": 2.1781511306762695,
      "learning_rate": 8.429840686274511e-06,
      "loss": 0.218,
      "step": 5253
    },
    {
      "epoch": 1.2072610294117647,
      "grad_norm": 1.9400488138198853,
      "learning_rate": 8.429330065359477e-06,
      "loss": 0.133,
      "step": 5254
    },
    {
      "epoch": 1.2074908088235294,
      "grad_norm": 1.9929784536361694,
      "learning_rate": 8.428819444444445e-06,
      "loss": 0.1896,
      "step": 5255
    },
    {
      "epoch": 1.2077205882352942,
      "grad_norm": 1.5502959489822388,
      "learning_rate": 8.428308823529411e-06,
      "loss": 0.1497,
      "step": 5256
    },
    {
      "epoch": 1.2079503676470589,
      "grad_norm": 1.6466244459152222,
      "learning_rate": 8.42779820261438e-06,
      "loss": 0.147,
      "step": 5257
    },
    {
      "epoch": 1.2081801470588236,
      "grad_norm": 1.6686489582061768,
      "learning_rate": 8.427287581699347e-06,
      "loss": 0.1312,
      "step": 5258
    },
    {
      "epoch": 1.2084099264705883,
      "grad_norm": 1.6817420721054077,
      "learning_rate": 8.426776960784313e-06,
      "loss": 0.1384,
      "step": 5259
    },
    {
      "epoch": 1.208639705882353,
      "grad_norm": 1.5616611242294312,
      "learning_rate": 8.426266339869281e-06,
      "loss": 0.1502,
      "step": 5260
    },
    {
      "epoch": 1.2088694852941178,
      "grad_norm": 1.7489210367202759,
      "learning_rate": 8.425755718954249e-06,
      "loss": 0.1459,
      "step": 5261
    },
    {
      "epoch": 1.2090992647058822,
      "grad_norm": 1.315255045890808,
      "learning_rate": 8.425245098039217e-06,
      "loss": 0.1163,
      "step": 5262
    },
    {
      "epoch": 1.209329044117647,
      "grad_norm": 1.4681018590927124,
      "learning_rate": 8.424734477124183e-06,
      "loss": 0.1239,
      "step": 5263
    },
    {
      "epoch": 1.2095588235294117,
      "grad_norm": 1.7990953922271729,
      "learning_rate": 8.424223856209151e-06,
      "loss": 0.1427,
      "step": 5264
    },
    {
      "epoch": 1.2097886029411764,
      "grad_norm": 1.6537531614303589,
      "learning_rate": 8.423713235294119e-06,
      "loss": 0.0826,
      "step": 5265
    },
    {
      "epoch": 1.2100183823529411,
      "grad_norm": 1.5888768434524536,
      "learning_rate": 8.423202614379085e-06,
      "loss": 0.1154,
      "step": 5266
    },
    {
      "epoch": 1.2102481617647058,
      "grad_norm": 1.4574609994888306,
      "learning_rate": 8.422691993464053e-06,
      "loss": 0.101,
      "step": 5267
    },
    {
      "epoch": 1.2104779411764706,
      "grad_norm": 1.5960793495178223,
      "learning_rate": 8.422181372549019e-06,
      "loss": 0.1367,
      "step": 5268
    },
    {
      "epoch": 1.2107077205882353,
      "grad_norm": 1.641538143157959,
      "learning_rate": 8.421670751633989e-06,
      "loss": 0.1226,
      "step": 5269
    },
    {
      "epoch": 1.2109375,
      "grad_norm": 1.3332161903381348,
      "learning_rate": 8.421160130718955e-06,
      "loss": 0.0991,
      "step": 5270
    },
    {
      "epoch": 1.2111672794117647,
      "grad_norm": 1.5423190593719482,
      "learning_rate": 8.420649509803923e-06,
      "loss": 0.151,
      "step": 5271
    },
    {
      "epoch": 1.2113970588235294,
      "grad_norm": 1.9379045963287354,
      "learning_rate": 8.420138888888889e-06,
      "loss": 0.135,
      "step": 5272
    },
    {
      "epoch": 1.2116268382352942,
      "grad_norm": 1.3439332246780396,
      "learning_rate": 8.419628267973857e-06,
      "loss": 0.1148,
      "step": 5273
    },
    {
      "epoch": 1.2118566176470589,
      "grad_norm": 1.9328268766403198,
      "learning_rate": 8.419117647058824e-06,
      "loss": 0.155,
      "step": 5274
    },
    {
      "epoch": 1.2120863970588236,
      "grad_norm": 1.1868641376495361,
      "learning_rate": 8.41860702614379e-06,
      "loss": 0.0979,
      "step": 5275
    },
    {
      "epoch": 1.2123161764705883,
      "grad_norm": 1.719873070716858,
      "learning_rate": 8.418096405228759e-06,
      "loss": 0.1594,
      "step": 5276
    },
    {
      "epoch": 1.212545955882353,
      "grad_norm": 1.746932864189148,
      "learning_rate": 8.417585784313726e-06,
      "loss": 0.142,
      "step": 5277
    },
    {
      "epoch": 1.2127757352941178,
      "grad_norm": 1.7576625347137451,
      "learning_rate": 8.417075163398694e-06,
      "loss": 0.1105,
      "step": 5278
    },
    {
      "epoch": 1.2130055147058822,
      "grad_norm": 1.6425358057022095,
      "learning_rate": 8.41656454248366e-06,
      "loss": 0.1394,
      "step": 5279
    },
    {
      "epoch": 1.213235294117647,
      "grad_norm": 1.5922434329986572,
      "learning_rate": 8.416053921568628e-06,
      "loss": 0.1507,
      "step": 5280
    },
    {
      "epoch": 1.2134650735294117,
      "grad_norm": 1.7942869663238525,
      "learning_rate": 8.415543300653596e-06,
      "loss": 0.1086,
      "step": 5281
    },
    {
      "epoch": 1.2136948529411764,
      "grad_norm": 1.5170910358428955,
      "learning_rate": 8.415032679738562e-06,
      "loss": 0.1417,
      "step": 5282
    },
    {
      "epoch": 1.2139246323529411,
      "grad_norm": 1.676137089729309,
      "learning_rate": 8.41452205882353e-06,
      "loss": 0.1535,
      "step": 5283
    },
    {
      "epoch": 1.2141544117647058,
      "grad_norm": 1.9783326387405396,
      "learning_rate": 8.414011437908496e-06,
      "loss": 0.1993,
      "step": 5284
    },
    {
      "epoch": 1.2143841911764706,
      "grad_norm": 2.037956953048706,
      "learning_rate": 8.413500816993466e-06,
      "loss": 0.1511,
      "step": 5285
    },
    {
      "epoch": 1.2146139705882353,
      "grad_norm": 1.4309715032577515,
      "learning_rate": 8.412990196078432e-06,
      "loss": 0.1347,
      "step": 5286
    },
    {
      "epoch": 1.21484375,
      "grad_norm": 1.8322498798370361,
      "learning_rate": 8.4124795751634e-06,
      "loss": 0.1802,
      "step": 5287
    },
    {
      "epoch": 1.2150735294117647,
      "grad_norm": 2.6081769466400146,
      "learning_rate": 8.411968954248366e-06,
      "loss": 0.1773,
      "step": 5288
    },
    {
      "epoch": 1.2153033088235294,
      "grad_norm": 1.4913973808288574,
      "learning_rate": 8.411458333333334e-06,
      "loss": 0.1594,
      "step": 5289
    },
    {
      "epoch": 1.2155330882352942,
      "grad_norm": 2.1281189918518066,
      "learning_rate": 8.410947712418302e-06,
      "loss": 0.1911,
      "step": 5290
    },
    {
      "epoch": 1.2157628676470589,
      "grad_norm": 2.378044366836548,
      "learning_rate": 8.410437091503268e-06,
      "loss": 0.1623,
      "step": 5291
    },
    {
      "epoch": 1.2159926470588236,
      "grad_norm": 1.5825557708740234,
      "learning_rate": 8.409926470588236e-06,
      "loss": 0.1238,
      "step": 5292
    },
    {
      "epoch": 1.2162224264705883,
      "grad_norm": 2.1554415225982666,
      "learning_rate": 8.409415849673204e-06,
      "loss": 0.1278,
      "step": 5293
    },
    {
      "epoch": 1.216452205882353,
      "grad_norm": 1.8572033643722534,
      "learning_rate": 8.408905228758172e-06,
      "loss": 0.1672,
      "step": 5294
    },
    {
      "epoch": 1.2166819852941178,
      "grad_norm": 1.6776365041732788,
      "learning_rate": 8.408394607843138e-06,
      "loss": 0.149,
      "step": 5295
    },
    {
      "epoch": 1.2169117647058822,
      "grad_norm": 1.6853097677230835,
      "learning_rate": 8.407883986928106e-06,
      "loss": 0.1347,
      "step": 5296
    },
    {
      "epoch": 1.217141544117647,
      "grad_norm": 1.616615891456604,
      "learning_rate": 8.407373366013073e-06,
      "loss": 0.1338,
      "step": 5297
    },
    {
      "epoch": 1.2173713235294117,
      "grad_norm": 1.7686388492584229,
      "learning_rate": 8.40686274509804e-06,
      "loss": 0.138,
      "step": 5298
    },
    {
      "epoch": 1.2176011029411764,
      "grad_norm": 1.9807050228118896,
      "learning_rate": 8.406352124183007e-06,
      "loss": 0.1605,
      "step": 5299
    },
    {
      "epoch": 1.2178308823529411,
      "grad_norm": 1.7962225675582886,
      "learning_rate": 8.405841503267974e-06,
      "loss": 0.1664,
      "step": 5300
    },
    {
      "epoch": 1.2180606617647058,
      "grad_norm": 1.8238693475723267,
      "learning_rate": 8.405330882352941e-06,
      "loss": 0.1509,
      "step": 5301
    },
    {
      "epoch": 1.2182904411764706,
      "grad_norm": 1.5914303064346313,
      "learning_rate": 8.40482026143791e-06,
      "loss": 0.1478,
      "step": 5302
    },
    {
      "epoch": 1.2185202205882353,
      "grad_norm": 1.749727487564087,
      "learning_rate": 8.404309640522876e-06,
      "loss": 0.1324,
      "step": 5303
    },
    {
      "epoch": 1.21875,
      "grad_norm": 1.7244701385498047,
      "learning_rate": 8.403799019607843e-06,
      "loss": 0.1283,
      "step": 5304
    },
    {
      "epoch": 1.2189797794117647,
      "grad_norm": 2.267571449279785,
      "learning_rate": 8.403288398692811e-06,
      "loss": 0.1585,
      "step": 5305
    },
    {
      "epoch": 1.2192095588235294,
      "grad_norm": 1.6221656799316406,
      "learning_rate": 8.402777777777779e-06,
      "loss": 0.1268,
      "step": 5306
    },
    {
      "epoch": 1.2194393382352942,
      "grad_norm": 1.8027828931808472,
      "learning_rate": 8.402267156862745e-06,
      "loss": 0.1403,
      "step": 5307
    },
    {
      "epoch": 1.2196691176470589,
      "grad_norm": 1.2656314373016357,
      "learning_rate": 8.401756535947713e-06,
      "loss": 0.1206,
      "step": 5308
    },
    {
      "epoch": 1.2198988970588236,
      "grad_norm": 1.618950366973877,
      "learning_rate": 8.401245915032681e-06,
      "loss": 0.1286,
      "step": 5309
    },
    {
      "epoch": 1.2201286764705883,
      "grad_norm": 1.4395089149475098,
      "learning_rate": 8.400735294117647e-06,
      "loss": 0.1574,
      "step": 5310
    },
    {
      "epoch": 1.220358455882353,
      "grad_norm": 1.9921342134475708,
      "learning_rate": 8.400224673202615e-06,
      "loss": 0.1702,
      "step": 5311
    },
    {
      "epoch": 1.2205882352941178,
      "grad_norm": 2.030907154083252,
      "learning_rate": 8.399714052287581e-06,
      "loss": 0.1745,
      "step": 5312
    },
    {
      "epoch": 1.2208180147058822,
      "grad_norm": 1.6860918998718262,
      "learning_rate": 8.39920343137255e-06,
      "loss": 0.1546,
      "step": 5313
    },
    {
      "epoch": 1.221047794117647,
      "grad_norm": 1.9861831665039062,
      "learning_rate": 8.398692810457517e-06,
      "loss": 0.115,
      "step": 5314
    },
    {
      "epoch": 1.2212775735294117,
      "grad_norm": 1.7380274534225464,
      "learning_rate": 8.398182189542485e-06,
      "loss": 0.192,
      "step": 5315
    },
    {
      "epoch": 1.2215073529411764,
      "grad_norm": 1.9163552522659302,
      "learning_rate": 8.397671568627451e-06,
      "loss": 0.1547,
      "step": 5316
    },
    {
      "epoch": 1.2217371323529411,
      "grad_norm": 2.1690733432769775,
      "learning_rate": 8.397160947712419e-06,
      "loss": 0.1247,
      "step": 5317
    },
    {
      "epoch": 1.2219669117647058,
      "grad_norm": 2.027316093444824,
      "learning_rate": 8.396650326797387e-06,
      "loss": 0.133,
      "step": 5318
    },
    {
      "epoch": 1.2221966911764706,
      "grad_norm": 1.8705458641052246,
      "learning_rate": 8.396139705882353e-06,
      "loss": 0.1156,
      "step": 5319
    },
    {
      "epoch": 1.2224264705882353,
      "grad_norm": 1.6983482837677002,
      "learning_rate": 8.39562908496732e-06,
      "loss": 0.1477,
      "step": 5320
    },
    {
      "epoch": 1.22265625,
      "grad_norm": 1.85274076461792,
      "learning_rate": 8.395118464052289e-06,
      "loss": 0.1352,
      "step": 5321
    },
    {
      "epoch": 1.2228860294117647,
      "grad_norm": 1.9191018342971802,
      "learning_rate": 8.394607843137256e-06,
      "loss": 0.1246,
      "step": 5322
    },
    {
      "epoch": 1.2231158088235294,
      "grad_norm": 1.7885963916778564,
      "learning_rate": 8.394097222222223e-06,
      "loss": 0.1906,
      "step": 5323
    },
    {
      "epoch": 1.2233455882352942,
      "grad_norm": 1.9917577505111694,
      "learning_rate": 8.39358660130719e-06,
      "loss": 0.1143,
      "step": 5324
    },
    {
      "epoch": 1.2235753676470589,
      "grad_norm": 2.154750347137451,
      "learning_rate": 8.393075980392158e-06,
      "loss": 0.2049,
      "step": 5325
    },
    {
      "epoch": 1.2238051470588236,
      "grad_norm": 1.8387713432312012,
      "learning_rate": 8.392565359477124e-06,
      "loss": 0.1963,
      "step": 5326
    },
    {
      "epoch": 1.2240349264705883,
      "grad_norm": 1.6940542459487915,
      "learning_rate": 8.392054738562092e-06,
      "loss": 0.1205,
      "step": 5327
    },
    {
      "epoch": 1.224264705882353,
      "grad_norm": 1.5340099334716797,
      "learning_rate": 8.391544117647059e-06,
      "loss": 0.1143,
      "step": 5328
    },
    {
      "epoch": 1.2244944852941178,
      "grad_norm": 1.5584853887557983,
      "learning_rate": 8.391033496732028e-06,
      "loss": 0.1415,
      "step": 5329
    },
    {
      "epoch": 1.2247242647058822,
      "grad_norm": 1.6319727897644043,
      "learning_rate": 8.390522875816994e-06,
      "loss": 0.1274,
      "step": 5330
    },
    {
      "epoch": 1.224954044117647,
      "grad_norm": 1.7848825454711914,
      "learning_rate": 8.390012254901962e-06,
      "loss": 0.1295,
      "step": 5331
    },
    {
      "epoch": 1.2251838235294117,
      "grad_norm": 1.526334285736084,
      "learning_rate": 8.389501633986928e-06,
      "loss": 0.115,
      "step": 5332
    },
    {
      "epoch": 1.2254136029411764,
      "grad_norm": 1.5546494722366333,
      "learning_rate": 8.388991013071896e-06,
      "loss": 0.1219,
      "step": 5333
    },
    {
      "epoch": 1.2256433823529411,
      "grad_norm": 1.471611499786377,
      "learning_rate": 8.388480392156864e-06,
      "loss": 0.1046,
      "step": 5334
    },
    {
      "epoch": 1.2258731617647058,
      "grad_norm": 2.0466806888580322,
      "learning_rate": 8.38796977124183e-06,
      "loss": 0.1332,
      "step": 5335
    },
    {
      "epoch": 1.2261029411764706,
      "grad_norm": 1.872580885887146,
      "learning_rate": 8.387459150326798e-06,
      "loss": 0.1271,
      "step": 5336
    },
    {
      "epoch": 1.2263327205882353,
      "grad_norm": 1.9676319360733032,
      "learning_rate": 8.386948529411766e-06,
      "loss": 0.1423,
      "step": 5337
    },
    {
      "epoch": 1.2265625,
      "grad_norm": 2.3872601985931396,
      "learning_rate": 8.386437908496734e-06,
      "loss": 0.1178,
      "step": 5338
    },
    {
      "epoch": 1.2267922794117647,
      "grad_norm": 1.6433911323547363,
      "learning_rate": 8.3859272875817e-06,
      "loss": 0.1379,
      "step": 5339
    },
    {
      "epoch": 1.2270220588235294,
      "grad_norm": 2.3180837631225586,
      "learning_rate": 8.385416666666668e-06,
      "loss": 0.1371,
      "step": 5340
    },
    {
      "epoch": 1.2272518382352942,
      "grad_norm": 1.8963518142700195,
      "learning_rate": 8.384906045751636e-06,
      "loss": 0.1325,
      "step": 5341
    },
    {
      "epoch": 1.2274816176470589,
      "grad_norm": 1.5958585739135742,
      "learning_rate": 8.384395424836602e-06,
      "loss": 0.1613,
      "step": 5342
    },
    {
      "epoch": 1.2277113970588236,
      "grad_norm": 1.5382599830627441,
      "learning_rate": 8.38388480392157e-06,
      "loss": 0.1395,
      "step": 5343
    },
    {
      "epoch": 1.2279411764705883,
      "grad_norm": 1.2980358600616455,
      "learning_rate": 8.383374183006536e-06,
      "loss": 0.1179,
      "step": 5344
    },
    {
      "epoch": 1.228170955882353,
      "grad_norm": 1.3855724334716797,
      "learning_rate": 8.382863562091504e-06,
      "loss": 0.09,
      "step": 5345
    },
    {
      "epoch": 1.2284007352941178,
      "grad_norm": 1.6537905931472778,
      "learning_rate": 8.382352941176472e-06,
      "loss": 0.1749,
      "step": 5346
    },
    {
      "epoch": 1.2286305147058822,
      "grad_norm": 1.8374950885772705,
      "learning_rate": 8.381842320261438e-06,
      "loss": 0.108,
      "step": 5347
    },
    {
      "epoch": 1.228860294117647,
      "grad_norm": 2.167617082595825,
      "learning_rate": 8.381331699346406e-06,
      "loss": 0.1094,
      "step": 5348
    },
    {
      "epoch": 1.2290900735294117,
      "grad_norm": 1.3926262855529785,
      "learning_rate": 8.380821078431373e-06,
      "loss": 0.0987,
      "step": 5349
    },
    {
      "epoch": 1.2293198529411764,
      "grad_norm": 1.9502865076065063,
      "learning_rate": 8.380310457516341e-06,
      "loss": 0.1437,
      "step": 5350
    },
    {
      "epoch": 1.2295496323529411,
      "grad_norm": 1.5697877407073975,
      "learning_rate": 8.379799836601307e-06,
      "loss": 0.1228,
      "step": 5351
    },
    {
      "epoch": 1.2297794117647058,
      "grad_norm": 1.8587452173233032,
      "learning_rate": 8.379289215686275e-06,
      "loss": 0.1163,
      "step": 5352
    },
    {
      "epoch": 1.2300091911764706,
      "grad_norm": 2.556469440460205,
      "learning_rate": 8.378778594771243e-06,
      "loss": 0.1606,
      "step": 5353
    },
    {
      "epoch": 1.2302389705882353,
      "grad_norm": 1.5457561016082764,
      "learning_rate": 8.37826797385621e-06,
      "loss": 0.1254,
      "step": 5354
    },
    {
      "epoch": 1.23046875,
      "grad_norm": 1.5356367826461792,
      "learning_rate": 8.377757352941177e-06,
      "loss": 0.1351,
      "step": 5355
    },
    {
      "epoch": 1.2306985294117647,
      "grad_norm": 1.3831379413604736,
      "learning_rate": 8.377246732026143e-06,
      "loss": 0.1034,
      "step": 5356
    },
    {
      "epoch": 1.2309283088235294,
      "grad_norm": 1.5911778211593628,
      "learning_rate": 8.376736111111113e-06,
      "loss": 0.1186,
      "step": 5357
    },
    {
      "epoch": 1.2311580882352942,
      "grad_norm": 1.635773777961731,
      "learning_rate": 8.376225490196079e-06,
      "loss": 0.1181,
      "step": 5358
    },
    {
      "epoch": 1.2313878676470589,
      "grad_norm": 1.6888837814331055,
      "learning_rate": 8.375714869281047e-06,
      "loss": 0.1279,
      "step": 5359
    },
    {
      "epoch": 1.2316176470588236,
      "grad_norm": 1.8080703020095825,
      "learning_rate": 8.375204248366013e-06,
      "loss": 0.1378,
      "step": 5360
    },
    {
      "epoch": 1.2318474264705883,
      "grad_norm": 2.0751683712005615,
      "learning_rate": 8.374693627450981e-06,
      "loss": 0.1517,
      "step": 5361
    },
    {
      "epoch": 1.232077205882353,
      "grad_norm": 1.6986297369003296,
      "learning_rate": 8.374183006535949e-06,
      "loss": 0.1401,
      "step": 5362
    },
    {
      "epoch": 1.2323069852941178,
      "grad_norm": 1.9011657238006592,
      "learning_rate": 8.373672385620915e-06,
      "loss": 0.0949,
      "step": 5363
    },
    {
      "epoch": 1.2325367647058822,
      "grad_norm": 1.931376576423645,
      "learning_rate": 8.373161764705883e-06,
      "loss": 0.1375,
      "step": 5364
    },
    {
      "epoch": 1.232766544117647,
      "grad_norm": 1.6004270315170288,
      "learning_rate": 8.37265114379085e-06,
      "loss": 0.1581,
      "step": 5365
    },
    {
      "epoch": 1.2329963235294117,
      "grad_norm": 1.8154171705245972,
      "learning_rate": 8.372140522875819e-06,
      "loss": 0.1241,
      "step": 5366
    },
    {
      "epoch": 1.2332261029411764,
      "grad_norm": 1.368237853050232,
      "learning_rate": 8.371629901960785e-06,
      "loss": 0.0831,
      "step": 5367
    },
    {
      "epoch": 1.2334558823529411,
      "grad_norm": 2.089646816253662,
      "learning_rate": 8.371119281045753e-06,
      "loss": 0.1496,
      "step": 5368
    },
    {
      "epoch": 1.2336856617647058,
      "grad_norm": 1.3039320707321167,
      "learning_rate": 8.37060866013072e-06,
      "loss": 0.1003,
      "step": 5369
    },
    {
      "epoch": 1.2339154411764706,
      "grad_norm": 1.7244668006896973,
      "learning_rate": 8.370098039215687e-06,
      "loss": 0.128,
      "step": 5370
    },
    {
      "epoch": 1.2341452205882353,
      "grad_norm": 1.8123677968978882,
      "learning_rate": 8.369587418300655e-06,
      "loss": 0.1139,
      "step": 5371
    },
    {
      "epoch": 1.234375,
      "grad_norm": 1.6161925792694092,
      "learning_rate": 8.36907679738562e-06,
      "loss": 0.1208,
      "step": 5372
    },
    {
      "epoch": 1.2346047794117647,
      "grad_norm": 1.54532790184021,
      "learning_rate": 8.36856617647059e-06,
      "loss": 0.1319,
      "step": 5373
    },
    {
      "epoch": 1.2348345588235294,
      "grad_norm": 1.673113226890564,
      "learning_rate": 8.368055555555556e-06,
      "loss": 0.1292,
      "step": 5374
    },
    {
      "epoch": 1.2350643382352942,
      "grad_norm": 1.9685319662094116,
      "learning_rate": 8.367544934640524e-06,
      "loss": 0.1442,
      "step": 5375
    },
    {
      "epoch": 1.2352941176470589,
      "grad_norm": 2.5223355293273926,
      "learning_rate": 8.36703431372549e-06,
      "loss": 0.1918,
      "step": 5376
    },
    {
      "epoch": 1.2355238970588236,
      "grad_norm": 1.6324139833450317,
      "learning_rate": 8.366523692810458e-06,
      "loss": 0.1347,
      "step": 5377
    },
    {
      "epoch": 1.2357536764705883,
      "grad_norm": 1.980747938156128,
      "learning_rate": 8.366013071895426e-06,
      "loss": 0.1268,
      "step": 5378
    },
    {
      "epoch": 1.235983455882353,
      "grad_norm": 1.5520029067993164,
      "learning_rate": 8.365502450980392e-06,
      "loss": 0.1692,
      "step": 5379
    },
    {
      "epoch": 1.2362132352941178,
      "grad_norm": 1.5191434621810913,
      "learning_rate": 8.36499183006536e-06,
      "loss": 0.0988,
      "step": 5380
    },
    {
      "epoch": 1.2364430147058822,
      "grad_norm": 1.501349925994873,
      "learning_rate": 8.364481209150328e-06,
      "loss": 0.1202,
      "step": 5381
    },
    {
      "epoch": 1.236672794117647,
      "grad_norm": 1.1874927282333374,
      "learning_rate": 8.363970588235294e-06,
      "loss": 0.1179,
      "step": 5382
    },
    {
      "epoch": 1.2369025735294117,
      "grad_norm": 1.6172449588775635,
      "learning_rate": 8.363459967320262e-06,
      "loss": 0.1154,
      "step": 5383
    },
    {
      "epoch": 1.2371323529411764,
      "grad_norm": 1.5530357360839844,
      "learning_rate": 8.36294934640523e-06,
      "loss": 0.1173,
      "step": 5384
    },
    {
      "epoch": 1.2373621323529411,
      "grad_norm": 2.14357328414917,
      "learning_rate": 8.362438725490198e-06,
      "loss": 0.1613,
      "step": 5385
    },
    {
      "epoch": 1.2375919117647058,
      "grad_norm": 2.1221578121185303,
      "learning_rate": 8.361928104575164e-06,
      "loss": 0.1573,
      "step": 5386
    },
    {
      "epoch": 1.2378216911764706,
      "grad_norm": 1.2557642459869385,
      "learning_rate": 8.361417483660132e-06,
      "loss": 0.1196,
      "step": 5387
    },
    {
      "epoch": 1.2380514705882353,
      "grad_norm": 1.5092414617538452,
      "learning_rate": 8.360906862745098e-06,
      "loss": 0.1474,
      "step": 5388
    },
    {
      "epoch": 1.23828125,
      "grad_norm": 2.2125391960144043,
      "learning_rate": 8.360396241830066e-06,
      "loss": 0.1683,
      "step": 5389
    },
    {
      "epoch": 1.2385110294117647,
      "grad_norm": 1.834814190864563,
      "learning_rate": 8.359885620915034e-06,
      "loss": 0.1303,
      "step": 5390
    },
    {
      "epoch": 1.2387408088235294,
      "grad_norm": 1.6888140439987183,
      "learning_rate": 8.359375e-06,
      "loss": 0.1555,
      "step": 5391
    },
    {
      "epoch": 1.2389705882352942,
      "grad_norm": 2.114873170852661,
      "learning_rate": 8.358864379084968e-06,
      "loss": 0.1759,
      "step": 5392
    },
    {
      "epoch": 1.2392003676470589,
      "grad_norm": 1.4324305057525635,
      "learning_rate": 8.358353758169934e-06,
      "loss": 0.1066,
      "step": 5393
    },
    {
      "epoch": 1.2394301470588236,
      "grad_norm": 1.5209215879440308,
      "learning_rate": 8.357843137254903e-06,
      "loss": 0.1621,
      "step": 5394
    },
    {
      "epoch": 1.2396599264705883,
      "grad_norm": 1.7355332374572754,
      "learning_rate": 8.35733251633987e-06,
      "loss": 0.1621,
      "step": 5395
    },
    {
      "epoch": 1.239889705882353,
      "grad_norm": 1.6739228963851929,
      "learning_rate": 8.356821895424838e-06,
      "loss": 0.1707,
      "step": 5396
    },
    {
      "epoch": 1.2401194852941178,
      "grad_norm": 1.7632735967636108,
      "learning_rate": 8.356311274509804e-06,
      "loss": 0.1327,
      "step": 5397
    },
    {
      "epoch": 1.2403492647058822,
      "grad_norm": 1.9097546339035034,
      "learning_rate": 8.355800653594772e-06,
      "loss": 0.1586,
      "step": 5398
    },
    {
      "epoch": 1.240579044117647,
      "grad_norm": 1.521276831626892,
      "learning_rate": 8.35529003267974e-06,
      "loss": 0.1424,
      "step": 5399
    },
    {
      "epoch": 1.2408088235294117,
      "grad_norm": 1.4420952796936035,
      "learning_rate": 8.354779411764706e-06,
      "loss": 0.1307,
      "step": 5400
    },
    {
      "epoch": 1.2410386029411764,
      "grad_norm": 1.4550286531448364,
      "learning_rate": 8.354268790849673e-06,
      "loss": 0.1436,
      "step": 5401
    },
    {
      "epoch": 1.2412683823529411,
      "grad_norm": 1.536056637763977,
      "learning_rate": 8.353758169934641e-06,
      "loss": 0.1298,
      "step": 5402
    },
    {
      "epoch": 1.2414981617647058,
      "grad_norm": 2.07353138923645,
      "learning_rate": 8.35324754901961e-06,
      "loss": 0.1656,
      "step": 5403
    },
    {
      "epoch": 1.2417279411764706,
      "grad_norm": 1.6888946294784546,
      "learning_rate": 8.352736928104575e-06,
      "loss": 0.1325,
      "step": 5404
    },
    {
      "epoch": 1.2419577205882353,
      "grad_norm": 1.7496219873428345,
      "learning_rate": 8.352226307189543e-06,
      "loss": 0.1206,
      "step": 5405
    },
    {
      "epoch": 1.2421875,
      "grad_norm": 1.448464035987854,
      "learning_rate": 8.351715686274511e-06,
      "loss": 0.128,
      "step": 5406
    },
    {
      "epoch": 1.2424172794117647,
      "grad_norm": 1.8217695951461792,
      "learning_rate": 8.351205065359477e-06,
      "loss": 0.1748,
      "step": 5407
    },
    {
      "epoch": 1.2426470588235294,
      "grad_norm": 1.6826006174087524,
      "learning_rate": 8.350694444444445e-06,
      "loss": 0.1794,
      "step": 5408
    },
    {
      "epoch": 1.2428768382352942,
      "grad_norm": 1.7938356399536133,
      "learning_rate": 8.350183823529411e-06,
      "loss": 0.1372,
      "step": 5409
    },
    {
      "epoch": 1.2431066176470589,
      "grad_norm": 2.2619824409484863,
      "learning_rate": 8.34967320261438e-06,
      "loss": 0.1594,
      "step": 5410
    },
    {
      "epoch": 1.2433363970588236,
      "grad_norm": 1.5575815439224243,
      "learning_rate": 8.349162581699347e-06,
      "loss": 0.1101,
      "step": 5411
    },
    {
      "epoch": 1.2435661764705883,
      "grad_norm": 1.3944573402404785,
      "learning_rate": 8.348651960784315e-06,
      "loss": 0.1319,
      "step": 5412
    },
    {
      "epoch": 1.243795955882353,
      "grad_norm": 2.048882484436035,
      "learning_rate": 8.348141339869281e-06,
      "loss": 0.1705,
      "step": 5413
    },
    {
      "epoch": 1.2440257352941178,
      "grad_norm": 1.466593623161316,
      "learning_rate": 8.347630718954249e-06,
      "loss": 0.1272,
      "step": 5414
    },
    {
      "epoch": 1.2442555147058822,
      "grad_norm": 1.579298734664917,
      "learning_rate": 8.347120098039217e-06,
      "loss": 0.1159,
      "step": 5415
    },
    {
      "epoch": 1.244485294117647,
      "grad_norm": 1.7771929502487183,
      "learning_rate": 8.346609477124183e-06,
      "loss": 0.1317,
      "step": 5416
    },
    {
      "epoch": 1.2447150735294117,
      "grad_norm": 1.8218992948532104,
      "learning_rate": 8.34609885620915e-06,
      "loss": 0.1263,
      "step": 5417
    },
    {
      "epoch": 1.2449448529411764,
      "grad_norm": 1.8658384084701538,
      "learning_rate": 8.345588235294119e-06,
      "loss": 0.1099,
      "step": 5418
    },
    {
      "epoch": 1.2451746323529411,
      "grad_norm": 1.8572735786437988,
      "learning_rate": 8.345077614379086e-06,
      "loss": 0.1946,
      "step": 5419
    },
    {
      "epoch": 1.2454044117647058,
      "grad_norm": 1.8938117027282715,
      "learning_rate": 8.344566993464053e-06,
      "loss": 0.148,
      "step": 5420
    },
    {
      "epoch": 1.2456341911764706,
      "grad_norm": 1.8137975931167603,
      "learning_rate": 8.34405637254902e-06,
      "loss": 0.1415,
      "step": 5421
    },
    {
      "epoch": 1.2458639705882353,
      "grad_norm": 1.9946538209915161,
      "learning_rate": 8.343545751633988e-06,
      "loss": 0.1345,
      "step": 5422
    },
    {
      "epoch": 1.24609375,
      "grad_norm": 1.4370516538619995,
      "learning_rate": 8.343035130718955e-06,
      "loss": 0.1231,
      "step": 5423
    },
    {
      "epoch": 1.2463235294117647,
      "grad_norm": 1.5275410413742065,
      "learning_rate": 8.342524509803922e-06,
      "loss": 0.1249,
      "step": 5424
    },
    {
      "epoch": 1.2465533088235294,
      "grad_norm": 1.568495512008667,
      "learning_rate": 8.342013888888889e-06,
      "loss": 0.1329,
      "step": 5425
    },
    {
      "epoch": 1.2467830882352942,
      "grad_norm": 1.8394473791122437,
      "learning_rate": 8.341503267973856e-06,
      "loss": 0.1264,
      "step": 5426
    },
    {
      "epoch": 1.2470128676470589,
      "grad_norm": 1.5125763416290283,
      "learning_rate": 8.340992647058824e-06,
      "loss": 0.1385,
      "step": 5427
    },
    {
      "epoch": 1.2472426470588236,
      "grad_norm": 2.15836763381958,
      "learning_rate": 8.340482026143792e-06,
      "loss": 0.1631,
      "step": 5428
    },
    {
      "epoch": 1.2474724264705883,
      "grad_norm": 1.5519365072250366,
      "learning_rate": 8.339971405228758e-06,
      "loss": 0.107,
      "step": 5429
    },
    {
      "epoch": 1.247702205882353,
      "grad_norm": 1.4337546825408936,
      "learning_rate": 8.339460784313726e-06,
      "loss": 0.144,
      "step": 5430
    },
    {
      "epoch": 1.2479319852941178,
      "grad_norm": 1.091785192489624,
      "learning_rate": 8.338950163398694e-06,
      "loss": 0.0806,
      "step": 5431
    },
    {
      "epoch": 1.2481617647058822,
      "grad_norm": 1.6462070941925049,
      "learning_rate": 8.33843954248366e-06,
      "loss": 0.1309,
      "step": 5432
    },
    {
      "epoch": 1.248391544117647,
      "grad_norm": 1.4817728996276855,
      "learning_rate": 8.337928921568628e-06,
      "loss": 0.1377,
      "step": 5433
    },
    {
      "epoch": 1.2486213235294117,
      "grad_norm": 1.8914909362792969,
      "learning_rate": 8.337418300653596e-06,
      "loss": 0.1458,
      "step": 5434
    },
    {
      "epoch": 1.2488511029411764,
      "grad_norm": 1.7536463737487793,
      "learning_rate": 8.336907679738562e-06,
      "loss": 0.1328,
      "step": 5435
    },
    {
      "epoch": 1.2490808823529411,
      "grad_norm": 1.9489988088607788,
      "learning_rate": 8.33639705882353e-06,
      "loss": 0.1314,
      "step": 5436
    },
    {
      "epoch": 1.2493106617647058,
      "grad_norm": 1.9629051685333252,
      "learning_rate": 8.335886437908496e-06,
      "loss": 0.1794,
      "step": 5437
    },
    {
      "epoch": 1.2495404411764706,
      "grad_norm": 1.837020754814148,
      "learning_rate": 8.335375816993466e-06,
      "loss": 0.173,
      "step": 5438
    },
    {
      "epoch": 1.2497702205882353,
      "grad_norm": 1.492048740386963,
      "learning_rate": 8.334865196078432e-06,
      "loss": 0.1521,
      "step": 5439
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.399322509765625,
      "learning_rate": 8.3343545751634e-06,
      "loss": 0.1278,
      "step": 5440
    },
    {
      "epoch": 1.2502297794117647,
      "grad_norm": 1.6085377931594849,
      "learning_rate": 8.333843954248366e-06,
      "loss": 0.1474,
      "step": 5441
    },
    {
      "epoch": 1.2504595588235294,
      "grad_norm": 1.6471151113510132,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.1009,
      "step": 5442
    },
    {
      "epoch": 1.2506893382352942,
      "grad_norm": 1.9948638677597046,
      "learning_rate": 8.332822712418302e-06,
      "loss": 0.1006,
      "step": 5443
    },
    {
      "epoch": 1.2509191176470589,
      "grad_norm": 1.5749794244766235,
      "learning_rate": 8.332312091503268e-06,
      "loss": 0.1383,
      "step": 5444
    },
    {
      "epoch": 1.2511488970588236,
      "grad_norm": 1.7716586589813232,
      "learning_rate": 8.331801470588236e-06,
      "loss": 0.1036,
      "step": 5445
    },
    {
      "epoch": 1.2513786764705883,
      "grad_norm": 1.549564242362976,
      "learning_rate": 8.331290849673203e-06,
      "loss": 0.1237,
      "step": 5446
    },
    {
      "epoch": 1.2516084558823528,
      "grad_norm": 1.4379020929336548,
      "learning_rate": 8.330780228758171e-06,
      "loss": 0.1423,
      "step": 5447
    },
    {
      "epoch": 1.2518382352941178,
      "grad_norm": 1.8669124841690063,
      "learning_rate": 8.330269607843138e-06,
      "loss": 0.1516,
      "step": 5448
    },
    {
      "epoch": 1.2520680147058822,
      "grad_norm": 2.129155397415161,
      "learning_rate": 8.329758986928105e-06,
      "loss": 0.1233,
      "step": 5449
    },
    {
      "epoch": 1.2522977941176472,
      "grad_norm": 1.5692393779754639,
      "learning_rate": 8.329248366013073e-06,
      "loss": 0.1026,
      "step": 5450
    },
    {
      "epoch": 1.2525275735294117,
      "grad_norm": 1.6366664171218872,
      "learning_rate": 8.32873774509804e-06,
      "loss": 0.1039,
      "step": 5451
    },
    {
      "epoch": 1.2527573529411764,
      "grad_norm": 2.1648190021514893,
      "learning_rate": 8.328227124183007e-06,
      "loss": 0.1337,
      "step": 5452
    },
    {
      "epoch": 1.2529871323529411,
      "grad_norm": 1.3755347728729248,
      "learning_rate": 8.327716503267973e-06,
      "loss": 0.0904,
      "step": 5453
    },
    {
      "epoch": 1.2532169117647058,
      "grad_norm": 1.3951126337051392,
      "learning_rate": 8.327205882352943e-06,
      "loss": 0.137,
      "step": 5454
    },
    {
      "epoch": 1.2534466911764706,
      "grad_norm": 1.5777959823608398,
      "learning_rate": 8.32669526143791e-06,
      "loss": 0.1399,
      "step": 5455
    },
    {
      "epoch": 1.2536764705882353,
      "grad_norm": 2.332604169845581,
      "learning_rate": 8.326184640522877e-06,
      "loss": 0.1396,
      "step": 5456
    },
    {
      "epoch": 1.25390625,
      "grad_norm": 1.9706038236618042,
      "learning_rate": 8.325674019607843e-06,
      "loss": 0.1373,
      "step": 5457
    },
    {
      "epoch": 1.2541360294117647,
      "grad_norm": 1.6776113510131836,
      "learning_rate": 8.325163398692811e-06,
      "loss": 0.1257,
      "step": 5458
    },
    {
      "epoch": 1.2543658088235294,
      "grad_norm": 1.6692622900009155,
      "learning_rate": 8.324652777777779e-06,
      "loss": 0.1412,
      "step": 5459
    },
    {
      "epoch": 1.2545955882352942,
      "grad_norm": 2.1309540271759033,
      "learning_rate": 8.324142156862745e-06,
      "loss": 0.1584,
      "step": 5460
    },
    {
      "epoch": 1.2548253676470589,
      "grad_norm": 1.7221862077713013,
      "learning_rate": 8.323631535947713e-06,
      "loss": 0.1747,
      "step": 5461
    },
    {
      "epoch": 1.2550551470588236,
      "grad_norm": 2.080940008163452,
      "learning_rate": 8.32312091503268e-06,
      "loss": 0.1265,
      "step": 5462
    },
    {
      "epoch": 1.2552849264705883,
      "grad_norm": 1.7181485891342163,
      "learning_rate": 8.322610294117649e-06,
      "loss": 0.1341,
      "step": 5463
    },
    {
      "epoch": 1.2555147058823528,
      "grad_norm": 1.8701391220092773,
      "learning_rate": 8.322099673202615e-06,
      "loss": 0.1267,
      "step": 5464
    },
    {
      "epoch": 1.2557444852941178,
      "grad_norm": 1.8141602277755737,
      "learning_rate": 8.321589052287583e-06,
      "loss": 0.1106,
      "step": 5465
    },
    {
      "epoch": 1.2559742647058822,
      "grad_norm": 1.4958974123001099,
      "learning_rate": 8.32107843137255e-06,
      "loss": 0.1544,
      "step": 5466
    },
    {
      "epoch": 1.2562040441176472,
      "grad_norm": 1.747277021408081,
      "learning_rate": 8.320567810457517e-06,
      "loss": 0.1326,
      "step": 5467
    },
    {
      "epoch": 1.2564338235294117,
      "grad_norm": 1.7567588090896606,
      "learning_rate": 8.320057189542485e-06,
      "loss": 0.1506,
      "step": 5468
    },
    {
      "epoch": 1.2566636029411764,
      "grad_norm": 1.7214322090148926,
      "learning_rate": 8.31954656862745e-06,
      "loss": 0.1099,
      "step": 5469
    },
    {
      "epoch": 1.2568933823529411,
      "grad_norm": 1.9024834632873535,
      "learning_rate": 8.319035947712419e-06,
      "loss": 0.1633,
      "step": 5470
    },
    {
      "epoch": 1.2571231617647058,
      "grad_norm": 2.3580446243286133,
      "learning_rate": 8.318525326797386e-06,
      "loss": 0.1573,
      "step": 5471
    },
    {
      "epoch": 1.2573529411764706,
      "grad_norm": 1.9837443828582764,
      "learning_rate": 8.318014705882354e-06,
      "loss": 0.1452,
      "step": 5472
    },
    {
      "epoch": 1.2575827205882353,
      "grad_norm": 1.890188455581665,
      "learning_rate": 8.31750408496732e-06,
      "loss": 0.1623,
      "step": 5473
    },
    {
      "epoch": 1.2578125,
      "grad_norm": 1.9060622453689575,
      "learning_rate": 8.316993464052288e-06,
      "loss": 0.1779,
      "step": 5474
    },
    {
      "epoch": 1.2580422794117647,
      "grad_norm": 1.6310546398162842,
      "learning_rate": 8.316482843137256e-06,
      "loss": 0.1399,
      "step": 5475
    },
    {
      "epoch": 1.2582720588235294,
      "grad_norm": 1.395371675491333,
      "learning_rate": 8.315972222222222e-06,
      "loss": 0.1323,
      "step": 5476
    },
    {
      "epoch": 1.2585018382352942,
      "grad_norm": 1.521289348602295,
      "learning_rate": 8.31546160130719e-06,
      "loss": 0.1407,
      "step": 5477
    },
    {
      "epoch": 1.2587316176470589,
      "grad_norm": 1.7074581384658813,
      "learning_rate": 8.314950980392158e-06,
      "loss": 0.1241,
      "step": 5478
    },
    {
      "epoch": 1.2589613970588236,
      "grad_norm": 1.4478832483291626,
      "learning_rate": 8.314440359477124e-06,
      "loss": 0.1224,
      "step": 5479
    },
    {
      "epoch": 1.2591911764705883,
      "grad_norm": 1.6665492057800293,
      "learning_rate": 8.313929738562092e-06,
      "loss": 0.1461,
      "step": 5480
    },
    {
      "epoch": 1.2594209558823528,
      "grad_norm": 1.8302197456359863,
      "learning_rate": 8.313419117647058e-06,
      "loss": 0.141,
      "step": 5481
    },
    {
      "epoch": 1.2596507352941178,
      "grad_norm": 1.670960545539856,
      "learning_rate": 8.312908496732028e-06,
      "loss": 0.1455,
      "step": 5482
    },
    {
      "epoch": 1.2598805147058822,
      "grad_norm": 1.7137595415115356,
      "learning_rate": 8.312397875816994e-06,
      "loss": 0.1241,
      "step": 5483
    },
    {
      "epoch": 1.2601102941176472,
      "grad_norm": 2.0468251705169678,
      "learning_rate": 8.311887254901962e-06,
      "loss": 0.1336,
      "step": 5484
    },
    {
      "epoch": 1.2603400735294117,
      "grad_norm": 2.278681755065918,
      "learning_rate": 8.311376633986928e-06,
      "loss": 0.1489,
      "step": 5485
    },
    {
      "epoch": 1.2605698529411764,
      "grad_norm": 1.8856968879699707,
      "learning_rate": 8.310866013071896e-06,
      "loss": 0.0857,
      "step": 5486
    },
    {
      "epoch": 1.2607996323529411,
      "grad_norm": 1.7426164150238037,
      "learning_rate": 8.310355392156864e-06,
      "loss": 0.1215,
      "step": 5487
    },
    {
      "epoch": 1.2610294117647058,
      "grad_norm": 1.622117042541504,
      "learning_rate": 8.30984477124183e-06,
      "loss": 0.1187,
      "step": 5488
    },
    {
      "epoch": 1.2612591911764706,
      "grad_norm": 2.0084593296051025,
      "learning_rate": 8.309334150326798e-06,
      "loss": 0.0895,
      "step": 5489
    },
    {
      "epoch": 1.2614889705882353,
      "grad_norm": 1.6568800210952759,
      "learning_rate": 8.308823529411766e-06,
      "loss": 0.1481,
      "step": 5490
    },
    {
      "epoch": 1.26171875,
      "grad_norm": 1.3982993364334106,
      "learning_rate": 8.308312908496734e-06,
      "loss": 0.1239,
      "step": 5491
    },
    {
      "epoch": 1.2619485294117647,
      "grad_norm": 1.5603041648864746,
      "learning_rate": 8.3078022875817e-06,
      "loss": 0.1468,
      "step": 5492
    },
    {
      "epoch": 1.2621783088235294,
      "grad_norm": 1.867347002029419,
      "learning_rate": 8.307291666666668e-06,
      "loss": 0.1521,
      "step": 5493
    },
    {
      "epoch": 1.2624080882352942,
      "grad_norm": 2.1787543296813965,
      "learning_rate": 8.306781045751635e-06,
      "loss": 0.154,
      "step": 5494
    },
    {
      "epoch": 1.2626378676470589,
      "grad_norm": 1.98801851272583,
      "learning_rate": 8.306270424836602e-06,
      "loss": 0.1409,
      "step": 5495
    },
    {
      "epoch": 1.2628676470588236,
      "grad_norm": 1.7591419219970703,
      "learning_rate": 8.30575980392157e-06,
      "loss": 0.1422,
      "step": 5496
    },
    {
      "epoch": 1.2630974264705883,
      "grad_norm": 2.1991145610809326,
      "learning_rate": 8.305249183006536e-06,
      "loss": 0.1792,
      "step": 5497
    },
    {
      "epoch": 1.2633272058823528,
      "grad_norm": 1.495742917060852,
      "learning_rate": 8.304738562091505e-06,
      "loss": 0.1232,
      "step": 5498
    },
    {
      "epoch": 1.2635569852941178,
      "grad_norm": 1.303013801574707,
      "learning_rate": 8.304227941176471e-06,
      "loss": 0.1236,
      "step": 5499
    },
    {
      "epoch": 1.2637867647058822,
      "grad_norm": 1.7741342782974243,
      "learning_rate": 8.30371732026144e-06,
      "loss": 0.1082,
      "step": 5500
    },
    {
      "epoch": 1.2637867647058822,
      "eval_loss": 0.13662180304527283,
      "eval_runtime": 422.2418,
      "eval_samples_per_second": 21.092,
      "eval_steps_per_second": 10.546,
      "step": 5500
    },
    {
      "epoch": 1.2640165441176472,
      "grad_norm": 1.8478442430496216,
      "learning_rate": 8.303206699346405e-06,
      "loss": 0.1404,
      "step": 5501
    },
    {
      "epoch": 1.2642463235294117,
      "grad_norm": 1.437756061553955,
      "learning_rate": 8.302696078431373e-06,
      "loss": 0.1002,
      "step": 5502
    },
    {
      "epoch": 1.2644761029411764,
      "grad_norm": 2.0323903560638428,
      "learning_rate": 8.302185457516341e-06,
      "loss": 0.1328,
      "step": 5503
    },
    {
      "epoch": 1.2647058823529411,
      "grad_norm": 1.287187099456787,
      "learning_rate": 8.301674836601307e-06,
      "loss": 0.1697,
      "step": 5504
    },
    {
      "epoch": 1.2649356617647058,
      "grad_norm": 1.1078596115112305,
      "learning_rate": 8.301164215686275e-06,
      "loss": 0.0721,
      "step": 5505
    },
    {
      "epoch": 1.2651654411764706,
      "grad_norm": 2.1935853958129883,
      "learning_rate": 8.300653594771243e-06,
      "loss": 0.1241,
      "step": 5506
    },
    {
      "epoch": 1.2653952205882353,
      "grad_norm": 1.8975943326950073,
      "learning_rate": 8.30014297385621e-06,
      "loss": 0.1722,
      "step": 5507
    },
    {
      "epoch": 1.265625,
      "grad_norm": 1.5455611944198608,
      "learning_rate": 8.299632352941177e-06,
      "loss": 0.1214,
      "step": 5508
    },
    {
      "epoch": 1.2658547794117647,
      "grad_norm": 1.5965676307678223,
      "learning_rate": 8.299121732026145e-06,
      "loss": 0.125,
      "step": 5509
    },
    {
      "epoch": 1.2660845588235294,
      "grad_norm": 2.2765579223632812,
      "learning_rate": 8.298611111111113e-06,
      "loss": 0.1856,
      "step": 5510
    },
    {
      "epoch": 1.2663143382352942,
      "grad_norm": 2.939981698989868,
      "learning_rate": 8.298100490196079e-06,
      "loss": 0.1482,
      "step": 5511
    },
    {
      "epoch": 1.2665441176470589,
      "grad_norm": 1.3441816568374634,
      "learning_rate": 8.297589869281047e-06,
      "loss": 0.1056,
      "step": 5512
    },
    {
      "epoch": 1.2667738970588236,
      "grad_norm": 1.601380467414856,
      "learning_rate": 8.297079248366013e-06,
      "loss": 0.1357,
      "step": 5513
    },
    {
      "epoch": 1.2670036764705883,
      "grad_norm": 1.7501132488250732,
      "learning_rate": 8.29656862745098e-06,
      "loss": 0.1298,
      "step": 5514
    },
    {
      "epoch": 1.2672334558823528,
      "grad_norm": 1.8398600816726685,
      "learning_rate": 8.296058006535949e-06,
      "loss": 0.1619,
      "step": 5515
    },
    {
      "epoch": 1.2674632352941178,
      "grad_norm": 2.2326629161834717,
      "learning_rate": 8.295547385620915e-06,
      "loss": 0.1013,
      "step": 5516
    },
    {
      "epoch": 1.2676930147058822,
      "grad_norm": 2.3094704151153564,
      "learning_rate": 8.295036764705883e-06,
      "loss": 0.1158,
      "step": 5517
    },
    {
      "epoch": 1.2679227941176472,
      "grad_norm": 1.426357388496399,
      "learning_rate": 8.29452614379085e-06,
      "loss": 0.102,
      "step": 5518
    },
    {
      "epoch": 1.2681525735294117,
      "grad_norm": 2.304748773574829,
      "learning_rate": 8.294015522875818e-06,
      "loss": 0.1773,
      "step": 5519
    },
    {
      "epoch": 1.2683823529411764,
      "grad_norm": 1.899369239807129,
      "learning_rate": 8.293504901960785e-06,
      "loss": 0.1569,
      "step": 5520
    },
    {
      "epoch": 1.2686121323529411,
      "grad_norm": 1.8108168840408325,
      "learning_rate": 8.292994281045752e-06,
      "loss": 0.1332,
      "step": 5521
    },
    {
      "epoch": 1.2688419117647058,
      "grad_norm": 2.0020501613616943,
      "learning_rate": 8.29248366013072e-06,
      "loss": 0.1276,
      "step": 5522
    },
    {
      "epoch": 1.2690716911764706,
      "grad_norm": 1.5779802799224854,
      "learning_rate": 8.291973039215686e-06,
      "loss": 0.1348,
      "step": 5523
    },
    {
      "epoch": 1.2693014705882353,
      "grad_norm": 1.518426775932312,
      "learning_rate": 8.291462418300654e-06,
      "loss": 0.1458,
      "step": 5524
    },
    {
      "epoch": 1.26953125,
      "grad_norm": 1.3566155433654785,
      "learning_rate": 8.29095179738562e-06,
      "loss": 0.1133,
      "step": 5525
    },
    {
      "epoch": 1.2697610294117647,
      "grad_norm": 1.57792067527771,
      "learning_rate": 8.29044117647059e-06,
      "loss": 0.1248,
      "step": 5526
    },
    {
      "epoch": 1.2699908088235294,
      "grad_norm": 2.041170120239258,
      "learning_rate": 8.289930555555556e-06,
      "loss": 0.1642,
      "step": 5527
    },
    {
      "epoch": 1.2702205882352942,
      "grad_norm": 1.789610505104065,
      "learning_rate": 8.289419934640524e-06,
      "loss": 0.1158,
      "step": 5528
    },
    {
      "epoch": 1.2704503676470589,
      "grad_norm": 1.4138517379760742,
      "learning_rate": 8.28890931372549e-06,
      "loss": 0.1005,
      "step": 5529
    },
    {
      "epoch": 1.2706801470588236,
      "grad_norm": 1.5829613208770752,
      "learning_rate": 8.288398692810458e-06,
      "loss": 0.1483,
      "step": 5530
    },
    {
      "epoch": 1.2709099264705883,
      "grad_norm": 1.7973179817199707,
      "learning_rate": 8.287888071895426e-06,
      "loss": 0.1225,
      "step": 5531
    },
    {
      "epoch": 1.2711397058823528,
      "grad_norm": 1.888554334640503,
      "learning_rate": 8.287377450980392e-06,
      "loss": 0.1361,
      "step": 5532
    },
    {
      "epoch": 1.2713694852941178,
      "grad_norm": 2.171326160430908,
      "learning_rate": 8.28686683006536e-06,
      "loss": 0.1875,
      "step": 5533
    },
    {
      "epoch": 1.2715992647058822,
      "grad_norm": 1.9494484663009644,
      "learning_rate": 8.286356209150328e-06,
      "loss": 0.1629,
      "step": 5534
    },
    {
      "epoch": 1.2718290441176472,
      "grad_norm": 2.510215997695923,
      "learning_rate": 8.285845588235296e-06,
      "loss": 0.1556,
      "step": 5535
    },
    {
      "epoch": 1.2720588235294117,
      "grad_norm": 1.7233408689498901,
      "learning_rate": 8.285334967320262e-06,
      "loss": 0.118,
      "step": 5536
    },
    {
      "epoch": 1.2722886029411764,
      "grad_norm": 1.7166720628738403,
      "learning_rate": 8.28482434640523e-06,
      "loss": 0.1206,
      "step": 5537
    },
    {
      "epoch": 1.2725183823529411,
      "grad_norm": 2.3092615604400635,
      "learning_rate": 8.284313725490198e-06,
      "loss": 0.1644,
      "step": 5538
    },
    {
      "epoch": 1.2727481617647058,
      "grad_norm": 1.7380419969558716,
      "learning_rate": 8.283803104575164e-06,
      "loss": 0.1159,
      "step": 5539
    },
    {
      "epoch": 1.2729779411764706,
      "grad_norm": 1.9646830558776855,
      "learning_rate": 8.283292483660132e-06,
      "loss": 0.1121,
      "step": 5540
    },
    {
      "epoch": 1.2732077205882353,
      "grad_norm": 1.5853326320648193,
      "learning_rate": 8.282781862745098e-06,
      "loss": 0.1662,
      "step": 5541
    },
    {
      "epoch": 1.2734375,
      "grad_norm": 1.5237343311309814,
      "learning_rate": 8.282271241830067e-06,
      "loss": 0.1217,
      "step": 5542
    },
    {
      "epoch": 1.2736672794117647,
      "grad_norm": 1.5365575551986694,
      "learning_rate": 8.281760620915034e-06,
      "loss": 0.1237,
      "step": 5543
    },
    {
      "epoch": 1.2738970588235294,
      "grad_norm": 1.9850119352340698,
      "learning_rate": 8.281250000000001e-06,
      "loss": 0.1464,
      "step": 5544
    },
    {
      "epoch": 1.2741268382352942,
      "grad_norm": 1.3668267726898193,
      "learning_rate": 8.280739379084968e-06,
      "loss": 0.1241,
      "step": 5545
    },
    {
      "epoch": 1.2743566176470589,
      "grad_norm": 1.7573587894439697,
      "learning_rate": 8.280228758169935e-06,
      "loss": 0.1281,
      "step": 5546
    },
    {
      "epoch": 1.2745863970588236,
      "grad_norm": 1.863589882850647,
      "learning_rate": 8.279718137254903e-06,
      "loss": 0.119,
      "step": 5547
    },
    {
      "epoch": 1.2748161764705883,
      "grad_norm": 1.7515013217926025,
      "learning_rate": 8.27920751633987e-06,
      "loss": 0.1575,
      "step": 5548
    },
    {
      "epoch": 1.2750459558823528,
      "grad_norm": 1.5365731716156006,
      "learning_rate": 8.278696895424837e-06,
      "loss": 0.132,
      "step": 5549
    },
    {
      "epoch": 1.2752757352941178,
      "grad_norm": 2.1990816593170166,
      "learning_rate": 8.278186274509803e-06,
      "loss": 0.0986,
      "step": 5550
    },
    {
      "epoch": 1.2755055147058822,
      "grad_norm": 1.700039267539978,
      "learning_rate": 8.277675653594773e-06,
      "loss": 0.1244,
      "step": 5551
    },
    {
      "epoch": 1.2757352941176472,
      "grad_norm": 1.812071442604065,
      "learning_rate": 8.27716503267974e-06,
      "loss": 0.1312,
      "step": 5552
    },
    {
      "epoch": 1.2759650735294117,
      "grad_norm": 1.7342422008514404,
      "learning_rate": 8.276654411764707e-06,
      "loss": 0.1226,
      "step": 5553
    },
    {
      "epoch": 1.2761948529411764,
      "grad_norm": 1.6403138637542725,
      "learning_rate": 8.276143790849673e-06,
      "loss": 0.1386,
      "step": 5554
    },
    {
      "epoch": 1.2764246323529411,
      "grad_norm": 1.9114227294921875,
      "learning_rate": 8.275633169934641e-06,
      "loss": 0.1109,
      "step": 5555
    },
    {
      "epoch": 1.2766544117647058,
      "grad_norm": 1.6302236318588257,
      "learning_rate": 8.275122549019609e-06,
      "loss": 0.1323,
      "step": 5556
    },
    {
      "epoch": 1.2768841911764706,
      "grad_norm": 1.571982502937317,
      "learning_rate": 8.274611928104575e-06,
      "loss": 0.1147,
      "step": 5557
    },
    {
      "epoch": 1.2771139705882353,
      "grad_norm": 2.0635809898376465,
      "learning_rate": 8.274101307189543e-06,
      "loss": 0.1654,
      "step": 5558
    },
    {
      "epoch": 1.27734375,
      "grad_norm": 1.7144896984100342,
      "learning_rate": 8.27359068627451e-06,
      "loss": 0.1271,
      "step": 5559
    },
    {
      "epoch": 1.2775735294117647,
      "grad_norm": 1.6017565727233887,
      "learning_rate": 8.273080065359477e-06,
      "loss": 0.1432,
      "step": 5560
    },
    {
      "epoch": 1.2778033088235294,
      "grad_norm": 2.5992610454559326,
      "learning_rate": 8.272569444444445e-06,
      "loss": 0.1693,
      "step": 5561
    },
    {
      "epoch": 1.2780330882352942,
      "grad_norm": 1.7587436437606812,
      "learning_rate": 8.272058823529413e-06,
      "loss": 0.1658,
      "step": 5562
    },
    {
      "epoch": 1.2782628676470589,
      "grad_norm": 2.2056217193603516,
      "learning_rate": 8.27154820261438e-06,
      "loss": 0.1277,
      "step": 5563
    },
    {
      "epoch": 1.2784926470588236,
      "grad_norm": 1.5526907444000244,
      "learning_rate": 8.271037581699347e-06,
      "loss": 0.1212,
      "step": 5564
    },
    {
      "epoch": 1.2787224264705883,
      "grad_norm": 2.0645430088043213,
      "learning_rate": 8.270526960784315e-06,
      "loss": 0.134,
      "step": 5565
    },
    {
      "epoch": 1.2789522058823528,
      "grad_norm": 1.3786089420318604,
      "learning_rate": 8.27001633986928e-06,
      "loss": 0.1097,
      "step": 5566
    },
    {
      "epoch": 1.2791819852941178,
      "grad_norm": 1.83424711227417,
      "learning_rate": 8.269505718954249e-06,
      "loss": 0.1318,
      "step": 5567
    },
    {
      "epoch": 1.2794117647058822,
      "grad_norm": 2.035947561264038,
      "learning_rate": 8.268995098039217e-06,
      "loss": 0.2405,
      "step": 5568
    },
    {
      "epoch": 1.2796415441176472,
      "grad_norm": 1.4926633834838867,
      "learning_rate": 8.268484477124183e-06,
      "loss": 0.1407,
      "step": 5569
    },
    {
      "epoch": 1.2798713235294117,
      "grad_norm": 1.8582245111465454,
      "learning_rate": 8.26797385620915e-06,
      "loss": 0.112,
      "step": 5570
    },
    {
      "epoch": 1.2801011029411764,
      "grad_norm": 2.4154717922210693,
      "learning_rate": 8.267463235294118e-06,
      "loss": 0.1348,
      "step": 5571
    },
    {
      "epoch": 1.2803308823529411,
      "grad_norm": 1.8878847360610962,
      "learning_rate": 8.266952614379086e-06,
      "loss": 0.1342,
      "step": 5572
    },
    {
      "epoch": 1.2805606617647058,
      "grad_norm": 1.6128567457199097,
      "learning_rate": 8.266441993464052e-06,
      "loss": 0.1138,
      "step": 5573
    },
    {
      "epoch": 1.2807904411764706,
      "grad_norm": 1.7670950889587402,
      "learning_rate": 8.26593137254902e-06,
      "loss": 0.1494,
      "step": 5574
    },
    {
      "epoch": 1.2810202205882353,
      "grad_norm": 1.5062870979309082,
      "learning_rate": 8.265420751633988e-06,
      "loss": 0.1368,
      "step": 5575
    },
    {
      "epoch": 1.28125,
      "grad_norm": 1.3424530029296875,
      "learning_rate": 8.264910130718954e-06,
      "loss": 0.1087,
      "step": 5576
    },
    {
      "epoch": 1.2814797794117647,
      "grad_norm": 1.6902016401290894,
      "learning_rate": 8.264399509803922e-06,
      "loss": 0.1647,
      "step": 5577
    },
    {
      "epoch": 1.2817095588235294,
      "grad_norm": 1.5518985986709595,
      "learning_rate": 8.263888888888888e-06,
      "loss": 0.1378,
      "step": 5578
    },
    {
      "epoch": 1.2819393382352942,
      "grad_norm": 1.9780868291854858,
      "learning_rate": 8.263378267973858e-06,
      "loss": 0.1544,
      "step": 5579
    },
    {
      "epoch": 1.2821691176470589,
      "grad_norm": 1.854544758796692,
      "learning_rate": 8.262867647058824e-06,
      "loss": 0.1692,
      "step": 5580
    },
    {
      "epoch": 1.2823988970588236,
      "grad_norm": 2.014287233352661,
      "learning_rate": 8.262357026143792e-06,
      "loss": 0.1762,
      "step": 5581
    },
    {
      "epoch": 1.2826286764705883,
      "grad_norm": 1.8613423109054565,
      "learning_rate": 8.261846405228758e-06,
      "loss": 0.1226,
      "step": 5582
    },
    {
      "epoch": 1.2828584558823528,
      "grad_norm": 1.6033090353012085,
      "learning_rate": 8.261335784313726e-06,
      "loss": 0.1176,
      "step": 5583
    },
    {
      "epoch": 1.2830882352941178,
      "grad_norm": 1.8685342073440552,
      "learning_rate": 8.260825163398694e-06,
      "loss": 0.1209,
      "step": 5584
    },
    {
      "epoch": 1.2833180147058822,
      "grad_norm": 1.6101570129394531,
      "learning_rate": 8.26031454248366e-06,
      "loss": 0.0922,
      "step": 5585
    },
    {
      "epoch": 1.2835477941176472,
      "grad_norm": 1.8425660133361816,
      "learning_rate": 8.259803921568628e-06,
      "loss": 0.1474,
      "step": 5586
    },
    {
      "epoch": 1.2837775735294117,
      "grad_norm": 1.759598970413208,
      "learning_rate": 8.259293300653596e-06,
      "loss": 0.1162,
      "step": 5587
    },
    {
      "epoch": 1.2840073529411764,
      "grad_norm": 1.6474661827087402,
      "learning_rate": 8.258782679738564e-06,
      "loss": 0.0998,
      "step": 5588
    },
    {
      "epoch": 1.2842371323529411,
      "grad_norm": 1.5411458015441895,
      "learning_rate": 8.25827205882353e-06,
      "loss": 0.1309,
      "step": 5589
    },
    {
      "epoch": 1.2844669117647058,
      "grad_norm": 2.1600193977355957,
      "learning_rate": 8.257761437908498e-06,
      "loss": 0.1179,
      "step": 5590
    },
    {
      "epoch": 1.2846966911764706,
      "grad_norm": 1.9655879735946655,
      "learning_rate": 8.257250816993465e-06,
      "loss": 0.1772,
      "step": 5591
    },
    {
      "epoch": 1.2849264705882353,
      "grad_norm": 2.536175489425659,
      "learning_rate": 8.256740196078432e-06,
      "loss": 0.1874,
      "step": 5592
    },
    {
      "epoch": 1.28515625,
      "grad_norm": 1.8334497213363647,
      "learning_rate": 8.2562295751634e-06,
      "loss": 0.1441,
      "step": 5593
    },
    {
      "epoch": 1.2853860294117647,
      "grad_norm": 2.096539258956909,
      "learning_rate": 8.255718954248366e-06,
      "loss": 0.1716,
      "step": 5594
    },
    {
      "epoch": 1.2856158088235294,
      "grad_norm": 1.724115014076233,
      "learning_rate": 8.255208333333335e-06,
      "loss": 0.1432,
      "step": 5595
    },
    {
      "epoch": 1.2858455882352942,
      "grad_norm": 1.2969059944152832,
      "learning_rate": 8.254697712418301e-06,
      "loss": 0.137,
      "step": 5596
    },
    {
      "epoch": 1.2860753676470589,
      "grad_norm": 1.608376383781433,
      "learning_rate": 8.25418709150327e-06,
      "loss": 0.1618,
      "step": 5597
    },
    {
      "epoch": 1.2863051470588236,
      "grad_norm": 1.5613646507263184,
      "learning_rate": 8.253676470588235e-06,
      "loss": 0.1356,
      "step": 5598
    },
    {
      "epoch": 1.2865349264705883,
      "grad_norm": 1.595274806022644,
      "learning_rate": 8.253165849673203e-06,
      "loss": 0.1383,
      "step": 5599
    },
    {
      "epoch": 1.2867647058823528,
      "grad_norm": 1.5258299112319946,
      "learning_rate": 8.252655228758171e-06,
      "loss": 0.1299,
      "step": 5600
    },
    {
      "epoch": 1.2869944852941178,
      "grad_norm": 1.7682312726974487,
      "learning_rate": 8.252144607843137e-06,
      "loss": 0.1481,
      "step": 5601
    },
    {
      "epoch": 1.2872242647058822,
      "grad_norm": 1.7593603134155273,
      "learning_rate": 8.251633986928105e-06,
      "loss": 0.1522,
      "step": 5602
    },
    {
      "epoch": 1.2874540441176472,
      "grad_norm": 1.8658475875854492,
      "learning_rate": 8.251123366013073e-06,
      "loss": 0.127,
      "step": 5603
    },
    {
      "epoch": 1.2876838235294117,
      "grad_norm": 2.137453079223633,
      "learning_rate": 8.25061274509804e-06,
      "loss": 0.2099,
      "step": 5604
    },
    {
      "epoch": 1.2879136029411764,
      "grad_norm": 1.3511264324188232,
      "learning_rate": 8.250102124183007e-06,
      "loss": 0.1085,
      "step": 5605
    },
    {
      "epoch": 1.2881433823529411,
      "grad_norm": 1.6042835712432861,
      "learning_rate": 8.249591503267975e-06,
      "loss": 0.1303,
      "step": 5606
    },
    {
      "epoch": 1.2883731617647058,
      "grad_norm": 1.698538064956665,
      "learning_rate": 8.249080882352943e-06,
      "loss": 0.1478,
      "step": 5607
    },
    {
      "epoch": 1.2886029411764706,
      "grad_norm": 1.3813371658325195,
      "learning_rate": 8.248570261437909e-06,
      "loss": 0.0914,
      "step": 5608
    },
    {
      "epoch": 1.2888327205882353,
      "grad_norm": 1.4577343463897705,
      "learning_rate": 8.248059640522877e-06,
      "loss": 0.1079,
      "step": 5609
    },
    {
      "epoch": 1.2890625,
      "grad_norm": 2.24969482421875,
      "learning_rate": 8.247549019607843e-06,
      "loss": 0.1632,
      "step": 5610
    },
    {
      "epoch": 1.2892922794117647,
      "grad_norm": 1.6602643728256226,
      "learning_rate": 8.24703839869281e-06,
      "loss": 0.1305,
      "step": 5611
    },
    {
      "epoch": 1.2895220588235294,
      "grad_norm": 1.8117238283157349,
      "learning_rate": 8.246527777777779e-06,
      "loss": 0.159,
      "step": 5612
    },
    {
      "epoch": 1.2897518382352942,
      "grad_norm": 1.8465508222579956,
      "learning_rate": 8.246017156862745e-06,
      "loss": 0.1815,
      "step": 5613
    },
    {
      "epoch": 1.2899816176470589,
      "grad_norm": 1.949902892112732,
      "learning_rate": 8.245506535947713e-06,
      "loss": 0.1362,
      "step": 5614
    },
    {
      "epoch": 1.2902113970588236,
      "grad_norm": 1.4694314002990723,
      "learning_rate": 8.24499591503268e-06,
      "loss": 0.1246,
      "step": 5615
    },
    {
      "epoch": 1.2904411764705883,
      "grad_norm": 1.5813486576080322,
      "learning_rate": 8.244485294117648e-06,
      "loss": 0.1211,
      "step": 5616
    },
    {
      "epoch": 1.2906709558823528,
      "grad_norm": 1.708739995956421,
      "learning_rate": 8.243974673202615e-06,
      "loss": 0.1156,
      "step": 5617
    },
    {
      "epoch": 1.2909007352941178,
      "grad_norm": 1.7636984586715698,
      "learning_rate": 8.243464052287582e-06,
      "loss": 0.1624,
      "step": 5618
    },
    {
      "epoch": 1.2911305147058822,
      "grad_norm": 1.6022460460662842,
      "learning_rate": 8.24295343137255e-06,
      "loss": 0.1535,
      "step": 5619
    },
    {
      "epoch": 1.2913602941176472,
      "grad_norm": 1.7758839130401611,
      "learning_rate": 8.242442810457517e-06,
      "loss": 0.113,
      "step": 5620
    },
    {
      "epoch": 1.2915900735294117,
      "grad_norm": 1.6395374536514282,
      "learning_rate": 8.241932189542484e-06,
      "loss": 0.1243,
      "step": 5621
    },
    {
      "epoch": 1.2918198529411764,
      "grad_norm": 2.0062992572784424,
      "learning_rate": 8.24142156862745e-06,
      "loss": 0.1803,
      "step": 5622
    },
    {
      "epoch": 1.2920496323529411,
      "grad_norm": 1.318129539489746,
      "learning_rate": 8.24091094771242e-06,
      "loss": 0.1165,
      "step": 5623
    },
    {
      "epoch": 1.2922794117647058,
      "grad_norm": 1.6686711311340332,
      "learning_rate": 8.240400326797386e-06,
      "loss": 0.1225,
      "step": 5624
    },
    {
      "epoch": 1.2925091911764706,
      "grad_norm": 1.9611917734146118,
      "learning_rate": 8.239889705882354e-06,
      "loss": 0.1461,
      "step": 5625
    },
    {
      "epoch": 1.2927389705882353,
      "grad_norm": 1.8799128532409668,
      "learning_rate": 8.23937908496732e-06,
      "loss": 0.132,
      "step": 5626
    },
    {
      "epoch": 1.29296875,
      "grad_norm": 1.828997254371643,
      "learning_rate": 8.238868464052288e-06,
      "loss": 0.1329,
      "step": 5627
    },
    {
      "epoch": 1.2931985294117647,
      "grad_norm": 1.7622357606887817,
      "learning_rate": 8.238357843137256e-06,
      "loss": 0.1233,
      "step": 5628
    },
    {
      "epoch": 1.2934283088235294,
      "grad_norm": 2.2208902835845947,
      "learning_rate": 8.237847222222222e-06,
      "loss": 0.1595,
      "step": 5629
    },
    {
      "epoch": 1.2936580882352942,
      "grad_norm": 1.905734896659851,
      "learning_rate": 8.23733660130719e-06,
      "loss": 0.1255,
      "step": 5630
    },
    {
      "epoch": 1.2938878676470589,
      "grad_norm": 1.3878211975097656,
      "learning_rate": 8.236825980392158e-06,
      "loss": 0.1201,
      "step": 5631
    },
    {
      "epoch": 1.2941176470588236,
      "grad_norm": 1.7624367475509644,
      "learning_rate": 8.236315359477126e-06,
      "loss": 0.1621,
      "step": 5632
    },
    {
      "epoch": 1.2943474264705883,
      "grad_norm": 1.6968131065368652,
      "learning_rate": 8.235804738562092e-06,
      "loss": 0.168,
      "step": 5633
    },
    {
      "epoch": 1.2945772058823528,
      "grad_norm": 1.818387508392334,
      "learning_rate": 8.23529411764706e-06,
      "loss": 0.1292,
      "step": 5634
    },
    {
      "epoch": 1.2948069852941178,
      "grad_norm": 1.9750776290893555,
      "learning_rate": 8.234783496732028e-06,
      "loss": 0.1463,
      "step": 5635
    },
    {
      "epoch": 1.2950367647058822,
      "grad_norm": 1.7562452554702759,
      "learning_rate": 8.234272875816994e-06,
      "loss": 0.1095,
      "step": 5636
    },
    {
      "epoch": 1.2952665441176472,
      "grad_norm": 1.952085256576538,
      "learning_rate": 8.233762254901962e-06,
      "loss": 0.2086,
      "step": 5637
    },
    {
      "epoch": 1.2954963235294117,
      "grad_norm": 1.5672820806503296,
      "learning_rate": 8.233251633986928e-06,
      "loss": 0.1254,
      "step": 5638
    },
    {
      "epoch": 1.2957261029411764,
      "grad_norm": 1.9695011377334595,
      "learning_rate": 8.232741013071896e-06,
      "loss": 0.1423,
      "step": 5639
    },
    {
      "epoch": 1.2959558823529411,
      "grad_norm": 1.6638514995574951,
      "learning_rate": 8.232230392156864e-06,
      "loss": 0.113,
      "step": 5640
    },
    {
      "epoch": 1.2961856617647058,
      "grad_norm": 1.5541051626205444,
      "learning_rate": 8.231719771241831e-06,
      "loss": 0.1273,
      "step": 5641
    },
    {
      "epoch": 1.2964154411764706,
      "grad_norm": 1.5047003030776978,
      "learning_rate": 8.231209150326798e-06,
      "loss": 0.1614,
      "step": 5642
    },
    {
      "epoch": 1.2966452205882353,
      "grad_norm": 1.4704159498214722,
      "learning_rate": 8.230698529411765e-06,
      "loss": 0.1519,
      "step": 5643
    },
    {
      "epoch": 1.296875,
      "grad_norm": 1.7881286144256592,
      "learning_rate": 8.230187908496733e-06,
      "loss": 0.1383,
      "step": 5644
    },
    {
      "epoch": 1.2971047794117647,
      "grad_norm": 1.5334182977676392,
      "learning_rate": 8.2296772875817e-06,
      "loss": 0.1311,
      "step": 5645
    },
    {
      "epoch": 1.2973345588235294,
      "grad_norm": 1.5892030000686646,
      "learning_rate": 8.229166666666667e-06,
      "loss": 0.1145,
      "step": 5646
    },
    {
      "epoch": 1.2975643382352942,
      "grad_norm": 1.9188182353973389,
      "learning_rate": 8.228656045751635e-06,
      "loss": 0.1531,
      "step": 5647
    },
    {
      "epoch": 1.2977941176470589,
      "grad_norm": 1.584984302520752,
      "learning_rate": 8.228145424836601e-06,
      "loss": 0.1315,
      "step": 5648
    },
    {
      "epoch": 1.2980238970588236,
      "grad_norm": 2.0652127265930176,
      "learning_rate": 8.22763480392157e-06,
      "loss": 0.1452,
      "step": 5649
    },
    {
      "epoch": 1.2982536764705883,
      "grad_norm": 1.6248536109924316,
      "learning_rate": 8.227124183006535e-06,
      "loss": 0.1013,
      "step": 5650
    },
    {
      "epoch": 1.2984834558823528,
      "grad_norm": 1.6385893821716309,
      "learning_rate": 8.226613562091505e-06,
      "loss": 0.1237,
      "step": 5651
    },
    {
      "epoch": 1.2987132352941178,
      "grad_norm": 2.40509033203125,
      "learning_rate": 8.226102941176471e-06,
      "loss": 0.1368,
      "step": 5652
    },
    {
      "epoch": 1.2989430147058822,
      "grad_norm": 1.3133355379104614,
      "learning_rate": 8.225592320261439e-06,
      "loss": 0.0985,
      "step": 5653
    },
    {
      "epoch": 1.2991727941176472,
      "grad_norm": 1.4197107553482056,
      "learning_rate": 8.225081699346405e-06,
      "loss": 0.116,
      "step": 5654
    },
    {
      "epoch": 1.2994025735294117,
      "grad_norm": 1.5396208763122559,
      "learning_rate": 8.224571078431373e-06,
      "loss": 0.1289,
      "step": 5655
    },
    {
      "epoch": 1.2996323529411764,
      "grad_norm": 1.1707329750061035,
      "learning_rate": 8.224060457516341e-06,
      "loss": 0.0867,
      "step": 5656
    },
    {
      "epoch": 1.2998621323529411,
      "grad_norm": 1.3063583374023438,
      "learning_rate": 8.223549836601307e-06,
      "loss": 0.1227,
      "step": 5657
    },
    {
      "epoch": 1.3000919117647058,
      "grad_norm": 1.8472671508789062,
      "learning_rate": 8.223039215686275e-06,
      "loss": 0.145,
      "step": 5658
    },
    {
      "epoch": 1.3003216911764706,
      "grad_norm": 1.6455156803131104,
      "learning_rate": 8.222528594771243e-06,
      "loss": 0.1369,
      "step": 5659
    },
    {
      "epoch": 1.3005514705882353,
      "grad_norm": 1.7967349290847778,
      "learning_rate": 8.22201797385621e-06,
      "loss": 0.105,
      "step": 5660
    },
    {
      "epoch": 1.30078125,
      "grad_norm": 1.9376591444015503,
      "learning_rate": 8.221507352941177e-06,
      "loss": 0.1646,
      "step": 5661
    },
    {
      "epoch": 1.3010110294117647,
      "grad_norm": 1.8114402294158936,
      "learning_rate": 8.220996732026145e-06,
      "loss": 0.1444,
      "step": 5662
    },
    {
      "epoch": 1.3012408088235294,
      "grad_norm": 1.7815295457839966,
      "learning_rate": 8.220486111111113e-06,
      "loss": 0.1702,
      "step": 5663
    },
    {
      "epoch": 1.3014705882352942,
      "grad_norm": 1.906292200088501,
      "learning_rate": 8.219975490196079e-06,
      "loss": 0.1294,
      "step": 5664
    },
    {
      "epoch": 1.3017003676470589,
      "grad_norm": 1.7624499797821045,
      "learning_rate": 8.219464869281047e-06,
      "loss": 0.107,
      "step": 5665
    },
    {
      "epoch": 1.3019301470588236,
      "grad_norm": 2.0934531688690186,
      "learning_rate": 8.218954248366013e-06,
      "loss": 0.1498,
      "step": 5666
    },
    {
      "epoch": 1.3021599264705883,
      "grad_norm": 2.1618173122406006,
      "learning_rate": 8.218443627450982e-06,
      "loss": 0.1296,
      "step": 5667
    },
    {
      "epoch": 1.3023897058823528,
      "grad_norm": 1.9363354444503784,
      "learning_rate": 8.217933006535948e-06,
      "loss": 0.1188,
      "step": 5668
    },
    {
      "epoch": 1.3026194852941178,
      "grad_norm": 1.3267035484313965,
      "learning_rate": 8.217422385620916e-06,
      "loss": 0.1343,
      "step": 5669
    },
    {
      "epoch": 1.3028492647058822,
      "grad_norm": 1.4256927967071533,
      "learning_rate": 8.216911764705882e-06,
      "loss": 0.1297,
      "step": 5670
    },
    {
      "epoch": 1.3030790441176472,
      "grad_norm": 1.4746201038360596,
      "learning_rate": 8.21640114379085e-06,
      "loss": 0.1177,
      "step": 5671
    },
    {
      "epoch": 1.3033088235294117,
      "grad_norm": 1.7993834018707275,
      "learning_rate": 8.215890522875818e-06,
      "loss": 0.1059,
      "step": 5672
    },
    {
      "epoch": 1.3035386029411764,
      "grad_norm": 1.7082825899124146,
      "learning_rate": 8.215379901960784e-06,
      "loss": 0.1554,
      "step": 5673
    },
    {
      "epoch": 1.3037683823529411,
      "grad_norm": 2.1060354709625244,
      "learning_rate": 8.214869281045752e-06,
      "loss": 0.1234,
      "step": 5674
    },
    {
      "epoch": 1.3039981617647058,
      "grad_norm": 1.3483397960662842,
      "learning_rate": 8.21435866013072e-06,
      "loss": 0.11,
      "step": 5675
    },
    {
      "epoch": 1.3042279411764706,
      "grad_norm": 2.0519516468048096,
      "learning_rate": 8.213848039215688e-06,
      "loss": 0.11,
      "step": 5676
    },
    {
      "epoch": 1.3044577205882353,
      "grad_norm": 1.9356204271316528,
      "learning_rate": 8.213337418300654e-06,
      "loss": 0.1744,
      "step": 5677
    },
    {
      "epoch": 1.3046875,
      "grad_norm": 1.743898630142212,
      "learning_rate": 8.212826797385622e-06,
      "loss": 0.0953,
      "step": 5678
    },
    {
      "epoch": 1.3049172794117647,
      "grad_norm": 1.549185037612915,
      "learning_rate": 8.21231617647059e-06,
      "loss": 0.1498,
      "step": 5679
    },
    {
      "epoch": 1.3051470588235294,
      "grad_norm": 1.708850622177124,
      "learning_rate": 8.211805555555556e-06,
      "loss": 0.1498,
      "step": 5680
    },
    {
      "epoch": 1.3053768382352942,
      "grad_norm": 1.6956242322921753,
      "learning_rate": 8.211294934640524e-06,
      "loss": 0.1184,
      "step": 5681
    },
    {
      "epoch": 1.3056066176470589,
      "grad_norm": 2.120718002319336,
      "learning_rate": 8.21078431372549e-06,
      "loss": 0.157,
      "step": 5682
    },
    {
      "epoch": 1.3058363970588236,
      "grad_norm": 1.988311767578125,
      "learning_rate": 8.210273692810458e-06,
      "loss": 0.1325,
      "step": 5683
    },
    {
      "epoch": 1.3060661764705883,
      "grad_norm": 1.31255304813385,
      "learning_rate": 8.209763071895426e-06,
      "loss": 0.1206,
      "step": 5684
    },
    {
      "epoch": 1.3062959558823528,
      "grad_norm": 1.6121538877487183,
      "learning_rate": 8.209252450980394e-06,
      "loss": 0.1301,
      "step": 5685
    },
    {
      "epoch": 1.3065257352941178,
      "grad_norm": 1.4686460494995117,
      "learning_rate": 8.20874183006536e-06,
      "loss": 0.11,
      "step": 5686
    },
    {
      "epoch": 1.3067555147058822,
      "grad_norm": 1.8172255754470825,
      "learning_rate": 8.208231209150328e-06,
      "loss": 0.1175,
      "step": 5687
    },
    {
      "epoch": 1.3069852941176472,
      "grad_norm": 1.5514534711837769,
      "learning_rate": 8.207720588235296e-06,
      "loss": 0.1547,
      "step": 5688
    },
    {
      "epoch": 1.3072150735294117,
      "grad_norm": 2.438896417617798,
      "learning_rate": 8.207209967320262e-06,
      "loss": 0.1474,
      "step": 5689
    },
    {
      "epoch": 1.3074448529411764,
      "grad_norm": 1.5404703617095947,
      "learning_rate": 8.20669934640523e-06,
      "loss": 0.1158,
      "step": 5690
    },
    {
      "epoch": 1.3076746323529411,
      "grad_norm": 2.0696208477020264,
      "learning_rate": 8.206188725490197e-06,
      "loss": 0.1496,
      "step": 5691
    },
    {
      "epoch": 1.3079044117647058,
      "grad_norm": 1.5809460878372192,
      "learning_rate": 8.205678104575164e-06,
      "loss": 0.1342,
      "step": 5692
    },
    {
      "epoch": 1.3081341911764706,
      "grad_norm": 1.9272891283035278,
      "learning_rate": 8.205167483660131e-06,
      "loss": 0.135,
      "step": 5693
    },
    {
      "epoch": 1.3083639705882353,
      "grad_norm": 1.7963937520980835,
      "learning_rate": 8.204656862745098e-06,
      "loss": 0.1657,
      "step": 5694
    },
    {
      "epoch": 1.30859375,
      "grad_norm": 1.8262460231781006,
      "learning_rate": 8.204146241830067e-06,
      "loss": 0.1206,
      "step": 5695
    },
    {
      "epoch": 1.3088235294117647,
      "grad_norm": 2.196993112564087,
      "learning_rate": 8.203635620915033e-06,
      "loss": 0.1401,
      "step": 5696
    },
    {
      "epoch": 1.3090533088235294,
      "grad_norm": 1.4963935613632202,
      "learning_rate": 8.203125000000001e-06,
      "loss": 0.1302,
      "step": 5697
    },
    {
      "epoch": 1.3092830882352942,
      "grad_norm": 1.5765482187271118,
      "learning_rate": 8.202614379084967e-06,
      "loss": 0.1322,
      "step": 5698
    },
    {
      "epoch": 1.3095128676470589,
      "grad_norm": 1.3878381252288818,
      "learning_rate": 8.202103758169935e-06,
      "loss": 0.1182,
      "step": 5699
    },
    {
      "epoch": 1.3097426470588236,
      "grad_norm": 1.5699669122695923,
      "learning_rate": 8.201593137254903e-06,
      "loss": 0.1308,
      "step": 5700
    },
    {
      "epoch": 1.3099724264705883,
      "grad_norm": 1.3575129508972168,
      "learning_rate": 8.20108251633987e-06,
      "loss": 0.102,
      "step": 5701
    },
    {
      "epoch": 1.3102022058823528,
      "grad_norm": 1.4764432907104492,
      "learning_rate": 8.200571895424837e-06,
      "loss": 0.1294,
      "step": 5702
    },
    {
      "epoch": 1.3104319852941178,
      "grad_norm": 1.9345766305923462,
      "learning_rate": 8.200061274509803e-06,
      "loss": 0.1564,
      "step": 5703
    },
    {
      "epoch": 1.3106617647058822,
      "grad_norm": 1.5761297941207886,
      "learning_rate": 8.199550653594773e-06,
      "loss": 0.1042,
      "step": 5704
    },
    {
      "epoch": 1.3108915441176472,
      "grad_norm": 1.686347246170044,
      "learning_rate": 8.199040032679739e-06,
      "loss": 0.1269,
      "step": 5705
    },
    {
      "epoch": 1.3111213235294117,
      "grad_norm": 1.8771919012069702,
      "learning_rate": 8.198529411764707e-06,
      "loss": 0.156,
      "step": 5706
    },
    {
      "epoch": 1.3113511029411764,
      "grad_norm": 1.8532915115356445,
      "learning_rate": 8.198018790849673e-06,
      "loss": 0.1623,
      "step": 5707
    },
    {
      "epoch": 1.3115808823529411,
      "grad_norm": 1.8921360969543457,
      "learning_rate": 8.197508169934641e-06,
      "loss": 0.1788,
      "step": 5708
    },
    {
      "epoch": 1.3118106617647058,
      "grad_norm": 1.5355091094970703,
      "learning_rate": 8.196997549019609e-06,
      "loss": 0.0901,
      "step": 5709
    },
    {
      "epoch": 1.3120404411764706,
      "grad_norm": 1.3706738948822021,
      "learning_rate": 8.196486928104575e-06,
      "loss": 0.1336,
      "step": 5710
    },
    {
      "epoch": 1.3122702205882353,
      "grad_norm": 1.795077919960022,
      "learning_rate": 8.195976307189543e-06,
      "loss": 0.146,
      "step": 5711
    },
    {
      "epoch": 1.3125,
      "grad_norm": 1.6825346946716309,
      "learning_rate": 8.19546568627451e-06,
      "loss": 0.093,
      "step": 5712
    },
    {
      "epoch": 1.3127297794117647,
      "grad_norm": 1.9383047819137573,
      "learning_rate": 8.194955065359479e-06,
      "loss": 0.1634,
      "step": 5713
    },
    {
      "epoch": 1.3129595588235294,
      "grad_norm": 1.9025555849075317,
      "learning_rate": 8.194444444444445e-06,
      "loss": 0.1037,
      "step": 5714
    },
    {
      "epoch": 1.3131893382352942,
      "grad_norm": 1.4103989601135254,
      "learning_rate": 8.193933823529413e-06,
      "loss": 0.1285,
      "step": 5715
    },
    {
      "epoch": 1.3134191176470589,
      "grad_norm": 1.428472638130188,
      "learning_rate": 8.19342320261438e-06,
      "loss": 0.1141,
      "step": 5716
    },
    {
      "epoch": 1.3136488970588236,
      "grad_norm": 1.2282261848449707,
      "learning_rate": 8.192912581699347e-06,
      "loss": 0.0991,
      "step": 5717
    },
    {
      "epoch": 1.3138786764705883,
      "grad_norm": 1.578019142150879,
      "learning_rate": 8.192401960784314e-06,
      "loss": 0.1123,
      "step": 5718
    },
    {
      "epoch": 1.3141084558823528,
      "grad_norm": 1.6884844303131104,
      "learning_rate": 8.19189133986928e-06,
      "loss": 0.1524,
      "step": 5719
    },
    {
      "epoch": 1.3143382352941178,
      "grad_norm": 1.329498052597046,
      "learning_rate": 8.19138071895425e-06,
      "loss": 0.1451,
      "step": 5720
    },
    {
      "epoch": 1.3145680147058822,
      "grad_norm": 1.6899386644363403,
      "learning_rate": 8.190870098039216e-06,
      "loss": 0.1671,
      "step": 5721
    },
    {
      "epoch": 1.3147977941176472,
      "grad_norm": 1.6620742082595825,
      "learning_rate": 8.190359477124184e-06,
      "loss": 0.1251,
      "step": 5722
    },
    {
      "epoch": 1.3150275735294117,
      "grad_norm": 2.454174518585205,
      "learning_rate": 8.18984885620915e-06,
      "loss": 0.2805,
      "step": 5723
    },
    {
      "epoch": 1.3152573529411764,
      "grad_norm": 1.531069278717041,
      "learning_rate": 8.189338235294118e-06,
      "loss": 0.1375,
      "step": 5724
    },
    {
      "epoch": 1.3154871323529411,
      "grad_norm": 1.9053153991699219,
      "learning_rate": 8.188827614379086e-06,
      "loss": 0.1413,
      "step": 5725
    },
    {
      "epoch": 1.3157169117647058,
      "grad_norm": 1.7807493209838867,
      "learning_rate": 8.188316993464052e-06,
      "loss": 0.0941,
      "step": 5726
    },
    {
      "epoch": 1.3159466911764706,
      "grad_norm": 2.2029783725738525,
      "learning_rate": 8.18780637254902e-06,
      "loss": 0.1545,
      "step": 5727
    },
    {
      "epoch": 1.3161764705882353,
      "grad_norm": 1.9419903755187988,
      "learning_rate": 8.187295751633988e-06,
      "loss": 0.1334,
      "step": 5728
    },
    {
      "epoch": 1.31640625,
      "grad_norm": 1.8194119930267334,
      "learning_rate": 8.186785130718956e-06,
      "loss": 0.1418,
      "step": 5729
    },
    {
      "epoch": 1.3166360294117647,
      "grad_norm": 1.3552279472351074,
      "learning_rate": 8.186274509803922e-06,
      "loss": 0.1291,
      "step": 5730
    },
    {
      "epoch": 1.3168658088235294,
      "grad_norm": 1.5662457942962646,
      "learning_rate": 8.18576388888889e-06,
      "loss": 0.102,
      "step": 5731
    },
    {
      "epoch": 1.3170955882352942,
      "grad_norm": 1.4621000289916992,
      "learning_rate": 8.185253267973858e-06,
      "loss": 0.129,
      "step": 5732
    },
    {
      "epoch": 1.3173253676470589,
      "grad_norm": 1.651137113571167,
      "learning_rate": 8.184742647058824e-06,
      "loss": 0.1894,
      "step": 5733
    },
    {
      "epoch": 1.3175551470588236,
      "grad_norm": 1.4193283319473267,
      "learning_rate": 8.184232026143792e-06,
      "loss": 0.1128,
      "step": 5734
    },
    {
      "epoch": 1.3177849264705883,
      "grad_norm": 1.6290035247802734,
      "learning_rate": 8.183721405228758e-06,
      "loss": 0.1025,
      "step": 5735
    },
    {
      "epoch": 1.3180147058823528,
      "grad_norm": 1.5525121688842773,
      "learning_rate": 8.183210784313726e-06,
      "loss": 0.093,
      "step": 5736
    },
    {
      "epoch": 1.3182444852941178,
      "grad_norm": 1.8606033325195312,
      "learning_rate": 8.182700163398694e-06,
      "loss": 0.1059,
      "step": 5737
    },
    {
      "epoch": 1.3184742647058822,
      "grad_norm": 1.8114075660705566,
      "learning_rate": 8.18218954248366e-06,
      "loss": 0.1543,
      "step": 5738
    },
    {
      "epoch": 1.3187040441176472,
      "grad_norm": 2.205151319503784,
      "learning_rate": 8.181678921568628e-06,
      "loss": 0.1376,
      "step": 5739
    },
    {
      "epoch": 1.3189338235294117,
      "grad_norm": 1.6147899627685547,
      "learning_rate": 8.181168300653596e-06,
      "loss": 0.1007,
      "step": 5740
    },
    {
      "epoch": 1.3191636029411764,
      "grad_norm": 1.3609927892684937,
      "learning_rate": 8.180657679738563e-06,
      "loss": 0.1428,
      "step": 5741
    },
    {
      "epoch": 1.3193933823529411,
      "grad_norm": 1.6756515502929688,
      "learning_rate": 8.18014705882353e-06,
      "loss": 0.1382,
      "step": 5742
    },
    {
      "epoch": 1.3196231617647058,
      "grad_norm": 1.4735517501831055,
      "learning_rate": 8.179636437908497e-06,
      "loss": 0.1399,
      "step": 5743
    },
    {
      "epoch": 1.3198529411764706,
      "grad_norm": 1.7920852899551392,
      "learning_rate": 8.179125816993465e-06,
      "loss": 0.136,
      "step": 5744
    },
    {
      "epoch": 1.3200827205882353,
      "grad_norm": 1.7165887355804443,
      "learning_rate": 8.178615196078431e-06,
      "loss": 0.1139,
      "step": 5745
    },
    {
      "epoch": 1.3203125,
      "grad_norm": 1.8948805332183838,
      "learning_rate": 8.1781045751634e-06,
      "loss": 0.1309,
      "step": 5746
    },
    {
      "epoch": 1.3205422794117647,
      "grad_norm": 1.1201756000518799,
      "learning_rate": 8.177593954248365e-06,
      "loss": 0.1172,
      "step": 5747
    },
    {
      "epoch": 1.3207720588235294,
      "grad_norm": 1.583725929260254,
      "learning_rate": 8.177083333333335e-06,
      "loss": 0.1276,
      "step": 5748
    },
    {
      "epoch": 1.3210018382352942,
      "grad_norm": 1.3162881135940552,
      "learning_rate": 8.176572712418301e-06,
      "loss": 0.1114,
      "step": 5749
    },
    {
      "epoch": 1.3212316176470589,
      "grad_norm": 1.5218372344970703,
      "learning_rate": 8.176062091503269e-06,
      "loss": 0.1134,
      "step": 5750
    },
    {
      "epoch": 1.3214613970588236,
      "grad_norm": 1.9437570571899414,
      "learning_rate": 8.175551470588235e-06,
      "loss": 0.1536,
      "step": 5751
    },
    {
      "epoch": 1.3216911764705883,
      "grad_norm": 1.5441750288009644,
      "learning_rate": 8.175040849673203e-06,
      "loss": 0.1367,
      "step": 5752
    },
    {
      "epoch": 1.3219209558823528,
      "grad_norm": 1.3312866687774658,
      "learning_rate": 8.174530228758171e-06,
      "loss": 0.1108,
      "step": 5753
    },
    {
      "epoch": 1.3221507352941178,
      "grad_norm": 1.6034836769104004,
      "learning_rate": 8.174019607843137e-06,
      "loss": 0.0966,
      "step": 5754
    },
    {
      "epoch": 1.3223805147058822,
      "grad_norm": 1.6740226745605469,
      "learning_rate": 8.173508986928105e-06,
      "loss": 0.1129,
      "step": 5755
    },
    {
      "epoch": 1.3226102941176472,
      "grad_norm": 2.484811782836914,
      "learning_rate": 8.172998366013073e-06,
      "loss": 0.2122,
      "step": 5756
    },
    {
      "epoch": 1.3228400735294117,
      "grad_norm": 2.1913747787475586,
      "learning_rate": 8.17248774509804e-06,
      "loss": 0.1143,
      "step": 5757
    },
    {
      "epoch": 1.3230698529411764,
      "grad_norm": 1.6607545614242554,
      "learning_rate": 8.171977124183007e-06,
      "loss": 0.1603,
      "step": 5758
    },
    {
      "epoch": 1.3232996323529411,
      "grad_norm": 1.7515162229537964,
      "learning_rate": 8.171466503267975e-06,
      "loss": 0.1368,
      "step": 5759
    },
    {
      "epoch": 1.3235294117647058,
      "grad_norm": 1.579582929611206,
      "learning_rate": 8.170955882352943e-06,
      "loss": 0.13,
      "step": 5760
    },
    {
      "epoch": 1.3237591911764706,
      "grad_norm": 1.4750144481658936,
      "learning_rate": 8.170445261437909e-06,
      "loss": 0.1005,
      "step": 5761
    },
    {
      "epoch": 1.3239889705882353,
      "grad_norm": 1.4721612930297852,
      "learning_rate": 8.169934640522877e-06,
      "loss": 0.1358,
      "step": 5762
    },
    {
      "epoch": 1.32421875,
      "grad_norm": 1.4664151668548584,
      "learning_rate": 8.169424019607843e-06,
      "loss": 0.0884,
      "step": 5763
    },
    {
      "epoch": 1.3244485294117647,
      "grad_norm": 1.9154689311981201,
      "learning_rate": 8.168913398692812e-06,
      "loss": 0.1432,
      "step": 5764
    },
    {
      "epoch": 1.3246783088235294,
      "grad_norm": 1.6196056604385376,
      "learning_rate": 8.168402777777778e-06,
      "loss": 0.1277,
      "step": 5765
    },
    {
      "epoch": 1.3249080882352942,
      "grad_norm": 1.3726310729980469,
      "learning_rate": 8.167892156862746e-06,
      "loss": 0.1242,
      "step": 5766
    },
    {
      "epoch": 1.3251378676470589,
      "grad_norm": 1.96523916721344,
      "learning_rate": 8.167381535947713e-06,
      "loss": 0.127,
      "step": 5767
    },
    {
      "epoch": 1.3253676470588236,
      "grad_norm": 2.047132730484009,
      "learning_rate": 8.16687091503268e-06,
      "loss": 0.1209,
      "step": 5768
    },
    {
      "epoch": 1.3255974264705883,
      "grad_norm": 2.0690832138061523,
      "learning_rate": 8.166360294117648e-06,
      "loss": 0.1808,
      "step": 5769
    },
    {
      "epoch": 1.3258272058823528,
      "grad_norm": 1.695235252380371,
      "learning_rate": 8.165849673202614e-06,
      "loss": 0.1426,
      "step": 5770
    },
    {
      "epoch": 1.3260569852941178,
      "grad_norm": 1.6198593378067017,
      "learning_rate": 8.165339052287582e-06,
      "loss": 0.1414,
      "step": 5771
    },
    {
      "epoch": 1.3262867647058822,
      "grad_norm": 1.8702974319458008,
      "learning_rate": 8.16482843137255e-06,
      "loss": 0.1368,
      "step": 5772
    },
    {
      "epoch": 1.3265165441176472,
      "grad_norm": 1.5186930894851685,
      "learning_rate": 8.164317810457516e-06,
      "loss": 0.1189,
      "step": 5773
    },
    {
      "epoch": 1.3267463235294117,
      "grad_norm": 2.5104453563690186,
      "learning_rate": 8.163807189542484e-06,
      "loss": 0.2296,
      "step": 5774
    },
    {
      "epoch": 1.3269761029411764,
      "grad_norm": 2.070282220840454,
      "learning_rate": 8.163296568627452e-06,
      "loss": 0.1311,
      "step": 5775
    },
    {
      "epoch": 1.3272058823529411,
      "grad_norm": 2.1573808193206787,
      "learning_rate": 8.16278594771242e-06,
      "loss": 0.1383,
      "step": 5776
    },
    {
      "epoch": 1.3274356617647058,
      "grad_norm": 2.2868125438690186,
      "learning_rate": 8.162275326797386e-06,
      "loss": 0.164,
      "step": 5777
    },
    {
      "epoch": 1.3276654411764706,
      "grad_norm": 1.8803911209106445,
      "learning_rate": 8.161764705882354e-06,
      "loss": 0.1066,
      "step": 5778
    },
    {
      "epoch": 1.3278952205882353,
      "grad_norm": 1.834334135055542,
      "learning_rate": 8.16125408496732e-06,
      "loss": 0.1024,
      "step": 5779
    },
    {
      "epoch": 1.328125,
      "grad_norm": 2.062023878097534,
      "learning_rate": 8.160743464052288e-06,
      "loss": 0.1397,
      "step": 5780
    },
    {
      "epoch": 1.3283547794117647,
      "grad_norm": 1.918470025062561,
      "learning_rate": 8.160232843137256e-06,
      "loss": 0.1425,
      "step": 5781
    },
    {
      "epoch": 1.3285845588235294,
      "grad_norm": 1.9072154760360718,
      "learning_rate": 8.159722222222222e-06,
      "loss": 0.1096,
      "step": 5782
    },
    {
      "epoch": 1.3288143382352942,
      "grad_norm": 2.434340476989746,
      "learning_rate": 8.15921160130719e-06,
      "loss": 0.2128,
      "step": 5783
    },
    {
      "epoch": 1.3290441176470589,
      "grad_norm": 2.0573463439941406,
      "learning_rate": 8.158700980392158e-06,
      "loss": 0.1379,
      "step": 5784
    },
    {
      "epoch": 1.3292738970588236,
      "grad_norm": 1.6192941665649414,
      "learning_rate": 8.158190359477126e-06,
      "loss": 0.1242,
      "step": 5785
    },
    {
      "epoch": 1.3295036764705883,
      "grad_norm": 1.4921692609786987,
      "learning_rate": 8.157679738562092e-06,
      "loss": 0.1376,
      "step": 5786
    },
    {
      "epoch": 1.3297334558823528,
      "grad_norm": 1.7041988372802734,
      "learning_rate": 8.15716911764706e-06,
      "loss": 0.1521,
      "step": 5787
    },
    {
      "epoch": 1.3299632352941178,
      "grad_norm": 1.9252734184265137,
      "learning_rate": 8.156658496732027e-06,
      "loss": 0.1168,
      "step": 5788
    },
    {
      "epoch": 1.3301930147058822,
      "grad_norm": 1.7325366735458374,
      "learning_rate": 8.156147875816994e-06,
      "loss": 0.1371,
      "step": 5789
    },
    {
      "epoch": 1.3304227941176472,
      "grad_norm": 1.47269868850708,
      "learning_rate": 8.155637254901961e-06,
      "loss": 0.1194,
      "step": 5790
    },
    {
      "epoch": 1.3306525735294117,
      "grad_norm": 1.7448623180389404,
      "learning_rate": 8.155126633986928e-06,
      "loss": 0.1109,
      "step": 5791
    },
    {
      "epoch": 1.3308823529411764,
      "grad_norm": 1.2423555850982666,
      "learning_rate": 8.154616013071897e-06,
      "loss": 0.0926,
      "step": 5792
    },
    {
      "epoch": 1.3311121323529411,
      "grad_norm": 1.2918825149536133,
      "learning_rate": 8.154105392156863e-06,
      "loss": 0.1044,
      "step": 5793
    },
    {
      "epoch": 1.3313419117647058,
      "grad_norm": 1.689331293106079,
      "learning_rate": 8.153594771241831e-06,
      "loss": 0.1393,
      "step": 5794
    },
    {
      "epoch": 1.3315716911764706,
      "grad_norm": 1.549935221672058,
      "learning_rate": 8.153084150326797e-06,
      "loss": 0.1121,
      "step": 5795
    },
    {
      "epoch": 1.3318014705882353,
      "grad_norm": 2.117709159851074,
      "learning_rate": 8.152573529411765e-06,
      "loss": 0.1369,
      "step": 5796
    },
    {
      "epoch": 1.33203125,
      "grad_norm": 1.4056446552276611,
      "learning_rate": 8.152062908496733e-06,
      "loss": 0.1023,
      "step": 5797
    },
    {
      "epoch": 1.3322610294117647,
      "grad_norm": 1.8663047552108765,
      "learning_rate": 8.1515522875817e-06,
      "loss": 0.1587,
      "step": 5798
    },
    {
      "epoch": 1.3324908088235294,
      "grad_norm": 1.3999563455581665,
      "learning_rate": 8.151041666666667e-06,
      "loss": 0.0981,
      "step": 5799
    },
    {
      "epoch": 1.3327205882352942,
      "grad_norm": 1.891811728477478,
      "learning_rate": 8.150531045751635e-06,
      "loss": 0.2015,
      "step": 5800
    },
    {
      "epoch": 1.3329503676470589,
      "grad_norm": 1.749424695968628,
      "learning_rate": 8.150020424836603e-06,
      "loss": 0.1037,
      "step": 5801
    },
    {
      "epoch": 1.3331801470588236,
      "grad_norm": 1.8574694395065308,
      "learning_rate": 8.149509803921569e-06,
      "loss": 0.1282,
      "step": 5802
    },
    {
      "epoch": 1.3334099264705883,
      "grad_norm": 2.2294702529907227,
      "learning_rate": 8.148999183006537e-06,
      "loss": 0.145,
      "step": 5803
    },
    {
      "epoch": 1.3336397058823528,
      "grad_norm": 2.420419216156006,
      "learning_rate": 8.148488562091505e-06,
      "loss": 0.1952,
      "step": 5804
    },
    {
      "epoch": 1.3338694852941178,
      "grad_norm": 1.7998403310775757,
      "learning_rate": 8.147977941176471e-06,
      "loss": 0.1577,
      "step": 5805
    },
    {
      "epoch": 1.3340992647058822,
      "grad_norm": 1.5391509532928467,
      "learning_rate": 8.147467320261439e-06,
      "loss": 0.113,
      "step": 5806
    },
    {
      "epoch": 1.3343290441176472,
      "grad_norm": 1.386953353881836,
      "learning_rate": 8.146956699346405e-06,
      "loss": 0.1056,
      "step": 5807
    },
    {
      "epoch": 1.3345588235294117,
      "grad_norm": 1.5876065492630005,
      "learning_rate": 8.146446078431375e-06,
      "loss": 0.1437,
      "step": 5808
    },
    {
      "epoch": 1.3347886029411764,
      "grad_norm": 1.9643324613571167,
      "learning_rate": 8.14593545751634e-06,
      "loss": 0.1852,
      "step": 5809
    },
    {
      "epoch": 1.3350183823529411,
      "grad_norm": 1.7463371753692627,
      "learning_rate": 8.145424836601309e-06,
      "loss": 0.11,
      "step": 5810
    },
    {
      "epoch": 1.3352481617647058,
      "grad_norm": 1.8312263488769531,
      "learning_rate": 8.144914215686275e-06,
      "loss": 0.1192,
      "step": 5811
    },
    {
      "epoch": 1.3354779411764706,
      "grad_norm": 1.920570731163025,
      "learning_rate": 8.144403594771243e-06,
      "loss": 0.1303,
      "step": 5812
    },
    {
      "epoch": 1.3357077205882353,
      "grad_norm": 1.773431658744812,
      "learning_rate": 8.14389297385621e-06,
      "loss": 0.1513,
      "step": 5813
    },
    {
      "epoch": 1.3359375,
      "grad_norm": 1.4311667680740356,
      "learning_rate": 8.143382352941177e-06,
      "loss": 0.1182,
      "step": 5814
    },
    {
      "epoch": 1.3361672794117647,
      "grad_norm": 2.085415840148926,
      "learning_rate": 8.142871732026144e-06,
      "loss": 0.1217,
      "step": 5815
    },
    {
      "epoch": 1.3363970588235294,
      "grad_norm": 1.7573356628417969,
      "learning_rate": 8.142361111111112e-06,
      "loss": 0.1218,
      "step": 5816
    },
    {
      "epoch": 1.3366268382352942,
      "grad_norm": 1.603682041168213,
      "learning_rate": 8.141850490196078e-06,
      "loss": 0.1314,
      "step": 5817
    },
    {
      "epoch": 1.3368566176470589,
      "grad_norm": 2.349107265472412,
      "learning_rate": 8.141339869281046e-06,
      "loss": 0.1886,
      "step": 5818
    },
    {
      "epoch": 1.3370863970588236,
      "grad_norm": 2.0136971473693848,
      "learning_rate": 8.140829248366014e-06,
      "loss": 0.1517,
      "step": 5819
    },
    {
      "epoch": 1.3373161764705883,
      "grad_norm": 1.5032414197921753,
      "learning_rate": 8.140318627450982e-06,
      "loss": 0.1336,
      "step": 5820
    },
    {
      "epoch": 1.3375459558823528,
      "grad_norm": 1.7624706029891968,
      "learning_rate": 8.139808006535948e-06,
      "loss": 0.1246,
      "step": 5821
    },
    {
      "epoch": 1.3377757352941178,
      "grad_norm": 1.8752026557922363,
      "learning_rate": 8.139297385620916e-06,
      "loss": 0.1365,
      "step": 5822
    },
    {
      "epoch": 1.3380055147058822,
      "grad_norm": 2.0867395401000977,
      "learning_rate": 8.138786764705882e-06,
      "loss": 0.1721,
      "step": 5823
    },
    {
      "epoch": 1.3382352941176472,
      "grad_norm": 1.6426920890808105,
      "learning_rate": 8.13827614379085e-06,
      "loss": 0.1418,
      "step": 5824
    },
    {
      "epoch": 1.3384650735294117,
      "grad_norm": 2.10650897026062,
      "learning_rate": 8.137765522875818e-06,
      "loss": 0.1454,
      "step": 5825
    },
    {
      "epoch": 1.3386948529411764,
      "grad_norm": 1.7362953424453735,
      "learning_rate": 8.137254901960784e-06,
      "loss": 0.0925,
      "step": 5826
    },
    {
      "epoch": 1.3389246323529411,
      "grad_norm": 1.613635778427124,
      "learning_rate": 8.136744281045752e-06,
      "loss": 0.1681,
      "step": 5827
    },
    {
      "epoch": 1.3391544117647058,
      "grad_norm": 1.7410619258880615,
      "learning_rate": 8.13623366013072e-06,
      "loss": 0.122,
      "step": 5828
    },
    {
      "epoch": 1.3393841911764706,
      "grad_norm": 1.9378219842910767,
      "learning_rate": 8.135723039215688e-06,
      "loss": 0.123,
      "step": 5829
    },
    {
      "epoch": 1.3396139705882353,
      "grad_norm": 1.887850284576416,
      "learning_rate": 8.135212418300654e-06,
      "loss": 0.1479,
      "step": 5830
    },
    {
      "epoch": 1.33984375,
      "grad_norm": 1.6555507183074951,
      "learning_rate": 8.134701797385622e-06,
      "loss": 0.1226,
      "step": 5831
    },
    {
      "epoch": 1.3400735294117647,
      "grad_norm": 1.8453363180160522,
      "learning_rate": 8.13419117647059e-06,
      "loss": 0.1505,
      "step": 5832
    },
    {
      "epoch": 1.3403033088235294,
      "grad_norm": 1.904097080230713,
      "learning_rate": 8.133680555555556e-06,
      "loss": 0.1502,
      "step": 5833
    },
    {
      "epoch": 1.3405330882352942,
      "grad_norm": 1.399595022201538,
      "learning_rate": 8.133169934640524e-06,
      "loss": 0.0991,
      "step": 5834
    },
    {
      "epoch": 1.3407628676470589,
      "grad_norm": 1.703423023223877,
      "learning_rate": 8.13265931372549e-06,
      "loss": 0.1595,
      "step": 5835
    },
    {
      "epoch": 1.3409926470588236,
      "grad_norm": 1.919161319732666,
      "learning_rate": 8.13214869281046e-06,
      "loss": 0.155,
      "step": 5836
    },
    {
      "epoch": 1.3412224264705883,
      "grad_norm": 1.8202100992202759,
      "learning_rate": 8.131638071895426e-06,
      "loss": 0.1224,
      "step": 5837
    },
    {
      "epoch": 1.3414522058823528,
      "grad_norm": 2.051668643951416,
      "learning_rate": 8.131127450980393e-06,
      "loss": 0.134,
      "step": 5838
    },
    {
      "epoch": 1.3416819852941178,
      "grad_norm": 1.468973159790039,
      "learning_rate": 8.13061683006536e-06,
      "loss": 0.1312,
      "step": 5839
    },
    {
      "epoch": 1.3419117647058822,
      "grad_norm": 1.7797064781188965,
      "learning_rate": 8.130106209150327e-06,
      "loss": 0.1249,
      "step": 5840
    },
    {
      "epoch": 1.3421415441176472,
      "grad_norm": 1.4358357191085815,
      "learning_rate": 8.129595588235295e-06,
      "loss": 0.1126,
      "step": 5841
    },
    {
      "epoch": 1.3423713235294117,
      "grad_norm": 1.551039218902588,
      "learning_rate": 8.129084967320261e-06,
      "loss": 0.1152,
      "step": 5842
    },
    {
      "epoch": 1.3426011029411764,
      "grad_norm": 1.7113239765167236,
      "learning_rate": 8.12857434640523e-06,
      "loss": 0.1246,
      "step": 5843
    },
    {
      "epoch": 1.3428308823529411,
      "grad_norm": 1.6510298252105713,
      "learning_rate": 8.128063725490197e-06,
      "loss": 0.1274,
      "step": 5844
    },
    {
      "epoch": 1.3430606617647058,
      "grad_norm": 2.008563756942749,
      "learning_rate": 8.127553104575165e-06,
      "loss": 0.1243,
      "step": 5845
    },
    {
      "epoch": 1.3432904411764706,
      "grad_norm": 1.7220627069473267,
      "learning_rate": 8.127042483660131e-06,
      "loss": 0.1049,
      "step": 5846
    },
    {
      "epoch": 1.3435202205882353,
      "grad_norm": 1.4085086584091187,
      "learning_rate": 8.126531862745099e-06,
      "loss": 0.1278,
      "step": 5847
    },
    {
      "epoch": 1.34375,
      "grad_norm": 1.6574870347976685,
      "learning_rate": 8.126021241830067e-06,
      "loss": 0.1263,
      "step": 5848
    },
    {
      "epoch": 1.3439797794117647,
      "grad_norm": 1.9198694229125977,
      "learning_rate": 8.125510620915033e-06,
      "loss": 0.1687,
      "step": 5849
    },
    {
      "epoch": 1.3442095588235294,
      "grad_norm": 1.4178332090377808,
      "learning_rate": 8.125000000000001e-06,
      "loss": 0.1153,
      "step": 5850
    },
    {
      "epoch": 1.3444393382352942,
      "grad_norm": 2.070389986038208,
      "learning_rate": 8.124489379084967e-06,
      "loss": 0.1048,
      "step": 5851
    },
    {
      "epoch": 1.3446691176470589,
      "grad_norm": 1.50946843624115,
      "learning_rate": 8.123978758169935e-06,
      "loss": 0.1343,
      "step": 5852
    },
    {
      "epoch": 1.3448988970588236,
      "grad_norm": 1.8110243082046509,
      "learning_rate": 8.123468137254903e-06,
      "loss": 0.1379,
      "step": 5853
    },
    {
      "epoch": 1.3451286764705883,
      "grad_norm": 1.3234013319015503,
      "learning_rate": 8.12295751633987e-06,
      "loss": 0.1236,
      "step": 5854
    },
    {
      "epoch": 1.3453584558823528,
      "grad_norm": 1.601768136024475,
      "learning_rate": 8.122446895424837e-06,
      "loss": 0.1434,
      "step": 5855
    },
    {
      "epoch": 1.3455882352941178,
      "grad_norm": 2.6272830963134766,
      "learning_rate": 8.121936274509805e-06,
      "loss": 0.1776,
      "step": 5856
    },
    {
      "epoch": 1.3458180147058822,
      "grad_norm": 1.8743633031845093,
      "learning_rate": 8.121425653594773e-06,
      "loss": 0.1184,
      "step": 5857
    },
    {
      "epoch": 1.3460477941176472,
      "grad_norm": 1.7541483640670776,
      "learning_rate": 8.120915032679739e-06,
      "loss": 0.1588,
      "step": 5858
    },
    {
      "epoch": 1.3462775735294117,
      "grad_norm": 2.100337028503418,
      "learning_rate": 8.120404411764707e-06,
      "loss": 0.1605,
      "step": 5859
    },
    {
      "epoch": 1.3465073529411764,
      "grad_norm": 1.8616242408752441,
      "learning_rate": 8.119893790849673e-06,
      "loss": 0.1116,
      "step": 5860
    },
    {
      "epoch": 1.3467371323529411,
      "grad_norm": 2.080880880355835,
      "learning_rate": 8.11938316993464e-06,
      "loss": 0.1429,
      "step": 5861
    },
    {
      "epoch": 1.3469669117647058,
      "grad_norm": 1.6719584465026855,
      "learning_rate": 8.118872549019609e-06,
      "loss": 0.129,
      "step": 5862
    },
    {
      "epoch": 1.3471966911764706,
      "grad_norm": 1.4169414043426514,
      "learning_rate": 8.118361928104576e-06,
      "loss": 0.1501,
      "step": 5863
    },
    {
      "epoch": 1.3474264705882353,
      "grad_norm": 1.6422679424285889,
      "learning_rate": 8.117851307189543e-06,
      "loss": 0.1317,
      "step": 5864
    },
    {
      "epoch": 1.34765625,
      "grad_norm": 1.4379379749298096,
      "learning_rate": 8.11734068627451e-06,
      "loss": 0.1018,
      "step": 5865
    },
    {
      "epoch": 1.3478860294117647,
      "grad_norm": 1.2926939725875854,
      "learning_rate": 8.116830065359478e-06,
      "loss": 0.1072,
      "step": 5866
    },
    {
      "epoch": 1.3481158088235294,
      "grad_norm": 2.243478298187256,
      "learning_rate": 8.116319444444444e-06,
      "loss": 0.1831,
      "step": 5867
    },
    {
      "epoch": 1.3483455882352942,
      "grad_norm": 1.868747591972351,
      "learning_rate": 8.115808823529412e-06,
      "loss": 0.135,
      "step": 5868
    },
    {
      "epoch": 1.3485753676470589,
      "grad_norm": 1.8416666984558105,
      "learning_rate": 8.11529820261438e-06,
      "loss": 0.1768,
      "step": 5869
    },
    {
      "epoch": 1.3488051470588236,
      "grad_norm": 1.6928715705871582,
      "learning_rate": 8.114787581699346e-06,
      "loss": 0.1378,
      "step": 5870
    },
    {
      "epoch": 1.3490349264705883,
      "grad_norm": 1.4733335971832275,
      "learning_rate": 8.114276960784314e-06,
      "loss": 0.1184,
      "step": 5871
    },
    {
      "epoch": 1.3492647058823528,
      "grad_norm": 2.188605308532715,
      "learning_rate": 8.11376633986928e-06,
      "loss": 0.1589,
      "step": 5872
    },
    {
      "epoch": 1.3494944852941178,
      "grad_norm": 1.5956884622573853,
      "learning_rate": 8.11325571895425e-06,
      "loss": 0.1008,
      "step": 5873
    },
    {
      "epoch": 1.3497242647058822,
      "grad_norm": 1.8678483963012695,
      "learning_rate": 8.112745098039216e-06,
      "loss": 0.1102,
      "step": 5874
    },
    {
      "epoch": 1.3499540441176472,
      "grad_norm": 1.6985626220703125,
      "learning_rate": 8.112234477124184e-06,
      "loss": 0.158,
      "step": 5875
    },
    {
      "epoch": 1.3501838235294117,
      "grad_norm": 1.8380112648010254,
      "learning_rate": 8.11172385620915e-06,
      "loss": 0.1227,
      "step": 5876
    },
    {
      "epoch": 1.3504136029411764,
      "grad_norm": 1.747523546218872,
      "learning_rate": 8.111213235294118e-06,
      "loss": 0.1141,
      "step": 5877
    },
    {
      "epoch": 1.3506433823529411,
      "grad_norm": 1.9025330543518066,
      "learning_rate": 8.110702614379086e-06,
      "loss": 0.1279,
      "step": 5878
    },
    {
      "epoch": 1.3508731617647058,
      "grad_norm": 1.8671928644180298,
      "learning_rate": 8.110191993464052e-06,
      "loss": 0.1308,
      "step": 5879
    },
    {
      "epoch": 1.3511029411764706,
      "grad_norm": 1.5398781299591064,
      "learning_rate": 8.10968137254902e-06,
      "loss": 0.1298,
      "step": 5880
    },
    {
      "epoch": 1.3513327205882353,
      "grad_norm": 1.4422976970672607,
      "learning_rate": 8.109170751633988e-06,
      "loss": 0.1359,
      "step": 5881
    },
    {
      "epoch": 1.3515625,
      "grad_norm": 2.306647777557373,
      "learning_rate": 8.108660130718956e-06,
      "loss": 0.1814,
      "step": 5882
    },
    {
      "epoch": 1.3517922794117647,
      "grad_norm": 1.8081952333450317,
      "learning_rate": 8.108149509803922e-06,
      "loss": 0.1121,
      "step": 5883
    },
    {
      "epoch": 1.3520220588235294,
      "grad_norm": 2.1461219787597656,
      "learning_rate": 8.10763888888889e-06,
      "loss": 0.2003,
      "step": 5884
    },
    {
      "epoch": 1.3522518382352942,
      "grad_norm": 1.7942776679992676,
      "learning_rate": 8.107128267973857e-06,
      "loss": 0.1378,
      "step": 5885
    },
    {
      "epoch": 1.3524816176470589,
      "grad_norm": 2.262073278427124,
      "learning_rate": 8.106617647058824e-06,
      "loss": 0.1131,
      "step": 5886
    },
    {
      "epoch": 1.3527113970588236,
      "grad_norm": 1.855017066001892,
      "learning_rate": 8.106107026143792e-06,
      "loss": 0.1323,
      "step": 5887
    },
    {
      "epoch": 1.3529411764705883,
      "grad_norm": 2.0245578289031982,
      "learning_rate": 8.105596405228758e-06,
      "loss": 0.184,
      "step": 5888
    },
    {
      "epoch": 1.3531709558823528,
      "grad_norm": 1.9986448287963867,
      "learning_rate": 8.105085784313727e-06,
      "loss": 0.1437,
      "step": 5889
    },
    {
      "epoch": 1.3534007352941178,
      "grad_norm": 1.6717065572738647,
      "learning_rate": 8.104575163398693e-06,
      "loss": 0.1214,
      "step": 5890
    },
    {
      "epoch": 1.3536305147058822,
      "grad_norm": 1.7075786590576172,
      "learning_rate": 8.104064542483661e-06,
      "loss": 0.1169,
      "step": 5891
    },
    {
      "epoch": 1.3538602941176472,
      "grad_norm": 1.4930338859558105,
      "learning_rate": 8.103553921568627e-06,
      "loss": 0.0986,
      "step": 5892
    },
    {
      "epoch": 1.3540900735294117,
      "grad_norm": 1.8328216075897217,
      "learning_rate": 8.103043300653595e-06,
      "loss": 0.1372,
      "step": 5893
    },
    {
      "epoch": 1.3543198529411764,
      "grad_norm": 2.2187561988830566,
      "learning_rate": 8.102532679738563e-06,
      "loss": 0.1465,
      "step": 5894
    },
    {
      "epoch": 1.3545496323529411,
      "grad_norm": 1.6065281629562378,
      "learning_rate": 8.10202205882353e-06,
      "loss": 0.1251,
      "step": 5895
    },
    {
      "epoch": 1.3547794117647058,
      "grad_norm": 2.052788257598877,
      "learning_rate": 8.101511437908497e-06,
      "loss": 0.1966,
      "step": 5896
    },
    {
      "epoch": 1.3550091911764706,
      "grad_norm": 1.847564458847046,
      "learning_rate": 8.101000816993465e-06,
      "loss": 0.183,
      "step": 5897
    },
    {
      "epoch": 1.3552389705882353,
      "grad_norm": 1.561449646949768,
      "learning_rate": 8.100490196078433e-06,
      "loss": 0.125,
      "step": 5898
    },
    {
      "epoch": 1.35546875,
      "grad_norm": 1.3989280462265015,
      "learning_rate": 8.099979575163399e-06,
      "loss": 0.1552,
      "step": 5899
    },
    {
      "epoch": 1.3556985294117647,
      "grad_norm": 1.5215493440628052,
      "learning_rate": 8.099468954248367e-06,
      "loss": 0.1238,
      "step": 5900
    },
    {
      "epoch": 1.3559283088235294,
      "grad_norm": 1.95089852809906,
      "learning_rate": 8.098958333333335e-06,
      "loss": 0.114,
      "step": 5901
    },
    {
      "epoch": 1.3561580882352942,
      "grad_norm": 1.7898496389389038,
      "learning_rate": 8.098447712418301e-06,
      "loss": 0.1404,
      "step": 5902
    },
    {
      "epoch": 1.3563878676470589,
      "grad_norm": 1.8041776418685913,
      "learning_rate": 8.097937091503269e-06,
      "loss": 0.1449,
      "step": 5903
    },
    {
      "epoch": 1.3566176470588236,
      "grad_norm": 1.2579983472824097,
      "learning_rate": 8.097426470588235e-06,
      "loss": 0.0912,
      "step": 5904
    },
    {
      "epoch": 1.3568474264705883,
      "grad_norm": 2.2030880451202393,
      "learning_rate": 8.096915849673203e-06,
      "loss": 0.2082,
      "step": 5905
    },
    {
      "epoch": 1.3570772058823528,
      "grad_norm": 1.3544907569885254,
      "learning_rate": 8.09640522875817e-06,
      "loss": 0.1026,
      "step": 5906
    },
    {
      "epoch": 1.3573069852941178,
      "grad_norm": 1.6238737106323242,
      "learning_rate": 8.095894607843137e-06,
      "loss": 0.1204,
      "step": 5907
    },
    {
      "epoch": 1.3575367647058822,
      "grad_norm": 1.5101873874664307,
      "learning_rate": 8.095383986928105e-06,
      "loss": 0.1099,
      "step": 5908
    },
    {
      "epoch": 1.3577665441176472,
      "grad_norm": 1.4333540201187134,
      "learning_rate": 8.094873366013073e-06,
      "loss": 0.0948,
      "step": 5909
    },
    {
      "epoch": 1.3579963235294117,
      "grad_norm": 1.6409214735031128,
      "learning_rate": 8.09436274509804e-06,
      "loss": 0.1366,
      "step": 5910
    },
    {
      "epoch": 1.3582261029411764,
      "grad_norm": 1.8812059164047241,
      "learning_rate": 8.093852124183007e-06,
      "loss": 0.1524,
      "step": 5911
    },
    {
      "epoch": 1.3584558823529411,
      "grad_norm": 1.8862513303756714,
      "learning_rate": 8.093341503267975e-06,
      "loss": 0.1292,
      "step": 5912
    },
    {
      "epoch": 1.3586856617647058,
      "grad_norm": 1.2192127704620361,
      "learning_rate": 8.092830882352942e-06,
      "loss": 0.1,
      "step": 5913
    },
    {
      "epoch": 1.3589154411764706,
      "grad_norm": 1.8807579278945923,
      "learning_rate": 8.092320261437909e-06,
      "loss": 0.1287,
      "step": 5914
    },
    {
      "epoch": 1.3591452205882353,
      "grad_norm": 1.681565761566162,
      "learning_rate": 8.091809640522876e-06,
      "loss": 0.1249,
      "step": 5915
    },
    {
      "epoch": 1.359375,
      "grad_norm": 1.6890180110931396,
      "learning_rate": 8.091299019607843e-06,
      "loss": 0.1072,
      "step": 5916
    },
    {
      "epoch": 1.3596047794117647,
      "grad_norm": 1.6049695014953613,
      "learning_rate": 8.090788398692812e-06,
      "loss": 0.1319,
      "step": 5917
    },
    {
      "epoch": 1.3598345588235294,
      "grad_norm": 1.349145531654358,
      "learning_rate": 8.090277777777778e-06,
      "loss": 0.1177,
      "step": 5918
    },
    {
      "epoch": 1.3600643382352942,
      "grad_norm": 1.424634337425232,
      "learning_rate": 8.089767156862746e-06,
      "loss": 0.1139,
      "step": 5919
    },
    {
      "epoch": 1.3602941176470589,
      "grad_norm": 1.345995545387268,
      "learning_rate": 8.089256535947712e-06,
      "loss": 0.1106,
      "step": 5920
    },
    {
      "epoch": 1.3605238970588236,
      "grad_norm": 1.778077244758606,
      "learning_rate": 8.08874591503268e-06,
      "loss": 0.1203,
      "step": 5921
    },
    {
      "epoch": 1.3607536764705883,
      "grad_norm": 1.7728828191757202,
      "learning_rate": 8.088235294117648e-06,
      "loss": 0.1172,
      "step": 5922
    },
    {
      "epoch": 1.3609834558823528,
      "grad_norm": 2.4318833351135254,
      "learning_rate": 8.087724673202614e-06,
      "loss": 0.1304,
      "step": 5923
    },
    {
      "epoch": 1.3612132352941178,
      "grad_norm": 2.284658193588257,
      "learning_rate": 8.087214052287582e-06,
      "loss": 0.1275,
      "step": 5924
    },
    {
      "epoch": 1.3614430147058822,
      "grad_norm": 1.628319501876831,
      "learning_rate": 8.08670343137255e-06,
      "loss": 0.1284,
      "step": 5925
    },
    {
      "epoch": 1.3616727941176472,
      "grad_norm": 2.0094900131225586,
      "learning_rate": 8.086192810457518e-06,
      "loss": 0.0993,
      "step": 5926
    },
    {
      "epoch": 1.3619025735294117,
      "grad_norm": 2.045891046524048,
      "learning_rate": 8.085682189542484e-06,
      "loss": 0.1485,
      "step": 5927
    },
    {
      "epoch": 1.3621323529411764,
      "grad_norm": 1.6333695650100708,
      "learning_rate": 8.085171568627452e-06,
      "loss": 0.1419,
      "step": 5928
    },
    {
      "epoch": 1.3623621323529411,
      "grad_norm": 1.6753551959991455,
      "learning_rate": 8.08466094771242e-06,
      "loss": 0.1333,
      "step": 5929
    },
    {
      "epoch": 1.3625919117647058,
      "grad_norm": 1.497960090637207,
      "learning_rate": 8.084150326797386e-06,
      "loss": 0.1207,
      "step": 5930
    },
    {
      "epoch": 1.3628216911764706,
      "grad_norm": 1.6304211616516113,
      "learning_rate": 8.083639705882354e-06,
      "loss": 0.1027,
      "step": 5931
    },
    {
      "epoch": 1.3630514705882353,
      "grad_norm": 1.4019542932510376,
      "learning_rate": 8.08312908496732e-06,
      "loss": 0.1342,
      "step": 5932
    },
    {
      "epoch": 1.36328125,
      "grad_norm": 1.6283015012741089,
      "learning_rate": 8.08261846405229e-06,
      "loss": 0.1117,
      "step": 5933
    },
    {
      "epoch": 1.3635110294117647,
      "grad_norm": 1.5611886978149414,
      "learning_rate": 8.082107843137256e-06,
      "loss": 0.1058,
      "step": 5934
    },
    {
      "epoch": 1.3637408088235294,
      "grad_norm": 1.7663166522979736,
      "learning_rate": 8.081597222222223e-06,
      "loss": 0.1386,
      "step": 5935
    },
    {
      "epoch": 1.3639705882352942,
      "grad_norm": 1.6135523319244385,
      "learning_rate": 8.08108660130719e-06,
      "loss": 0.1028,
      "step": 5936
    },
    {
      "epoch": 1.3642003676470589,
      "grad_norm": 1.4913181066513062,
      "learning_rate": 8.080575980392157e-06,
      "loss": 0.1657,
      "step": 5937
    },
    {
      "epoch": 1.3644301470588236,
      "grad_norm": 1.5612014532089233,
      "learning_rate": 8.080065359477125e-06,
      "loss": 0.0995,
      "step": 5938
    },
    {
      "epoch": 1.3646599264705883,
      "grad_norm": 2.2814273834228516,
      "learning_rate": 8.079554738562092e-06,
      "loss": 0.1577,
      "step": 5939
    },
    {
      "epoch": 1.3648897058823528,
      "grad_norm": 1.9166080951690674,
      "learning_rate": 8.07904411764706e-06,
      "loss": 0.1308,
      "step": 5940
    },
    {
      "epoch": 1.3651194852941178,
      "grad_norm": 1.4790220260620117,
      "learning_rate": 8.078533496732027e-06,
      "loss": 0.1311,
      "step": 5941
    },
    {
      "epoch": 1.3653492647058822,
      "grad_norm": 1.359954595565796,
      "learning_rate": 8.078022875816995e-06,
      "loss": 0.1054,
      "step": 5942
    },
    {
      "epoch": 1.3655790441176472,
      "grad_norm": 1.694256067276001,
      "learning_rate": 8.077512254901961e-06,
      "loss": 0.1212,
      "step": 5943
    },
    {
      "epoch": 1.3658088235294117,
      "grad_norm": 1.8741823434829712,
      "learning_rate": 8.077001633986929e-06,
      "loss": 0.1422,
      "step": 5944
    },
    {
      "epoch": 1.3660386029411764,
      "grad_norm": 1.5972325801849365,
      "learning_rate": 8.076491013071897e-06,
      "loss": 0.1058,
      "step": 5945
    },
    {
      "epoch": 1.3662683823529411,
      "grad_norm": 1.9882484674453735,
      "learning_rate": 8.075980392156863e-06,
      "loss": 0.1172,
      "step": 5946
    },
    {
      "epoch": 1.3664981617647058,
      "grad_norm": 1.3817065954208374,
      "learning_rate": 8.075469771241831e-06,
      "loss": 0.1133,
      "step": 5947
    },
    {
      "epoch": 1.3667279411764706,
      "grad_norm": 2.643084764480591,
      "learning_rate": 8.074959150326797e-06,
      "loss": 0.116,
      "step": 5948
    },
    {
      "epoch": 1.3669577205882353,
      "grad_norm": 2.062838077545166,
      "learning_rate": 8.074448529411765e-06,
      "loss": 0.172,
      "step": 5949
    },
    {
      "epoch": 1.3671875,
      "grad_norm": 1.6457035541534424,
      "learning_rate": 8.073937908496733e-06,
      "loss": 0.1359,
      "step": 5950
    },
    {
      "epoch": 1.3674172794117647,
      "grad_norm": 1.7044084072113037,
      "learning_rate": 8.073427287581699e-06,
      "loss": 0.1676,
      "step": 5951
    },
    {
      "epoch": 1.3676470588235294,
      "grad_norm": 1.5005595684051514,
      "learning_rate": 8.072916666666667e-06,
      "loss": 0.1183,
      "step": 5952
    },
    {
      "epoch": 1.3678768382352942,
      "grad_norm": 1.8840559720993042,
      "learning_rate": 8.072406045751635e-06,
      "loss": 0.1247,
      "step": 5953
    },
    {
      "epoch": 1.3681066176470589,
      "grad_norm": 1.7537263631820679,
      "learning_rate": 8.071895424836603e-06,
      "loss": 0.1315,
      "step": 5954
    },
    {
      "epoch": 1.3683363970588236,
      "grad_norm": 1.9230610132217407,
      "learning_rate": 8.071384803921569e-06,
      "loss": 0.1606,
      "step": 5955
    },
    {
      "epoch": 1.3685661764705883,
      "grad_norm": 1.840480089187622,
      "learning_rate": 8.070874183006537e-06,
      "loss": 0.1018,
      "step": 5956
    },
    {
      "epoch": 1.3687959558823528,
      "grad_norm": 1.6346286535263062,
      "learning_rate": 8.070363562091505e-06,
      "loss": 0.1588,
      "step": 5957
    },
    {
      "epoch": 1.3690257352941178,
      "grad_norm": 1.8092665672302246,
      "learning_rate": 8.06985294117647e-06,
      "loss": 0.1041,
      "step": 5958
    },
    {
      "epoch": 1.3692555147058822,
      "grad_norm": 1.4374840259552002,
      "learning_rate": 8.069342320261439e-06,
      "loss": 0.1478,
      "step": 5959
    },
    {
      "epoch": 1.3694852941176472,
      "grad_norm": 1.8953208923339844,
      "learning_rate": 8.068831699346405e-06,
      "loss": 0.1135,
      "step": 5960
    },
    {
      "epoch": 1.3697150735294117,
      "grad_norm": 1.431670904159546,
      "learning_rate": 8.068321078431374e-06,
      "loss": 0.0861,
      "step": 5961
    },
    {
      "epoch": 1.3699448529411764,
      "grad_norm": 2.1289994716644287,
      "learning_rate": 8.06781045751634e-06,
      "loss": 0.185,
      "step": 5962
    },
    {
      "epoch": 1.3701746323529411,
      "grad_norm": 1.9869906902313232,
      "learning_rate": 8.067299836601308e-06,
      "loss": 0.112,
      "step": 5963
    },
    {
      "epoch": 1.3704044117647058,
      "grad_norm": 1.7749799489974976,
      "learning_rate": 8.066789215686275e-06,
      "loss": 0.1534,
      "step": 5964
    },
    {
      "epoch": 1.3706341911764706,
      "grad_norm": 1.6987696886062622,
      "learning_rate": 8.066278594771242e-06,
      "loss": 0.1201,
      "step": 5965
    },
    {
      "epoch": 1.3708639705882353,
      "grad_norm": 1.5768113136291504,
      "learning_rate": 8.06576797385621e-06,
      "loss": 0.0782,
      "step": 5966
    },
    {
      "epoch": 1.37109375,
      "grad_norm": 1.846323847770691,
      "learning_rate": 8.065257352941176e-06,
      "loss": 0.1308,
      "step": 5967
    },
    {
      "epoch": 1.3713235294117647,
      "grad_norm": 1.7108135223388672,
      "learning_rate": 8.064746732026144e-06,
      "loss": 0.1432,
      "step": 5968
    },
    {
      "epoch": 1.3715533088235294,
      "grad_norm": 2.0319387912750244,
      "learning_rate": 8.064236111111112e-06,
      "loss": 0.1177,
      "step": 5969
    },
    {
      "epoch": 1.3717830882352942,
      "grad_norm": 2.010293960571289,
      "learning_rate": 8.06372549019608e-06,
      "loss": 0.1036,
      "step": 5970
    },
    {
      "epoch": 1.3720128676470589,
      "grad_norm": 1.7858428955078125,
      "learning_rate": 8.063214869281046e-06,
      "loss": 0.1465,
      "step": 5971
    },
    {
      "epoch": 1.3722426470588236,
      "grad_norm": 1.7172983884811401,
      "learning_rate": 8.062704248366014e-06,
      "loss": 0.1478,
      "step": 5972
    },
    {
      "epoch": 1.3724724264705883,
      "grad_norm": 1.5818918943405151,
      "learning_rate": 8.062193627450982e-06,
      "loss": 0.1222,
      "step": 5973
    },
    {
      "epoch": 1.3727022058823528,
      "grad_norm": 1.5261136293411255,
      "learning_rate": 8.061683006535948e-06,
      "loss": 0.1305,
      "step": 5974
    },
    {
      "epoch": 1.3729319852941178,
      "grad_norm": 1.5846449136734009,
      "learning_rate": 8.061172385620916e-06,
      "loss": 0.1385,
      "step": 5975
    },
    {
      "epoch": 1.3731617647058822,
      "grad_norm": 1.6553566455841064,
      "learning_rate": 8.060661764705882e-06,
      "loss": 0.0909,
      "step": 5976
    },
    {
      "epoch": 1.3733915441176472,
      "grad_norm": 1.3842768669128418,
      "learning_rate": 8.060151143790852e-06,
      "loss": 0.1213,
      "step": 5977
    },
    {
      "epoch": 1.3736213235294117,
      "grad_norm": 1.7336441278457642,
      "learning_rate": 8.059640522875818e-06,
      "loss": 0.0943,
      "step": 5978
    },
    {
      "epoch": 1.3738511029411764,
      "grad_norm": 1.4056285619735718,
      "learning_rate": 8.059129901960786e-06,
      "loss": 0.1066,
      "step": 5979
    },
    {
      "epoch": 1.3740808823529411,
      "grad_norm": 1.918777346611023,
      "learning_rate": 8.058619281045752e-06,
      "loss": 0.1672,
      "step": 5980
    },
    {
      "epoch": 1.3743106617647058,
      "grad_norm": 1.4312132596969604,
      "learning_rate": 8.05810866013072e-06,
      "loss": 0.1098,
      "step": 5981
    },
    {
      "epoch": 1.3745404411764706,
      "grad_norm": 1.7808045148849487,
      "learning_rate": 8.057598039215688e-06,
      "loss": 0.1005,
      "step": 5982
    },
    {
      "epoch": 1.3747702205882353,
      "grad_norm": 1.615511178970337,
      "learning_rate": 8.057087418300654e-06,
      "loss": 0.1127,
      "step": 5983
    },
    {
      "epoch": 1.375,
      "grad_norm": 1.684828519821167,
      "learning_rate": 8.056576797385622e-06,
      "loss": 0.1144,
      "step": 5984
    },
    {
      "epoch": 1.3752297794117647,
      "grad_norm": 1.7537848949432373,
      "learning_rate": 8.05606617647059e-06,
      "loss": 0.1067,
      "step": 5985
    },
    {
      "epoch": 1.3754595588235294,
      "grad_norm": 2.1183230876922607,
      "learning_rate": 8.055555555555557e-06,
      "loss": 0.1755,
      "step": 5986
    },
    {
      "epoch": 1.3756893382352942,
      "grad_norm": 1.6866838932037354,
      "learning_rate": 8.055044934640523e-06,
      "loss": 0.1045,
      "step": 5987
    },
    {
      "epoch": 1.3759191176470589,
      "grad_norm": 1.9975742101669312,
      "learning_rate": 8.054534313725491e-06,
      "loss": 0.1346,
      "step": 5988
    },
    {
      "epoch": 1.3761488970588236,
      "grad_norm": 1.7228929996490479,
      "learning_rate": 8.05402369281046e-06,
      "loss": 0.1148,
      "step": 5989
    },
    {
      "epoch": 1.3763786764705883,
      "grad_norm": 1.7863178253173828,
      "learning_rate": 8.053513071895425e-06,
      "loss": 0.1424,
      "step": 5990
    },
    {
      "epoch": 1.3766084558823528,
      "grad_norm": 1.697935938835144,
      "learning_rate": 8.053002450980393e-06,
      "loss": 0.1171,
      "step": 5991
    },
    {
      "epoch": 1.3768382352941178,
      "grad_norm": 2.323241710662842,
      "learning_rate": 8.05249183006536e-06,
      "loss": 0.1515,
      "step": 5992
    },
    {
      "epoch": 1.3770680147058822,
      "grad_norm": 1.4677269458770752,
      "learning_rate": 8.051981209150327e-06,
      "loss": 0.1038,
      "step": 5993
    },
    {
      "epoch": 1.3772977941176472,
      "grad_norm": 2.4637506008148193,
      "learning_rate": 8.051470588235295e-06,
      "loss": 0.1285,
      "step": 5994
    },
    {
      "epoch": 1.3775275735294117,
      "grad_norm": 1.2177337408065796,
      "learning_rate": 8.050959967320261e-06,
      "loss": 0.1105,
      "step": 5995
    },
    {
      "epoch": 1.3777573529411764,
      "grad_norm": 1.6462440490722656,
      "learning_rate": 8.050449346405229e-06,
      "loss": 0.1151,
      "step": 5996
    },
    {
      "epoch": 1.3779871323529411,
      "grad_norm": 2.2963998317718506,
      "learning_rate": 8.049938725490197e-06,
      "loss": 0.1589,
      "step": 5997
    },
    {
      "epoch": 1.3782169117647058,
      "grad_norm": 1.6207401752471924,
      "learning_rate": 8.049428104575165e-06,
      "loss": 0.1463,
      "step": 5998
    },
    {
      "epoch": 1.3784466911764706,
      "grad_norm": 1.4729918241500854,
      "learning_rate": 8.048917483660131e-06,
      "loss": 0.1146,
      "step": 5999
    },
    {
      "epoch": 1.3786764705882353,
      "grad_norm": 1.9825140237808228,
      "learning_rate": 8.048406862745099e-06,
      "loss": 0.1353,
      "step": 6000
    },
    {
      "epoch": 1.3786764705882353,
      "eval_loss": 0.1299019604921341,
      "eval_runtime": 419.8232,
      "eval_samples_per_second": 21.214,
      "eval_steps_per_second": 10.607,
      "step": 6000
    },
    {
      "epoch": 1.37890625,
      "grad_norm": 1.6754515171051025,
      "learning_rate": 8.047896241830067e-06,
      "loss": 0.1369,
      "step": 6001
    },
    {
      "epoch": 1.3791360294117647,
      "grad_norm": 1.6683330535888672,
      "learning_rate": 8.047385620915033e-06,
      "loss": 0.1096,
      "step": 6002
    },
    {
      "epoch": 1.3793658088235294,
      "grad_norm": 1.6571587324142456,
      "learning_rate": 8.046875e-06,
      "loss": 0.1393,
      "step": 6003
    },
    {
      "epoch": 1.3795955882352942,
      "grad_norm": 1.7470282316207886,
      "learning_rate": 8.046364379084967e-06,
      "loss": 0.1344,
      "step": 6004
    },
    {
      "epoch": 1.3798253676470589,
      "grad_norm": 1.4258517026901245,
      "learning_rate": 8.045853758169935e-06,
      "loss": 0.1274,
      "step": 6005
    },
    {
      "epoch": 1.3800551470588236,
      "grad_norm": 1.5055190324783325,
      "learning_rate": 8.045343137254903e-06,
      "loss": 0.1289,
      "step": 6006
    },
    {
      "epoch": 1.3802849264705883,
      "grad_norm": 2.030524730682373,
      "learning_rate": 8.04483251633987e-06,
      "loss": 0.1557,
      "step": 6007
    },
    {
      "epoch": 1.3805147058823528,
      "grad_norm": 1.8544793128967285,
      "learning_rate": 8.044321895424837e-06,
      "loss": 0.1485,
      "step": 6008
    },
    {
      "epoch": 1.3807444852941178,
      "grad_norm": 1.954816460609436,
      "learning_rate": 8.043811274509805e-06,
      "loss": 0.1573,
      "step": 6009
    },
    {
      "epoch": 1.3809742647058822,
      "grad_norm": 1.6068087816238403,
      "learning_rate": 8.043300653594772e-06,
      "loss": 0.1239,
      "step": 6010
    },
    {
      "epoch": 1.3812040441176472,
      "grad_norm": 1.7074867486953735,
      "learning_rate": 8.042790032679739e-06,
      "loss": 0.0937,
      "step": 6011
    },
    {
      "epoch": 1.3814338235294117,
      "grad_norm": 1.8630177974700928,
      "learning_rate": 8.042279411764706e-06,
      "loss": 0.1124,
      "step": 6012
    },
    {
      "epoch": 1.3816636029411764,
      "grad_norm": 1.5638244152069092,
      "learning_rate": 8.041768790849673e-06,
      "loss": 0.1188,
      "step": 6013
    },
    {
      "epoch": 1.3818933823529411,
      "grad_norm": 2.4248106479644775,
      "learning_rate": 8.041258169934642e-06,
      "loss": 0.1008,
      "step": 6014
    },
    {
      "epoch": 1.3821231617647058,
      "grad_norm": 2.2448620796203613,
      "learning_rate": 8.040747549019608e-06,
      "loss": 0.1516,
      "step": 6015
    },
    {
      "epoch": 1.3823529411764706,
      "grad_norm": 2.065106153488159,
      "learning_rate": 8.040236928104576e-06,
      "loss": 0.1393,
      "step": 6016
    },
    {
      "epoch": 1.3825827205882353,
      "grad_norm": 1.521986484527588,
      "learning_rate": 8.039726307189542e-06,
      "loss": 0.1752,
      "step": 6017
    },
    {
      "epoch": 1.3828125,
      "grad_norm": 2.2171401977539062,
      "learning_rate": 8.03921568627451e-06,
      "loss": 0.1457,
      "step": 6018
    },
    {
      "epoch": 1.3830422794117647,
      "grad_norm": 1.3762922286987305,
      "learning_rate": 8.038705065359478e-06,
      "loss": 0.1226,
      "step": 6019
    },
    {
      "epoch": 1.3832720588235294,
      "grad_norm": 1.917796015739441,
      "learning_rate": 8.038194444444444e-06,
      "loss": 0.1369,
      "step": 6020
    },
    {
      "epoch": 1.3835018382352942,
      "grad_norm": 1.6112607717514038,
      "learning_rate": 8.037683823529412e-06,
      "loss": 0.1059,
      "step": 6021
    },
    {
      "epoch": 1.3837316176470589,
      "grad_norm": 1.9196826219558716,
      "learning_rate": 8.03717320261438e-06,
      "loss": 0.0973,
      "step": 6022
    },
    {
      "epoch": 1.3839613970588236,
      "grad_norm": 2.0672872066497803,
      "learning_rate": 8.036662581699348e-06,
      "loss": 0.1499,
      "step": 6023
    },
    {
      "epoch": 1.3841911764705883,
      "grad_norm": 1.6830123662948608,
      "learning_rate": 8.036151960784314e-06,
      "loss": 0.1127,
      "step": 6024
    },
    {
      "epoch": 1.3844209558823528,
      "grad_norm": 1.591418743133545,
      "learning_rate": 8.035641339869282e-06,
      "loss": 0.1277,
      "step": 6025
    },
    {
      "epoch": 1.3846507352941178,
      "grad_norm": 1.5942920446395874,
      "learning_rate": 8.03513071895425e-06,
      "loss": 0.149,
      "step": 6026
    },
    {
      "epoch": 1.3848805147058822,
      "grad_norm": 1.7125186920166016,
      "learning_rate": 8.034620098039216e-06,
      "loss": 0.1404,
      "step": 6027
    },
    {
      "epoch": 1.3851102941176472,
      "grad_norm": 1.7379473447799683,
      "learning_rate": 8.034109477124184e-06,
      "loss": 0.1359,
      "step": 6028
    },
    {
      "epoch": 1.3853400735294117,
      "grad_norm": 1.876572847366333,
      "learning_rate": 8.03359885620915e-06,
      "loss": 0.1486,
      "step": 6029
    },
    {
      "epoch": 1.3855698529411764,
      "grad_norm": 2.0141520500183105,
      "learning_rate": 8.033088235294118e-06,
      "loss": 0.1023,
      "step": 6030
    },
    {
      "epoch": 1.3857996323529411,
      "grad_norm": 1.5546939373016357,
      "learning_rate": 8.032577614379086e-06,
      "loss": 0.1065,
      "step": 6031
    },
    {
      "epoch": 1.3860294117647058,
      "grad_norm": 1.8810374736785889,
      "learning_rate": 8.032066993464054e-06,
      "loss": 0.1181,
      "step": 6032
    },
    {
      "epoch": 1.3862591911764706,
      "grad_norm": 1.650622844696045,
      "learning_rate": 8.03155637254902e-06,
      "loss": 0.1062,
      "step": 6033
    },
    {
      "epoch": 1.3864889705882353,
      "grad_norm": 1.7975355386734009,
      "learning_rate": 8.031045751633988e-06,
      "loss": 0.1138,
      "step": 6034
    },
    {
      "epoch": 1.38671875,
      "grad_norm": 1.7247487306594849,
      "learning_rate": 8.030535130718955e-06,
      "loss": 0.1788,
      "step": 6035
    },
    {
      "epoch": 1.3869485294117647,
      "grad_norm": 1.7430943250656128,
      "learning_rate": 8.030024509803922e-06,
      "loss": 0.1331,
      "step": 6036
    },
    {
      "epoch": 1.3871783088235294,
      "grad_norm": 1.9935972690582275,
      "learning_rate": 8.02951388888889e-06,
      "loss": 0.1416,
      "step": 6037
    },
    {
      "epoch": 1.3874080882352942,
      "grad_norm": 1.5787382125854492,
      "learning_rate": 8.029003267973857e-06,
      "loss": 0.177,
      "step": 6038
    },
    {
      "epoch": 1.3876378676470589,
      "grad_norm": 1.420900583267212,
      "learning_rate": 8.028492647058823e-06,
      "loss": 0.0935,
      "step": 6039
    },
    {
      "epoch": 1.3878676470588236,
      "grad_norm": 1.4360722303390503,
      "learning_rate": 8.027982026143791e-06,
      "loss": 0.1309,
      "step": 6040
    },
    {
      "epoch": 1.3880974264705883,
      "grad_norm": 1.5122203826904297,
      "learning_rate": 8.02747140522876e-06,
      "loss": 0.1185,
      "step": 6041
    },
    {
      "epoch": 1.3883272058823528,
      "grad_norm": 1.6928026676177979,
      "learning_rate": 8.026960784313727e-06,
      "loss": 0.1267,
      "step": 6042
    },
    {
      "epoch": 1.3885569852941178,
      "grad_norm": 1.5908337831497192,
      "learning_rate": 8.026450163398693e-06,
      "loss": 0.1188,
      "step": 6043
    },
    {
      "epoch": 1.3887867647058822,
      "grad_norm": 1.443624496459961,
      "learning_rate": 8.025939542483661e-06,
      "loss": 0.0858,
      "step": 6044
    },
    {
      "epoch": 1.3890165441176472,
      "grad_norm": 2.3333029747009277,
      "learning_rate": 8.025428921568627e-06,
      "loss": 0.148,
      "step": 6045
    },
    {
      "epoch": 1.3892463235294117,
      "grad_norm": 1.7862755060195923,
      "learning_rate": 8.024918300653595e-06,
      "loss": 0.1439,
      "step": 6046
    },
    {
      "epoch": 1.3894761029411764,
      "grad_norm": 1.4417139291763306,
      "learning_rate": 8.024407679738563e-06,
      "loss": 0.138,
      "step": 6047
    },
    {
      "epoch": 1.3897058823529411,
      "grad_norm": 1.7556989192962646,
      "learning_rate": 8.023897058823529e-06,
      "loss": 0.1433,
      "step": 6048
    },
    {
      "epoch": 1.3899356617647058,
      "grad_norm": 1.8441084623336792,
      "learning_rate": 8.023386437908497e-06,
      "loss": 0.1431,
      "step": 6049
    },
    {
      "epoch": 1.3901654411764706,
      "grad_norm": 1.9079642295837402,
      "learning_rate": 8.022875816993465e-06,
      "loss": 0.1026,
      "step": 6050
    },
    {
      "epoch": 1.3903952205882353,
      "grad_norm": 1.8728392124176025,
      "learning_rate": 8.022365196078433e-06,
      "loss": 0.1143,
      "step": 6051
    },
    {
      "epoch": 1.390625,
      "grad_norm": 1.582851529121399,
      "learning_rate": 8.021854575163399e-06,
      "loss": 0.1001,
      "step": 6052
    },
    {
      "epoch": 1.3908547794117647,
      "grad_norm": 2.0892293453216553,
      "learning_rate": 8.021343954248367e-06,
      "loss": 0.1315,
      "step": 6053
    },
    {
      "epoch": 1.3910845588235294,
      "grad_norm": 1.0833061933517456,
      "learning_rate": 8.020833333333335e-06,
      "loss": 0.1071,
      "step": 6054
    },
    {
      "epoch": 1.3913143382352942,
      "grad_norm": 2.092350721359253,
      "learning_rate": 8.0203227124183e-06,
      "loss": 0.1047,
      "step": 6055
    },
    {
      "epoch": 1.3915441176470589,
      "grad_norm": 1.872923493385315,
      "learning_rate": 8.019812091503269e-06,
      "loss": 0.1169,
      "step": 6056
    },
    {
      "epoch": 1.3917738970588236,
      "grad_norm": 1.6363604068756104,
      "learning_rate": 8.019301470588235e-06,
      "loss": 0.1072,
      "step": 6057
    },
    {
      "epoch": 1.3920036764705883,
      "grad_norm": 1.8748780488967896,
      "learning_rate": 8.018790849673204e-06,
      "loss": 0.1125,
      "step": 6058
    },
    {
      "epoch": 1.3922334558823528,
      "grad_norm": 1.5498262643814087,
      "learning_rate": 8.01828022875817e-06,
      "loss": 0.0994,
      "step": 6059
    },
    {
      "epoch": 1.3924632352941178,
      "grad_norm": 1.371656894683838,
      "learning_rate": 8.017769607843138e-06,
      "loss": 0.1183,
      "step": 6060
    },
    {
      "epoch": 1.3926930147058822,
      "grad_norm": 1.527232050895691,
      "learning_rate": 8.017258986928105e-06,
      "loss": 0.1416,
      "step": 6061
    },
    {
      "epoch": 1.3929227941176472,
      "grad_norm": 1.88339102268219,
      "learning_rate": 8.016748366013072e-06,
      "loss": 0.1446,
      "step": 6062
    },
    {
      "epoch": 1.3931525735294117,
      "grad_norm": 1.5846490859985352,
      "learning_rate": 8.01623774509804e-06,
      "loss": 0.1208,
      "step": 6063
    },
    {
      "epoch": 1.3933823529411764,
      "grad_norm": 1.7081736326217651,
      "learning_rate": 8.015727124183006e-06,
      "loss": 0.1332,
      "step": 6064
    },
    {
      "epoch": 1.3936121323529411,
      "grad_norm": 1.6913217306137085,
      "learning_rate": 8.015216503267974e-06,
      "loss": 0.1155,
      "step": 6065
    },
    {
      "epoch": 1.3938419117647058,
      "grad_norm": 1.872023344039917,
      "learning_rate": 8.014705882352942e-06,
      "loss": 0.1485,
      "step": 6066
    },
    {
      "epoch": 1.3940716911764706,
      "grad_norm": 1.8862695693969727,
      "learning_rate": 8.01419526143791e-06,
      "loss": 0.1307,
      "step": 6067
    },
    {
      "epoch": 1.3943014705882353,
      "grad_norm": 2.49931263923645,
      "learning_rate": 8.013684640522876e-06,
      "loss": 0.1648,
      "step": 6068
    },
    {
      "epoch": 1.39453125,
      "grad_norm": 1.9011235237121582,
      "learning_rate": 8.013174019607844e-06,
      "loss": 0.1663,
      "step": 6069
    },
    {
      "epoch": 1.3947610294117647,
      "grad_norm": 1.7592785358428955,
      "learning_rate": 8.012663398692812e-06,
      "loss": 0.1009,
      "step": 6070
    },
    {
      "epoch": 1.3949908088235294,
      "grad_norm": 1.7014427185058594,
      "learning_rate": 8.012152777777778e-06,
      "loss": 0.0911,
      "step": 6071
    },
    {
      "epoch": 1.3952205882352942,
      "grad_norm": 1.3955227136611938,
      "learning_rate": 8.011642156862746e-06,
      "loss": 0.1069,
      "step": 6072
    },
    {
      "epoch": 1.3954503676470589,
      "grad_norm": 1.925098180770874,
      "learning_rate": 8.011131535947712e-06,
      "loss": 0.1638,
      "step": 6073
    },
    {
      "epoch": 1.3956801470588236,
      "grad_norm": 1.663922667503357,
      "learning_rate": 8.01062091503268e-06,
      "loss": 0.1227,
      "step": 6074
    },
    {
      "epoch": 1.3959099264705883,
      "grad_norm": 1.82172429561615,
      "learning_rate": 8.010110294117648e-06,
      "loss": 0.1074,
      "step": 6075
    },
    {
      "epoch": 1.3961397058823528,
      "grad_norm": 1.5414069890975952,
      "learning_rate": 8.009599673202616e-06,
      "loss": 0.1062,
      "step": 6076
    },
    {
      "epoch": 1.3963694852941178,
      "grad_norm": 1.3177918195724487,
      "learning_rate": 8.009089052287582e-06,
      "loss": 0.1383,
      "step": 6077
    },
    {
      "epoch": 1.3965992647058822,
      "grad_norm": 2.0245847702026367,
      "learning_rate": 8.00857843137255e-06,
      "loss": 0.1437,
      "step": 6078
    },
    {
      "epoch": 1.3968290441176472,
      "grad_norm": 1.4932714700698853,
      "learning_rate": 8.008067810457518e-06,
      "loss": 0.1216,
      "step": 6079
    },
    {
      "epoch": 1.3970588235294117,
      "grad_norm": 1.3870540857315063,
      "learning_rate": 8.007557189542484e-06,
      "loss": 0.0815,
      "step": 6080
    },
    {
      "epoch": 1.3972886029411764,
      "grad_norm": 1.7617334127426147,
      "learning_rate": 8.007046568627452e-06,
      "loss": 0.1284,
      "step": 6081
    },
    {
      "epoch": 1.3975183823529411,
      "grad_norm": 1.2940638065338135,
      "learning_rate": 8.00653594771242e-06,
      "loss": 0.1037,
      "step": 6082
    },
    {
      "epoch": 1.3977481617647058,
      "grad_norm": 1.5310403108596802,
      "learning_rate": 8.006025326797386e-06,
      "loss": 0.1137,
      "step": 6083
    },
    {
      "epoch": 1.3979779411764706,
      "grad_norm": 1.3227633237838745,
      "learning_rate": 8.005514705882354e-06,
      "loss": 0.1153,
      "step": 6084
    },
    {
      "epoch": 1.3982077205882353,
      "grad_norm": 2.70611834526062,
      "learning_rate": 8.00500408496732e-06,
      "loss": 0.2241,
      "step": 6085
    },
    {
      "epoch": 1.3984375,
      "grad_norm": 1.6021384000778198,
      "learning_rate": 8.00449346405229e-06,
      "loss": 0.1192,
      "step": 6086
    },
    {
      "epoch": 1.3986672794117647,
      "grad_norm": 1.986019492149353,
      "learning_rate": 8.003982843137255e-06,
      "loss": 0.1424,
      "step": 6087
    },
    {
      "epoch": 1.3988970588235294,
      "grad_norm": 1.9899016618728638,
      "learning_rate": 8.003472222222223e-06,
      "loss": 0.1312,
      "step": 6088
    },
    {
      "epoch": 1.3991268382352942,
      "grad_norm": 1.410947561264038,
      "learning_rate": 8.00296160130719e-06,
      "loss": 0.1335,
      "step": 6089
    },
    {
      "epoch": 1.3993566176470589,
      "grad_norm": 1.7496485710144043,
      "learning_rate": 8.002450980392157e-06,
      "loss": 0.1306,
      "step": 6090
    },
    {
      "epoch": 1.3995863970588236,
      "grad_norm": 1.990862488746643,
      "learning_rate": 8.001940359477125e-06,
      "loss": 0.1337,
      "step": 6091
    },
    {
      "epoch": 1.3998161764705883,
      "grad_norm": 1.4903147220611572,
      "learning_rate": 8.001429738562091e-06,
      "loss": 0.1308,
      "step": 6092
    },
    {
      "epoch": 1.4000459558823528,
      "grad_norm": 1.7947773933410645,
      "learning_rate": 8.00091911764706e-06,
      "loss": 0.1105,
      "step": 6093
    },
    {
      "epoch": 1.4002757352941178,
      "grad_norm": 1.8265055418014526,
      "learning_rate": 8.000408496732027e-06,
      "loss": 0.1184,
      "step": 6094
    },
    {
      "epoch": 1.4005055147058822,
      "grad_norm": 1.8640398979187012,
      "learning_rate": 7.999897875816995e-06,
      "loss": 0.1222,
      "step": 6095
    },
    {
      "epoch": 1.4007352941176472,
      "grad_norm": 2.3235018253326416,
      "learning_rate": 7.999387254901961e-06,
      "loss": 0.1586,
      "step": 6096
    },
    {
      "epoch": 1.4009650735294117,
      "grad_norm": 1.8609817028045654,
      "learning_rate": 7.998876633986929e-06,
      "loss": 0.1391,
      "step": 6097
    },
    {
      "epoch": 1.4011948529411764,
      "grad_norm": 1.287904977798462,
      "learning_rate": 7.998366013071897e-06,
      "loss": 0.0958,
      "step": 6098
    },
    {
      "epoch": 1.4014246323529411,
      "grad_norm": 1.610174536705017,
      "learning_rate": 7.997855392156863e-06,
      "loss": 0.1083,
      "step": 6099
    },
    {
      "epoch": 1.4016544117647058,
      "grad_norm": 1.8311926126480103,
      "learning_rate": 7.99734477124183e-06,
      "loss": 0.1723,
      "step": 6100
    },
    {
      "epoch": 1.4018841911764706,
      "grad_norm": 1.9395604133605957,
      "learning_rate": 7.996834150326797e-06,
      "loss": 0.1633,
      "step": 6101
    },
    {
      "epoch": 1.4021139705882353,
      "grad_norm": 1.6516920328140259,
      "learning_rate": 7.996323529411767e-06,
      "loss": 0.129,
      "step": 6102
    },
    {
      "epoch": 1.40234375,
      "grad_norm": 1.6630609035491943,
      "learning_rate": 7.995812908496733e-06,
      "loss": 0.1232,
      "step": 6103
    },
    {
      "epoch": 1.4025735294117647,
      "grad_norm": 1.5234096050262451,
      "learning_rate": 7.9953022875817e-06,
      "loss": 0.0808,
      "step": 6104
    },
    {
      "epoch": 1.4028033088235294,
      "grad_norm": 1.7386150360107422,
      "learning_rate": 7.994791666666667e-06,
      "loss": 0.1072,
      "step": 6105
    },
    {
      "epoch": 1.4030330882352942,
      "grad_norm": 2.0500383377075195,
      "learning_rate": 7.994281045751635e-06,
      "loss": 0.1291,
      "step": 6106
    },
    {
      "epoch": 1.4032628676470589,
      "grad_norm": 1.6629254817962646,
      "learning_rate": 7.993770424836602e-06,
      "loss": 0.1391,
      "step": 6107
    },
    {
      "epoch": 1.4034926470588236,
      "grad_norm": 2.353116750717163,
      "learning_rate": 7.993259803921569e-06,
      "loss": 0.1338,
      "step": 6108
    },
    {
      "epoch": 1.4037224264705883,
      "grad_norm": 1.8828051090240479,
      "learning_rate": 7.992749183006536e-06,
      "loss": 0.1808,
      "step": 6109
    },
    {
      "epoch": 1.4039522058823528,
      "grad_norm": 1.8341971635818481,
      "learning_rate": 7.992238562091504e-06,
      "loss": 0.1414,
      "step": 6110
    },
    {
      "epoch": 1.4041819852941178,
      "grad_norm": 2.0585408210754395,
      "learning_rate": 7.991727941176472e-06,
      "loss": 0.1267,
      "step": 6111
    },
    {
      "epoch": 1.4044117647058822,
      "grad_norm": 2.5148658752441406,
      "learning_rate": 7.991217320261438e-06,
      "loss": 0.15,
      "step": 6112
    },
    {
      "epoch": 1.4046415441176472,
      "grad_norm": 2.002934694290161,
      "learning_rate": 7.990706699346406e-06,
      "loss": 0.1401,
      "step": 6113
    },
    {
      "epoch": 1.4048713235294117,
      "grad_norm": 1.3376977443695068,
      "learning_rate": 7.990196078431374e-06,
      "loss": 0.1052,
      "step": 6114
    },
    {
      "epoch": 1.4051011029411764,
      "grad_norm": 1.4340074062347412,
      "learning_rate": 7.98968545751634e-06,
      "loss": 0.0943,
      "step": 6115
    },
    {
      "epoch": 1.4053308823529411,
      "grad_norm": 2.2936718463897705,
      "learning_rate": 7.989174836601308e-06,
      "loss": 0.1631,
      "step": 6116
    },
    {
      "epoch": 1.4055606617647058,
      "grad_norm": 2.2815604209899902,
      "learning_rate": 7.988664215686274e-06,
      "loss": 0.1967,
      "step": 6117
    },
    {
      "epoch": 1.4057904411764706,
      "grad_norm": 1.531800627708435,
      "learning_rate": 7.988153594771242e-06,
      "loss": 0.102,
      "step": 6118
    },
    {
      "epoch": 1.4060202205882353,
      "grad_norm": 2.233811378479004,
      "learning_rate": 7.98764297385621e-06,
      "loss": 0.1636,
      "step": 6119
    },
    {
      "epoch": 1.40625,
      "grad_norm": 1.7596880197525024,
      "learning_rate": 7.987132352941178e-06,
      "loss": 0.1219,
      "step": 6120
    },
    {
      "epoch": 1.4064797794117647,
      "grad_norm": 1.800609827041626,
      "learning_rate": 7.986621732026144e-06,
      "loss": 0.1486,
      "step": 6121
    },
    {
      "epoch": 1.4067095588235294,
      "grad_norm": 1.5151338577270508,
      "learning_rate": 7.986111111111112e-06,
      "loss": 0.1208,
      "step": 6122
    },
    {
      "epoch": 1.4069393382352942,
      "grad_norm": 1.4846426248550415,
      "learning_rate": 7.98560049019608e-06,
      "loss": 0.1143,
      "step": 6123
    },
    {
      "epoch": 1.4071691176470589,
      "grad_norm": 1.9520725011825562,
      "learning_rate": 7.985089869281046e-06,
      "loss": 0.1378,
      "step": 6124
    },
    {
      "epoch": 1.4073988970588236,
      "grad_norm": 1.562687635421753,
      "learning_rate": 7.984579248366014e-06,
      "loss": 0.1134,
      "step": 6125
    },
    {
      "epoch": 1.4076286764705883,
      "grad_norm": 1.8077484369277954,
      "learning_rate": 7.984068627450982e-06,
      "loss": 0.0905,
      "step": 6126
    },
    {
      "epoch": 1.4078584558823528,
      "grad_norm": 1.7006056308746338,
      "learning_rate": 7.983558006535948e-06,
      "loss": 0.1476,
      "step": 6127
    },
    {
      "epoch": 1.4080882352941178,
      "grad_norm": 1.5883721113204956,
      "learning_rate": 7.983047385620916e-06,
      "loss": 0.1224,
      "step": 6128
    },
    {
      "epoch": 1.4083180147058822,
      "grad_norm": 2.1521384716033936,
      "learning_rate": 7.982536764705882e-06,
      "loss": 0.1113,
      "step": 6129
    },
    {
      "epoch": 1.4085477941176472,
      "grad_norm": 1.6983083486557007,
      "learning_rate": 7.982026143790851e-06,
      "loss": 0.1363,
      "step": 6130
    },
    {
      "epoch": 1.4087775735294117,
      "grad_norm": 2.1179277896881104,
      "learning_rate": 7.981515522875818e-06,
      "loss": 0.1894,
      "step": 6131
    },
    {
      "epoch": 1.4090073529411764,
      "grad_norm": 1.5616459846496582,
      "learning_rate": 7.981004901960785e-06,
      "loss": 0.1509,
      "step": 6132
    },
    {
      "epoch": 1.4092371323529411,
      "grad_norm": 1.769281268119812,
      "learning_rate": 7.980494281045752e-06,
      "loss": 0.0982,
      "step": 6133
    },
    {
      "epoch": 1.4094669117647058,
      "grad_norm": 1.9263194799423218,
      "learning_rate": 7.97998366013072e-06,
      "loss": 0.1436,
      "step": 6134
    },
    {
      "epoch": 1.4096966911764706,
      "grad_norm": 1.554862141609192,
      "learning_rate": 7.979473039215687e-06,
      "loss": 0.0984,
      "step": 6135
    },
    {
      "epoch": 1.4099264705882353,
      "grad_norm": 1.1541626453399658,
      "learning_rate": 7.978962418300654e-06,
      "loss": 0.0929,
      "step": 6136
    },
    {
      "epoch": 1.41015625,
      "grad_norm": 1.4872032403945923,
      "learning_rate": 7.978451797385621e-06,
      "loss": 0.1174,
      "step": 6137
    },
    {
      "epoch": 1.4103860294117647,
      "grad_norm": 1.687890887260437,
      "learning_rate": 7.97794117647059e-06,
      "loss": 0.1212,
      "step": 6138
    },
    {
      "epoch": 1.4106158088235294,
      "grad_norm": 1.9558393955230713,
      "learning_rate": 7.977430555555557e-06,
      "loss": 0.147,
      "step": 6139
    },
    {
      "epoch": 1.4108455882352942,
      "grad_norm": 1.3992141485214233,
      "learning_rate": 7.976919934640523e-06,
      "loss": 0.1068,
      "step": 6140
    },
    {
      "epoch": 1.4110753676470589,
      "grad_norm": 1.9445909261703491,
      "learning_rate": 7.976409313725491e-06,
      "loss": 0.1206,
      "step": 6141
    },
    {
      "epoch": 1.4113051470588236,
      "grad_norm": 1.2776333093643188,
      "learning_rate": 7.975898692810459e-06,
      "loss": 0.1192,
      "step": 6142
    },
    {
      "epoch": 1.4115349264705883,
      "grad_norm": 1.6417850255966187,
      "learning_rate": 7.975388071895425e-06,
      "loss": 0.1227,
      "step": 6143
    },
    {
      "epoch": 1.4117647058823528,
      "grad_norm": 1.5204509496688843,
      "learning_rate": 7.974877450980393e-06,
      "loss": 0.1177,
      "step": 6144
    },
    {
      "epoch": 1.4119944852941178,
      "grad_norm": 2.043121814727783,
      "learning_rate": 7.97436683006536e-06,
      "loss": 0.1222,
      "step": 6145
    },
    {
      "epoch": 1.4122242647058822,
      "grad_norm": 1.4604530334472656,
      "learning_rate": 7.973856209150329e-06,
      "loss": 0.1032,
      "step": 6146
    },
    {
      "epoch": 1.4124540441176472,
      "grad_norm": 1.8756089210510254,
      "learning_rate": 7.973345588235295e-06,
      "loss": 0.1571,
      "step": 6147
    },
    {
      "epoch": 1.4126838235294117,
      "grad_norm": 1.4465641975402832,
      "learning_rate": 7.972834967320263e-06,
      "loss": 0.1127,
      "step": 6148
    },
    {
      "epoch": 1.4129136029411764,
      "grad_norm": 1.9588137865066528,
      "learning_rate": 7.972324346405229e-06,
      "loss": 0.1167,
      "step": 6149
    },
    {
      "epoch": 1.4131433823529411,
      "grad_norm": 1.7195706367492676,
      "learning_rate": 7.971813725490197e-06,
      "loss": 0.1625,
      "step": 6150
    },
    {
      "epoch": 1.4133731617647058,
      "grad_norm": 2.188887596130371,
      "learning_rate": 7.971303104575165e-06,
      "loss": 0.1534,
      "step": 6151
    },
    {
      "epoch": 1.4136029411764706,
      "grad_norm": 1.82151198387146,
      "learning_rate": 7.97079248366013e-06,
      "loss": 0.1154,
      "step": 6152
    },
    {
      "epoch": 1.4138327205882353,
      "grad_norm": 1.4334502220153809,
      "learning_rate": 7.970281862745099e-06,
      "loss": 0.111,
      "step": 6153
    },
    {
      "epoch": 1.4140625,
      "grad_norm": 1.6795644760131836,
      "learning_rate": 7.969771241830067e-06,
      "loss": 0.1496,
      "step": 6154
    },
    {
      "epoch": 1.4142922794117647,
      "grad_norm": 1.8103150129318237,
      "learning_rate": 7.969260620915034e-06,
      "loss": 0.1202,
      "step": 6155
    },
    {
      "epoch": 1.4145220588235294,
      "grad_norm": 1.5130549669265747,
      "learning_rate": 7.96875e-06,
      "loss": 0.119,
      "step": 6156
    },
    {
      "epoch": 1.4147518382352942,
      "grad_norm": 1.7515816688537598,
      "learning_rate": 7.968239379084968e-06,
      "loss": 0.1728,
      "step": 6157
    },
    {
      "epoch": 1.4149816176470589,
      "grad_norm": 1.7533378601074219,
      "learning_rate": 7.967728758169935e-06,
      "loss": 0.1536,
      "step": 6158
    },
    {
      "epoch": 1.4152113970588236,
      "grad_norm": 1.9582722187042236,
      "learning_rate": 7.967218137254902e-06,
      "loss": 0.1224,
      "step": 6159
    },
    {
      "epoch": 1.4154411764705883,
      "grad_norm": 2.066875696182251,
      "learning_rate": 7.96670751633987e-06,
      "loss": 0.1276,
      "step": 6160
    },
    {
      "epoch": 1.4156709558823528,
      "grad_norm": 1.5844930410385132,
      "learning_rate": 7.966196895424836e-06,
      "loss": 0.1445,
      "step": 6161
    },
    {
      "epoch": 1.4159007352941178,
      "grad_norm": 2.007780075073242,
      "learning_rate": 7.965686274509804e-06,
      "loss": 0.1206,
      "step": 6162
    },
    {
      "epoch": 1.4161305147058822,
      "grad_norm": 1.8865017890930176,
      "learning_rate": 7.965175653594772e-06,
      "loss": 0.1466,
      "step": 6163
    },
    {
      "epoch": 1.4163602941176472,
      "grad_norm": 2.1198835372924805,
      "learning_rate": 7.964665032679738e-06,
      "loss": 0.1731,
      "step": 6164
    },
    {
      "epoch": 1.4165900735294117,
      "grad_norm": 1.3174241781234741,
      "learning_rate": 7.964154411764706e-06,
      "loss": 0.1086,
      "step": 6165
    },
    {
      "epoch": 1.4168198529411764,
      "grad_norm": 1.5118863582611084,
      "learning_rate": 7.963643790849674e-06,
      "loss": 0.1125,
      "step": 6166
    },
    {
      "epoch": 1.4170496323529411,
      "grad_norm": 1.904066562652588,
      "learning_rate": 7.963133169934642e-06,
      "loss": 0.1047,
      "step": 6167
    },
    {
      "epoch": 1.4172794117647058,
      "grad_norm": 1.8089957237243652,
      "learning_rate": 7.962622549019608e-06,
      "loss": 0.144,
      "step": 6168
    },
    {
      "epoch": 1.4175091911764706,
      "grad_norm": 1.4207425117492676,
      "learning_rate": 7.962111928104576e-06,
      "loss": 0.0994,
      "step": 6169
    },
    {
      "epoch": 1.4177389705882353,
      "grad_norm": 1.6352472305297852,
      "learning_rate": 7.961601307189542e-06,
      "loss": 0.0988,
      "step": 6170
    },
    {
      "epoch": 1.41796875,
      "grad_norm": 1.7701650857925415,
      "learning_rate": 7.96109068627451e-06,
      "loss": 0.1726,
      "step": 6171
    },
    {
      "epoch": 1.4181985294117647,
      "grad_norm": 1.704673171043396,
      "learning_rate": 7.960580065359478e-06,
      "loss": 0.115,
      "step": 6172
    },
    {
      "epoch": 1.4184283088235294,
      "grad_norm": 1.4760743379592896,
      "learning_rate": 7.960069444444444e-06,
      "loss": 0.1422,
      "step": 6173
    },
    {
      "epoch": 1.4186580882352942,
      "grad_norm": 1.7111674547195435,
      "learning_rate": 7.959558823529412e-06,
      "loss": 0.1129,
      "step": 6174
    },
    {
      "epoch": 1.4188878676470589,
      "grad_norm": 1.368503451347351,
      "learning_rate": 7.95904820261438e-06,
      "loss": 0.1287,
      "step": 6175
    },
    {
      "epoch": 1.4191176470588236,
      "grad_norm": 1.7566819190979004,
      "learning_rate": 7.958537581699348e-06,
      "loss": 0.1146,
      "step": 6176
    },
    {
      "epoch": 1.4193474264705883,
      "grad_norm": 2.1744072437286377,
      "learning_rate": 7.958026960784314e-06,
      "loss": 0.1711,
      "step": 6177
    },
    {
      "epoch": 1.4195772058823528,
      "grad_norm": 1.5272122621536255,
      "learning_rate": 7.957516339869282e-06,
      "loss": 0.1232,
      "step": 6178
    },
    {
      "epoch": 1.4198069852941178,
      "grad_norm": 1.5801466703414917,
      "learning_rate": 7.95700571895425e-06,
      "loss": 0.123,
      "step": 6179
    },
    {
      "epoch": 1.4200367647058822,
      "grad_norm": 1.3839417695999146,
      "learning_rate": 7.956495098039216e-06,
      "loss": 0.0829,
      "step": 6180
    },
    {
      "epoch": 1.4202665441176472,
      "grad_norm": 1.7693525552749634,
      "learning_rate": 7.955984477124184e-06,
      "loss": 0.1367,
      "step": 6181
    },
    {
      "epoch": 1.4204963235294117,
      "grad_norm": 1.8396075963974,
      "learning_rate": 7.95547385620915e-06,
      "loss": 0.1578,
      "step": 6182
    },
    {
      "epoch": 1.4207261029411764,
      "grad_norm": 1.4172250032424927,
      "learning_rate": 7.95496323529412e-06,
      "loss": 0.0806,
      "step": 6183
    },
    {
      "epoch": 1.4209558823529411,
      "grad_norm": 1.8995383977890015,
      "learning_rate": 7.954452614379085e-06,
      "loss": 0.1315,
      "step": 6184
    },
    {
      "epoch": 1.4211856617647058,
      "grad_norm": 1.5869873762130737,
      "learning_rate": 7.953941993464053e-06,
      "loss": 0.1226,
      "step": 6185
    },
    {
      "epoch": 1.4214154411764706,
      "grad_norm": 1.6493197679519653,
      "learning_rate": 7.95343137254902e-06,
      "loss": 0.1072,
      "step": 6186
    },
    {
      "epoch": 1.4216452205882353,
      "grad_norm": 2.001136064529419,
      "learning_rate": 7.952920751633987e-06,
      "loss": 0.165,
      "step": 6187
    },
    {
      "epoch": 1.421875,
      "grad_norm": 1.5573816299438477,
      "learning_rate": 7.952410130718955e-06,
      "loss": 0.1153,
      "step": 6188
    },
    {
      "epoch": 1.4221047794117647,
      "grad_norm": 1.6780411005020142,
      "learning_rate": 7.951899509803921e-06,
      "loss": 0.1858,
      "step": 6189
    },
    {
      "epoch": 1.4223345588235294,
      "grad_norm": 1.6186909675598145,
      "learning_rate": 7.95138888888889e-06,
      "loss": 0.1367,
      "step": 6190
    },
    {
      "epoch": 1.4225643382352942,
      "grad_norm": 1.8270152807235718,
      "learning_rate": 7.950878267973857e-06,
      "loss": 0.1817,
      "step": 6191
    },
    {
      "epoch": 1.4227941176470589,
      "grad_norm": 1.6854619979858398,
      "learning_rate": 7.950367647058825e-06,
      "loss": 0.121,
      "step": 6192
    },
    {
      "epoch": 1.4230238970588236,
      "grad_norm": 1.3657362461090088,
      "learning_rate": 7.949857026143791e-06,
      "loss": 0.0821,
      "step": 6193
    },
    {
      "epoch": 1.4232536764705883,
      "grad_norm": 1.8665835857391357,
      "learning_rate": 7.949346405228759e-06,
      "loss": 0.1187,
      "step": 6194
    },
    {
      "epoch": 1.4234834558823528,
      "grad_norm": 1.6276410818099976,
      "learning_rate": 7.948835784313727e-06,
      "loss": 0.1084,
      "step": 6195
    },
    {
      "epoch": 1.4237132352941178,
      "grad_norm": 1.4727160930633545,
      "learning_rate": 7.948325163398693e-06,
      "loss": 0.1375,
      "step": 6196
    },
    {
      "epoch": 1.4239430147058822,
      "grad_norm": 1.875993251800537,
      "learning_rate": 7.947814542483661e-06,
      "loss": 0.1075,
      "step": 6197
    },
    {
      "epoch": 1.4241727941176472,
      "grad_norm": 1.8690301179885864,
      "learning_rate": 7.947303921568627e-06,
      "loss": 0.1541,
      "step": 6198
    },
    {
      "epoch": 1.4244025735294117,
      "grad_norm": 1.6372019052505493,
      "learning_rate": 7.946793300653597e-06,
      "loss": 0.085,
      "step": 6199
    },
    {
      "epoch": 1.4246323529411764,
      "grad_norm": 1.8365204334259033,
      "learning_rate": 7.946282679738563e-06,
      "loss": 0.1117,
      "step": 6200
    },
    {
      "epoch": 1.4248621323529411,
      "grad_norm": 1.8382184505462646,
      "learning_rate": 7.94577205882353e-06,
      "loss": 0.1544,
      "step": 6201
    },
    {
      "epoch": 1.4250919117647058,
      "grad_norm": 1.3522394895553589,
      "learning_rate": 7.945261437908497e-06,
      "loss": 0.122,
      "step": 6202
    },
    {
      "epoch": 1.4253216911764706,
      "grad_norm": 1.779594898223877,
      "learning_rate": 7.944750816993465e-06,
      "loss": 0.1193,
      "step": 6203
    },
    {
      "epoch": 1.4255514705882353,
      "grad_norm": 1.9473868608474731,
      "learning_rate": 7.944240196078433e-06,
      "loss": 0.1171,
      "step": 6204
    },
    {
      "epoch": 1.42578125,
      "grad_norm": 1.584485650062561,
      "learning_rate": 7.943729575163399e-06,
      "loss": 0.1337,
      "step": 6205
    },
    {
      "epoch": 1.4260110294117647,
      "grad_norm": 1.7745954990386963,
      "learning_rate": 7.943218954248367e-06,
      "loss": 0.1234,
      "step": 6206
    },
    {
      "epoch": 1.4262408088235294,
      "grad_norm": 1.7132867574691772,
      "learning_rate": 7.942708333333334e-06,
      "loss": 0.1078,
      "step": 6207
    },
    {
      "epoch": 1.4264705882352942,
      "grad_norm": 1.3608832359313965,
      "learning_rate": 7.9421977124183e-06,
      "loss": 0.1102,
      "step": 6208
    },
    {
      "epoch": 1.4267003676470589,
      "grad_norm": 1.563011646270752,
      "learning_rate": 7.941687091503268e-06,
      "loss": 0.123,
      "step": 6209
    },
    {
      "epoch": 1.4269301470588236,
      "grad_norm": 1.9183053970336914,
      "learning_rate": 7.941176470588236e-06,
      "loss": 0.1306,
      "step": 6210
    },
    {
      "epoch": 1.4271599264705883,
      "grad_norm": 1.7485013008117676,
      "learning_rate": 7.940665849673204e-06,
      "loss": 0.1397,
      "step": 6211
    },
    {
      "epoch": 1.4273897058823528,
      "grad_norm": 1.551530361175537,
      "learning_rate": 7.94015522875817e-06,
      "loss": 0.113,
      "step": 6212
    },
    {
      "epoch": 1.4276194852941178,
      "grad_norm": 1.501356840133667,
      "learning_rate": 7.939644607843138e-06,
      "loss": 0.0862,
      "step": 6213
    },
    {
      "epoch": 1.4278492647058822,
      "grad_norm": 2.0062873363494873,
      "learning_rate": 7.939133986928104e-06,
      "loss": 0.1144,
      "step": 6214
    },
    {
      "epoch": 1.4280790441176472,
      "grad_norm": 2.0110344886779785,
      "learning_rate": 7.938623366013072e-06,
      "loss": 0.151,
      "step": 6215
    },
    {
      "epoch": 1.4283088235294117,
      "grad_norm": 1.62172532081604,
      "learning_rate": 7.93811274509804e-06,
      "loss": 0.1153,
      "step": 6216
    },
    {
      "epoch": 1.4285386029411764,
      "grad_norm": 1.7854191064834595,
      "learning_rate": 7.937602124183006e-06,
      "loss": 0.1365,
      "step": 6217
    },
    {
      "epoch": 1.4287683823529411,
      "grad_norm": 1.8627748489379883,
      "learning_rate": 7.937091503267974e-06,
      "loss": 0.1576,
      "step": 6218
    },
    {
      "epoch": 1.4289981617647058,
      "grad_norm": 2.141406297683716,
      "learning_rate": 7.936580882352942e-06,
      "loss": 0.1371,
      "step": 6219
    },
    {
      "epoch": 1.4292279411764706,
      "grad_norm": 1.619122862815857,
      "learning_rate": 7.93607026143791e-06,
      "loss": 0.1223,
      "step": 6220
    },
    {
      "epoch": 1.4294577205882353,
      "grad_norm": 1.7052890062332153,
      "learning_rate": 7.935559640522876e-06,
      "loss": 0.1199,
      "step": 6221
    },
    {
      "epoch": 1.4296875,
      "grad_norm": 1.4180339574813843,
      "learning_rate": 7.935049019607844e-06,
      "loss": 0.1201,
      "step": 6222
    },
    {
      "epoch": 1.4299172794117647,
      "grad_norm": 1.2078906297683716,
      "learning_rate": 7.934538398692812e-06,
      "loss": 0.1005,
      "step": 6223
    },
    {
      "epoch": 1.4301470588235294,
      "grad_norm": 1.7651731967926025,
      "learning_rate": 7.934027777777778e-06,
      "loss": 0.1012,
      "step": 6224
    },
    {
      "epoch": 1.4303768382352942,
      "grad_norm": 1.5818982124328613,
      "learning_rate": 7.933517156862746e-06,
      "loss": 0.0859,
      "step": 6225
    },
    {
      "epoch": 1.4306066176470589,
      "grad_norm": 1.2313485145568848,
      "learning_rate": 7.933006535947712e-06,
      "loss": 0.1205,
      "step": 6226
    },
    {
      "epoch": 1.4308363970588236,
      "grad_norm": 1.2854324579238892,
      "learning_rate": 7.932495915032681e-06,
      "loss": 0.0979,
      "step": 6227
    },
    {
      "epoch": 1.4310661764705883,
      "grad_norm": 1.9695559740066528,
      "learning_rate": 7.931985294117648e-06,
      "loss": 0.1585,
      "step": 6228
    },
    {
      "epoch": 1.4312959558823528,
      "grad_norm": 1.6224616765975952,
      "learning_rate": 7.931474673202615e-06,
      "loss": 0.121,
      "step": 6229
    },
    {
      "epoch": 1.4315257352941178,
      "grad_norm": 1.9301851987838745,
      "learning_rate": 7.930964052287582e-06,
      "loss": 0.102,
      "step": 6230
    },
    {
      "epoch": 1.4317555147058822,
      "grad_norm": 1.9997435808181763,
      "learning_rate": 7.93045343137255e-06,
      "loss": 0.1253,
      "step": 6231
    },
    {
      "epoch": 1.4319852941176472,
      "grad_norm": 1.6502258777618408,
      "learning_rate": 7.929942810457517e-06,
      "loss": 0.1348,
      "step": 6232
    },
    {
      "epoch": 1.4322150735294117,
      "grad_norm": 1.6176060438156128,
      "learning_rate": 7.929432189542484e-06,
      "loss": 0.1288,
      "step": 6233
    },
    {
      "epoch": 1.4324448529411764,
      "grad_norm": 1.406381607055664,
      "learning_rate": 7.928921568627451e-06,
      "loss": 0.0987,
      "step": 6234
    },
    {
      "epoch": 1.4326746323529411,
      "grad_norm": 1.6336067914962769,
      "learning_rate": 7.92841094771242e-06,
      "loss": 0.1381,
      "step": 6235
    },
    {
      "epoch": 1.4329044117647058,
      "grad_norm": 1.6246094703674316,
      "learning_rate": 7.927900326797387e-06,
      "loss": 0.1233,
      "step": 6236
    },
    {
      "epoch": 1.4331341911764706,
      "grad_norm": 1.7983347177505493,
      "learning_rate": 7.927389705882353e-06,
      "loss": 0.0879,
      "step": 6237
    },
    {
      "epoch": 1.4333639705882353,
      "grad_norm": 1.73724365234375,
      "learning_rate": 7.926879084967321e-06,
      "loss": 0.107,
      "step": 6238
    },
    {
      "epoch": 1.43359375,
      "grad_norm": 1.6654188632965088,
      "learning_rate": 7.926368464052289e-06,
      "loss": 0.1697,
      "step": 6239
    },
    {
      "epoch": 1.4338235294117647,
      "grad_norm": 2.0016517639160156,
      "learning_rate": 7.925857843137255e-06,
      "loss": 0.1095,
      "step": 6240
    },
    {
      "epoch": 1.4340533088235294,
      "grad_norm": 1.7145024538040161,
      "learning_rate": 7.925347222222223e-06,
      "loss": 0.1375,
      "step": 6241
    },
    {
      "epoch": 1.4342830882352942,
      "grad_norm": 1.7616020441055298,
      "learning_rate": 7.92483660130719e-06,
      "loss": 0.1078,
      "step": 6242
    },
    {
      "epoch": 1.4345128676470589,
      "grad_norm": 1.7738111019134521,
      "learning_rate": 7.924325980392159e-06,
      "loss": 0.1307,
      "step": 6243
    },
    {
      "epoch": 1.4347426470588236,
      "grad_norm": 1.58743417263031,
      "learning_rate": 7.923815359477125e-06,
      "loss": 0.1334,
      "step": 6244
    },
    {
      "epoch": 1.4349724264705883,
      "grad_norm": 1.3965812921524048,
      "learning_rate": 7.923304738562093e-06,
      "loss": 0.0981,
      "step": 6245
    },
    {
      "epoch": 1.4352022058823528,
      "grad_norm": 2.4054598808288574,
      "learning_rate": 7.922794117647059e-06,
      "loss": 0.108,
      "step": 6246
    },
    {
      "epoch": 1.4354319852941178,
      "grad_norm": 1.8725188970565796,
      "learning_rate": 7.922283496732027e-06,
      "loss": 0.1316,
      "step": 6247
    },
    {
      "epoch": 1.4356617647058822,
      "grad_norm": 1.6542102098464966,
      "learning_rate": 7.921772875816995e-06,
      "loss": 0.109,
      "step": 6248
    },
    {
      "epoch": 1.4358915441176472,
      "grad_norm": 1.5591639280319214,
      "learning_rate": 7.921262254901961e-06,
      "loss": 0.1101,
      "step": 6249
    },
    {
      "epoch": 1.4361213235294117,
      "grad_norm": 1.913968801498413,
      "learning_rate": 7.920751633986929e-06,
      "loss": 0.1062,
      "step": 6250
    },
    {
      "epoch": 1.4363511029411764,
      "grad_norm": 1.786242961883545,
      "learning_rate": 7.920241013071897e-06,
      "loss": 0.1205,
      "step": 6251
    },
    {
      "epoch": 1.4365808823529411,
      "grad_norm": 1.5554898977279663,
      "learning_rate": 7.919730392156863e-06,
      "loss": 0.1303,
      "step": 6252
    },
    {
      "epoch": 1.4368106617647058,
      "grad_norm": 1.6840829849243164,
      "learning_rate": 7.91921977124183e-06,
      "loss": 0.1249,
      "step": 6253
    },
    {
      "epoch": 1.4370404411764706,
      "grad_norm": 2.1449687480926514,
      "learning_rate": 7.918709150326798e-06,
      "loss": 0.195,
      "step": 6254
    },
    {
      "epoch": 1.4372702205882353,
      "grad_norm": 1.3576300144195557,
      "learning_rate": 7.918198529411766e-06,
      "loss": 0.0986,
      "step": 6255
    },
    {
      "epoch": 1.4375,
      "grad_norm": 1.2782618999481201,
      "learning_rate": 7.917687908496733e-06,
      "loss": 0.1204,
      "step": 6256
    },
    {
      "epoch": 1.4377297794117647,
      "grad_norm": 1.5996172428131104,
      "learning_rate": 7.9171772875817e-06,
      "loss": 0.1006,
      "step": 6257
    },
    {
      "epoch": 1.4379595588235294,
      "grad_norm": 1.6230809688568115,
      "learning_rate": 7.916666666666667e-06,
      "loss": 0.144,
      "step": 6258
    },
    {
      "epoch": 1.4381893382352942,
      "grad_norm": 1.572339653968811,
      "learning_rate": 7.916156045751634e-06,
      "loss": 0.1108,
      "step": 6259
    },
    {
      "epoch": 1.4384191176470589,
      "grad_norm": 1.6066184043884277,
      "learning_rate": 7.915645424836602e-06,
      "loss": 0.1487,
      "step": 6260
    },
    {
      "epoch": 1.4386488970588236,
      "grad_norm": 1.8051261901855469,
      "learning_rate": 7.915134803921568e-06,
      "loss": 0.1435,
      "step": 6261
    },
    {
      "epoch": 1.4388786764705883,
      "grad_norm": 1.7235199213027954,
      "learning_rate": 7.914624183006536e-06,
      "loss": 0.1271,
      "step": 6262
    },
    {
      "epoch": 1.4391084558823528,
      "grad_norm": 1.3432122468948364,
      "learning_rate": 7.914113562091504e-06,
      "loss": 0.1127,
      "step": 6263
    },
    {
      "epoch": 1.4393382352941178,
      "grad_norm": 1.1431424617767334,
      "learning_rate": 7.913602941176472e-06,
      "loss": 0.0776,
      "step": 6264
    },
    {
      "epoch": 1.4395680147058822,
      "grad_norm": 1.5242760181427002,
      "learning_rate": 7.913092320261438e-06,
      "loss": 0.1203,
      "step": 6265
    },
    {
      "epoch": 1.4397977941176472,
      "grad_norm": 1.8278049230575562,
      "learning_rate": 7.912581699346406e-06,
      "loss": 0.1186,
      "step": 6266
    },
    {
      "epoch": 1.4400275735294117,
      "grad_norm": 1.5138415098190308,
      "learning_rate": 7.912071078431374e-06,
      "loss": 0.1094,
      "step": 6267
    },
    {
      "epoch": 1.4402573529411764,
      "grad_norm": 2.063474416732788,
      "learning_rate": 7.91156045751634e-06,
      "loss": 0.15,
      "step": 6268
    },
    {
      "epoch": 1.4404871323529411,
      "grad_norm": 2.059013605117798,
      "learning_rate": 7.911049836601308e-06,
      "loss": 0.1471,
      "step": 6269
    },
    {
      "epoch": 1.4407169117647058,
      "grad_norm": 2.2346959114074707,
      "learning_rate": 7.910539215686274e-06,
      "loss": 0.1092,
      "step": 6270
    },
    {
      "epoch": 1.4409466911764706,
      "grad_norm": 1.8949731588363647,
      "learning_rate": 7.910028594771244e-06,
      "loss": 0.1044,
      "step": 6271
    },
    {
      "epoch": 1.4411764705882353,
      "grad_norm": 1.6721919775009155,
      "learning_rate": 7.90951797385621e-06,
      "loss": 0.1071,
      "step": 6272
    },
    {
      "epoch": 1.44140625,
      "grad_norm": 1.9080724716186523,
      "learning_rate": 7.909007352941178e-06,
      "loss": 0.1309,
      "step": 6273
    },
    {
      "epoch": 1.4416360294117647,
      "grad_norm": 1.7166005373001099,
      "learning_rate": 7.908496732026144e-06,
      "loss": 0.1241,
      "step": 6274
    },
    {
      "epoch": 1.4418658088235294,
      "grad_norm": 1.8579559326171875,
      "learning_rate": 7.907986111111112e-06,
      "loss": 0.1414,
      "step": 6275
    },
    {
      "epoch": 1.4420955882352942,
      "grad_norm": 1.7271589040756226,
      "learning_rate": 7.90747549019608e-06,
      "loss": 0.1059,
      "step": 6276
    },
    {
      "epoch": 1.4423253676470589,
      "grad_norm": 2.3623697757720947,
      "learning_rate": 7.906964869281046e-06,
      "loss": 0.1564,
      "step": 6277
    },
    {
      "epoch": 1.4425551470588236,
      "grad_norm": 1.7923637628555298,
      "learning_rate": 7.906454248366014e-06,
      "loss": 0.1265,
      "step": 6278
    },
    {
      "epoch": 1.4427849264705883,
      "grad_norm": 2.3190579414367676,
      "learning_rate": 7.905943627450981e-06,
      "loss": 0.1164,
      "step": 6279
    },
    {
      "epoch": 1.4430147058823528,
      "grad_norm": 1.5352773666381836,
      "learning_rate": 7.90543300653595e-06,
      "loss": 0.108,
      "step": 6280
    },
    {
      "epoch": 1.4432444852941178,
      "grad_norm": 1.5090737342834473,
      "learning_rate": 7.904922385620915e-06,
      "loss": 0.1001,
      "step": 6281
    },
    {
      "epoch": 1.4434742647058822,
      "grad_norm": 2.5545177459716797,
      "learning_rate": 7.904411764705883e-06,
      "loss": 0.1829,
      "step": 6282
    },
    {
      "epoch": 1.4437040441176472,
      "grad_norm": 2.315222978591919,
      "learning_rate": 7.903901143790851e-06,
      "loss": 0.1579,
      "step": 6283
    },
    {
      "epoch": 1.4439338235294117,
      "grad_norm": 1.388400912284851,
      "learning_rate": 7.903390522875817e-06,
      "loss": 0.1183,
      "step": 6284
    },
    {
      "epoch": 1.4441636029411764,
      "grad_norm": 1.8030154705047607,
      "learning_rate": 7.902879901960785e-06,
      "loss": 0.1178,
      "step": 6285
    },
    {
      "epoch": 1.4443933823529411,
      "grad_norm": 1.9801017045974731,
      "learning_rate": 7.902369281045751e-06,
      "loss": 0.1426,
      "step": 6286
    },
    {
      "epoch": 1.4446231617647058,
      "grad_norm": 1.3624908924102783,
      "learning_rate": 7.90185866013072e-06,
      "loss": 0.0904,
      "step": 6287
    },
    {
      "epoch": 1.4448529411764706,
      "grad_norm": 1.7174439430236816,
      "learning_rate": 7.901348039215687e-06,
      "loss": 0.1177,
      "step": 6288
    },
    {
      "epoch": 1.4450827205882353,
      "grad_norm": 1.3591272830963135,
      "learning_rate": 7.900837418300655e-06,
      "loss": 0.1095,
      "step": 6289
    },
    {
      "epoch": 1.4453125,
      "grad_norm": 1.7295808792114258,
      "learning_rate": 7.900326797385621e-06,
      "loss": 0.1014,
      "step": 6290
    },
    {
      "epoch": 1.4455422794117647,
      "grad_norm": 2.122204542160034,
      "learning_rate": 7.899816176470589e-06,
      "loss": 0.1521,
      "step": 6291
    },
    {
      "epoch": 1.4457720588235294,
      "grad_norm": 1.6629951000213623,
      "learning_rate": 7.899305555555557e-06,
      "loss": 0.1083,
      "step": 6292
    },
    {
      "epoch": 1.4460018382352942,
      "grad_norm": 1.46565842628479,
      "learning_rate": 7.898794934640523e-06,
      "loss": 0.0844,
      "step": 6293
    },
    {
      "epoch": 1.4462316176470589,
      "grad_norm": 1.5544251203536987,
      "learning_rate": 7.898284313725491e-06,
      "loss": 0.0888,
      "step": 6294
    },
    {
      "epoch": 1.4464613970588236,
      "grad_norm": 1.5259621143341064,
      "learning_rate": 7.897773692810459e-06,
      "loss": 0.0959,
      "step": 6295
    },
    {
      "epoch": 1.4466911764705883,
      "grad_norm": 1.852779507637024,
      "learning_rate": 7.897263071895425e-06,
      "loss": 0.1327,
      "step": 6296
    },
    {
      "epoch": 1.4469209558823528,
      "grad_norm": 1.5797736644744873,
      "learning_rate": 7.896752450980393e-06,
      "loss": 0.1322,
      "step": 6297
    },
    {
      "epoch": 1.4471507352941178,
      "grad_norm": 1.9369510412216187,
      "learning_rate": 7.89624183006536e-06,
      "loss": 0.1405,
      "step": 6298
    },
    {
      "epoch": 1.4473805147058822,
      "grad_norm": 2.076143980026245,
      "learning_rate": 7.895731209150329e-06,
      "loss": 0.1653,
      "step": 6299
    },
    {
      "epoch": 1.4476102941176472,
      "grad_norm": 1.2972828149795532,
      "learning_rate": 7.895220588235295e-06,
      "loss": 0.0937,
      "step": 6300
    },
    {
      "epoch": 1.4478400735294117,
      "grad_norm": 1.585397720336914,
      "learning_rate": 7.894709967320263e-06,
      "loss": 0.1131,
      "step": 6301
    },
    {
      "epoch": 1.4480698529411764,
      "grad_norm": 1.718421459197998,
      "learning_rate": 7.894199346405229e-06,
      "loss": 0.1188,
      "step": 6302
    },
    {
      "epoch": 1.4482996323529411,
      "grad_norm": 2.035207509994507,
      "learning_rate": 7.893688725490197e-06,
      "loss": 0.1958,
      "step": 6303
    },
    {
      "epoch": 1.4485294117647058,
      "grad_norm": 1.2648990154266357,
      "learning_rate": 7.893178104575164e-06,
      "loss": 0.1083,
      "step": 6304
    },
    {
      "epoch": 1.4487591911764706,
      "grad_norm": 1.663534164428711,
      "learning_rate": 7.89266748366013e-06,
      "loss": 0.1445,
      "step": 6305
    },
    {
      "epoch": 1.4489889705882353,
      "grad_norm": 1.6823558807373047,
      "learning_rate": 7.892156862745098e-06,
      "loss": 0.0951,
      "step": 6306
    },
    {
      "epoch": 1.44921875,
      "grad_norm": 1.6266298294067383,
      "learning_rate": 7.891646241830066e-06,
      "loss": 0.0967,
      "step": 6307
    },
    {
      "epoch": 1.4494485294117647,
      "grad_norm": 1.2767014503479004,
      "learning_rate": 7.891135620915034e-06,
      "loss": 0.1214,
      "step": 6308
    },
    {
      "epoch": 1.4496783088235294,
      "grad_norm": 1.5571227073669434,
      "learning_rate": 7.890625e-06,
      "loss": 0.0952,
      "step": 6309
    },
    {
      "epoch": 1.4499080882352942,
      "grad_norm": 1.6447975635528564,
      "learning_rate": 7.890114379084968e-06,
      "loss": 0.1026,
      "step": 6310
    },
    {
      "epoch": 1.4501378676470589,
      "grad_norm": 1.8794063329696655,
      "learning_rate": 7.889603758169934e-06,
      "loss": 0.1257,
      "step": 6311
    },
    {
      "epoch": 1.4503676470588236,
      "grad_norm": 1.7288542985916138,
      "learning_rate": 7.889093137254902e-06,
      "loss": 0.1473,
      "step": 6312
    },
    {
      "epoch": 1.4505974264705883,
      "grad_norm": 2.088839292526245,
      "learning_rate": 7.88858251633987e-06,
      "loss": 0.1315,
      "step": 6313
    },
    {
      "epoch": 1.4508272058823528,
      "grad_norm": 1.741990327835083,
      "learning_rate": 7.888071895424836e-06,
      "loss": 0.136,
      "step": 6314
    },
    {
      "epoch": 1.4510569852941178,
      "grad_norm": 1.9559420347213745,
      "learning_rate": 7.887561274509804e-06,
      "loss": 0.1611,
      "step": 6315
    },
    {
      "epoch": 1.4512867647058822,
      "grad_norm": 1.5245767831802368,
      "learning_rate": 7.887050653594772e-06,
      "loss": 0.125,
      "step": 6316
    },
    {
      "epoch": 1.4515165441176472,
      "grad_norm": 1.9422296285629272,
      "learning_rate": 7.88654003267974e-06,
      "loss": 0.1063,
      "step": 6317
    },
    {
      "epoch": 1.4517463235294117,
      "grad_norm": 1.598300576210022,
      "learning_rate": 7.886029411764706e-06,
      "loss": 0.1044,
      "step": 6318
    },
    {
      "epoch": 1.4519761029411764,
      "grad_norm": 1.680088996887207,
      "learning_rate": 7.885518790849674e-06,
      "loss": 0.1075,
      "step": 6319
    },
    {
      "epoch": 1.4522058823529411,
      "grad_norm": 1.4827314615249634,
      "learning_rate": 7.885008169934642e-06,
      "loss": 0.081,
      "step": 6320
    },
    {
      "epoch": 1.4524356617647058,
      "grad_norm": 2.261909246444702,
      "learning_rate": 7.884497549019608e-06,
      "loss": 0.1479,
      "step": 6321
    },
    {
      "epoch": 1.4526654411764706,
      "grad_norm": 1.5743552446365356,
      "learning_rate": 7.883986928104576e-06,
      "loss": 0.0967,
      "step": 6322
    },
    {
      "epoch": 1.4528952205882353,
      "grad_norm": 2.295380115509033,
      "learning_rate": 7.883476307189542e-06,
      "loss": 0.1527,
      "step": 6323
    },
    {
      "epoch": 1.453125,
      "grad_norm": 1.7415039539337158,
      "learning_rate": 7.882965686274512e-06,
      "loss": 0.1104,
      "step": 6324
    },
    {
      "epoch": 1.4533547794117647,
      "grad_norm": 1.8168143033981323,
      "learning_rate": 7.882455065359478e-06,
      "loss": 0.1327,
      "step": 6325
    },
    {
      "epoch": 1.4535845588235294,
      "grad_norm": 1.4325653314590454,
      "learning_rate": 7.881944444444446e-06,
      "loss": 0.0863,
      "step": 6326
    },
    {
      "epoch": 1.4538143382352942,
      "grad_norm": 1.6816068887710571,
      "learning_rate": 7.881433823529412e-06,
      "loss": 0.097,
      "step": 6327
    },
    {
      "epoch": 1.4540441176470589,
      "grad_norm": 1.8854002952575684,
      "learning_rate": 7.88092320261438e-06,
      "loss": 0.1437,
      "step": 6328
    },
    {
      "epoch": 1.4542738970588236,
      "grad_norm": 1.6052794456481934,
      "learning_rate": 7.880412581699347e-06,
      "loss": 0.133,
      "step": 6329
    },
    {
      "epoch": 1.4545036764705883,
      "grad_norm": 1.5032302141189575,
      "learning_rate": 7.879901960784314e-06,
      "loss": 0.1532,
      "step": 6330
    },
    {
      "epoch": 1.4547334558823528,
      "grad_norm": 2.8301572799682617,
      "learning_rate": 7.879391339869281e-06,
      "loss": 0.1515,
      "step": 6331
    },
    {
      "epoch": 1.4549632352941178,
      "grad_norm": 2.280700922012329,
      "learning_rate": 7.87888071895425e-06,
      "loss": 0.1191,
      "step": 6332
    },
    {
      "epoch": 1.4551930147058822,
      "grad_norm": 1.8061333894729614,
      "learning_rate": 7.878370098039217e-06,
      "loss": 0.141,
      "step": 6333
    },
    {
      "epoch": 1.4554227941176472,
      "grad_norm": 1.811854362487793,
      "learning_rate": 7.877859477124183e-06,
      "loss": 0.0999,
      "step": 6334
    },
    {
      "epoch": 1.4556525735294117,
      "grad_norm": 2.0353541374206543,
      "learning_rate": 7.877348856209151e-06,
      "loss": 0.1414,
      "step": 6335
    },
    {
      "epoch": 1.4558823529411764,
      "grad_norm": 1.7266756296157837,
      "learning_rate": 7.876838235294119e-06,
      "loss": 0.1006,
      "step": 6336
    },
    {
      "epoch": 1.4561121323529411,
      "grad_norm": 1.41266667842865,
      "learning_rate": 7.876327614379085e-06,
      "loss": 0.1029,
      "step": 6337
    },
    {
      "epoch": 1.4563419117647058,
      "grad_norm": 1.6149283647537231,
      "learning_rate": 7.875816993464053e-06,
      "loss": 0.122,
      "step": 6338
    },
    {
      "epoch": 1.4565716911764706,
      "grad_norm": 1.5738420486450195,
      "learning_rate": 7.87530637254902e-06,
      "loss": 0.1306,
      "step": 6339
    },
    {
      "epoch": 1.4568014705882353,
      "grad_norm": 1.5455020666122437,
      "learning_rate": 7.874795751633987e-06,
      "loss": 0.0935,
      "step": 6340
    },
    {
      "epoch": 1.45703125,
      "grad_norm": 1.429856300354004,
      "learning_rate": 7.874285130718955e-06,
      "loss": 0.1162,
      "step": 6341
    },
    {
      "epoch": 1.4572610294117647,
      "grad_norm": 1.5904264450073242,
      "learning_rate": 7.873774509803921e-06,
      "loss": 0.1446,
      "step": 6342
    },
    {
      "epoch": 1.4574908088235294,
      "grad_norm": 2.1284072399139404,
      "learning_rate": 7.873263888888889e-06,
      "loss": 0.1604,
      "step": 6343
    },
    {
      "epoch": 1.4577205882352942,
      "grad_norm": 2.0951874256134033,
      "learning_rate": 7.872753267973857e-06,
      "loss": 0.1656,
      "step": 6344
    },
    {
      "epoch": 1.4579503676470589,
      "grad_norm": 1.9441087245941162,
      "learning_rate": 7.872242647058825e-06,
      "loss": 0.1168,
      "step": 6345
    },
    {
      "epoch": 1.4581801470588236,
      "grad_norm": 1.7981040477752686,
      "learning_rate": 7.871732026143791e-06,
      "loss": 0.1114,
      "step": 6346
    },
    {
      "epoch": 1.4584099264705883,
      "grad_norm": 1.5601534843444824,
      "learning_rate": 7.871221405228759e-06,
      "loss": 0.1238,
      "step": 6347
    },
    {
      "epoch": 1.4586397058823528,
      "grad_norm": 1.494518756866455,
      "learning_rate": 7.870710784313727e-06,
      "loss": 0.1433,
      "step": 6348
    },
    {
      "epoch": 1.4588694852941178,
      "grad_norm": 1.6416161060333252,
      "learning_rate": 7.870200163398693e-06,
      "loss": 0.1131,
      "step": 6349
    },
    {
      "epoch": 1.4590992647058822,
      "grad_norm": 1.5707242488861084,
      "learning_rate": 7.86968954248366e-06,
      "loss": 0.1557,
      "step": 6350
    },
    {
      "epoch": 1.4593290441176472,
      "grad_norm": 1.9911013841629028,
      "learning_rate": 7.869178921568627e-06,
      "loss": 0.1174,
      "step": 6351
    },
    {
      "epoch": 1.4595588235294117,
      "grad_norm": 2.585024356842041,
      "learning_rate": 7.868668300653596e-06,
      "loss": 0.1377,
      "step": 6352
    },
    {
      "epoch": 1.4597886029411764,
      "grad_norm": 1.7719403505325317,
      "learning_rate": 7.868157679738563e-06,
      "loss": 0.1336,
      "step": 6353
    },
    {
      "epoch": 1.4600183823529411,
      "grad_norm": 1.8735785484313965,
      "learning_rate": 7.86764705882353e-06,
      "loss": 0.1299,
      "step": 6354
    },
    {
      "epoch": 1.4602481617647058,
      "grad_norm": 1.4226800203323364,
      "learning_rate": 7.867136437908497e-06,
      "loss": 0.1163,
      "step": 6355
    },
    {
      "epoch": 1.4604779411764706,
      "grad_norm": 1.4042106866836548,
      "learning_rate": 7.866625816993464e-06,
      "loss": 0.1081,
      "step": 6356
    },
    {
      "epoch": 1.4607077205882353,
      "grad_norm": 1.3231638669967651,
      "learning_rate": 7.866115196078432e-06,
      "loss": 0.1073,
      "step": 6357
    },
    {
      "epoch": 1.4609375,
      "grad_norm": 1.866290807723999,
      "learning_rate": 7.865604575163398e-06,
      "loss": 0.1704,
      "step": 6358
    },
    {
      "epoch": 1.4611672794117647,
      "grad_norm": 1.4978119134902954,
      "learning_rate": 7.865093954248366e-06,
      "loss": 0.1036,
      "step": 6359
    },
    {
      "epoch": 1.4613970588235294,
      "grad_norm": 1.997969150543213,
      "learning_rate": 7.864583333333334e-06,
      "loss": 0.1312,
      "step": 6360
    },
    {
      "epoch": 1.4616268382352942,
      "grad_norm": 2.0413196086883545,
      "learning_rate": 7.864072712418302e-06,
      "loss": 0.1572,
      "step": 6361
    },
    {
      "epoch": 1.4618566176470589,
      "grad_norm": 2.1380808353424072,
      "learning_rate": 7.863562091503268e-06,
      "loss": 0.1779,
      "step": 6362
    },
    {
      "epoch": 1.4620863970588236,
      "grad_norm": 1.5976616144180298,
      "learning_rate": 7.863051470588236e-06,
      "loss": 0.1084,
      "step": 6363
    },
    {
      "epoch": 1.4623161764705883,
      "grad_norm": 2.255903959274292,
      "learning_rate": 7.862540849673204e-06,
      "loss": 0.1188,
      "step": 6364
    },
    {
      "epoch": 1.4625459558823528,
      "grad_norm": 1.8575160503387451,
      "learning_rate": 7.86203022875817e-06,
      "loss": 0.0821,
      "step": 6365
    },
    {
      "epoch": 1.4627757352941178,
      "grad_norm": 2.2998194694519043,
      "learning_rate": 7.861519607843138e-06,
      "loss": 0.1601,
      "step": 6366
    },
    {
      "epoch": 1.4630055147058822,
      "grad_norm": 1.9569268226623535,
      "learning_rate": 7.861008986928104e-06,
      "loss": 0.112,
      "step": 6367
    },
    {
      "epoch": 1.4632352941176472,
      "grad_norm": 1.5359817743301392,
      "learning_rate": 7.860498366013074e-06,
      "loss": 0.1021,
      "step": 6368
    },
    {
      "epoch": 1.4634650735294117,
      "grad_norm": 2.3739960193634033,
      "learning_rate": 7.85998774509804e-06,
      "loss": 0.2078,
      "step": 6369
    },
    {
      "epoch": 1.4636948529411764,
      "grad_norm": 1.650783658027649,
      "learning_rate": 7.859477124183008e-06,
      "loss": 0.1303,
      "step": 6370
    },
    {
      "epoch": 1.4639246323529411,
      "grad_norm": 1.8701602220535278,
      "learning_rate": 7.858966503267974e-06,
      "loss": 0.145,
      "step": 6371
    },
    {
      "epoch": 1.4641544117647058,
      "grad_norm": 1.5407261848449707,
      "learning_rate": 7.858455882352942e-06,
      "loss": 0.0959,
      "step": 6372
    },
    {
      "epoch": 1.4643841911764706,
      "grad_norm": 1.4787095785140991,
      "learning_rate": 7.85794526143791e-06,
      "loss": 0.0993,
      "step": 6373
    },
    {
      "epoch": 1.4646139705882353,
      "grad_norm": 1.8916267156600952,
      "learning_rate": 7.857434640522876e-06,
      "loss": 0.1174,
      "step": 6374
    },
    {
      "epoch": 1.46484375,
      "grad_norm": 1.382483959197998,
      "learning_rate": 7.856924019607844e-06,
      "loss": 0.1149,
      "step": 6375
    },
    {
      "epoch": 1.4650735294117647,
      "grad_norm": 1.8876246213912964,
      "learning_rate": 7.856413398692812e-06,
      "loss": 0.1788,
      "step": 6376
    },
    {
      "epoch": 1.4653033088235294,
      "grad_norm": 1.7680245637893677,
      "learning_rate": 7.85590277777778e-06,
      "loss": 0.1085,
      "step": 6377
    },
    {
      "epoch": 1.4655330882352942,
      "grad_norm": 1.430572509765625,
      "learning_rate": 7.855392156862746e-06,
      "loss": 0.1121,
      "step": 6378
    },
    {
      "epoch": 1.4657628676470589,
      "grad_norm": 1.931268334388733,
      "learning_rate": 7.854881535947713e-06,
      "loss": 0.1376,
      "step": 6379
    },
    {
      "epoch": 1.4659926470588236,
      "grad_norm": 2.1934316158294678,
      "learning_rate": 7.854370915032681e-06,
      "loss": 0.181,
      "step": 6380
    },
    {
      "epoch": 1.4662224264705883,
      "grad_norm": 1.9656932353973389,
      "learning_rate": 7.853860294117647e-06,
      "loss": 0.1786,
      "step": 6381
    },
    {
      "epoch": 1.4664522058823528,
      "grad_norm": 1.256168007850647,
      "learning_rate": 7.853349673202615e-06,
      "loss": 0.1169,
      "step": 6382
    },
    {
      "epoch": 1.4666819852941178,
      "grad_norm": 1.4718782901763916,
      "learning_rate": 7.852839052287581e-06,
      "loss": 0.1422,
      "step": 6383
    },
    {
      "epoch": 1.4669117647058822,
      "grad_norm": 1.8791643381118774,
      "learning_rate": 7.85232843137255e-06,
      "loss": 0.1252,
      "step": 6384
    },
    {
      "epoch": 1.4671415441176472,
      "grad_norm": 1.9224709272384644,
      "learning_rate": 7.851817810457517e-06,
      "loss": 0.1273,
      "step": 6385
    },
    {
      "epoch": 1.4673713235294117,
      "grad_norm": 1.482064127922058,
      "learning_rate": 7.851307189542483e-06,
      "loss": 0.1072,
      "step": 6386
    },
    {
      "epoch": 1.4676011029411764,
      "grad_norm": 1.6744195222854614,
      "learning_rate": 7.850796568627451e-06,
      "loss": 0.1062,
      "step": 6387
    },
    {
      "epoch": 1.4678308823529411,
      "grad_norm": 2.0526256561279297,
      "learning_rate": 7.850285947712419e-06,
      "loss": 0.1732,
      "step": 6388
    },
    {
      "epoch": 1.4680606617647058,
      "grad_norm": 1.5954844951629639,
      "learning_rate": 7.849775326797387e-06,
      "loss": 0.1081,
      "step": 6389
    },
    {
      "epoch": 1.4682904411764706,
      "grad_norm": 1.8614802360534668,
      "learning_rate": 7.849264705882353e-06,
      "loss": 0.104,
      "step": 6390
    },
    {
      "epoch": 1.4685202205882353,
      "grad_norm": 1.658677101135254,
      "learning_rate": 7.848754084967321e-06,
      "loss": 0.1715,
      "step": 6391
    },
    {
      "epoch": 1.46875,
      "grad_norm": 1.7433079481124878,
      "learning_rate": 7.848243464052289e-06,
      "loss": 0.1142,
      "step": 6392
    },
    {
      "epoch": 1.4689797794117647,
      "grad_norm": 1.5773168802261353,
      "learning_rate": 7.847732843137255e-06,
      "loss": 0.0875,
      "step": 6393
    },
    {
      "epoch": 1.4692095588235294,
      "grad_norm": 1.43219792842865,
      "learning_rate": 7.847222222222223e-06,
      "loss": 0.1032,
      "step": 6394
    },
    {
      "epoch": 1.4694393382352942,
      "grad_norm": 1.626227617263794,
      "learning_rate": 7.846711601307189e-06,
      "loss": 0.1214,
      "step": 6395
    },
    {
      "epoch": 1.4696691176470589,
      "grad_norm": 1.535151481628418,
      "learning_rate": 7.846200980392159e-06,
      "loss": 0.108,
      "step": 6396
    },
    {
      "epoch": 1.4698988970588236,
      "grad_norm": 1.5632410049438477,
      "learning_rate": 7.845690359477125e-06,
      "loss": 0.0939,
      "step": 6397
    },
    {
      "epoch": 1.4701286764705883,
      "grad_norm": 1.498475193977356,
      "learning_rate": 7.845179738562093e-06,
      "loss": 0.0924,
      "step": 6398
    },
    {
      "epoch": 1.4703584558823528,
      "grad_norm": 1.6645691394805908,
      "learning_rate": 7.844669117647059e-06,
      "loss": 0.1268,
      "step": 6399
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 1.3284355401992798,
      "learning_rate": 7.844158496732027e-06,
      "loss": 0.1024,
      "step": 6400
    },
    {
      "epoch": 1.4708180147058822,
      "grad_norm": 1.5443596839904785,
      "learning_rate": 7.843647875816994e-06,
      "loss": 0.1129,
      "step": 6401
    },
    {
      "epoch": 1.4710477941176472,
      "grad_norm": 1.977408766746521,
      "learning_rate": 7.84313725490196e-06,
      "loss": 0.1162,
      "step": 6402
    },
    {
      "epoch": 1.4712775735294117,
      "grad_norm": 1.579728364944458,
      "learning_rate": 7.842626633986929e-06,
      "loss": 0.1121,
      "step": 6403
    },
    {
      "epoch": 1.4715073529411764,
      "grad_norm": 1.655344009399414,
      "learning_rate": 7.842116013071896e-06,
      "loss": 0.124,
      "step": 6404
    },
    {
      "epoch": 1.4717371323529411,
      "grad_norm": 1.9446487426757812,
      "learning_rate": 7.841605392156864e-06,
      "loss": 0.0986,
      "step": 6405
    },
    {
      "epoch": 1.4719669117647058,
      "grad_norm": 1.65472412109375,
      "learning_rate": 7.84109477124183e-06,
      "loss": 0.147,
      "step": 6406
    },
    {
      "epoch": 1.4721966911764706,
      "grad_norm": 1.9566110372543335,
      "learning_rate": 7.840584150326798e-06,
      "loss": 0.1146,
      "step": 6407
    },
    {
      "epoch": 1.4724264705882353,
      "grad_norm": 1.4925910234451294,
      "learning_rate": 7.840073529411766e-06,
      "loss": 0.107,
      "step": 6408
    },
    {
      "epoch": 1.47265625,
      "grad_norm": 1.703595757484436,
      "learning_rate": 7.839562908496732e-06,
      "loss": 0.1026,
      "step": 6409
    },
    {
      "epoch": 1.4728860294117647,
      "grad_norm": 1.6969131231307983,
      "learning_rate": 7.8390522875817e-06,
      "loss": 0.1347,
      "step": 6410
    },
    {
      "epoch": 1.4731158088235294,
      "grad_norm": 1.6258450746536255,
      "learning_rate": 7.838541666666666e-06,
      "loss": 0.1133,
      "step": 6411
    },
    {
      "epoch": 1.4733455882352942,
      "grad_norm": 1.490404486656189,
      "learning_rate": 7.838031045751636e-06,
      "loss": 0.1245,
      "step": 6412
    },
    {
      "epoch": 1.4735753676470589,
      "grad_norm": 1.34723699092865,
      "learning_rate": 7.837520424836602e-06,
      "loss": 0.1021,
      "step": 6413
    },
    {
      "epoch": 1.4738051470588236,
      "grad_norm": 1.8525266647338867,
      "learning_rate": 7.83700980392157e-06,
      "loss": 0.1276,
      "step": 6414
    },
    {
      "epoch": 1.4740349264705883,
      "grad_norm": 1.5844324827194214,
      "learning_rate": 7.836499183006536e-06,
      "loss": 0.1068,
      "step": 6415
    },
    {
      "epoch": 1.4742647058823528,
      "grad_norm": 1.6206121444702148,
      "learning_rate": 7.835988562091504e-06,
      "loss": 0.1408,
      "step": 6416
    },
    {
      "epoch": 1.4744944852941178,
      "grad_norm": 1.4752753973007202,
      "learning_rate": 7.835477941176472e-06,
      "loss": 0.0858,
      "step": 6417
    },
    {
      "epoch": 1.4747242647058822,
      "grad_norm": 1.7213780879974365,
      "learning_rate": 7.834967320261438e-06,
      "loss": 0.1301,
      "step": 6418
    },
    {
      "epoch": 1.4749540441176472,
      "grad_norm": 1.61305570602417,
      "learning_rate": 7.834456699346406e-06,
      "loss": 0.1097,
      "step": 6419
    },
    {
      "epoch": 1.4751838235294117,
      "grad_norm": 2.1141886711120605,
      "learning_rate": 7.833946078431374e-06,
      "loss": 0.1296,
      "step": 6420
    },
    {
      "epoch": 1.4754136029411764,
      "grad_norm": 1.5976643562316895,
      "learning_rate": 7.833435457516342e-06,
      "loss": 0.0906,
      "step": 6421
    },
    {
      "epoch": 1.4756433823529411,
      "grad_norm": 1.707175612449646,
      "learning_rate": 7.832924836601308e-06,
      "loss": 0.1098,
      "step": 6422
    },
    {
      "epoch": 1.4758731617647058,
      "grad_norm": 1.7158198356628418,
      "learning_rate": 7.832414215686276e-06,
      "loss": 0.1421,
      "step": 6423
    },
    {
      "epoch": 1.4761029411764706,
      "grad_norm": 1.327545404434204,
      "learning_rate": 7.831903594771243e-06,
      "loss": 0.0921,
      "step": 6424
    },
    {
      "epoch": 1.4763327205882353,
      "grad_norm": 1.533515453338623,
      "learning_rate": 7.83139297385621e-06,
      "loss": 0.1264,
      "step": 6425
    },
    {
      "epoch": 1.4765625,
      "grad_norm": 1.462842583656311,
      "learning_rate": 7.830882352941177e-06,
      "loss": 0.1225,
      "step": 6426
    },
    {
      "epoch": 1.4767922794117647,
      "grad_norm": 1.7168822288513184,
      "learning_rate": 7.830371732026144e-06,
      "loss": 0.1037,
      "step": 6427
    },
    {
      "epoch": 1.4770220588235294,
      "grad_norm": 1.560408115386963,
      "learning_rate": 7.829861111111112e-06,
      "loss": 0.1277,
      "step": 6428
    },
    {
      "epoch": 1.4772518382352942,
      "grad_norm": 1.5067744255065918,
      "learning_rate": 7.82935049019608e-06,
      "loss": 0.1305,
      "step": 6429
    },
    {
      "epoch": 1.4774816176470589,
      "grad_norm": 2.1964828968048096,
      "learning_rate": 7.828839869281046e-06,
      "loss": 0.1294,
      "step": 6430
    },
    {
      "epoch": 1.4777113970588236,
      "grad_norm": 1.9755303859710693,
      "learning_rate": 7.828329248366013e-06,
      "loss": 0.1417,
      "step": 6431
    },
    {
      "epoch": 1.4779411764705883,
      "grad_norm": 1.3461993932724,
      "learning_rate": 7.827818627450981e-06,
      "loss": 0.0832,
      "step": 6432
    },
    {
      "epoch": 1.4781709558823528,
      "grad_norm": 1.7271655797958374,
      "learning_rate": 7.827308006535949e-06,
      "loss": 0.1097,
      "step": 6433
    },
    {
      "epoch": 1.4784007352941178,
      "grad_norm": 1.9232875108718872,
      "learning_rate": 7.826797385620915e-06,
      "loss": 0.1399,
      "step": 6434
    },
    {
      "epoch": 1.4786305147058822,
      "grad_norm": 1.5766578912734985,
      "learning_rate": 7.826286764705883e-06,
      "loss": 0.1279,
      "step": 6435
    },
    {
      "epoch": 1.4788602941176472,
      "grad_norm": 1.1838711500167847,
      "learning_rate": 7.825776143790851e-06,
      "loss": 0.1135,
      "step": 6436
    },
    {
      "epoch": 1.4790900735294117,
      "grad_norm": 1.2526756525039673,
      "learning_rate": 7.825265522875817e-06,
      "loss": 0.0876,
      "step": 6437
    },
    {
      "epoch": 1.4793198529411764,
      "grad_norm": 1.7980209589004517,
      "learning_rate": 7.824754901960785e-06,
      "loss": 0.1401,
      "step": 6438
    },
    {
      "epoch": 1.4795496323529411,
      "grad_norm": 1.4896714687347412,
      "learning_rate": 7.824244281045751e-06,
      "loss": 0.146,
      "step": 6439
    },
    {
      "epoch": 1.4797794117647058,
      "grad_norm": 1.391055703163147,
      "learning_rate": 7.82373366013072e-06,
      "loss": 0.1124,
      "step": 6440
    },
    {
      "epoch": 1.4800091911764706,
      "grad_norm": 1.5983195304870605,
      "learning_rate": 7.823223039215687e-06,
      "loss": 0.1365,
      "step": 6441
    },
    {
      "epoch": 1.4802389705882353,
      "grad_norm": 1.797408103942871,
      "learning_rate": 7.822712418300655e-06,
      "loss": 0.115,
      "step": 6442
    },
    {
      "epoch": 1.48046875,
      "grad_norm": 1.4084653854370117,
      "learning_rate": 7.822201797385621e-06,
      "loss": 0.1182,
      "step": 6443
    },
    {
      "epoch": 1.4806985294117647,
      "grad_norm": 1.420669674873352,
      "learning_rate": 7.821691176470589e-06,
      "loss": 0.1216,
      "step": 6444
    },
    {
      "epoch": 1.4809283088235294,
      "grad_norm": 1.621734380722046,
      "learning_rate": 7.821180555555557e-06,
      "loss": 0.1068,
      "step": 6445
    },
    {
      "epoch": 1.4811580882352942,
      "grad_norm": 1.441140055656433,
      "learning_rate": 7.820669934640523e-06,
      "loss": 0.1161,
      "step": 6446
    },
    {
      "epoch": 1.4813878676470589,
      "grad_norm": 1.823337435722351,
      "learning_rate": 7.82015931372549e-06,
      "loss": 0.1145,
      "step": 6447
    },
    {
      "epoch": 1.4816176470588236,
      "grad_norm": 1.5464016199111938,
      "learning_rate": 7.819648692810459e-06,
      "loss": 0.109,
      "step": 6448
    },
    {
      "epoch": 1.4818474264705883,
      "grad_norm": 1.9066965579986572,
      "learning_rate": 7.819138071895426e-06,
      "loss": 0.1549,
      "step": 6449
    },
    {
      "epoch": 1.4820772058823528,
      "grad_norm": 2.07614803314209,
      "learning_rate": 7.818627450980393e-06,
      "loss": 0.1782,
      "step": 6450
    },
    {
      "epoch": 1.4823069852941178,
      "grad_norm": 1.7250548601150513,
      "learning_rate": 7.81811683006536e-06,
      "loss": 0.1199,
      "step": 6451
    },
    {
      "epoch": 1.4825367647058822,
      "grad_norm": 1.635148525238037,
      "learning_rate": 7.817606209150328e-06,
      "loss": 0.1404,
      "step": 6452
    },
    {
      "epoch": 1.4827665441176472,
      "grad_norm": 1.42795729637146,
      "learning_rate": 7.817095588235294e-06,
      "loss": 0.094,
      "step": 6453
    },
    {
      "epoch": 1.4829963235294117,
      "grad_norm": 1.936538577079773,
      "learning_rate": 7.816584967320262e-06,
      "loss": 0.1348,
      "step": 6454
    },
    {
      "epoch": 1.4832261029411764,
      "grad_norm": 1.5140128135681152,
      "learning_rate": 7.816074346405229e-06,
      "loss": 0.1338,
      "step": 6455
    },
    {
      "epoch": 1.4834558823529411,
      "grad_norm": 1.7563204765319824,
      "learning_rate": 7.815563725490198e-06,
      "loss": 0.1105,
      "step": 6456
    },
    {
      "epoch": 1.4836856617647058,
      "grad_norm": 1.481680154800415,
      "learning_rate": 7.815053104575164e-06,
      "loss": 0.0774,
      "step": 6457
    },
    {
      "epoch": 1.4839154411764706,
      "grad_norm": 1.5746709108352661,
      "learning_rate": 7.814542483660132e-06,
      "loss": 0.1382,
      "step": 6458
    },
    {
      "epoch": 1.4841452205882353,
      "grad_norm": 1.7629393339157104,
      "learning_rate": 7.814031862745098e-06,
      "loss": 0.1403,
      "step": 6459
    },
    {
      "epoch": 1.484375,
      "grad_norm": 2.1100010871887207,
      "learning_rate": 7.813521241830066e-06,
      "loss": 0.1126,
      "step": 6460
    },
    {
      "epoch": 1.4846047794117647,
      "grad_norm": 1.5286248922348022,
      "learning_rate": 7.813010620915034e-06,
      "loss": 0.1114,
      "step": 6461
    },
    {
      "epoch": 1.4848345588235294,
      "grad_norm": 1.6043741703033447,
      "learning_rate": 7.8125e-06,
      "loss": 0.0901,
      "step": 6462
    },
    {
      "epoch": 1.4850643382352942,
      "grad_norm": 1.5725698471069336,
      "learning_rate": 7.811989379084968e-06,
      "loss": 0.1346,
      "step": 6463
    },
    {
      "epoch": 1.4852941176470589,
      "grad_norm": 2.0461959838867188,
      "learning_rate": 7.811478758169934e-06,
      "loss": 0.1223,
      "step": 6464
    },
    {
      "epoch": 1.4855238970588236,
      "grad_norm": 1.600088119506836,
      "learning_rate": 7.810968137254902e-06,
      "loss": 0.1314,
      "step": 6465
    },
    {
      "epoch": 1.4857536764705883,
      "grad_norm": 2.503213405609131,
      "learning_rate": 7.81045751633987e-06,
      "loss": 0.1293,
      "step": 6466
    },
    {
      "epoch": 1.4859834558823528,
      "grad_norm": 1.7058260440826416,
      "learning_rate": 7.809946895424838e-06,
      "loss": 0.1582,
      "step": 6467
    },
    {
      "epoch": 1.4862132352941178,
      "grad_norm": 2.173619031906128,
      "learning_rate": 7.809436274509804e-06,
      "loss": 0.1084,
      "step": 6468
    },
    {
      "epoch": 1.4864430147058822,
      "grad_norm": 1.8172489404678345,
      "learning_rate": 7.808925653594772e-06,
      "loss": 0.1311,
      "step": 6469
    },
    {
      "epoch": 1.4866727941176472,
      "grad_norm": 1.6039680242538452,
      "learning_rate": 7.80841503267974e-06,
      "loss": 0.105,
      "step": 6470
    },
    {
      "epoch": 1.4869025735294117,
      "grad_norm": 1.7636997699737549,
      "learning_rate": 7.807904411764706e-06,
      "loss": 0.1066,
      "step": 6471
    },
    {
      "epoch": 1.4871323529411764,
      "grad_norm": 1.7638355493545532,
      "learning_rate": 7.807393790849674e-06,
      "loss": 0.1019,
      "step": 6472
    },
    {
      "epoch": 1.4873621323529411,
      "grad_norm": 1.6106247901916504,
      "learning_rate": 7.806883169934642e-06,
      "loss": 0.1003,
      "step": 6473
    },
    {
      "epoch": 1.4875919117647058,
      "grad_norm": 1.533065676689148,
      "learning_rate": 7.806372549019608e-06,
      "loss": 0.112,
      "step": 6474
    },
    {
      "epoch": 1.4878216911764706,
      "grad_norm": 2.2688705921173096,
      "learning_rate": 7.805861928104576e-06,
      "loss": 0.1612,
      "step": 6475
    },
    {
      "epoch": 1.4880514705882353,
      "grad_norm": 1.793229103088379,
      "learning_rate": 7.805351307189542e-06,
      "loss": 0.1186,
      "step": 6476
    },
    {
      "epoch": 1.48828125,
      "grad_norm": 1.2203171253204346,
      "learning_rate": 7.804840686274511e-06,
      "loss": 0.1066,
      "step": 6477
    },
    {
      "epoch": 1.4885110294117647,
      "grad_norm": 1.9682514667510986,
      "learning_rate": 7.804330065359477e-06,
      "loss": 0.1314,
      "step": 6478
    },
    {
      "epoch": 1.4887408088235294,
      "grad_norm": 1.7494792938232422,
      "learning_rate": 7.803819444444445e-06,
      "loss": 0.1406,
      "step": 6479
    },
    {
      "epoch": 1.4889705882352942,
      "grad_norm": 2.1093053817749023,
      "learning_rate": 7.803308823529412e-06,
      "loss": 0.1144,
      "step": 6480
    },
    {
      "epoch": 1.4892003676470589,
      "grad_norm": 2.1628270149230957,
      "learning_rate": 7.80279820261438e-06,
      "loss": 0.1239,
      "step": 6481
    },
    {
      "epoch": 1.4894301470588236,
      "grad_norm": 1.9838944673538208,
      "learning_rate": 7.802287581699347e-06,
      "loss": 0.1498,
      "step": 6482
    },
    {
      "epoch": 1.4896599264705883,
      "grad_norm": 1.4685919284820557,
      "learning_rate": 7.801776960784313e-06,
      "loss": 0.1061,
      "step": 6483
    },
    {
      "epoch": 1.4898897058823528,
      "grad_norm": 1.5580024719238281,
      "learning_rate": 7.801266339869281e-06,
      "loss": 0.1197,
      "step": 6484
    },
    {
      "epoch": 1.4901194852941178,
      "grad_norm": 1.7441880702972412,
      "learning_rate": 7.800755718954249e-06,
      "loss": 0.1455,
      "step": 6485
    },
    {
      "epoch": 1.4903492647058822,
      "grad_norm": 1.9134479761123657,
      "learning_rate": 7.800245098039217e-06,
      "loss": 0.1145,
      "step": 6486
    },
    {
      "epoch": 1.4905790441176472,
      "grad_norm": 1.6570870876312256,
      "learning_rate": 7.799734477124183e-06,
      "loss": 0.1014,
      "step": 6487
    },
    {
      "epoch": 1.4908088235294117,
      "grad_norm": 1.858700156211853,
      "learning_rate": 7.799223856209151e-06,
      "loss": 0.1195,
      "step": 6488
    },
    {
      "epoch": 1.4910386029411764,
      "grad_norm": 2.0540521144866943,
      "learning_rate": 7.798713235294119e-06,
      "loss": 0.1455,
      "step": 6489
    },
    {
      "epoch": 1.4912683823529411,
      "grad_norm": 2.086036443710327,
      "learning_rate": 7.798202614379085e-06,
      "loss": 0.1268,
      "step": 6490
    },
    {
      "epoch": 1.4914981617647058,
      "grad_norm": 2.5126845836639404,
      "learning_rate": 7.797691993464053e-06,
      "loss": 0.1735,
      "step": 6491
    },
    {
      "epoch": 1.4917279411764706,
      "grad_norm": 1.6379497051239014,
      "learning_rate": 7.797181372549019e-06,
      "loss": 0.1044,
      "step": 6492
    },
    {
      "epoch": 1.4919577205882353,
      "grad_norm": 1.6303941011428833,
      "learning_rate": 7.796670751633989e-06,
      "loss": 0.1131,
      "step": 6493
    },
    {
      "epoch": 1.4921875,
      "grad_norm": 1.310604214668274,
      "learning_rate": 7.796160130718955e-06,
      "loss": 0.0859,
      "step": 6494
    },
    {
      "epoch": 1.4924172794117647,
      "grad_norm": 1.728752613067627,
      "learning_rate": 7.795649509803923e-06,
      "loss": 0.0879,
      "step": 6495
    },
    {
      "epoch": 1.4926470588235294,
      "grad_norm": 1.7706890106201172,
      "learning_rate": 7.795138888888889e-06,
      "loss": 0.0956,
      "step": 6496
    },
    {
      "epoch": 1.4928768382352942,
      "grad_norm": 1.7766625881195068,
      "learning_rate": 7.794628267973857e-06,
      "loss": 0.149,
      "step": 6497
    },
    {
      "epoch": 1.4931066176470589,
      "grad_norm": 1.3890008926391602,
      "learning_rate": 7.794117647058825e-06,
      "loss": 0.1226,
      "step": 6498
    },
    {
      "epoch": 1.4933363970588236,
      "grad_norm": 1.7153562307357788,
      "learning_rate": 7.79360702614379e-06,
      "loss": 0.0955,
      "step": 6499
    },
    {
      "epoch": 1.4935661764705883,
      "grad_norm": 1.9168483018875122,
      "learning_rate": 7.793096405228759e-06,
      "loss": 0.1084,
      "step": 6500
    },
    {
      "epoch": 1.4935661764705883,
      "eval_loss": 0.12454954534769058,
      "eval_runtime": 419.863,
      "eval_samples_per_second": 21.212,
      "eval_steps_per_second": 10.606,
      "step": 6500
    },
    {
      "epoch": 1.4937959558823528,
      "grad_norm": 2.6726114749908447,
      "learning_rate": 7.792585784313726e-06,
      "loss": 0.16,
      "step": 6501
    },
    {
      "epoch": 1.4940257352941178,
      "grad_norm": 1.9469879865646362,
      "learning_rate": 7.792075163398694e-06,
      "loss": 0.1313,
      "step": 6502
    },
    {
      "epoch": 1.4942555147058822,
      "grad_norm": 1.3843775987625122,
      "learning_rate": 7.79156454248366e-06,
      "loss": 0.0783,
      "step": 6503
    },
    {
      "epoch": 1.4944852941176472,
      "grad_norm": 2.0159616470336914,
      "learning_rate": 7.791053921568628e-06,
      "loss": 0.1041,
      "step": 6504
    },
    {
      "epoch": 1.4947150735294117,
      "grad_norm": 1.7165050506591797,
      "learning_rate": 7.790543300653596e-06,
      "loss": 0.1279,
      "step": 6505
    },
    {
      "epoch": 1.4949448529411764,
      "grad_norm": 1.6765851974487305,
      "learning_rate": 7.790032679738562e-06,
      "loss": 0.1349,
      "step": 6506
    },
    {
      "epoch": 1.4951746323529411,
      "grad_norm": 2.1001429557800293,
      "learning_rate": 7.78952205882353e-06,
      "loss": 0.1132,
      "step": 6507
    },
    {
      "epoch": 1.4954044117647058,
      "grad_norm": 1.67424476146698,
      "learning_rate": 7.789011437908496e-06,
      "loss": 0.1246,
      "step": 6508
    },
    {
      "epoch": 1.4956341911764706,
      "grad_norm": 1.6726855039596558,
      "learning_rate": 7.788500816993464e-06,
      "loss": 0.135,
      "step": 6509
    },
    {
      "epoch": 1.4958639705882353,
      "grad_norm": 1.394726037979126,
      "learning_rate": 7.787990196078432e-06,
      "loss": 0.1005,
      "step": 6510
    },
    {
      "epoch": 1.49609375,
      "grad_norm": 1.3923120498657227,
      "learning_rate": 7.7874795751634e-06,
      "loss": 0.0927,
      "step": 6511
    },
    {
      "epoch": 1.4963235294117647,
      "grad_norm": 1.833946704864502,
      "learning_rate": 7.786968954248366e-06,
      "loss": 0.1116,
      "step": 6512
    },
    {
      "epoch": 1.4965533088235294,
      "grad_norm": 1.9626519680023193,
      "learning_rate": 7.786458333333334e-06,
      "loss": 0.1033,
      "step": 6513
    },
    {
      "epoch": 1.4967830882352942,
      "grad_norm": 1.0887525081634521,
      "learning_rate": 7.785947712418302e-06,
      "loss": 0.0997,
      "step": 6514
    },
    {
      "epoch": 1.4970128676470589,
      "grad_norm": 1.607861876487732,
      "learning_rate": 7.785437091503268e-06,
      "loss": 0.1288,
      "step": 6515
    },
    {
      "epoch": 1.4972426470588236,
      "grad_norm": 1.8044703006744385,
      "learning_rate": 7.784926470588236e-06,
      "loss": 0.1009,
      "step": 6516
    },
    {
      "epoch": 1.4974724264705883,
      "grad_norm": 1.3597431182861328,
      "learning_rate": 7.784415849673204e-06,
      "loss": 0.0923,
      "step": 6517
    },
    {
      "epoch": 1.4977022058823528,
      "grad_norm": 2.0224273204803467,
      "learning_rate": 7.78390522875817e-06,
      "loss": 0.0933,
      "step": 6518
    },
    {
      "epoch": 1.4979319852941178,
      "grad_norm": 1.692114233970642,
      "learning_rate": 7.783394607843138e-06,
      "loss": 0.1144,
      "step": 6519
    },
    {
      "epoch": 1.4981617647058822,
      "grad_norm": 1.2952680587768555,
      "learning_rate": 7.782883986928104e-06,
      "loss": 0.0941,
      "step": 6520
    },
    {
      "epoch": 1.4983915441176472,
      "grad_norm": 2.4576125144958496,
      "learning_rate": 7.782373366013073e-06,
      "loss": 0.1556,
      "step": 6521
    },
    {
      "epoch": 1.4986213235294117,
      "grad_norm": 1.9522019624710083,
      "learning_rate": 7.78186274509804e-06,
      "loss": 0.1593,
      "step": 6522
    },
    {
      "epoch": 1.4988511029411764,
      "grad_norm": 2.2300524711608887,
      "learning_rate": 7.781352124183008e-06,
      "loss": 0.1628,
      "step": 6523
    },
    {
      "epoch": 1.4990808823529411,
      "grad_norm": 1.8916045427322388,
      "learning_rate": 7.780841503267974e-06,
      "loss": 0.1134,
      "step": 6524
    },
    {
      "epoch": 1.4993106617647058,
      "grad_norm": 2.041501045227051,
      "learning_rate": 7.780330882352942e-06,
      "loss": 0.1752,
      "step": 6525
    },
    {
      "epoch": 1.4995404411764706,
      "grad_norm": 1.2386119365692139,
      "learning_rate": 7.77982026143791e-06,
      "loss": 0.0714,
      "step": 6526
    },
    {
      "epoch": 1.4997702205882353,
      "grad_norm": 1.5389701128005981,
      "learning_rate": 7.779309640522876e-06,
      "loss": 0.1119,
      "step": 6527
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.1779192686080933,
      "learning_rate": 7.778799019607843e-06,
      "loss": 0.103,
      "step": 6528
    },
    {
      "epoch": 1.5002297794117647,
      "grad_norm": 1.7747917175292969,
      "learning_rate": 7.778288398692811e-06,
      "loss": 0.1229,
      "step": 6529
    },
    {
      "epoch": 1.5004595588235294,
      "grad_norm": 1.5681432485580444,
      "learning_rate": 7.77777777777778e-06,
      "loss": 0.1038,
      "step": 6530
    },
    {
      "epoch": 1.5006893382352942,
      "grad_norm": 2.165571689605713,
      "learning_rate": 7.777267156862745e-06,
      "loss": 0.1627,
      "step": 6531
    },
    {
      "epoch": 1.5009191176470589,
      "grad_norm": 1.5996006727218628,
      "learning_rate": 7.776756535947713e-06,
      "loss": 0.1191,
      "step": 6532
    },
    {
      "epoch": 1.5011488970588234,
      "grad_norm": 1.8701274394989014,
      "learning_rate": 7.776245915032681e-06,
      "loss": 0.1373,
      "step": 6533
    },
    {
      "epoch": 1.5013786764705883,
      "grad_norm": 1.7633957862854004,
      "learning_rate": 7.775735294117647e-06,
      "loss": 0.1233,
      "step": 6534
    },
    {
      "epoch": 1.5016084558823528,
      "grad_norm": 1.3035211563110352,
      "learning_rate": 7.775224673202615e-06,
      "loss": 0.0958,
      "step": 6535
    },
    {
      "epoch": 1.5018382352941178,
      "grad_norm": 1.999434471130371,
      "learning_rate": 7.774714052287581e-06,
      "loss": 0.1154,
      "step": 6536
    },
    {
      "epoch": 1.5020680147058822,
      "grad_norm": 1.7635407447814941,
      "learning_rate": 7.77420343137255e-06,
      "loss": 0.1253,
      "step": 6537
    },
    {
      "epoch": 1.5022977941176472,
      "grad_norm": 2.334585428237915,
      "learning_rate": 7.773692810457517e-06,
      "loss": 0.1256,
      "step": 6538
    },
    {
      "epoch": 1.5025275735294117,
      "grad_norm": 1.5548946857452393,
      "learning_rate": 7.773182189542485e-06,
      "loss": 0.0957,
      "step": 6539
    },
    {
      "epoch": 1.5027573529411766,
      "grad_norm": 1.8387320041656494,
      "learning_rate": 7.772671568627451e-06,
      "loss": 0.1306,
      "step": 6540
    },
    {
      "epoch": 1.5029871323529411,
      "grad_norm": 1.4128185510635376,
      "learning_rate": 7.772160947712419e-06,
      "loss": 0.0945,
      "step": 6541
    },
    {
      "epoch": 1.5032169117647058,
      "grad_norm": 1.505167841911316,
      "learning_rate": 7.771650326797387e-06,
      "loss": 0.1286,
      "step": 6542
    },
    {
      "epoch": 1.5034466911764706,
      "grad_norm": 1.9296311140060425,
      "learning_rate": 7.771139705882353e-06,
      "loss": 0.1209,
      "step": 6543
    },
    {
      "epoch": 1.5036764705882353,
      "grad_norm": 1.722499132156372,
      "learning_rate": 7.77062908496732e-06,
      "loss": 0.1176,
      "step": 6544
    },
    {
      "epoch": 1.50390625,
      "grad_norm": 1.6191673278808594,
      "learning_rate": 7.770118464052289e-06,
      "loss": 0.1038,
      "step": 6545
    },
    {
      "epoch": 1.5041360294117647,
      "grad_norm": 2.0686521530151367,
      "learning_rate": 7.769607843137256e-06,
      "loss": 0.1395,
      "step": 6546
    },
    {
      "epoch": 1.5043658088235294,
      "grad_norm": 1.7157070636749268,
      "learning_rate": 7.769097222222223e-06,
      "loss": 0.1248,
      "step": 6547
    },
    {
      "epoch": 1.5045955882352942,
      "grad_norm": 1.5593996047973633,
      "learning_rate": 7.76858660130719e-06,
      "loss": 0.122,
      "step": 6548
    },
    {
      "epoch": 1.5048253676470589,
      "grad_norm": 1.325546145439148,
      "learning_rate": 7.768075980392158e-06,
      "loss": 0.0916,
      "step": 6549
    },
    {
      "epoch": 1.5050551470588234,
      "grad_norm": 1.4194189310073853,
      "learning_rate": 7.767565359477125e-06,
      "loss": 0.0973,
      "step": 6550
    },
    {
      "epoch": 1.5052849264705883,
      "grad_norm": 2.152024745941162,
      "learning_rate": 7.767054738562092e-06,
      "loss": 0.136,
      "step": 6551
    },
    {
      "epoch": 1.5055147058823528,
      "grad_norm": 1.793866515159607,
      "learning_rate": 7.766544117647059e-06,
      "loss": 0.1097,
      "step": 6552
    },
    {
      "epoch": 1.5057444852941178,
      "grad_norm": 1.6596660614013672,
      "learning_rate": 7.766033496732026e-06,
      "loss": 0.1582,
      "step": 6553
    },
    {
      "epoch": 1.5059742647058822,
      "grad_norm": 1.370883584022522,
      "learning_rate": 7.765522875816994e-06,
      "loss": 0.0898,
      "step": 6554
    },
    {
      "epoch": 1.5062040441176472,
      "grad_norm": 1.4040471315383911,
      "learning_rate": 7.765012254901962e-06,
      "loss": 0.1063,
      "step": 6555
    },
    {
      "epoch": 1.5064338235294117,
      "grad_norm": 1.6184674501419067,
      "learning_rate": 7.764501633986928e-06,
      "loss": 0.0992,
      "step": 6556
    },
    {
      "epoch": 1.5066636029411766,
      "grad_norm": 1.162453532218933,
      "learning_rate": 7.763991013071896e-06,
      "loss": 0.0882,
      "step": 6557
    },
    {
      "epoch": 1.5068933823529411,
      "grad_norm": 1.6034895181655884,
      "learning_rate": 7.763480392156864e-06,
      "loss": 0.1084,
      "step": 6558
    },
    {
      "epoch": 1.5071231617647058,
      "grad_norm": 1.332210898399353,
      "learning_rate": 7.76296977124183e-06,
      "loss": 0.0752,
      "step": 6559
    },
    {
      "epoch": 1.5073529411764706,
      "grad_norm": 1.3939414024353027,
      "learning_rate": 7.762459150326798e-06,
      "loss": 0.1102,
      "step": 6560
    },
    {
      "epoch": 1.5075827205882353,
      "grad_norm": 1.8973054885864258,
      "learning_rate": 7.761948529411766e-06,
      "loss": 0.1823,
      "step": 6561
    },
    {
      "epoch": 1.5078125,
      "grad_norm": 1.5148228406906128,
      "learning_rate": 7.761437908496732e-06,
      "loss": 0.1151,
      "step": 6562
    },
    {
      "epoch": 1.5080422794117647,
      "grad_norm": 1.6858645677566528,
      "learning_rate": 7.7609272875817e-06,
      "loss": 0.1202,
      "step": 6563
    },
    {
      "epoch": 1.5082720588235294,
      "grad_norm": 2.227370262145996,
      "learning_rate": 7.760416666666666e-06,
      "loss": 0.15,
      "step": 6564
    },
    {
      "epoch": 1.5085018382352942,
      "grad_norm": 1.6040823459625244,
      "learning_rate": 7.759906045751636e-06,
      "loss": 0.1221,
      "step": 6565
    },
    {
      "epoch": 1.5087316176470589,
      "grad_norm": 2.148413896560669,
      "learning_rate": 7.759395424836602e-06,
      "loss": 0.1361,
      "step": 6566
    },
    {
      "epoch": 1.5089613970588234,
      "grad_norm": 1.6655932664871216,
      "learning_rate": 7.75888480392157e-06,
      "loss": 0.12,
      "step": 6567
    },
    {
      "epoch": 1.5091911764705883,
      "grad_norm": 1.3926993608474731,
      "learning_rate": 7.758374183006536e-06,
      "loss": 0.085,
      "step": 6568
    },
    {
      "epoch": 1.5094209558823528,
      "grad_norm": 2.5384457111358643,
      "learning_rate": 7.757863562091504e-06,
      "loss": 0.1504,
      "step": 6569
    },
    {
      "epoch": 1.5096507352941178,
      "grad_norm": 1.792952537536621,
      "learning_rate": 7.757352941176472e-06,
      "loss": 0.13,
      "step": 6570
    },
    {
      "epoch": 1.5098805147058822,
      "grad_norm": 1.49595308303833,
      "learning_rate": 7.756842320261438e-06,
      "loss": 0.1225,
      "step": 6571
    },
    {
      "epoch": 1.5101102941176472,
      "grad_norm": 1.447761058807373,
      "learning_rate": 7.756331699346406e-06,
      "loss": 0.1136,
      "step": 6572
    },
    {
      "epoch": 1.5103400735294117,
      "grad_norm": 1.9760972261428833,
      "learning_rate": 7.755821078431373e-06,
      "loss": 0.1358,
      "step": 6573
    },
    {
      "epoch": 1.5105698529411766,
      "grad_norm": 1.4171364307403564,
      "learning_rate": 7.755310457516341e-06,
      "loss": 0.1089,
      "step": 6574
    },
    {
      "epoch": 1.5107996323529411,
      "grad_norm": 1.4255186319351196,
      "learning_rate": 7.754799836601308e-06,
      "loss": 0.1396,
      "step": 6575
    },
    {
      "epoch": 1.5110294117647058,
      "grad_norm": 1.7312414646148682,
      "learning_rate": 7.754289215686275e-06,
      "loss": 0.1468,
      "step": 6576
    },
    {
      "epoch": 1.5112591911764706,
      "grad_norm": 1.516601324081421,
      "learning_rate": 7.753778594771243e-06,
      "loss": 0.0997,
      "step": 6577
    },
    {
      "epoch": 1.5114889705882353,
      "grad_norm": 1.4008666276931763,
      "learning_rate": 7.75326797385621e-06,
      "loss": 0.0972,
      "step": 6578
    },
    {
      "epoch": 1.51171875,
      "grad_norm": 2.0702567100524902,
      "learning_rate": 7.752757352941177e-06,
      "loss": 0.1297,
      "step": 6579
    },
    {
      "epoch": 1.5119485294117647,
      "grad_norm": 1.9734619855880737,
      "learning_rate": 7.752246732026143e-06,
      "loss": 0.1673,
      "step": 6580
    },
    {
      "epoch": 1.5121783088235294,
      "grad_norm": 1.582106351852417,
      "learning_rate": 7.751736111111113e-06,
      "loss": 0.1111,
      "step": 6581
    },
    {
      "epoch": 1.5124080882352942,
      "grad_norm": 1.7926305532455444,
      "learning_rate": 7.75122549019608e-06,
      "loss": 0.1057,
      "step": 6582
    },
    {
      "epoch": 1.5126378676470589,
      "grad_norm": 1.392198920249939,
      "learning_rate": 7.750714869281047e-06,
      "loss": 0.09,
      "step": 6583
    },
    {
      "epoch": 1.5128676470588234,
      "grad_norm": 1.9152286052703857,
      "learning_rate": 7.750204248366013e-06,
      "loss": 0.1134,
      "step": 6584
    },
    {
      "epoch": 1.5130974264705883,
      "grad_norm": 1.685314416885376,
      "learning_rate": 7.749693627450981e-06,
      "loss": 0.1514,
      "step": 6585
    },
    {
      "epoch": 1.5133272058823528,
      "grad_norm": 1.2774633169174194,
      "learning_rate": 7.749183006535949e-06,
      "loss": 0.1031,
      "step": 6586
    },
    {
      "epoch": 1.5135569852941178,
      "grad_norm": 1.374980092048645,
      "learning_rate": 7.748672385620915e-06,
      "loss": 0.1117,
      "step": 6587
    },
    {
      "epoch": 1.5137867647058822,
      "grad_norm": 1.6283257007598877,
      "learning_rate": 7.748161764705883e-06,
      "loss": 0.1405,
      "step": 6588
    },
    {
      "epoch": 1.5140165441176472,
      "grad_norm": 1.846102237701416,
      "learning_rate": 7.74765114379085e-06,
      "loss": 0.1149,
      "step": 6589
    },
    {
      "epoch": 1.5142463235294117,
      "grad_norm": 1.6405532360076904,
      "learning_rate": 7.747140522875819e-06,
      "loss": 0.0899,
      "step": 6590
    },
    {
      "epoch": 1.5144761029411766,
      "grad_norm": 1.8719595670700073,
      "learning_rate": 7.746629901960785e-06,
      "loss": 0.102,
      "step": 6591
    },
    {
      "epoch": 1.5147058823529411,
      "grad_norm": 1.3397043943405151,
      "learning_rate": 7.746119281045753e-06,
      "loss": 0.0878,
      "step": 6592
    },
    {
      "epoch": 1.5149356617647058,
      "grad_norm": 2.0229074954986572,
      "learning_rate": 7.74560866013072e-06,
      "loss": 0.1372,
      "step": 6593
    },
    {
      "epoch": 1.5151654411764706,
      "grad_norm": 1.4904968738555908,
      "learning_rate": 7.745098039215687e-06,
      "loss": 0.109,
      "step": 6594
    },
    {
      "epoch": 1.5153952205882353,
      "grad_norm": 2.0414204597473145,
      "learning_rate": 7.744587418300655e-06,
      "loss": 0.1258,
      "step": 6595
    },
    {
      "epoch": 1.515625,
      "grad_norm": 1.667822241783142,
      "learning_rate": 7.74407679738562e-06,
      "loss": 0.1248,
      "step": 6596
    },
    {
      "epoch": 1.5158547794117647,
      "grad_norm": 2.270496368408203,
      "learning_rate": 7.743566176470589e-06,
      "loss": 0.1624,
      "step": 6597
    },
    {
      "epoch": 1.5160845588235294,
      "grad_norm": 1.6998599767684937,
      "learning_rate": 7.743055555555556e-06,
      "loss": 0.1645,
      "step": 6598
    },
    {
      "epoch": 1.5163143382352942,
      "grad_norm": 1.260356068611145,
      "learning_rate": 7.742544934640523e-06,
      "loss": 0.0997,
      "step": 6599
    },
    {
      "epoch": 1.5165441176470589,
      "grad_norm": 1.7908203601837158,
      "learning_rate": 7.74203431372549e-06,
      "loss": 0.161,
      "step": 6600
    },
    {
      "epoch": 1.5167738970588234,
      "grad_norm": 1.5445044040679932,
      "learning_rate": 7.741523692810458e-06,
      "loss": 0.1024,
      "step": 6601
    },
    {
      "epoch": 1.5170036764705883,
      "grad_norm": 1.6300759315490723,
      "learning_rate": 7.741013071895426e-06,
      "loss": 0.1241,
      "step": 6602
    },
    {
      "epoch": 1.5172334558823528,
      "grad_norm": 2.4562995433807373,
      "learning_rate": 7.740502450980392e-06,
      "loss": 0.1526,
      "step": 6603
    },
    {
      "epoch": 1.5174632352941178,
      "grad_norm": 1.305787444114685,
      "learning_rate": 7.73999183006536e-06,
      "loss": 0.0823,
      "step": 6604
    },
    {
      "epoch": 1.5176930147058822,
      "grad_norm": 1.3587323427200317,
      "learning_rate": 7.739481209150328e-06,
      "loss": 0.0888,
      "step": 6605
    },
    {
      "epoch": 1.5179227941176472,
      "grad_norm": 1.7922486066818237,
      "learning_rate": 7.738970588235294e-06,
      "loss": 0.1375,
      "step": 6606
    },
    {
      "epoch": 1.5181525735294117,
      "grad_norm": 1.7371474504470825,
      "learning_rate": 7.738459967320262e-06,
      "loss": 0.0904,
      "step": 6607
    },
    {
      "epoch": 1.5183823529411766,
      "grad_norm": 1.1768993139266968,
      "learning_rate": 7.737949346405228e-06,
      "loss": 0.0899,
      "step": 6608
    },
    {
      "epoch": 1.5186121323529411,
      "grad_norm": 1.5509856939315796,
      "learning_rate": 7.737438725490198e-06,
      "loss": 0.0949,
      "step": 6609
    },
    {
      "epoch": 1.5188419117647058,
      "grad_norm": 1.3633430004119873,
      "learning_rate": 7.736928104575164e-06,
      "loss": 0.0935,
      "step": 6610
    },
    {
      "epoch": 1.5190716911764706,
      "grad_norm": 2.1681485176086426,
      "learning_rate": 7.736417483660132e-06,
      "loss": 0.1087,
      "step": 6611
    },
    {
      "epoch": 1.5193014705882353,
      "grad_norm": 1.6643435955047607,
      "learning_rate": 7.735906862745098e-06,
      "loss": 0.1102,
      "step": 6612
    },
    {
      "epoch": 1.51953125,
      "grad_norm": 1.8910208940505981,
      "learning_rate": 7.735396241830066e-06,
      "loss": 0.0993,
      "step": 6613
    },
    {
      "epoch": 1.5197610294117647,
      "grad_norm": 1.6750733852386475,
      "learning_rate": 7.734885620915034e-06,
      "loss": 0.1147,
      "step": 6614
    },
    {
      "epoch": 1.5199908088235294,
      "grad_norm": 1.5768659114837646,
      "learning_rate": 7.734375e-06,
      "loss": 0.1256,
      "step": 6615
    },
    {
      "epoch": 1.5202205882352942,
      "grad_norm": 1.3356847763061523,
      "learning_rate": 7.733864379084968e-06,
      "loss": 0.063,
      "step": 6616
    },
    {
      "epoch": 1.5204503676470589,
      "grad_norm": 1.6961030960083008,
      "learning_rate": 7.733353758169934e-06,
      "loss": 0.1168,
      "step": 6617
    },
    {
      "epoch": 1.5206801470588234,
      "grad_norm": 1.6028056144714355,
      "learning_rate": 7.732843137254904e-06,
      "loss": 0.1456,
      "step": 6618
    },
    {
      "epoch": 1.5209099264705883,
      "grad_norm": 2.046267509460449,
      "learning_rate": 7.73233251633987e-06,
      "loss": 0.1338,
      "step": 6619
    },
    {
      "epoch": 1.5211397058823528,
      "grad_norm": 1.4079304933547974,
      "learning_rate": 7.731821895424838e-06,
      "loss": 0.0914,
      "step": 6620
    },
    {
      "epoch": 1.5213694852941178,
      "grad_norm": 1.6866613626480103,
      "learning_rate": 7.731311274509804e-06,
      "loss": 0.1015,
      "step": 6621
    },
    {
      "epoch": 1.5215992647058822,
      "grad_norm": 2.114499807357788,
      "learning_rate": 7.730800653594772e-06,
      "loss": 0.1642,
      "step": 6622
    },
    {
      "epoch": 1.5218290441176472,
      "grad_norm": 2.5739905834198,
      "learning_rate": 7.73029003267974e-06,
      "loss": 0.1217,
      "step": 6623
    },
    {
      "epoch": 1.5220588235294117,
      "grad_norm": 1.18434739112854,
      "learning_rate": 7.729779411764706e-06,
      "loss": 0.0767,
      "step": 6624
    },
    {
      "epoch": 1.5222886029411766,
      "grad_norm": 2.1405014991760254,
      "learning_rate": 7.729268790849673e-06,
      "loss": 0.1695,
      "step": 6625
    },
    {
      "epoch": 1.5225183823529411,
      "grad_norm": 2.1554791927337646,
      "learning_rate": 7.728758169934641e-06,
      "loss": 0.1083,
      "step": 6626
    },
    {
      "epoch": 1.5227481617647058,
      "grad_norm": 1.5089775323867798,
      "learning_rate": 7.72824754901961e-06,
      "loss": 0.1125,
      "step": 6627
    },
    {
      "epoch": 1.5229779411764706,
      "grad_norm": 1.3251603841781616,
      "learning_rate": 7.727736928104575e-06,
      "loss": 0.1138,
      "step": 6628
    },
    {
      "epoch": 1.5232077205882353,
      "grad_norm": 2.4354186058044434,
      "learning_rate": 7.727226307189543e-06,
      "loss": 0.1097,
      "step": 6629
    },
    {
      "epoch": 1.5234375,
      "grad_norm": 1.456279993057251,
      "learning_rate": 7.726715686274511e-06,
      "loss": 0.1073,
      "step": 6630
    },
    {
      "epoch": 1.5236672794117647,
      "grad_norm": 1.7683964967727661,
      "learning_rate": 7.726205065359477e-06,
      "loss": 0.1008,
      "step": 6631
    },
    {
      "epoch": 1.5238970588235294,
      "grad_norm": 1.5610300302505493,
      "learning_rate": 7.725694444444445e-06,
      "loss": 0.0967,
      "step": 6632
    },
    {
      "epoch": 1.5241268382352942,
      "grad_norm": 1.39585542678833,
      "learning_rate": 7.725183823529411e-06,
      "loss": 0.099,
      "step": 6633
    },
    {
      "epoch": 1.5243566176470589,
      "grad_norm": 1.4619828462600708,
      "learning_rate": 7.724673202614381e-06,
      "loss": 0.1117,
      "step": 6634
    },
    {
      "epoch": 1.5245863970588234,
      "grad_norm": 1.914101243019104,
      "learning_rate": 7.724162581699347e-06,
      "loss": 0.1357,
      "step": 6635
    },
    {
      "epoch": 1.5248161764705883,
      "grad_norm": 1.6731181144714355,
      "learning_rate": 7.723651960784315e-06,
      "loss": 0.1664,
      "step": 6636
    },
    {
      "epoch": 1.5250459558823528,
      "grad_norm": 1.6366677284240723,
      "learning_rate": 7.723141339869281e-06,
      "loss": 0.0996,
      "step": 6637
    },
    {
      "epoch": 1.5252757352941178,
      "grad_norm": 1.4608389139175415,
      "learning_rate": 7.722630718954249e-06,
      "loss": 0.1261,
      "step": 6638
    },
    {
      "epoch": 1.5255055147058822,
      "grad_norm": 1.6472973823547363,
      "learning_rate": 7.722120098039217e-06,
      "loss": 0.1015,
      "step": 6639
    },
    {
      "epoch": 1.5257352941176472,
      "grad_norm": 1.4818321466445923,
      "learning_rate": 7.721609477124183e-06,
      "loss": 0.0762,
      "step": 6640
    },
    {
      "epoch": 1.5259650735294117,
      "grad_norm": 1.3594516515731812,
      "learning_rate": 7.72109885620915e-06,
      "loss": 0.1266,
      "step": 6641
    },
    {
      "epoch": 1.5261948529411766,
      "grad_norm": 2.1722335815429688,
      "learning_rate": 7.720588235294119e-06,
      "loss": 0.0992,
      "step": 6642
    },
    {
      "epoch": 1.5264246323529411,
      "grad_norm": 1.5639233589172363,
      "learning_rate": 7.720077614379085e-06,
      "loss": 0.1371,
      "step": 6643
    },
    {
      "epoch": 1.5266544117647058,
      "grad_norm": 1.6848468780517578,
      "learning_rate": 7.719566993464053e-06,
      "loss": 0.1041,
      "step": 6644
    },
    {
      "epoch": 1.5268841911764706,
      "grad_norm": 1.7206876277923584,
      "learning_rate": 7.71905637254902e-06,
      "loss": 0.102,
      "step": 6645
    },
    {
      "epoch": 1.5271139705882353,
      "grad_norm": 1.7338017225265503,
      "learning_rate": 7.718545751633988e-06,
      "loss": 0.1133,
      "step": 6646
    },
    {
      "epoch": 1.52734375,
      "grad_norm": 1.8884153366088867,
      "learning_rate": 7.718035130718955e-06,
      "loss": 0.1076,
      "step": 6647
    },
    {
      "epoch": 1.5275735294117647,
      "grad_norm": Infinity,
      "learning_rate": 7.717524509803922e-06,
      "loss": 0.1469,
      "step": 6648
    },
    {
      "epoch": 1.5278033088235294,
      "grad_norm": 2.0012383460998535,
      "learning_rate": 7.717524509803922e-06,
      "loss": 0.1094,
      "step": 6649
    },
    {
      "epoch": 1.5280330882352942,
      "grad_norm": 2.710188627243042,
      "learning_rate": 7.717013888888889e-06,
      "loss": 0.117,
      "step": 6650
    },
    {
      "epoch": 1.5282628676470589,
      "grad_norm": 1.6778589487075806,
      "learning_rate": 7.716503267973856e-06,
      "loss": 0.1491,
      "step": 6651
    },
    {
      "epoch": 1.5284926470588234,
      "grad_norm": 1.6658862829208374,
      "learning_rate": 7.715992647058824e-06,
      "loss": 0.1514,
      "step": 6652
    },
    {
      "epoch": 1.5287224264705883,
      "grad_norm": 1.5978113412857056,
      "learning_rate": 7.71548202614379e-06,
      "loss": 0.1086,
      "step": 6653
    },
    {
      "epoch": 1.5289522058823528,
      "grad_norm": 2.0418777465820312,
      "learning_rate": 7.714971405228758e-06,
      "loss": 0.1054,
      "step": 6654
    },
    {
      "epoch": 1.5291819852941178,
      "grad_norm": 1.586124062538147,
      "learning_rate": 7.714460784313726e-06,
      "loss": 0.1306,
      "step": 6655
    },
    {
      "epoch": 1.5294117647058822,
      "grad_norm": 1.9440845251083374,
      "learning_rate": 7.713950163398694e-06,
      "loss": 0.164,
      "step": 6656
    },
    {
      "epoch": 1.5296415441176472,
      "grad_norm": 1.8469241857528687,
      "learning_rate": 7.71343954248366e-06,
      "loss": 0.1424,
      "step": 6657
    },
    {
      "epoch": 1.5298713235294117,
      "grad_norm": 1.7492860555648804,
      "learning_rate": 7.712928921568628e-06,
      "loss": 0.1231,
      "step": 6658
    },
    {
      "epoch": 1.5301011029411766,
      "grad_norm": 2.105741500854492,
      "learning_rate": 7.712418300653596e-06,
      "loss": 0.084,
      "step": 6659
    },
    {
      "epoch": 1.5303308823529411,
      "grad_norm": 1.3934787511825562,
      "learning_rate": 7.711907679738562e-06,
      "loss": 0.0649,
      "step": 6660
    },
    {
      "epoch": 1.5305606617647058,
      "grad_norm": 1.8668467998504639,
      "learning_rate": 7.71139705882353e-06,
      "loss": 0.1625,
      "step": 6661
    },
    {
      "epoch": 1.5307904411764706,
      "grad_norm": 1.9326484203338623,
      "learning_rate": 7.710886437908496e-06,
      "loss": 0.1096,
      "step": 6662
    },
    {
      "epoch": 1.5310202205882353,
      "grad_norm": 1.934067726135254,
      "learning_rate": 7.710375816993466e-06,
      "loss": 0.1033,
      "step": 6663
    },
    {
      "epoch": 1.53125,
      "grad_norm": 1.7349520921707153,
      "learning_rate": 7.709865196078432e-06,
      "loss": 0.1309,
      "step": 6664
    },
    {
      "epoch": 1.5314797794117647,
      "grad_norm": 2.231346368789673,
      "learning_rate": 7.7093545751634e-06,
      "loss": 0.1369,
      "step": 6665
    },
    {
      "epoch": 1.5317095588235294,
      "grad_norm": 2.116525173187256,
      "learning_rate": 7.708843954248366e-06,
      "loss": 0.1124,
      "step": 6666
    },
    {
      "epoch": 1.5319393382352942,
      "grad_norm": 1.3960446119308472,
      "learning_rate": 7.708333333333334e-06,
      "loss": 0.1281,
      "step": 6667
    },
    {
      "epoch": 1.5321691176470589,
      "grad_norm": 1.3560009002685547,
      "learning_rate": 7.707822712418302e-06,
      "loss": 0.1087,
      "step": 6668
    },
    {
      "epoch": 1.5323988970588234,
      "grad_norm": 1.8541244268417358,
      "learning_rate": 7.707312091503268e-06,
      "loss": 0.1044,
      "step": 6669
    },
    {
      "epoch": 1.5326286764705883,
      "grad_norm": 1.2219018936157227,
      "learning_rate": 7.706801470588236e-06,
      "loss": 0.0711,
      "step": 6670
    },
    {
      "epoch": 1.5328584558823528,
      "grad_norm": 1.5453482866287231,
      "learning_rate": 7.706290849673204e-06,
      "loss": 0.1128,
      "step": 6671
    },
    {
      "epoch": 1.5330882352941178,
      "grad_norm": 1.4499261379241943,
      "learning_rate": 7.705780228758171e-06,
      "loss": 0.124,
      "step": 6672
    },
    {
      "epoch": 1.5333180147058822,
      "grad_norm": 1.911388635635376,
      "learning_rate": 7.705269607843138e-06,
      "loss": 0.1284,
      "step": 6673
    },
    {
      "epoch": 1.5335477941176472,
      "grad_norm": 1.4015135765075684,
      "learning_rate": 7.704758986928105e-06,
      "loss": 0.1145,
      "step": 6674
    },
    {
      "epoch": 1.5337775735294117,
      "grad_norm": 1.3395358324050903,
      "learning_rate": 7.704248366013073e-06,
      "loss": 0.1047,
      "step": 6675
    },
    {
      "epoch": 1.5340073529411766,
      "grad_norm": 1.538663387298584,
      "learning_rate": 7.70373774509804e-06,
      "loss": 0.1236,
      "step": 6676
    },
    {
      "epoch": 1.5342371323529411,
      "grad_norm": 1.5182616710662842,
      "learning_rate": 7.703227124183007e-06,
      "loss": 0.1407,
      "step": 6677
    },
    {
      "epoch": 1.5344669117647058,
      "grad_norm": 2.1221413612365723,
      "learning_rate": 7.702716503267973e-06,
      "loss": 0.1403,
      "step": 6678
    },
    {
      "epoch": 1.5346966911764706,
      "grad_norm": 1.8893963098526,
      "learning_rate": 7.702205882352943e-06,
      "loss": 0.1655,
      "step": 6679
    },
    {
      "epoch": 1.5349264705882353,
      "grad_norm": 2.082390308380127,
      "learning_rate": 7.70169526143791e-06,
      "loss": 0.159,
      "step": 6680
    },
    {
      "epoch": 1.53515625,
      "grad_norm": 1.70367431640625,
      "learning_rate": 7.701184640522877e-06,
      "loss": 0.1498,
      "step": 6681
    },
    {
      "epoch": 1.5353860294117647,
      "grad_norm": 1.5643450021743774,
      "learning_rate": 7.700674019607843e-06,
      "loss": 0.1145,
      "step": 6682
    },
    {
      "epoch": 1.5356158088235294,
      "grad_norm": 2.0256569385528564,
      "learning_rate": 7.700163398692811e-06,
      "loss": 0.0999,
      "step": 6683
    },
    {
      "epoch": 1.5358455882352942,
      "grad_norm": 1.7313212156295776,
      "learning_rate": 7.699652777777779e-06,
      "loss": 0.0954,
      "step": 6684
    },
    {
      "epoch": 1.5360753676470589,
      "grad_norm": 1.8728265762329102,
      "learning_rate": 7.699142156862745e-06,
      "loss": 0.1192,
      "step": 6685
    },
    {
      "epoch": 1.5363051470588234,
      "grad_norm": 1.770992636680603,
      "learning_rate": 7.698631535947713e-06,
      "loss": 0.1157,
      "step": 6686
    },
    {
      "epoch": 1.5365349264705883,
      "grad_norm": 1.256036639213562,
      "learning_rate": 7.698120915032681e-06,
      "loss": 0.0994,
      "step": 6687
    },
    {
      "epoch": 1.5367647058823528,
      "grad_norm": 2.110137939453125,
      "learning_rate": 7.697610294117647e-06,
      "loss": 0.1333,
      "step": 6688
    },
    {
      "epoch": 1.5369944852941178,
      "grad_norm": 1.3088310956954956,
      "learning_rate": 7.697099673202615e-06,
      "loss": 0.1191,
      "step": 6689
    },
    {
      "epoch": 1.5372242647058822,
      "grad_norm": 1.5665581226348877,
      "learning_rate": 7.696589052287583e-06,
      "loss": 0.1135,
      "step": 6690
    },
    {
      "epoch": 1.5374540441176472,
      "grad_norm": 1.5974923372268677,
      "learning_rate": 7.69607843137255e-06,
      "loss": 0.1317,
      "step": 6691
    },
    {
      "epoch": 1.5376838235294117,
      "grad_norm": 1.6770224571228027,
      "learning_rate": 7.695567810457517e-06,
      "loss": 0.1321,
      "step": 6692
    },
    {
      "epoch": 1.5379136029411766,
      "grad_norm": 1.9131624698638916,
      "learning_rate": 7.695057189542485e-06,
      "loss": 0.1308,
      "step": 6693
    },
    {
      "epoch": 1.5381433823529411,
      "grad_norm": 1.4791065454483032,
      "learning_rate": 7.69454656862745e-06,
      "loss": 0.0984,
      "step": 6694
    },
    {
      "epoch": 1.5383731617647058,
      "grad_norm": 1.5812290906906128,
      "learning_rate": 7.694035947712419e-06,
      "loss": 0.1147,
      "step": 6695
    },
    {
      "epoch": 1.5386029411764706,
      "grad_norm": 1.5000134706497192,
      "learning_rate": 7.693525326797387e-06,
      "loss": 0.1399,
      "step": 6696
    },
    {
      "epoch": 1.5388327205882353,
      "grad_norm": 1.407224178314209,
      "learning_rate": 7.693014705882353e-06,
      "loss": 0.0991,
      "step": 6697
    },
    {
      "epoch": 1.5390625,
      "grad_norm": 2.2597239017486572,
      "learning_rate": 7.69250408496732e-06,
      "loss": 0.1552,
      "step": 6698
    },
    {
      "epoch": 1.5392922794117647,
      "grad_norm": 1.7643373012542725,
      "learning_rate": 7.691993464052288e-06,
      "loss": 0.1459,
      "step": 6699
    },
    {
      "epoch": 1.5395220588235294,
      "grad_norm": 2.3965349197387695,
      "learning_rate": 7.691482843137256e-06,
      "loss": 0.0992,
      "step": 6700
    },
    {
      "epoch": 1.5397518382352942,
      "grad_norm": 1.635398268699646,
      "learning_rate": 7.690972222222222e-06,
      "loss": 0.1193,
      "step": 6701
    },
    {
      "epoch": 1.5399816176470589,
      "grad_norm": 1.6124714612960815,
      "learning_rate": 7.69046160130719e-06,
      "loss": 0.1613,
      "step": 6702
    },
    {
      "epoch": 1.5402113970588234,
      "grad_norm": 1.3903967142105103,
      "learning_rate": 7.689950980392158e-06,
      "loss": 0.0887,
      "step": 6703
    },
    {
      "epoch": 1.5404411764705883,
      "grad_norm": 1.5638513565063477,
      "learning_rate": 7.689440359477124e-06,
      "loss": 0.1015,
      "step": 6704
    },
    {
      "epoch": 1.5406709558823528,
      "grad_norm": 1.3095812797546387,
      "learning_rate": 7.688929738562092e-06,
      "loss": 0.1227,
      "step": 6705
    },
    {
      "epoch": 1.5409007352941178,
      "grad_norm": 2.0261025428771973,
      "learning_rate": 7.688419117647058e-06,
      "loss": 0.1151,
      "step": 6706
    },
    {
      "epoch": 1.5411305147058822,
      "grad_norm": 1.9399967193603516,
      "learning_rate": 7.687908496732028e-06,
      "loss": 0.1246,
      "step": 6707
    },
    {
      "epoch": 1.5413602941176472,
      "grad_norm": 2.0459182262420654,
      "learning_rate": 7.687397875816994e-06,
      "loss": 0.1319,
      "step": 6708
    },
    {
      "epoch": 1.5415900735294117,
      "grad_norm": 2.027081251144409,
      "learning_rate": 7.686887254901962e-06,
      "loss": 0.1365,
      "step": 6709
    },
    {
      "epoch": 1.5418198529411766,
      "grad_norm": 1.8604308366775513,
      "learning_rate": 7.686376633986928e-06,
      "loss": 0.1465,
      "step": 6710
    },
    {
      "epoch": 1.5420496323529411,
      "grad_norm": 1.6644021272659302,
      "learning_rate": 7.685866013071896e-06,
      "loss": 0.1016,
      "step": 6711
    },
    {
      "epoch": 1.5422794117647058,
      "grad_norm": 1.7829312086105347,
      "learning_rate": 7.685355392156864e-06,
      "loss": 0.1333,
      "step": 6712
    },
    {
      "epoch": 1.5425091911764706,
      "grad_norm": 1.7367517948150635,
      "learning_rate": 7.68484477124183e-06,
      "loss": 0.0963,
      "step": 6713
    },
    {
      "epoch": 1.5427389705882353,
      "grad_norm": 1.9680202007293701,
      "learning_rate": 7.684334150326798e-06,
      "loss": 0.1554,
      "step": 6714
    },
    {
      "epoch": 1.54296875,
      "grad_norm": 1.7012836933135986,
      "learning_rate": 7.683823529411766e-06,
      "loss": 0.1574,
      "step": 6715
    },
    {
      "epoch": 1.5431985294117647,
      "grad_norm": 1.843477725982666,
      "learning_rate": 7.683312908496734e-06,
      "loss": 0.1439,
      "step": 6716
    },
    {
      "epoch": 1.5434283088235294,
      "grad_norm": 1.584241509437561,
      "learning_rate": 7.6828022875817e-06,
      "loss": 0.1694,
      "step": 6717
    },
    {
      "epoch": 1.5436580882352942,
      "grad_norm": 1.596409797668457,
      "learning_rate": 7.682291666666668e-06,
      "loss": 0.0931,
      "step": 6718
    },
    {
      "epoch": 1.5438878676470589,
      "grad_norm": 2.2575039863586426,
      "learning_rate": 7.681781045751635e-06,
      "loss": 0.1294,
      "step": 6719
    },
    {
      "epoch": 1.5441176470588234,
      "grad_norm": 1.4380102157592773,
      "learning_rate": 7.681270424836602e-06,
      "loss": 0.1082,
      "step": 6720
    },
    {
      "epoch": 1.5443474264705883,
      "grad_norm": 1.6443791389465332,
      "learning_rate": 7.68075980392157e-06,
      "loss": 0.0974,
      "step": 6721
    },
    {
      "epoch": 1.5445772058823528,
      "grad_norm": 1.9201469421386719,
      "learning_rate": 7.680249183006536e-06,
      "loss": 0.107,
      "step": 6722
    },
    {
      "epoch": 1.5448069852941178,
      "grad_norm": 1.420143961906433,
      "learning_rate": 7.679738562091504e-06,
      "loss": 0.1397,
      "step": 6723
    },
    {
      "epoch": 1.5450367647058822,
      "grad_norm": 1.8358474969863892,
      "learning_rate": 7.679227941176471e-06,
      "loss": 0.1141,
      "step": 6724
    },
    {
      "epoch": 1.5452665441176472,
      "grad_norm": 1.85722017288208,
      "learning_rate": 7.67871732026144e-06,
      "loss": 0.1543,
      "step": 6725
    },
    {
      "epoch": 1.5454963235294117,
      "grad_norm": 1.9375803470611572,
      "learning_rate": 7.678206699346405e-06,
      "loss": 0.1571,
      "step": 6726
    },
    {
      "epoch": 1.5457261029411766,
      "grad_norm": 1.531138300895691,
      "learning_rate": 7.677696078431373e-06,
      "loss": 0.1268,
      "step": 6727
    },
    {
      "epoch": 1.5459558823529411,
      "grad_norm": 1.5622296333312988,
      "learning_rate": 7.677185457516341e-06,
      "loss": 0.1149,
      "step": 6728
    },
    {
      "epoch": 1.5461856617647058,
      "grad_norm": 2.0875699520111084,
      "learning_rate": 7.676674836601307e-06,
      "loss": 0.1709,
      "step": 6729
    },
    {
      "epoch": 1.5464154411764706,
      "grad_norm": 1.79267156124115,
      "learning_rate": 7.676164215686275e-06,
      "loss": 0.1313,
      "step": 6730
    },
    {
      "epoch": 1.5466452205882353,
      "grad_norm": 1.5697298049926758,
      "learning_rate": 7.675653594771243e-06,
      "loss": 0.1158,
      "step": 6731
    },
    {
      "epoch": 1.546875,
      "grad_norm": 2.107767105102539,
      "learning_rate": 7.67514297385621e-06,
      "loss": 0.1354,
      "step": 6732
    },
    {
      "epoch": 1.5471047794117647,
      "grad_norm": 2.5925562381744385,
      "learning_rate": 7.674632352941177e-06,
      "loss": 0.1495,
      "step": 6733
    },
    {
      "epoch": 1.5473345588235294,
      "grad_norm": 1.743855595588684,
      "learning_rate": 7.674121732026143e-06,
      "loss": 0.1117,
      "step": 6734
    },
    {
      "epoch": 1.5475643382352942,
      "grad_norm": 1.7353668212890625,
      "learning_rate": 7.673611111111113e-06,
      "loss": 0.1222,
      "step": 6735
    },
    {
      "epoch": 1.5477941176470589,
      "grad_norm": 1.1606522798538208,
      "learning_rate": 7.673100490196079e-06,
      "loss": 0.0782,
      "step": 6736
    },
    {
      "epoch": 1.5480238970588234,
      "grad_norm": 1.9553170204162598,
      "learning_rate": 7.672589869281047e-06,
      "loss": 0.1509,
      "step": 6737
    },
    {
      "epoch": 1.5482536764705883,
      "grad_norm": 1.6983150243759155,
      "learning_rate": 7.672079248366013e-06,
      "loss": 0.147,
      "step": 6738
    },
    {
      "epoch": 1.5484834558823528,
      "grad_norm": 1.5456615686416626,
      "learning_rate": 7.671568627450981e-06,
      "loss": 0.1239,
      "step": 6739
    },
    {
      "epoch": 1.5487132352941178,
      "grad_norm": 1.3917186260223389,
      "learning_rate": 7.671058006535949e-06,
      "loss": 0.1032,
      "step": 6740
    },
    {
      "epoch": 1.5489430147058822,
      "grad_norm": 1.991621494293213,
      "learning_rate": 7.670547385620915e-06,
      "loss": 0.1158,
      "step": 6741
    },
    {
      "epoch": 1.5491727941176472,
      "grad_norm": 1.5809167623519897,
      "learning_rate": 7.670036764705883e-06,
      "loss": 0.1155,
      "step": 6742
    },
    {
      "epoch": 1.5494025735294117,
      "grad_norm": 2.1538219451904297,
      "learning_rate": 7.66952614379085e-06,
      "loss": 0.1234,
      "step": 6743
    },
    {
      "epoch": 1.5496323529411766,
      "grad_norm": 2.4316306114196777,
      "learning_rate": 7.669015522875818e-06,
      "loss": 0.1352,
      "step": 6744
    },
    {
      "epoch": 1.5498621323529411,
      "grad_norm": 1.877044677734375,
      "learning_rate": 7.668504901960785e-06,
      "loss": 0.0962,
      "step": 6745
    },
    {
      "epoch": 1.5500919117647058,
      "grad_norm": 1.5883342027664185,
      "learning_rate": 7.667994281045752e-06,
      "loss": 0.1202,
      "step": 6746
    },
    {
      "epoch": 1.5503216911764706,
      "grad_norm": 1.3001148700714111,
      "learning_rate": 7.66748366013072e-06,
      "loss": 0.1085,
      "step": 6747
    },
    {
      "epoch": 1.5505514705882353,
      "grad_norm": 1.5013412237167358,
      "learning_rate": 7.666973039215687e-06,
      "loss": 0.1179,
      "step": 6748
    },
    {
      "epoch": 1.55078125,
      "grad_norm": 2.2392518520355225,
      "learning_rate": 7.666462418300654e-06,
      "loss": 0.1446,
      "step": 6749
    },
    {
      "epoch": 1.5510110294117647,
      "grad_norm": 2.048269271850586,
      "learning_rate": 7.66595179738562e-06,
      "loss": 0.1795,
      "step": 6750
    },
    {
      "epoch": 1.5512408088235294,
      "grad_norm": 1.2479496002197266,
      "learning_rate": 7.66544117647059e-06,
      "loss": 0.1007,
      "step": 6751
    },
    {
      "epoch": 1.5514705882352942,
      "grad_norm": 1.6291531324386597,
      "learning_rate": 7.664930555555556e-06,
      "loss": 0.1093,
      "step": 6752
    },
    {
      "epoch": 1.5517003676470589,
      "grad_norm": 1.7755401134490967,
      "learning_rate": 7.664419934640524e-06,
      "loss": 0.1403,
      "step": 6753
    },
    {
      "epoch": 1.5519301470588234,
      "grad_norm": 1.4556951522827148,
      "learning_rate": 7.66390931372549e-06,
      "loss": 0.1208,
      "step": 6754
    },
    {
      "epoch": 1.5521599264705883,
      "grad_norm": 1.7792237997055054,
      "learning_rate": 7.663398692810458e-06,
      "loss": 0.1254,
      "step": 6755
    },
    {
      "epoch": 1.5523897058823528,
      "grad_norm": 1.489233136177063,
      "learning_rate": 7.662888071895426e-06,
      "loss": 0.0887,
      "step": 6756
    },
    {
      "epoch": 1.5526194852941178,
      "grad_norm": 1.658434510231018,
      "learning_rate": 7.662377450980392e-06,
      "loss": 0.1468,
      "step": 6757
    },
    {
      "epoch": 1.5528492647058822,
      "grad_norm": 2.5053763389587402,
      "learning_rate": 7.66186683006536e-06,
      "loss": 0.1129,
      "step": 6758
    },
    {
      "epoch": 1.5530790441176472,
      "grad_norm": 2.2470741271972656,
      "learning_rate": 7.661356209150328e-06,
      "loss": 0.1131,
      "step": 6759
    },
    {
      "epoch": 1.5533088235294117,
      "grad_norm": 1.630881428718567,
      "learning_rate": 7.660845588235296e-06,
      "loss": 0.126,
      "step": 6760
    },
    {
      "epoch": 1.5535386029411766,
      "grad_norm": 2.3548436164855957,
      "learning_rate": 7.660334967320262e-06,
      "loss": 0.1624,
      "step": 6761
    },
    {
      "epoch": 1.5537683823529411,
      "grad_norm": 1.532028317451477,
      "learning_rate": 7.65982434640523e-06,
      "loss": 0.1314,
      "step": 6762
    },
    {
      "epoch": 1.5539981617647058,
      "grad_norm": 1.444623351097107,
      "learning_rate": 7.659313725490198e-06,
      "loss": 0.1081,
      "step": 6763
    },
    {
      "epoch": 1.5542279411764706,
      "grad_norm": 1.7277169227600098,
      "learning_rate": 7.658803104575164e-06,
      "loss": 0.1272,
      "step": 6764
    },
    {
      "epoch": 1.5544577205882353,
      "grad_norm": 3.080113649368286,
      "learning_rate": 7.658292483660132e-06,
      "loss": 0.1919,
      "step": 6765
    },
    {
      "epoch": 1.5546875,
      "grad_norm": 1.7917637825012207,
      "learning_rate": 7.657781862745098e-06,
      "loss": 0.1117,
      "step": 6766
    },
    {
      "epoch": 1.5549172794117647,
      "grad_norm": 1.6567281484603882,
      "learning_rate": 7.657271241830066e-06,
      "loss": 0.1281,
      "step": 6767
    },
    {
      "epoch": 1.5551470588235294,
      "grad_norm": 1.4504061937332153,
      "learning_rate": 7.656760620915034e-06,
      "loss": 0.0944,
      "step": 6768
    },
    {
      "epoch": 1.5553768382352942,
      "grad_norm": 1.7969801425933838,
      "learning_rate": 7.656250000000001e-06,
      "loss": 0.1169,
      "step": 6769
    },
    {
      "epoch": 1.5556066176470589,
      "grad_norm": 1.5206481218338013,
      "learning_rate": 7.655739379084968e-06,
      "loss": 0.1102,
      "step": 6770
    },
    {
      "epoch": 1.5558363970588234,
      "grad_norm": 1.4588758945465088,
      "learning_rate": 7.655228758169935e-06,
      "loss": 0.1094,
      "step": 6771
    },
    {
      "epoch": 1.5560661764705883,
      "grad_norm": 1.2888524532318115,
      "learning_rate": 7.654718137254903e-06,
      "loss": 0.1129,
      "step": 6772
    },
    {
      "epoch": 1.5562959558823528,
      "grad_norm": 1.6697231531143188,
      "learning_rate": 7.65420751633987e-06,
      "loss": 0.1018,
      "step": 6773
    },
    {
      "epoch": 1.5565257352941178,
      "grad_norm": 1.4148021936416626,
      "learning_rate": 7.653696895424837e-06,
      "loss": 0.0983,
      "step": 6774
    },
    {
      "epoch": 1.5567555147058822,
      "grad_norm": 1.789690375328064,
      "learning_rate": 7.653186274509804e-06,
      "loss": 0.1105,
      "step": 6775
    },
    {
      "epoch": 1.5569852941176472,
      "grad_norm": 1.6912426948547363,
      "learning_rate": 7.652675653594771e-06,
      "loss": 0.0929,
      "step": 6776
    },
    {
      "epoch": 1.5572150735294117,
      "grad_norm": 1.6395387649536133,
      "learning_rate": 7.65216503267974e-06,
      "loss": 0.1219,
      "step": 6777
    },
    {
      "epoch": 1.5574448529411766,
      "grad_norm": 1.9919042587280273,
      "learning_rate": 7.651654411764705e-06,
      "loss": 0.1589,
      "step": 6778
    },
    {
      "epoch": 1.5576746323529411,
      "grad_norm": 1.5473341941833496,
      "learning_rate": 7.651143790849673e-06,
      "loss": 0.1224,
      "step": 6779
    },
    {
      "epoch": 1.5579044117647058,
      "grad_norm": 1.7273164987564087,
      "learning_rate": 7.650633169934641e-06,
      "loss": 0.1022,
      "step": 6780
    },
    {
      "epoch": 1.5581341911764706,
      "grad_norm": 1.3228164911270142,
      "learning_rate": 7.650122549019609e-06,
      "loss": 0.0929,
      "step": 6781
    },
    {
      "epoch": 1.5583639705882353,
      "grad_norm": 1.7813236713409424,
      "learning_rate": 7.649611928104575e-06,
      "loss": 0.0987,
      "step": 6782
    },
    {
      "epoch": 1.55859375,
      "grad_norm": 1.9772931337356567,
      "learning_rate": 7.649101307189543e-06,
      "loss": 0.1098,
      "step": 6783
    },
    {
      "epoch": 1.5588235294117647,
      "grad_norm": 1.7524584531784058,
      "learning_rate": 7.648590686274511e-06,
      "loss": 0.125,
      "step": 6784
    },
    {
      "epoch": 1.5590533088235294,
      "grad_norm": 1.2126429080963135,
      "learning_rate": 7.648080065359477e-06,
      "loss": 0.0942,
      "step": 6785
    },
    {
      "epoch": 1.5592830882352942,
      "grad_norm": 1.577817678451538,
      "learning_rate": 7.647569444444445e-06,
      "loss": 0.0983,
      "step": 6786
    },
    {
      "epoch": 1.5595128676470589,
      "grad_norm": 1.7928515672683716,
      "learning_rate": 7.647058823529411e-06,
      "loss": 0.1382,
      "step": 6787
    },
    {
      "epoch": 1.5597426470588234,
      "grad_norm": 1.8897241353988647,
      "learning_rate": 7.64654820261438e-06,
      "loss": 0.1538,
      "step": 6788
    },
    {
      "epoch": 1.5599724264705883,
      "grad_norm": 1.7749969959259033,
      "learning_rate": 7.646037581699347e-06,
      "loss": 0.1534,
      "step": 6789
    },
    {
      "epoch": 1.5602022058823528,
      "grad_norm": 1.5780237913131714,
      "learning_rate": 7.645526960784315e-06,
      "loss": 0.1234,
      "step": 6790
    },
    {
      "epoch": 1.5604319852941178,
      "grad_norm": 1.2859312295913696,
      "learning_rate": 7.64501633986928e-06,
      "loss": 0.1074,
      "step": 6791
    },
    {
      "epoch": 1.5606617647058822,
      "grad_norm": 1.747193694114685,
      "learning_rate": 7.644505718954249e-06,
      "loss": 0.1265,
      "step": 6792
    },
    {
      "epoch": 1.5608915441176472,
      "grad_norm": 1.8205171823501587,
      "learning_rate": 7.643995098039217e-06,
      "loss": 0.1203,
      "step": 6793
    },
    {
      "epoch": 1.5611213235294117,
      "grad_norm": 1.7853131294250488,
      "learning_rate": 7.643484477124183e-06,
      "loss": 0.1274,
      "step": 6794
    },
    {
      "epoch": 1.5613511029411766,
      "grad_norm": 1.411463737487793,
      "learning_rate": 7.64297385620915e-06,
      "loss": 0.1137,
      "step": 6795
    },
    {
      "epoch": 1.5615808823529411,
      "grad_norm": 1.67362380027771,
      "learning_rate": 7.642463235294118e-06,
      "loss": 0.1537,
      "step": 6796
    },
    {
      "epoch": 1.5618106617647058,
      "grad_norm": 1.523337483406067,
      "learning_rate": 7.641952614379086e-06,
      "loss": 0.0779,
      "step": 6797
    },
    {
      "epoch": 1.5620404411764706,
      "grad_norm": 1.5372004508972168,
      "learning_rate": 7.641441993464052e-06,
      "loss": 0.1023,
      "step": 6798
    },
    {
      "epoch": 1.5622702205882353,
      "grad_norm": 1.776158094406128,
      "learning_rate": 7.64093137254902e-06,
      "loss": 0.1191,
      "step": 6799
    },
    {
      "epoch": 1.5625,
      "grad_norm": 1.3546607494354248,
      "learning_rate": 7.640420751633988e-06,
      "loss": 0.157,
      "step": 6800
    },
    {
      "epoch": 1.5627297794117647,
      "grad_norm": 1.9690269231796265,
      "learning_rate": 7.639910130718954e-06,
      "loss": 0.126,
      "step": 6801
    },
    {
      "epoch": 1.5629595588235294,
      "grad_norm": 1.4725146293640137,
      "learning_rate": 7.639399509803922e-06,
      "loss": 0.1096,
      "step": 6802
    },
    {
      "epoch": 1.5631893382352942,
      "grad_norm": 1.5615246295928955,
      "learning_rate": 7.638888888888888e-06,
      "loss": 0.1675,
      "step": 6803
    },
    {
      "epoch": 1.5634191176470589,
      "grad_norm": 1.6805771589279175,
      "learning_rate": 7.638378267973858e-06,
      "loss": 0.1047,
      "step": 6804
    },
    {
      "epoch": 1.5636488970588234,
      "grad_norm": 2.0805530548095703,
      "learning_rate": 7.637867647058824e-06,
      "loss": 0.1604,
      "step": 6805
    },
    {
      "epoch": 1.5638786764705883,
      "grad_norm": 1.259155035018921,
      "learning_rate": 7.637357026143792e-06,
      "loss": 0.1034,
      "step": 6806
    },
    {
      "epoch": 1.5641084558823528,
      "grad_norm": 1.5437064170837402,
      "learning_rate": 7.636846405228758e-06,
      "loss": 0.1296,
      "step": 6807
    },
    {
      "epoch": 1.5643382352941178,
      "grad_norm": 1.7069326639175415,
      "learning_rate": 7.636335784313726e-06,
      "loss": 0.1566,
      "step": 6808
    },
    {
      "epoch": 1.5645680147058822,
      "grad_norm": 1.613729476928711,
      "learning_rate": 7.635825163398694e-06,
      "loss": 0.1202,
      "step": 6809
    },
    {
      "epoch": 1.5647977941176472,
      "grad_norm": 2.1960597038269043,
      "learning_rate": 7.63531454248366e-06,
      "loss": 0.1626,
      "step": 6810
    },
    {
      "epoch": 1.5650275735294117,
      "grad_norm": 2.1538617610931396,
      "learning_rate": 7.634803921568628e-06,
      "loss": 0.127,
      "step": 6811
    },
    {
      "epoch": 1.5652573529411766,
      "grad_norm": 1.1518229246139526,
      "learning_rate": 7.634293300653596e-06,
      "loss": 0.0845,
      "step": 6812
    },
    {
      "epoch": 1.5654871323529411,
      "grad_norm": 2.297642230987549,
      "learning_rate": 7.633782679738564e-06,
      "loss": 0.1423,
      "step": 6813
    },
    {
      "epoch": 1.5657169117647058,
      "grad_norm": 1.7383352518081665,
      "learning_rate": 7.63327205882353e-06,
      "loss": 0.1186,
      "step": 6814
    },
    {
      "epoch": 1.5659466911764706,
      "grad_norm": 1.9736156463623047,
      "learning_rate": 7.632761437908498e-06,
      "loss": 0.1557,
      "step": 6815
    },
    {
      "epoch": 1.5661764705882353,
      "grad_norm": 1.6359628438949585,
      "learning_rate": 7.632250816993466e-06,
      "loss": 0.1351,
      "step": 6816
    },
    {
      "epoch": 1.56640625,
      "grad_norm": 1.6462361812591553,
      "learning_rate": 7.631740196078432e-06,
      "loss": 0.1325,
      "step": 6817
    },
    {
      "epoch": 1.5666360294117647,
      "grad_norm": 1.3457773923873901,
      "learning_rate": 7.6312295751634e-06,
      "loss": 0.1462,
      "step": 6818
    },
    {
      "epoch": 1.5668658088235294,
      "grad_norm": 1.8554553985595703,
      "learning_rate": 7.630718954248366e-06,
      "loss": 0.1188,
      "step": 6819
    },
    {
      "epoch": 1.5670955882352942,
      "grad_norm": 1.9252188205718994,
      "learning_rate": 7.630208333333334e-06,
      "loss": 0.1269,
      "step": 6820
    },
    {
      "epoch": 1.5673253676470589,
      "grad_norm": 1.6409363746643066,
      "learning_rate": 7.629697712418301e-06,
      "loss": 0.1096,
      "step": 6821
    },
    {
      "epoch": 1.5675551470588234,
      "grad_norm": 1.6249982118606567,
      "learning_rate": 7.6291870915032685e-06,
      "loss": 0.1173,
      "step": 6822
    },
    {
      "epoch": 1.5677849264705883,
      "grad_norm": 2.631934404373169,
      "learning_rate": 7.6286764705882355e-06,
      "loss": 0.1425,
      "step": 6823
    },
    {
      "epoch": 1.5680147058823528,
      "grad_norm": 1.9915217161178589,
      "learning_rate": 7.628165849673203e-06,
      "loss": 0.0799,
      "step": 6824
    },
    {
      "epoch": 1.5682444852941178,
      "grad_norm": 1.4063211679458618,
      "learning_rate": 7.62765522875817e-06,
      "loss": 0.1413,
      "step": 6825
    },
    {
      "epoch": 1.5684742647058822,
      "grad_norm": 1.3106905221939087,
      "learning_rate": 7.627144607843137e-06,
      "loss": 0.0832,
      "step": 6826
    },
    {
      "epoch": 1.5687040441176472,
      "grad_norm": 1.9835890531539917,
      "learning_rate": 7.626633986928104e-06,
      "loss": 0.1379,
      "step": 6827
    },
    {
      "epoch": 1.5689338235294117,
      "grad_norm": 1.9909321069717407,
      "learning_rate": 7.626123366013073e-06,
      "loss": 0.1191,
      "step": 6828
    },
    {
      "epoch": 1.5691636029411766,
      "grad_norm": 1.7580753564834595,
      "learning_rate": 7.62561274509804e-06,
      "loss": 0.1299,
      "step": 6829
    },
    {
      "epoch": 1.5693933823529411,
      "grad_norm": 1.7016749382019043,
      "learning_rate": 7.625102124183007e-06,
      "loss": 0.1297,
      "step": 6830
    },
    {
      "epoch": 1.5696231617647058,
      "grad_norm": 1.3302093744277954,
      "learning_rate": 7.624591503267974e-06,
      "loss": 0.1071,
      "step": 6831
    },
    {
      "epoch": 1.5698529411764706,
      "grad_norm": 1.6407177448272705,
      "learning_rate": 7.624080882352942e-06,
      "loss": 0.1185,
      "step": 6832
    },
    {
      "epoch": 1.5700827205882353,
      "grad_norm": 1.8163233995437622,
      "learning_rate": 7.623570261437909e-06,
      "loss": 0.127,
      "step": 6833
    },
    {
      "epoch": 1.5703125,
      "grad_norm": 1.6652806997299194,
      "learning_rate": 7.623059640522876e-06,
      "loss": 0.0994,
      "step": 6834
    },
    {
      "epoch": 1.5705422794117647,
      "grad_norm": 1.844780683517456,
      "learning_rate": 7.622549019607843e-06,
      "loss": 0.1269,
      "step": 6835
    },
    {
      "epoch": 1.5707720588235294,
      "grad_norm": 1.3749747276306152,
      "learning_rate": 7.622038398692812e-06,
      "loss": 0.1289,
      "step": 6836
    },
    {
      "epoch": 1.5710018382352942,
      "grad_norm": 1.5104069709777832,
      "learning_rate": 7.621527777777779e-06,
      "loss": 0.1033,
      "step": 6837
    },
    {
      "epoch": 1.5712316176470589,
      "grad_norm": 1.5304831266403198,
      "learning_rate": 7.621017156862746e-06,
      "loss": 0.1335,
      "step": 6838
    },
    {
      "epoch": 1.5714613970588234,
      "grad_norm": 1.7026913166046143,
      "learning_rate": 7.620506535947713e-06,
      "loss": 0.1543,
      "step": 6839
    },
    {
      "epoch": 1.5716911764705883,
      "grad_norm": 1.524940013885498,
      "learning_rate": 7.619995915032681e-06,
      "loss": 0.1215,
      "step": 6840
    },
    {
      "epoch": 1.5719209558823528,
      "grad_norm": 1.3409205675125122,
      "learning_rate": 7.619485294117648e-06,
      "loss": 0.1043,
      "step": 6841
    },
    {
      "epoch": 1.5721507352941178,
      "grad_norm": 1.7622617483139038,
      "learning_rate": 7.618974673202615e-06,
      "loss": 0.109,
      "step": 6842
    },
    {
      "epoch": 1.5723805147058822,
      "grad_norm": 1.6907817125320435,
      "learning_rate": 7.618464052287582e-06,
      "loss": 0.1094,
      "step": 6843
    },
    {
      "epoch": 1.5726102941176472,
      "grad_norm": 2.1280345916748047,
      "learning_rate": 7.61795343137255e-06,
      "loss": 0.149,
      "step": 6844
    },
    {
      "epoch": 1.5728400735294117,
      "grad_norm": 1.3151828050613403,
      "learning_rate": 7.617442810457517e-06,
      "loss": 0.082,
      "step": 6845
    },
    {
      "epoch": 1.5730698529411766,
      "grad_norm": 1.771801471710205,
      "learning_rate": 7.6169321895424844e-06,
      "loss": 0.117,
      "step": 6846
    },
    {
      "epoch": 1.5732996323529411,
      "grad_norm": 1.4314073324203491,
      "learning_rate": 7.6164215686274514e-06,
      "loss": 0.0889,
      "step": 6847
    },
    {
      "epoch": 1.5735294117647058,
      "grad_norm": 1.833981990814209,
      "learning_rate": 7.615910947712419e-06,
      "loss": 0.1468,
      "step": 6848
    },
    {
      "epoch": 1.5737591911764706,
      "grad_norm": 1.8778170347213745,
      "learning_rate": 7.615400326797386e-06,
      "loss": 0.1865,
      "step": 6849
    },
    {
      "epoch": 1.5739889705882353,
      "grad_norm": 1.6050140857696533,
      "learning_rate": 7.614889705882353e-06,
      "loss": 0.1344,
      "step": 6850
    },
    {
      "epoch": 1.57421875,
      "grad_norm": 1.4583253860473633,
      "learning_rate": 7.61437908496732e-06,
      "loss": 0.1302,
      "step": 6851
    },
    {
      "epoch": 1.5744485294117647,
      "grad_norm": 1.6434693336486816,
      "learning_rate": 7.613868464052289e-06,
      "loss": 0.1112,
      "step": 6852
    },
    {
      "epoch": 1.5746783088235294,
      "grad_norm": 1.7007865905761719,
      "learning_rate": 7.613357843137256e-06,
      "loss": 0.1202,
      "step": 6853
    },
    {
      "epoch": 1.5749080882352942,
      "grad_norm": 1.7406878471374512,
      "learning_rate": 7.612847222222223e-06,
      "loss": 0.134,
      "step": 6854
    },
    {
      "epoch": 1.5751378676470589,
      "grad_norm": 1.8730230331420898,
      "learning_rate": 7.61233660130719e-06,
      "loss": 0.1311,
      "step": 6855
    },
    {
      "epoch": 1.5753676470588234,
      "grad_norm": 1.8167283535003662,
      "learning_rate": 7.611825980392158e-06,
      "loss": 0.0944,
      "step": 6856
    },
    {
      "epoch": 1.5755974264705883,
      "grad_norm": 1.6282368898391724,
      "learning_rate": 7.611315359477125e-06,
      "loss": 0.0935,
      "step": 6857
    },
    {
      "epoch": 1.5758272058823528,
      "grad_norm": 2.108468532562256,
      "learning_rate": 7.610804738562092e-06,
      "loss": 0.1021,
      "step": 6858
    },
    {
      "epoch": 1.5760569852941178,
      "grad_norm": 1.2141004800796509,
      "learning_rate": 7.610294117647059e-06,
      "loss": 0.0777,
      "step": 6859
    },
    {
      "epoch": 1.5762867647058822,
      "grad_norm": 1.7377514839172363,
      "learning_rate": 7.609783496732027e-06,
      "loss": 0.1236,
      "step": 6860
    },
    {
      "epoch": 1.5765165441176472,
      "grad_norm": 2.277631998062134,
      "learning_rate": 7.609272875816994e-06,
      "loss": 0.1512,
      "step": 6861
    },
    {
      "epoch": 1.5767463235294117,
      "grad_norm": 1.7447243928909302,
      "learning_rate": 7.608762254901961e-06,
      "loss": 0.1185,
      "step": 6862
    },
    {
      "epoch": 1.5769761029411766,
      "grad_norm": 1.8188049793243408,
      "learning_rate": 7.608251633986929e-06,
      "loss": 0.0953,
      "step": 6863
    },
    {
      "epoch": 1.5772058823529411,
      "grad_norm": 2.0617470741271973,
      "learning_rate": 7.607741013071897e-06,
      "loss": 0.1214,
      "step": 6864
    },
    {
      "epoch": 1.5774356617647058,
      "grad_norm": 1.7801759243011475,
      "learning_rate": 7.607230392156864e-06,
      "loss": 0.1286,
      "step": 6865
    },
    {
      "epoch": 1.5776654411764706,
      "grad_norm": 1.4243525266647339,
      "learning_rate": 7.606719771241831e-06,
      "loss": 0.1076,
      "step": 6866
    },
    {
      "epoch": 1.5778952205882353,
      "grad_norm": 1.6357396841049194,
      "learning_rate": 7.606209150326798e-06,
      "loss": 0.1143,
      "step": 6867
    },
    {
      "epoch": 1.578125,
      "grad_norm": 1.7323155403137207,
      "learning_rate": 7.6056985294117655e-06,
      "loss": 0.1165,
      "step": 6868
    },
    {
      "epoch": 1.5783547794117647,
      "grad_norm": 1.6198712587356567,
      "learning_rate": 7.6051879084967325e-06,
      "loss": 0.0714,
      "step": 6869
    },
    {
      "epoch": 1.5785845588235294,
      "grad_norm": 1.726391077041626,
      "learning_rate": 7.6046772875816996e-06,
      "loss": 0.1268,
      "step": 6870
    },
    {
      "epoch": 1.5788143382352942,
      "grad_norm": 3.4542322158813477,
      "learning_rate": 7.6041666666666666e-06,
      "loss": 0.1654,
      "step": 6871
    },
    {
      "epoch": 1.5790441176470589,
      "grad_norm": 2.4267995357513428,
      "learning_rate": 7.603656045751635e-06,
      "loss": 0.1063,
      "step": 6872
    },
    {
      "epoch": 1.5792738970588234,
      "grad_norm": 1.4408115148544312,
      "learning_rate": 7.603145424836602e-06,
      "loss": 0.0828,
      "step": 6873
    },
    {
      "epoch": 1.5795036764705883,
      "grad_norm": 1.7897504568099976,
      "learning_rate": 7.602634803921569e-06,
      "loss": 0.1282,
      "step": 6874
    },
    {
      "epoch": 1.5797334558823528,
      "grad_norm": 1.5560886859893799,
      "learning_rate": 7.602124183006536e-06,
      "loss": 0.1153,
      "step": 6875
    },
    {
      "epoch": 1.5799632352941178,
      "grad_norm": 1.6695640087127686,
      "learning_rate": 7.601613562091504e-06,
      "loss": 0.1106,
      "step": 6876
    },
    {
      "epoch": 1.5801930147058822,
      "grad_norm": 1.6559749841690063,
      "learning_rate": 7.601102941176471e-06,
      "loss": 0.1217,
      "step": 6877
    },
    {
      "epoch": 1.5804227941176472,
      "grad_norm": 1.8837106227874756,
      "learning_rate": 7.600592320261438e-06,
      "loss": 0.1519,
      "step": 6878
    },
    {
      "epoch": 1.5806525735294117,
      "grad_norm": 1.8549706935882568,
      "learning_rate": 7.600081699346405e-06,
      "loss": 0.0906,
      "step": 6879
    },
    {
      "epoch": 1.5808823529411766,
      "grad_norm": 1.7566401958465576,
      "learning_rate": 7.599571078431374e-06,
      "loss": 0.1417,
      "step": 6880
    },
    {
      "epoch": 1.5811121323529411,
      "grad_norm": 2.1316637992858887,
      "learning_rate": 7.599060457516341e-06,
      "loss": 0.0993,
      "step": 6881
    },
    {
      "epoch": 1.5813419117647058,
      "grad_norm": 2.226011276245117,
      "learning_rate": 7.598549836601308e-06,
      "loss": 0.1646,
      "step": 6882
    },
    {
      "epoch": 1.5815716911764706,
      "grad_norm": 2.053267240524292,
      "learning_rate": 7.598039215686275e-06,
      "loss": 0.1438,
      "step": 6883
    },
    {
      "epoch": 1.5818014705882353,
      "grad_norm": 1.952494740486145,
      "learning_rate": 7.597528594771243e-06,
      "loss": 0.1291,
      "step": 6884
    },
    {
      "epoch": 1.58203125,
      "grad_norm": 1.379015564918518,
      "learning_rate": 7.59701797385621e-06,
      "loss": 0.1018,
      "step": 6885
    },
    {
      "epoch": 1.5822610294117647,
      "grad_norm": 1.2310829162597656,
      "learning_rate": 7.596507352941177e-06,
      "loss": 0.0843,
      "step": 6886
    },
    {
      "epoch": 1.5824908088235294,
      "grad_norm": 1.4940739870071411,
      "learning_rate": 7.595996732026144e-06,
      "loss": 0.1252,
      "step": 6887
    },
    {
      "epoch": 1.5827205882352942,
      "grad_norm": 2.046781539916992,
      "learning_rate": 7.595486111111113e-06,
      "loss": 0.1168,
      "step": 6888
    },
    {
      "epoch": 1.5829503676470589,
      "grad_norm": 1.9372090101242065,
      "learning_rate": 7.59497549019608e-06,
      "loss": 0.128,
      "step": 6889
    },
    {
      "epoch": 1.5831801470588234,
      "grad_norm": 1.3739172220230103,
      "learning_rate": 7.594464869281047e-06,
      "loss": 0.1006,
      "step": 6890
    },
    {
      "epoch": 1.5834099264705883,
      "grad_norm": 1.6561466455459595,
      "learning_rate": 7.593954248366014e-06,
      "loss": 0.1523,
      "step": 6891
    },
    {
      "epoch": 1.5836397058823528,
      "grad_norm": 1.8141099214553833,
      "learning_rate": 7.5934436274509815e-06,
      "loss": 0.099,
      "step": 6892
    },
    {
      "epoch": 1.5838694852941178,
      "grad_norm": 1.5394877195358276,
      "learning_rate": 7.5929330065359485e-06,
      "loss": 0.0999,
      "step": 6893
    },
    {
      "epoch": 1.5840992647058822,
      "grad_norm": 1.4101545810699463,
      "learning_rate": 7.5924223856209155e-06,
      "loss": 0.105,
      "step": 6894
    },
    {
      "epoch": 1.5843290441176472,
      "grad_norm": 1.4651917219161987,
      "learning_rate": 7.5919117647058825e-06,
      "loss": 0.1029,
      "step": 6895
    },
    {
      "epoch": 1.5845588235294117,
      "grad_norm": 1.8251289129257202,
      "learning_rate": 7.59140114379085e-06,
      "loss": 0.09,
      "step": 6896
    },
    {
      "epoch": 1.5847886029411766,
      "grad_norm": 1.5365991592407227,
      "learning_rate": 7.590890522875818e-06,
      "loss": 0.1241,
      "step": 6897
    },
    {
      "epoch": 1.5850183823529411,
      "grad_norm": 1.645077109336853,
      "learning_rate": 7.590379901960785e-06,
      "loss": 0.1099,
      "step": 6898
    },
    {
      "epoch": 1.5852481617647058,
      "grad_norm": 1.8446651697158813,
      "learning_rate": 7.589869281045752e-06,
      "loss": 0.1245,
      "step": 6899
    },
    {
      "epoch": 1.5854779411764706,
      "grad_norm": 1.8171327114105225,
      "learning_rate": 7.58935866013072e-06,
      "loss": 0.1364,
      "step": 6900
    },
    {
      "epoch": 1.5857077205882353,
      "grad_norm": 1.3733857870101929,
      "learning_rate": 7.588848039215687e-06,
      "loss": 0.0995,
      "step": 6901
    },
    {
      "epoch": 1.5859375,
      "grad_norm": 2.143183946609497,
      "learning_rate": 7.588337418300654e-06,
      "loss": 0.1244,
      "step": 6902
    },
    {
      "epoch": 1.5861672794117647,
      "grad_norm": 1.9631956815719604,
      "learning_rate": 7.587826797385621e-06,
      "loss": 0.1362,
      "step": 6903
    },
    {
      "epoch": 1.5863970588235294,
      "grad_norm": 2.402796983718872,
      "learning_rate": 7.587316176470589e-06,
      "loss": 0.1049,
      "step": 6904
    },
    {
      "epoch": 1.5866268382352942,
      "grad_norm": 1.5911471843719482,
      "learning_rate": 7.586805555555556e-06,
      "loss": 0.1206,
      "step": 6905
    },
    {
      "epoch": 1.5868566176470589,
      "grad_norm": 1.466210126876831,
      "learning_rate": 7.586294934640523e-06,
      "loss": 0.1155,
      "step": 6906
    },
    {
      "epoch": 1.5870863970588234,
      "grad_norm": 1.508928894996643,
      "learning_rate": 7.58578431372549e-06,
      "loss": 0.1071,
      "step": 6907
    },
    {
      "epoch": 1.5873161764705883,
      "grad_norm": 1.9976768493652344,
      "learning_rate": 7.585273692810459e-06,
      "loss": 0.09,
      "step": 6908
    },
    {
      "epoch": 1.5875459558823528,
      "grad_norm": 1.9973738193511963,
      "learning_rate": 7.584763071895426e-06,
      "loss": 0.1007,
      "step": 6909
    },
    {
      "epoch": 1.5877757352941178,
      "grad_norm": 1.4459689855575562,
      "learning_rate": 7.584252450980393e-06,
      "loss": 0.1279,
      "step": 6910
    },
    {
      "epoch": 1.5880055147058822,
      "grad_norm": 2.6854076385498047,
      "learning_rate": 7.58374183006536e-06,
      "loss": 0.1909,
      "step": 6911
    },
    {
      "epoch": 1.5882352941176472,
      "grad_norm": 1.9201445579528809,
      "learning_rate": 7.583231209150328e-06,
      "loss": 0.1612,
      "step": 6912
    },
    {
      "epoch": 1.5884650735294117,
      "grad_norm": 1.9067128896713257,
      "learning_rate": 7.582720588235295e-06,
      "loss": 0.0887,
      "step": 6913
    },
    {
      "epoch": 1.5886948529411766,
      "grad_norm": 2.4671413898468018,
      "learning_rate": 7.582209967320262e-06,
      "loss": 0.1006,
      "step": 6914
    },
    {
      "epoch": 1.5889246323529411,
      "grad_norm": 1.8012813329696655,
      "learning_rate": 7.581699346405229e-06,
      "loss": 0.1964,
      "step": 6915
    },
    {
      "epoch": 1.5891544117647058,
      "grad_norm": 1.6348819732666016,
      "learning_rate": 7.5811887254901975e-06,
      "loss": 0.1495,
      "step": 6916
    },
    {
      "epoch": 1.5893841911764706,
      "grad_norm": 1.374337077140808,
      "learning_rate": 7.5806781045751645e-06,
      "loss": 0.0835,
      "step": 6917
    },
    {
      "epoch": 1.5896139705882353,
      "grad_norm": 1.4776357412338257,
      "learning_rate": 7.5801674836601315e-06,
      "loss": 0.0745,
      "step": 6918
    },
    {
      "epoch": 1.58984375,
      "grad_norm": 1.6332200765609741,
      "learning_rate": 7.5796568627450985e-06,
      "loss": 0.1251,
      "step": 6919
    },
    {
      "epoch": 1.5900735294117647,
      "grad_norm": 2.1808485984802246,
      "learning_rate": 7.579146241830066e-06,
      "loss": 0.1272,
      "step": 6920
    },
    {
      "epoch": 1.5903033088235294,
      "grad_norm": 2.268362522125244,
      "learning_rate": 7.578635620915033e-06,
      "loss": 0.1441,
      "step": 6921
    },
    {
      "epoch": 1.5905330882352942,
      "grad_norm": 1.4962763786315918,
      "learning_rate": 7.578125e-06,
      "loss": 0.0766,
      "step": 6922
    },
    {
      "epoch": 1.5907628676470589,
      "grad_norm": 2.007413864135742,
      "learning_rate": 7.577614379084967e-06,
      "loss": 0.0863,
      "step": 6923
    },
    {
      "epoch": 1.5909926470588234,
      "grad_norm": 1.9957244396209717,
      "learning_rate": 7.5771037581699344e-06,
      "loss": 0.1259,
      "step": 6924
    },
    {
      "epoch": 1.5912224264705883,
      "grad_norm": 2.188810110092163,
      "learning_rate": 7.576593137254903e-06,
      "loss": 0.1283,
      "step": 6925
    },
    {
      "epoch": 1.5914522058823528,
      "grad_norm": 1.5812236070632935,
      "learning_rate": 7.57608251633987e-06,
      "loss": 0.0956,
      "step": 6926
    },
    {
      "epoch": 1.5916819852941178,
      "grad_norm": 1.4966589212417603,
      "learning_rate": 7.575571895424837e-06,
      "loss": 0.1002,
      "step": 6927
    },
    {
      "epoch": 1.5919117647058822,
      "grad_norm": 1.6045145988464355,
      "learning_rate": 7.575061274509804e-06,
      "loss": 0.1322,
      "step": 6928
    },
    {
      "epoch": 1.5921415441176472,
      "grad_norm": 1.6408004760742188,
      "learning_rate": 7.574550653594772e-06,
      "loss": 0.1501,
      "step": 6929
    },
    {
      "epoch": 1.5923713235294117,
      "grad_norm": 1.3759572505950928,
      "learning_rate": 7.574040032679739e-06,
      "loss": 0.0922,
      "step": 6930
    },
    {
      "epoch": 1.5926011029411766,
      "grad_norm": 1.76240074634552,
      "learning_rate": 7.573529411764706e-06,
      "loss": 0.1029,
      "step": 6931
    },
    {
      "epoch": 1.5928308823529411,
      "grad_norm": 1.456982135772705,
      "learning_rate": 7.573018790849673e-06,
      "loss": 0.0971,
      "step": 6932
    },
    {
      "epoch": 1.5930606617647058,
      "grad_norm": 1.6969258785247803,
      "learning_rate": 7.572508169934642e-06,
      "loss": 0.1374,
      "step": 6933
    },
    {
      "epoch": 1.5932904411764706,
      "grad_norm": 1.8492982387542725,
      "learning_rate": 7.571997549019609e-06,
      "loss": 0.113,
      "step": 6934
    },
    {
      "epoch": 1.5935202205882353,
      "grad_norm": 1.8272724151611328,
      "learning_rate": 7.571486928104576e-06,
      "loss": 0.1707,
      "step": 6935
    },
    {
      "epoch": 1.59375,
      "grad_norm": 2.9368841648101807,
      "learning_rate": 7.570976307189543e-06,
      "loss": 0.1494,
      "step": 6936
    },
    {
      "epoch": 1.5939797794117647,
      "grad_norm": 2.2188222408294678,
      "learning_rate": 7.570465686274511e-06,
      "loss": 0.1439,
      "step": 6937
    },
    {
      "epoch": 1.5942095588235294,
      "grad_norm": 1.824391484260559,
      "learning_rate": 7.569955065359478e-06,
      "loss": 0.1481,
      "step": 6938
    },
    {
      "epoch": 1.5944393382352942,
      "grad_norm": 2.083310127258301,
      "learning_rate": 7.569444444444445e-06,
      "loss": 0.1616,
      "step": 6939
    },
    {
      "epoch": 1.5946691176470589,
      "grad_norm": 1.7860950231552124,
      "learning_rate": 7.568933823529412e-06,
      "loss": 0.1202,
      "step": 6940
    },
    {
      "epoch": 1.5948988970588234,
      "grad_norm": 1.4992963075637817,
      "learning_rate": 7.56842320261438e-06,
      "loss": 0.0989,
      "step": 6941
    },
    {
      "epoch": 1.5951286764705883,
      "grad_norm": 1.499268889427185,
      "learning_rate": 7.5679125816993475e-06,
      "loss": 0.1183,
      "step": 6942
    },
    {
      "epoch": 1.5953584558823528,
      "grad_norm": 1.9327547550201416,
      "learning_rate": 7.5674019607843145e-06,
      "loss": 0.1531,
      "step": 6943
    },
    {
      "epoch": 1.5955882352941178,
      "grad_norm": 1.6306884288787842,
      "learning_rate": 7.5668913398692815e-06,
      "loss": 0.0855,
      "step": 6944
    },
    {
      "epoch": 1.5958180147058822,
      "grad_norm": 1.731113314628601,
      "learning_rate": 7.566380718954249e-06,
      "loss": 0.1288,
      "step": 6945
    },
    {
      "epoch": 1.5960477941176472,
      "grad_norm": 1.5728484392166138,
      "learning_rate": 7.565870098039216e-06,
      "loss": 0.1091,
      "step": 6946
    },
    {
      "epoch": 1.5962775735294117,
      "grad_norm": 1.9721606969833374,
      "learning_rate": 7.565359477124183e-06,
      "loss": 0.1143,
      "step": 6947
    },
    {
      "epoch": 1.5965073529411766,
      "grad_norm": 1.3838443756103516,
      "learning_rate": 7.56484885620915e-06,
      "loss": 0.0949,
      "step": 6948
    },
    {
      "epoch": 1.5967371323529411,
      "grad_norm": 1.7363052368164062,
      "learning_rate": 7.564338235294118e-06,
      "loss": 0.1198,
      "step": 6949
    },
    {
      "epoch": 1.5969669117647058,
      "grad_norm": 1.6687195301055908,
      "learning_rate": 7.563827614379085e-06,
      "loss": 0.0945,
      "step": 6950
    },
    {
      "epoch": 1.5971966911764706,
      "grad_norm": 1.7787020206451416,
      "learning_rate": 7.563316993464052e-06,
      "loss": 0.1311,
      "step": 6951
    },
    {
      "epoch": 1.5974264705882353,
      "grad_norm": 1.8753306865692139,
      "learning_rate": 7.56280637254902e-06,
      "loss": 0.1538,
      "step": 6952
    },
    {
      "epoch": 1.59765625,
      "grad_norm": 1.8693653345108032,
      "learning_rate": 7.562295751633988e-06,
      "loss": 0.0988,
      "step": 6953
    },
    {
      "epoch": 1.5978860294117647,
      "grad_norm": 1.419983983039856,
      "learning_rate": 7.561785130718955e-06,
      "loss": 0.1115,
      "step": 6954
    },
    {
      "epoch": 1.5981158088235294,
      "grad_norm": 2.1974096298217773,
      "learning_rate": 7.561274509803922e-06,
      "loss": 0.0994,
      "step": 6955
    },
    {
      "epoch": 1.5983455882352942,
      "grad_norm": 1.301207184791565,
      "learning_rate": 7.560763888888889e-06,
      "loss": 0.1139,
      "step": 6956
    },
    {
      "epoch": 1.5985753676470589,
      "grad_norm": 1.6971635818481445,
      "learning_rate": 7.560253267973857e-06,
      "loss": 0.1265,
      "step": 6957
    },
    {
      "epoch": 1.5988051470588234,
      "grad_norm": 1.647168755531311,
      "learning_rate": 7.559742647058824e-06,
      "loss": 0.1188,
      "step": 6958
    },
    {
      "epoch": 1.5990349264705883,
      "grad_norm": 1.6328799724578857,
      "learning_rate": 7.559232026143791e-06,
      "loss": 0.1458,
      "step": 6959
    },
    {
      "epoch": 1.5992647058823528,
      "grad_norm": 2.031358242034912,
      "learning_rate": 7.558721405228758e-06,
      "loss": 0.0983,
      "step": 6960
    },
    {
      "epoch": 1.5994944852941178,
      "grad_norm": 1.6382416486740112,
      "learning_rate": 7.558210784313727e-06,
      "loss": 0.1025,
      "step": 6961
    },
    {
      "epoch": 1.5997242647058822,
      "grad_norm": 1.636043906211853,
      "learning_rate": 7.557700163398694e-06,
      "loss": 0.1133,
      "step": 6962
    },
    {
      "epoch": 1.5999540441176472,
      "grad_norm": 1.6546330451965332,
      "learning_rate": 7.557189542483661e-06,
      "loss": 0.1559,
      "step": 6963
    },
    {
      "epoch": 1.6001838235294117,
      "grad_norm": 2.491499185562134,
      "learning_rate": 7.556678921568628e-06,
      "loss": 0.1722,
      "step": 6964
    },
    {
      "epoch": 1.6004136029411766,
      "grad_norm": 1.4527908563613892,
      "learning_rate": 7.5561683006535956e-06,
      "loss": 0.1059,
      "step": 6965
    },
    {
      "epoch": 1.6006433823529411,
      "grad_norm": 1.8086587190628052,
      "learning_rate": 7.555657679738563e-06,
      "loss": 0.0957,
      "step": 6966
    },
    {
      "epoch": 1.6008731617647058,
      "grad_norm": 1.3967759609222412,
      "learning_rate": 7.55514705882353e-06,
      "loss": 0.1228,
      "step": 6967
    },
    {
      "epoch": 1.6011029411764706,
      "grad_norm": 2.014925241470337,
      "learning_rate": 7.554636437908497e-06,
      "loss": 0.1751,
      "step": 6968
    },
    {
      "epoch": 1.6013327205882353,
      "grad_norm": 1.454544186592102,
      "learning_rate": 7.554125816993465e-06,
      "loss": 0.1084,
      "step": 6969
    },
    {
      "epoch": 1.6015625,
      "grad_norm": 1.445244312286377,
      "learning_rate": 7.553615196078432e-06,
      "loss": 0.1127,
      "step": 6970
    },
    {
      "epoch": 1.6017922794117647,
      "grad_norm": 1.428500771522522,
      "learning_rate": 7.553104575163399e-06,
      "loss": 0.1257,
      "step": 6971
    },
    {
      "epoch": 1.6020220588235294,
      "grad_norm": 1.735987663269043,
      "learning_rate": 7.552593954248366e-06,
      "loss": 0.1396,
      "step": 6972
    },
    {
      "epoch": 1.6022518382352942,
      "grad_norm": 2.5940635204315186,
      "learning_rate": 7.552083333333334e-06,
      "loss": 0.1046,
      "step": 6973
    },
    {
      "epoch": 1.6024816176470589,
      "grad_norm": 2.149526596069336,
      "learning_rate": 7.551572712418301e-06,
      "loss": 0.1342,
      "step": 6974
    },
    {
      "epoch": 1.6027113970588234,
      "grad_norm": 1.388501763343811,
      "learning_rate": 7.551062091503268e-06,
      "loss": 0.1059,
      "step": 6975
    },
    {
      "epoch": 1.6029411764705883,
      "grad_norm": 1.686118245124817,
      "learning_rate": 7.550551470588235e-06,
      "loss": 0.1333,
      "step": 6976
    },
    {
      "epoch": 1.6031709558823528,
      "grad_norm": 1.5219393968582153,
      "learning_rate": 7.550040849673204e-06,
      "loss": 0.1047,
      "step": 6977
    },
    {
      "epoch": 1.6034007352941178,
      "grad_norm": 1.807982325553894,
      "learning_rate": 7.549530228758171e-06,
      "loss": 0.1369,
      "step": 6978
    },
    {
      "epoch": 1.6036305147058822,
      "grad_norm": 1.8128716945648193,
      "learning_rate": 7.549019607843138e-06,
      "loss": 0.1349,
      "step": 6979
    },
    {
      "epoch": 1.6038602941176472,
      "grad_norm": 2.0552761554718018,
      "learning_rate": 7.548508986928105e-06,
      "loss": 0.1245,
      "step": 6980
    },
    {
      "epoch": 1.6040900735294117,
      "grad_norm": 1.3385694026947021,
      "learning_rate": 7.547998366013073e-06,
      "loss": 0.1157,
      "step": 6981
    },
    {
      "epoch": 1.6043198529411766,
      "grad_norm": 1.643537998199463,
      "learning_rate": 7.54748774509804e-06,
      "loss": 0.1575,
      "step": 6982
    },
    {
      "epoch": 1.6045496323529411,
      "grad_norm": 1.5243276357650757,
      "learning_rate": 7.546977124183007e-06,
      "loss": 0.1383,
      "step": 6983
    },
    {
      "epoch": 1.6047794117647058,
      "grad_norm": 1.1864489316940308,
      "learning_rate": 7.546466503267974e-06,
      "loss": 0.1075,
      "step": 6984
    },
    {
      "epoch": 1.6050091911764706,
      "grad_norm": 1.4175302982330322,
      "learning_rate": 7.545955882352942e-06,
      "loss": 0.0818,
      "step": 6985
    },
    {
      "epoch": 1.6052389705882353,
      "grad_norm": 1.7808607816696167,
      "learning_rate": 7.54544526143791e-06,
      "loss": 0.1273,
      "step": 6986
    },
    {
      "epoch": 1.60546875,
      "grad_norm": 1.7373881340026855,
      "learning_rate": 7.544934640522877e-06,
      "loss": 0.0892,
      "step": 6987
    },
    {
      "epoch": 1.6056985294117647,
      "grad_norm": 1.7457401752471924,
      "learning_rate": 7.544424019607844e-06,
      "loss": 0.0814,
      "step": 6988
    },
    {
      "epoch": 1.6059283088235294,
      "grad_norm": 1.3760881423950195,
      "learning_rate": 7.5439133986928115e-06,
      "loss": 0.1049,
      "step": 6989
    },
    {
      "epoch": 1.6061580882352942,
      "grad_norm": 1.7114005088806152,
      "learning_rate": 7.5434027777777786e-06,
      "loss": 0.1046,
      "step": 6990
    },
    {
      "epoch": 1.6063878676470589,
      "grad_norm": 1.6187260150909424,
      "learning_rate": 7.5428921568627456e-06,
      "loss": 0.1275,
      "step": 6991
    },
    {
      "epoch": 1.6066176470588234,
      "grad_norm": 1.5226441621780396,
      "learning_rate": 7.542381535947713e-06,
      "loss": 0.1205,
      "step": 6992
    },
    {
      "epoch": 1.6068474264705883,
      "grad_norm": 1.8070889711380005,
      "learning_rate": 7.5418709150326804e-06,
      "loss": 0.1107,
      "step": 6993
    },
    {
      "epoch": 1.6070772058823528,
      "grad_norm": 1.4996464252471924,
      "learning_rate": 7.5413602941176475e-06,
      "loss": 0.0982,
      "step": 6994
    },
    {
      "epoch": 1.6073069852941178,
      "grad_norm": 1.6452133655548096,
      "learning_rate": 7.5408496732026145e-06,
      "loss": 0.1196,
      "step": 6995
    },
    {
      "epoch": 1.6075367647058822,
      "grad_norm": 2.6103110313415527,
      "learning_rate": 7.5403390522875815e-06,
      "loss": 0.1626,
      "step": 6996
    },
    {
      "epoch": 1.6077665441176472,
      "grad_norm": 1.8985828161239624,
      "learning_rate": 7.53982843137255e-06,
      "loss": 0.1239,
      "step": 6997
    },
    {
      "epoch": 1.6079963235294117,
      "grad_norm": 1.9665364027023315,
      "learning_rate": 7.539317810457517e-06,
      "loss": 0.1522,
      "step": 6998
    },
    {
      "epoch": 1.6082261029411766,
      "grad_norm": 1.5203866958618164,
      "learning_rate": 7.538807189542484e-06,
      "loss": 0.1023,
      "step": 6999
    },
    {
      "epoch": 1.6084558823529411,
      "grad_norm": 1.5122848749160767,
      "learning_rate": 7.538296568627451e-06,
      "loss": 0.1106,
      "step": 7000
    },
    {
      "epoch": 1.6084558823529411,
      "eval_loss": 0.1191077008843422,
      "eval_runtime": 420.8112,
      "eval_samples_per_second": 21.164,
      "eval_steps_per_second": 10.582,
      "step": 7000
    },
    {
      "epoch": 1.6086856617647058,
      "grad_norm": 1.6276636123657227,
      "learning_rate": 7.537785947712419e-06,
      "loss": 0.1028,
      "step": 7001
    },
    {
      "epoch": 1.6089154411764706,
      "grad_norm": 1.869450330734253,
      "learning_rate": 7.537275326797386e-06,
      "loss": 0.1158,
      "step": 7002
    },
    {
      "epoch": 1.6091452205882353,
      "grad_norm": 1.700689673423767,
      "learning_rate": 7.536764705882353e-06,
      "loss": 0.1085,
      "step": 7003
    },
    {
      "epoch": 1.609375,
      "grad_norm": 1.5461761951446533,
      "learning_rate": 7.53625408496732e-06,
      "loss": 0.0813,
      "step": 7004
    },
    {
      "epoch": 1.6096047794117647,
      "grad_norm": 1.80634343624115,
      "learning_rate": 7.535743464052289e-06,
      "loss": 0.1047,
      "step": 7005
    },
    {
      "epoch": 1.6098345588235294,
      "grad_norm": 2.1503746509552,
      "learning_rate": 7.535232843137256e-06,
      "loss": 0.1261,
      "step": 7006
    },
    {
      "epoch": 1.6100643382352942,
      "grad_norm": 1.5681021213531494,
      "learning_rate": 7.534722222222223e-06,
      "loss": 0.1291,
      "step": 7007
    },
    {
      "epoch": 1.6102941176470589,
      "grad_norm": 1.8281493186950684,
      "learning_rate": 7.53421160130719e-06,
      "loss": 0.1327,
      "step": 7008
    },
    {
      "epoch": 1.6105238970588234,
      "grad_norm": 1.7217817306518555,
      "learning_rate": 7.533700980392158e-06,
      "loss": 0.1181,
      "step": 7009
    },
    {
      "epoch": 1.6107536764705883,
      "grad_norm": 1.8165100812911987,
      "learning_rate": 7.533190359477125e-06,
      "loss": 0.1403,
      "step": 7010
    },
    {
      "epoch": 1.6109834558823528,
      "grad_norm": 1.5868642330169678,
      "learning_rate": 7.532679738562092e-06,
      "loss": 0.1279,
      "step": 7011
    },
    {
      "epoch": 1.6112132352941178,
      "grad_norm": 1.638909101486206,
      "learning_rate": 7.532169117647059e-06,
      "loss": 0.1232,
      "step": 7012
    },
    {
      "epoch": 1.6114430147058822,
      "grad_norm": 1.3183332681655884,
      "learning_rate": 7.5316584967320275e-06,
      "loss": 0.1069,
      "step": 7013
    },
    {
      "epoch": 1.6116727941176472,
      "grad_norm": 2.0151381492614746,
      "learning_rate": 7.5311478758169945e-06,
      "loss": 0.1339,
      "step": 7014
    },
    {
      "epoch": 1.6119025735294117,
      "grad_norm": 1.548988938331604,
      "learning_rate": 7.5306372549019615e-06,
      "loss": 0.129,
      "step": 7015
    },
    {
      "epoch": 1.6121323529411766,
      "grad_norm": 1.720657229423523,
      "learning_rate": 7.5301266339869286e-06,
      "loss": 0.14,
      "step": 7016
    },
    {
      "epoch": 1.6123621323529411,
      "grad_norm": 1.370496392250061,
      "learning_rate": 7.529616013071896e-06,
      "loss": 0.074,
      "step": 7017
    },
    {
      "epoch": 1.6125919117647058,
      "grad_norm": 2.931598424911499,
      "learning_rate": 7.5291053921568634e-06,
      "loss": 0.1282,
      "step": 7018
    },
    {
      "epoch": 1.6128216911764706,
      "grad_norm": 1.7136178016662598,
      "learning_rate": 7.5285947712418304e-06,
      "loss": 0.1012,
      "step": 7019
    },
    {
      "epoch": 1.6130514705882353,
      "grad_norm": 2.068800687789917,
      "learning_rate": 7.5280841503267975e-06,
      "loss": 0.1359,
      "step": 7020
    },
    {
      "epoch": 1.61328125,
      "grad_norm": 2.3523671627044678,
      "learning_rate": 7.527573529411766e-06,
      "loss": 0.1485,
      "step": 7021
    },
    {
      "epoch": 1.6135110294117647,
      "grad_norm": 2.44416880607605,
      "learning_rate": 7.527062908496733e-06,
      "loss": 0.1345,
      "step": 7022
    },
    {
      "epoch": 1.6137408088235294,
      "grad_norm": 1.5373302698135376,
      "learning_rate": 7.5265522875817e-06,
      "loss": 0.1188,
      "step": 7023
    },
    {
      "epoch": 1.6139705882352942,
      "grad_norm": 1.6882646083831787,
      "learning_rate": 7.526041666666667e-06,
      "loss": 0.0971,
      "step": 7024
    },
    {
      "epoch": 1.6142003676470589,
      "grad_norm": 1.9068386554718018,
      "learning_rate": 7.525531045751635e-06,
      "loss": 0.1323,
      "step": 7025
    },
    {
      "epoch": 1.6144301470588234,
      "grad_norm": 1.8430949449539185,
      "learning_rate": 7.525020424836602e-06,
      "loss": 0.0912,
      "step": 7026
    },
    {
      "epoch": 1.6146599264705883,
      "grad_norm": 2.07844614982605,
      "learning_rate": 7.524509803921569e-06,
      "loss": 0.1296,
      "step": 7027
    },
    {
      "epoch": 1.6148897058823528,
      "grad_norm": 1.8211240768432617,
      "learning_rate": 7.523999183006536e-06,
      "loss": 0.1293,
      "step": 7028
    },
    {
      "epoch": 1.6151194852941178,
      "grad_norm": 1.7158457040786743,
      "learning_rate": 7.523488562091504e-06,
      "loss": 0.1089,
      "step": 7029
    },
    {
      "epoch": 1.6153492647058822,
      "grad_norm": 1.5184036493301392,
      "learning_rate": 7.522977941176471e-06,
      "loss": 0.0982,
      "step": 7030
    },
    {
      "epoch": 1.6155790441176472,
      "grad_norm": 1.4039342403411865,
      "learning_rate": 7.522467320261439e-06,
      "loss": 0.1168,
      "step": 7031
    },
    {
      "epoch": 1.6158088235294117,
      "grad_norm": 1.712351679801941,
      "learning_rate": 7.521956699346406e-06,
      "loss": 0.1307,
      "step": 7032
    },
    {
      "epoch": 1.6160386029411766,
      "grad_norm": 1.8951187133789062,
      "learning_rate": 7.521446078431374e-06,
      "loss": 0.1701,
      "step": 7033
    },
    {
      "epoch": 1.6162683823529411,
      "grad_norm": 1.8323266506195068,
      "learning_rate": 7.520935457516341e-06,
      "loss": 0.1241,
      "step": 7034
    },
    {
      "epoch": 1.6164981617647058,
      "grad_norm": 2.1162383556365967,
      "learning_rate": 7.520424836601308e-06,
      "loss": 0.1393,
      "step": 7035
    },
    {
      "epoch": 1.6167279411764706,
      "grad_norm": 1.581721305847168,
      "learning_rate": 7.519914215686275e-06,
      "loss": 0.1225,
      "step": 7036
    },
    {
      "epoch": 1.6169577205882353,
      "grad_norm": 1.619857668876648,
      "learning_rate": 7.519403594771243e-06,
      "loss": 0.1424,
      "step": 7037
    },
    {
      "epoch": 1.6171875,
      "grad_norm": 1.3525205850601196,
      "learning_rate": 7.51889297385621e-06,
      "loss": 0.0894,
      "step": 7038
    },
    {
      "epoch": 1.6174172794117647,
      "grad_norm": 1.5522910356521606,
      "learning_rate": 7.518382352941177e-06,
      "loss": 0.1012,
      "step": 7039
    },
    {
      "epoch": 1.6176470588235294,
      "grad_norm": 1.3704898357391357,
      "learning_rate": 7.517871732026144e-06,
      "loss": 0.0942,
      "step": 7040
    },
    {
      "epoch": 1.6178768382352942,
      "grad_norm": 1.7033357620239258,
      "learning_rate": 7.517361111111112e-06,
      "loss": 0.1081,
      "step": 7041
    },
    {
      "epoch": 1.6181066176470589,
      "grad_norm": 1.5672534704208374,
      "learning_rate": 7.516850490196079e-06,
      "loss": 0.0904,
      "step": 7042
    },
    {
      "epoch": 1.6183363970588234,
      "grad_norm": 1.723960041999817,
      "learning_rate": 7.516339869281046e-06,
      "loss": 0.0868,
      "step": 7043
    },
    {
      "epoch": 1.6185661764705883,
      "grad_norm": 2.1320760250091553,
      "learning_rate": 7.5158292483660134e-06,
      "loss": 0.1352,
      "step": 7044
    },
    {
      "epoch": 1.6187959558823528,
      "grad_norm": 5.172754764556885,
      "learning_rate": 7.515318627450981e-06,
      "loss": 0.1209,
      "step": 7045
    },
    {
      "epoch": 1.6190257352941178,
      "grad_norm": 1.5619146823883057,
      "learning_rate": 7.514808006535948e-06,
      "loss": 0.1324,
      "step": 7046
    },
    {
      "epoch": 1.6192555147058822,
      "grad_norm": 1.5971273183822632,
      "learning_rate": 7.514297385620915e-06,
      "loss": 0.1005,
      "step": 7047
    },
    {
      "epoch": 1.6194852941176472,
      "grad_norm": 1.6937341690063477,
      "learning_rate": 7.513786764705882e-06,
      "loss": 0.1222,
      "step": 7048
    },
    {
      "epoch": 1.6197150735294117,
      "grad_norm": 1.8380593061447144,
      "learning_rate": 7.513276143790851e-06,
      "loss": 0.1051,
      "step": 7049
    },
    {
      "epoch": 1.6199448529411766,
      "grad_norm": 1.9252129793167114,
      "learning_rate": 7.512765522875818e-06,
      "loss": 0.1028,
      "step": 7050
    },
    {
      "epoch": 1.6201746323529411,
      "grad_norm": 1.650241732597351,
      "learning_rate": 7.512254901960785e-06,
      "loss": 0.144,
      "step": 7051
    },
    {
      "epoch": 1.6204044117647058,
      "grad_norm": 1.9057551622390747,
      "learning_rate": 7.511744281045752e-06,
      "loss": 0.1405,
      "step": 7052
    },
    {
      "epoch": 1.6206341911764706,
      "grad_norm": 1.752898097038269,
      "learning_rate": 7.51123366013072e-06,
      "loss": 0.1163,
      "step": 7053
    },
    {
      "epoch": 1.6208639705882353,
      "grad_norm": 1.5015087127685547,
      "learning_rate": 7.510723039215687e-06,
      "loss": 0.1081,
      "step": 7054
    },
    {
      "epoch": 1.62109375,
      "grad_norm": 1.4631415605545044,
      "learning_rate": 7.510212418300654e-06,
      "loss": 0.1135,
      "step": 7055
    },
    {
      "epoch": 1.6213235294117647,
      "grad_norm": 1.62693190574646,
      "learning_rate": 7.509701797385621e-06,
      "loss": 0.1157,
      "step": 7056
    },
    {
      "epoch": 1.6215533088235294,
      "grad_norm": 1.8865110874176025,
      "learning_rate": 7.50919117647059e-06,
      "loss": 0.1359,
      "step": 7057
    },
    {
      "epoch": 1.6217830882352942,
      "grad_norm": 1.7449097633361816,
      "learning_rate": 7.508680555555557e-06,
      "loss": 0.1776,
      "step": 7058
    },
    {
      "epoch": 1.6220128676470589,
      "grad_norm": 1.5448384284973145,
      "learning_rate": 7.508169934640524e-06,
      "loss": 0.1196,
      "step": 7059
    },
    {
      "epoch": 1.6222426470588234,
      "grad_norm": 1.8254809379577637,
      "learning_rate": 7.507659313725491e-06,
      "loss": 0.0754,
      "step": 7060
    },
    {
      "epoch": 1.6224724264705883,
      "grad_norm": 1.8044687509536743,
      "learning_rate": 7.507148692810459e-06,
      "loss": 0.1056,
      "step": 7061
    },
    {
      "epoch": 1.6227022058823528,
      "grad_norm": 1.820380449295044,
      "learning_rate": 7.506638071895426e-06,
      "loss": 0.1307,
      "step": 7062
    },
    {
      "epoch": 1.6229319852941178,
      "grad_norm": 1.728202223777771,
      "learning_rate": 7.506127450980393e-06,
      "loss": 0.1572,
      "step": 7063
    },
    {
      "epoch": 1.6231617647058822,
      "grad_norm": 1.6124485731124878,
      "learning_rate": 7.50561683006536e-06,
      "loss": 0.1247,
      "step": 7064
    },
    {
      "epoch": 1.6233915441176472,
      "grad_norm": 1.7895762920379639,
      "learning_rate": 7.505106209150328e-06,
      "loss": 0.0991,
      "step": 7065
    },
    {
      "epoch": 1.6236213235294117,
      "grad_norm": 1.398525357246399,
      "learning_rate": 7.504595588235295e-06,
      "loss": 0.1116,
      "step": 7066
    },
    {
      "epoch": 1.6238511029411766,
      "grad_norm": 1.8225810527801514,
      "learning_rate": 7.504084967320262e-06,
      "loss": 0.1074,
      "step": 7067
    },
    {
      "epoch": 1.6240808823529411,
      "grad_norm": 1.544907569885254,
      "learning_rate": 7.503574346405229e-06,
      "loss": 0.1069,
      "step": 7068
    },
    {
      "epoch": 1.6243106617647058,
      "grad_norm": 1.5548896789550781,
      "learning_rate": 7.503063725490197e-06,
      "loss": 0.1064,
      "step": 7069
    },
    {
      "epoch": 1.6245404411764706,
      "grad_norm": 1.4946736097335815,
      "learning_rate": 7.502553104575164e-06,
      "loss": 0.1253,
      "step": 7070
    },
    {
      "epoch": 1.6247702205882353,
      "grad_norm": 1.2780872583389282,
      "learning_rate": 7.502042483660131e-06,
      "loss": 0.1,
      "step": 7071
    },
    {
      "epoch": 1.625,
      "grad_norm": 1.5789779424667358,
      "learning_rate": 7.501531862745098e-06,
      "loss": 0.1219,
      "step": 7072
    },
    {
      "epoch": 1.6252297794117647,
      "grad_norm": 1.5907292366027832,
      "learning_rate": 7.501021241830066e-06,
      "loss": 0.0889,
      "step": 7073
    },
    {
      "epoch": 1.6254595588235294,
      "grad_norm": 1.7443324327468872,
      "learning_rate": 7.500510620915033e-06,
      "loss": 0.0914,
      "step": 7074
    },
    {
      "epoch": 1.6256893382352942,
      "grad_norm": 1.6321814060211182,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.0992,
      "step": 7075
    },
    {
      "epoch": 1.6259191176470589,
      "grad_norm": 2.322605609893799,
      "learning_rate": 7.499489379084968e-06,
      "loss": 0.2027,
      "step": 7076
    },
    {
      "epoch": 1.6261488970588234,
      "grad_norm": 1.53658926486969,
      "learning_rate": 7.498978758169935e-06,
      "loss": 0.0915,
      "step": 7077
    },
    {
      "epoch": 1.6263786764705883,
      "grad_norm": 1.4224884510040283,
      "learning_rate": 7.498468137254903e-06,
      "loss": 0.1365,
      "step": 7078
    },
    {
      "epoch": 1.6266084558823528,
      "grad_norm": 2.097500801086426,
      "learning_rate": 7.49795751633987e-06,
      "loss": 0.121,
      "step": 7079
    },
    {
      "epoch": 1.6268382352941178,
      "grad_norm": 1.6948373317718506,
      "learning_rate": 7.497446895424837e-06,
      "loss": 0.1174,
      "step": 7080
    },
    {
      "epoch": 1.6270680147058822,
      "grad_norm": 1.6161365509033203,
      "learning_rate": 7.496936274509804e-06,
      "loss": 0.1127,
      "step": 7081
    },
    {
      "epoch": 1.6272977941176472,
      "grad_norm": 1.4918869733810425,
      "learning_rate": 7.496425653594772e-06,
      "loss": 0.1342,
      "step": 7082
    },
    {
      "epoch": 1.6275275735294117,
      "grad_norm": 1.737282633781433,
      "learning_rate": 7.495915032679739e-06,
      "loss": 0.1132,
      "step": 7083
    },
    {
      "epoch": 1.6277573529411766,
      "grad_norm": 1.977994680404663,
      "learning_rate": 7.495404411764706e-06,
      "loss": 0.1013,
      "step": 7084
    },
    {
      "epoch": 1.6279871323529411,
      "grad_norm": 1.9552032947540283,
      "learning_rate": 7.494893790849673e-06,
      "loss": 0.1144,
      "step": 7085
    },
    {
      "epoch": 1.6282169117647058,
      "grad_norm": 1.3998382091522217,
      "learning_rate": 7.494383169934642e-06,
      "loss": 0.1145,
      "step": 7086
    },
    {
      "epoch": 1.6284466911764706,
      "grad_norm": 1.5970666408538818,
      "learning_rate": 7.493872549019609e-06,
      "loss": 0.1261,
      "step": 7087
    },
    {
      "epoch": 1.6286764705882353,
      "grad_norm": 2.4608733654022217,
      "learning_rate": 7.493361928104576e-06,
      "loss": 0.1283,
      "step": 7088
    },
    {
      "epoch": 1.62890625,
      "grad_norm": 1.6765360832214355,
      "learning_rate": 7.492851307189543e-06,
      "loss": 0.1122,
      "step": 7089
    },
    {
      "epoch": 1.6291360294117647,
      "grad_norm": 2.1557233333587646,
      "learning_rate": 7.4923406862745105e-06,
      "loss": 0.1081,
      "step": 7090
    },
    {
      "epoch": 1.6293658088235294,
      "grad_norm": 1.943960428237915,
      "learning_rate": 7.4918300653594775e-06,
      "loss": 0.1551,
      "step": 7091
    },
    {
      "epoch": 1.6295955882352942,
      "grad_norm": 1.8538503646850586,
      "learning_rate": 7.4913194444444445e-06,
      "loss": 0.104,
      "step": 7092
    },
    {
      "epoch": 1.6298253676470589,
      "grad_norm": 1.5074504613876343,
      "learning_rate": 7.4908088235294115e-06,
      "loss": 0.1129,
      "step": 7093
    },
    {
      "epoch": 1.6300551470588234,
      "grad_norm": 1.5394587516784668,
      "learning_rate": 7.49029820261438e-06,
      "loss": 0.0959,
      "step": 7094
    },
    {
      "epoch": 1.6302849264705883,
      "grad_norm": 2.5290277004241943,
      "learning_rate": 7.489787581699347e-06,
      "loss": 0.1486,
      "step": 7095
    },
    {
      "epoch": 1.6305147058823528,
      "grad_norm": 2.49821138381958,
      "learning_rate": 7.489276960784314e-06,
      "loss": 0.1488,
      "step": 7096
    },
    {
      "epoch": 1.6307444852941178,
      "grad_norm": 1.5753393173217773,
      "learning_rate": 7.488766339869281e-06,
      "loss": 0.0896,
      "step": 7097
    },
    {
      "epoch": 1.6309742647058822,
      "grad_norm": 1.7186816930770874,
      "learning_rate": 7.488255718954249e-06,
      "loss": 0.1221,
      "step": 7098
    },
    {
      "epoch": 1.6312040441176472,
      "grad_norm": 1.9546189308166504,
      "learning_rate": 7.487745098039216e-06,
      "loss": 0.1096,
      "step": 7099
    },
    {
      "epoch": 1.6314338235294117,
      "grad_norm": 1.5242044925689697,
      "learning_rate": 7.487234477124183e-06,
      "loss": 0.1476,
      "step": 7100
    },
    {
      "epoch": 1.6316636029411766,
      "grad_norm": 1.699467420578003,
      "learning_rate": 7.48672385620915e-06,
      "loss": 0.1262,
      "step": 7101
    },
    {
      "epoch": 1.6318933823529411,
      "grad_norm": 1.566595196723938,
      "learning_rate": 7.486213235294119e-06,
      "loss": 0.1118,
      "step": 7102
    },
    {
      "epoch": 1.6321231617647058,
      "grad_norm": 1.529612421989441,
      "learning_rate": 7.485702614379086e-06,
      "loss": 0.1014,
      "step": 7103
    },
    {
      "epoch": 1.6323529411764706,
      "grad_norm": 1.6986984014511108,
      "learning_rate": 7.485191993464053e-06,
      "loss": 0.1107,
      "step": 7104
    },
    {
      "epoch": 1.6325827205882353,
      "grad_norm": 1.9042649269104004,
      "learning_rate": 7.48468137254902e-06,
      "loss": 0.1301,
      "step": 7105
    },
    {
      "epoch": 1.6328125,
      "grad_norm": 1.8448899984359741,
      "learning_rate": 7.484170751633988e-06,
      "loss": 0.0852,
      "step": 7106
    },
    {
      "epoch": 1.6330422794117647,
      "grad_norm": 1.44962739944458,
      "learning_rate": 7.483660130718955e-06,
      "loss": 0.0928,
      "step": 7107
    },
    {
      "epoch": 1.6332720588235294,
      "grad_norm": 1.773618221282959,
      "learning_rate": 7.483149509803922e-06,
      "loss": 0.0895,
      "step": 7108
    },
    {
      "epoch": 1.6335018382352942,
      "grad_norm": 1.3636597394943237,
      "learning_rate": 7.482638888888889e-06,
      "loss": 0.1264,
      "step": 7109
    },
    {
      "epoch": 1.6337316176470589,
      "grad_norm": 1.8227308988571167,
      "learning_rate": 7.4821282679738576e-06,
      "loss": 0.0933,
      "step": 7110
    },
    {
      "epoch": 1.6339613970588234,
      "grad_norm": 1.570554494857788,
      "learning_rate": 7.4816176470588246e-06,
      "loss": 0.129,
      "step": 7111
    },
    {
      "epoch": 1.6341911764705883,
      "grad_norm": 1.8462576866149902,
      "learning_rate": 7.481107026143792e-06,
      "loss": 0.1234,
      "step": 7112
    },
    {
      "epoch": 1.6344209558823528,
      "grad_norm": 1.6014270782470703,
      "learning_rate": 7.480596405228759e-06,
      "loss": 0.1324,
      "step": 7113
    },
    {
      "epoch": 1.6346507352941178,
      "grad_norm": 1.489842176437378,
      "learning_rate": 7.4800857843137265e-06,
      "loss": 0.1152,
      "step": 7114
    },
    {
      "epoch": 1.6348805147058822,
      "grad_norm": 2.0343921184539795,
      "learning_rate": 7.4795751633986935e-06,
      "loss": 0.1228,
      "step": 7115
    },
    {
      "epoch": 1.6351102941176472,
      "grad_norm": 1.9781278371810913,
      "learning_rate": 7.4790645424836605e-06,
      "loss": 0.1657,
      "step": 7116
    },
    {
      "epoch": 1.6353400735294117,
      "grad_norm": 1.6398358345031738,
      "learning_rate": 7.4785539215686275e-06,
      "loss": 0.117,
      "step": 7117
    },
    {
      "epoch": 1.6355698529411766,
      "grad_norm": 1.92817223072052,
      "learning_rate": 7.478043300653595e-06,
      "loss": 0.1649,
      "step": 7118
    },
    {
      "epoch": 1.6357996323529411,
      "grad_norm": 1.8361880779266357,
      "learning_rate": 7.477532679738562e-06,
      "loss": 0.1444,
      "step": 7119
    },
    {
      "epoch": 1.6360294117647058,
      "grad_norm": 1.850094199180603,
      "learning_rate": 7.47702205882353e-06,
      "loss": 0.1021,
      "step": 7120
    },
    {
      "epoch": 1.6362591911764706,
      "grad_norm": 1.7721995115280151,
      "learning_rate": 7.476511437908497e-06,
      "loss": 0.1471,
      "step": 7121
    },
    {
      "epoch": 1.6364889705882353,
      "grad_norm": 2.196514129638672,
      "learning_rate": 7.476000816993465e-06,
      "loss": 0.1064,
      "step": 7122
    },
    {
      "epoch": 1.63671875,
      "grad_norm": 1.287322759628296,
      "learning_rate": 7.475490196078432e-06,
      "loss": 0.1036,
      "step": 7123
    },
    {
      "epoch": 1.6369485294117647,
      "grad_norm": 1.27289879322052,
      "learning_rate": 7.474979575163399e-06,
      "loss": 0.1065,
      "step": 7124
    },
    {
      "epoch": 1.6371783088235294,
      "grad_norm": 1.9057632684707642,
      "learning_rate": 7.474468954248366e-06,
      "loss": 0.1196,
      "step": 7125
    },
    {
      "epoch": 1.6374080882352942,
      "grad_norm": 1.6691064834594727,
      "learning_rate": 7.473958333333334e-06,
      "loss": 0.1615,
      "step": 7126
    },
    {
      "epoch": 1.6376378676470589,
      "grad_norm": 1.459852695465088,
      "learning_rate": 7.473447712418301e-06,
      "loss": 0.1163,
      "step": 7127
    },
    {
      "epoch": 1.6378676470588234,
      "grad_norm": 1.9012387990951538,
      "learning_rate": 7.472937091503268e-06,
      "loss": 0.151,
      "step": 7128
    },
    {
      "epoch": 1.6380974264705883,
      "grad_norm": 1.2248364686965942,
      "learning_rate": 7.472426470588235e-06,
      "loss": 0.0874,
      "step": 7129
    },
    {
      "epoch": 1.6383272058823528,
      "grad_norm": 1.5334101915359497,
      "learning_rate": 7.471915849673204e-06,
      "loss": 0.1161,
      "step": 7130
    },
    {
      "epoch": 1.6385569852941178,
      "grad_norm": 1.5833654403686523,
      "learning_rate": 7.471405228758171e-06,
      "loss": 0.079,
      "step": 7131
    },
    {
      "epoch": 1.6387867647058822,
      "grad_norm": 1.2434993982315063,
      "learning_rate": 7.470894607843138e-06,
      "loss": 0.0783,
      "step": 7132
    },
    {
      "epoch": 1.6390165441176472,
      "grad_norm": 1.599029779434204,
      "learning_rate": 7.470383986928105e-06,
      "loss": 0.105,
      "step": 7133
    },
    {
      "epoch": 1.6392463235294117,
      "grad_norm": 1.6016234159469604,
      "learning_rate": 7.469873366013073e-06,
      "loss": 0.1038,
      "step": 7134
    },
    {
      "epoch": 1.6394761029411766,
      "grad_norm": 1.7908846139907837,
      "learning_rate": 7.46936274509804e-06,
      "loss": 0.094,
      "step": 7135
    },
    {
      "epoch": 1.6397058823529411,
      "grad_norm": 1.3632749319076538,
      "learning_rate": 7.468852124183007e-06,
      "loss": 0.1236,
      "step": 7136
    },
    {
      "epoch": 1.6399356617647058,
      "grad_norm": 1.9800395965576172,
      "learning_rate": 7.468341503267974e-06,
      "loss": 0.1324,
      "step": 7137
    },
    {
      "epoch": 1.6401654411764706,
      "grad_norm": 1.8242700099945068,
      "learning_rate": 7.4678308823529424e-06,
      "loss": 0.1102,
      "step": 7138
    },
    {
      "epoch": 1.6403952205882353,
      "grad_norm": 1.4024711847305298,
      "learning_rate": 7.4673202614379094e-06,
      "loss": 0.0775,
      "step": 7139
    },
    {
      "epoch": 1.640625,
      "grad_norm": 1.2153290510177612,
      "learning_rate": 7.4668096405228765e-06,
      "loss": 0.0871,
      "step": 7140
    },
    {
      "epoch": 1.6408547794117647,
      "grad_norm": 1.8438262939453125,
      "learning_rate": 7.4662990196078435e-06,
      "loss": 0.1161,
      "step": 7141
    },
    {
      "epoch": 1.6410845588235294,
      "grad_norm": 1.746119499206543,
      "learning_rate": 7.465788398692811e-06,
      "loss": 0.1183,
      "step": 7142
    },
    {
      "epoch": 1.6413143382352942,
      "grad_norm": 1.4935836791992188,
      "learning_rate": 7.465277777777778e-06,
      "loss": 0.099,
      "step": 7143
    },
    {
      "epoch": 1.6415441176470589,
      "grad_norm": 1.6016491651535034,
      "learning_rate": 7.464767156862745e-06,
      "loss": 0.0981,
      "step": 7144
    },
    {
      "epoch": 1.6417738970588234,
      "grad_norm": 1.645955204963684,
      "learning_rate": 7.464256535947712e-06,
      "loss": 0.1056,
      "step": 7145
    },
    {
      "epoch": 1.6420036764705883,
      "grad_norm": 1.4460821151733398,
      "learning_rate": 7.463745915032681e-06,
      "loss": 0.1137,
      "step": 7146
    },
    {
      "epoch": 1.6422334558823528,
      "grad_norm": 2.4398951530456543,
      "learning_rate": 7.463235294117648e-06,
      "loss": 0.1314,
      "step": 7147
    },
    {
      "epoch": 1.6424632352941178,
      "grad_norm": 2.3245370388031006,
      "learning_rate": 7.462724673202615e-06,
      "loss": 0.1235,
      "step": 7148
    },
    {
      "epoch": 1.6426930147058822,
      "grad_norm": 1.6724069118499756,
      "learning_rate": 7.462214052287582e-06,
      "loss": 0.1113,
      "step": 7149
    },
    {
      "epoch": 1.6429227941176472,
      "grad_norm": 2.1091065406799316,
      "learning_rate": 7.46170343137255e-06,
      "loss": 0.0998,
      "step": 7150
    },
    {
      "epoch": 1.6431525735294117,
      "grad_norm": 1.5210484266281128,
      "learning_rate": 7.461192810457517e-06,
      "loss": 0.1221,
      "step": 7151
    },
    {
      "epoch": 1.6433823529411766,
      "grad_norm": 1.4488168954849243,
      "learning_rate": 7.460682189542484e-06,
      "loss": 0.1016,
      "step": 7152
    },
    {
      "epoch": 1.6436121323529411,
      "grad_norm": 1.4332997798919678,
      "learning_rate": 7.460171568627451e-06,
      "loss": 0.1183,
      "step": 7153
    },
    {
      "epoch": 1.6438419117647058,
      "grad_norm": 1.3874781131744385,
      "learning_rate": 7.45966094771242e-06,
      "loss": 0.0858,
      "step": 7154
    },
    {
      "epoch": 1.6440716911764706,
      "grad_norm": 1.5631821155548096,
      "learning_rate": 7.459150326797387e-06,
      "loss": 0.1123,
      "step": 7155
    },
    {
      "epoch": 1.6443014705882353,
      "grad_norm": 1.6657180786132812,
      "learning_rate": 7.458639705882354e-06,
      "loss": 0.1225,
      "step": 7156
    },
    {
      "epoch": 1.64453125,
      "grad_norm": 1.4986320734024048,
      "learning_rate": 7.458129084967321e-06,
      "loss": 0.1201,
      "step": 7157
    },
    {
      "epoch": 1.6447610294117647,
      "grad_norm": 1.7943227291107178,
      "learning_rate": 7.457618464052289e-06,
      "loss": 0.1327,
      "step": 7158
    },
    {
      "epoch": 1.6449908088235294,
      "grad_norm": 1.6442451477050781,
      "learning_rate": 7.457107843137256e-06,
      "loss": 0.1072,
      "step": 7159
    },
    {
      "epoch": 1.6452205882352942,
      "grad_norm": 1.4960886240005493,
      "learning_rate": 7.456597222222223e-06,
      "loss": 0.1062,
      "step": 7160
    },
    {
      "epoch": 1.6454503676470589,
      "grad_norm": 1.5288114547729492,
      "learning_rate": 7.45608660130719e-06,
      "loss": 0.1364,
      "step": 7161
    },
    {
      "epoch": 1.6456801470588234,
      "grad_norm": 1.7476853132247925,
      "learning_rate": 7.4555759803921576e-06,
      "loss": 0.1285,
      "step": 7162
    },
    {
      "epoch": 1.6459099264705883,
      "grad_norm": 1.9162629842758179,
      "learning_rate": 7.4550653594771246e-06,
      "loss": 0.1491,
      "step": 7163
    },
    {
      "epoch": 1.6461397058823528,
      "grad_norm": 1.583727240562439,
      "learning_rate": 7.454554738562092e-06,
      "loss": 0.1111,
      "step": 7164
    },
    {
      "epoch": 1.6463694852941178,
      "grad_norm": 2.421778440475464,
      "learning_rate": 7.4540441176470594e-06,
      "loss": 0.1184,
      "step": 7165
    },
    {
      "epoch": 1.6465992647058822,
      "grad_norm": 1.7317616939544678,
      "learning_rate": 7.453533496732027e-06,
      "loss": 0.1118,
      "step": 7166
    },
    {
      "epoch": 1.6468290441176472,
      "grad_norm": 1.6664382219314575,
      "learning_rate": 7.453022875816994e-06,
      "loss": 0.1145,
      "step": 7167
    },
    {
      "epoch": 1.6470588235294117,
      "grad_norm": 1.417844533920288,
      "learning_rate": 7.452512254901961e-06,
      "loss": 0.1131,
      "step": 7168
    },
    {
      "epoch": 1.6472886029411766,
      "grad_norm": 1.5785529613494873,
      "learning_rate": 7.452001633986928e-06,
      "loss": 0.1402,
      "step": 7169
    },
    {
      "epoch": 1.6475183823529411,
      "grad_norm": 1.6143290996551514,
      "learning_rate": 7.451491013071896e-06,
      "loss": 0.0718,
      "step": 7170
    },
    {
      "epoch": 1.6477481617647058,
      "grad_norm": 1.9205858707427979,
      "learning_rate": 7.450980392156863e-06,
      "loss": 0.1264,
      "step": 7171
    },
    {
      "epoch": 1.6479779411764706,
      "grad_norm": 1.5647521018981934,
      "learning_rate": 7.45046977124183e-06,
      "loss": 0.0861,
      "step": 7172
    },
    {
      "epoch": 1.6482077205882353,
      "grad_norm": 1.3476307392120361,
      "learning_rate": 7.449959150326797e-06,
      "loss": 0.1157,
      "step": 7173
    },
    {
      "epoch": 1.6484375,
      "grad_norm": 1.4917300939559937,
      "learning_rate": 7.449448529411766e-06,
      "loss": 0.1148,
      "step": 7174
    },
    {
      "epoch": 1.6486672794117647,
      "grad_norm": 1.8719099760055542,
      "learning_rate": 7.448937908496733e-06,
      "loss": 0.09,
      "step": 7175
    },
    {
      "epoch": 1.6488970588235294,
      "grad_norm": 1.9286515712738037,
      "learning_rate": 7.4484272875817e-06,
      "loss": 0.1445,
      "step": 7176
    },
    {
      "epoch": 1.6491268382352942,
      "grad_norm": 2.5565526485443115,
      "learning_rate": 7.447916666666667e-06,
      "loss": 0.123,
      "step": 7177
    },
    {
      "epoch": 1.6493566176470589,
      "grad_norm": 1.6425386667251587,
      "learning_rate": 7.447406045751635e-06,
      "loss": 0.1316,
      "step": 7178
    },
    {
      "epoch": 1.6495863970588234,
      "grad_norm": 1.3322923183441162,
      "learning_rate": 7.446895424836602e-06,
      "loss": 0.1024,
      "step": 7179
    },
    {
      "epoch": 1.6498161764705883,
      "grad_norm": 1.663245677947998,
      "learning_rate": 7.446384803921569e-06,
      "loss": 0.0993,
      "step": 7180
    },
    {
      "epoch": 1.6500459558823528,
      "grad_norm": 1.7245099544525146,
      "learning_rate": 7.445874183006536e-06,
      "loss": 0.1541,
      "step": 7181
    },
    {
      "epoch": 1.6502757352941178,
      "grad_norm": 2.108790397644043,
      "learning_rate": 7.445363562091505e-06,
      "loss": 0.1682,
      "step": 7182
    },
    {
      "epoch": 1.6505055147058822,
      "grad_norm": 2.0676164627075195,
      "learning_rate": 7.444852941176472e-06,
      "loss": 0.1142,
      "step": 7183
    },
    {
      "epoch": 1.6507352941176472,
      "grad_norm": 1.9458532333374023,
      "learning_rate": 7.444342320261439e-06,
      "loss": 0.1338,
      "step": 7184
    },
    {
      "epoch": 1.6509650735294117,
      "grad_norm": 1.1784424781799316,
      "learning_rate": 7.443831699346406e-06,
      "loss": 0.0853,
      "step": 7185
    },
    {
      "epoch": 1.6511948529411766,
      "grad_norm": 1.7526313066482544,
      "learning_rate": 7.4433210784313735e-06,
      "loss": 0.1497,
      "step": 7186
    },
    {
      "epoch": 1.6514246323529411,
      "grad_norm": 1.4385085105895996,
      "learning_rate": 7.4428104575163405e-06,
      "loss": 0.0837,
      "step": 7187
    },
    {
      "epoch": 1.6516544117647058,
      "grad_norm": 1.5912010669708252,
      "learning_rate": 7.4422998366013075e-06,
      "loss": 0.0874,
      "step": 7188
    },
    {
      "epoch": 1.6518841911764706,
      "grad_norm": 1.5603877305984497,
      "learning_rate": 7.4417892156862746e-06,
      "loss": 0.0924,
      "step": 7189
    },
    {
      "epoch": 1.6521139705882353,
      "grad_norm": 1.452851414680481,
      "learning_rate": 7.441278594771243e-06,
      "loss": 0.1187,
      "step": 7190
    },
    {
      "epoch": 1.65234375,
      "grad_norm": 1.736045002937317,
      "learning_rate": 7.44076797385621e-06,
      "loss": 0.1011,
      "step": 7191
    },
    {
      "epoch": 1.6525735294117647,
      "grad_norm": 1.5518454313278198,
      "learning_rate": 7.440257352941177e-06,
      "loss": 0.1356,
      "step": 7192
    },
    {
      "epoch": 1.6528033088235294,
      "grad_norm": 1.949655532836914,
      "learning_rate": 7.439746732026144e-06,
      "loss": 0.1087,
      "step": 7193
    },
    {
      "epoch": 1.6530330882352942,
      "grad_norm": 1.7091121673583984,
      "learning_rate": 7.439236111111112e-06,
      "loss": 0.1222,
      "step": 7194
    },
    {
      "epoch": 1.6532628676470589,
      "grad_norm": 2.3093249797821045,
      "learning_rate": 7.438725490196079e-06,
      "loss": 0.1721,
      "step": 7195
    },
    {
      "epoch": 1.6534926470588234,
      "grad_norm": 1.8283188343048096,
      "learning_rate": 7.438214869281046e-06,
      "loss": 0.0955,
      "step": 7196
    },
    {
      "epoch": 1.6537224264705883,
      "grad_norm": 1.9196141958236694,
      "learning_rate": 7.437704248366013e-06,
      "loss": 0.1194,
      "step": 7197
    },
    {
      "epoch": 1.6539522058823528,
      "grad_norm": 1.4322924613952637,
      "learning_rate": 7.437193627450981e-06,
      "loss": 0.1032,
      "step": 7198
    },
    {
      "epoch": 1.6541819852941178,
      "grad_norm": 1.2886524200439453,
      "learning_rate": 7.436683006535949e-06,
      "loss": 0.0854,
      "step": 7199
    },
    {
      "epoch": 1.6544117647058822,
      "grad_norm": 1.9577797651290894,
      "learning_rate": 7.436172385620916e-06,
      "loss": 0.1294,
      "step": 7200
    },
    {
      "epoch": 1.6546415441176472,
      "grad_norm": 1.284864902496338,
      "learning_rate": 7.435661764705883e-06,
      "loss": 0.0798,
      "step": 7201
    },
    {
      "epoch": 1.6548713235294117,
      "grad_norm": 2.4125232696533203,
      "learning_rate": 7.435151143790851e-06,
      "loss": 0.0835,
      "step": 7202
    },
    {
      "epoch": 1.6551011029411766,
      "grad_norm": 1.524397850036621,
      "learning_rate": 7.434640522875818e-06,
      "loss": 0.095,
      "step": 7203
    },
    {
      "epoch": 1.6553308823529411,
      "grad_norm": 2.098400592803955,
      "learning_rate": 7.434129901960785e-06,
      "loss": 0.1299,
      "step": 7204
    },
    {
      "epoch": 1.6555606617647058,
      "grad_norm": 1.4181842803955078,
      "learning_rate": 7.433619281045752e-06,
      "loss": 0.1034,
      "step": 7205
    },
    {
      "epoch": 1.6557904411764706,
      "grad_norm": 1.5195400714874268,
      "learning_rate": 7.43310866013072e-06,
      "loss": 0.1121,
      "step": 7206
    },
    {
      "epoch": 1.6560202205882353,
      "grad_norm": 2.082883358001709,
      "learning_rate": 7.432598039215687e-06,
      "loss": 0.1316,
      "step": 7207
    },
    {
      "epoch": 1.65625,
      "grad_norm": 1.8662086725234985,
      "learning_rate": 7.432087418300654e-06,
      "loss": 0.1216,
      "step": 7208
    },
    {
      "epoch": 1.6564797794117647,
      "grad_norm": 2.0083746910095215,
      "learning_rate": 7.431576797385622e-06,
      "loss": 0.1473,
      "step": 7209
    },
    {
      "epoch": 1.6567095588235294,
      "grad_norm": 1.9711599349975586,
      "learning_rate": 7.4310661764705895e-06,
      "loss": 0.1369,
      "step": 7210
    },
    {
      "epoch": 1.6569393382352942,
      "grad_norm": 1.44488525390625,
      "learning_rate": 7.4305555555555565e-06,
      "loss": 0.0725,
      "step": 7211
    },
    {
      "epoch": 1.6571691176470589,
      "grad_norm": 1.3703882694244385,
      "learning_rate": 7.4300449346405235e-06,
      "loss": 0.093,
      "step": 7212
    },
    {
      "epoch": 1.6573988970588234,
      "grad_norm": 2.1451127529144287,
      "learning_rate": 7.4295343137254905e-06,
      "loss": 0.0899,
      "step": 7213
    },
    {
      "epoch": 1.6576286764705883,
      "grad_norm": 1.806516408920288,
      "learning_rate": 7.429023692810458e-06,
      "loss": 0.0984,
      "step": 7214
    },
    {
      "epoch": 1.6578584558823528,
      "grad_norm": 1.3151944875717163,
      "learning_rate": 7.428513071895425e-06,
      "loss": 0.0952,
      "step": 7215
    },
    {
      "epoch": 1.6580882352941178,
      "grad_norm": 1.4593979120254517,
      "learning_rate": 7.4280024509803924e-06,
      "loss": 0.1231,
      "step": 7216
    },
    {
      "epoch": 1.6583180147058822,
      "grad_norm": 1.699053168296814,
      "learning_rate": 7.4274918300653594e-06,
      "loss": 0.1488,
      "step": 7217
    },
    {
      "epoch": 1.6585477941176472,
      "grad_norm": 1.5634361505508423,
      "learning_rate": 7.426981209150328e-06,
      "loss": 0.1222,
      "step": 7218
    },
    {
      "epoch": 1.6587775735294117,
      "grad_norm": 1.862534523010254,
      "learning_rate": 7.426470588235295e-06,
      "loss": 0.1255,
      "step": 7219
    },
    {
      "epoch": 1.6590073529411766,
      "grad_norm": 1.9088678359985352,
      "learning_rate": 7.425959967320262e-06,
      "loss": 0.1384,
      "step": 7220
    },
    {
      "epoch": 1.6592371323529411,
      "grad_norm": 2.1208624839782715,
      "learning_rate": 7.425449346405229e-06,
      "loss": 0.1068,
      "step": 7221
    },
    {
      "epoch": 1.6594669117647058,
      "grad_norm": 1.7620099782943726,
      "learning_rate": 7.424938725490197e-06,
      "loss": 0.1454,
      "step": 7222
    },
    {
      "epoch": 1.6596966911764706,
      "grad_norm": 2.231588840484619,
      "learning_rate": 7.424428104575164e-06,
      "loss": 0.1412,
      "step": 7223
    },
    {
      "epoch": 1.6599264705882353,
      "grad_norm": 1.4201503992080688,
      "learning_rate": 7.423917483660131e-06,
      "loss": 0.0885,
      "step": 7224
    },
    {
      "epoch": 1.66015625,
      "grad_norm": 1.6935776472091675,
      "learning_rate": 7.423406862745098e-06,
      "loss": 0.1361,
      "step": 7225
    },
    {
      "epoch": 1.6603860294117647,
      "grad_norm": 1.8118433952331543,
      "learning_rate": 7.422896241830067e-06,
      "loss": 0.1406,
      "step": 7226
    },
    {
      "epoch": 1.6606158088235294,
      "grad_norm": 1.5863162279129028,
      "learning_rate": 7.422385620915034e-06,
      "loss": 0.0906,
      "step": 7227
    },
    {
      "epoch": 1.6608455882352942,
      "grad_norm": 1.3456811904907227,
      "learning_rate": 7.421875000000001e-06,
      "loss": 0.1173,
      "step": 7228
    },
    {
      "epoch": 1.6610753676470589,
      "grad_norm": 1.8696097135543823,
      "learning_rate": 7.421364379084968e-06,
      "loss": 0.1291,
      "step": 7229
    },
    {
      "epoch": 1.6613051470588234,
      "grad_norm": 2.2798218727111816,
      "learning_rate": 7.420853758169935e-06,
      "loss": 0.1125,
      "step": 7230
    },
    {
      "epoch": 1.6615349264705883,
      "grad_norm": 2.1666452884674072,
      "learning_rate": 7.420343137254903e-06,
      "loss": 0.1368,
      "step": 7231
    },
    {
      "epoch": 1.6617647058823528,
      "grad_norm": 2.0913734436035156,
      "learning_rate": 7.41983251633987e-06,
      "loss": 0.0871,
      "step": 7232
    },
    {
      "epoch": 1.6619944852941178,
      "grad_norm": 1.3085408210754395,
      "learning_rate": 7.419321895424837e-06,
      "loss": 0.1006,
      "step": 7233
    },
    {
      "epoch": 1.6622242647058822,
      "grad_norm": 1.7370951175689697,
      "learning_rate": 7.418811274509804e-06,
      "loss": 0.0963,
      "step": 7234
    },
    {
      "epoch": 1.6624540441176472,
      "grad_norm": 1.5914149284362793,
      "learning_rate": 7.4183006535947725e-06,
      "loss": 0.1038,
      "step": 7235
    },
    {
      "epoch": 1.6626838235294117,
      "grad_norm": 2.081768751144409,
      "learning_rate": 7.4177900326797395e-06,
      "loss": 0.176,
      "step": 7236
    },
    {
      "epoch": 1.6629136029411766,
      "grad_norm": 1.5847437381744385,
      "learning_rate": 7.4172794117647065e-06,
      "loss": 0.0952,
      "step": 7237
    },
    {
      "epoch": 1.6631433823529411,
      "grad_norm": 2.1246767044067383,
      "learning_rate": 7.4167687908496735e-06,
      "loss": 0.1196,
      "step": 7238
    },
    {
      "epoch": 1.6633731617647058,
      "grad_norm": 1.7530330419540405,
      "learning_rate": 7.416258169934641e-06,
      "loss": 0.1166,
      "step": 7239
    },
    {
      "epoch": 1.6636029411764706,
      "grad_norm": 1.829007863998413,
      "learning_rate": 7.415747549019608e-06,
      "loss": 0.1165,
      "step": 7240
    },
    {
      "epoch": 1.6638327205882353,
      "grad_norm": 1.935882568359375,
      "learning_rate": 7.415236928104575e-06,
      "loss": 0.1159,
      "step": 7241
    },
    {
      "epoch": 1.6640625,
      "grad_norm": 1.8426662683486938,
      "learning_rate": 7.414726307189542e-06,
      "loss": 0.1283,
      "step": 7242
    },
    {
      "epoch": 1.6642922794117647,
      "grad_norm": 1.7580077648162842,
      "learning_rate": 7.414215686274511e-06,
      "loss": 0.0895,
      "step": 7243
    },
    {
      "epoch": 1.6645220588235294,
      "grad_norm": 1.9717921018600464,
      "learning_rate": 7.413705065359478e-06,
      "loss": 0.1361,
      "step": 7244
    },
    {
      "epoch": 1.6647518382352942,
      "grad_norm": 1.8278642892837524,
      "learning_rate": 7.413194444444445e-06,
      "loss": 0.1233,
      "step": 7245
    },
    {
      "epoch": 1.6649816176470589,
      "grad_norm": 1.8526560068130493,
      "learning_rate": 7.412683823529412e-06,
      "loss": 0.1194,
      "step": 7246
    },
    {
      "epoch": 1.6652113970588234,
      "grad_norm": 1.4734889268875122,
      "learning_rate": 7.41217320261438e-06,
      "loss": 0.0767,
      "step": 7247
    },
    {
      "epoch": 1.6654411764705883,
      "grad_norm": 1.3955641984939575,
      "learning_rate": 7.411662581699347e-06,
      "loss": 0.0855,
      "step": 7248
    },
    {
      "epoch": 1.6656709558823528,
      "grad_norm": 1.368150234222412,
      "learning_rate": 7.411151960784314e-06,
      "loss": 0.0971,
      "step": 7249
    },
    {
      "epoch": 1.6659007352941178,
      "grad_norm": 1.8692104816436768,
      "learning_rate": 7.410641339869281e-06,
      "loss": 0.1104,
      "step": 7250
    },
    {
      "epoch": 1.6661305147058822,
      "grad_norm": 2.0858774185180664,
      "learning_rate": 7.410130718954249e-06,
      "loss": 0.1433,
      "step": 7251
    },
    {
      "epoch": 1.6663602941176472,
      "grad_norm": 2.311748504638672,
      "learning_rate": 7.409620098039216e-06,
      "loss": 0.1426,
      "step": 7252
    },
    {
      "epoch": 1.6665900735294117,
      "grad_norm": 1.7748373746871948,
      "learning_rate": 7.409109477124183e-06,
      "loss": 0.0953,
      "step": 7253
    },
    {
      "epoch": 1.6668198529411766,
      "grad_norm": 1.6281962394714355,
      "learning_rate": 7.408598856209151e-06,
      "loss": 0.0804,
      "step": 7254
    },
    {
      "epoch": 1.6670496323529411,
      "grad_norm": 1.759580135345459,
      "learning_rate": 7.408088235294119e-06,
      "loss": 0.1221,
      "step": 7255
    },
    {
      "epoch": 1.6672794117647058,
      "grad_norm": 1.6589936017990112,
      "learning_rate": 7.407577614379086e-06,
      "loss": 0.091,
      "step": 7256
    },
    {
      "epoch": 1.6675091911764706,
      "grad_norm": 2.1632556915283203,
      "learning_rate": 7.407066993464053e-06,
      "loss": 0.1546,
      "step": 7257
    },
    {
      "epoch": 1.6677389705882353,
      "grad_norm": 1.9005075693130493,
      "learning_rate": 7.40655637254902e-06,
      "loss": 0.0915,
      "step": 7258
    },
    {
      "epoch": 1.66796875,
      "grad_norm": 1.7999117374420166,
      "learning_rate": 7.406045751633988e-06,
      "loss": 0.1564,
      "step": 7259
    },
    {
      "epoch": 1.6681985294117647,
      "grad_norm": 1.6270992755889893,
      "learning_rate": 7.405535130718955e-06,
      "loss": 0.0993,
      "step": 7260
    },
    {
      "epoch": 1.6684283088235294,
      "grad_norm": 1.733547568321228,
      "learning_rate": 7.405024509803922e-06,
      "loss": 0.1405,
      "step": 7261
    },
    {
      "epoch": 1.6686580882352942,
      "grad_norm": 1.152861475944519,
      "learning_rate": 7.404513888888889e-06,
      "loss": 0.0767,
      "step": 7262
    },
    {
      "epoch": 1.6688878676470589,
      "grad_norm": 1.4986786842346191,
      "learning_rate": 7.404003267973857e-06,
      "loss": 0.085,
      "step": 7263
    },
    {
      "epoch": 1.6691176470588234,
      "grad_norm": 1.485432744026184,
      "learning_rate": 7.403492647058824e-06,
      "loss": 0.119,
      "step": 7264
    },
    {
      "epoch": 1.6693474264705883,
      "grad_norm": 2.018048048019409,
      "learning_rate": 7.402982026143791e-06,
      "loss": 0.0914,
      "step": 7265
    },
    {
      "epoch": 1.6695772058823528,
      "grad_norm": 2.1369924545288086,
      "learning_rate": 7.402471405228758e-06,
      "loss": 0.1346,
      "step": 7266
    },
    {
      "epoch": 1.6698069852941178,
      "grad_norm": 2.056964635848999,
      "learning_rate": 7.401960784313726e-06,
      "loss": 0.1471,
      "step": 7267
    },
    {
      "epoch": 1.6700367647058822,
      "grad_norm": 1.5575642585754395,
      "learning_rate": 7.401450163398693e-06,
      "loss": 0.1282,
      "step": 7268
    },
    {
      "epoch": 1.6702665441176472,
      "grad_norm": 2.1354482173919678,
      "learning_rate": 7.40093954248366e-06,
      "loss": 0.1464,
      "step": 7269
    },
    {
      "epoch": 1.6704963235294117,
      "grad_norm": 1.7693222761154175,
      "learning_rate": 7.400428921568627e-06,
      "loss": 0.1194,
      "step": 7270
    },
    {
      "epoch": 1.6707261029411766,
      "grad_norm": 1.7852638959884644,
      "learning_rate": 7.399918300653596e-06,
      "loss": 0.1116,
      "step": 7271
    },
    {
      "epoch": 1.6709558823529411,
      "grad_norm": 1.5700256824493408,
      "learning_rate": 7.399407679738563e-06,
      "loss": 0.1009,
      "step": 7272
    },
    {
      "epoch": 1.6711856617647058,
      "grad_norm": 1.7535123825073242,
      "learning_rate": 7.39889705882353e-06,
      "loss": 0.1087,
      "step": 7273
    },
    {
      "epoch": 1.6714154411764706,
      "grad_norm": 1.6496025323867798,
      "learning_rate": 7.398386437908497e-06,
      "loss": 0.1036,
      "step": 7274
    },
    {
      "epoch": 1.6716452205882353,
      "grad_norm": 1.5394237041473389,
      "learning_rate": 7.397875816993465e-06,
      "loss": 0.1314,
      "step": 7275
    },
    {
      "epoch": 1.671875,
      "grad_norm": 1.88933265209198,
      "learning_rate": 7.397365196078432e-06,
      "loss": 0.1373,
      "step": 7276
    },
    {
      "epoch": 1.6721047794117647,
      "grad_norm": 1.8373230695724487,
      "learning_rate": 7.396854575163399e-06,
      "loss": 0.0977,
      "step": 7277
    },
    {
      "epoch": 1.6723345588235294,
      "grad_norm": 2.139462947845459,
      "learning_rate": 7.396343954248366e-06,
      "loss": 0.1201,
      "step": 7278
    },
    {
      "epoch": 1.6725643382352942,
      "grad_norm": 1.5358637571334839,
      "learning_rate": 7.395833333333335e-06,
      "loss": 0.1024,
      "step": 7279
    },
    {
      "epoch": 1.6727941176470589,
      "grad_norm": 1.5891587734222412,
      "learning_rate": 7.395322712418302e-06,
      "loss": 0.1313,
      "step": 7280
    },
    {
      "epoch": 1.6730238970588234,
      "grad_norm": 1.8501025438308716,
      "learning_rate": 7.394812091503269e-06,
      "loss": 0.1051,
      "step": 7281
    },
    {
      "epoch": 1.6732536764705883,
      "grad_norm": 2.047720432281494,
      "learning_rate": 7.394301470588236e-06,
      "loss": 0.149,
      "step": 7282
    },
    {
      "epoch": 1.6734834558823528,
      "grad_norm": 1.7113322019577026,
      "learning_rate": 7.3937908496732036e-06,
      "loss": 0.138,
      "step": 7283
    },
    {
      "epoch": 1.6737132352941178,
      "grad_norm": 1.5430591106414795,
      "learning_rate": 7.393280228758171e-06,
      "loss": 0.11,
      "step": 7284
    },
    {
      "epoch": 1.6739430147058822,
      "grad_norm": 2.057382583618164,
      "learning_rate": 7.392769607843138e-06,
      "loss": 0.1664,
      "step": 7285
    },
    {
      "epoch": 1.6741727941176472,
      "grad_norm": 1.421199917793274,
      "learning_rate": 7.392258986928105e-06,
      "loss": 0.1095,
      "step": 7286
    },
    {
      "epoch": 1.6744025735294117,
      "grad_norm": 1.523983359336853,
      "learning_rate": 7.3917483660130725e-06,
      "loss": 0.1477,
      "step": 7287
    },
    {
      "epoch": 1.6746323529411766,
      "grad_norm": 1.8579097986221313,
      "learning_rate": 7.39123774509804e-06,
      "loss": 0.1649,
      "step": 7288
    },
    {
      "epoch": 1.6748621323529411,
      "grad_norm": 2.043063163757324,
      "learning_rate": 7.390727124183007e-06,
      "loss": 0.1668,
      "step": 7289
    },
    {
      "epoch": 1.6750919117647058,
      "grad_norm": 2.770707130432129,
      "learning_rate": 7.390216503267974e-06,
      "loss": 0.1552,
      "step": 7290
    },
    {
      "epoch": 1.6753216911764706,
      "grad_norm": 1.4708491563796997,
      "learning_rate": 7.389705882352942e-06,
      "loss": 0.1324,
      "step": 7291
    },
    {
      "epoch": 1.6755514705882353,
      "grad_norm": 1.4787591695785522,
      "learning_rate": 7.389195261437909e-06,
      "loss": 0.1305,
      "step": 7292
    },
    {
      "epoch": 1.67578125,
      "grad_norm": 1.4286350011825562,
      "learning_rate": 7.388684640522876e-06,
      "loss": 0.1055,
      "step": 7293
    },
    {
      "epoch": 1.6760110294117647,
      "grad_norm": 1.8870956897735596,
      "learning_rate": 7.388174019607843e-06,
      "loss": 0.1529,
      "step": 7294
    },
    {
      "epoch": 1.6762408088235294,
      "grad_norm": 2.1523191928863525,
      "learning_rate": 7.387663398692811e-06,
      "loss": 0.1348,
      "step": 7295
    },
    {
      "epoch": 1.6764705882352942,
      "grad_norm": 1.3981969356536865,
      "learning_rate": 7.387152777777778e-06,
      "loss": 0.1186,
      "step": 7296
    },
    {
      "epoch": 1.6767003676470589,
      "grad_norm": 2.211895227432251,
      "learning_rate": 7.386642156862745e-06,
      "loss": 0.1338,
      "step": 7297
    },
    {
      "epoch": 1.6769301470588234,
      "grad_norm": 1.390030860900879,
      "learning_rate": 7.386131535947712e-06,
      "loss": 0.1056,
      "step": 7298
    },
    {
      "epoch": 1.6771599264705883,
      "grad_norm": 2.1807327270507812,
      "learning_rate": 7.385620915032681e-06,
      "loss": 0.1385,
      "step": 7299
    },
    {
      "epoch": 1.6773897058823528,
      "grad_norm": 1.6604095697402954,
      "learning_rate": 7.385110294117648e-06,
      "loss": 0.1474,
      "step": 7300
    },
    {
      "epoch": 1.6776194852941178,
      "grad_norm": 1.5119857788085938,
      "learning_rate": 7.384599673202615e-06,
      "loss": 0.1047,
      "step": 7301
    },
    {
      "epoch": 1.6778492647058822,
      "grad_norm": 1.9945544004440308,
      "learning_rate": 7.384089052287582e-06,
      "loss": 0.1117,
      "step": 7302
    },
    {
      "epoch": 1.6780790441176472,
      "grad_norm": 1.6561787128448486,
      "learning_rate": 7.38357843137255e-06,
      "loss": 0.1001,
      "step": 7303
    },
    {
      "epoch": 1.6783088235294117,
      "grad_norm": 1.5950216054916382,
      "learning_rate": 7.383067810457517e-06,
      "loss": 0.1035,
      "step": 7304
    },
    {
      "epoch": 1.6785386029411766,
      "grad_norm": 1.387254238128662,
      "learning_rate": 7.382557189542484e-06,
      "loss": 0.0844,
      "step": 7305
    },
    {
      "epoch": 1.6787683823529411,
      "grad_norm": 1.5191560983657837,
      "learning_rate": 7.382046568627451e-06,
      "loss": 0.1199,
      "step": 7306
    },
    {
      "epoch": 1.6789981617647058,
      "grad_norm": 1.6874366998672485,
      "learning_rate": 7.3815359477124195e-06,
      "loss": 0.1191,
      "step": 7307
    },
    {
      "epoch": 1.6792279411764706,
      "grad_norm": 1.3869696855545044,
      "learning_rate": 7.3810253267973866e-06,
      "loss": 0.1238,
      "step": 7308
    },
    {
      "epoch": 1.6794577205882353,
      "grad_norm": 2.054474115371704,
      "learning_rate": 7.3805147058823536e-06,
      "loss": 0.1393,
      "step": 7309
    },
    {
      "epoch": 1.6796875,
      "grad_norm": 2.0947041511535645,
      "learning_rate": 7.380004084967321e-06,
      "loss": 0.1462,
      "step": 7310
    },
    {
      "epoch": 1.6799172794117647,
      "grad_norm": 2.06840443611145,
      "learning_rate": 7.3794934640522884e-06,
      "loss": 0.1055,
      "step": 7311
    },
    {
      "epoch": 1.6801470588235294,
      "grad_norm": 1.4498581886291504,
      "learning_rate": 7.3789828431372555e-06,
      "loss": 0.0958,
      "step": 7312
    },
    {
      "epoch": 1.6803768382352942,
      "grad_norm": 2.1427316665649414,
      "learning_rate": 7.3784722222222225e-06,
      "loss": 0.1018,
      "step": 7313
    },
    {
      "epoch": 1.6806066176470589,
      "grad_norm": 1.7733793258666992,
      "learning_rate": 7.3779616013071895e-06,
      "loss": 0.0987,
      "step": 7314
    },
    {
      "epoch": 1.6808363970588234,
      "grad_norm": 2.2881505489349365,
      "learning_rate": 7.377450980392158e-06,
      "loss": 0.0997,
      "step": 7315
    },
    {
      "epoch": 1.6810661764705883,
      "grad_norm": 1.650546669960022,
      "learning_rate": 7.376940359477125e-06,
      "loss": 0.1012,
      "step": 7316
    },
    {
      "epoch": 1.6812959558823528,
      "grad_norm": 1.7206339836120605,
      "learning_rate": 7.376429738562092e-06,
      "loss": 0.1233,
      "step": 7317
    },
    {
      "epoch": 1.6815257352941178,
      "grad_norm": 2.004966974258423,
      "learning_rate": 7.375919117647059e-06,
      "loss": 0.1651,
      "step": 7318
    },
    {
      "epoch": 1.6817555147058822,
      "grad_norm": 1.6691943407058716,
      "learning_rate": 7.375408496732027e-06,
      "loss": 0.1267,
      "step": 7319
    },
    {
      "epoch": 1.6819852941176472,
      "grad_norm": 2.3182034492492676,
      "learning_rate": 7.374897875816994e-06,
      "loss": 0.1308,
      "step": 7320
    },
    {
      "epoch": 1.6822150735294117,
      "grad_norm": 1.3964670896530151,
      "learning_rate": 7.374387254901961e-06,
      "loss": 0.1205,
      "step": 7321
    },
    {
      "epoch": 1.6824448529411766,
      "grad_norm": 1.1019386053085327,
      "learning_rate": 7.373876633986928e-06,
      "loss": 0.0969,
      "step": 7322
    },
    {
      "epoch": 1.6826746323529411,
      "grad_norm": 1.5471352338790894,
      "learning_rate": 7.373366013071897e-06,
      "loss": 0.1126,
      "step": 7323
    },
    {
      "epoch": 1.6829044117647058,
      "grad_norm": 1.4809316396713257,
      "learning_rate": 7.372855392156864e-06,
      "loss": 0.1054,
      "step": 7324
    },
    {
      "epoch": 1.6831341911764706,
      "grad_norm": 1.6450251340866089,
      "learning_rate": 7.372344771241831e-06,
      "loss": 0.0858,
      "step": 7325
    },
    {
      "epoch": 1.6833639705882353,
      "grad_norm": 2.0162837505340576,
      "learning_rate": 7.371834150326798e-06,
      "loss": 0.126,
      "step": 7326
    },
    {
      "epoch": 1.68359375,
      "grad_norm": 2.2663769721984863,
      "learning_rate": 7.371323529411766e-06,
      "loss": 0.1663,
      "step": 7327
    },
    {
      "epoch": 1.6838235294117647,
      "grad_norm": 1.675781011581421,
      "learning_rate": 7.370812908496733e-06,
      "loss": 0.0992,
      "step": 7328
    },
    {
      "epoch": 1.6840533088235294,
      "grad_norm": 1.8804758787155151,
      "learning_rate": 7.3703022875817e-06,
      "loss": 0.116,
      "step": 7329
    },
    {
      "epoch": 1.6842830882352942,
      "grad_norm": 1.3427225351333618,
      "learning_rate": 7.369791666666667e-06,
      "loss": 0.131,
      "step": 7330
    },
    {
      "epoch": 1.6845128676470589,
      "grad_norm": 1.3217356204986572,
      "learning_rate": 7.369281045751635e-06,
      "loss": 0.0728,
      "step": 7331
    },
    {
      "epoch": 1.6847426470588234,
      "grad_norm": 1.5183892250061035,
      "learning_rate": 7.3687704248366025e-06,
      "loss": 0.1355,
      "step": 7332
    },
    {
      "epoch": 1.6849724264705883,
      "grad_norm": 1.8592063188552856,
      "learning_rate": 7.3682598039215695e-06,
      "loss": 0.1431,
      "step": 7333
    },
    {
      "epoch": 1.6852022058823528,
      "grad_norm": 1.5300401449203491,
      "learning_rate": 7.3677491830065365e-06,
      "loss": 0.0975,
      "step": 7334
    },
    {
      "epoch": 1.6854319852941178,
      "grad_norm": 1.600257158279419,
      "learning_rate": 7.367238562091504e-06,
      "loss": 0.1537,
      "step": 7335
    },
    {
      "epoch": 1.6856617647058822,
      "grad_norm": 1.8552098274230957,
      "learning_rate": 7.3667279411764714e-06,
      "loss": 0.1264,
      "step": 7336
    },
    {
      "epoch": 1.6858915441176472,
      "grad_norm": 1.3717845678329468,
      "learning_rate": 7.3662173202614384e-06,
      "loss": 0.0823,
      "step": 7337
    },
    {
      "epoch": 1.6861213235294117,
      "grad_norm": 1.4930583238601685,
      "learning_rate": 7.3657066993464055e-06,
      "loss": 0.0921,
      "step": 7338
    },
    {
      "epoch": 1.6863511029411766,
      "grad_norm": 1.6397936344146729,
      "learning_rate": 7.365196078431373e-06,
      "loss": 0.0925,
      "step": 7339
    },
    {
      "epoch": 1.6865808823529411,
      "grad_norm": 1.7994171380996704,
      "learning_rate": 7.36468545751634e-06,
      "loss": 0.115,
      "step": 7340
    },
    {
      "epoch": 1.6868106617647058,
      "grad_norm": 1.6118512153625488,
      "learning_rate": 7.364174836601307e-06,
      "loss": 0.1267,
      "step": 7341
    },
    {
      "epoch": 1.6870404411764706,
      "grad_norm": 1.5533292293548584,
      "learning_rate": 7.363664215686274e-06,
      "loss": 0.0849,
      "step": 7342
    },
    {
      "epoch": 1.6872702205882353,
      "grad_norm": 1.5533593893051147,
      "learning_rate": 7.363153594771243e-06,
      "loss": 0.0899,
      "step": 7343
    },
    {
      "epoch": 1.6875,
      "grad_norm": 1.3865364789962769,
      "learning_rate": 7.36264297385621e-06,
      "loss": 0.0993,
      "step": 7344
    },
    {
      "epoch": 1.6877297794117647,
      "grad_norm": 2.048715829849243,
      "learning_rate": 7.362132352941177e-06,
      "loss": 0.1353,
      "step": 7345
    },
    {
      "epoch": 1.6879595588235294,
      "grad_norm": 1.5120068788528442,
      "learning_rate": 7.361621732026144e-06,
      "loss": 0.1318,
      "step": 7346
    },
    {
      "epoch": 1.6881893382352942,
      "grad_norm": 1.5371555089950562,
      "learning_rate": 7.361111111111112e-06,
      "loss": 0.0731,
      "step": 7347
    },
    {
      "epoch": 1.6884191176470589,
      "grad_norm": 1.689024806022644,
      "learning_rate": 7.360600490196079e-06,
      "loss": 0.1438,
      "step": 7348
    },
    {
      "epoch": 1.6886488970588234,
      "grad_norm": 1.8798377513885498,
      "learning_rate": 7.360089869281046e-06,
      "loss": 0.1329,
      "step": 7349
    },
    {
      "epoch": 1.6888786764705883,
      "grad_norm": 1.768558382987976,
      "learning_rate": 7.359579248366013e-06,
      "loss": 0.108,
      "step": 7350
    },
    {
      "epoch": 1.6891084558823528,
      "grad_norm": 2.37479829788208,
      "learning_rate": 7.359068627450982e-06,
      "loss": 0.0905,
      "step": 7351
    },
    {
      "epoch": 1.6893382352941178,
      "grad_norm": 1.4812941551208496,
      "learning_rate": 7.358558006535949e-06,
      "loss": 0.0974,
      "step": 7352
    },
    {
      "epoch": 1.6895680147058822,
      "grad_norm": 1.751084804534912,
      "learning_rate": 7.358047385620916e-06,
      "loss": 0.1187,
      "step": 7353
    },
    {
      "epoch": 1.6897977941176472,
      "grad_norm": 1.531623125076294,
      "learning_rate": 7.357536764705883e-06,
      "loss": 0.1174,
      "step": 7354
    },
    {
      "epoch": 1.6900275735294117,
      "grad_norm": 1.7377749681472778,
      "learning_rate": 7.357026143790851e-06,
      "loss": 0.117,
      "step": 7355
    },
    {
      "epoch": 1.6902573529411766,
      "grad_norm": 1.380012035369873,
      "learning_rate": 7.356515522875818e-06,
      "loss": 0.0934,
      "step": 7356
    },
    {
      "epoch": 1.6904871323529411,
      "grad_norm": 1.5400980710983276,
      "learning_rate": 7.356004901960785e-06,
      "loss": 0.0913,
      "step": 7357
    },
    {
      "epoch": 1.6907169117647058,
      "grad_norm": 1.5191048383712769,
      "learning_rate": 7.355494281045752e-06,
      "loss": 0.1429,
      "step": 7358
    },
    {
      "epoch": 1.6909466911764706,
      "grad_norm": 1.4602924585342407,
      "learning_rate": 7.35498366013072e-06,
      "loss": 0.089,
      "step": 7359
    },
    {
      "epoch": 1.6911764705882353,
      "grad_norm": 2.3607261180877686,
      "learning_rate": 7.354473039215687e-06,
      "loss": 0.1876,
      "step": 7360
    },
    {
      "epoch": 1.69140625,
      "grad_norm": 1.5627498626708984,
      "learning_rate": 7.353962418300654e-06,
      "loss": 0.1344,
      "step": 7361
    },
    {
      "epoch": 1.6916360294117647,
      "grad_norm": 1.1837959289550781,
      "learning_rate": 7.3534517973856214e-06,
      "loss": 0.0799,
      "step": 7362
    },
    {
      "epoch": 1.6918658088235294,
      "grad_norm": 1.5270731449127197,
      "learning_rate": 7.352941176470589e-06,
      "loss": 0.0931,
      "step": 7363
    },
    {
      "epoch": 1.6920955882352942,
      "grad_norm": 1.589139461517334,
      "learning_rate": 7.352430555555556e-06,
      "loss": 0.104,
      "step": 7364
    },
    {
      "epoch": 1.6923253676470589,
      "grad_norm": 1.8868504762649536,
      "learning_rate": 7.351919934640523e-06,
      "loss": 0.0903,
      "step": 7365
    },
    {
      "epoch": 1.6925551470588234,
      "grad_norm": 1.7745269536972046,
      "learning_rate": 7.35140931372549e-06,
      "loss": 0.1371,
      "step": 7366
    },
    {
      "epoch": 1.6927849264705883,
      "grad_norm": 1.787238597869873,
      "learning_rate": 7.350898692810459e-06,
      "loss": 0.1199,
      "step": 7367
    },
    {
      "epoch": 1.6930147058823528,
      "grad_norm": 1.7629101276397705,
      "learning_rate": 7.350388071895426e-06,
      "loss": 0.1292,
      "step": 7368
    },
    {
      "epoch": 1.6932444852941178,
      "grad_norm": 1.764944076538086,
      "learning_rate": 7.349877450980393e-06,
      "loss": 0.0723,
      "step": 7369
    },
    {
      "epoch": 1.6934742647058822,
      "grad_norm": 1.492893099784851,
      "learning_rate": 7.34936683006536e-06,
      "loss": 0.0826,
      "step": 7370
    },
    {
      "epoch": 1.6937040441176472,
      "grad_norm": 2.218127489089966,
      "learning_rate": 7.348856209150328e-06,
      "loss": 0.1405,
      "step": 7371
    },
    {
      "epoch": 1.6939338235294117,
      "grad_norm": 1.8076657056808472,
      "learning_rate": 7.348345588235295e-06,
      "loss": 0.1248,
      "step": 7372
    },
    {
      "epoch": 1.6941636029411766,
      "grad_norm": 1.8863129615783691,
      "learning_rate": 7.347834967320262e-06,
      "loss": 0.1235,
      "step": 7373
    },
    {
      "epoch": 1.6943933823529411,
      "grad_norm": 1.52812922000885,
      "learning_rate": 7.347324346405229e-06,
      "loss": 0.121,
      "step": 7374
    },
    {
      "epoch": 1.6946231617647058,
      "grad_norm": 1.347362756729126,
      "learning_rate": 7.346813725490197e-06,
      "loss": 0.0846,
      "step": 7375
    },
    {
      "epoch": 1.6948529411764706,
      "grad_norm": 1.629360556602478,
      "learning_rate": 7.346303104575164e-06,
      "loss": 0.1078,
      "step": 7376
    },
    {
      "epoch": 1.6950827205882353,
      "grad_norm": 1.863045334815979,
      "learning_rate": 7.345792483660132e-06,
      "loss": 0.143,
      "step": 7377
    },
    {
      "epoch": 1.6953125,
      "grad_norm": 2.0916991233825684,
      "learning_rate": 7.345281862745099e-06,
      "loss": 0.1138,
      "step": 7378
    },
    {
      "epoch": 1.6955422794117647,
      "grad_norm": 1.438254714012146,
      "learning_rate": 7.344771241830067e-06,
      "loss": 0.0932,
      "step": 7379
    },
    {
      "epoch": 1.6957720588235294,
      "grad_norm": 1.248772144317627,
      "learning_rate": 7.344260620915034e-06,
      "loss": 0.0957,
      "step": 7380
    },
    {
      "epoch": 1.6960018382352942,
      "grad_norm": 2.133214235305786,
      "learning_rate": 7.343750000000001e-06,
      "loss": 0.1286,
      "step": 7381
    },
    {
      "epoch": 1.6962316176470589,
      "grad_norm": 1.6545507907867432,
      "learning_rate": 7.343239379084968e-06,
      "loss": 0.0878,
      "step": 7382
    },
    {
      "epoch": 1.6964613970588234,
      "grad_norm": 1.466257095336914,
      "learning_rate": 7.342728758169935e-06,
      "loss": 0.0986,
      "step": 7383
    },
    {
      "epoch": 1.6966911764705883,
      "grad_norm": 1.632310390472412,
      "learning_rate": 7.3422181372549025e-06,
      "loss": 0.1269,
      "step": 7384
    },
    {
      "epoch": 1.6969209558823528,
      "grad_norm": 1.5101182460784912,
      "learning_rate": 7.3417075163398695e-06,
      "loss": 0.0754,
      "step": 7385
    },
    {
      "epoch": 1.6971507352941178,
      "grad_norm": 1.389602541923523,
      "learning_rate": 7.3411968954248365e-06,
      "loss": 0.1099,
      "step": 7386
    },
    {
      "epoch": 1.6973805147058822,
      "grad_norm": 1.4239593744277954,
      "learning_rate": 7.3406862745098036e-06,
      "loss": 0.099,
      "step": 7387
    },
    {
      "epoch": 1.6976102941176472,
      "grad_norm": 1.5715601444244385,
      "learning_rate": 7.340175653594772e-06,
      "loss": 0.0784,
      "step": 7388
    },
    {
      "epoch": 1.6978400735294117,
      "grad_norm": 2.5225918292999268,
      "learning_rate": 7.339665032679739e-06,
      "loss": 0.1446,
      "step": 7389
    },
    {
      "epoch": 1.6980698529411766,
      "grad_norm": 1.2685467004776,
      "learning_rate": 7.339154411764706e-06,
      "loss": 0.0874,
      "step": 7390
    },
    {
      "epoch": 1.6982996323529411,
      "grad_norm": 1.4989731311798096,
      "learning_rate": 7.338643790849673e-06,
      "loss": 0.0924,
      "step": 7391
    },
    {
      "epoch": 1.6985294117647058,
      "grad_norm": 1.3808790445327759,
      "learning_rate": 7.338133169934641e-06,
      "loss": 0.076,
      "step": 7392
    },
    {
      "epoch": 1.6987591911764706,
      "grad_norm": 1.9053884744644165,
      "learning_rate": 7.337622549019608e-06,
      "loss": 0.1033,
      "step": 7393
    },
    {
      "epoch": 1.6989889705882353,
      "grad_norm": 1.7966119050979614,
      "learning_rate": 7.337111928104575e-06,
      "loss": 0.1536,
      "step": 7394
    },
    {
      "epoch": 1.69921875,
      "grad_norm": 1.3415719270706177,
      "learning_rate": 7.336601307189542e-06,
      "loss": 0.1055,
      "step": 7395
    },
    {
      "epoch": 1.6994485294117647,
      "grad_norm": 1.741039514541626,
      "learning_rate": 7.336090686274511e-06,
      "loss": 0.1182,
      "step": 7396
    },
    {
      "epoch": 1.6996783088235294,
      "grad_norm": 2.4602532386779785,
      "learning_rate": 7.335580065359478e-06,
      "loss": 0.1141,
      "step": 7397
    },
    {
      "epoch": 1.6999080882352942,
      "grad_norm": 1.6864359378814697,
      "learning_rate": 7.335069444444445e-06,
      "loss": 0.0925,
      "step": 7398
    },
    {
      "epoch": 1.7001378676470589,
      "grad_norm": 1.565220832824707,
      "learning_rate": 7.334558823529412e-06,
      "loss": 0.0802,
      "step": 7399
    },
    {
      "epoch": 1.7003676470588234,
      "grad_norm": 1.7532474994659424,
      "learning_rate": 7.33404820261438e-06,
      "loss": 0.1225,
      "step": 7400
    },
    {
      "epoch": 1.7005974264705883,
      "grad_norm": 1.5238194465637207,
      "learning_rate": 7.333537581699347e-06,
      "loss": 0.1081,
      "step": 7401
    },
    {
      "epoch": 1.7008272058823528,
      "grad_norm": 1.8751341104507446,
      "learning_rate": 7.333026960784314e-06,
      "loss": 0.1365,
      "step": 7402
    },
    {
      "epoch": 1.7010569852941178,
      "grad_norm": 1.8686603307724,
      "learning_rate": 7.332516339869281e-06,
      "loss": 0.1288,
      "step": 7403
    },
    {
      "epoch": 1.7012867647058822,
      "grad_norm": 1.933997392654419,
      "learning_rate": 7.33200571895425e-06,
      "loss": 0.1447,
      "step": 7404
    },
    {
      "epoch": 1.7015165441176472,
      "grad_norm": 1.26993989944458,
      "learning_rate": 7.331495098039217e-06,
      "loss": 0.0768,
      "step": 7405
    },
    {
      "epoch": 1.7017463235294117,
      "grad_norm": 2.055722713470459,
      "learning_rate": 7.330984477124184e-06,
      "loss": 0.1089,
      "step": 7406
    },
    {
      "epoch": 1.7019761029411766,
      "grad_norm": 1.3958141803741455,
      "learning_rate": 7.330473856209151e-06,
      "loss": 0.1025,
      "step": 7407
    },
    {
      "epoch": 1.7022058823529411,
      "grad_norm": 1.6473714113235474,
      "learning_rate": 7.3299632352941185e-06,
      "loss": 0.0906,
      "step": 7408
    },
    {
      "epoch": 1.7024356617647058,
      "grad_norm": 1.858182668685913,
      "learning_rate": 7.3294526143790855e-06,
      "loss": 0.1338,
      "step": 7409
    },
    {
      "epoch": 1.7026654411764706,
      "grad_norm": 1.6426540613174438,
      "learning_rate": 7.3289419934640525e-06,
      "loss": 0.1081,
      "step": 7410
    },
    {
      "epoch": 1.7028952205882353,
      "grad_norm": 1.6361838579177856,
      "learning_rate": 7.3284313725490195e-06,
      "loss": 0.1046,
      "step": 7411
    },
    {
      "epoch": 1.703125,
      "grad_norm": 1.4605687856674194,
      "learning_rate": 7.327920751633988e-06,
      "loss": 0.1194,
      "step": 7412
    },
    {
      "epoch": 1.7033547794117647,
      "grad_norm": 1.6999093294143677,
      "learning_rate": 7.327410130718955e-06,
      "loss": 0.1046,
      "step": 7413
    },
    {
      "epoch": 1.7035845588235294,
      "grad_norm": 1.5614912509918213,
      "learning_rate": 7.326899509803922e-06,
      "loss": 0.0981,
      "step": 7414
    },
    {
      "epoch": 1.7038143382352942,
      "grad_norm": 1.6546216011047363,
      "learning_rate": 7.326388888888889e-06,
      "loss": 0.1081,
      "step": 7415
    },
    {
      "epoch": 1.7040441176470589,
      "grad_norm": 2.0176572799682617,
      "learning_rate": 7.325878267973857e-06,
      "loss": 0.1095,
      "step": 7416
    },
    {
      "epoch": 1.7042738970588234,
      "grad_norm": 1.58498215675354,
      "learning_rate": 7.325367647058824e-06,
      "loss": 0.1481,
      "step": 7417
    },
    {
      "epoch": 1.7045036764705883,
      "grad_norm": 1.448046088218689,
      "learning_rate": 7.324857026143791e-06,
      "loss": 0.084,
      "step": 7418
    },
    {
      "epoch": 1.7047334558823528,
      "grad_norm": 1.716214895248413,
      "learning_rate": 7.324346405228758e-06,
      "loss": 0.1007,
      "step": 7419
    },
    {
      "epoch": 1.7049632352941178,
      "grad_norm": 1.3511103391647339,
      "learning_rate": 7.323835784313726e-06,
      "loss": 0.0775,
      "step": 7420
    },
    {
      "epoch": 1.7051930147058822,
      "grad_norm": 2.667264699935913,
      "learning_rate": 7.323325163398693e-06,
      "loss": 0.1235,
      "step": 7421
    },
    {
      "epoch": 1.7054227941176472,
      "grad_norm": 1.6798670291900635,
      "learning_rate": 7.322814542483661e-06,
      "loss": 0.0941,
      "step": 7422
    },
    {
      "epoch": 1.7056525735294117,
      "grad_norm": 1.5114597082138062,
      "learning_rate": 7.322303921568628e-06,
      "loss": 0.1228,
      "step": 7423
    },
    {
      "epoch": 1.7058823529411766,
      "grad_norm": 1.7468363046646118,
      "learning_rate": 7.321793300653596e-06,
      "loss": 0.1089,
      "step": 7424
    },
    {
      "epoch": 1.7061121323529411,
      "grad_norm": 1.3494253158569336,
      "learning_rate": 7.321282679738563e-06,
      "loss": 0.0994,
      "step": 7425
    },
    {
      "epoch": 1.7063419117647058,
      "grad_norm": 1.7924039363861084,
      "learning_rate": 7.32077205882353e-06,
      "loss": 0.0799,
      "step": 7426
    },
    {
      "epoch": 1.7065716911764706,
      "grad_norm": 2.3025929927825928,
      "learning_rate": 7.320261437908497e-06,
      "loss": 0.1394,
      "step": 7427
    },
    {
      "epoch": 1.7068014705882353,
      "grad_norm": 1.5405893325805664,
      "learning_rate": 7.319750816993465e-06,
      "loss": 0.1019,
      "step": 7428
    },
    {
      "epoch": 1.70703125,
      "grad_norm": 1.6822742223739624,
      "learning_rate": 7.319240196078432e-06,
      "loss": 0.1292,
      "step": 7429
    },
    {
      "epoch": 1.7072610294117647,
      "grad_norm": 1.884019136428833,
      "learning_rate": 7.318729575163399e-06,
      "loss": 0.107,
      "step": 7430
    },
    {
      "epoch": 1.7074908088235294,
      "grad_norm": 1.5598526000976562,
      "learning_rate": 7.318218954248366e-06,
      "loss": 0.1087,
      "step": 7431
    },
    {
      "epoch": 1.7077205882352942,
      "grad_norm": 1.9028583765029907,
      "learning_rate": 7.3177083333333345e-06,
      "loss": 0.1417,
      "step": 7432
    },
    {
      "epoch": 1.7079503676470589,
      "grad_norm": 1.4263379573822021,
      "learning_rate": 7.3171977124183015e-06,
      "loss": 0.097,
      "step": 7433
    },
    {
      "epoch": 1.7081801470588234,
      "grad_norm": 1.8292514085769653,
      "learning_rate": 7.3166870915032685e-06,
      "loss": 0.17,
      "step": 7434
    },
    {
      "epoch": 1.7084099264705883,
      "grad_norm": 1.687870740890503,
      "learning_rate": 7.3161764705882355e-06,
      "loss": 0.0908,
      "step": 7435
    },
    {
      "epoch": 1.7086397058823528,
      "grad_norm": 2.0425310134887695,
      "learning_rate": 7.315665849673203e-06,
      "loss": 0.0995,
      "step": 7436
    },
    {
      "epoch": 1.7088694852941178,
      "grad_norm": 1.9993196725845337,
      "learning_rate": 7.31515522875817e-06,
      "loss": 0.1256,
      "step": 7437
    },
    {
      "epoch": 1.7090992647058822,
      "grad_norm": 1.6736881732940674,
      "learning_rate": 7.314644607843137e-06,
      "loss": 0.1061,
      "step": 7438
    },
    {
      "epoch": 1.7093290441176472,
      "grad_norm": 1.6632530689239502,
      "learning_rate": 7.314133986928104e-06,
      "loss": 0.0855,
      "step": 7439
    },
    {
      "epoch": 1.7095588235294117,
      "grad_norm": 2.1354806423187256,
      "learning_rate": 7.313623366013073e-06,
      "loss": 0.086,
      "step": 7440
    },
    {
      "epoch": 1.7097886029411766,
      "grad_norm": 2.02803111076355,
      "learning_rate": 7.31311274509804e-06,
      "loss": 0.1417,
      "step": 7441
    },
    {
      "epoch": 1.7100183823529411,
      "grad_norm": 1.5511730909347534,
      "learning_rate": 7.312602124183007e-06,
      "loss": 0.1192,
      "step": 7442
    },
    {
      "epoch": 1.7102481617647058,
      "grad_norm": 1.534533143043518,
      "learning_rate": 7.312091503267974e-06,
      "loss": 0.1018,
      "step": 7443
    },
    {
      "epoch": 1.7104779411764706,
      "grad_norm": 2.2342514991760254,
      "learning_rate": 7.311580882352942e-06,
      "loss": 0.1601,
      "step": 7444
    },
    {
      "epoch": 1.7107077205882353,
      "grad_norm": 1.882200002670288,
      "learning_rate": 7.311070261437909e-06,
      "loss": 0.0961,
      "step": 7445
    },
    {
      "epoch": 1.7109375,
      "grad_norm": 1.6595122814178467,
      "learning_rate": 7.310559640522876e-06,
      "loss": 0.1088,
      "step": 7446
    },
    {
      "epoch": 1.7111672794117647,
      "grad_norm": 1.546626091003418,
      "learning_rate": 7.310049019607843e-06,
      "loss": 0.0981,
      "step": 7447
    },
    {
      "epoch": 1.7113970588235294,
      "grad_norm": 1.4867172241210938,
      "learning_rate": 7.309538398692812e-06,
      "loss": 0.1043,
      "step": 7448
    },
    {
      "epoch": 1.7116268382352942,
      "grad_norm": 1.7369627952575684,
      "learning_rate": 7.309027777777779e-06,
      "loss": 0.0942,
      "step": 7449
    },
    {
      "epoch": 1.7118566176470589,
      "grad_norm": 1.8160313367843628,
      "learning_rate": 7.308517156862746e-06,
      "loss": 0.1246,
      "step": 7450
    },
    {
      "epoch": 1.7120863970588234,
      "grad_norm": 2.1543405055999756,
      "learning_rate": 7.308006535947713e-06,
      "loss": 0.1356,
      "step": 7451
    },
    {
      "epoch": 1.7123161764705883,
      "grad_norm": 1.2758783102035522,
      "learning_rate": 7.307495915032681e-06,
      "loss": 0.0807,
      "step": 7452
    },
    {
      "epoch": 1.7125459558823528,
      "grad_norm": 1.9702945947647095,
      "learning_rate": 7.306985294117648e-06,
      "loss": 0.1223,
      "step": 7453
    },
    {
      "epoch": 1.7127757352941178,
      "grad_norm": 1.5392310619354248,
      "learning_rate": 7.306474673202615e-06,
      "loss": 0.0823,
      "step": 7454
    },
    {
      "epoch": 1.7130055147058822,
      "grad_norm": 1.5933728218078613,
      "learning_rate": 7.305964052287582e-06,
      "loss": 0.0787,
      "step": 7455
    },
    {
      "epoch": 1.7132352941176472,
      "grad_norm": 2.227815628051758,
      "learning_rate": 7.3054534313725504e-06,
      "loss": 0.1189,
      "step": 7456
    },
    {
      "epoch": 1.7134650735294117,
      "grad_norm": 1.4987928867340088,
      "learning_rate": 7.3049428104575174e-06,
      "loss": 0.0831,
      "step": 7457
    },
    {
      "epoch": 1.7136948529411766,
      "grad_norm": 1.9088388681411743,
      "learning_rate": 7.3044321895424845e-06,
      "loss": 0.0845,
      "step": 7458
    },
    {
      "epoch": 1.7139246323529411,
      "grad_norm": 2.108970880508423,
      "learning_rate": 7.3039215686274515e-06,
      "loss": 0.1288,
      "step": 7459
    },
    {
      "epoch": 1.7141544117647058,
      "grad_norm": 1.5924303531646729,
      "learning_rate": 7.303410947712419e-06,
      "loss": 0.08,
      "step": 7460
    },
    {
      "epoch": 1.7143841911764706,
      "grad_norm": 1.42250657081604,
      "learning_rate": 7.302900326797386e-06,
      "loss": 0.083,
      "step": 7461
    },
    {
      "epoch": 1.7146139705882353,
      "grad_norm": 1.5111640691757202,
      "learning_rate": 7.302389705882353e-06,
      "loss": 0.0954,
      "step": 7462
    },
    {
      "epoch": 1.71484375,
      "grad_norm": 1.6206333637237549,
      "learning_rate": 7.30187908496732e-06,
      "loss": 0.1041,
      "step": 7463
    },
    {
      "epoch": 1.7150735294117647,
      "grad_norm": 1.4386138916015625,
      "learning_rate": 7.301368464052288e-06,
      "loss": 0.0887,
      "step": 7464
    },
    {
      "epoch": 1.7153033088235294,
      "grad_norm": 1.613330364227295,
      "learning_rate": 7.300857843137255e-06,
      "loss": 0.1023,
      "step": 7465
    },
    {
      "epoch": 1.7155330882352942,
      "grad_norm": 1.6955633163452148,
      "learning_rate": 7.300347222222223e-06,
      "loss": 0.1357,
      "step": 7466
    },
    {
      "epoch": 1.7157628676470589,
      "grad_norm": 1.3949127197265625,
      "learning_rate": 7.29983660130719e-06,
      "loss": 0.0913,
      "step": 7467
    },
    {
      "epoch": 1.7159926470588234,
      "grad_norm": 2.5895400047302246,
      "learning_rate": 7.299325980392158e-06,
      "loss": 0.1614,
      "step": 7468
    },
    {
      "epoch": 1.7162224264705883,
      "grad_norm": 2.2482998371124268,
      "learning_rate": 7.298815359477125e-06,
      "loss": 0.1711,
      "step": 7469
    },
    {
      "epoch": 1.7164522058823528,
      "grad_norm": 1.8958369493484497,
      "learning_rate": 7.298304738562092e-06,
      "loss": 0.1175,
      "step": 7470
    },
    {
      "epoch": 1.7166819852941178,
      "grad_norm": 2.3808162212371826,
      "learning_rate": 7.297794117647059e-06,
      "loss": 0.1142,
      "step": 7471
    },
    {
      "epoch": 1.7169117647058822,
      "grad_norm": 1.7181705236434937,
      "learning_rate": 7.297283496732027e-06,
      "loss": 0.1376,
      "step": 7472
    },
    {
      "epoch": 1.7171415441176472,
      "grad_norm": 1.7952746152877808,
      "learning_rate": 7.296772875816994e-06,
      "loss": 0.1228,
      "step": 7473
    },
    {
      "epoch": 1.7173713235294117,
      "grad_norm": 1.2850415706634521,
      "learning_rate": 7.296262254901961e-06,
      "loss": 0.1161,
      "step": 7474
    },
    {
      "epoch": 1.7176011029411766,
      "grad_norm": 1.4700344800949097,
      "learning_rate": 7.295751633986928e-06,
      "loss": 0.0874,
      "step": 7475
    },
    {
      "epoch": 1.7178308823529411,
      "grad_norm": 2.7582530975341797,
      "learning_rate": 7.295241013071897e-06,
      "loss": 0.134,
      "step": 7476
    },
    {
      "epoch": 1.7180606617647058,
      "grad_norm": 1.3003467321395874,
      "learning_rate": 7.294730392156864e-06,
      "loss": 0.0991,
      "step": 7477
    },
    {
      "epoch": 1.7182904411764706,
      "grad_norm": 1.5463335514068604,
      "learning_rate": 7.294219771241831e-06,
      "loss": 0.0928,
      "step": 7478
    },
    {
      "epoch": 1.7185202205882353,
      "grad_norm": 1.8402196168899536,
      "learning_rate": 7.293709150326798e-06,
      "loss": 0.1147,
      "step": 7479
    },
    {
      "epoch": 1.71875,
      "grad_norm": 2.255444288253784,
      "learning_rate": 7.2931985294117655e-06,
      "loss": 0.1435,
      "step": 7480
    },
    {
      "epoch": 1.7189797794117647,
      "grad_norm": 2.3482794761657715,
      "learning_rate": 7.2926879084967326e-06,
      "loss": 0.1202,
      "step": 7481
    },
    {
      "epoch": 1.7192095588235294,
      "grad_norm": 1.8142186403274536,
      "learning_rate": 7.2921772875817e-06,
      "loss": 0.1332,
      "step": 7482
    },
    {
      "epoch": 1.7194393382352942,
      "grad_norm": 1.2910817861557007,
      "learning_rate": 7.291666666666667e-06,
      "loss": 0.0991,
      "step": 7483
    },
    {
      "epoch": 1.7196691176470589,
      "grad_norm": 1.360622525215149,
      "learning_rate": 7.291156045751635e-06,
      "loss": 0.1051,
      "step": 7484
    },
    {
      "epoch": 1.7198988970588234,
      "grad_norm": 1.5583724975585938,
      "learning_rate": 7.290645424836602e-06,
      "loss": 0.1176,
      "step": 7485
    },
    {
      "epoch": 1.7201286764705883,
      "grad_norm": 2.112884998321533,
      "learning_rate": 7.290134803921569e-06,
      "loss": 0.148,
      "step": 7486
    },
    {
      "epoch": 1.7203584558823528,
      "grad_norm": 2.5975966453552246,
      "learning_rate": 7.289624183006536e-06,
      "loss": 0.1254,
      "step": 7487
    },
    {
      "epoch": 1.7205882352941178,
      "grad_norm": 1.5088388919830322,
      "learning_rate": 7.289113562091504e-06,
      "loss": 0.0777,
      "step": 7488
    },
    {
      "epoch": 1.7208180147058822,
      "grad_norm": 1.3507851362228394,
      "learning_rate": 7.288602941176471e-06,
      "loss": 0.0807,
      "step": 7489
    },
    {
      "epoch": 1.7210477941176472,
      "grad_norm": 1.4734207391738892,
      "learning_rate": 7.288092320261438e-06,
      "loss": 0.0976,
      "step": 7490
    },
    {
      "epoch": 1.7212775735294117,
      "grad_norm": 1.5368046760559082,
      "learning_rate": 7.287581699346405e-06,
      "loss": 0.1096,
      "step": 7491
    },
    {
      "epoch": 1.7215073529411766,
      "grad_norm": 1.4902390241622925,
      "learning_rate": 7.287071078431374e-06,
      "loss": 0.1251,
      "step": 7492
    },
    {
      "epoch": 1.7217371323529411,
      "grad_norm": 1.75450599193573,
      "learning_rate": 7.286560457516341e-06,
      "loss": 0.1094,
      "step": 7493
    },
    {
      "epoch": 1.7219669117647058,
      "grad_norm": 1.6987457275390625,
      "learning_rate": 7.286049836601308e-06,
      "loss": 0.1036,
      "step": 7494
    },
    {
      "epoch": 1.7221966911764706,
      "grad_norm": 1.512472152709961,
      "learning_rate": 7.285539215686275e-06,
      "loss": 0.0735,
      "step": 7495
    },
    {
      "epoch": 1.7224264705882353,
      "grad_norm": 1.581954836845398,
      "learning_rate": 7.285028594771243e-06,
      "loss": 0.1156,
      "step": 7496
    },
    {
      "epoch": 1.72265625,
      "grad_norm": 1.645176649093628,
      "learning_rate": 7.28451797385621e-06,
      "loss": 0.117,
      "step": 7497
    },
    {
      "epoch": 1.7228860294117647,
      "grad_norm": 1.7274936437606812,
      "learning_rate": 7.284007352941177e-06,
      "loss": 0.1076,
      "step": 7498
    },
    {
      "epoch": 1.7231158088235294,
      "grad_norm": 1.5290547609329224,
      "learning_rate": 7.283496732026144e-06,
      "loss": 0.104,
      "step": 7499
    },
    {
      "epoch": 1.7233455882352942,
      "grad_norm": 1.4395804405212402,
      "learning_rate": 7.282986111111113e-06,
      "loss": 0.099,
      "step": 7500
    },
    {
      "epoch": 1.7233455882352942,
      "eval_loss": 0.11463302373886108,
      "eval_runtime": 419.8327,
      "eval_samples_per_second": 21.213,
      "eval_steps_per_second": 10.607,
      "step": 7500
    },
    {
      "epoch": 1.7235753676470589,
      "grad_norm": 1.4864407777786255,
      "learning_rate": 7.28247549019608e-06,
      "loss": 0.0797,
      "step": 7501
    },
    {
      "epoch": 1.7238051470588234,
      "grad_norm": 1.6235283613204956,
      "learning_rate": 7.281964869281047e-06,
      "loss": 0.084,
      "step": 7502
    },
    {
      "epoch": 1.7240349264705883,
      "grad_norm": 1.5976895093917847,
      "learning_rate": 7.281454248366014e-06,
      "loss": 0.0974,
      "step": 7503
    },
    {
      "epoch": 1.7242647058823528,
      "grad_norm": 2.3399643898010254,
      "learning_rate": 7.2809436274509815e-06,
      "loss": 0.1427,
      "step": 7504
    },
    {
      "epoch": 1.7244944852941178,
      "grad_norm": 1.8408615589141846,
      "learning_rate": 7.2804330065359485e-06,
      "loss": 0.1103,
      "step": 7505
    },
    {
      "epoch": 1.7247242647058822,
      "grad_norm": 1.4922763109207153,
      "learning_rate": 7.2799223856209155e-06,
      "loss": 0.1161,
      "step": 7506
    },
    {
      "epoch": 1.7249540441176472,
      "grad_norm": 1.6159913539886475,
      "learning_rate": 7.2794117647058826e-06,
      "loss": 0.1114,
      "step": 7507
    },
    {
      "epoch": 1.7251838235294117,
      "grad_norm": 2.857736825942993,
      "learning_rate": 7.2789011437908504e-06,
      "loss": 0.0847,
      "step": 7508
    },
    {
      "epoch": 1.7254136029411766,
      "grad_norm": 2.887807607650757,
      "learning_rate": 7.2783905228758174e-06,
      "loss": 0.0844,
      "step": 7509
    },
    {
      "epoch": 1.7256433823529411,
      "grad_norm": 2.1919937133789062,
      "learning_rate": 7.2778799019607845e-06,
      "loss": 0.1022,
      "step": 7510
    },
    {
      "epoch": 1.7258731617647058,
      "grad_norm": 1.404057502746582,
      "learning_rate": 7.277369281045752e-06,
      "loss": 0.0814,
      "step": 7511
    },
    {
      "epoch": 1.7261029411764706,
      "grad_norm": 2.155172824859619,
      "learning_rate": 7.27685866013072e-06,
      "loss": 0.1434,
      "step": 7512
    },
    {
      "epoch": 1.7263327205882353,
      "grad_norm": 1.744964599609375,
      "learning_rate": 7.276348039215687e-06,
      "loss": 0.1178,
      "step": 7513
    },
    {
      "epoch": 1.7265625,
      "grad_norm": 2.146923780441284,
      "learning_rate": 7.275837418300654e-06,
      "loss": 0.1132,
      "step": 7514
    },
    {
      "epoch": 1.7267922794117647,
      "grad_norm": 1.6595004796981812,
      "learning_rate": 7.275326797385621e-06,
      "loss": 0.1088,
      "step": 7515
    },
    {
      "epoch": 1.7270220588235294,
      "grad_norm": 1.9262956380844116,
      "learning_rate": 7.274816176470589e-06,
      "loss": 0.1386,
      "step": 7516
    },
    {
      "epoch": 1.7272518382352942,
      "grad_norm": 1.993381381034851,
      "learning_rate": 7.274305555555556e-06,
      "loss": 0.1282,
      "step": 7517
    },
    {
      "epoch": 1.7274816176470589,
      "grad_norm": 1.945124626159668,
      "learning_rate": 7.273794934640523e-06,
      "loss": 0.0885,
      "step": 7518
    },
    {
      "epoch": 1.7277113970588234,
      "grad_norm": 1.6250767707824707,
      "learning_rate": 7.27328431372549e-06,
      "loss": 0.0926,
      "step": 7519
    },
    {
      "epoch": 1.7279411764705883,
      "grad_norm": 2.1977450847625732,
      "learning_rate": 7.272773692810459e-06,
      "loss": 0.0862,
      "step": 7520
    },
    {
      "epoch": 1.7281709558823528,
      "grad_norm": 1.8186930418014526,
      "learning_rate": 7.272263071895426e-06,
      "loss": 0.1097,
      "step": 7521
    },
    {
      "epoch": 1.7284007352941178,
      "grad_norm": 2.1344614028930664,
      "learning_rate": 7.271752450980393e-06,
      "loss": 0.115,
      "step": 7522
    },
    {
      "epoch": 1.7286305147058822,
      "grad_norm": 2.123251438140869,
      "learning_rate": 7.27124183006536e-06,
      "loss": 0.1276,
      "step": 7523
    },
    {
      "epoch": 1.7288602941176472,
      "grad_norm": 1.3923311233520508,
      "learning_rate": 7.270731209150328e-06,
      "loss": 0.0898,
      "step": 7524
    },
    {
      "epoch": 1.7290900735294117,
      "grad_norm": 2.577118396759033,
      "learning_rate": 7.270220588235295e-06,
      "loss": 0.1168,
      "step": 7525
    },
    {
      "epoch": 1.7293198529411766,
      "grad_norm": 1.6083779335021973,
      "learning_rate": 7.269709967320262e-06,
      "loss": 0.1218,
      "step": 7526
    },
    {
      "epoch": 1.7295496323529411,
      "grad_norm": 1.830341100692749,
      "learning_rate": 7.269199346405229e-06,
      "loss": 0.1586,
      "step": 7527
    },
    {
      "epoch": 1.7297794117647058,
      "grad_norm": 1.6625620126724243,
      "learning_rate": 7.2686887254901975e-06,
      "loss": 0.1031,
      "step": 7528
    },
    {
      "epoch": 1.7300091911764706,
      "grad_norm": 2.172614097595215,
      "learning_rate": 7.2681781045751645e-06,
      "loss": 0.0832,
      "step": 7529
    },
    {
      "epoch": 1.7302389705882353,
      "grad_norm": 1.9020174741744995,
      "learning_rate": 7.2676674836601315e-06,
      "loss": 0.1276,
      "step": 7530
    },
    {
      "epoch": 1.73046875,
      "grad_norm": 1.957270860671997,
      "learning_rate": 7.2671568627450985e-06,
      "loss": 0.1323,
      "step": 7531
    },
    {
      "epoch": 1.7306985294117647,
      "grad_norm": 2.21235728263855,
      "learning_rate": 7.266646241830066e-06,
      "loss": 0.1147,
      "step": 7532
    },
    {
      "epoch": 1.7309283088235294,
      "grad_norm": 1.8332988023757935,
      "learning_rate": 7.266135620915033e-06,
      "loss": 0.1014,
      "step": 7533
    },
    {
      "epoch": 1.7311580882352942,
      "grad_norm": 2.319995164871216,
      "learning_rate": 7.265625e-06,
      "loss": 0.1335,
      "step": 7534
    },
    {
      "epoch": 1.7313878676470589,
      "grad_norm": 1.5794072151184082,
      "learning_rate": 7.2651143790849674e-06,
      "loss": 0.1173,
      "step": 7535
    },
    {
      "epoch": 1.7316176470588234,
      "grad_norm": 1.8784964084625244,
      "learning_rate": 7.2646037581699345e-06,
      "loss": 0.1526,
      "step": 7536
    },
    {
      "epoch": 1.7318474264705883,
      "grad_norm": 1.6537184715270996,
      "learning_rate": 7.264093137254903e-06,
      "loss": 0.128,
      "step": 7537
    },
    {
      "epoch": 1.7320772058823528,
      "grad_norm": 1.4486888647079468,
      "learning_rate": 7.26358251633987e-06,
      "loss": 0.0756,
      "step": 7538
    },
    {
      "epoch": 1.7323069852941178,
      "grad_norm": 1.533079743385315,
      "learning_rate": 7.263071895424837e-06,
      "loss": 0.0908,
      "step": 7539
    },
    {
      "epoch": 1.7325367647058822,
      "grad_norm": 1.6636693477630615,
      "learning_rate": 7.262561274509804e-06,
      "loss": 0.1135,
      "step": 7540
    },
    {
      "epoch": 1.7327665441176472,
      "grad_norm": 1.632789969444275,
      "learning_rate": 7.262050653594772e-06,
      "loss": 0.1507,
      "step": 7541
    },
    {
      "epoch": 1.7329963235294117,
      "grad_norm": 1.5633013248443604,
      "learning_rate": 7.261540032679739e-06,
      "loss": 0.1121,
      "step": 7542
    },
    {
      "epoch": 1.7332261029411766,
      "grad_norm": 1.3510727882385254,
      "learning_rate": 7.261029411764706e-06,
      "loss": 0.0919,
      "step": 7543
    },
    {
      "epoch": 1.7334558823529411,
      "grad_norm": 1.949067234992981,
      "learning_rate": 7.260518790849673e-06,
      "loss": 0.1216,
      "step": 7544
    },
    {
      "epoch": 1.7336856617647058,
      "grad_norm": 1.7568845748901367,
      "learning_rate": 7.260008169934642e-06,
      "loss": 0.1198,
      "step": 7545
    },
    {
      "epoch": 1.7339154411764706,
      "grad_norm": 1.6653480529785156,
      "learning_rate": 7.259497549019609e-06,
      "loss": 0.0952,
      "step": 7546
    },
    {
      "epoch": 1.7341452205882353,
      "grad_norm": 1.5131053924560547,
      "learning_rate": 7.258986928104576e-06,
      "loss": 0.0971,
      "step": 7547
    },
    {
      "epoch": 1.734375,
      "grad_norm": 1.5739080905914307,
      "learning_rate": 7.258476307189543e-06,
      "loss": 0.113,
      "step": 7548
    },
    {
      "epoch": 1.7346047794117647,
      "grad_norm": 1.8229432106018066,
      "learning_rate": 7.257965686274511e-06,
      "loss": 0.1371,
      "step": 7549
    },
    {
      "epoch": 1.7348345588235294,
      "grad_norm": 1.8452907800674438,
      "learning_rate": 7.257455065359478e-06,
      "loss": 0.0912,
      "step": 7550
    },
    {
      "epoch": 1.7350643382352942,
      "grad_norm": 1.2556006908416748,
      "learning_rate": 7.256944444444445e-06,
      "loss": 0.0908,
      "step": 7551
    },
    {
      "epoch": 1.7352941176470589,
      "grad_norm": 1.5612053871154785,
      "learning_rate": 7.256433823529412e-06,
      "loss": 0.0875,
      "step": 7552
    },
    {
      "epoch": 1.7355238970588234,
      "grad_norm": 1.8795945644378662,
      "learning_rate": 7.25592320261438e-06,
      "loss": 0.1037,
      "step": 7553
    },
    {
      "epoch": 1.7357536764705883,
      "grad_norm": 1.6882532835006714,
      "learning_rate": 7.255412581699347e-06,
      "loss": 0.1102,
      "step": 7554
    },
    {
      "epoch": 1.7359834558823528,
      "grad_norm": 1.6087090969085693,
      "learning_rate": 7.2549019607843145e-06,
      "loss": 0.1015,
      "step": 7555
    },
    {
      "epoch": 1.7362132352941178,
      "grad_norm": 1.3797104358673096,
      "learning_rate": 7.2543913398692815e-06,
      "loss": 0.0755,
      "step": 7556
    },
    {
      "epoch": 1.7364430147058822,
      "grad_norm": 1.7304610013961792,
      "learning_rate": 7.253880718954249e-06,
      "loss": 0.1488,
      "step": 7557
    },
    {
      "epoch": 1.7366727941176472,
      "grad_norm": 2.022150754928589,
      "learning_rate": 7.253370098039216e-06,
      "loss": 0.1582,
      "step": 7558
    },
    {
      "epoch": 1.7369025735294117,
      "grad_norm": 1.3313813209533691,
      "learning_rate": 7.252859477124183e-06,
      "loss": 0.0826,
      "step": 7559
    },
    {
      "epoch": 1.7371323529411766,
      "grad_norm": 1.4312025308609009,
      "learning_rate": 7.25234885620915e-06,
      "loss": 0.0875,
      "step": 7560
    },
    {
      "epoch": 1.7373621323529411,
      "grad_norm": 1.7888896465301514,
      "learning_rate": 7.251838235294118e-06,
      "loss": 0.1252,
      "step": 7561
    },
    {
      "epoch": 1.7375919117647058,
      "grad_norm": 1.5115275382995605,
      "learning_rate": 7.251327614379085e-06,
      "loss": 0.0939,
      "step": 7562
    },
    {
      "epoch": 1.7378216911764706,
      "grad_norm": 1.8179930448532104,
      "learning_rate": 7.250816993464052e-06,
      "loss": 0.1527,
      "step": 7563
    },
    {
      "epoch": 1.7380514705882353,
      "grad_norm": 1.8192248344421387,
      "learning_rate": 7.250306372549019e-06,
      "loss": 0.0904,
      "step": 7564
    },
    {
      "epoch": 1.73828125,
      "grad_norm": 1.7123548984527588,
      "learning_rate": 7.249795751633988e-06,
      "loss": 0.1086,
      "step": 7565
    },
    {
      "epoch": 1.7385110294117647,
      "grad_norm": 2.6290948390960693,
      "learning_rate": 7.249285130718955e-06,
      "loss": 0.1848,
      "step": 7566
    },
    {
      "epoch": 1.7387408088235294,
      "grad_norm": 1.802048921585083,
      "learning_rate": 7.248774509803922e-06,
      "loss": 0.1074,
      "step": 7567
    },
    {
      "epoch": 1.7389705882352942,
      "grad_norm": 1.6861785650253296,
      "learning_rate": 7.248263888888889e-06,
      "loss": 0.0956,
      "step": 7568
    },
    {
      "epoch": 1.7392003676470589,
      "grad_norm": 1.7259535789489746,
      "learning_rate": 7.247753267973857e-06,
      "loss": 0.0953,
      "step": 7569
    },
    {
      "epoch": 1.7394301470588234,
      "grad_norm": 2.0726261138916016,
      "learning_rate": 7.247242647058824e-06,
      "loss": 0.1045,
      "step": 7570
    },
    {
      "epoch": 1.7396599264705883,
      "grad_norm": 1.5855072736740112,
      "learning_rate": 7.246732026143791e-06,
      "loss": 0.1045,
      "step": 7571
    },
    {
      "epoch": 1.7398897058823528,
      "grad_norm": 1.7919325828552246,
      "learning_rate": 7.246221405228758e-06,
      "loss": 0.1014,
      "step": 7572
    },
    {
      "epoch": 1.7401194852941178,
      "grad_norm": 1.878866195678711,
      "learning_rate": 7.245710784313727e-06,
      "loss": 0.1079,
      "step": 7573
    },
    {
      "epoch": 1.7403492647058822,
      "grad_norm": 2.9047536849975586,
      "learning_rate": 7.245200163398694e-06,
      "loss": 0.1322,
      "step": 7574
    },
    {
      "epoch": 1.7405790441176472,
      "grad_norm": 1.803876280784607,
      "learning_rate": 7.244689542483661e-06,
      "loss": 0.1132,
      "step": 7575
    },
    {
      "epoch": 1.7408088235294117,
      "grad_norm": 1.5592260360717773,
      "learning_rate": 7.244178921568628e-06,
      "loss": 0.1195,
      "step": 7576
    },
    {
      "epoch": 1.7410386029411766,
      "grad_norm": 1.5669175386428833,
      "learning_rate": 7.243668300653596e-06,
      "loss": 0.131,
      "step": 7577
    },
    {
      "epoch": 1.7412683823529411,
      "grad_norm": 1.9437750577926636,
      "learning_rate": 7.243157679738563e-06,
      "loss": 0.0988,
      "step": 7578
    },
    {
      "epoch": 1.7414981617647058,
      "grad_norm": 1.4230502843856812,
      "learning_rate": 7.24264705882353e-06,
      "loss": 0.0972,
      "step": 7579
    },
    {
      "epoch": 1.7417279411764706,
      "grad_norm": 1.6353399753570557,
      "learning_rate": 7.242136437908497e-06,
      "loss": 0.1148,
      "step": 7580
    },
    {
      "epoch": 1.7419577205882353,
      "grad_norm": 3.5491573810577393,
      "learning_rate": 7.241625816993465e-06,
      "loss": 0.1736,
      "step": 7581
    },
    {
      "epoch": 1.7421875,
      "grad_norm": 1.7851831912994385,
      "learning_rate": 7.241115196078432e-06,
      "loss": 0.1263,
      "step": 7582
    },
    {
      "epoch": 1.7424172794117647,
      "grad_norm": 1.9999358654022217,
      "learning_rate": 7.240604575163399e-06,
      "loss": 0.1378,
      "step": 7583
    },
    {
      "epoch": 1.7426470588235294,
      "grad_norm": 1.976009726524353,
      "learning_rate": 7.240093954248366e-06,
      "loss": 0.1105,
      "step": 7584
    },
    {
      "epoch": 1.7428768382352942,
      "grad_norm": 1.7644325494766235,
      "learning_rate": 7.239583333333334e-06,
      "loss": 0.1126,
      "step": 7585
    },
    {
      "epoch": 1.7431066176470589,
      "grad_norm": 1.5552457571029663,
      "learning_rate": 7.239072712418301e-06,
      "loss": 0.1257,
      "step": 7586
    },
    {
      "epoch": 1.7433363970588234,
      "grad_norm": 1.9922302961349487,
      "learning_rate": 7.238562091503268e-06,
      "loss": 0.0895,
      "step": 7587
    },
    {
      "epoch": 1.7435661764705883,
      "grad_norm": 1.606444001197815,
      "learning_rate": 7.238051470588235e-06,
      "loss": 0.1274,
      "step": 7588
    },
    {
      "epoch": 1.7437959558823528,
      "grad_norm": 1.8194962739944458,
      "learning_rate": 7.237540849673204e-06,
      "loss": 0.1215,
      "step": 7589
    },
    {
      "epoch": 1.7440257352941178,
      "grad_norm": 1.632851004600525,
      "learning_rate": 7.237030228758171e-06,
      "loss": 0.1291,
      "step": 7590
    },
    {
      "epoch": 1.7442555147058822,
      "grad_norm": 1.8891770839691162,
      "learning_rate": 7.236519607843138e-06,
      "loss": 0.1124,
      "step": 7591
    },
    {
      "epoch": 1.7444852941176472,
      "grad_norm": 1.605448603630066,
      "learning_rate": 7.236008986928105e-06,
      "loss": 0.1368,
      "step": 7592
    },
    {
      "epoch": 1.7447150735294117,
      "grad_norm": 1.9827343225479126,
      "learning_rate": 7.235498366013073e-06,
      "loss": 0.1293,
      "step": 7593
    },
    {
      "epoch": 1.7449448529411766,
      "grad_norm": 1.5434330701828003,
      "learning_rate": 7.23498774509804e-06,
      "loss": 0.1247,
      "step": 7594
    },
    {
      "epoch": 1.7451746323529411,
      "grad_norm": 1.6105574369430542,
      "learning_rate": 7.234477124183007e-06,
      "loss": 0.1097,
      "step": 7595
    },
    {
      "epoch": 1.7454044117647058,
      "grad_norm": 1.6201447248458862,
      "learning_rate": 7.233966503267974e-06,
      "loss": 0.1304,
      "step": 7596
    },
    {
      "epoch": 1.7456341911764706,
      "grad_norm": 1.53873872756958,
      "learning_rate": 7.233455882352942e-06,
      "loss": 0.0978,
      "step": 7597
    },
    {
      "epoch": 1.7458639705882353,
      "grad_norm": 1.964422583580017,
      "learning_rate": 7.232945261437909e-06,
      "loss": 0.1347,
      "step": 7598
    },
    {
      "epoch": 1.74609375,
      "grad_norm": 1.3551985025405884,
      "learning_rate": 7.232434640522876e-06,
      "loss": 0.0974,
      "step": 7599
    },
    {
      "epoch": 1.7463235294117647,
      "grad_norm": 1.8431282043457031,
      "learning_rate": 7.231924019607844e-06,
      "loss": 0.1292,
      "step": 7600
    },
    {
      "epoch": 1.7465533088235294,
      "grad_norm": 1.9726338386535645,
      "learning_rate": 7.2314133986928116e-06,
      "loss": 0.105,
      "step": 7601
    },
    {
      "epoch": 1.7467830882352942,
      "grad_norm": 2.219015598297119,
      "learning_rate": 7.230902777777779e-06,
      "loss": 0.1438,
      "step": 7602
    },
    {
      "epoch": 1.7470128676470589,
      "grad_norm": 1.2244956493377686,
      "learning_rate": 7.230392156862746e-06,
      "loss": 0.1173,
      "step": 7603
    },
    {
      "epoch": 1.7472426470588234,
      "grad_norm": 1.9935534000396729,
      "learning_rate": 7.229881535947713e-06,
      "loss": 0.1265,
      "step": 7604
    },
    {
      "epoch": 1.7474724264705883,
      "grad_norm": 1.3440110683441162,
      "learning_rate": 7.2293709150326805e-06,
      "loss": 0.088,
      "step": 7605
    },
    {
      "epoch": 1.7477022058823528,
      "grad_norm": 1.5096911191940308,
      "learning_rate": 7.2288602941176475e-06,
      "loss": 0.0851,
      "step": 7606
    },
    {
      "epoch": 1.7479319852941178,
      "grad_norm": 1.571555495262146,
      "learning_rate": 7.2283496732026145e-06,
      "loss": 0.1015,
      "step": 7607
    },
    {
      "epoch": 1.7481617647058822,
      "grad_norm": 1.5296990871429443,
      "learning_rate": 7.2278390522875815e-06,
      "loss": 0.1143,
      "step": 7608
    },
    {
      "epoch": 1.7483915441176472,
      "grad_norm": 2.2029356956481934,
      "learning_rate": 7.22732843137255e-06,
      "loss": 0.1265,
      "step": 7609
    },
    {
      "epoch": 1.7486213235294117,
      "grad_norm": 1.6256660223007202,
      "learning_rate": 7.226817810457517e-06,
      "loss": 0.1045,
      "step": 7610
    },
    {
      "epoch": 1.7488511029411766,
      "grad_norm": 1.4681493043899536,
      "learning_rate": 7.226307189542484e-06,
      "loss": 0.1072,
      "step": 7611
    },
    {
      "epoch": 1.7490808823529411,
      "grad_norm": 1.6324113607406616,
      "learning_rate": 7.225796568627451e-06,
      "loss": 0.0708,
      "step": 7612
    },
    {
      "epoch": 1.7493106617647058,
      "grad_norm": 1.8039239645004272,
      "learning_rate": 7.225285947712419e-06,
      "loss": 0.1122,
      "step": 7613
    },
    {
      "epoch": 1.7495404411764706,
      "grad_norm": 1.8555078506469727,
      "learning_rate": 7.224775326797386e-06,
      "loss": 0.1015,
      "step": 7614
    },
    {
      "epoch": 1.7497702205882353,
      "grad_norm": 1.5110132694244385,
      "learning_rate": 7.224264705882353e-06,
      "loss": 0.1204,
      "step": 7615
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.6766176223754883,
      "learning_rate": 7.22375408496732e-06,
      "loss": 0.0949,
      "step": 7616
    },
    {
      "epoch": 1.7502297794117647,
      "grad_norm": 1.86313796043396,
      "learning_rate": 7.223243464052289e-06,
      "loss": 0.1135,
      "step": 7617
    },
    {
      "epoch": 1.7504595588235294,
      "grad_norm": 1.7093727588653564,
      "learning_rate": 7.222732843137256e-06,
      "loss": 0.1135,
      "step": 7618
    },
    {
      "epoch": 1.7506893382352942,
      "grad_norm": 1.4961109161376953,
      "learning_rate": 7.222222222222223e-06,
      "loss": 0.1032,
      "step": 7619
    },
    {
      "epoch": 1.7509191176470589,
      "grad_norm": 1.646538496017456,
      "learning_rate": 7.22171160130719e-06,
      "loss": 0.0969,
      "step": 7620
    },
    {
      "epoch": 1.7511488970588234,
      "grad_norm": 1.7097498178482056,
      "learning_rate": 7.221200980392158e-06,
      "loss": 0.1165,
      "step": 7621
    },
    {
      "epoch": 1.7513786764705883,
      "grad_norm": 2.3719305992126465,
      "learning_rate": 7.220690359477125e-06,
      "loss": 0.1637,
      "step": 7622
    },
    {
      "epoch": 1.7516084558823528,
      "grad_norm": 1.7308547496795654,
      "learning_rate": 7.220179738562092e-06,
      "loss": 0.1025,
      "step": 7623
    },
    {
      "epoch": 1.7518382352941178,
      "grad_norm": 1.7810031175613403,
      "learning_rate": 7.219669117647059e-06,
      "loss": 0.1179,
      "step": 7624
    },
    {
      "epoch": 1.7520680147058822,
      "grad_norm": 2.122675657272339,
      "learning_rate": 7.2191584967320275e-06,
      "loss": 0.1054,
      "step": 7625
    },
    {
      "epoch": 1.7522977941176472,
      "grad_norm": 2.774411678314209,
      "learning_rate": 7.2186478758169945e-06,
      "loss": 0.1165,
      "step": 7626
    },
    {
      "epoch": 1.7525275735294117,
      "grad_norm": 1.7138055562973022,
      "learning_rate": 7.2181372549019616e-06,
      "loss": 0.112,
      "step": 7627
    },
    {
      "epoch": 1.7527573529411766,
      "grad_norm": 1.672887921333313,
      "learning_rate": 7.217626633986929e-06,
      "loss": 0.0914,
      "step": 7628
    },
    {
      "epoch": 1.7529871323529411,
      "grad_norm": 2.0138967037200928,
      "learning_rate": 7.2171160130718964e-06,
      "loss": 0.1421,
      "step": 7629
    },
    {
      "epoch": 1.7532169117647058,
      "grad_norm": 2.842618227005005,
      "learning_rate": 7.2166053921568635e-06,
      "loss": 0.1388,
      "step": 7630
    },
    {
      "epoch": 1.7534466911764706,
      "grad_norm": 1.3943685293197632,
      "learning_rate": 7.2160947712418305e-06,
      "loss": 0.0872,
      "step": 7631
    },
    {
      "epoch": 1.7536764705882353,
      "grad_norm": 1.430933952331543,
      "learning_rate": 7.2155841503267975e-06,
      "loss": 0.1015,
      "step": 7632
    },
    {
      "epoch": 1.75390625,
      "grad_norm": 1.5722821950912476,
      "learning_rate": 7.215073529411765e-06,
      "loss": 0.0932,
      "step": 7633
    },
    {
      "epoch": 1.7541360294117647,
      "grad_norm": 1.7334542274475098,
      "learning_rate": 7.214562908496733e-06,
      "loss": 0.1268,
      "step": 7634
    },
    {
      "epoch": 1.7543658088235294,
      "grad_norm": 1.5435328483581543,
      "learning_rate": 7.2140522875817e-06,
      "loss": 0.1085,
      "step": 7635
    },
    {
      "epoch": 1.7545955882352942,
      "grad_norm": 1.3803668022155762,
      "learning_rate": 7.213541666666667e-06,
      "loss": 0.0724,
      "step": 7636
    },
    {
      "epoch": 1.7548253676470589,
      "grad_norm": 1.763339877128601,
      "learning_rate": 7.213031045751635e-06,
      "loss": 0.0905,
      "step": 7637
    },
    {
      "epoch": 1.7550551470588234,
      "grad_norm": 1.858879566192627,
      "learning_rate": 7.212520424836602e-06,
      "loss": 0.1245,
      "step": 7638
    },
    {
      "epoch": 1.7552849264705883,
      "grad_norm": 1.660534143447876,
      "learning_rate": 7.212009803921569e-06,
      "loss": 0.0903,
      "step": 7639
    },
    {
      "epoch": 1.7555147058823528,
      "grad_norm": 1.5488159656524658,
      "learning_rate": 7.211499183006536e-06,
      "loss": 0.0994,
      "step": 7640
    },
    {
      "epoch": 1.7557444852941178,
      "grad_norm": 2.126730442047119,
      "learning_rate": 7.210988562091504e-06,
      "loss": 0.1093,
      "step": 7641
    },
    {
      "epoch": 1.7559742647058822,
      "grad_norm": 2.0255308151245117,
      "learning_rate": 7.210477941176471e-06,
      "loss": 0.1519,
      "step": 7642
    },
    {
      "epoch": 1.7562040441176472,
      "grad_norm": 1.4945250749588013,
      "learning_rate": 7.209967320261438e-06,
      "loss": 0.1026,
      "step": 7643
    },
    {
      "epoch": 1.7564338235294117,
      "grad_norm": 1.2971521615982056,
      "learning_rate": 7.209456699346405e-06,
      "loss": 0.0876,
      "step": 7644
    },
    {
      "epoch": 1.7566636029411766,
      "grad_norm": 1.748360276222229,
      "learning_rate": 7.208946078431374e-06,
      "loss": 0.104,
      "step": 7645
    },
    {
      "epoch": 1.7568933823529411,
      "grad_norm": 1.8010878562927246,
      "learning_rate": 7.208435457516341e-06,
      "loss": 0.1153,
      "step": 7646
    },
    {
      "epoch": 1.7571231617647058,
      "grad_norm": 1.9189752340316772,
      "learning_rate": 7.207924836601308e-06,
      "loss": 0.0908,
      "step": 7647
    },
    {
      "epoch": 1.7573529411764706,
      "grad_norm": 1.912075400352478,
      "learning_rate": 7.207414215686275e-06,
      "loss": 0.0969,
      "step": 7648
    },
    {
      "epoch": 1.7575827205882353,
      "grad_norm": 1.654848575592041,
      "learning_rate": 7.206903594771243e-06,
      "loss": 0.1048,
      "step": 7649
    },
    {
      "epoch": 1.7578125,
      "grad_norm": 1.2409744262695312,
      "learning_rate": 7.20639297385621e-06,
      "loss": 0.0857,
      "step": 7650
    },
    {
      "epoch": 1.7580422794117647,
      "grad_norm": 1.5734875202178955,
      "learning_rate": 7.205882352941177e-06,
      "loss": 0.1025,
      "step": 7651
    },
    {
      "epoch": 1.7582720588235294,
      "grad_norm": 2.2234303951263428,
      "learning_rate": 7.205371732026144e-06,
      "loss": 0.1254,
      "step": 7652
    },
    {
      "epoch": 1.7585018382352942,
      "grad_norm": 1.972071886062622,
      "learning_rate": 7.204861111111112e-06,
      "loss": 0.072,
      "step": 7653
    },
    {
      "epoch": 1.7587316176470589,
      "grad_norm": 1.6998381614685059,
      "learning_rate": 7.2043504901960794e-06,
      "loss": 0.1067,
      "step": 7654
    },
    {
      "epoch": 1.7589613970588234,
      "grad_norm": 1.772839069366455,
      "learning_rate": 7.2038398692810464e-06,
      "loss": 0.0928,
      "step": 7655
    },
    {
      "epoch": 1.7591911764705883,
      "grad_norm": 1.8661264181137085,
      "learning_rate": 7.2033292483660135e-06,
      "loss": 0.134,
      "step": 7656
    },
    {
      "epoch": 1.7594209558823528,
      "grad_norm": 1.8395041227340698,
      "learning_rate": 7.202818627450981e-06,
      "loss": 0.1403,
      "step": 7657
    },
    {
      "epoch": 1.7596507352941178,
      "grad_norm": 2.061859369277954,
      "learning_rate": 7.202308006535948e-06,
      "loss": 0.1337,
      "step": 7658
    },
    {
      "epoch": 1.7598805147058822,
      "grad_norm": 1.886410117149353,
      "learning_rate": 7.201797385620915e-06,
      "loss": 0.1308,
      "step": 7659
    },
    {
      "epoch": 1.7601102941176472,
      "grad_norm": 1.832362413406372,
      "learning_rate": 7.201286764705882e-06,
      "loss": 0.1186,
      "step": 7660
    },
    {
      "epoch": 1.7603400735294117,
      "grad_norm": 1.993539810180664,
      "learning_rate": 7.200776143790851e-06,
      "loss": 0.1653,
      "step": 7661
    },
    {
      "epoch": 1.7605698529411766,
      "grad_norm": 1.770230770111084,
      "learning_rate": 7.200265522875818e-06,
      "loss": 0.127,
      "step": 7662
    },
    {
      "epoch": 1.7607996323529411,
      "grad_norm": 1.7936068773269653,
      "learning_rate": 7.199754901960785e-06,
      "loss": 0.1082,
      "step": 7663
    },
    {
      "epoch": 1.7610294117647058,
      "grad_norm": 2.4651644229888916,
      "learning_rate": 7.199244281045752e-06,
      "loss": 0.1181,
      "step": 7664
    },
    {
      "epoch": 1.7612591911764706,
      "grad_norm": 1.908581018447876,
      "learning_rate": 7.19873366013072e-06,
      "loss": 0.1235,
      "step": 7665
    },
    {
      "epoch": 1.7614889705882353,
      "grad_norm": 1.9466789960861206,
      "learning_rate": 7.198223039215687e-06,
      "loss": 0.1277,
      "step": 7666
    },
    {
      "epoch": 1.76171875,
      "grad_norm": 1.5136137008666992,
      "learning_rate": 7.197712418300654e-06,
      "loss": 0.0914,
      "step": 7667
    },
    {
      "epoch": 1.7619485294117647,
      "grad_norm": 1.699662446975708,
      "learning_rate": 7.197201797385621e-06,
      "loss": 0.1047,
      "step": 7668
    },
    {
      "epoch": 1.7621783088235294,
      "grad_norm": 2.771812915802002,
      "learning_rate": 7.19669117647059e-06,
      "loss": 0.1169,
      "step": 7669
    },
    {
      "epoch": 1.7624080882352942,
      "grad_norm": 1.2597355842590332,
      "learning_rate": 7.196180555555557e-06,
      "loss": 0.107,
      "step": 7670
    },
    {
      "epoch": 1.7626378676470589,
      "grad_norm": 1.6841367483139038,
      "learning_rate": 7.195669934640524e-06,
      "loss": 0.1241,
      "step": 7671
    },
    {
      "epoch": 1.7628676470588234,
      "grad_norm": 1.5034552812576294,
      "learning_rate": 7.195159313725491e-06,
      "loss": 0.0834,
      "step": 7672
    },
    {
      "epoch": 1.7630974264705883,
      "grad_norm": 1.3555546998977661,
      "learning_rate": 7.194648692810459e-06,
      "loss": 0.0807,
      "step": 7673
    },
    {
      "epoch": 1.7633272058823528,
      "grad_norm": 1.3340339660644531,
      "learning_rate": 7.194138071895426e-06,
      "loss": 0.1239,
      "step": 7674
    },
    {
      "epoch": 1.7635569852941178,
      "grad_norm": 2.0373079776763916,
      "learning_rate": 7.193627450980393e-06,
      "loss": 0.1303,
      "step": 7675
    },
    {
      "epoch": 1.7637867647058822,
      "grad_norm": 1.6812418699264526,
      "learning_rate": 7.19311683006536e-06,
      "loss": 0.1254,
      "step": 7676
    },
    {
      "epoch": 1.7640165441176472,
      "grad_norm": 1.7786983251571655,
      "learning_rate": 7.1926062091503275e-06,
      "loss": 0.1182,
      "step": 7677
    },
    {
      "epoch": 1.7642463235294117,
      "grad_norm": 1.4282125234603882,
      "learning_rate": 7.1920955882352945e-06,
      "loss": 0.099,
      "step": 7678
    },
    {
      "epoch": 1.7644761029411766,
      "grad_norm": 1.7487448453903198,
      "learning_rate": 7.191584967320262e-06,
      "loss": 0.0961,
      "step": 7679
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 1.8273324966430664,
      "learning_rate": 7.191074346405229e-06,
      "loss": 0.1342,
      "step": 7680
    },
    {
      "epoch": 1.7649356617647058,
      "grad_norm": 1.9836864471435547,
      "learning_rate": 7.190563725490197e-06,
      "loss": 0.1122,
      "step": 7681
    },
    {
      "epoch": 1.7651654411764706,
      "grad_norm": 1.7435753345489502,
      "learning_rate": 7.190053104575164e-06,
      "loss": 0.1483,
      "step": 7682
    },
    {
      "epoch": 1.7653952205882353,
      "grad_norm": 1.9418638944625854,
      "learning_rate": 7.189542483660131e-06,
      "loss": 0.1663,
      "step": 7683
    },
    {
      "epoch": 1.765625,
      "grad_norm": 2.023435354232788,
      "learning_rate": 7.189031862745098e-06,
      "loss": 0.1291,
      "step": 7684
    },
    {
      "epoch": 1.7658547794117647,
      "grad_norm": 1.8109514713287354,
      "learning_rate": 7.188521241830066e-06,
      "loss": 0.1388,
      "step": 7685
    },
    {
      "epoch": 1.7660845588235294,
      "grad_norm": 1.5630087852478027,
      "learning_rate": 7.188010620915033e-06,
      "loss": 0.1007,
      "step": 7686
    },
    {
      "epoch": 1.7663143382352942,
      "grad_norm": 1.5371179580688477,
      "learning_rate": 7.1875e-06,
      "loss": 0.1068,
      "step": 7687
    },
    {
      "epoch": 1.7665441176470589,
      "grad_norm": 1.6031955480575562,
      "learning_rate": 7.186989379084967e-06,
      "loss": 0.1324,
      "step": 7688
    },
    {
      "epoch": 1.7667738970588234,
      "grad_norm": 1.471665859222412,
      "learning_rate": 7.186478758169935e-06,
      "loss": 0.1087,
      "step": 7689
    },
    {
      "epoch": 1.7670036764705883,
      "grad_norm": 2.2895383834838867,
      "learning_rate": 7.185968137254903e-06,
      "loss": 0.1595,
      "step": 7690
    },
    {
      "epoch": 1.7672334558823528,
      "grad_norm": 1.670533537864685,
      "learning_rate": 7.18545751633987e-06,
      "loss": 0.1258,
      "step": 7691
    },
    {
      "epoch": 1.7674632352941178,
      "grad_norm": 1.5150490999221802,
      "learning_rate": 7.184946895424837e-06,
      "loss": 0.1164,
      "step": 7692
    },
    {
      "epoch": 1.7676930147058822,
      "grad_norm": 1.8849308490753174,
      "learning_rate": 7.184436274509804e-06,
      "loss": 0.103,
      "step": 7693
    },
    {
      "epoch": 1.7679227941176472,
      "grad_norm": 1.3156758546829224,
      "learning_rate": 7.183925653594772e-06,
      "loss": 0.1261,
      "step": 7694
    },
    {
      "epoch": 1.7681525735294117,
      "grad_norm": 1.6378498077392578,
      "learning_rate": 7.183415032679739e-06,
      "loss": 0.085,
      "step": 7695
    },
    {
      "epoch": 1.7683823529411766,
      "grad_norm": 1.4466016292572021,
      "learning_rate": 7.182904411764706e-06,
      "loss": 0.1239,
      "step": 7696
    },
    {
      "epoch": 1.7686121323529411,
      "grad_norm": 1.3061941862106323,
      "learning_rate": 7.182393790849673e-06,
      "loss": 0.0866,
      "step": 7697
    },
    {
      "epoch": 1.7688419117647058,
      "grad_norm": 1.8571155071258545,
      "learning_rate": 7.181883169934642e-06,
      "loss": 0.1407,
      "step": 7698
    },
    {
      "epoch": 1.7690716911764706,
      "grad_norm": 1.330171823501587,
      "learning_rate": 7.181372549019609e-06,
      "loss": 0.1149,
      "step": 7699
    },
    {
      "epoch": 1.7693014705882353,
      "grad_norm": 1.5674721002578735,
      "learning_rate": 7.180861928104576e-06,
      "loss": 0.0725,
      "step": 7700
    },
    {
      "epoch": 1.76953125,
      "grad_norm": 1.6702699661254883,
      "learning_rate": 7.180351307189543e-06,
      "loss": 0.123,
      "step": 7701
    },
    {
      "epoch": 1.7697610294117647,
      "grad_norm": 1.531631588935852,
      "learning_rate": 7.1798406862745105e-06,
      "loss": 0.1013,
      "step": 7702
    },
    {
      "epoch": 1.7699908088235294,
      "grad_norm": 1.5997328758239746,
      "learning_rate": 7.1793300653594775e-06,
      "loss": 0.1256,
      "step": 7703
    },
    {
      "epoch": 1.7702205882352942,
      "grad_norm": 1.8227523565292358,
      "learning_rate": 7.1788194444444445e-06,
      "loss": 0.105,
      "step": 7704
    },
    {
      "epoch": 1.7704503676470589,
      "grad_norm": 1.941136360168457,
      "learning_rate": 7.1783088235294116e-06,
      "loss": 0.1271,
      "step": 7705
    },
    {
      "epoch": 1.7706801470588234,
      "grad_norm": 1.7050600051879883,
      "learning_rate": 7.17779820261438e-06,
      "loss": 0.1209,
      "step": 7706
    },
    {
      "epoch": 1.7709099264705883,
      "grad_norm": 1.433750867843628,
      "learning_rate": 7.177287581699347e-06,
      "loss": 0.1083,
      "step": 7707
    },
    {
      "epoch": 1.7711397058823528,
      "grad_norm": 1.9229322671890259,
      "learning_rate": 7.176776960784314e-06,
      "loss": 0.1334,
      "step": 7708
    },
    {
      "epoch": 1.7713694852941178,
      "grad_norm": 2.1418514251708984,
      "learning_rate": 7.176266339869281e-06,
      "loss": 0.1064,
      "step": 7709
    },
    {
      "epoch": 1.7715992647058822,
      "grad_norm": 1.5197972059249878,
      "learning_rate": 7.175755718954249e-06,
      "loss": 0.1109,
      "step": 7710
    },
    {
      "epoch": 1.7718290441176472,
      "grad_norm": 1.6617296934127808,
      "learning_rate": 7.175245098039216e-06,
      "loss": 0.0766,
      "step": 7711
    },
    {
      "epoch": 1.7720588235294117,
      "grad_norm": 1.4777449369430542,
      "learning_rate": 7.174734477124183e-06,
      "loss": 0.1243,
      "step": 7712
    },
    {
      "epoch": 1.7722886029411766,
      "grad_norm": 2.29837703704834,
      "learning_rate": 7.17422385620915e-06,
      "loss": 0.1129,
      "step": 7713
    },
    {
      "epoch": 1.7725183823529411,
      "grad_norm": 2.1249561309814453,
      "learning_rate": 7.173713235294119e-06,
      "loss": 0.0965,
      "step": 7714
    },
    {
      "epoch": 1.7727481617647058,
      "grad_norm": 1.701690912246704,
      "learning_rate": 7.173202614379086e-06,
      "loss": 0.1304,
      "step": 7715
    },
    {
      "epoch": 1.7729779411764706,
      "grad_norm": 1.3732216358184814,
      "learning_rate": 7.172691993464053e-06,
      "loss": 0.0744,
      "step": 7716
    },
    {
      "epoch": 1.7732077205882353,
      "grad_norm": 1.980555534362793,
      "learning_rate": 7.17218137254902e-06,
      "loss": 0.122,
      "step": 7717
    },
    {
      "epoch": 1.7734375,
      "grad_norm": 1.7380590438842773,
      "learning_rate": 7.171670751633988e-06,
      "loss": 0.1153,
      "step": 7718
    },
    {
      "epoch": 1.7736672794117647,
      "grad_norm": 2.0375430583953857,
      "learning_rate": 7.171160130718955e-06,
      "loss": 0.1112,
      "step": 7719
    },
    {
      "epoch": 1.7738970588235294,
      "grad_norm": 1.687243938446045,
      "learning_rate": 7.170649509803922e-06,
      "loss": 0.1059,
      "step": 7720
    },
    {
      "epoch": 1.7741268382352942,
      "grad_norm": 1.8512508869171143,
      "learning_rate": 7.170138888888889e-06,
      "loss": 0.1002,
      "step": 7721
    },
    {
      "epoch": 1.7743566176470589,
      "grad_norm": 2.1519935131073,
      "learning_rate": 7.169628267973857e-06,
      "loss": 0.1256,
      "step": 7722
    },
    {
      "epoch": 1.7745863970588234,
      "grad_norm": 2.083390712738037,
      "learning_rate": 7.169117647058825e-06,
      "loss": 0.1383,
      "step": 7723
    },
    {
      "epoch": 1.7748161764705883,
      "grad_norm": 1.8250324726104736,
      "learning_rate": 7.168607026143792e-06,
      "loss": 0.1095,
      "step": 7724
    },
    {
      "epoch": 1.7750459558823528,
      "grad_norm": 1.9358221292495728,
      "learning_rate": 7.168096405228759e-06,
      "loss": 0.1156,
      "step": 7725
    },
    {
      "epoch": 1.7752757352941178,
      "grad_norm": 1.502035140991211,
      "learning_rate": 7.1675857843137265e-06,
      "loss": 0.0977,
      "step": 7726
    },
    {
      "epoch": 1.7755055147058822,
      "grad_norm": 1.9508813619613647,
      "learning_rate": 7.1670751633986935e-06,
      "loss": 0.0856,
      "step": 7727
    },
    {
      "epoch": 1.7757352941176472,
      "grad_norm": 1.5941928625106812,
      "learning_rate": 7.1665645424836605e-06,
      "loss": 0.0945,
      "step": 7728
    },
    {
      "epoch": 1.7759650735294117,
      "grad_norm": 1.4250916242599487,
      "learning_rate": 7.1660539215686275e-06,
      "loss": 0.1384,
      "step": 7729
    },
    {
      "epoch": 1.7761948529411766,
      "grad_norm": 1.4603079557418823,
      "learning_rate": 7.165543300653595e-06,
      "loss": 0.0726,
      "step": 7730
    },
    {
      "epoch": 1.7764246323529411,
      "grad_norm": 1.7052029371261597,
      "learning_rate": 7.165032679738562e-06,
      "loss": 0.0991,
      "step": 7731
    },
    {
      "epoch": 1.7766544117647058,
      "grad_norm": 1.8229238986968994,
      "learning_rate": 7.164522058823529e-06,
      "loss": 0.126,
      "step": 7732
    },
    {
      "epoch": 1.7768841911764706,
      "grad_norm": 1.2995104789733887,
      "learning_rate": 7.1640114379084964e-06,
      "loss": 0.108,
      "step": 7733
    },
    {
      "epoch": 1.7771139705882353,
      "grad_norm": 1.3297704458236694,
      "learning_rate": 7.163500816993465e-06,
      "loss": 0.104,
      "step": 7734
    },
    {
      "epoch": 1.77734375,
      "grad_norm": 1.855647087097168,
      "learning_rate": 7.162990196078432e-06,
      "loss": 0.0959,
      "step": 7735
    },
    {
      "epoch": 1.7775735294117647,
      "grad_norm": 2.0848987102508545,
      "learning_rate": 7.162479575163399e-06,
      "loss": 0.1621,
      "step": 7736
    },
    {
      "epoch": 1.7778033088235294,
      "grad_norm": 1.463008165359497,
      "learning_rate": 7.161968954248366e-06,
      "loss": 0.1017,
      "step": 7737
    },
    {
      "epoch": 1.7780330882352942,
      "grad_norm": 1.9945353269577026,
      "learning_rate": 7.161458333333334e-06,
      "loss": 0.138,
      "step": 7738
    },
    {
      "epoch": 1.7782628676470589,
      "grad_norm": 1.8987579345703125,
      "learning_rate": 7.160947712418301e-06,
      "loss": 0.135,
      "step": 7739
    },
    {
      "epoch": 1.7784926470588234,
      "grad_norm": 1.786444902420044,
      "learning_rate": 7.160437091503268e-06,
      "loss": 0.0913,
      "step": 7740
    },
    {
      "epoch": 1.7787224264705883,
      "grad_norm": 1.5565259456634521,
      "learning_rate": 7.159926470588235e-06,
      "loss": 0.1232,
      "step": 7741
    },
    {
      "epoch": 1.7789522058823528,
      "grad_norm": 1.741498589515686,
      "learning_rate": 7.159415849673204e-06,
      "loss": 0.1135,
      "step": 7742
    },
    {
      "epoch": 1.7791819852941178,
      "grad_norm": 2.375821352005005,
      "learning_rate": 7.158905228758171e-06,
      "loss": 0.105,
      "step": 7743
    },
    {
      "epoch": 1.7794117647058822,
      "grad_norm": 1.700850486755371,
      "learning_rate": 7.158394607843138e-06,
      "loss": 0.1269,
      "step": 7744
    },
    {
      "epoch": 1.7796415441176472,
      "grad_norm": 1.3752375841140747,
      "learning_rate": 7.157883986928105e-06,
      "loss": 0.081,
      "step": 7745
    },
    {
      "epoch": 1.7798713235294117,
      "grad_norm": 1.694753646850586,
      "learning_rate": 7.157373366013073e-06,
      "loss": 0.0791,
      "step": 7746
    },
    {
      "epoch": 1.7801011029411766,
      "grad_norm": 1.690662145614624,
      "learning_rate": 7.15686274509804e-06,
      "loss": 0.1142,
      "step": 7747
    },
    {
      "epoch": 1.7803308823529411,
      "grad_norm": 1.7076666355133057,
      "learning_rate": 7.156352124183007e-06,
      "loss": 0.1021,
      "step": 7748
    },
    {
      "epoch": 1.7805606617647058,
      "grad_norm": 1.7609328031539917,
      "learning_rate": 7.155841503267974e-06,
      "loss": 0.1422,
      "step": 7749
    },
    {
      "epoch": 1.7807904411764706,
      "grad_norm": 1.6493644714355469,
      "learning_rate": 7.1553308823529425e-06,
      "loss": 0.1199,
      "step": 7750
    },
    {
      "epoch": 1.7810202205882353,
      "grad_norm": 1.4809545278549194,
      "learning_rate": 7.1548202614379095e-06,
      "loss": 0.1152,
      "step": 7751
    },
    {
      "epoch": 1.78125,
      "grad_norm": 1.7978013753890991,
      "learning_rate": 7.1543096405228765e-06,
      "loss": 0.1211,
      "step": 7752
    },
    {
      "epoch": 1.7814797794117647,
      "grad_norm": 1.7681572437286377,
      "learning_rate": 7.1537990196078435e-06,
      "loss": 0.1088,
      "step": 7753
    },
    {
      "epoch": 1.7817095588235294,
      "grad_norm": 2.085758686065674,
      "learning_rate": 7.153288398692811e-06,
      "loss": 0.13,
      "step": 7754
    },
    {
      "epoch": 1.7819393382352942,
      "grad_norm": 1.6210360527038574,
      "learning_rate": 7.152777777777778e-06,
      "loss": 0.1007,
      "step": 7755
    },
    {
      "epoch": 1.7821691176470589,
      "grad_norm": 1.5736950635910034,
      "learning_rate": 7.152267156862745e-06,
      "loss": 0.1024,
      "step": 7756
    },
    {
      "epoch": 1.7823988970588234,
      "grad_norm": 1.784114122390747,
      "learning_rate": 7.151756535947712e-06,
      "loss": 0.1174,
      "step": 7757
    },
    {
      "epoch": 1.7826286764705883,
      "grad_norm": 1.640448808670044,
      "learning_rate": 7.151245915032681e-06,
      "loss": 0.0825,
      "step": 7758
    },
    {
      "epoch": 1.7828584558823528,
      "grad_norm": 1.5981523990631104,
      "learning_rate": 7.150735294117648e-06,
      "loss": 0.08,
      "step": 7759
    },
    {
      "epoch": 1.7830882352941178,
      "grad_norm": 1.6627346277236938,
      "learning_rate": 7.150224673202615e-06,
      "loss": 0.1099,
      "step": 7760
    },
    {
      "epoch": 1.7833180147058822,
      "grad_norm": 1.4273258447647095,
      "learning_rate": 7.149714052287582e-06,
      "loss": 0.1054,
      "step": 7761
    },
    {
      "epoch": 1.7835477941176472,
      "grad_norm": 1.5661134719848633,
      "learning_rate": 7.14920343137255e-06,
      "loss": 0.1268,
      "step": 7762
    },
    {
      "epoch": 1.7837775735294117,
      "grad_norm": 1.5178625583648682,
      "learning_rate": 7.148692810457517e-06,
      "loss": 0.0841,
      "step": 7763
    },
    {
      "epoch": 1.7840073529411766,
      "grad_norm": 1.4981920719146729,
      "learning_rate": 7.148182189542484e-06,
      "loss": 0.0805,
      "step": 7764
    },
    {
      "epoch": 1.7842371323529411,
      "grad_norm": 1.5873204469680786,
      "learning_rate": 7.147671568627451e-06,
      "loss": 0.0684,
      "step": 7765
    },
    {
      "epoch": 1.7844669117647058,
      "grad_norm": 1.7970044612884521,
      "learning_rate": 7.147160947712419e-06,
      "loss": 0.0935,
      "step": 7766
    },
    {
      "epoch": 1.7846966911764706,
      "grad_norm": 2.033907651901245,
      "learning_rate": 7.146650326797386e-06,
      "loss": 0.1166,
      "step": 7767
    },
    {
      "epoch": 1.7849264705882353,
      "grad_norm": 1.4112322330474854,
      "learning_rate": 7.146139705882354e-06,
      "loss": 0.0934,
      "step": 7768
    },
    {
      "epoch": 1.78515625,
      "grad_norm": 1.659425973892212,
      "learning_rate": 7.145629084967321e-06,
      "loss": 0.1054,
      "step": 7769
    },
    {
      "epoch": 1.7853860294117647,
      "grad_norm": 1.9025133848190308,
      "learning_rate": 7.145118464052289e-06,
      "loss": 0.1187,
      "step": 7770
    },
    {
      "epoch": 1.7856158088235294,
      "grad_norm": 2.1715805530548096,
      "learning_rate": 7.144607843137256e-06,
      "loss": 0.1594,
      "step": 7771
    },
    {
      "epoch": 1.7858455882352942,
      "grad_norm": 1.9206123352050781,
      "learning_rate": 7.144097222222223e-06,
      "loss": 0.127,
      "step": 7772
    },
    {
      "epoch": 1.7860753676470589,
      "grad_norm": 1.7729572057724,
      "learning_rate": 7.14358660130719e-06,
      "loss": 0.1498,
      "step": 7773
    },
    {
      "epoch": 1.7863051470588234,
      "grad_norm": 1.6961443424224854,
      "learning_rate": 7.143075980392158e-06,
      "loss": 0.1374,
      "step": 7774
    },
    {
      "epoch": 1.7865349264705883,
      "grad_norm": 2.522832155227661,
      "learning_rate": 7.142565359477125e-06,
      "loss": 0.1494,
      "step": 7775
    },
    {
      "epoch": 1.7867647058823528,
      "grad_norm": 1.657388687133789,
      "learning_rate": 7.142054738562092e-06,
      "loss": 0.0646,
      "step": 7776
    },
    {
      "epoch": 1.7869944852941178,
      "grad_norm": 2.4108572006225586,
      "learning_rate": 7.141544117647059e-06,
      "loss": 0.1238,
      "step": 7777
    },
    {
      "epoch": 1.7872242647058822,
      "grad_norm": 1.5609220266342163,
      "learning_rate": 7.141033496732027e-06,
      "loss": 0.1423,
      "step": 7778
    },
    {
      "epoch": 1.7874540441176472,
      "grad_norm": 1.6352152824401855,
      "learning_rate": 7.140522875816994e-06,
      "loss": 0.1104,
      "step": 7779
    },
    {
      "epoch": 1.7876838235294117,
      "grad_norm": 1.370463252067566,
      "learning_rate": 7.140012254901961e-06,
      "loss": 0.076,
      "step": 7780
    },
    {
      "epoch": 1.7879136029411766,
      "grad_norm": 1.6856732368469238,
      "learning_rate": 7.139501633986928e-06,
      "loss": 0.0971,
      "step": 7781
    },
    {
      "epoch": 1.7881433823529411,
      "grad_norm": 1.6964492797851562,
      "learning_rate": 7.138991013071896e-06,
      "loss": 0.1243,
      "step": 7782
    },
    {
      "epoch": 1.7883731617647058,
      "grad_norm": 1.8651916980743408,
      "learning_rate": 7.138480392156863e-06,
      "loss": 0.1046,
      "step": 7783
    },
    {
      "epoch": 1.7886029411764706,
      "grad_norm": 2.2766542434692383,
      "learning_rate": 7.13796977124183e-06,
      "loss": 0.1083,
      "step": 7784
    },
    {
      "epoch": 1.7888327205882353,
      "grad_norm": 1.736687421798706,
      "learning_rate": 7.137459150326797e-06,
      "loss": 0.1062,
      "step": 7785
    },
    {
      "epoch": 1.7890625,
      "grad_norm": 1.544277310371399,
      "learning_rate": 7.136948529411766e-06,
      "loss": 0.1184,
      "step": 7786
    },
    {
      "epoch": 1.7892922794117647,
      "grad_norm": 1.8149206638336182,
      "learning_rate": 7.136437908496733e-06,
      "loss": 0.1053,
      "step": 7787
    },
    {
      "epoch": 1.7895220588235294,
      "grad_norm": 1.7169287204742432,
      "learning_rate": 7.1359272875817e-06,
      "loss": 0.1281,
      "step": 7788
    },
    {
      "epoch": 1.7897518382352942,
      "grad_norm": 1.401858925819397,
      "learning_rate": 7.135416666666667e-06,
      "loss": 0.0983,
      "step": 7789
    },
    {
      "epoch": 1.7899816176470589,
      "grad_norm": 2.3325905799865723,
      "learning_rate": 7.134906045751635e-06,
      "loss": 0.135,
      "step": 7790
    },
    {
      "epoch": 1.7902113970588234,
      "grad_norm": 1.1315370798110962,
      "learning_rate": 7.134395424836602e-06,
      "loss": 0.0731,
      "step": 7791
    },
    {
      "epoch": 1.7904411764705883,
      "grad_norm": 1.4115608930587769,
      "learning_rate": 7.133884803921569e-06,
      "loss": 0.0972,
      "step": 7792
    },
    {
      "epoch": 1.7906709558823528,
      "grad_norm": 1.6148115396499634,
      "learning_rate": 7.133374183006536e-06,
      "loss": 0.1089,
      "step": 7793
    },
    {
      "epoch": 1.7909007352941178,
      "grad_norm": 1.5045799016952515,
      "learning_rate": 7.132863562091505e-06,
      "loss": 0.1203,
      "step": 7794
    },
    {
      "epoch": 1.7911305147058822,
      "grad_norm": 1.5544302463531494,
      "learning_rate": 7.132352941176472e-06,
      "loss": 0.0967,
      "step": 7795
    },
    {
      "epoch": 1.7913602941176472,
      "grad_norm": 1.9503591060638428,
      "learning_rate": 7.131842320261439e-06,
      "loss": 0.1154,
      "step": 7796
    },
    {
      "epoch": 1.7915900735294117,
      "grad_norm": 1.6436740159988403,
      "learning_rate": 7.131331699346406e-06,
      "loss": 0.1167,
      "step": 7797
    },
    {
      "epoch": 1.7918198529411766,
      "grad_norm": 1.6323959827423096,
      "learning_rate": 7.1308210784313735e-06,
      "loss": 0.097,
      "step": 7798
    },
    {
      "epoch": 1.7920496323529411,
      "grad_norm": 2.6933414936065674,
      "learning_rate": 7.1303104575163406e-06,
      "loss": 0.1761,
      "step": 7799
    },
    {
      "epoch": 1.7922794117647058,
      "grad_norm": 1.338226079940796,
      "learning_rate": 7.129799836601308e-06,
      "loss": 0.0862,
      "step": 7800
    },
    {
      "epoch": 1.7925091911764706,
      "grad_norm": 2.38499116897583,
      "learning_rate": 7.129289215686275e-06,
      "loss": 0.1657,
      "step": 7801
    },
    {
      "epoch": 1.7927389705882353,
      "grad_norm": 1.6696207523345947,
      "learning_rate": 7.128778594771243e-06,
      "loss": 0.1222,
      "step": 7802
    },
    {
      "epoch": 1.79296875,
      "grad_norm": 1.7709765434265137,
      "learning_rate": 7.12826797385621e-06,
      "loss": 0.1051,
      "step": 7803
    },
    {
      "epoch": 1.7931985294117647,
      "grad_norm": 2.0400242805480957,
      "learning_rate": 7.127757352941177e-06,
      "loss": 0.0977,
      "step": 7804
    },
    {
      "epoch": 1.7934283088235294,
      "grad_norm": 1.7250277996063232,
      "learning_rate": 7.127246732026144e-06,
      "loss": 0.1266,
      "step": 7805
    },
    {
      "epoch": 1.7936580882352942,
      "grad_norm": 2.0044586658477783,
      "learning_rate": 7.126736111111112e-06,
      "loss": 0.1095,
      "step": 7806
    },
    {
      "epoch": 1.7938878676470589,
      "grad_norm": 1.4327082633972168,
      "learning_rate": 7.126225490196079e-06,
      "loss": 0.109,
      "step": 7807
    },
    {
      "epoch": 1.7941176470588234,
      "grad_norm": 1.194360613822937,
      "learning_rate": 7.125714869281046e-06,
      "loss": 0.0792,
      "step": 7808
    },
    {
      "epoch": 1.7943474264705883,
      "grad_norm": 1.9729100465774536,
      "learning_rate": 7.125204248366013e-06,
      "loss": 0.09,
      "step": 7809
    },
    {
      "epoch": 1.7945772058823528,
      "grad_norm": 1.4055501222610474,
      "learning_rate": 7.124693627450981e-06,
      "loss": 0.0784,
      "step": 7810
    },
    {
      "epoch": 1.7948069852941178,
      "grad_norm": 2.649233818054199,
      "learning_rate": 7.124183006535948e-06,
      "loss": 0.1658,
      "step": 7811
    },
    {
      "epoch": 1.7950367647058822,
      "grad_norm": 1.6455378532409668,
      "learning_rate": 7.123672385620916e-06,
      "loss": 0.1165,
      "step": 7812
    },
    {
      "epoch": 1.7952665441176472,
      "grad_norm": 1.6244134902954102,
      "learning_rate": 7.123161764705883e-06,
      "loss": 0.101,
      "step": 7813
    },
    {
      "epoch": 1.7954963235294117,
      "grad_norm": 2.1173269748687744,
      "learning_rate": 7.122651143790851e-06,
      "loss": 0.1179,
      "step": 7814
    },
    {
      "epoch": 1.7957261029411766,
      "grad_norm": 2.0208466053009033,
      "learning_rate": 7.122140522875818e-06,
      "loss": 0.1419,
      "step": 7815
    },
    {
      "epoch": 1.7959558823529411,
      "grad_norm": 1.7187776565551758,
      "learning_rate": 7.121629901960785e-06,
      "loss": 0.1039,
      "step": 7816
    },
    {
      "epoch": 1.7961856617647058,
      "grad_norm": 1.41367769241333,
      "learning_rate": 7.121119281045752e-06,
      "loss": 0.0897,
      "step": 7817
    },
    {
      "epoch": 1.7964154411764706,
      "grad_norm": 2.036897659301758,
      "learning_rate": 7.12060866013072e-06,
      "loss": 0.1405,
      "step": 7818
    },
    {
      "epoch": 1.7966452205882353,
      "grad_norm": 1.7264344692230225,
      "learning_rate": 7.120098039215687e-06,
      "loss": 0.1283,
      "step": 7819
    },
    {
      "epoch": 1.796875,
      "grad_norm": 1.8115849494934082,
      "learning_rate": 7.119587418300654e-06,
      "loss": 0.0858,
      "step": 7820
    },
    {
      "epoch": 1.7971047794117647,
      "grad_norm": 1.7706066370010376,
      "learning_rate": 7.119076797385621e-06,
      "loss": 0.1113,
      "step": 7821
    },
    {
      "epoch": 1.7973345588235294,
      "grad_norm": 1.7263447046279907,
      "learning_rate": 7.1185661764705895e-06,
      "loss": 0.1007,
      "step": 7822
    },
    {
      "epoch": 1.7975643382352942,
      "grad_norm": 1.2971765995025635,
      "learning_rate": 7.1180555555555565e-06,
      "loss": 0.0793,
      "step": 7823
    },
    {
      "epoch": 1.7977941176470589,
      "grad_norm": 1.85389244556427,
      "learning_rate": 7.1175449346405235e-06,
      "loss": 0.1053,
      "step": 7824
    },
    {
      "epoch": 1.7980238970588234,
      "grad_norm": 1.266025424003601,
      "learning_rate": 7.1170343137254906e-06,
      "loss": 0.0783,
      "step": 7825
    },
    {
      "epoch": 1.7982536764705883,
      "grad_norm": 1.560500979423523,
      "learning_rate": 7.116523692810458e-06,
      "loss": 0.0953,
      "step": 7826
    },
    {
      "epoch": 1.7984834558823528,
      "grad_norm": 1.6098616123199463,
      "learning_rate": 7.1160130718954254e-06,
      "loss": 0.1064,
      "step": 7827
    },
    {
      "epoch": 1.7987132352941178,
      "grad_norm": 1.7721731662750244,
      "learning_rate": 7.1155024509803925e-06,
      "loss": 0.0956,
      "step": 7828
    },
    {
      "epoch": 1.7989430147058822,
      "grad_norm": 1.3259185552597046,
      "learning_rate": 7.1149918300653595e-06,
      "loss": 0.1245,
      "step": 7829
    },
    {
      "epoch": 1.7991727941176472,
      "grad_norm": 1.4580113887786865,
      "learning_rate": 7.114481209150328e-06,
      "loss": 0.0879,
      "step": 7830
    },
    {
      "epoch": 1.7994025735294117,
      "grad_norm": 1.2493106126785278,
      "learning_rate": 7.113970588235295e-06,
      "loss": 0.0849,
      "step": 7831
    },
    {
      "epoch": 1.7996323529411766,
      "grad_norm": 1.6139097213745117,
      "learning_rate": 7.113459967320262e-06,
      "loss": 0.0978,
      "step": 7832
    },
    {
      "epoch": 1.7998621323529411,
      "grad_norm": 1.8386836051940918,
      "learning_rate": 7.112949346405229e-06,
      "loss": 0.1842,
      "step": 7833
    },
    {
      "epoch": 1.8000919117647058,
      "grad_norm": 1.5344539880752563,
      "learning_rate": 7.112438725490197e-06,
      "loss": 0.0955,
      "step": 7834
    },
    {
      "epoch": 1.8003216911764706,
      "grad_norm": 1.622890830039978,
      "learning_rate": 7.111928104575164e-06,
      "loss": 0.1164,
      "step": 7835
    },
    {
      "epoch": 1.8005514705882353,
      "grad_norm": 2.046807050704956,
      "learning_rate": 7.111417483660131e-06,
      "loss": 0.1179,
      "step": 7836
    },
    {
      "epoch": 1.80078125,
      "grad_norm": 1.7708438634872437,
      "learning_rate": 7.110906862745098e-06,
      "loss": 0.1224,
      "step": 7837
    },
    {
      "epoch": 1.8010110294117647,
      "grad_norm": 1.331426739692688,
      "learning_rate": 7.110396241830067e-06,
      "loss": 0.0814,
      "step": 7838
    },
    {
      "epoch": 1.8012408088235294,
      "grad_norm": 1.3706715106964111,
      "learning_rate": 7.109885620915034e-06,
      "loss": 0.0595,
      "step": 7839
    },
    {
      "epoch": 1.8014705882352942,
      "grad_norm": 1.5957082509994507,
      "learning_rate": 7.109375000000001e-06,
      "loss": 0.125,
      "step": 7840
    },
    {
      "epoch": 1.8017003676470589,
      "grad_norm": 1.5901682376861572,
      "learning_rate": 7.108864379084968e-06,
      "loss": 0.0751,
      "step": 7841
    },
    {
      "epoch": 1.8019301470588234,
      "grad_norm": 1.2922531366348267,
      "learning_rate": 7.108353758169935e-06,
      "loss": 0.1045,
      "step": 7842
    },
    {
      "epoch": 1.8021599264705883,
      "grad_norm": 1.7688930034637451,
      "learning_rate": 7.107843137254903e-06,
      "loss": 0.1359,
      "step": 7843
    },
    {
      "epoch": 1.8023897058823528,
      "grad_norm": 2.150852680206299,
      "learning_rate": 7.10733251633987e-06,
      "loss": 0.092,
      "step": 7844
    },
    {
      "epoch": 1.8026194852941178,
      "grad_norm": 1.930938482284546,
      "learning_rate": 7.106821895424837e-06,
      "loss": 0.1167,
      "step": 7845
    },
    {
      "epoch": 1.8028492647058822,
      "grad_norm": 2.9208996295928955,
      "learning_rate": 7.106311274509804e-06,
      "loss": 0.1453,
      "step": 7846
    },
    {
      "epoch": 1.8030790441176472,
      "grad_norm": 1.4246816635131836,
      "learning_rate": 7.1058006535947725e-06,
      "loss": 0.0869,
      "step": 7847
    },
    {
      "epoch": 1.8033088235294117,
      "grad_norm": 1.9533536434173584,
      "learning_rate": 7.1052900326797395e-06,
      "loss": 0.1116,
      "step": 7848
    },
    {
      "epoch": 1.8035386029411766,
      "grad_norm": 1.645206332206726,
      "learning_rate": 7.1047794117647065e-06,
      "loss": 0.1239,
      "step": 7849
    },
    {
      "epoch": 1.8037683823529411,
      "grad_norm": 1.4275790452957153,
      "learning_rate": 7.1042687908496735e-06,
      "loss": 0.1124,
      "step": 7850
    },
    {
      "epoch": 1.8039981617647058,
      "grad_norm": 1.6912494897842407,
      "learning_rate": 7.103758169934641e-06,
      "loss": 0.116,
      "step": 7851
    },
    {
      "epoch": 1.8042279411764706,
      "grad_norm": 1.5876606702804565,
      "learning_rate": 7.103247549019608e-06,
      "loss": 0.1186,
      "step": 7852
    },
    {
      "epoch": 1.8044577205882353,
      "grad_norm": 2.325556755065918,
      "learning_rate": 7.1027369281045754e-06,
      "loss": 0.1288,
      "step": 7853
    },
    {
      "epoch": 1.8046875,
      "grad_norm": 1.3916096687316895,
      "learning_rate": 7.1022263071895424e-06,
      "loss": 0.099,
      "step": 7854
    },
    {
      "epoch": 1.8049172794117647,
      "grad_norm": 2.0268967151641846,
      "learning_rate": 7.10171568627451e-06,
      "loss": 0.1578,
      "step": 7855
    },
    {
      "epoch": 1.8051470588235294,
      "grad_norm": 1.6222703456878662,
      "learning_rate": 7.101205065359477e-06,
      "loss": 0.0889,
      "step": 7856
    },
    {
      "epoch": 1.8053768382352942,
      "grad_norm": 1.954172968864441,
      "learning_rate": 7.100694444444445e-06,
      "loss": 0.159,
      "step": 7857
    },
    {
      "epoch": 1.8056066176470589,
      "grad_norm": 1.5780129432678223,
      "learning_rate": 7.100183823529412e-06,
      "loss": 0.1197,
      "step": 7858
    },
    {
      "epoch": 1.8058363970588234,
      "grad_norm": 1.7636388540267944,
      "learning_rate": 7.09967320261438e-06,
      "loss": 0.1157,
      "step": 7859
    },
    {
      "epoch": 1.8060661764705883,
      "grad_norm": 1.6793725490570068,
      "learning_rate": 7.099162581699347e-06,
      "loss": 0.111,
      "step": 7860
    },
    {
      "epoch": 1.8062959558823528,
      "grad_norm": 1.9826115369796753,
      "learning_rate": 7.098651960784314e-06,
      "loss": 0.096,
      "step": 7861
    },
    {
      "epoch": 1.8065257352941178,
      "grad_norm": 2.3994784355163574,
      "learning_rate": 7.098141339869281e-06,
      "loss": 0.1444,
      "step": 7862
    },
    {
      "epoch": 1.8067555147058822,
      "grad_norm": 1.8233836889266968,
      "learning_rate": 7.097630718954249e-06,
      "loss": 0.1324,
      "step": 7863
    },
    {
      "epoch": 1.8069852941176472,
      "grad_norm": 1.1952524185180664,
      "learning_rate": 7.097120098039216e-06,
      "loss": 0.0905,
      "step": 7864
    },
    {
      "epoch": 1.8072150735294117,
      "grad_norm": 2.057229995727539,
      "learning_rate": 7.096609477124183e-06,
      "loss": 0.1285,
      "step": 7865
    },
    {
      "epoch": 1.8074448529411766,
      "grad_norm": 1.903826117515564,
      "learning_rate": 7.09609885620915e-06,
      "loss": 0.1035,
      "step": 7866
    },
    {
      "epoch": 1.8076746323529411,
      "grad_norm": 1.6324524879455566,
      "learning_rate": 7.095588235294119e-06,
      "loss": 0.1335,
      "step": 7867
    },
    {
      "epoch": 1.8079044117647058,
      "grad_norm": 1.8369946479797363,
      "learning_rate": 7.095077614379086e-06,
      "loss": 0.1337,
      "step": 7868
    },
    {
      "epoch": 1.8081341911764706,
      "grad_norm": 1.964614748954773,
      "learning_rate": 7.094566993464053e-06,
      "loss": 0.1339,
      "step": 7869
    },
    {
      "epoch": 1.8083639705882353,
      "grad_norm": 2.007025718688965,
      "learning_rate": 7.09405637254902e-06,
      "loss": 0.1109,
      "step": 7870
    },
    {
      "epoch": 1.80859375,
      "grad_norm": 2.1977930068969727,
      "learning_rate": 7.093545751633988e-06,
      "loss": 0.151,
      "step": 7871
    },
    {
      "epoch": 1.8088235294117647,
      "grad_norm": 2.1546247005462646,
      "learning_rate": 7.093035130718955e-06,
      "loss": 0.1252,
      "step": 7872
    },
    {
      "epoch": 1.8090533088235294,
      "grad_norm": 2.065521478652954,
      "learning_rate": 7.092524509803922e-06,
      "loss": 0.1022,
      "step": 7873
    },
    {
      "epoch": 1.8092830882352942,
      "grad_norm": 1.6935150623321533,
      "learning_rate": 7.092013888888889e-06,
      "loss": 0.1141,
      "step": 7874
    },
    {
      "epoch": 1.8095128676470589,
      "grad_norm": 1.75843346118927,
      "learning_rate": 7.091503267973857e-06,
      "loss": 0.1137,
      "step": 7875
    },
    {
      "epoch": 1.8097426470588234,
      "grad_norm": 1.5303432941436768,
      "learning_rate": 7.090992647058824e-06,
      "loss": 0.1063,
      "step": 7876
    },
    {
      "epoch": 1.8099724264705883,
      "grad_norm": 2.294294595718384,
      "learning_rate": 7.090482026143791e-06,
      "loss": 0.111,
      "step": 7877
    },
    {
      "epoch": 1.8102022058823528,
      "grad_norm": 2.4489288330078125,
      "learning_rate": 7.089971405228758e-06,
      "loss": 0.1197,
      "step": 7878
    },
    {
      "epoch": 1.8104319852941178,
      "grad_norm": 1.6415592432022095,
      "learning_rate": 7.089460784313726e-06,
      "loss": 0.0954,
      "step": 7879
    },
    {
      "epoch": 1.8106617647058822,
      "grad_norm": 2.222156286239624,
      "learning_rate": 7.088950163398693e-06,
      "loss": 0.122,
      "step": 7880
    },
    {
      "epoch": 1.8108915441176472,
      "grad_norm": 1.6386139392852783,
      "learning_rate": 7.08843954248366e-06,
      "loss": 0.0913,
      "step": 7881
    },
    {
      "epoch": 1.8111213235294117,
      "grad_norm": 2.1905617713928223,
      "learning_rate": 7.087928921568627e-06,
      "loss": 0.1127,
      "step": 7882
    },
    {
      "epoch": 1.8113511029411766,
      "grad_norm": 1.3511731624603271,
      "learning_rate": 7.087418300653596e-06,
      "loss": 0.0965,
      "step": 7883
    },
    {
      "epoch": 1.8115808823529411,
      "grad_norm": 1.9011651277542114,
      "learning_rate": 7.086907679738563e-06,
      "loss": 0.1109,
      "step": 7884
    },
    {
      "epoch": 1.8118106617647058,
      "grad_norm": 1.6171516180038452,
      "learning_rate": 7.08639705882353e-06,
      "loss": 0.1339,
      "step": 7885
    },
    {
      "epoch": 1.8120404411764706,
      "grad_norm": 2.4683234691619873,
      "learning_rate": 7.085886437908497e-06,
      "loss": 0.1212,
      "step": 7886
    },
    {
      "epoch": 1.8122702205882353,
      "grad_norm": 1.610526204109192,
      "learning_rate": 7.085375816993465e-06,
      "loss": 0.0722,
      "step": 7887
    },
    {
      "epoch": 1.8125,
      "grad_norm": 2.2267634868621826,
      "learning_rate": 7.084865196078432e-06,
      "loss": 0.1076,
      "step": 7888
    },
    {
      "epoch": 1.8127297794117647,
      "grad_norm": 1.9929910898208618,
      "learning_rate": 7.084354575163399e-06,
      "loss": 0.1342,
      "step": 7889
    },
    {
      "epoch": 1.8129595588235294,
      "grad_norm": 1.8995596170425415,
      "learning_rate": 7.083843954248366e-06,
      "loss": 0.1589,
      "step": 7890
    },
    {
      "epoch": 1.8131893382352942,
      "grad_norm": 1.5670605897903442,
      "learning_rate": 7.083333333333335e-06,
      "loss": 0.1182,
      "step": 7891
    },
    {
      "epoch": 1.8134191176470589,
      "grad_norm": 1.4950186014175415,
      "learning_rate": 7.082822712418302e-06,
      "loss": 0.1084,
      "step": 7892
    },
    {
      "epoch": 1.8136488970588234,
      "grad_norm": 1.3358681201934814,
      "learning_rate": 7.082312091503269e-06,
      "loss": 0.0847,
      "step": 7893
    },
    {
      "epoch": 1.8138786764705883,
      "grad_norm": 1.428061604499817,
      "learning_rate": 7.081801470588236e-06,
      "loss": 0.1196,
      "step": 7894
    },
    {
      "epoch": 1.8141084558823528,
      "grad_norm": 1.6435602903366089,
      "learning_rate": 7.081290849673204e-06,
      "loss": 0.1268,
      "step": 7895
    },
    {
      "epoch": 1.8143382352941178,
      "grad_norm": 2.3703293800354004,
      "learning_rate": 7.080780228758171e-06,
      "loss": 0.116,
      "step": 7896
    },
    {
      "epoch": 1.8145680147058822,
      "grad_norm": 1.7870090007781982,
      "learning_rate": 7.080269607843138e-06,
      "loss": 0.132,
      "step": 7897
    },
    {
      "epoch": 1.8147977941176472,
      "grad_norm": 1.9049876928329468,
      "learning_rate": 7.079758986928105e-06,
      "loss": 0.1106,
      "step": 7898
    },
    {
      "epoch": 1.8150275735294117,
      "grad_norm": 2.4111433029174805,
      "learning_rate": 7.0792483660130725e-06,
      "loss": 0.1142,
      "step": 7899
    },
    {
      "epoch": 1.8152573529411766,
      "grad_norm": 2.057905435562134,
      "learning_rate": 7.0787377450980395e-06,
      "loss": 0.1375,
      "step": 7900
    },
    {
      "epoch": 1.8154871323529411,
      "grad_norm": 1.901543140411377,
      "learning_rate": 7.0782271241830065e-06,
      "loss": 0.0987,
      "step": 7901
    },
    {
      "epoch": 1.8157169117647058,
      "grad_norm": 1.8660427331924438,
      "learning_rate": 7.077716503267974e-06,
      "loss": 0.0973,
      "step": 7902
    },
    {
      "epoch": 1.8159466911764706,
      "grad_norm": 1.4034175872802734,
      "learning_rate": 7.077205882352942e-06,
      "loss": 0.0971,
      "step": 7903
    },
    {
      "epoch": 1.8161764705882353,
      "grad_norm": 1.5812567472457886,
      "learning_rate": 7.076695261437909e-06,
      "loss": 0.0915,
      "step": 7904
    },
    {
      "epoch": 1.81640625,
      "grad_norm": 2.382406711578369,
      "learning_rate": 7.076184640522876e-06,
      "loss": 0.1744,
      "step": 7905
    },
    {
      "epoch": 1.8166360294117647,
      "grad_norm": 2.4998691082000732,
      "learning_rate": 7.075674019607843e-06,
      "loss": 0.1296,
      "step": 7906
    },
    {
      "epoch": 1.8168658088235294,
      "grad_norm": 2.802473306655884,
      "learning_rate": 7.075163398692811e-06,
      "loss": 0.1091,
      "step": 7907
    },
    {
      "epoch": 1.8170955882352942,
      "grad_norm": 1.3084437847137451,
      "learning_rate": 7.074652777777778e-06,
      "loss": 0.0764,
      "step": 7908
    },
    {
      "epoch": 1.8173253676470589,
      "grad_norm": 1.7363834381103516,
      "learning_rate": 7.074142156862745e-06,
      "loss": 0.0796,
      "step": 7909
    },
    {
      "epoch": 1.8175551470588234,
      "grad_norm": 1.546188473701477,
      "learning_rate": 7.073631535947712e-06,
      "loss": 0.1012,
      "step": 7910
    },
    {
      "epoch": 1.8177849264705883,
      "grad_norm": 2.3742434978485107,
      "learning_rate": 7.073120915032681e-06,
      "loss": 0.1282,
      "step": 7911
    },
    {
      "epoch": 1.8180147058823528,
      "grad_norm": 1.9562897682189941,
      "learning_rate": 7.072610294117648e-06,
      "loss": 0.0951,
      "step": 7912
    },
    {
      "epoch": 1.8182444852941178,
      "grad_norm": 1.5692894458770752,
      "learning_rate": 7.072099673202615e-06,
      "loss": 0.1079,
      "step": 7913
    },
    {
      "epoch": 1.8184742647058822,
      "grad_norm": 1.3859102725982666,
      "learning_rate": 7.071589052287582e-06,
      "loss": 0.1127,
      "step": 7914
    },
    {
      "epoch": 1.8187040441176472,
      "grad_norm": 1.8974682092666626,
      "learning_rate": 7.07107843137255e-06,
      "loss": 0.1156,
      "step": 7915
    },
    {
      "epoch": 1.8189338235294117,
      "grad_norm": 1.9382598400115967,
      "learning_rate": 7.070567810457517e-06,
      "loss": 0.1359,
      "step": 7916
    },
    {
      "epoch": 1.8191636029411766,
      "grad_norm": 1.9131771326065063,
      "learning_rate": 7.070057189542484e-06,
      "loss": 0.0729,
      "step": 7917
    },
    {
      "epoch": 1.8193933823529411,
      "grad_norm": 2.1985974311828613,
      "learning_rate": 7.069546568627451e-06,
      "loss": 0.1212,
      "step": 7918
    },
    {
      "epoch": 1.8196231617647058,
      "grad_norm": 1.5701706409454346,
      "learning_rate": 7.0690359477124196e-06,
      "loss": 0.0748,
      "step": 7919
    },
    {
      "epoch": 1.8198529411764706,
      "grad_norm": 2.16668438911438,
      "learning_rate": 7.068525326797387e-06,
      "loss": 0.1226,
      "step": 7920
    },
    {
      "epoch": 1.8200827205882353,
      "grad_norm": 1.906512975692749,
      "learning_rate": 7.068014705882354e-06,
      "loss": 0.0902,
      "step": 7921
    },
    {
      "epoch": 1.8203125,
      "grad_norm": 2.336475133895874,
      "learning_rate": 7.067504084967321e-06,
      "loss": 0.1083,
      "step": 7922
    },
    {
      "epoch": 1.8205422794117647,
      "grad_norm": 1.3188369274139404,
      "learning_rate": 7.0669934640522885e-06,
      "loss": 0.1003,
      "step": 7923
    },
    {
      "epoch": 1.8207720588235294,
      "grad_norm": 1.41292142868042,
      "learning_rate": 7.0664828431372555e-06,
      "loss": 0.1462,
      "step": 7924
    },
    {
      "epoch": 1.8210018382352942,
      "grad_norm": 1.5648462772369385,
      "learning_rate": 7.0659722222222225e-06,
      "loss": 0.0842,
      "step": 7925
    },
    {
      "epoch": 1.8212316176470589,
      "grad_norm": 1.6097257137298584,
      "learning_rate": 7.0654616013071895e-06,
      "loss": 0.1082,
      "step": 7926
    },
    {
      "epoch": 1.8214613970588234,
      "grad_norm": 1.8647007942199707,
      "learning_rate": 7.064950980392158e-06,
      "loss": 0.1359,
      "step": 7927
    },
    {
      "epoch": 1.8216911764705883,
      "grad_norm": 1.5732097625732422,
      "learning_rate": 7.064440359477125e-06,
      "loss": 0.0702,
      "step": 7928
    },
    {
      "epoch": 1.8219209558823528,
      "grad_norm": 2.38228702545166,
      "learning_rate": 7.063929738562092e-06,
      "loss": 0.1281,
      "step": 7929
    },
    {
      "epoch": 1.8221507352941178,
      "grad_norm": 2.100628137588501,
      "learning_rate": 7.063419117647059e-06,
      "loss": 0.0983,
      "step": 7930
    },
    {
      "epoch": 1.8223805147058822,
      "grad_norm": 2.0084378719329834,
      "learning_rate": 7.062908496732027e-06,
      "loss": 0.0976,
      "step": 7931
    },
    {
      "epoch": 1.8226102941176472,
      "grad_norm": 1.500932216644287,
      "learning_rate": 7.062397875816994e-06,
      "loss": 0.0972,
      "step": 7932
    },
    {
      "epoch": 1.8228400735294117,
      "grad_norm": 1.8551349639892578,
      "learning_rate": 7.061887254901961e-06,
      "loss": 0.1234,
      "step": 7933
    },
    {
      "epoch": 1.8230698529411766,
      "grad_norm": 1.5031471252441406,
      "learning_rate": 7.061376633986928e-06,
      "loss": 0.1013,
      "step": 7934
    },
    {
      "epoch": 1.8232996323529411,
      "grad_norm": 1.437095284461975,
      "learning_rate": 7.060866013071896e-06,
      "loss": 0.1205,
      "step": 7935
    },
    {
      "epoch": 1.8235294117647058,
      "grad_norm": 1.905693769454956,
      "learning_rate": 7.060355392156864e-06,
      "loss": 0.1429,
      "step": 7936
    },
    {
      "epoch": 1.8237591911764706,
      "grad_norm": 2.1451969146728516,
      "learning_rate": 7.059844771241831e-06,
      "loss": 0.1154,
      "step": 7937
    },
    {
      "epoch": 1.8239889705882353,
      "grad_norm": 2.1838021278381348,
      "learning_rate": 7.059334150326798e-06,
      "loss": 0.1232,
      "step": 7938
    },
    {
      "epoch": 1.82421875,
      "grad_norm": 1.977588176727295,
      "learning_rate": 7.058823529411766e-06,
      "loss": 0.0919,
      "step": 7939
    },
    {
      "epoch": 1.8244485294117647,
      "grad_norm": 2.057976007461548,
      "learning_rate": 7.058312908496733e-06,
      "loss": 0.1217,
      "step": 7940
    },
    {
      "epoch": 1.8246783088235294,
      "grad_norm": 1.8334230184555054,
      "learning_rate": 7.0578022875817e-06,
      "loss": 0.1226,
      "step": 7941
    },
    {
      "epoch": 1.8249080882352942,
      "grad_norm": 1.6118799448013306,
      "learning_rate": 7.057291666666667e-06,
      "loss": 0.1073,
      "step": 7942
    },
    {
      "epoch": 1.8251378676470589,
      "grad_norm": 1.6360286474227905,
      "learning_rate": 7.056781045751635e-06,
      "loss": 0.1045,
      "step": 7943
    },
    {
      "epoch": 1.8253676470588234,
      "grad_norm": 2.0219666957855225,
      "learning_rate": 7.056270424836602e-06,
      "loss": 0.1315,
      "step": 7944
    },
    {
      "epoch": 1.8255974264705883,
      "grad_norm": 1.4752706289291382,
      "learning_rate": 7.055759803921569e-06,
      "loss": 0.0994,
      "step": 7945
    },
    {
      "epoch": 1.8258272058823528,
      "grad_norm": 1.8763314485549927,
      "learning_rate": 7.055249183006537e-06,
      "loss": 0.1306,
      "step": 7946
    },
    {
      "epoch": 1.8260569852941178,
      "grad_norm": 2.558399200439453,
      "learning_rate": 7.0547385620915044e-06,
      "loss": 0.1157,
      "step": 7947
    },
    {
      "epoch": 1.8262867647058822,
      "grad_norm": 1.5873643159866333,
      "learning_rate": 7.0542279411764715e-06,
      "loss": 0.1266,
      "step": 7948
    },
    {
      "epoch": 1.8265165441176472,
      "grad_norm": 1.4282946586608887,
      "learning_rate": 7.0537173202614385e-06,
      "loss": 0.095,
      "step": 7949
    },
    {
      "epoch": 1.8267463235294117,
      "grad_norm": 1.268573522567749,
      "learning_rate": 7.0532066993464055e-06,
      "loss": 0.0953,
      "step": 7950
    },
    {
      "epoch": 1.8269761029411766,
      "grad_norm": 1.256270170211792,
      "learning_rate": 7.052696078431373e-06,
      "loss": 0.082,
      "step": 7951
    },
    {
      "epoch": 1.8272058823529411,
      "grad_norm": 1.465535044670105,
      "learning_rate": 7.05218545751634e-06,
      "loss": 0.0784,
      "step": 7952
    },
    {
      "epoch": 1.8274356617647058,
      "grad_norm": 1.872928500175476,
      "learning_rate": 7.051674836601307e-06,
      "loss": 0.1146,
      "step": 7953
    },
    {
      "epoch": 1.8276654411764706,
      "grad_norm": 1.503401756286621,
      "learning_rate": 7.051164215686274e-06,
      "loss": 0.1131,
      "step": 7954
    },
    {
      "epoch": 1.8278952205882353,
      "grad_norm": 1.6364926099777222,
      "learning_rate": 7.050653594771243e-06,
      "loss": 0.1241,
      "step": 7955
    },
    {
      "epoch": 1.828125,
      "grad_norm": 1.4635560512542725,
      "learning_rate": 7.05014297385621e-06,
      "loss": 0.1198,
      "step": 7956
    },
    {
      "epoch": 1.8283547794117647,
      "grad_norm": 1.2377979755401611,
      "learning_rate": 7.049632352941177e-06,
      "loss": 0.0903,
      "step": 7957
    },
    {
      "epoch": 1.8285845588235294,
      "grad_norm": 1.6754724979400635,
      "learning_rate": 7.049121732026144e-06,
      "loss": 0.0823,
      "step": 7958
    },
    {
      "epoch": 1.8288143382352942,
      "grad_norm": 1.571244478225708,
      "learning_rate": 7.048611111111112e-06,
      "loss": 0.1211,
      "step": 7959
    },
    {
      "epoch": 1.8290441176470589,
      "grad_norm": 1.4863669872283936,
      "learning_rate": 7.048100490196079e-06,
      "loss": 0.1074,
      "step": 7960
    },
    {
      "epoch": 1.8292738970588234,
      "grad_norm": 1.6223403215408325,
      "learning_rate": 7.047589869281046e-06,
      "loss": 0.1449,
      "step": 7961
    },
    {
      "epoch": 1.8295036764705883,
      "grad_norm": 2.126343011856079,
      "learning_rate": 7.047079248366013e-06,
      "loss": 0.1128,
      "step": 7962
    },
    {
      "epoch": 1.8297334558823528,
      "grad_norm": 1.393897533416748,
      "learning_rate": 7.046568627450982e-06,
      "loss": 0.0981,
      "step": 7963
    },
    {
      "epoch": 1.8299632352941178,
      "grad_norm": 1.7643522024154663,
      "learning_rate": 7.046058006535949e-06,
      "loss": 0.1054,
      "step": 7964
    },
    {
      "epoch": 1.8301930147058822,
      "grad_norm": 1.282321572303772,
      "learning_rate": 7.045547385620916e-06,
      "loss": 0.0634,
      "step": 7965
    },
    {
      "epoch": 1.8304227941176472,
      "grad_norm": 1.7214953899383545,
      "learning_rate": 7.045036764705883e-06,
      "loss": 0.1048,
      "step": 7966
    },
    {
      "epoch": 1.8306525735294117,
      "grad_norm": 1.730359673500061,
      "learning_rate": 7.044526143790851e-06,
      "loss": 0.0798,
      "step": 7967
    },
    {
      "epoch": 1.8308823529411766,
      "grad_norm": 1.981176495552063,
      "learning_rate": 7.044015522875818e-06,
      "loss": 0.1169,
      "step": 7968
    },
    {
      "epoch": 1.8311121323529411,
      "grad_norm": 2.00699782371521,
      "learning_rate": 7.043504901960785e-06,
      "loss": 0.1274,
      "step": 7969
    },
    {
      "epoch": 1.8313419117647058,
      "grad_norm": 2.4535326957702637,
      "learning_rate": 7.042994281045752e-06,
      "loss": 0.135,
      "step": 7970
    },
    {
      "epoch": 1.8315716911764706,
      "grad_norm": 1.6979697942733765,
      "learning_rate": 7.04248366013072e-06,
      "loss": 0.1319,
      "step": 7971
    },
    {
      "epoch": 1.8318014705882353,
      "grad_norm": 1.522241234779358,
      "learning_rate": 7.041973039215687e-06,
      "loss": 0.1004,
      "step": 7972
    },
    {
      "epoch": 1.83203125,
      "grad_norm": 2.0737714767456055,
      "learning_rate": 7.0414624183006544e-06,
      "loss": 0.1146,
      "step": 7973
    },
    {
      "epoch": 1.8322610294117647,
      "grad_norm": 1.602220058441162,
      "learning_rate": 7.0409517973856215e-06,
      "loss": 0.1189,
      "step": 7974
    },
    {
      "epoch": 1.8324908088235294,
      "grad_norm": 1.773037314414978,
      "learning_rate": 7.040441176470589e-06,
      "loss": 0.0834,
      "step": 7975
    },
    {
      "epoch": 1.8327205882352942,
      "grad_norm": 1.7203278541564941,
      "learning_rate": 7.039930555555556e-06,
      "loss": 0.1007,
      "step": 7976
    },
    {
      "epoch": 1.8329503676470589,
      "grad_norm": 2.222487449645996,
      "learning_rate": 7.039419934640523e-06,
      "loss": 0.1279,
      "step": 7977
    },
    {
      "epoch": 1.8331801470588234,
      "grad_norm": 1.9810450077056885,
      "learning_rate": 7.03890931372549e-06,
      "loss": 0.1096,
      "step": 7978
    },
    {
      "epoch": 1.8334099264705883,
      "grad_norm": 1.7023491859436035,
      "learning_rate": 7.038398692810458e-06,
      "loss": 0.1048,
      "step": 7979
    },
    {
      "epoch": 1.8336397058823528,
      "grad_norm": 1.5136423110961914,
      "learning_rate": 7.037888071895426e-06,
      "loss": 0.0997,
      "step": 7980
    },
    {
      "epoch": 1.8338694852941178,
      "grad_norm": 2.076801300048828,
      "learning_rate": 7.037377450980393e-06,
      "loss": 0.1219,
      "step": 7981
    },
    {
      "epoch": 1.8340992647058822,
      "grad_norm": 1.2152135372161865,
      "learning_rate": 7.03686683006536e-06,
      "loss": 0.0879,
      "step": 7982
    },
    {
      "epoch": 1.8343290441176472,
      "grad_norm": 1.7658562660217285,
      "learning_rate": 7.036356209150328e-06,
      "loss": 0.1149,
      "step": 7983
    },
    {
      "epoch": 1.8345588235294117,
      "grad_norm": 1.6362965106964111,
      "learning_rate": 7.035845588235295e-06,
      "loss": 0.0809,
      "step": 7984
    },
    {
      "epoch": 1.8347886029411766,
      "grad_norm": 1.6658499240875244,
      "learning_rate": 7.035334967320262e-06,
      "loss": 0.1104,
      "step": 7985
    },
    {
      "epoch": 1.8350183823529411,
      "grad_norm": 1.9670851230621338,
      "learning_rate": 7.034824346405229e-06,
      "loss": 0.1283,
      "step": 7986
    },
    {
      "epoch": 1.8352481617647058,
      "grad_norm": 1.448668122291565,
      "learning_rate": 7.034313725490197e-06,
      "loss": 0.0867,
      "step": 7987
    },
    {
      "epoch": 1.8354779411764706,
      "grad_norm": 1.2085903882980347,
      "learning_rate": 7.033803104575164e-06,
      "loss": 0.0864,
      "step": 7988
    },
    {
      "epoch": 1.8357077205882353,
      "grad_norm": 1.2751998901367188,
      "learning_rate": 7.033292483660131e-06,
      "loss": 0.0856,
      "step": 7989
    },
    {
      "epoch": 1.8359375,
      "grad_norm": 1.7279082536697388,
      "learning_rate": 7.032781862745098e-06,
      "loss": 0.13,
      "step": 7990
    },
    {
      "epoch": 1.8361672794117647,
      "grad_norm": 1.5428087711334229,
      "learning_rate": 7.032271241830067e-06,
      "loss": 0.1254,
      "step": 7991
    },
    {
      "epoch": 1.8363970588235294,
      "grad_norm": 1.6401746273040771,
      "learning_rate": 7.031760620915034e-06,
      "loss": 0.1104,
      "step": 7992
    },
    {
      "epoch": 1.8366268382352942,
      "grad_norm": 1.3637101650238037,
      "learning_rate": 7.031250000000001e-06,
      "loss": 0.0835,
      "step": 7993
    },
    {
      "epoch": 1.8368566176470589,
      "grad_norm": 2.296119213104248,
      "learning_rate": 7.030739379084968e-06,
      "loss": 0.1396,
      "step": 7994
    },
    {
      "epoch": 1.8370863970588234,
      "grad_norm": 2.122473955154419,
      "learning_rate": 7.030228758169935e-06,
      "loss": 0.1392,
      "step": 7995
    },
    {
      "epoch": 1.8373161764705883,
      "grad_norm": 1.6535779237747192,
      "learning_rate": 7.0297181372549025e-06,
      "loss": 0.121,
      "step": 7996
    },
    {
      "epoch": 1.8375459558823528,
      "grad_norm": 1.9550455808639526,
      "learning_rate": 7.0292075163398696e-06,
      "loss": 0.1034,
      "step": 7997
    },
    {
      "epoch": 1.8377757352941178,
      "grad_norm": 1.6799582242965698,
      "learning_rate": 7.0286968954248366e-06,
      "loss": 0.1069,
      "step": 7998
    },
    {
      "epoch": 1.8380055147058822,
      "grad_norm": 1.3237158060073853,
      "learning_rate": 7.028186274509804e-06,
      "loss": 0.1114,
      "step": 7999
    },
    {
      "epoch": 1.8382352941176472,
      "grad_norm": 1.354085922241211,
      "learning_rate": 7.027675653594772e-06,
      "loss": 0.1022,
      "step": 8000
    },
    {
      "epoch": 1.8382352941176472,
      "eval_loss": 0.11095448583364487,
      "eval_runtime": 420.5271,
      "eval_samples_per_second": 21.178,
      "eval_steps_per_second": 10.589,
      "step": 8000
    },
    {
      "epoch": 1.8384650735294117,
      "grad_norm": 1.858580470085144,
      "learning_rate": 7.027165032679739e-06,
      "loss": 0.1251,
      "step": 8001
    },
    {
      "epoch": 1.8386948529411766,
      "grad_norm": 1.6266885995864868,
      "learning_rate": 7.026654411764706e-06,
      "loss": 0.1215,
      "step": 8002
    },
    {
      "epoch": 1.8389246323529411,
      "grad_norm": 1.388193130493164,
      "learning_rate": 7.026143790849673e-06,
      "loss": 0.0925,
      "step": 8003
    },
    {
      "epoch": 1.8391544117647058,
      "grad_norm": 1.9322460889816284,
      "learning_rate": 7.025633169934641e-06,
      "loss": 0.1186,
      "step": 8004
    },
    {
      "epoch": 1.8393841911764706,
      "grad_norm": 1.699000358581543,
      "learning_rate": 7.025122549019608e-06,
      "loss": 0.116,
      "step": 8005
    },
    {
      "epoch": 1.8396139705882353,
      "grad_norm": 1.769388198852539,
      "learning_rate": 7.024611928104575e-06,
      "loss": 0.1188,
      "step": 8006
    },
    {
      "epoch": 1.83984375,
      "grad_norm": 1.629130482673645,
      "learning_rate": 7.024101307189542e-06,
      "loss": 0.0957,
      "step": 8007
    },
    {
      "epoch": 1.8400735294117647,
      "grad_norm": 1.3170850276947021,
      "learning_rate": 7.023590686274511e-06,
      "loss": 0.0876,
      "step": 8008
    },
    {
      "epoch": 1.8403033088235294,
      "grad_norm": 2.2551112174987793,
      "learning_rate": 7.023080065359478e-06,
      "loss": 0.1242,
      "step": 8009
    },
    {
      "epoch": 1.8405330882352942,
      "grad_norm": 1.4826103448867798,
      "learning_rate": 7.022569444444445e-06,
      "loss": 0.1002,
      "step": 8010
    },
    {
      "epoch": 1.8407628676470589,
      "grad_norm": 1.7592960596084595,
      "learning_rate": 7.022058823529412e-06,
      "loss": 0.1191,
      "step": 8011
    },
    {
      "epoch": 1.8409926470588234,
      "grad_norm": 1.6097874641418457,
      "learning_rate": 7.02154820261438e-06,
      "loss": 0.0967,
      "step": 8012
    },
    {
      "epoch": 1.8412224264705883,
      "grad_norm": 1.502667784690857,
      "learning_rate": 7.021037581699347e-06,
      "loss": 0.1105,
      "step": 8013
    },
    {
      "epoch": 1.8414522058823528,
      "grad_norm": 1.5890486240386963,
      "learning_rate": 7.020526960784314e-06,
      "loss": 0.1071,
      "step": 8014
    },
    {
      "epoch": 1.8416819852941178,
      "grad_norm": 2.117608070373535,
      "learning_rate": 7.020016339869281e-06,
      "loss": 0.1031,
      "step": 8015
    },
    {
      "epoch": 1.8419117647058822,
      "grad_norm": 1.7815139293670654,
      "learning_rate": 7.01950571895425e-06,
      "loss": 0.1673,
      "step": 8016
    },
    {
      "epoch": 1.8421415441176472,
      "grad_norm": 1.7296431064605713,
      "learning_rate": 7.018995098039217e-06,
      "loss": 0.1303,
      "step": 8017
    },
    {
      "epoch": 1.8423713235294117,
      "grad_norm": 1.7457870244979858,
      "learning_rate": 7.018484477124184e-06,
      "loss": 0.1394,
      "step": 8018
    },
    {
      "epoch": 1.8426011029411766,
      "grad_norm": 1.3619308471679688,
      "learning_rate": 7.017973856209151e-06,
      "loss": 0.1191,
      "step": 8019
    },
    {
      "epoch": 1.8428308823529411,
      "grad_norm": 1.9152249097824097,
      "learning_rate": 7.0174632352941185e-06,
      "loss": 0.0787,
      "step": 8020
    },
    {
      "epoch": 1.8430606617647058,
      "grad_norm": 1.7144328355789185,
      "learning_rate": 7.0169526143790855e-06,
      "loss": 0.1042,
      "step": 8021
    },
    {
      "epoch": 1.8432904411764706,
      "grad_norm": 2.1134285926818848,
      "learning_rate": 7.0164419934640525e-06,
      "loss": 0.1335,
      "step": 8022
    },
    {
      "epoch": 1.8435202205882353,
      "grad_norm": 1.5862927436828613,
      "learning_rate": 7.0159313725490196e-06,
      "loss": 0.0861,
      "step": 8023
    },
    {
      "epoch": 1.84375,
      "grad_norm": 1.5543677806854248,
      "learning_rate": 7.015420751633987e-06,
      "loss": 0.1028,
      "step": 8024
    },
    {
      "epoch": 1.8439797794117647,
      "grad_norm": 1.5256538391113281,
      "learning_rate": 7.014910130718955e-06,
      "loss": 0.1052,
      "step": 8025
    },
    {
      "epoch": 1.8442095588235294,
      "grad_norm": 1.5911378860473633,
      "learning_rate": 7.014399509803922e-06,
      "loss": 0.1088,
      "step": 8026
    },
    {
      "epoch": 1.8444393382352942,
      "grad_norm": 1.8907830715179443,
      "learning_rate": 7.013888888888889e-06,
      "loss": 0.1109,
      "step": 8027
    },
    {
      "epoch": 1.8446691176470589,
      "grad_norm": 1.6523349285125732,
      "learning_rate": 7.013378267973857e-06,
      "loss": 0.1128,
      "step": 8028
    },
    {
      "epoch": 1.8448988970588234,
      "grad_norm": 1.9816067218780518,
      "learning_rate": 7.012867647058824e-06,
      "loss": 0.1184,
      "step": 8029
    },
    {
      "epoch": 1.8451286764705883,
      "grad_norm": 1.8298888206481934,
      "learning_rate": 7.012357026143791e-06,
      "loss": 0.1142,
      "step": 8030
    },
    {
      "epoch": 1.8453584558823528,
      "grad_norm": 1.7574700117111206,
      "learning_rate": 7.011846405228758e-06,
      "loss": 0.1298,
      "step": 8031
    },
    {
      "epoch": 1.8455882352941178,
      "grad_norm": 1.582995057106018,
      "learning_rate": 7.011335784313726e-06,
      "loss": 0.0907,
      "step": 8032
    },
    {
      "epoch": 1.8458180147058822,
      "grad_norm": 1.7109662294387817,
      "learning_rate": 7.010825163398693e-06,
      "loss": 0.1531,
      "step": 8033
    },
    {
      "epoch": 1.8460477941176472,
      "grad_norm": 1.450806736946106,
      "learning_rate": 7.01031454248366e-06,
      "loss": 0.1003,
      "step": 8034
    },
    {
      "epoch": 1.8462775735294117,
      "grad_norm": 1.3009490966796875,
      "learning_rate": 7.009803921568628e-06,
      "loss": 0.0852,
      "step": 8035
    },
    {
      "epoch": 1.8465073529411766,
      "grad_norm": 1.251460313796997,
      "learning_rate": 7.009293300653596e-06,
      "loss": 0.0938,
      "step": 8036
    },
    {
      "epoch": 1.8467371323529411,
      "grad_norm": 1.3696422576904297,
      "learning_rate": 7.008782679738563e-06,
      "loss": 0.093,
      "step": 8037
    },
    {
      "epoch": 1.8469669117647058,
      "grad_norm": 2.033712863922119,
      "learning_rate": 7.00827205882353e-06,
      "loss": 0.1304,
      "step": 8038
    },
    {
      "epoch": 1.8471966911764706,
      "grad_norm": 1.7941430807113647,
      "learning_rate": 7.007761437908497e-06,
      "loss": 0.0879,
      "step": 8039
    },
    {
      "epoch": 1.8474264705882353,
      "grad_norm": 1.7106853723526,
      "learning_rate": 7.007250816993465e-06,
      "loss": 0.0999,
      "step": 8040
    },
    {
      "epoch": 1.84765625,
      "grad_norm": 1.7857547998428345,
      "learning_rate": 7.006740196078432e-06,
      "loss": 0.1141,
      "step": 8041
    },
    {
      "epoch": 1.8478860294117647,
      "grad_norm": 1.6581884622573853,
      "learning_rate": 7.006229575163399e-06,
      "loss": 0.092,
      "step": 8042
    },
    {
      "epoch": 1.8481158088235294,
      "grad_norm": 1.8844609260559082,
      "learning_rate": 7.005718954248366e-06,
      "loss": 0.1012,
      "step": 8043
    },
    {
      "epoch": 1.8483455882352942,
      "grad_norm": 1.994820237159729,
      "learning_rate": 7.0052083333333345e-06,
      "loss": 0.151,
      "step": 8044
    },
    {
      "epoch": 1.8485753676470589,
      "grad_norm": 1.795835018157959,
      "learning_rate": 7.0046977124183015e-06,
      "loss": 0.1347,
      "step": 8045
    },
    {
      "epoch": 1.8488051470588234,
      "grad_norm": 1.5227094888687134,
      "learning_rate": 7.0041870915032685e-06,
      "loss": 0.1108,
      "step": 8046
    },
    {
      "epoch": 1.8490349264705883,
      "grad_norm": 1.829172968864441,
      "learning_rate": 7.0036764705882355e-06,
      "loss": 0.1613,
      "step": 8047
    },
    {
      "epoch": 1.8492647058823528,
      "grad_norm": 1.7765077352523804,
      "learning_rate": 7.003165849673203e-06,
      "loss": 0.1401,
      "step": 8048
    },
    {
      "epoch": 1.8494944852941178,
      "grad_norm": 1.6482573747634888,
      "learning_rate": 7.00265522875817e-06,
      "loss": 0.1074,
      "step": 8049
    },
    {
      "epoch": 1.8497242647058822,
      "grad_norm": 1.5166360139846802,
      "learning_rate": 7.002144607843137e-06,
      "loss": 0.0965,
      "step": 8050
    },
    {
      "epoch": 1.8499540441176472,
      "grad_norm": 1.9801279306411743,
      "learning_rate": 7.0016339869281044e-06,
      "loss": 0.1137,
      "step": 8051
    },
    {
      "epoch": 1.8501838235294117,
      "grad_norm": 1.3749843835830688,
      "learning_rate": 7.001123366013073e-06,
      "loss": 0.0895,
      "step": 8052
    },
    {
      "epoch": 1.8504136029411766,
      "grad_norm": 1.6436553001403809,
      "learning_rate": 7.00061274509804e-06,
      "loss": 0.079,
      "step": 8053
    },
    {
      "epoch": 1.8506433823529411,
      "grad_norm": 1.6523958444595337,
      "learning_rate": 7.000102124183007e-06,
      "loss": 0.0943,
      "step": 8054
    },
    {
      "epoch": 1.8508731617647058,
      "grad_norm": 1.4333763122558594,
      "learning_rate": 6.999591503267974e-06,
      "loss": 0.0978,
      "step": 8055
    },
    {
      "epoch": 1.8511029411764706,
      "grad_norm": 1.4555492401123047,
      "learning_rate": 6.999080882352942e-06,
      "loss": 0.0979,
      "step": 8056
    },
    {
      "epoch": 1.8513327205882353,
      "grad_norm": 2.077214241027832,
      "learning_rate": 6.998570261437909e-06,
      "loss": 0.1289,
      "step": 8057
    },
    {
      "epoch": 1.8515625,
      "grad_norm": 1.3882412910461426,
      "learning_rate": 6.998059640522876e-06,
      "loss": 0.1248,
      "step": 8058
    },
    {
      "epoch": 1.8517922794117647,
      "grad_norm": 1.5556515455245972,
      "learning_rate": 6.997549019607843e-06,
      "loss": 0.0999,
      "step": 8059
    },
    {
      "epoch": 1.8520220588235294,
      "grad_norm": 1.4392517805099487,
      "learning_rate": 6.997038398692812e-06,
      "loss": 0.1045,
      "step": 8060
    },
    {
      "epoch": 1.8522518382352942,
      "grad_norm": 1.7894145250320435,
      "learning_rate": 6.996527777777779e-06,
      "loss": 0.1113,
      "step": 8061
    },
    {
      "epoch": 1.8524816176470589,
      "grad_norm": 1.4561280012130737,
      "learning_rate": 6.996017156862746e-06,
      "loss": 0.1107,
      "step": 8062
    },
    {
      "epoch": 1.8527113970588234,
      "grad_norm": 1.8781894445419312,
      "learning_rate": 6.995506535947713e-06,
      "loss": 0.1495,
      "step": 8063
    },
    {
      "epoch": 1.8529411764705883,
      "grad_norm": 1.423741102218628,
      "learning_rate": 6.994995915032681e-06,
      "loss": 0.0922,
      "step": 8064
    },
    {
      "epoch": 1.8531709558823528,
      "grad_norm": 2.171766519546509,
      "learning_rate": 6.994485294117648e-06,
      "loss": 0.1296,
      "step": 8065
    },
    {
      "epoch": 1.8534007352941178,
      "grad_norm": 1.434917688369751,
      "learning_rate": 6.993974673202615e-06,
      "loss": 0.0895,
      "step": 8066
    },
    {
      "epoch": 1.8536305147058822,
      "grad_norm": 1.6090189218521118,
      "learning_rate": 6.993464052287582e-06,
      "loss": 0.1335,
      "step": 8067
    },
    {
      "epoch": 1.8538602941176472,
      "grad_norm": 1.3315638303756714,
      "learning_rate": 6.99295343137255e-06,
      "loss": 0.0766,
      "step": 8068
    },
    {
      "epoch": 1.8540900735294117,
      "grad_norm": 1.4925203323364258,
      "learning_rate": 6.9924428104575175e-06,
      "loss": 0.0968,
      "step": 8069
    },
    {
      "epoch": 1.8543198529411766,
      "grad_norm": 1.8173413276672363,
      "learning_rate": 6.9919321895424845e-06,
      "loss": 0.1147,
      "step": 8070
    },
    {
      "epoch": 1.8545496323529411,
      "grad_norm": 1.9029338359832764,
      "learning_rate": 6.9914215686274515e-06,
      "loss": 0.1151,
      "step": 8071
    },
    {
      "epoch": 1.8547794117647058,
      "grad_norm": 1.7546967267990112,
      "learning_rate": 6.990910947712419e-06,
      "loss": 0.1171,
      "step": 8072
    },
    {
      "epoch": 1.8550091911764706,
      "grad_norm": 1.6416934728622437,
      "learning_rate": 6.990400326797386e-06,
      "loss": 0.0859,
      "step": 8073
    },
    {
      "epoch": 1.8552389705882353,
      "grad_norm": 2.149709463119507,
      "learning_rate": 6.989889705882353e-06,
      "loss": 0.1332,
      "step": 8074
    },
    {
      "epoch": 1.85546875,
      "grad_norm": 1.3293524980545044,
      "learning_rate": 6.98937908496732e-06,
      "loss": 0.0984,
      "step": 8075
    },
    {
      "epoch": 1.8556985294117647,
      "grad_norm": 2.3806943893432617,
      "learning_rate": 6.988868464052288e-06,
      "loss": 0.1875,
      "step": 8076
    },
    {
      "epoch": 1.8559283088235294,
      "grad_norm": 1.819447636604309,
      "learning_rate": 6.988357843137255e-06,
      "loss": 0.1279,
      "step": 8077
    },
    {
      "epoch": 1.8561580882352942,
      "grad_norm": 1.2735795974731445,
      "learning_rate": 6.987847222222222e-06,
      "loss": 0.0839,
      "step": 8078
    },
    {
      "epoch": 1.8563878676470589,
      "grad_norm": 2.26694917678833,
      "learning_rate": 6.987336601307189e-06,
      "loss": 0.1244,
      "step": 8079
    },
    {
      "epoch": 1.8566176470588234,
      "grad_norm": 1.6545782089233398,
      "learning_rate": 6.986825980392158e-06,
      "loss": 0.1326,
      "step": 8080
    },
    {
      "epoch": 1.8568474264705883,
      "grad_norm": 2.2604269981384277,
      "learning_rate": 6.986315359477125e-06,
      "loss": 0.1414,
      "step": 8081
    },
    {
      "epoch": 1.8570772058823528,
      "grad_norm": 1.7592871189117432,
      "learning_rate": 6.985804738562092e-06,
      "loss": 0.0957,
      "step": 8082
    },
    {
      "epoch": 1.8573069852941178,
      "grad_norm": 1.4255293607711792,
      "learning_rate": 6.985294117647059e-06,
      "loss": 0.092,
      "step": 8083
    },
    {
      "epoch": 1.8575367647058822,
      "grad_norm": 1.3769736289978027,
      "learning_rate": 6.984783496732027e-06,
      "loss": 0.08,
      "step": 8084
    },
    {
      "epoch": 1.8577665441176472,
      "grad_norm": 1.456068992614746,
      "learning_rate": 6.984272875816994e-06,
      "loss": 0.0735,
      "step": 8085
    },
    {
      "epoch": 1.8579963235294117,
      "grad_norm": 1.5508315563201904,
      "learning_rate": 6.983762254901961e-06,
      "loss": 0.1243,
      "step": 8086
    },
    {
      "epoch": 1.8582261029411766,
      "grad_norm": 1.225846767425537,
      "learning_rate": 6.983251633986928e-06,
      "loss": 0.0861,
      "step": 8087
    },
    {
      "epoch": 1.8584558823529411,
      "grad_norm": 1.568795919418335,
      "learning_rate": 6.982741013071897e-06,
      "loss": 0.1333,
      "step": 8088
    },
    {
      "epoch": 1.8586856617647058,
      "grad_norm": 2.400279998779297,
      "learning_rate": 6.982230392156864e-06,
      "loss": 0.1424,
      "step": 8089
    },
    {
      "epoch": 1.8589154411764706,
      "grad_norm": 1.678351879119873,
      "learning_rate": 6.981719771241831e-06,
      "loss": 0.0972,
      "step": 8090
    },
    {
      "epoch": 1.8591452205882353,
      "grad_norm": 1.8641579151153564,
      "learning_rate": 6.981209150326798e-06,
      "loss": 0.1285,
      "step": 8091
    },
    {
      "epoch": 1.859375,
      "grad_norm": 1.7504360675811768,
      "learning_rate": 6.980698529411766e-06,
      "loss": 0.1308,
      "step": 8092
    },
    {
      "epoch": 1.8596047794117647,
      "grad_norm": 1.6168497800827026,
      "learning_rate": 6.980187908496733e-06,
      "loss": 0.0992,
      "step": 8093
    },
    {
      "epoch": 1.8598345588235294,
      "grad_norm": 2.3020846843719482,
      "learning_rate": 6.9796772875817e-06,
      "loss": 0.1159,
      "step": 8094
    },
    {
      "epoch": 1.8600643382352942,
      "grad_norm": 1.767101526260376,
      "learning_rate": 6.979166666666667e-06,
      "loss": 0.1087,
      "step": 8095
    },
    {
      "epoch": 1.8602941176470589,
      "grad_norm": 1.3848387002944946,
      "learning_rate": 6.978656045751635e-06,
      "loss": 0.0932,
      "step": 8096
    },
    {
      "epoch": 1.8605238970588234,
      "grad_norm": 2.1589138507843018,
      "learning_rate": 6.978145424836602e-06,
      "loss": 0.1163,
      "step": 8097
    },
    {
      "epoch": 1.8607536764705883,
      "grad_norm": 1.6768765449523926,
      "learning_rate": 6.977634803921569e-06,
      "loss": 0.1094,
      "step": 8098
    },
    {
      "epoch": 1.8609834558823528,
      "grad_norm": 1.7746634483337402,
      "learning_rate": 6.977124183006536e-06,
      "loss": 0.0962,
      "step": 8099
    },
    {
      "epoch": 1.8612132352941178,
      "grad_norm": 1.952728271484375,
      "learning_rate": 6.976613562091504e-06,
      "loss": 0.1138,
      "step": 8100
    },
    {
      "epoch": 1.8614430147058822,
      "grad_norm": 2.158360242843628,
      "learning_rate": 6.976102941176471e-06,
      "loss": 0.1126,
      "step": 8101
    },
    {
      "epoch": 1.8616727941176472,
      "grad_norm": 1.3698890209197998,
      "learning_rate": 6.975592320261438e-06,
      "loss": 0.1066,
      "step": 8102
    },
    {
      "epoch": 1.8619025735294117,
      "grad_norm": 1.4787530899047852,
      "learning_rate": 6.975081699346405e-06,
      "loss": 0.0854,
      "step": 8103
    },
    {
      "epoch": 1.8621323529411766,
      "grad_norm": 1.6592555046081543,
      "learning_rate": 6.974571078431374e-06,
      "loss": 0.0942,
      "step": 8104
    },
    {
      "epoch": 1.8623621323529411,
      "grad_norm": 1.7096073627471924,
      "learning_rate": 6.974060457516341e-06,
      "loss": 0.1186,
      "step": 8105
    },
    {
      "epoch": 1.8625919117647058,
      "grad_norm": 1.7132197618484497,
      "learning_rate": 6.973549836601308e-06,
      "loss": 0.1112,
      "step": 8106
    },
    {
      "epoch": 1.8628216911764706,
      "grad_norm": 1.5357528924942017,
      "learning_rate": 6.973039215686275e-06,
      "loss": 0.118,
      "step": 8107
    },
    {
      "epoch": 1.8630514705882353,
      "grad_norm": 1.7041864395141602,
      "learning_rate": 6.972528594771243e-06,
      "loss": 0.1032,
      "step": 8108
    },
    {
      "epoch": 1.86328125,
      "grad_norm": 1.63944673538208,
      "learning_rate": 6.97201797385621e-06,
      "loss": 0.0906,
      "step": 8109
    },
    {
      "epoch": 1.8635110294117647,
      "grad_norm": 1.9007337093353271,
      "learning_rate": 6.971507352941177e-06,
      "loss": 0.11,
      "step": 8110
    },
    {
      "epoch": 1.8637408088235294,
      "grad_norm": 1.9336354732513428,
      "learning_rate": 6.970996732026144e-06,
      "loss": 0.0893,
      "step": 8111
    },
    {
      "epoch": 1.8639705882352942,
      "grad_norm": 2.001532793045044,
      "learning_rate": 6.970486111111112e-06,
      "loss": 0.109,
      "step": 8112
    },
    {
      "epoch": 1.8642003676470589,
      "grad_norm": 2.4467861652374268,
      "learning_rate": 6.969975490196079e-06,
      "loss": 0.1565,
      "step": 8113
    },
    {
      "epoch": 1.8644301470588234,
      "grad_norm": 1.9989380836486816,
      "learning_rate": 6.969464869281047e-06,
      "loss": 0.1422,
      "step": 8114
    },
    {
      "epoch": 1.8646599264705883,
      "grad_norm": 2.077986240386963,
      "learning_rate": 6.968954248366014e-06,
      "loss": 0.1418,
      "step": 8115
    },
    {
      "epoch": 1.8648897058823528,
      "grad_norm": 1.7772178649902344,
      "learning_rate": 6.9684436274509815e-06,
      "loss": 0.1033,
      "step": 8116
    },
    {
      "epoch": 1.8651194852941178,
      "grad_norm": 1.5279488563537598,
      "learning_rate": 6.9679330065359486e-06,
      "loss": 0.0838,
      "step": 8117
    },
    {
      "epoch": 1.8653492647058822,
      "grad_norm": 1.7830939292907715,
      "learning_rate": 6.9674223856209156e-06,
      "loss": 0.1056,
      "step": 8118
    },
    {
      "epoch": 1.8655790441176472,
      "grad_norm": 1.6614668369293213,
      "learning_rate": 6.966911764705883e-06,
      "loss": 0.1096,
      "step": 8119
    },
    {
      "epoch": 1.8658088235294117,
      "grad_norm": 2.106187343597412,
      "learning_rate": 6.9664011437908505e-06,
      "loss": 0.129,
      "step": 8120
    },
    {
      "epoch": 1.8660386029411766,
      "grad_norm": 2.1554996967315674,
      "learning_rate": 6.9658905228758175e-06,
      "loss": 0.1106,
      "step": 8121
    },
    {
      "epoch": 1.8662683823529411,
      "grad_norm": 2.434624433517456,
      "learning_rate": 6.9653799019607845e-06,
      "loss": 0.1764,
      "step": 8122
    },
    {
      "epoch": 1.8664981617647058,
      "grad_norm": 1.5880707502365112,
      "learning_rate": 6.9648692810457515e-06,
      "loss": 0.1029,
      "step": 8123
    },
    {
      "epoch": 1.8667279411764706,
      "grad_norm": 1.430450201034546,
      "learning_rate": 6.96435866013072e-06,
      "loss": 0.1068,
      "step": 8124
    },
    {
      "epoch": 1.8669577205882353,
      "grad_norm": 1.3006069660186768,
      "learning_rate": 6.963848039215687e-06,
      "loss": 0.0955,
      "step": 8125
    },
    {
      "epoch": 1.8671875,
      "grad_norm": 1.8960329294204712,
      "learning_rate": 6.963337418300654e-06,
      "loss": 0.1197,
      "step": 8126
    },
    {
      "epoch": 1.8674172794117647,
      "grad_norm": 1.4756017923355103,
      "learning_rate": 6.962826797385621e-06,
      "loss": 0.1069,
      "step": 8127
    },
    {
      "epoch": 1.8676470588235294,
      "grad_norm": 1.5462026596069336,
      "learning_rate": 6.962316176470589e-06,
      "loss": 0.0925,
      "step": 8128
    },
    {
      "epoch": 1.8678768382352942,
      "grad_norm": 2.1059670448303223,
      "learning_rate": 6.961805555555556e-06,
      "loss": 0.129,
      "step": 8129
    },
    {
      "epoch": 1.8681066176470589,
      "grad_norm": 1.7718232870101929,
      "learning_rate": 6.961294934640523e-06,
      "loss": 0.107,
      "step": 8130
    },
    {
      "epoch": 1.8683363970588234,
      "grad_norm": 1.6770336627960205,
      "learning_rate": 6.96078431372549e-06,
      "loss": 0.1049,
      "step": 8131
    },
    {
      "epoch": 1.8685661764705883,
      "grad_norm": 1.7951571941375732,
      "learning_rate": 6.960273692810459e-06,
      "loss": 0.1133,
      "step": 8132
    },
    {
      "epoch": 1.8687959558823528,
      "grad_norm": 1.3876549005508423,
      "learning_rate": 6.959763071895426e-06,
      "loss": 0.0963,
      "step": 8133
    },
    {
      "epoch": 1.8690257352941178,
      "grad_norm": 1.5822714567184448,
      "learning_rate": 6.959252450980393e-06,
      "loss": 0.0772,
      "step": 8134
    },
    {
      "epoch": 1.8692555147058822,
      "grad_norm": 2.2025561332702637,
      "learning_rate": 6.95874183006536e-06,
      "loss": 0.1015,
      "step": 8135
    },
    {
      "epoch": 1.8694852941176472,
      "grad_norm": 1.413694977760315,
      "learning_rate": 6.958231209150328e-06,
      "loss": 0.1157,
      "step": 8136
    },
    {
      "epoch": 1.8697150735294117,
      "grad_norm": 1.5932625532150269,
      "learning_rate": 6.957720588235295e-06,
      "loss": 0.1087,
      "step": 8137
    },
    {
      "epoch": 1.8699448529411766,
      "grad_norm": 1.5212041139602661,
      "learning_rate": 6.957209967320262e-06,
      "loss": 0.0847,
      "step": 8138
    },
    {
      "epoch": 1.8701746323529411,
      "grad_norm": 1.4934872388839722,
      "learning_rate": 6.956699346405229e-06,
      "loss": 0.0974,
      "step": 8139
    },
    {
      "epoch": 1.8704044117647058,
      "grad_norm": 1.4423500299453735,
      "learning_rate": 6.9561887254901975e-06,
      "loss": 0.1065,
      "step": 8140
    },
    {
      "epoch": 1.8706341911764706,
      "grad_norm": 1.6809701919555664,
      "learning_rate": 6.9556781045751645e-06,
      "loss": 0.088,
      "step": 8141
    },
    {
      "epoch": 1.8708639705882353,
      "grad_norm": 2.0823464393615723,
      "learning_rate": 6.9551674836601315e-06,
      "loss": 0.1238,
      "step": 8142
    },
    {
      "epoch": 1.87109375,
      "grad_norm": 1.4406850337982178,
      "learning_rate": 6.9546568627450986e-06,
      "loss": 0.1052,
      "step": 8143
    },
    {
      "epoch": 1.8713235294117647,
      "grad_norm": 1.4857796430587769,
      "learning_rate": 6.954146241830066e-06,
      "loss": 0.1071,
      "step": 8144
    },
    {
      "epoch": 1.8715533088235294,
      "grad_norm": 1.9198822975158691,
      "learning_rate": 6.9536356209150334e-06,
      "loss": 0.1216,
      "step": 8145
    },
    {
      "epoch": 1.8717830882352942,
      "grad_norm": 2.0476300716400146,
      "learning_rate": 6.9531250000000004e-06,
      "loss": 0.104,
      "step": 8146
    },
    {
      "epoch": 1.8720128676470589,
      "grad_norm": 1.526852011680603,
      "learning_rate": 6.9526143790849675e-06,
      "loss": 0.0877,
      "step": 8147
    },
    {
      "epoch": 1.8722426470588234,
      "grad_norm": 1.6155987977981567,
      "learning_rate": 6.9521037581699345e-06,
      "loss": 0.1033,
      "step": 8148
    },
    {
      "epoch": 1.8724724264705883,
      "grad_norm": Infinity,
      "learning_rate": 6.951593137254903e-06,
      "loss": 0.2536,
      "step": 8149
    },
    {
      "epoch": 1.8727022058823528,
      "grad_norm": 2.1855015754699707,
      "learning_rate": 6.951593137254903e-06,
      "loss": 0.0993,
      "step": 8150
    },
    {
      "epoch": 1.8729319852941178,
      "grad_norm": 2.204347610473633,
      "learning_rate": 6.95108251633987e-06,
      "loss": 0.1058,
      "step": 8151
    },
    {
      "epoch": 1.8731617647058822,
      "grad_norm": 2.51141357421875,
      "learning_rate": 6.950571895424837e-06,
      "loss": 0.1271,
      "step": 8152
    },
    {
      "epoch": 1.8733915441176472,
      "grad_norm": 1.5441824197769165,
      "learning_rate": 6.950061274509804e-06,
      "loss": 0.1168,
      "step": 8153
    },
    {
      "epoch": 1.8736213235294117,
      "grad_norm": 1.645236849784851,
      "learning_rate": 6.949550653594772e-06,
      "loss": 0.1037,
      "step": 8154
    },
    {
      "epoch": 1.8738511029411766,
      "grad_norm": 1.61040461063385,
      "learning_rate": 6.949040032679739e-06,
      "loss": 0.1151,
      "step": 8155
    },
    {
      "epoch": 1.8740808823529411,
      "grad_norm": 1.6553053855895996,
      "learning_rate": 6.948529411764706e-06,
      "loss": 0.1023,
      "step": 8156
    },
    {
      "epoch": 1.8743106617647058,
      "grad_norm": 1.873288869857788,
      "learning_rate": 6.948018790849673e-06,
      "loss": 0.1134,
      "step": 8157
    },
    {
      "epoch": 1.8745404411764706,
      "grad_norm": 1.9377782344818115,
      "learning_rate": 6.947508169934641e-06,
      "loss": 0.0866,
      "step": 8158
    },
    {
      "epoch": 1.8747702205882353,
      "grad_norm": 1.676133632659912,
      "learning_rate": 6.946997549019608e-06,
      "loss": 0.0968,
      "step": 8159
    },
    {
      "epoch": 1.875,
      "grad_norm": 1.3383113145828247,
      "learning_rate": 6.946486928104576e-06,
      "loss": 0.0959,
      "step": 8160
    },
    {
      "epoch": 1.8752297794117647,
      "grad_norm": 2.0662524700164795,
      "learning_rate": 6.945976307189543e-06,
      "loss": 0.1245,
      "step": 8161
    },
    {
      "epoch": 1.8754595588235294,
      "grad_norm": 1.155579924583435,
      "learning_rate": 6.945465686274511e-06,
      "loss": 0.0861,
      "step": 8162
    },
    {
      "epoch": 1.8756893382352942,
      "grad_norm": 1.3682763576507568,
      "learning_rate": 6.944955065359478e-06,
      "loss": 0.0833,
      "step": 8163
    },
    {
      "epoch": 1.8759191176470589,
      "grad_norm": 1.2646175622940063,
      "learning_rate": 6.944444444444445e-06,
      "loss": 0.1119,
      "step": 8164
    },
    {
      "epoch": 1.8761488970588234,
      "grad_norm": 2.099879026412964,
      "learning_rate": 6.943933823529412e-06,
      "loss": 0.1121,
      "step": 8165
    },
    {
      "epoch": 1.8763786764705883,
      "grad_norm": 1.5848811864852905,
      "learning_rate": 6.94342320261438e-06,
      "loss": 0.1217,
      "step": 8166
    },
    {
      "epoch": 1.8766084558823528,
      "grad_norm": 1.6877562999725342,
      "learning_rate": 6.942912581699347e-06,
      "loss": 0.1212,
      "step": 8167
    },
    {
      "epoch": 1.8768382352941178,
      "grad_norm": 1.3350365161895752,
      "learning_rate": 6.942401960784314e-06,
      "loss": 0.1086,
      "step": 8168
    },
    {
      "epoch": 1.8770680147058822,
      "grad_norm": 1.866921067237854,
      "learning_rate": 6.941891339869281e-06,
      "loss": 0.1096,
      "step": 8169
    },
    {
      "epoch": 1.8772977941176472,
      "grad_norm": 1.4325515031814575,
      "learning_rate": 6.941380718954249e-06,
      "loss": 0.1145,
      "step": 8170
    },
    {
      "epoch": 1.8775275735294117,
      "grad_norm": 1.8090184926986694,
      "learning_rate": 6.940870098039216e-06,
      "loss": 0.0934,
      "step": 8171
    },
    {
      "epoch": 1.8777573529411766,
      "grad_norm": 1.5838555097579956,
      "learning_rate": 6.9403594771241834e-06,
      "loss": 0.1297,
      "step": 8172
    },
    {
      "epoch": 1.8779871323529411,
      "grad_norm": 1.2487411499023438,
      "learning_rate": 6.9398488562091504e-06,
      "loss": 0.102,
      "step": 8173
    },
    {
      "epoch": 1.8782169117647058,
      "grad_norm": 1.3591296672821045,
      "learning_rate": 6.939338235294118e-06,
      "loss": 0.0793,
      "step": 8174
    },
    {
      "epoch": 1.8784466911764706,
      "grad_norm": 2.197075843811035,
      "learning_rate": 6.938827614379085e-06,
      "loss": 0.0992,
      "step": 8175
    },
    {
      "epoch": 1.8786764705882353,
      "grad_norm": 2.06229829788208,
      "learning_rate": 6.938316993464052e-06,
      "loss": 0.1002,
      "step": 8176
    },
    {
      "epoch": 1.87890625,
      "grad_norm": 1.4943146705627441,
      "learning_rate": 6.937806372549019e-06,
      "loss": 0.1091,
      "step": 8177
    },
    {
      "epoch": 1.8791360294117647,
      "grad_norm": 1.5088273286819458,
      "learning_rate": 6.937295751633988e-06,
      "loss": 0.1131,
      "step": 8178
    },
    {
      "epoch": 1.8793658088235294,
      "grad_norm": 2.1028478145599365,
      "learning_rate": 6.936785130718955e-06,
      "loss": 0.1321,
      "step": 8179
    },
    {
      "epoch": 1.8795955882352942,
      "grad_norm": 1.7902625799179077,
      "learning_rate": 6.936274509803922e-06,
      "loss": 0.1,
      "step": 8180
    },
    {
      "epoch": 1.8798253676470589,
      "grad_norm": 1.5465822219848633,
      "learning_rate": 6.935763888888889e-06,
      "loss": 0.1137,
      "step": 8181
    },
    {
      "epoch": 1.8800551470588234,
      "grad_norm": 1.5602606534957886,
      "learning_rate": 6.935253267973857e-06,
      "loss": 0.0973,
      "step": 8182
    },
    {
      "epoch": 1.8802849264705883,
      "grad_norm": 1.7891671657562256,
      "learning_rate": 6.934742647058824e-06,
      "loss": 0.1309,
      "step": 8183
    },
    {
      "epoch": 1.8805147058823528,
      "grad_norm": 1.7274059057235718,
      "learning_rate": 6.934232026143791e-06,
      "loss": 0.0833,
      "step": 8184
    },
    {
      "epoch": 1.8807444852941178,
      "grad_norm": 1.8836175203323364,
      "learning_rate": 6.933721405228758e-06,
      "loss": 0.1149,
      "step": 8185
    },
    {
      "epoch": 1.8809742647058822,
      "grad_norm": 1.907112956047058,
      "learning_rate": 6.933210784313727e-06,
      "loss": 0.1293,
      "step": 8186
    },
    {
      "epoch": 1.8812040441176472,
      "grad_norm": 2.0058443546295166,
      "learning_rate": 6.932700163398694e-06,
      "loss": 0.1146,
      "step": 8187
    },
    {
      "epoch": 1.8814338235294117,
      "grad_norm": 1.4989579916000366,
      "learning_rate": 6.932189542483661e-06,
      "loss": 0.0933,
      "step": 8188
    },
    {
      "epoch": 1.8816636029411766,
      "grad_norm": 1.6823707818984985,
      "learning_rate": 6.931678921568628e-06,
      "loss": 0.1146,
      "step": 8189
    },
    {
      "epoch": 1.8818933823529411,
      "grad_norm": 1.973077416419983,
      "learning_rate": 6.931168300653596e-06,
      "loss": 0.1255,
      "step": 8190
    },
    {
      "epoch": 1.8821231617647058,
      "grad_norm": 1.5603045225143433,
      "learning_rate": 6.930657679738563e-06,
      "loss": 0.1305,
      "step": 8191
    },
    {
      "epoch": 1.8823529411764706,
      "grad_norm": 1.912495732307434,
      "learning_rate": 6.93014705882353e-06,
      "loss": 0.0753,
      "step": 8192
    },
    {
      "epoch": 1.8825827205882353,
      "grad_norm": 1.8422391414642334,
      "learning_rate": 6.929636437908497e-06,
      "loss": 0.1244,
      "step": 8193
    },
    {
      "epoch": 1.8828125,
      "grad_norm": 1.5311156511306763,
      "learning_rate": 6.929125816993465e-06,
      "loss": 0.0923,
      "step": 8194
    },
    {
      "epoch": 1.8830422794117647,
      "grad_norm": 1.3080500364303589,
      "learning_rate": 6.928615196078432e-06,
      "loss": 0.099,
      "step": 8195
    },
    {
      "epoch": 1.8832720588235294,
      "grad_norm": 1.463660478591919,
      "learning_rate": 6.928104575163399e-06,
      "loss": 0.1097,
      "step": 8196
    },
    {
      "epoch": 1.8835018382352942,
      "grad_norm": 1.9927952289581299,
      "learning_rate": 6.927593954248366e-06,
      "loss": 0.1127,
      "step": 8197
    },
    {
      "epoch": 1.8837316176470589,
      "grad_norm": 2.064690113067627,
      "learning_rate": 6.927083333333334e-06,
      "loss": 0.1205,
      "step": 8198
    },
    {
      "epoch": 1.8839613970588234,
      "grad_norm": 1.4718003273010254,
      "learning_rate": 6.926572712418301e-06,
      "loss": 0.1124,
      "step": 8199
    },
    {
      "epoch": 1.8841911764705883,
      "grad_norm": 1.6793922185897827,
      "learning_rate": 6.926062091503268e-06,
      "loss": 0.111,
      "step": 8200
    },
    {
      "epoch": 1.8844209558823528,
      "grad_norm": 2.113347053527832,
      "learning_rate": 6.925551470588235e-06,
      "loss": 0.0867,
      "step": 8201
    },
    {
      "epoch": 1.8846507352941178,
      "grad_norm": 2.0161020755767822,
      "learning_rate": 6.925040849673203e-06,
      "loss": 0.1102,
      "step": 8202
    },
    {
      "epoch": 1.8848805147058822,
      "grad_norm": 2.0066311359405518,
      "learning_rate": 6.92453022875817e-06,
      "loss": 0.1091,
      "step": 8203
    },
    {
      "epoch": 1.8851102941176472,
      "grad_norm": 1.932822585105896,
      "learning_rate": 6.924019607843138e-06,
      "loss": 0.0963,
      "step": 8204
    },
    {
      "epoch": 1.8853400735294117,
      "grad_norm": 1.9188506603240967,
      "learning_rate": 6.923508986928105e-06,
      "loss": 0.1169,
      "step": 8205
    },
    {
      "epoch": 1.8855698529411766,
      "grad_norm": 1.6094156503677368,
      "learning_rate": 6.922998366013073e-06,
      "loss": 0.1047,
      "step": 8206
    },
    {
      "epoch": 1.8857996323529411,
      "grad_norm": 1.5092048645019531,
      "learning_rate": 6.92248774509804e-06,
      "loss": 0.1076,
      "step": 8207
    },
    {
      "epoch": 1.8860294117647058,
      "grad_norm": 2.032146692276001,
      "learning_rate": 6.921977124183007e-06,
      "loss": 0.1259,
      "step": 8208
    },
    {
      "epoch": 1.8862591911764706,
      "grad_norm": 1.9277572631835938,
      "learning_rate": 6.921466503267974e-06,
      "loss": 0.073,
      "step": 8209
    },
    {
      "epoch": 1.8864889705882353,
      "grad_norm": 1.5488008260726929,
      "learning_rate": 6.920955882352942e-06,
      "loss": 0.096,
      "step": 8210
    },
    {
      "epoch": 1.88671875,
      "grad_norm": 1.6189556121826172,
      "learning_rate": 6.920445261437909e-06,
      "loss": 0.1093,
      "step": 8211
    },
    {
      "epoch": 1.8869485294117647,
      "grad_norm": 1.384810209274292,
      "learning_rate": 6.919934640522876e-06,
      "loss": 0.103,
      "step": 8212
    },
    {
      "epoch": 1.8871783088235294,
      "grad_norm": 1.5994714498519897,
      "learning_rate": 6.919424019607843e-06,
      "loss": 0.0951,
      "step": 8213
    },
    {
      "epoch": 1.8874080882352942,
      "grad_norm": 1.5365196466445923,
      "learning_rate": 6.918913398692812e-06,
      "loss": 0.1402,
      "step": 8214
    },
    {
      "epoch": 1.8876378676470589,
      "grad_norm": 2.119563579559326,
      "learning_rate": 6.918402777777779e-06,
      "loss": 0.1004,
      "step": 8215
    },
    {
      "epoch": 1.8878676470588234,
      "grad_norm": 2.175442695617676,
      "learning_rate": 6.917892156862746e-06,
      "loss": 0.1085,
      "step": 8216
    },
    {
      "epoch": 1.8880974264705883,
      "grad_norm": 2.2525744438171387,
      "learning_rate": 6.917381535947713e-06,
      "loss": 0.138,
      "step": 8217
    },
    {
      "epoch": 1.8883272058823528,
      "grad_norm": 1.8288214206695557,
      "learning_rate": 6.9168709150326805e-06,
      "loss": 0.1066,
      "step": 8218
    },
    {
      "epoch": 1.8885569852941178,
      "grad_norm": 1.385117769241333,
      "learning_rate": 6.9163602941176475e-06,
      "loss": 0.0694,
      "step": 8219
    },
    {
      "epoch": 1.8887867647058822,
      "grad_norm": 1.615099310874939,
      "learning_rate": 6.9158496732026145e-06,
      "loss": 0.1276,
      "step": 8220
    },
    {
      "epoch": 1.8890165441176472,
      "grad_norm": 1.5290873050689697,
      "learning_rate": 6.9153390522875815e-06,
      "loss": 0.0949,
      "step": 8221
    },
    {
      "epoch": 1.8892463235294117,
      "grad_norm": 1.5702691078186035,
      "learning_rate": 6.91482843137255e-06,
      "loss": 0.0891,
      "step": 8222
    },
    {
      "epoch": 1.8894761029411766,
      "grad_norm": 1.625496745109558,
      "learning_rate": 6.914317810457517e-06,
      "loss": 0.1358,
      "step": 8223
    },
    {
      "epoch": 1.8897058823529411,
      "grad_norm": 1.6374051570892334,
      "learning_rate": 6.913807189542484e-06,
      "loss": 0.13,
      "step": 8224
    },
    {
      "epoch": 1.8899356617647058,
      "grad_norm": 1.7969578504562378,
      "learning_rate": 6.913296568627451e-06,
      "loss": 0.1318,
      "step": 8225
    },
    {
      "epoch": 1.8901654411764706,
      "grad_norm": 1.6692450046539307,
      "learning_rate": 6.912785947712419e-06,
      "loss": 0.1023,
      "step": 8226
    },
    {
      "epoch": 1.8903952205882353,
      "grad_norm": 1.6250321865081787,
      "learning_rate": 6.912275326797386e-06,
      "loss": 0.1134,
      "step": 8227
    },
    {
      "epoch": 1.890625,
      "grad_norm": 1.749741554260254,
      "learning_rate": 6.911764705882353e-06,
      "loss": 0.1297,
      "step": 8228
    },
    {
      "epoch": 1.8908547794117647,
      "grad_norm": 1.4650148153305054,
      "learning_rate": 6.91125408496732e-06,
      "loss": 0.0976,
      "step": 8229
    },
    {
      "epoch": 1.8910845588235294,
      "grad_norm": 1.7480131387710571,
      "learning_rate": 6.910743464052289e-06,
      "loss": 0.139,
      "step": 8230
    },
    {
      "epoch": 1.8913143382352942,
      "grad_norm": 1.9550411701202393,
      "learning_rate": 6.910232843137256e-06,
      "loss": 0.1611,
      "step": 8231
    },
    {
      "epoch": 1.8915441176470589,
      "grad_norm": 1.8920315504074097,
      "learning_rate": 6.909722222222223e-06,
      "loss": 0.148,
      "step": 8232
    },
    {
      "epoch": 1.8917738970588234,
      "grad_norm": 1.9395865201950073,
      "learning_rate": 6.90921160130719e-06,
      "loss": 0.1297,
      "step": 8233
    },
    {
      "epoch": 1.8920036764705883,
      "grad_norm": 1.4981199502944946,
      "learning_rate": 6.908700980392158e-06,
      "loss": 0.1316,
      "step": 8234
    },
    {
      "epoch": 1.8922334558823528,
      "grad_norm": 1.9313876628875732,
      "learning_rate": 6.908190359477125e-06,
      "loss": 0.0833,
      "step": 8235
    },
    {
      "epoch": 1.8924632352941178,
      "grad_norm": 1.5497984886169434,
      "learning_rate": 6.907679738562092e-06,
      "loss": 0.0895,
      "step": 8236
    },
    {
      "epoch": 1.8926930147058822,
      "grad_norm": 1.3355519771575928,
      "learning_rate": 6.907169117647059e-06,
      "loss": 0.072,
      "step": 8237
    },
    {
      "epoch": 1.8929227941176472,
      "grad_norm": 1.8224167823791504,
      "learning_rate": 6.9066584967320276e-06,
      "loss": 0.0843,
      "step": 8238
    },
    {
      "epoch": 1.8931525735294117,
      "grad_norm": 1.8492894172668457,
      "learning_rate": 6.906147875816995e-06,
      "loss": 0.1068,
      "step": 8239
    },
    {
      "epoch": 1.8933823529411766,
      "grad_norm": 1.7418440580368042,
      "learning_rate": 6.905637254901962e-06,
      "loss": 0.1322,
      "step": 8240
    },
    {
      "epoch": 1.8936121323529411,
      "grad_norm": 1.505622148513794,
      "learning_rate": 6.905126633986929e-06,
      "loss": 0.1186,
      "step": 8241
    },
    {
      "epoch": 1.8938419117647058,
      "grad_norm": 1.3399266004562378,
      "learning_rate": 6.9046160130718965e-06,
      "loss": 0.1114,
      "step": 8242
    },
    {
      "epoch": 1.8940716911764706,
      "grad_norm": 1.4907283782958984,
      "learning_rate": 6.9041053921568635e-06,
      "loss": 0.0812,
      "step": 8243
    },
    {
      "epoch": 1.8943014705882353,
      "grad_norm": 1.2575883865356445,
      "learning_rate": 6.9035947712418305e-06,
      "loss": 0.1045,
      "step": 8244
    },
    {
      "epoch": 1.89453125,
      "grad_norm": 1.6490726470947266,
      "learning_rate": 6.9030841503267975e-06,
      "loss": 0.1392,
      "step": 8245
    },
    {
      "epoch": 1.8947610294117647,
      "grad_norm": 1.6735789775848389,
      "learning_rate": 6.902573529411765e-06,
      "loss": 0.0943,
      "step": 8246
    },
    {
      "epoch": 1.8949908088235294,
      "grad_norm": 1.4420901536941528,
      "learning_rate": 6.902062908496732e-06,
      "loss": 0.1004,
      "step": 8247
    },
    {
      "epoch": 1.8952205882352942,
      "grad_norm": 1.660751223564148,
      "learning_rate": 6.901552287581699e-06,
      "loss": 0.0861,
      "step": 8248
    },
    {
      "epoch": 1.8954503676470589,
      "grad_norm": 2.0222079753875732,
      "learning_rate": 6.901041666666667e-06,
      "loss": 0.1221,
      "step": 8249
    },
    {
      "epoch": 1.8956801470588234,
      "grad_norm": 1.7666730880737305,
      "learning_rate": 6.900531045751635e-06,
      "loss": 0.0979,
      "step": 8250
    },
    {
      "epoch": 1.8959099264705883,
      "grad_norm": 1.533617615699768,
      "learning_rate": 6.900020424836602e-06,
      "loss": 0.0895,
      "step": 8251
    },
    {
      "epoch": 1.8961397058823528,
      "grad_norm": 1.422013521194458,
      "learning_rate": 6.899509803921569e-06,
      "loss": 0.0867,
      "step": 8252
    },
    {
      "epoch": 1.8963694852941178,
      "grad_norm": 1.604783296585083,
      "learning_rate": 6.898999183006536e-06,
      "loss": 0.1018,
      "step": 8253
    },
    {
      "epoch": 1.8965992647058822,
      "grad_norm": 1.8202258348464966,
      "learning_rate": 6.898488562091504e-06,
      "loss": 0.1413,
      "step": 8254
    },
    {
      "epoch": 1.8968290441176472,
      "grad_norm": 1.662136435508728,
      "learning_rate": 6.897977941176471e-06,
      "loss": 0.1367,
      "step": 8255
    },
    {
      "epoch": 1.8970588235294117,
      "grad_norm": 1.8367213010787964,
      "learning_rate": 6.897467320261438e-06,
      "loss": 0.1238,
      "step": 8256
    },
    {
      "epoch": 1.8972886029411766,
      "grad_norm": 2.016184091567993,
      "learning_rate": 6.896956699346405e-06,
      "loss": 0.1415,
      "step": 8257
    },
    {
      "epoch": 1.8975183823529411,
      "grad_norm": 1.763739824295044,
      "learning_rate": 6.896446078431374e-06,
      "loss": 0.1109,
      "step": 8258
    },
    {
      "epoch": 1.8977481617647058,
      "grad_norm": 1.4637300968170166,
      "learning_rate": 6.895935457516341e-06,
      "loss": 0.1034,
      "step": 8259
    },
    {
      "epoch": 1.8979779411764706,
      "grad_norm": 1.9092798233032227,
      "learning_rate": 6.895424836601308e-06,
      "loss": 0.0997,
      "step": 8260
    },
    {
      "epoch": 1.8982077205882353,
      "grad_norm": 1.9183809757232666,
      "learning_rate": 6.894914215686275e-06,
      "loss": 0.1233,
      "step": 8261
    },
    {
      "epoch": 1.8984375,
      "grad_norm": 1.99191415309906,
      "learning_rate": 6.894403594771243e-06,
      "loss": 0.1224,
      "step": 8262
    },
    {
      "epoch": 1.8986672794117647,
      "grad_norm": 2.0976600646972656,
      "learning_rate": 6.89389297385621e-06,
      "loss": 0.1291,
      "step": 8263
    },
    {
      "epoch": 1.8988970588235294,
      "grad_norm": 2.2273805141448975,
      "learning_rate": 6.893382352941177e-06,
      "loss": 0.1094,
      "step": 8264
    },
    {
      "epoch": 1.8991268382352942,
      "grad_norm": 1.9506937265396118,
      "learning_rate": 6.892871732026144e-06,
      "loss": 0.108,
      "step": 8265
    },
    {
      "epoch": 1.8993566176470589,
      "grad_norm": 2.0290746688842773,
      "learning_rate": 6.8923611111111124e-06,
      "loss": 0.1144,
      "step": 8266
    },
    {
      "epoch": 1.8995863970588234,
      "grad_norm": 1.4930952787399292,
      "learning_rate": 6.8918504901960795e-06,
      "loss": 0.0841,
      "step": 8267
    },
    {
      "epoch": 1.8998161764705883,
      "grad_norm": 1.6585100889205933,
      "learning_rate": 6.8913398692810465e-06,
      "loss": 0.1144,
      "step": 8268
    },
    {
      "epoch": 1.9000459558823528,
      "grad_norm": 1.7870607376098633,
      "learning_rate": 6.8908292483660135e-06,
      "loss": 0.1144,
      "step": 8269
    },
    {
      "epoch": 1.9002757352941178,
      "grad_norm": 1.9121363162994385,
      "learning_rate": 6.890318627450981e-06,
      "loss": 0.1092,
      "step": 8270
    },
    {
      "epoch": 1.9005055147058822,
      "grad_norm": 1.958735466003418,
      "learning_rate": 6.889808006535948e-06,
      "loss": 0.1093,
      "step": 8271
    },
    {
      "epoch": 1.9007352941176472,
      "grad_norm": 1.8049620389938354,
      "learning_rate": 6.889297385620915e-06,
      "loss": 0.0972,
      "step": 8272
    },
    {
      "epoch": 1.9009650735294117,
      "grad_norm": 2.3795907497406006,
      "learning_rate": 6.888786764705882e-06,
      "loss": 0.1035,
      "step": 8273
    },
    {
      "epoch": 1.9011948529411766,
      "grad_norm": 2.3526368141174316,
      "learning_rate": 6.888276143790851e-06,
      "loss": 0.1207,
      "step": 8274
    },
    {
      "epoch": 1.9014246323529411,
      "grad_norm": 2.2411158084869385,
      "learning_rate": 6.887765522875818e-06,
      "loss": 0.12,
      "step": 8275
    },
    {
      "epoch": 1.9016544117647058,
      "grad_norm": 1.6875802278518677,
      "learning_rate": 6.887254901960785e-06,
      "loss": 0.115,
      "step": 8276
    },
    {
      "epoch": 1.9018841911764706,
      "grad_norm": 1.404641032218933,
      "learning_rate": 6.886744281045752e-06,
      "loss": 0.0868,
      "step": 8277
    },
    {
      "epoch": 1.9021139705882353,
      "grad_norm": 1.3425250053405762,
      "learning_rate": 6.88623366013072e-06,
      "loss": 0.0836,
      "step": 8278
    },
    {
      "epoch": 1.90234375,
      "grad_norm": 1.8876813650131226,
      "learning_rate": 6.885723039215687e-06,
      "loss": 0.1212,
      "step": 8279
    },
    {
      "epoch": 1.9025735294117647,
      "grad_norm": 1.2557002305984497,
      "learning_rate": 6.885212418300654e-06,
      "loss": 0.0874,
      "step": 8280
    },
    {
      "epoch": 1.9028033088235294,
      "grad_norm": 1.4650217294692993,
      "learning_rate": 6.884701797385621e-06,
      "loss": 0.0974,
      "step": 8281
    },
    {
      "epoch": 1.9030330882352942,
      "grad_norm": 1.9760279655456543,
      "learning_rate": 6.884191176470589e-06,
      "loss": 0.106,
      "step": 8282
    },
    {
      "epoch": 1.9032628676470589,
      "grad_norm": 2.847494125366211,
      "learning_rate": 6.883680555555557e-06,
      "loss": 0.1323,
      "step": 8283
    },
    {
      "epoch": 1.9034926470588234,
      "grad_norm": 2.177635431289673,
      "learning_rate": 6.883169934640524e-06,
      "loss": 0.1245,
      "step": 8284
    },
    {
      "epoch": 1.9037224264705883,
      "grad_norm": 1.6109055280685425,
      "learning_rate": 6.882659313725491e-06,
      "loss": 0.1048,
      "step": 8285
    },
    {
      "epoch": 1.9039522058823528,
      "grad_norm": 1.766602873802185,
      "learning_rate": 6.882148692810459e-06,
      "loss": 0.0793,
      "step": 8286
    },
    {
      "epoch": 1.9041819852941178,
      "grad_norm": 1.9513373374938965,
      "learning_rate": 6.881638071895426e-06,
      "loss": 0.1307,
      "step": 8287
    },
    {
      "epoch": 1.9044117647058822,
      "grad_norm": 1.982851505279541,
      "learning_rate": 6.881127450980393e-06,
      "loss": 0.1307,
      "step": 8288
    },
    {
      "epoch": 1.9046415441176472,
      "grad_norm": 1.4849339723587036,
      "learning_rate": 6.88061683006536e-06,
      "loss": 0.0614,
      "step": 8289
    },
    {
      "epoch": 1.9048713235294117,
      "grad_norm": 1.595172643661499,
      "learning_rate": 6.8801062091503276e-06,
      "loss": 0.091,
      "step": 8290
    },
    {
      "epoch": 1.9051011029411766,
      "grad_norm": 2.6751291751861572,
      "learning_rate": 6.8795955882352946e-06,
      "loss": 0.142,
      "step": 8291
    },
    {
      "epoch": 1.9053308823529411,
      "grad_norm": 1.7402172088623047,
      "learning_rate": 6.879084967320262e-06,
      "loss": 0.0847,
      "step": 8292
    },
    {
      "epoch": 1.9055606617647058,
      "grad_norm": 1.589624047279358,
      "learning_rate": 6.8785743464052294e-06,
      "loss": 0.1161,
      "step": 8293
    },
    {
      "epoch": 1.9057904411764706,
      "grad_norm": 2.04591703414917,
      "learning_rate": 6.878063725490197e-06,
      "loss": 0.1159,
      "step": 8294
    },
    {
      "epoch": 1.9060202205882353,
      "grad_norm": 1.4605059623718262,
      "learning_rate": 6.877553104575164e-06,
      "loss": 0.0948,
      "step": 8295
    },
    {
      "epoch": 1.90625,
      "grad_norm": 1.331599473953247,
      "learning_rate": 6.877042483660131e-06,
      "loss": 0.0798,
      "step": 8296
    },
    {
      "epoch": 1.9064797794117647,
      "grad_norm": 1.5463440418243408,
      "learning_rate": 6.876531862745098e-06,
      "loss": 0.1478,
      "step": 8297
    },
    {
      "epoch": 1.9067095588235294,
      "grad_norm": 2.0457539558410645,
      "learning_rate": 6.876021241830066e-06,
      "loss": 0.1429,
      "step": 8298
    },
    {
      "epoch": 1.9069393382352942,
      "grad_norm": 2.462913751602173,
      "learning_rate": 6.875510620915033e-06,
      "loss": 0.1285,
      "step": 8299
    },
    {
      "epoch": 1.9071691176470589,
      "grad_norm": 1.6140965223312378,
      "learning_rate": 6.875e-06,
      "loss": 0.1181,
      "step": 8300
    },
    {
      "epoch": 1.9073988970588234,
      "grad_norm": 1.5626829862594604,
      "learning_rate": 6.874489379084967e-06,
      "loss": 0.1237,
      "step": 8301
    },
    {
      "epoch": 1.9076286764705883,
      "grad_norm": 1.4121568202972412,
      "learning_rate": 6.873978758169934e-06,
      "loss": 0.0964,
      "step": 8302
    },
    {
      "epoch": 1.9078584558823528,
      "grad_norm": 3.1118977069854736,
      "learning_rate": 6.873468137254903e-06,
      "loss": 0.1016,
      "step": 8303
    },
    {
      "epoch": 1.9080882352941178,
      "grad_norm": 1.4497756958007812,
      "learning_rate": 6.87295751633987e-06,
      "loss": 0.0868,
      "step": 8304
    },
    {
      "epoch": 1.9083180147058822,
      "grad_norm": 1.9051696062088013,
      "learning_rate": 6.872446895424837e-06,
      "loss": 0.1187,
      "step": 8305
    },
    {
      "epoch": 1.9085477941176472,
      "grad_norm": 1.4208382368087769,
      "learning_rate": 6.871936274509804e-06,
      "loss": 0.0976,
      "step": 8306
    },
    {
      "epoch": 1.9087775735294117,
      "grad_norm": 1.5513193607330322,
      "learning_rate": 6.871425653594772e-06,
      "loss": 0.103,
      "step": 8307
    },
    {
      "epoch": 1.9090073529411766,
      "grad_norm": 1.725881814956665,
      "learning_rate": 6.870915032679739e-06,
      "loss": 0.0982,
      "step": 8308
    },
    {
      "epoch": 1.9092371323529411,
      "grad_norm": 1.507356882095337,
      "learning_rate": 6.870404411764706e-06,
      "loss": 0.0887,
      "step": 8309
    },
    {
      "epoch": 1.9094669117647058,
      "grad_norm": 1.7563068866729736,
      "learning_rate": 6.869893790849673e-06,
      "loss": 0.1194,
      "step": 8310
    },
    {
      "epoch": 1.9096966911764706,
      "grad_norm": 1.929476022720337,
      "learning_rate": 6.869383169934642e-06,
      "loss": 0.1151,
      "step": 8311
    },
    {
      "epoch": 1.9099264705882353,
      "grad_norm": 1.711391806602478,
      "learning_rate": 6.868872549019609e-06,
      "loss": 0.0948,
      "step": 8312
    },
    {
      "epoch": 1.91015625,
      "grad_norm": 1.7799321413040161,
      "learning_rate": 6.868361928104576e-06,
      "loss": 0.1366,
      "step": 8313
    },
    {
      "epoch": 1.9103860294117647,
      "grad_norm": 1.7535902261734009,
      "learning_rate": 6.867851307189543e-06,
      "loss": 0.1196,
      "step": 8314
    },
    {
      "epoch": 1.9106158088235294,
      "grad_norm": 1.641970157623291,
      "learning_rate": 6.8673406862745105e-06,
      "loss": 0.1104,
      "step": 8315
    },
    {
      "epoch": 1.9108455882352942,
      "grad_norm": 2.0512614250183105,
      "learning_rate": 6.8668300653594776e-06,
      "loss": 0.1537,
      "step": 8316
    },
    {
      "epoch": 1.9110753676470589,
      "grad_norm": 1.4495270252227783,
      "learning_rate": 6.8663194444444446e-06,
      "loss": 0.0779,
      "step": 8317
    },
    {
      "epoch": 1.9113051470588234,
      "grad_norm": 1.4746447801589966,
      "learning_rate": 6.865808823529412e-06,
      "loss": 0.1166,
      "step": 8318
    },
    {
      "epoch": 1.9115349264705883,
      "grad_norm": 1.5932066440582275,
      "learning_rate": 6.86529820261438e-06,
      "loss": 0.1243,
      "step": 8319
    },
    {
      "epoch": 1.9117647058823528,
      "grad_norm": 1.917112112045288,
      "learning_rate": 6.864787581699347e-06,
      "loss": 0.0743,
      "step": 8320
    },
    {
      "epoch": 1.9119944852941178,
      "grad_norm": 1.6203752756118774,
      "learning_rate": 6.864276960784314e-06,
      "loss": 0.1211,
      "step": 8321
    },
    {
      "epoch": 1.9122242647058822,
      "grad_norm": 1.488025188446045,
      "learning_rate": 6.863766339869281e-06,
      "loss": 0.0982,
      "step": 8322
    },
    {
      "epoch": 1.9124540441176472,
      "grad_norm": 2.6546971797943115,
      "learning_rate": 6.863255718954249e-06,
      "loss": 0.1351,
      "step": 8323
    },
    {
      "epoch": 1.9126838235294117,
      "grad_norm": 1.9714345932006836,
      "learning_rate": 6.862745098039216e-06,
      "loss": 0.1097,
      "step": 8324
    },
    {
      "epoch": 1.9129136029411766,
      "grad_norm": 1.476958990097046,
      "learning_rate": 6.862234477124183e-06,
      "loss": 0.1114,
      "step": 8325
    },
    {
      "epoch": 1.9131433823529411,
      "grad_norm": 1.2371177673339844,
      "learning_rate": 6.86172385620915e-06,
      "loss": 0.1041,
      "step": 8326
    },
    {
      "epoch": 1.9133731617647058,
      "grad_norm": 1.398542046546936,
      "learning_rate": 6.861213235294119e-06,
      "loss": 0.0954,
      "step": 8327
    },
    {
      "epoch": 1.9136029411764706,
      "grad_norm": 1.8308387994766235,
      "learning_rate": 6.860702614379086e-06,
      "loss": 0.1039,
      "step": 8328
    },
    {
      "epoch": 1.9138327205882353,
      "grad_norm": 1.5177079439163208,
      "learning_rate": 6.860191993464053e-06,
      "loss": 0.1192,
      "step": 8329
    },
    {
      "epoch": 1.9140625,
      "grad_norm": 1.2604691982269287,
      "learning_rate": 6.85968137254902e-06,
      "loss": 0.1023,
      "step": 8330
    },
    {
      "epoch": 1.9142922794117647,
      "grad_norm": 1.3994461297988892,
      "learning_rate": 6.859170751633988e-06,
      "loss": 0.0869,
      "step": 8331
    },
    {
      "epoch": 1.9145220588235294,
      "grad_norm": 1.9177439212799072,
      "learning_rate": 6.858660130718955e-06,
      "loss": 0.1093,
      "step": 8332
    },
    {
      "epoch": 1.9147518382352942,
      "grad_norm": 2.0159077644348145,
      "learning_rate": 6.858149509803922e-06,
      "loss": 0.0794,
      "step": 8333
    },
    {
      "epoch": 1.9149816176470589,
      "grad_norm": 1.6407796144485474,
      "learning_rate": 6.857638888888889e-06,
      "loss": 0.0834,
      "step": 8334
    },
    {
      "epoch": 1.9152113970588234,
      "grad_norm": 1.395661473274231,
      "learning_rate": 6.857128267973857e-06,
      "loss": 0.08,
      "step": 8335
    },
    {
      "epoch": 1.9154411764705883,
      "grad_norm": 1.3288551568984985,
      "learning_rate": 6.856617647058824e-06,
      "loss": 0.0709,
      "step": 8336
    },
    {
      "epoch": 1.9156709558823528,
      "grad_norm": 1.78345787525177,
      "learning_rate": 6.856107026143791e-06,
      "loss": 0.1384,
      "step": 8337
    },
    {
      "epoch": 1.9159007352941178,
      "grad_norm": 1.5829874277114868,
      "learning_rate": 6.855596405228759e-06,
      "loss": 0.1149,
      "step": 8338
    },
    {
      "epoch": 1.9161305147058822,
      "grad_norm": 1.3160547018051147,
      "learning_rate": 6.8550857843137265e-06,
      "loss": 0.0989,
      "step": 8339
    },
    {
      "epoch": 1.9163602941176472,
      "grad_norm": 1.253377914428711,
      "learning_rate": 6.8545751633986935e-06,
      "loss": 0.0967,
      "step": 8340
    },
    {
      "epoch": 1.9165900735294117,
      "grad_norm": 1.1550599336624146,
      "learning_rate": 6.8540645424836605e-06,
      "loss": 0.0764,
      "step": 8341
    },
    {
      "epoch": 1.9168198529411766,
      "grad_norm": 1.7568576335906982,
      "learning_rate": 6.8535539215686276e-06,
      "loss": 0.1398,
      "step": 8342
    },
    {
      "epoch": 1.9170496323529411,
      "grad_norm": 1.8290008306503296,
      "learning_rate": 6.853043300653595e-06,
      "loss": 0.1012,
      "step": 8343
    },
    {
      "epoch": 1.9172794117647058,
      "grad_norm": 2.301762580871582,
      "learning_rate": 6.8525326797385624e-06,
      "loss": 0.1266,
      "step": 8344
    },
    {
      "epoch": 1.9175091911764706,
      "grad_norm": 1.699049949645996,
      "learning_rate": 6.8520220588235294e-06,
      "loss": 0.1205,
      "step": 8345
    },
    {
      "epoch": 1.9177389705882353,
      "grad_norm": 1.4283345937728882,
      "learning_rate": 6.8515114379084965e-06,
      "loss": 0.0821,
      "step": 8346
    },
    {
      "epoch": 1.91796875,
      "grad_norm": 2.0226032733917236,
      "learning_rate": 6.851000816993465e-06,
      "loss": 0.122,
      "step": 8347
    },
    {
      "epoch": 1.9181985294117647,
      "grad_norm": 1.4557245969772339,
      "learning_rate": 6.850490196078432e-06,
      "loss": 0.0788,
      "step": 8348
    },
    {
      "epoch": 1.9184283088235294,
      "grad_norm": 1.8837487697601318,
      "learning_rate": 6.849979575163399e-06,
      "loss": 0.1074,
      "step": 8349
    },
    {
      "epoch": 1.9186580882352942,
      "grad_norm": 1.6056114435195923,
      "learning_rate": 6.849468954248366e-06,
      "loss": 0.0823,
      "step": 8350
    },
    {
      "epoch": 1.9188878676470589,
      "grad_norm": 1.5757083892822266,
      "learning_rate": 6.848958333333334e-06,
      "loss": 0.122,
      "step": 8351
    },
    {
      "epoch": 1.9191176470588234,
      "grad_norm": 1.509183645248413,
      "learning_rate": 6.848447712418301e-06,
      "loss": 0.0953,
      "step": 8352
    },
    {
      "epoch": 1.9193474264705883,
      "grad_norm": 1.9447280168533325,
      "learning_rate": 6.847937091503268e-06,
      "loss": 0.1076,
      "step": 8353
    },
    {
      "epoch": 1.9195772058823528,
      "grad_norm": 1.6191105842590332,
      "learning_rate": 6.847426470588235e-06,
      "loss": 0.0803,
      "step": 8354
    },
    {
      "epoch": 1.9198069852941178,
      "grad_norm": 1.6928521394729614,
      "learning_rate": 6.846915849673204e-06,
      "loss": 0.0972,
      "step": 8355
    },
    {
      "epoch": 1.9200367647058822,
      "grad_norm": 1.6426442861557007,
      "learning_rate": 6.846405228758171e-06,
      "loss": 0.1085,
      "step": 8356
    },
    {
      "epoch": 1.9202665441176472,
      "grad_norm": 2.160022258758545,
      "learning_rate": 6.845894607843138e-06,
      "loss": 0.1568,
      "step": 8357
    },
    {
      "epoch": 1.9204963235294117,
      "grad_norm": 2.1028032302856445,
      "learning_rate": 6.845383986928105e-06,
      "loss": 0.1398,
      "step": 8358
    },
    {
      "epoch": 1.9207261029411766,
      "grad_norm": 1.7433775663375854,
      "learning_rate": 6.844873366013073e-06,
      "loss": 0.1155,
      "step": 8359
    },
    {
      "epoch": 1.9209558823529411,
      "grad_norm": 1.6766108274459839,
      "learning_rate": 6.84436274509804e-06,
      "loss": 0.1268,
      "step": 8360
    },
    {
      "epoch": 1.9211856617647058,
      "grad_norm": 1.3674553632736206,
      "learning_rate": 6.843852124183007e-06,
      "loss": 0.084,
      "step": 8361
    },
    {
      "epoch": 1.9214154411764706,
      "grad_norm": 1.8800952434539795,
      "learning_rate": 6.843341503267974e-06,
      "loss": 0.1069,
      "step": 8362
    },
    {
      "epoch": 1.9216452205882353,
      "grad_norm": 1.7174245119094849,
      "learning_rate": 6.8428308823529425e-06,
      "loss": 0.1268,
      "step": 8363
    },
    {
      "epoch": 1.921875,
      "grad_norm": 1.4365278482437134,
      "learning_rate": 6.8423202614379095e-06,
      "loss": 0.1429,
      "step": 8364
    },
    {
      "epoch": 1.9221047794117647,
      "grad_norm": 1.9388136863708496,
      "learning_rate": 6.8418096405228765e-06,
      "loss": 0.1016,
      "step": 8365
    },
    {
      "epoch": 1.9223345588235294,
      "grad_norm": 1.2424819469451904,
      "learning_rate": 6.8412990196078435e-06,
      "loss": 0.0953,
      "step": 8366
    },
    {
      "epoch": 1.9225643382352942,
      "grad_norm": 1.9160735607147217,
      "learning_rate": 6.840788398692811e-06,
      "loss": 0.1312,
      "step": 8367
    },
    {
      "epoch": 1.9227941176470589,
      "grad_norm": 1.7092398405075073,
      "learning_rate": 6.840277777777778e-06,
      "loss": 0.1135,
      "step": 8368
    },
    {
      "epoch": 1.9230238970588234,
      "grad_norm": 1.3454954624176025,
      "learning_rate": 6.839767156862745e-06,
      "loss": 0.0739,
      "step": 8369
    },
    {
      "epoch": 1.9232536764705883,
      "grad_norm": 1.9357892274856567,
      "learning_rate": 6.8392565359477124e-06,
      "loss": 0.121,
      "step": 8370
    },
    {
      "epoch": 1.9234834558823528,
      "grad_norm": 1.1281006336212158,
      "learning_rate": 6.83874591503268e-06,
      "loss": 0.0699,
      "step": 8371
    },
    {
      "epoch": 1.9237132352941178,
      "grad_norm": 1.8792047500610352,
      "learning_rate": 6.838235294117648e-06,
      "loss": 0.0771,
      "step": 8372
    },
    {
      "epoch": 1.9239430147058822,
      "grad_norm": 1.9770179986953735,
      "learning_rate": 6.837724673202615e-06,
      "loss": 0.1086,
      "step": 8373
    },
    {
      "epoch": 1.9241727941176472,
      "grad_norm": 1.4231204986572266,
      "learning_rate": 6.837214052287582e-06,
      "loss": 0.0721,
      "step": 8374
    },
    {
      "epoch": 1.9244025735294117,
      "grad_norm": 1.9559985399246216,
      "learning_rate": 6.83670343137255e-06,
      "loss": 0.12,
      "step": 8375
    },
    {
      "epoch": 1.9246323529411766,
      "grad_norm": 1.4965885877609253,
      "learning_rate": 6.836192810457517e-06,
      "loss": 0.105,
      "step": 8376
    },
    {
      "epoch": 1.9248621323529411,
      "grad_norm": 1.413492202758789,
      "learning_rate": 6.835682189542484e-06,
      "loss": 0.0924,
      "step": 8377
    },
    {
      "epoch": 1.9250919117647058,
      "grad_norm": 1.605448603630066,
      "learning_rate": 6.835171568627451e-06,
      "loss": 0.1074,
      "step": 8378
    },
    {
      "epoch": 1.9253216911764706,
      "grad_norm": 1.8940167427062988,
      "learning_rate": 6.834660947712419e-06,
      "loss": 0.1181,
      "step": 8379
    },
    {
      "epoch": 1.9255514705882353,
      "grad_norm": 1.6268396377563477,
      "learning_rate": 6.834150326797386e-06,
      "loss": 0.091,
      "step": 8380
    },
    {
      "epoch": 1.92578125,
      "grad_norm": 1.4456342458724976,
      "learning_rate": 6.833639705882353e-06,
      "loss": 0.0722,
      "step": 8381
    },
    {
      "epoch": 1.9260110294117647,
      "grad_norm": 1.611770749092102,
      "learning_rate": 6.83312908496732e-06,
      "loss": 0.132,
      "step": 8382
    },
    {
      "epoch": 1.9262408088235294,
      "grad_norm": 1.6905685663223267,
      "learning_rate": 6.832618464052289e-06,
      "loss": 0.1301,
      "step": 8383
    },
    {
      "epoch": 1.9264705882352942,
      "grad_norm": 1.8179550170898438,
      "learning_rate": 6.832107843137256e-06,
      "loss": 0.1075,
      "step": 8384
    },
    {
      "epoch": 1.9267003676470589,
      "grad_norm": 1.9013664722442627,
      "learning_rate": 6.831597222222223e-06,
      "loss": 0.1254,
      "step": 8385
    },
    {
      "epoch": 1.9269301470588234,
      "grad_norm": 1.5725464820861816,
      "learning_rate": 6.83108660130719e-06,
      "loss": 0.1311,
      "step": 8386
    },
    {
      "epoch": 1.9271599264705883,
      "grad_norm": 1.9369444847106934,
      "learning_rate": 6.830575980392158e-06,
      "loss": 0.0823,
      "step": 8387
    },
    {
      "epoch": 1.9273897058823528,
      "grad_norm": 1.2760920524597168,
      "learning_rate": 6.830065359477125e-06,
      "loss": 0.0868,
      "step": 8388
    },
    {
      "epoch": 1.9276194852941178,
      "grad_norm": 2.6837856769561768,
      "learning_rate": 6.829554738562092e-06,
      "loss": 0.1308,
      "step": 8389
    },
    {
      "epoch": 1.9278492647058822,
      "grad_norm": 1.275029182434082,
      "learning_rate": 6.829044117647059e-06,
      "loss": 0.0922,
      "step": 8390
    },
    {
      "epoch": 1.9280790441176472,
      "grad_norm": 1.2462114095687866,
      "learning_rate": 6.828533496732027e-06,
      "loss": 0.0693,
      "step": 8391
    },
    {
      "epoch": 1.9283088235294117,
      "grad_norm": 2.011544704437256,
      "learning_rate": 6.828022875816994e-06,
      "loss": 0.1607,
      "step": 8392
    },
    {
      "epoch": 1.9285386029411766,
      "grad_norm": 1.5407851934432983,
      "learning_rate": 6.827512254901961e-06,
      "loss": 0.0811,
      "step": 8393
    },
    {
      "epoch": 1.9287683823529411,
      "grad_norm": 1.2283878326416016,
      "learning_rate": 6.827001633986928e-06,
      "loss": 0.0808,
      "step": 8394
    },
    {
      "epoch": 1.9289981617647058,
      "grad_norm": 1.9803963899612427,
      "learning_rate": 6.826491013071896e-06,
      "loss": 0.1391,
      "step": 8395
    },
    {
      "epoch": 1.9292279411764706,
      "grad_norm": 1.7209564447402954,
      "learning_rate": 6.825980392156863e-06,
      "loss": 0.1376,
      "step": 8396
    },
    {
      "epoch": 1.9294577205882353,
      "grad_norm": 1.6555465459823608,
      "learning_rate": 6.82546977124183e-06,
      "loss": 0.097,
      "step": 8397
    },
    {
      "epoch": 1.9296875,
      "grad_norm": 1.6976053714752197,
      "learning_rate": 6.824959150326797e-06,
      "loss": 0.1117,
      "step": 8398
    },
    {
      "epoch": 1.9299172794117647,
      "grad_norm": 1.58140230178833,
      "learning_rate": 6.824448529411766e-06,
      "loss": 0.1191,
      "step": 8399
    },
    {
      "epoch": 1.9301470588235294,
      "grad_norm": 1.4995992183685303,
      "learning_rate": 6.823937908496733e-06,
      "loss": 0.0898,
      "step": 8400
    },
    {
      "epoch": 1.9303768382352942,
      "grad_norm": 1.421573281288147,
      "learning_rate": 6.8234272875817e-06,
      "loss": 0.0825,
      "step": 8401
    },
    {
      "epoch": 1.9306066176470589,
      "grad_norm": 1.8673385381698608,
      "learning_rate": 6.822916666666667e-06,
      "loss": 0.1255,
      "step": 8402
    },
    {
      "epoch": 1.9308363970588234,
      "grad_norm": 1.5932823419570923,
      "learning_rate": 6.822406045751635e-06,
      "loss": 0.0931,
      "step": 8403
    },
    {
      "epoch": 1.9310661764705883,
      "grad_norm": 1.2543017864227295,
      "learning_rate": 6.821895424836602e-06,
      "loss": 0.0559,
      "step": 8404
    },
    {
      "epoch": 1.9312959558823528,
      "grad_norm": 1.5201480388641357,
      "learning_rate": 6.821384803921569e-06,
      "loss": 0.0976,
      "step": 8405
    },
    {
      "epoch": 1.9315257352941178,
      "grad_norm": 2.0656044483184814,
      "learning_rate": 6.820874183006536e-06,
      "loss": 0.1083,
      "step": 8406
    },
    {
      "epoch": 1.9317555147058822,
      "grad_norm": 1.5609074831008911,
      "learning_rate": 6.820363562091505e-06,
      "loss": 0.0798,
      "step": 8407
    },
    {
      "epoch": 1.9319852941176472,
      "grad_norm": 1.4262694120407104,
      "learning_rate": 6.819852941176472e-06,
      "loss": 0.108,
      "step": 8408
    },
    {
      "epoch": 1.9322150735294117,
      "grad_norm": 1.3574917316436768,
      "learning_rate": 6.819342320261439e-06,
      "loss": 0.0922,
      "step": 8409
    },
    {
      "epoch": 1.9324448529411766,
      "grad_norm": 1.8890631198883057,
      "learning_rate": 6.818831699346406e-06,
      "loss": 0.1044,
      "step": 8410
    },
    {
      "epoch": 1.9326746323529411,
      "grad_norm": 1.4888756275177002,
      "learning_rate": 6.8183210784313736e-06,
      "loss": 0.1215,
      "step": 8411
    },
    {
      "epoch": 1.9329044117647058,
      "grad_norm": 1.618952989578247,
      "learning_rate": 6.817810457516341e-06,
      "loss": 0.12,
      "step": 8412
    },
    {
      "epoch": 1.9331341911764706,
      "grad_norm": 1.7261680364608765,
      "learning_rate": 6.817299836601308e-06,
      "loss": 0.1192,
      "step": 8413
    },
    {
      "epoch": 1.9333639705882353,
      "grad_norm": 1.9459922313690186,
      "learning_rate": 6.816789215686275e-06,
      "loss": 0.1375,
      "step": 8414
    },
    {
      "epoch": 1.93359375,
      "grad_norm": 1.3486769199371338,
      "learning_rate": 6.8162785947712425e-06,
      "loss": 0.0935,
      "step": 8415
    },
    {
      "epoch": 1.9338235294117647,
      "grad_norm": 1.2749359607696533,
      "learning_rate": 6.81576797385621e-06,
      "loss": 0.0997,
      "step": 8416
    },
    {
      "epoch": 1.9340533088235294,
      "grad_norm": 1.985746145248413,
      "learning_rate": 6.815257352941177e-06,
      "loss": 0.1184,
      "step": 8417
    },
    {
      "epoch": 1.9342830882352942,
      "grad_norm": 1.6346256732940674,
      "learning_rate": 6.814746732026144e-06,
      "loss": 0.1024,
      "step": 8418
    },
    {
      "epoch": 1.9345128676470589,
      "grad_norm": 1.330930233001709,
      "learning_rate": 6.814236111111112e-06,
      "loss": 0.1061,
      "step": 8419
    },
    {
      "epoch": 1.9347426470588234,
      "grad_norm": 1.508561611175537,
      "learning_rate": 6.813725490196079e-06,
      "loss": 0.0941,
      "step": 8420
    },
    {
      "epoch": 1.9349724264705883,
      "grad_norm": 1.8084464073181152,
      "learning_rate": 6.813214869281046e-06,
      "loss": 0.1438,
      "step": 8421
    },
    {
      "epoch": 1.9352022058823528,
      "grad_norm": 1.4358173608779907,
      "learning_rate": 6.812704248366013e-06,
      "loss": 0.1064,
      "step": 8422
    },
    {
      "epoch": 1.9354319852941178,
      "grad_norm": 1.5303014516830444,
      "learning_rate": 6.812193627450981e-06,
      "loss": 0.0969,
      "step": 8423
    },
    {
      "epoch": 1.9356617647058822,
      "grad_norm": 1.5754063129425049,
      "learning_rate": 6.811683006535948e-06,
      "loss": 0.1096,
      "step": 8424
    },
    {
      "epoch": 1.9358915441176472,
      "grad_norm": 1.466422200202942,
      "learning_rate": 6.811172385620915e-06,
      "loss": 0.1253,
      "step": 8425
    },
    {
      "epoch": 1.9361213235294117,
      "grad_norm": 1.5395435094833374,
      "learning_rate": 6.810661764705882e-06,
      "loss": 0.1049,
      "step": 8426
    },
    {
      "epoch": 1.9363511029411766,
      "grad_norm": 1.4365601539611816,
      "learning_rate": 6.810151143790851e-06,
      "loss": 0.0875,
      "step": 8427
    },
    {
      "epoch": 1.9365808823529411,
      "grad_norm": 1.9136180877685547,
      "learning_rate": 6.809640522875818e-06,
      "loss": 0.1198,
      "step": 8428
    },
    {
      "epoch": 1.9368106617647058,
      "grad_norm": 1.6588691473007202,
      "learning_rate": 6.809129901960785e-06,
      "loss": 0.0954,
      "step": 8429
    },
    {
      "epoch": 1.9370404411764706,
      "grad_norm": 1.6187852621078491,
      "learning_rate": 6.808619281045752e-06,
      "loss": 0.0955,
      "step": 8430
    },
    {
      "epoch": 1.9372702205882353,
      "grad_norm": 1.5086225271224976,
      "learning_rate": 6.80810866013072e-06,
      "loss": 0.1234,
      "step": 8431
    },
    {
      "epoch": 1.9375,
      "grad_norm": 1.6420074701309204,
      "learning_rate": 6.807598039215687e-06,
      "loss": 0.0874,
      "step": 8432
    },
    {
      "epoch": 1.9377297794117647,
      "grad_norm": 1.482954502105713,
      "learning_rate": 6.807087418300654e-06,
      "loss": 0.11,
      "step": 8433
    },
    {
      "epoch": 1.9379595588235294,
      "grad_norm": 2.4086403846740723,
      "learning_rate": 6.806576797385621e-06,
      "loss": 0.1357,
      "step": 8434
    },
    {
      "epoch": 1.9381893382352942,
      "grad_norm": 3.235311985015869,
      "learning_rate": 6.8060661764705895e-06,
      "loss": 0.1989,
      "step": 8435
    },
    {
      "epoch": 1.9384191176470589,
      "grad_norm": 2.016721487045288,
      "learning_rate": 6.8055555555555566e-06,
      "loss": 0.1207,
      "step": 8436
    },
    {
      "epoch": 1.9386488970588234,
      "grad_norm": 1.2447997331619263,
      "learning_rate": 6.8050449346405236e-06,
      "loss": 0.0618,
      "step": 8437
    },
    {
      "epoch": 1.9388786764705883,
      "grad_norm": 1.7419286966323853,
      "learning_rate": 6.804534313725491e-06,
      "loss": 0.1127,
      "step": 8438
    },
    {
      "epoch": 1.9391084558823528,
      "grad_norm": 1.6639827489852905,
      "learning_rate": 6.8040236928104584e-06,
      "loss": 0.1196,
      "step": 8439
    },
    {
      "epoch": 1.9393382352941178,
      "grad_norm": 1.8626573085784912,
      "learning_rate": 6.8035130718954255e-06,
      "loss": 0.1031,
      "step": 8440
    },
    {
      "epoch": 1.9395680147058822,
      "grad_norm": 1.5192193984985352,
      "learning_rate": 6.8030024509803925e-06,
      "loss": 0.097,
      "step": 8441
    },
    {
      "epoch": 1.9397977941176472,
      "grad_norm": 1.563469648361206,
      "learning_rate": 6.8024918300653595e-06,
      "loss": 0.101,
      "step": 8442
    },
    {
      "epoch": 1.9400275735294117,
      "grad_norm": 1.7829259634017944,
      "learning_rate": 6.801981209150328e-06,
      "loss": 0.1263,
      "step": 8443
    },
    {
      "epoch": 1.9402573529411766,
      "grad_norm": 1.4208263158798218,
      "learning_rate": 6.801470588235295e-06,
      "loss": 0.0734,
      "step": 8444
    },
    {
      "epoch": 1.9404871323529411,
      "grad_norm": 1.2757794857025146,
      "learning_rate": 6.800959967320262e-06,
      "loss": 0.0932,
      "step": 8445
    },
    {
      "epoch": 1.9407169117647058,
      "grad_norm": 1.8343075513839722,
      "learning_rate": 6.800449346405229e-06,
      "loss": 0.1119,
      "step": 8446
    },
    {
      "epoch": 1.9409466911764706,
      "grad_norm": 1.3680349588394165,
      "learning_rate": 6.799938725490197e-06,
      "loss": 0.078,
      "step": 8447
    },
    {
      "epoch": 1.9411764705882353,
      "grad_norm": 1.3008427619934082,
      "learning_rate": 6.799428104575164e-06,
      "loss": 0.0976,
      "step": 8448
    },
    {
      "epoch": 1.94140625,
      "grad_norm": 1.4454615116119385,
      "learning_rate": 6.798917483660131e-06,
      "loss": 0.085,
      "step": 8449
    },
    {
      "epoch": 1.9416360294117647,
      "grad_norm": 2.118518114089966,
      "learning_rate": 6.798406862745098e-06,
      "loss": 0.1394,
      "step": 8450
    },
    {
      "epoch": 1.9418658088235294,
      "grad_norm": 2.086435317993164,
      "learning_rate": 6.797896241830067e-06,
      "loss": 0.1086,
      "step": 8451
    },
    {
      "epoch": 1.9420955882352942,
      "grad_norm": 2.528874397277832,
      "learning_rate": 6.797385620915034e-06,
      "loss": 0.1497,
      "step": 8452
    },
    {
      "epoch": 1.9423253676470589,
      "grad_norm": 1.4082204103469849,
      "learning_rate": 6.796875000000001e-06,
      "loss": 0.0842,
      "step": 8453
    },
    {
      "epoch": 1.9425551470588234,
      "grad_norm": 1.8372305631637573,
      "learning_rate": 6.796364379084968e-06,
      "loss": 0.1384,
      "step": 8454
    },
    {
      "epoch": 1.9427849264705883,
      "grad_norm": 2.320223093032837,
      "learning_rate": 6.795853758169935e-06,
      "loss": 0.0835,
      "step": 8455
    },
    {
      "epoch": 1.9430147058823528,
      "grad_norm": 1.408187747001648,
      "learning_rate": 6.795343137254903e-06,
      "loss": 0.092,
      "step": 8456
    },
    {
      "epoch": 1.9432444852941178,
      "grad_norm": 1.9387987852096558,
      "learning_rate": 6.79483251633987e-06,
      "loss": 0.1179,
      "step": 8457
    },
    {
      "epoch": 1.9434742647058822,
      "grad_norm": 2.0199368000030518,
      "learning_rate": 6.794321895424837e-06,
      "loss": 0.1247,
      "step": 8458
    },
    {
      "epoch": 1.9437040441176472,
      "grad_norm": 1.847177505493164,
      "learning_rate": 6.793811274509804e-06,
      "loss": 0.1215,
      "step": 8459
    },
    {
      "epoch": 1.9439338235294117,
      "grad_norm": 1.7026914358139038,
      "learning_rate": 6.793300653594772e-06,
      "loss": 0.1411,
      "step": 8460
    },
    {
      "epoch": 1.9441636029411766,
      "grad_norm": 1.4958244562149048,
      "learning_rate": 6.7927900326797395e-06,
      "loss": 0.0835,
      "step": 8461
    },
    {
      "epoch": 1.9443933823529411,
      "grad_norm": 1.843078374862671,
      "learning_rate": 6.7922794117647066e-06,
      "loss": 0.0876,
      "step": 8462
    },
    {
      "epoch": 1.9446231617647058,
      "grad_norm": 1.5531574487686157,
      "learning_rate": 6.7917687908496736e-06,
      "loss": 0.1144,
      "step": 8463
    },
    {
      "epoch": 1.9448529411764706,
      "grad_norm": 1.2974320650100708,
      "learning_rate": 6.7912581699346414e-06,
      "loss": 0.0788,
      "step": 8464
    },
    {
      "epoch": 1.9450827205882353,
      "grad_norm": 1.7333952188491821,
      "learning_rate": 6.7907475490196084e-06,
      "loss": 0.059,
      "step": 8465
    },
    {
      "epoch": 1.9453125,
      "grad_norm": 1.77727210521698,
      "learning_rate": 6.7902369281045755e-06,
      "loss": 0.0905,
      "step": 8466
    },
    {
      "epoch": 1.9455422794117647,
      "grad_norm": 1.922052264213562,
      "learning_rate": 6.7897263071895425e-06,
      "loss": 0.0865,
      "step": 8467
    },
    {
      "epoch": 1.9457720588235294,
      "grad_norm": 2.018768072128296,
      "learning_rate": 6.78921568627451e-06,
      "loss": 0.1367,
      "step": 8468
    },
    {
      "epoch": 1.9460018382352942,
      "grad_norm": 1.4422519207000732,
      "learning_rate": 6.788705065359477e-06,
      "loss": 0.129,
      "step": 8469
    },
    {
      "epoch": 1.9462316176470589,
      "grad_norm": 1.6030385494232178,
      "learning_rate": 6.788194444444444e-06,
      "loss": 0.0613,
      "step": 8470
    },
    {
      "epoch": 1.9464613970588234,
      "grad_norm": 1.6978700160980225,
      "learning_rate": 6.787683823529411e-06,
      "loss": 0.1267,
      "step": 8471
    },
    {
      "epoch": 1.9466911764705883,
      "grad_norm": 2.5489509105682373,
      "learning_rate": 6.78717320261438e-06,
      "loss": 0.0955,
      "step": 8472
    },
    {
      "epoch": 1.9469209558823528,
      "grad_norm": 1.5128730535507202,
      "learning_rate": 6.786662581699347e-06,
      "loss": 0.1115,
      "step": 8473
    },
    {
      "epoch": 1.9471507352941178,
      "grad_norm": 1.6124560832977295,
      "learning_rate": 6.786151960784314e-06,
      "loss": 0.0842,
      "step": 8474
    },
    {
      "epoch": 1.9473805147058822,
      "grad_norm": 1.8317632675170898,
      "learning_rate": 6.785641339869281e-06,
      "loss": 0.1143,
      "step": 8475
    },
    {
      "epoch": 1.9476102941176472,
      "grad_norm": 2.4174141883850098,
      "learning_rate": 6.785130718954249e-06,
      "loss": 0.1253,
      "step": 8476
    },
    {
      "epoch": 1.9478400735294117,
      "grad_norm": 1.7800366878509521,
      "learning_rate": 6.784620098039216e-06,
      "loss": 0.1014,
      "step": 8477
    },
    {
      "epoch": 1.9480698529411766,
      "grad_norm": 1.6756410598754883,
      "learning_rate": 6.784109477124183e-06,
      "loss": 0.1028,
      "step": 8478
    },
    {
      "epoch": 1.9482996323529411,
      "grad_norm": 1.8343173265457153,
      "learning_rate": 6.78359885620915e-06,
      "loss": 0.0844,
      "step": 8479
    },
    {
      "epoch": 1.9485294117647058,
      "grad_norm": 1.9067022800445557,
      "learning_rate": 6.783088235294119e-06,
      "loss": 0.1221,
      "step": 8480
    },
    {
      "epoch": 1.9487591911764706,
      "grad_norm": 1.8880314826965332,
      "learning_rate": 6.782577614379086e-06,
      "loss": 0.1607,
      "step": 8481
    },
    {
      "epoch": 1.9489889705882353,
      "grad_norm": 2.088663339614868,
      "learning_rate": 6.782066993464053e-06,
      "loss": 0.134,
      "step": 8482
    },
    {
      "epoch": 1.94921875,
      "grad_norm": 1.1806713342666626,
      "learning_rate": 6.78155637254902e-06,
      "loss": 0.0701,
      "step": 8483
    },
    {
      "epoch": 1.9494485294117647,
      "grad_norm": 1.8790149688720703,
      "learning_rate": 6.781045751633988e-06,
      "loss": 0.1266,
      "step": 8484
    },
    {
      "epoch": 1.9496783088235294,
      "grad_norm": 1.4599827527999878,
      "learning_rate": 6.780535130718955e-06,
      "loss": 0.0889,
      "step": 8485
    },
    {
      "epoch": 1.9499080882352942,
      "grad_norm": 1.8540828227996826,
      "learning_rate": 6.780024509803922e-06,
      "loss": 0.0959,
      "step": 8486
    },
    {
      "epoch": 1.9501378676470589,
      "grad_norm": 2.083038330078125,
      "learning_rate": 6.779513888888889e-06,
      "loss": 0.1284,
      "step": 8487
    },
    {
      "epoch": 1.9503676470588234,
      "grad_norm": 1.8067642450332642,
      "learning_rate": 6.779003267973857e-06,
      "loss": 0.1241,
      "step": 8488
    },
    {
      "epoch": 1.9505974264705883,
      "grad_norm": 1.5352822542190552,
      "learning_rate": 6.778492647058824e-06,
      "loss": 0.0778,
      "step": 8489
    },
    {
      "epoch": 1.9508272058823528,
      "grad_norm": 1.385507345199585,
      "learning_rate": 6.7779820261437914e-06,
      "loss": 0.0905,
      "step": 8490
    },
    {
      "epoch": 1.9510569852941178,
      "grad_norm": 1.8880208730697632,
      "learning_rate": 6.7774714052287584e-06,
      "loss": 0.1049,
      "step": 8491
    },
    {
      "epoch": 1.9512867647058822,
      "grad_norm": 1.4806021451950073,
      "learning_rate": 6.776960784313726e-06,
      "loss": 0.1189,
      "step": 8492
    },
    {
      "epoch": 1.9515165441176472,
      "grad_norm": 2.233072280883789,
      "learning_rate": 6.776450163398693e-06,
      "loss": 0.0918,
      "step": 8493
    },
    {
      "epoch": 1.9517463235294117,
      "grad_norm": 1.8749046325683594,
      "learning_rate": 6.77593954248366e-06,
      "loss": 0.0824,
      "step": 8494
    },
    {
      "epoch": 1.9519761029411766,
      "grad_norm": 1.5406994819641113,
      "learning_rate": 6.775428921568627e-06,
      "loss": 0.0902,
      "step": 8495
    },
    {
      "epoch": 1.9522058823529411,
      "grad_norm": 1.3301602602005005,
      "learning_rate": 6.774918300653596e-06,
      "loss": 0.0746,
      "step": 8496
    },
    {
      "epoch": 1.9524356617647058,
      "grad_norm": 1.3310110569000244,
      "learning_rate": 6.774407679738563e-06,
      "loss": 0.0928,
      "step": 8497
    },
    {
      "epoch": 1.9526654411764706,
      "grad_norm": 1.4617551565170288,
      "learning_rate": 6.77389705882353e-06,
      "loss": 0.0611,
      "step": 8498
    },
    {
      "epoch": 1.9528952205882353,
      "grad_norm": 2.0316576957702637,
      "learning_rate": 6.773386437908497e-06,
      "loss": 0.146,
      "step": 8499
    },
    {
      "epoch": 1.953125,
      "grad_norm": 2.0804972648620605,
      "learning_rate": 6.772875816993465e-06,
      "loss": 0.0775,
      "step": 8500
    },
    {
      "epoch": 1.953125,
      "eval_loss": 0.10822968184947968,
      "eval_runtime": 420.798,
      "eval_samples_per_second": 21.165,
      "eval_steps_per_second": 10.582,
      "step": 8500
    },
    {
      "epoch": 1.9533547794117647,
      "grad_norm": 1.4428787231445312,
      "learning_rate": 6.772365196078432e-06,
      "loss": 0.0952,
      "step": 8501
    },
    {
      "epoch": 1.9535845588235294,
      "grad_norm": 2.643157720565796,
      "learning_rate": 6.771854575163399e-06,
      "loss": 0.1123,
      "step": 8502
    },
    {
      "epoch": 1.9538143382352942,
      "grad_norm": 1.461302399635315,
      "learning_rate": 6.771343954248366e-06,
      "loss": 0.1159,
      "step": 8503
    },
    {
      "epoch": 1.9540441176470589,
      "grad_norm": 1.5763897895812988,
      "learning_rate": 6.770833333333334e-06,
      "loss": 0.0996,
      "step": 8504
    },
    {
      "epoch": 1.9542738970588234,
      "grad_norm": 1.7360138893127441,
      "learning_rate": 6.770322712418301e-06,
      "loss": 0.0949,
      "step": 8505
    },
    {
      "epoch": 1.9545036764705883,
      "grad_norm": 1.7308008670806885,
      "learning_rate": 6.769812091503269e-06,
      "loss": 0.083,
      "step": 8506
    },
    {
      "epoch": 1.9547334558823528,
      "grad_norm": 2.6197922229766846,
      "learning_rate": 6.769301470588236e-06,
      "loss": 0.0683,
      "step": 8507
    },
    {
      "epoch": 1.9549632352941178,
      "grad_norm": 2.1445202827453613,
      "learning_rate": 6.768790849673204e-06,
      "loss": 0.1011,
      "step": 8508
    },
    {
      "epoch": 1.9551930147058822,
      "grad_norm": 1.2654138803482056,
      "learning_rate": 6.768280228758171e-06,
      "loss": 0.0945,
      "step": 8509
    },
    {
      "epoch": 1.9554227941176472,
      "grad_norm": 1.8986318111419678,
      "learning_rate": 6.767769607843138e-06,
      "loss": 0.1025,
      "step": 8510
    },
    {
      "epoch": 1.9556525735294117,
      "grad_norm": 1.7057242393493652,
      "learning_rate": 6.767258986928105e-06,
      "loss": 0.1067,
      "step": 8511
    },
    {
      "epoch": 1.9558823529411766,
      "grad_norm": 1.7101072072982788,
      "learning_rate": 6.7667483660130725e-06,
      "loss": 0.1025,
      "step": 8512
    },
    {
      "epoch": 1.9561121323529411,
      "grad_norm": 2.118162155151367,
      "learning_rate": 6.7662377450980395e-06,
      "loss": 0.1069,
      "step": 8513
    },
    {
      "epoch": 1.9563419117647058,
      "grad_norm": 1.9700651168823242,
      "learning_rate": 6.7657271241830066e-06,
      "loss": 0.1073,
      "step": 8514
    },
    {
      "epoch": 1.9565716911764706,
      "grad_norm": 1.774594783782959,
      "learning_rate": 6.7652165032679736e-06,
      "loss": 0.0945,
      "step": 8515
    },
    {
      "epoch": 1.9568014705882353,
      "grad_norm": 2.3139617443084717,
      "learning_rate": 6.764705882352942e-06,
      "loss": 0.1543,
      "step": 8516
    },
    {
      "epoch": 1.95703125,
      "grad_norm": 1.916560411453247,
      "learning_rate": 6.764195261437909e-06,
      "loss": 0.0835,
      "step": 8517
    },
    {
      "epoch": 1.9572610294117647,
      "grad_norm": 1.6954175233840942,
      "learning_rate": 6.763684640522876e-06,
      "loss": 0.1133,
      "step": 8518
    },
    {
      "epoch": 1.9574908088235294,
      "grad_norm": 1.4670778512954712,
      "learning_rate": 6.763174019607843e-06,
      "loss": 0.0683,
      "step": 8519
    },
    {
      "epoch": 1.9577205882352942,
      "grad_norm": 2.125781536102295,
      "learning_rate": 6.762663398692811e-06,
      "loss": 0.1245,
      "step": 8520
    },
    {
      "epoch": 1.9579503676470589,
      "grad_norm": 1.6713603734970093,
      "learning_rate": 6.762152777777778e-06,
      "loss": 0.0749,
      "step": 8521
    },
    {
      "epoch": 1.9581801470588234,
      "grad_norm": 1.6326240301132202,
      "learning_rate": 6.761642156862745e-06,
      "loss": 0.0941,
      "step": 8522
    },
    {
      "epoch": 1.9584099264705883,
      "grad_norm": 2.089728832244873,
      "learning_rate": 6.761131535947712e-06,
      "loss": 0.0864,
      "step": 8523
    },
    {
      "epoch": 1.9586397058823528,
      "grad_norm": 2.2893221378326416,
      "learning_rate": 6.760620915032681e-06,
      "loss": 0.0842,
      "step": 8524
    },
    {
      "epoch": 1.9588694852941178,
      "grad_norm": 1.78739333152771,
      "learning_rate": 6.760110294117648e-06,
      "loss": 0.0711,
      "step": 8525
    },
    {
      "epoch": 1.9590992647058822,
      "grad_norm": 1.376067876815796,
      "learning_rate": 6.759599673202615e-06,
      "loss": 0.0849,
      "step": 8526
    },
    {
      "epoch": 1.9593290441176472,
      "grad_norm": 1.6208038330078125,
      "learning_rate": 6.759089052287582e-06,
      "loss": 0.1099,
      "step": 8527
    },
    {
      "epoch": 1.9595588235294117,
      "grad_norm": 2.2820491790771484,
      "learning_rate": 6.75857843137255e-06,
      "loss": 0.1012,
      "step": 8528
    },
    {
      "epoch": 1.9597886029411766,
      "grad_norm": 1.3873984813690186,
      "learning_rate": 6.758067810457517e-06,
      "loss": 0.0649,
      "step": 8529
    },
    {
      "epoch": 1.9600183823529411,
      "grad_norm": 2.027008533477783,
      "learning_rate": 6.757557189542484e-06,
      "loss": 0.125,
      "step": 8530
    },
    {
      "epoch": 1.9602481617647058,
      "grad_norm": 1.6297324895858765,
      "learning_rate": 6.757046568627451e-06,
      "loss": 0.0819,
      "step": 8531
    },
    {
      "epoch": 1.9604779411764706,
      "grad_norm": 1.6827116012573242,
      "learning_rate": 6.75653594771242e-06,
      "loss": 0.1087,
      "step": 8532
    },
    {
      "epoch": 1.9607077205882353,
      "grad_norm": 1.4914360046386719,
      "learning_rate": 6.756025326797387e-06,
      "loss": 0.1143,
      "step": 8533
    },
    {
      "epoch": 1.9609375,
      "grad_norm": 1.6864882707595825,
      "learning_rate": 6.755514705882354e-06,
      "loss": 0.1029,
      "step": 8534
    },
    {
      "epoch": 1.9611672794117647,
      "grad_norm": 1.2314767837524414,
      "learning_rate": 6.755004084967321e-06,
      "loss": 0.0823,
      "step": 8535
    },
    {
      "epoch": 1.9613970588235294,
      "grad_norm": 1.5597786903381348,
      "learning_rate": 6.7544934640522885e-06,
      "loss": 0.0838,
      "step": 8536
    },
    {
      "epoch": 1.9616268382352942,
      "grad_norm": 2.1217241287231445,
      "learning_rate": 6.7539828431372555e-06,
      "loss": 0.1263,
      "step": 8537
    },
    {
      "epoch": 1.9618566176470589,
      "grad_norm": 1.3011857271194458,
      "learning_rate": 6.7534722222222225e-06,
      "loss": 0.0899,
      "step": 8538
    },
    {
      "epoch": 1.9620863970588234,
      "grad_norm": 1.5196847915649414,
      "learning_rate": 6.7529616013071895e-06,
      "loss": 0.1292,
      "step": 8539
    },
    {
      "epoch": 1.9623161764705883,
      "grad_norm": 1.2729895114898682,
      "learning_rate": 6.752450980392158e-06,
      "loss": 0.0964,
      "step": 8540
    },
    {
      "epoch": 1.9625459558823528,
      "grad_norm": 2.3102803230285645,
      "learning_rate": 6.751940359477125e-06,
      "loss": 0.1283,
      "step": 8541
    },
    {
      "epoch": 1.9627757352941178,
      "grad_norm": 2.003274917602539,
      "learning_rate": 6.751429738562092e-06,
      "loss": 0.12,
      "step": 8542
    },
    {
      "epoch": 1.9630055147058822,
      "grad_norm": 2.0306789875030518,
      "learning_rate": 6.750919117647059e-06,
      "loss": 0.1227,
      "step": 8543
    },
    {
      "epoch": 1.9632352941176472,
      "grad_norm": 1.5907139778137207,
      "learning_rate": 6.750408496732027e-06,
      "loss": 0.1139,
      "step": 8544
    },
    {
      "epoch": 1.9634650735294117,
      "grad_norm": 1.695924162864685,
      "learning_rate": 6.749897875816994e-06,
      "loss": 0.0972,
      "step": 8545
    },
    {
      "epoch": 1.9636948529411766,
      "grad_norm": 1.4710571765899658,
      "learning_rate": 6.749387254901961e-06,
      "loss": 0.1084,
      "step": 8546
    },
    {
      "epoch": 1.9639246323529411,
      "grad_norm": 2.389479637145996,
      "learning_rate": 6.748876633986928e-06,
      "loss": 0.1286,
      "step": 8547
    },
    {
      "epoch": 1.9641544117647058,
      "grad_norm": 1.4907567501068115,
      "learning_rate": 6.748366013071896e-06,
      "loss": 0.1125,
      "step": 8548
    },
    {
      "epoch": 1.9643841911764706,
      "grad_norm": 1.2958886623382568,
      "learning_rate": 6.747855392156863e-06,
      "loss": 0.0776,
      "step": 8549
    },
    {
      "epoch": 1.9646139705882353,
      "grad_norm": 1.5824240446090698,
      "learning_rate": 6.747344771241831e-06,
      "loss": 0.0949,
      "step": 8550
    },
    {
      "epoch": 1.96484375,
      "grad_norm": 1.4779022932052612,
      "learning_rate": 6.746834150326798e-06,
      "loss": 0.1091,
      "step": 8551
    },
    {
      "epoch": 1.9650735294117647,
      "grad_norm": 1.615222692489624,
      "learning_rate": 6.746323529411766e-06,
      "loss": 0.1142,
      "step": 8552
    },
    {
      "epoch": 1.9653033088235294,
      "grad_norm": 2.0617902278900146,
      "learning_rate": 6.745812908496733e-06,
      "loss": 0.1115,
      "step": 8553
    },
    {
      "epoch": 1.9655330882352942,
      "grad_norm": 1.4508886337280273,
      "learning_rate": 6.7453022875817e-06,
      "loss": 0.1366,
      "step": 8554
    },
    {
      "epoch": 1.9657628676470589,
      "grad_norm": 1.9436794519424438,
      "learning_rate": 6.744791666666667e-06,
      "loss": 0.131,
      "step": 8555
    },
    {
      "epoch": 1.9659926470588234,
      "grad_norm": 2.802980899810791,
      "learning_rate": 6.744281045751635e-06,
      "loss": 0.1553,
      "step": 8556
    },
    {
      "epoch": 1.9662224264705883,
      "grad_norm": 1.6848469972610474,
      "learning_rate": 6.743770424836602e-06,
      "loss": 0.1244,
      "step": 8557
    },
    {
      "epoch": 1.9664522058823528,
      "grad_norm": 1.595216155052185,
      "learning_rate": 6.743259803921569e-06,
      "loss": 0.1341,
      "step": 8558
    },
    {
      "epoch": 1.9666819852941178,
      "grad_norm": 1.3199964761734009,
      "learning_rate": 6.742749183006536e-06,
      "loss": 0.0781,
      "step": 8559
    },
    {
      "epoch": 1.9669117647058822,
      "grad_norm": 1.269290566444397,
      "learning_rate": 6.7422385620915045e-06,
      "loss": 0.0914,
      "step": 8560
    },
    {
      "epoch": 1.9671415441176472,
      "grad_norm": 1.4477853775024414,
      "learning_rate": 6.7417279411764715e-06,
      "loss": 0.0892,
      "step": 8561
    },
    {
      "epoch": 1.9673713235294117,
      "grad_norm": 1.8709951639175415,
      "learning_rate": 6.7412173202614385e-06,
      "loss": 0.115,
      "step": 8562
    },
    {
      "epoch": 1.9676011029411766,
      "grad_norm": 2.269219160079956,
      "learning_rate": 6.7407066993464055e-06,
      "loss": 0.1353,
      "step": 8563
    },
    {
      "epoch": 1.9678308823529411,
      "grad_norm": 1.5383210182189941,
      "learning_rate": 6.740196078431373e-06,
      "loss": 0.1114,
      "step": 8564
    },
    {
      "epoch": 1.9680606617647058,
      "grad_norm": 1.602583646774292,
      "learning_rate": 6.73968545751634e-06,
      "loss": 0.1116,
      "step": 8565
    },
    {
      "epoch": 1.9682904411764706,
      "grad_norm": 1.8542346954345703,
      "learning_rate": 6.739174836601307e-06,
      "loss": 0.0931,
      "step": 8566
    },
    {
      "epoch": 1.9685202205882353,
      "grad_norm": 2.057875394821167,
      "learning_rate": 6.738664215686274e-06,
      "loss": 0.1173,
      "step": 8567
    },
    {
      "epoch": 1.96875,
      "grad_norm": 1.4971227645874023,
      "learning_rate": 6.738153594771243e-06,
      "loss": 0.0804,
      "step": 8568
    },
    {
      "epoch": 1.9689797794117647,
      "grad_norm": 1.7704581022262573,
      "learning_rate": 6.73764297385621e-06,
      "loss": 0.1572,
      "step": 8569
    },
    {
      "epoch": 1.9692095588235294,
      "grad_norm": 1.7620114088058472,
      "learning_rate": 6.737132352941177e-06,
      "loss": 0.1091,
      "step": 8570
    },
    {
      "epoch": 1.9694393382352942,
      "grad_norm": 1.4202996492385864,
      "learning_rate": 6.736621732026144e-06,
      "loss": 0.0925,
      "step": 8571
    },
    {
      "epoch": 1.9696691176470589,
      "grad_norm": 1.378134846687317,
      "learning_rate": 6.736111111111112e-06,
      "loss": 0.0579,
      "step": 8572
    },
    {
      "epoch": 1.9698988970588234,
      "grad_norm": 1.691105604171753,
      "learning_rate": 6.735600490196079e-06,
      "loss": 0.1017,
      "step": 8573
    },
    {
      "epoch": 1.9701286764705883,
      "grad_norm": 1.8942863941192627,
      "learning_rate": 6.735089869281046e-06,
      "loss": 0.1535,
      "step": 8574
    },
    {
      "epoch": 1.9703584558823528,
      "grad_norm": 1.7676719427108765,
      "learning_rate": 6.734579248366013e-06,
      "loss": 0.0809,
      "step": 8575
    },
    {
      "epoch": 1.9705882352941178,
      "grad_norm": 1.7107473611831665,
      "learning_rate": 6.734068627450982e-06,
      "loss": 0.0749,
      "step": 8576
    },
    {
      "epoch": 1.9708180147058822,
      "grad_norm": 1.8263591527938843,
      "learning_rate": 6.733558006535949e-06,
      "loss": 0.1178,
      "step": 8577
    },
    {
      "epoch": 1.9710477941176472,
      "grad_norm": 1.3459813594818115,
      "learning_rate": 6.733047385620916e-06,
      "loss": 0.073,
      "step": 8578
    },
    {
      "epoch": 1.9712775735294117,
      "grad_norm": 1.5734384059906006,
      "learning_rate": 6.732536764705883e-06,
      "loss": 0.106,
      "step": 8579
    },
    {
      "epoch": 1.9715073529411766,
      "grad_norm": 1.4997286796569824,
      "learning_rate": 6.732026143790851e-06,
      "loss": 0.0929,
      "step": 8580
    },
    {
      "epoch": 1.9717371323529411,
      "grad_norm": 1.387565016746521,
      "learning_rate": 6.731515522875818e-06,
      "loss": 0.0929,
      "step": 8581
    },
    {
      "epoch": 1.9719669117647058,
      "grad_norm": 1.5115553140640259,
      "learning_rate": 6.731004901960785e-06,
      "loss": 0.0893,
      "step": 8582
    },
    {
      "epoch": 1.9721966911764706,
      "grad_norm": 1.6129170656204224,
      "learning_rate": 6.730494281045752e-06,
      "loss": 0.1037,
      "step": 8583
    },
    {
      "epoch": 1.9724264705882353,
      "grad_norm": 1.9760695695877075,
      "learning_rate": 6.7299836601307204e-06,
      "loss": 0.132,
      "step": 8584
    },
    {
      "epoch": 1.97265625,
      "grad_norm": 1.8255385160446167,
      "learning_rate": 6.7294730392156874e-06,
      "loss": 0.0912,
      "step": 8585
    },
    {
      "epoch": 1.9728860294117647,
      "grad_norm": 1.6801981925964355,
      "learning_rate": 6.7289624183006545e-06,
      "loss": 0.1218,
      "step": 8586
    },
    {
      "epoch": 1.9731158088235294,
      "grad_norm": 1.4450016021728516,
      "learning_rate": 6.7284517973856215e-06,
      "loss": 0.0681,
      "step": 8587
    },
    {
      "epoch": 1.9733455882352942,
      "grad_norm": 1.5813130140304565,
      "learning_rate": 6.727941176470589e-06,
      "loss": 0.111,
      "step": 8588
    },
    {
      "epoch": 1.9735753676470589,
      "grad_norm": 2.444239616394043,
      "learning_rate": 6.727430555555556e-06,
      "loss": 0.1483,
      "step": 8589
    },
    {
      "epoch": 1.9738051470588234,
      "grad_norm": 2.053189992904663,
      "learning_rate": 6.726919934640523e-06,
      "loss": 0.0878,
      "step": 8590
    },
    {
      "epoch": 1.9740349264705883,
      "grad_norm": 2.139188528060913,
      "learning_rate": 6.72640931372549e-06,
      "loss": 0.1136,
      "step": 8591
    },
    {
      "epoch": 1.9742647058823528,
      "grad_norm": 1.307700753211975,
      "learning_rate": 6.725898692810458e-06,
      "loss": 0.0623,
      "step": 8592
    },
    {
      "epoch": 1.9744944852941178,
      "grad_norm": 1.7628884315490723,
      "learning_rate": 6.725388071895425e-06,
      "loss": 0.1016,
      "step": 8593
    },
    {
      "epoch": 1.9747242647058822,
      "grad_norm": 2.0690577030181885,
      "learning_rate": 6.724877450980392e-06,
      "loss": 0.0999,
      "step": 8594
    },
    {
      "epoch": 1.9749540441176472,
      "grad_norm": 1.4939093589782715,
      "learning_rate": 6.72436683006536e-06,
      "loss": 0.0779,
      "step": 8595
    },
    {
      "epoch": 1.9751838235294117,
      "grad_norm": 2.008685350418091,
      "learning_rate": 6.723856209150328e-06,
      "loss": 0.124,
      "step": 8596
    },
    {
      "epoch": 1.9754136029411766,
      "grad_norm": 1.7835681438446045,
      "learning_rate": 6.723345588235295e-06,
      "loss": 0.1455,
      "step": 8597
    },
    {
      "epoch": 1.9756433823529411,
      "grad_norm": 1.752964735031128,
      "learning_rate": 6.722834967320262e-06,
      "loss": 0.1316,
      "step": 8598
    },
    {
      "epoch": 1.9758731617647058,
      "grad_norm": 1.5351049900054932,
      "learning_rate": 6.722324346405229e-06,
      "loss": 0.098,
      "step": 8599
    },
    {
      "epoch": 1.9761029411764706,
      "grad_norm": 1.4764597415924072,
      "learning_rate": 6.721813725490197e-06,
      "loss": 0.0809,
      "step": 8600
    },
    {
      "epoch": 1.9763327205882353,
      "grad_norm": 2.033173084259033,
      "learning_rate": 6.721303104575164e-06,
      "loss": 0.1266,
      "step": 8601
    },
    {
      "epoch": 1.9765625,
      "grad_norm": 1.417524814605713,
      "learning_rate": 6.720792483660131e-06,
      "loss": 0.084,
      "step": 8602
    },
    {
      "epoch": 1.9767922794117647,
      "grad_norm": 1.6377885341644287,
      "learning_rate": 6.720281862745098e-06,
      "loss": 0.0928,
      "step": 8603
    },
    {
      "epoch": 1.9770220588235294,
      "grad_norm": 1.842923879623413,
      "learning_rate": 6.719771241830067e-06,
      "loss": 0.1055,
      "step": 8604
    },
    {
      "epoch": 1.9772518382352942,
      "grad_norm": 1.6839821338653564,
      "learning_rate": 6.719260620915034e-06,
      "loss": 0.1191,
      "step": 8605
    },
    {
      "epoch": 1.9774816176470589,
      "grad_norm": 1.5708568096160889,
      "learning_rate": 6.718750000000001e-06,
      "loss": 0.1179,
      "step": 8606
    },
    {
      "epoch": 1.9777113970588234,
      "grad_norm": 1.9624645709991455,
      "learning_rate": 6.718239379084968e-06,
      "loss": 0.1089,
      "step": 8607
    },
    {
      "epoch": 1.9779411764705883,
      "grad_norm": 1.3133572340011597,
      "learning_rate": 6.717728758169935e-06,
      "loss": 0.0729,
      "step": 8608
    },
    {
      "epoch": 1.9781709558823528,
      "grad_norm": 2.0859737396240234,
      "learning_rate": 6.7172181372549026e-06,
      "loss": 0.109,
      "step": 8609
    },
    {
      "epoch": 1.9784007352941178,
      "grad_norm": 1.9469342231750488,
      "learning_rate": 6.71670751633987e-06,
      "loss": 0.085,
      "step": 8610
    },
    {
      "epoch": 1.9786305147058822,
      "grad_norm": 1.6115305423736572,
      "learning_rate": 6.716196895424837e-06,
      "loss": 0.1188,
      "step": 8611
    },
    {
      "epoch": 1.9788602941176472,
      "grad_norm": 1.4247444868087769,
      "learning_rate": 6.715686274509804e-06,
      "loss": 0.0929,
      "step": 8612
    },
    {
      "epoch": 1.9790900735294117,
      "grad_norm": 1.5114408731460571,
      "learning_rate": 6.715175653594772e-06,
      "loss": 0.0792,
      "step": 8613
    },
    {
      "epoch": 1.9793198529411766,
      "grad_norm": 1.4400238990783691,
      "learning_rate": 6.714665032679739e-06,
      "loss": 0.0927,
      "step": 8614
    },
    {
      "epoch": 1.9795496323529411,
      "grad_norm": 1.619426965713501,
      "learning_rate": 6.714154411764706e-06,
      "loss": 0.0812,
      "step": 8615
    },
    {
      "epoch": 1.9797794117647058,
      "grad_norm": 1.3013556003570557,
      "learning_rate": 6.713643790849673e-06,
      "loss": 0.0964,
      "step": 8616
    },
    {
      "epoch": 1.9800091911764706,
      "grad_norm": 2.2165637016296387,
      "learning_rate": 6.713133169934641e-06,
      "loss": 0.1382,
      "step": 8617
    },
    {
      "epoch": 1.9802389705882353,
      "grad_norm": 1.139304280281067,
      "learning_rate": 6.712622549019608e-06,
      "loss": 0.0744,
      "step": 8618
    },
    {
      "epoch": 1.98046875,
      "grad_norm": 1.6549441814422607,
      "learning_rate": 6.712111928104575e-06,
      "loss": 0.0998,
      "step": 8619
    },
    {
      "epoch": 1.9806985294117647,
      "grad_norm": 1.9258248805999756,
      "learning_rate": 6.711601307189542e-06,
      "loss": 0.1289,
      "step": 8620
    },
    {
      "epoch": 1.9809283088235294,
      "grad_norm": 1.7230533361434937,
      "learning_rate": 6.711090686274511e-06,
      "loss": 0.1102,
      "step": 8621
    },
    {
      "epoch": 1.9811580882352942,
      "grad_norm": 1.856122374534607,
      "learning_rate": 6.710580065359478e-06,
      "loss": 0.0955,
      "step": 8622
    },
    {
      "epoch": 1.9813878676470589,
      "grad_norm": 1.6270897388458252,
      "learning_rate": 6.710069444444445e-06,
      "loss": 0.1001,
      "step": 8623
    },
    {
      "epoch": 1.9816176470588234,
      "grad_norm": 1.7184765338897705,
      "learning_rate": 6.709558823529412e-06,
      "loss": 0.0709,
      "step": 8624
    },
    {
      "epoch": 1.9818474264705883,
      "grad_norm": 1.4251604080200195,
      "learning_rate": 6.70904820261438e-06,
      "loss": 0.0613,
      "step": 8625
    },
    {
      "epoch": 1.9820772058823528,
      "grad_norm": 1.8946797847747803,
      "learning_rate": 6.708537581699347e-06,
      "loss": 0.0973,
      "step": 8626
    },
    {
      "epoch": 1.9823069852941178,
      "grad_norm": 1.400194525718689,
      "learning_rate": 6.708026960784314e-06,
      "loss": 0.1344,
      "step": 8627
    },
    {
      "epoch": 1.9825367647058822,
      "grad_norm": 1.4358397722244263,
      "learning_rate": 6.707516339869281e-06,
      "loss": 0.08,
      "step": 8628
    },
    {
      "epoch": 1.9827665441176472,
      "grad_norm": 2.1034722328186035,
      "learning_rate": 6.70700571895425e-06,
      "loss": 0.0972,
      "step": 8629
    },
    {
      "epoch": 1.9829963235294117,
      "grad_norm": 2.117682933807373,
      "learning_rate": 6.706495098039217e-06,
      "loss": 0.1349,
      "step": 8630
    },
    {
      "epoch": 1.9832261029411766,
      "grad_norm": 1.6406878232955933,
      "learning_rate": 6.705984477124184e-06,
      "loss": 0.0818,
      "step": 8631
    },
    {
      "epoch": 1.9834558823529411,
      "grad_norm": 1.70314359664917,
      "learning_rate": 6.705473856209151e-06,
      "loss": 0.1007,
      "step": 8632
    },
    {
      "epoch": 1.9836856617647058,
      "grad_norm": 1.7648919820785522,
      "learning_rate": 6.7049632352941185e-06,
      "loss": 0.1258,
      "step": 8633
    },
    {
      "epoch": 1.9839154411764706,
      "grad_norm": 1.4192805290222168,
      "learning_rate": 6.7044526143790856e-06,
      "loss": 0.0988,
      "step": 8634
    },
    {
      "epoch": 1.9841452205882353,
      "grad_norm": 1.7930024862289429,
      "learning_rate": 6.7039419934640526e-06,
      "loss": 0.0978,
      "step": 8635
    },
    {
      "epoch": 1.984375,
      "grad_norm": 1.5353835821151733,
      "learning_rate": 6.70343137254902e-06,
      "loss": 0.1013,
      "step": 8636
    },
    {
      "epoch": 1.9846047794117647,
      "grad_norm": 1.6015019416809082,
      "learning_rate": 6.7029207516339874e-06,
      "loss": 0.0826,
      "step": 8637
    },
    {
      "epoch": 1.9848345588235294,
      "grad_norm": 1.5571423768997192,
      "learning_rate": 6.7024101307189545e-06,
      "loss": 0.1007,
      "step": 8638
    },
    {
      "epoch": 1.9850643382352942,
      "grad_norm": 1.57659912109375,
      "learning_rate": 6.701899509803922e-06,
      "loss": 0.1014,
      "step": 8639
    },
    {
      "epoch": 1.9852941176470589,
      "grad_norm": 2.050487518310547,
      "learning_rate": 6.701388888888889e-06,
      "loss": 0.1063,
      "step": 8640
    },
    {
      "epoch": 1.9855238970588234,
      "grad_norm": 2.1490471363067627,
      "learning_rate": 6.700878267973857e-06,
      "loss": 0.1201,
      "step": 8641
    },
    {
      "epoch": 1.9857536764705883,
      "grad_norm": 1.6291420459747314,
      "learning_rate": 6.700367647058824e-06,
      "loss": 0.0917,
      "step": 8642
    },
    {
      "epoch": 1.9859834558823528,
      "grad_norm": 1.7031832933425903,
      "learning_rate": 6.699857026143791e-06,
      "loss": 0.1009,
      "step": 8643
    },
    {
      "epoch": 1.9862132352941178,
      "grad_norm": 1.7088711261749268,
      "learning_rate": 6.699346405228758e-06,
      "loss": 0.1024,
      "step": 8644
    },
    {
      "epoch": 1.9864430147058822,
      "grad_norm": 1.5114409923553467,
      "learning_rate": 6.698835784313726e-06,
      "loss": 0.0823,
      "step": 8645
    },
    {
      "epoch": 1.9866727941176472,
      "grad_norm": 2.1032004356384277,
      "learning_rate": 6.698325163398693e-06,
      "loss": 0.1365,
      "step": 8646
    },
    {
      "epoch": 1.9869025735294117,
      "grad_norm": 2.07397198677063,
      "learning_rate": 6.69781454248366e-06,
      "loss": 0.1121,
      "step": 8647
    },
    {
      "epoch": 1.9871323529411766,
      "grad_norm": 1.564689040184021,
      "learning_rate": 6.697303921568627e-06,
      "loss": 0.0978,
      "step": 8648
    },
    {
      "epoch": 1.9873621323529411,
      "grad_norm": 1.6269017457962036,
      "learning_rate": 6.696793300653596e-06,
      "loss": 0.1163,
      "step": 8649
    },
    {
      "epoch": 1.9875919117647058,
      "grad_norm": 1.4252763986587524,
      "learning_rate": 6.696282679738563e-06,
      "loss": 0.0929,
      "step": 8650
    },
    {
      "epoch": 1.9878216911764706,
      "grad_norm": 2.3606419563293457,
      "learning_rate": 6.69577205882353e-06,
      "loss": 0.104,
      "step": 8651
    },
    {
      "epoch": 1.9880514705882353,
      "grad_norm": 1.6745229959487915,
      "learning_rate": 6.695261437908497e-06,
      "loss": 0.1185,
      "step": 8652
    },
    {
      "epoch": 1.98828125,
      "grad_norm": 2.2525057792663574,
      "learning_rate": 6.694750816993465e-06,
      "loss": 0.1454,
      "step": 8653
    },
    {
      "epoch": 1.9885110294117647,
      "grad_norm": 1.283547282218933,
      "learning_rate": 6.694240196078432e-06,
      "loss": 0.101,
      "step": 8654
    },
    {
      "epoch": 1.9887408088235294,
      "grad_norm": 2.198608636856079,
      "learning_rate": 6.693729575163399e-06,
      "loss": 0.108,
      "step": 8655
    },
    {
      "epoch": 1.9889705882352942,
      "grad_norm": 1.8467751741409302,
      "learning_rate": 6.693218954248366e-06,
      "loss": 0.1004,
      "step": 8656
    },
    {
      "epoch": 1.9892003676470589,
      "grad_norm": 1.9365358352661133,
      "learning_rate": 6.6927083333333345e-06,
      "loss": 0.0746,
      "step": 8657
    },
    {
      "epoch": 1.9894301470588234,
      "grad_norm": 2.2579450607299805,
      "learning_rate": 6.6921977124183015e-06,
      "loss": 0.1633,
      "step": 8658
    },
    {
      "epoch": 1.9896599264705883,
      "grad_norm": 1.5989288091659546,
      "learning_rate": 6.6916870915032685e-06,
      "loss": 0.1021,
      "step": 8659
    },
    {
      "epoch": 1.9898897058823528,
      "grad_norm": 2.4114229679107666,
      "learning_rate": 6.6911764705882356e-06,
      "loss": 0.1711,
      "step": 8660
    },
    {
      "epoch": 1.9901194852941178,
      "grad_norm": 1.7904555797576904,
      "learning_rate": 6.690665849673203e-06,
      "loss": 0.1107,
      "step": 8661
    },
    {
      "epoch": 1.9903492647058822,
      "grad_norm": 1.7136162519454956,
      "learning_rate": 6.6901552287581704e-06,
      "loss": 0.0936,
      "step": 8662
    },
    {
      "epoch": 1.9905790441176472,
      "grad_norm": 1.7486871480941772,
      "learning_rate": 6.6896446078431374e-06,
      "loss": 0.0979,
      "step": 8663
    },
    {
      "epoch": 1.9908088235294117,
      "grad_norm": 1.5894805192947388,
      "learning_rate": 6.6891339869281045e-06,
      "loss": 0.1371,
      "step": 8664
    },
    {
      "epoch": 1.9910386029411766,
      "grad_norm": 1.8960700035095215,
      "learning_rate": 6.688623366013073e-06,
      "loss": 0.1281,
      "step": 8665
    },
    {
      "epoch": 1.9912683823529411,
      "grad_norm": 1.3656275272369385,
      "learning_rate": 6.68811274509804e-06,
      "loss": 0.1046,
      "step": 8666
    },
    {
      "epoch": 1.9914981617647058,
      "grad_norm": 1.6989836692810059,
      "learning_rate": 6.687602124183007e-06,
      "loss": 0.1193,
      "step": 8667
    },
    {
      "epoch": 1.9917279411764706,
      "grad_norm": 1.5608941316604614,
      "learning_rate": 6.687091503267974e-06,
      "loss": 0.0806,
      "step": 8668
    },
    {
      "epoch": 1.9919577205882353,
      "grad_norm": 1.6484522819519043,
      "learning_rate": 6.686580882352942e-06,
      "loss": 0.0915,
      "step": 8669
    },
    {
      "epoch": 1.9921875,
      "grad_norm": 1.700554370880127,
      "learning_rate": 6.686070261437909e-06,
      "loss": 0.0898,
      "step": 8670
    },
    {
      "epoch": 1.9924172794117647,
      "grad_norm": 1.4962319135665894,
      "learning_rate": 6.685559640522876e-06,
      "loss": 0.1014,
      "step": 8671
    },
    {
      "epoch": 1.9926470588235294,
      "grad_norm": 2.1609983444213867,
      "learning_rate": 6.685049019607843e-06,
      "loss": 0.1351,
      "step": 8672
    },
    {
      "epoch": 1.9928768382352942,
      "grad_norm": 1.3590357303619385,
      "learning_rate": 6.684538398692812e-06,
      "loss": 0.1002,
      "step": 8673
    },
    {
      "epoch": 1.9931066176470589,
      "grad_norm": 1.7006651163101196,
      "learning_rate": 6.684027777777779e-06,
      "loss": 0.0797,
      "step": 8674
    },
    {
      "epoch": 1.9933363970588234,
      "grad_norm": 1.6018811464309692,
      "learning_rate": 6.683517156862746e-06,
      "loss": 0.1126,
      "step": 8675
    },
    {
      "epoch": 1.9935661764705883,
      "grad_norm": 1.6620439291000366,
      "learning_rate": 6.683006535947713e-06,
      "loss": 0.1332,
      "step": 8676
    },
    {
      "epoch": 1.9937959558823528,
      "grad_norm": 1.680200219154358,
      "learning_rate": 6.682495915032681e-06,
      "loss": 0.1066,
      "step": 8677
    },
    {
      "epoch": 1.9940257352941178,
      "grad_norm": 1.6899001598358154,
      "learning_rate": 6.681985294117648e-06,
      "loss": 0.0985,
      "step": 8678
    },
    {
      "epoch": 1.9942555147058822,
      "grad_norm": 1.425439715385437,
      "learning_rate": 6.681474673202615e-06,
      "loss": 0.0796,
      "step": 8679
    },
    {
      "epoch": 1.9944852941176472,
      "grad_norm": 1.2370045185089111,
      "learning_rate": 6.680964052287582e-06,
      "loss": 0.0681,
      "step": 8680
    },
    {
      "epoch": 1.9947150735294117,
      "grad_norm": 1.8073982000350952,
      "learning_rate": 6.68045343137255e-06,
      "loss": 0.1085,
      "step": 8681
    },
    {
      "epoch": 1.9949448529411766,
      "grad_norm": 1.3385201692581177,
      "learning_rate": 6.679942810457517e-06,
      "loss": 0.0965,
      "step": 8682
    },
    {
      "epoch": 1.9951746323529411,
      "grad_norm": 1.4298770427703857,
      "learning_rate": 6.679432189542484e-06,
      "loss": 0.0821,
      "step": 8683
    },
    {
      "epoch": 1.9954044117647058,
      "grad_norm": 1.6650795936584473,
      "learning_rate": 6.6789215686274515e-06,
      "loss": 0.0963,
      "step": 8684
    },
    {
      "epoch": 1.9956341911764706,
      "grad_norm": 1.4230834245681763,
      "learning_rate": 6.678410947712419e-06,
      "loss": 0.1028,
      "step": 8685
    },
    {
      "epoch": 1.9958639705882353,
      "grad_norm": 1.4021767377853394,
      "learning_rate": 6.677900326797386e-06,
      "loss": 0.0837,
      "step": 8686
    },
    {
      "epoch": 1.99609375,
      "grad_norm": 2.3164355754852295,
      "learning_rate": 6.677389705882353e-06,
      "loss": 0.2095,
      "step": 8687
    },
    {
      "epoch": 1.9963235294117647,
      "grad_norm": 2.1577484607696533,
      "learning_rate": 6.6768790849673204e-06,
      "loss": 0.1,
      "step": 8688
    },
    {
      "epoch": 1.9965533088235294,
      "grad_norm": 1.4360450506210327,
      "learning_rate": 6.676368464052288e-06,
      "loss": 0.1099,
      "step": 8689
    },
    {
      "epoch": 1.9967830882352942,
      "grad_norm": 1.3763625621795654,
      "learning_rate": 6.675857843137255e-06,
      "loss": 0.0824,
      "step": 8690
    },
    {
      "epoch": 1.9970128676470589,
      "grad_norm": 2.132948160171509,
      "learning_rate": 6.675347222222222e-06,
      "loss": 0.1069,
      "step": 8691
    },
    {
      "epoch": 1.9972426470588234,
      "grad_norm": 1.835017442703247,
      "learning_rate": 6.674836601307189e-06,
      "loss": 0.1194,
      "step": 8692
    },
    {
      "epoch": 1.9974724264705883,
      "grad_norm": 1.7796036005020142,
      "learning_rate": 6.674325980392158e-06,
      "loss": 0.1021,
      "step": 8693
    },
    {
      "epoch": 1.9977022058823528,
      "grad_norm": 1.24977707862854,
      "learning_rate": 6.673815359477125e-06,
      "loss": 0.0877,
      "step": 8694
    },
    {
      "epoch": 1.9979319852941178,
      "grad_norm": 1.3758628368377686,
      "learning_rate": 6.673304738562092e-06,
      "loss": 0.09,
      "step": 8695
    },
    {
      "epoch": 1.9981617647058822,
      "grad_norm": 1.5250457525253296,
      "learning_rate": 6.672794117647059e-06,
      "loss": 0.0772,
      "step": 8696
    },
    {
      "epoch": 1.9983915441176472,
      "grad_norm": 1.2168164253234863,
      "learning_rate": 6.672283496732027e-06,
      "loss": 0.073,
      "step": 8697
    },
    {
      "epoch": 1.9986213235294117,
      "grad_norm": 1.6048970222473145,
      "learning_rate": 6.671772875816994e-06,
      "loss": 0.0922,
      "step": 8698
    },
    {
      "epoch": 1.9988511029411766,
      "grad_norm": 2.44319748878479,
      "learning_rate": 6.671262254901961e-06,
      "loss": 0.0982,
      "step": 8699
    },
    {
      "epoch": 1.9990808823529411,
      "grad_norm": 1.3923494815826416,
      "learning_rate": 6.670751633986928e-06,
      "loss": 0.1111,
      "step": 8700
    },
    {
      "epoch": 1.9993106617647058,
      "grad_norm": 1.8400779962539673,
      "learning_rate": 6.670241013071897e-06,
      "loss": 0.1308,
      "step": 8701
    },
    {
      "epoch": 1.9995404411764706,
      "grad_norm": 1.3567489385604858,
      "learning_rate": 6.669730392156864e-06,
      "loss": 0.0849,
      "step": 8702
    },
    {
      "epoch": 1.9997702205882353,
      "grad_norm": 1.4837043285369873,
      "learning_rate": 6.669219771241831e-06,
      "loss": 0.0938,
      "step": 8703
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.690246820449829,
      "learning_rate": 6.668709150326798e-06,
      "loss": 0.0877,
      "step": 8704
    }
  ],
  "logging_steps": 1,
  "max_steps": 21760,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.014540454435226e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
