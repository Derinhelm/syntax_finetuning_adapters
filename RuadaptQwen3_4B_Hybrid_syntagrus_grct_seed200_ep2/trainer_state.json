{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 8704,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00022977941176470588,
      "grad_norm": 2.444596290588379,
      "learning_rate": 0.0,
      "loss": 2.9732,
      "step": 1
    },
    {
      "epoch": 0.00045955882352941176,
      "grad_norm": 2.4544248580932617,
      "learning_rate": 7.65696784073507e-09,
      "loss": 3.1398,
      "step": 2
    },
    {
      "epoch": 0.0006893382352941177,
      "grad_norm": 2.455373525619507,
      "learning_rate": 1.531393568147014e-08,
      "loss": 2.9385,
      "step": 3
    },
    {
      "epoch": 0.0009191176470588235,
      "grad_norm": 2.42751145362854,
      "learning_rate": 2.2970903522205212e-08,
      "loss": 2.8517,
      "step": 4
    },
    {
      "epoch": 0.0011488970588235295,
      "grad_norm": 2.839806318283081,
      "learning_rate": 3.062787136294028e-08,
      "loss": 3.1569,
      "step": 5
    },
    {
      "epoch": 0.0013786764705882354,
      "grad_norm": 2.3524062633514404,
      "learning_rate": 3.8284839203675346e-08,
      "loss": 2.9984,
      "step": 6
    },
    {
      "epoch": 0.001608455882352941,
      "grad_norm": 2.2320749759674072,
      "learning_rate": 4.5941807044410424e-08,
      "loss": 2.8544,
      "step": 7
    },
    {
      "epoch": 0.001838235294117647,
      "grad_norm": 2.5777909755706787,
      "learning_rate": 5.359877488514548e-08,
      "loss": 3.1305,
      "step": 8
    },
    {
      "epoch": 0.002068014705882353,
      "grad_norm": 2.553971529006958,
      "learning_rate": 6.125574272588056e-08,
      "loss": 2.8503,
      "step": 9
    },
    {
      "epoch": 0.002297794117647059,
      "grad_norm": 2.6296818256378174,
      "learning_rate": 6.891271056661562e-08,
      "loss": 3.089,
      "step": 10
    },
    {
      "epoch": 0.002527573529411765,
      "grad_norm": 2.295599937438965,
      "learning_rate": 7.656967840735069e-08,
      "loss": 2.7866,
      "step": 11
    },
    {
      "epoch": 0.0027573529411764708,
      "grad_norm": 2.386648654937744,
      "learning_rate": 8.422664624808578e-08,
      "loss": 3.0044,
      "step": 12
    },
    {
      "epoch": 0.0029871323529411763,
      "grad_norm": 2.430790662765503,
      "learning_rate": 9.188361408882085e-08,
      "loss": 3.0996,
      "step": 13
    },
    {
      "epoch": 0.003216911764705882,
      "grad_norm": 2.275491952896118,
      "learning_rate": 9.954058192955589e-08,
      "loss": 2.9492,
      "step": 14
    },
    {
      "epoch": 0.003446691176470588,
      "grad_norm": 2.5539886951446533,
      "learning_rate": 1.0719754977029096e-07,
      "loss": 3.0316,
      "step": 15
    },
    {
      "epoch": 0.003676470588235294,
      "grad_norm": 2.2279319763183594,
      "learning_rate": 1.1485451761102605e-07,
      "loss": 2.8541,
      "step": 16
    },
    {
      "epoch": 0.00390625,
      "grad_norm": 2.2812788486480713,
      "learning_rate": 1.2251148545176112e-07,
      "loss": 2.9481,
      "step": 17
    },
    {
      "epoch": 0.004136029411764706,
      "grad_norm": 3.0857157707214355,
      "learning_rate": 1.3016845329249618e-07,
      "loss": 3.0236,
      "step": 18
    },
    {
      "epoch": 0.004365808823529412,
      "grad_norm": 2.314502000808716,
      "learning_rate": 1.3782542113323124e-07,
      "loss": 2.8812,
      "step": 19
    },
    {
      "epoch": 0.004595588235294118,
      "grad_norm": 2.100585699081421,
      "learning_rate": 1.4548238897396632e-07,
      "loss": 2.6489,
      "step": 20
    },
    {
      "epoch": 0.004825367647058824,
      "grad_norm": 2.4896371364593506,
      "learning_rate": 1.5313935681470138e-07,
      "loss": 2.9239,
      "step": 21
    },
    {
      "epoch": 0.00505514705882353,
      "grad_norm": 2.2380359172821045,
      "learning_rate": 1.6079632465543647e-07,
      "loss": 2.8687,
      "step": 22
    },
    {
      "epoch": 0.005284926470588236,
      "grad_norm": 2.633216619491577,
      "learning_rate": 1.6845329249617155e-07,
      "loss": 3.2688,
      "step": 23
    },
    {
      "epoch": 0.0055147058823529415,
      "grad_norm": 2.33847713470459,
      "learning_rate": 1.761102603369066e-07,
      "loss": 2.8965,
      "step": 24
    },
    {
      "epoch": 0.0057444852941176475,
      "grad_norm": 2.2000842094421387,
      "learning_rate": 1.837672281776417e-07,
      "loss": 2.9422,
      "step": 25
    },
    {
      "epoch": 0.0059742647058823525,
      "grad_norm": 2.466287851333618,
      "learning_rate": 1.9142419601837673e-07,
      "loss": 2.9411,
      "step": 26
    },
    {
      "epoch": 0.0062040441176470585,
      "grad_norm": 2.361924886703491,
      "learning_rate": 1.9908116385911179e-07,
      "loss": 3.0893,
      "step": 27
    },
    {
      "epoch": 0.006433823529411764,
      "grad_norm": 2.0757791996002197,
      "learning_rate": 2.0673813169984687e-07,
      "loss": 2.8229,
      "step": 28
    },
    {
      "epoch": 0.00666360294117647,
      "grad_norm": 2.058990478515625,
      "learning_rate": 2.1439509954058193e-07,
      "loss": 2.5717,
      "step": 29
    },
    {
      "epoch": 0.006893382352941176,
      "grad_norm": 2.276277542114258,
      "learning_rate": 2.2205206738131701e-07,
      "loss": 2.9114,
      "step": 30
    },
    {
      "epoch": 0.007123161764705882,
      "grad_norm": 2.2629036903381348,
      "learning_rate": 2.297090352220521e-07,
      "loss": 2.7371,
      "step": 31
    },
    {
      "epoch": 0.007352941176470588,
      "grad_norm": 2.3908026218414307,
      "learning_rate": 2.3736600306278716e-07,
      "loss": 2.9259,
      "step": 32
    },
    {
      "epoch": 0.007582720588235294,
      "grad_norm": 2.1492087841033936,
      "learning_rate": 2.4502297090352224e-07,
      "loss": 2.9072,
      "step": 33
    },
    {
      "epoch": 0.0078125,
      "grad_norm": 2.1439499855041504,
      "learning_rate": 2.526799387442573e-07,
      "loss": 2.7026,
      "step": 34
    },
    {
      "epoch": 0.008042279411764705,
      "grad_norm": 2.1556942462921143,
      "learning_rate": 2.6033690658499236e-07,
      "loss": 2.7446,
      "step": 35
    },
    {
      "epoch": 0.008272058823529412,
      "grad_norm": 2.487175226211548,
      "learning_rate": 2.679938744257274e-07,
      "loss": 3.1101,
      "step": 36
    },
    {
      "epoch": 0.008501838235294117,
      "grad_norm": 2.7282865047454834,
      "learning_rate": 2.756508422664625e-07,
      "loss": 3.3214,
      "step": 37
    },
    {
      "epoch": 0.008731617647058824,
      "grad_norm": 3.038008451461792,
      "learning_rate": 2.833078101071976e-07,
      "loss": 3.2779,
      "step": 38
    },
    {
      "epoch": 0.008961397058823529,
      "grad_norm": 2.8249475955963135,
      "learning_rate": 2.9096477794793265e-07,
      "loss": 3.2796,
      "step": 39
    },
    {
      "epoch": 0.009191176470588236,
      "grad_norm": 2.659369707107544,
      "learning_rate": 2.986217457886677e-07,
      "loss": 3.067,
      "step": 40
    },
    {
      "epoch": 0.00942095588235294,
      "grad_norm": 2.563760995864868,
      "learning_rate": 3.0627871362940276e-07,
      "loss": 3.1094,
      "step": 41
    },
    {
      "epoch": 0.009650735294117647,
      "grad_norm": 2.208472490310669,
      "learning_rate": 3.139356814701378e-07,
      "loss": 2.6835,
      "step": 42
    },
    {
      "epoch": 0.009880514705882353,
      "grad_norm": 2.6813511848449707,
      "learning_rate": 3.2159264931087293e-07,
      "loss": 3.1539,
      "step": 43
    },
    {
      "epoch": 0.01011029411764706,
      "grad_norm": 2.2981064319610596,
      "learning_rate": 3.29249617151608e-07,
      "loss": 3.094,
      "step": 44
    },
    {
      "epoch": 0.010340073529411764,
      "grad_norm": 2.2275171279907227,
      "learning_rate": 3.369065849923431e-07,
      "loss": 2.8756,
      "step": 45
    },
    {
      "epoch": 0.010569852941176471,
      "grad_norm": 2.2387547492980957,
      "learning_rate": 3.445635528330781e-07,
      "loss": 2.9516,
      "step": 46
    },
    {
      "epoch": 0.010799632352941176,
      "grad_norm": 1.9220097064971924,
      "learning_rate": 3.522205206738132e-07,
      "loss": 2.5659,
      "step": 47
    },
    {
      "epoch": 0.011029411764705883,
      "grad_norm": 2.2841906547546387,
      "learning_rate": 3.598774885145483e-07,
      "loss": 2.7966,
      "step": 48
    },
    {
      "epoch": 0.011259191176470588,
      "grad_norm": 2.2475075721740723,
      "learning_rate": 3.675344563552834e-07,
      "loss": 2.9576,
      "step": 49
    },
    {
      "epoch": 0.011488970588235295,
      "grad_norm": 2.339071273803711,
      "learning_rate": 3.751914241960184e-07,
      "loss": 3.1309,
      "step": 50
    },
    {
      "epoch": 0.01171875,
      "grad_norm": 2.466055154800415,
      "learning_rate": 3.8284839203675346e-07,
      "loss": 2.8365,
      "step": 51
    },
    {
      "epoch": 0.011948529411764705,
      "grad_norm": 2.381629467010498,
      "learning_rate": 3.9050535987748857e-07,
      "loss": 2.8802,
      "step": 52
    },
    {
      "epoch": 0.012178308823529412,
      "grad_norm": 2.7118120193481445,
      "learning_rate": 3.9816232771822357e-07,
      "loss": 3.1988,
      "step": 53
    },
    {
      "epoch": 0.012408088235294117,
      "grad_norm": 2.320619583129883,
      "learning_rate": 4.058192955589587e-07,
      "loss": 2.9596,
      "step": 54
    },
    {
      "epoch": 0.012637867647058824,
      "grad_norm": 2.2854950428009033,
      "learning_rate": 4.1347626339969374e-07,
      "loss": 2.7694,
      "step": 55
    },
    {
      "epoch": 0.012867647058823529,
      "grad_norm": 2.553924322128296,
      "learning_rate": 4.2113323124042885e-07,
      "loss": 3.0472,
      "step": 56
    },
    {
      "epoch": 0.013097426470588236,
      "grad_norm": 2.366743803024292,
      "learning_rate": 4.2879019908116386e-07,
      "loss": 2.9659,
      "step": 57
    },
    {
      "epoch": 0.01332720588235294,
      "grad_norm": 2.3445682525634766,
      "learning_rate": 4.3644716692189897e-07,
      "loss": 2.86,
      "step": 58
    },
    {
      "epoch": 0.013556985294117647,
      "grad_norm": 2.332277774810791,
      "learning_rate": 4.4410413476263403e-07,
      "loss": 2.8971,
      "step": 59
    },
    {
      "epoch": 0.013786764705882353,
      "grad_norm": 2.2248003482818604,
      "learning_rate": 4.517611026033691e-07,
      "loss": 2.8504,
      "step": 60
    },
    {
      "epoch": 0.01401654411764706,
      "grad_norm": 2.194516181945801,
      "learning_rate": 4.594180704441042e-07,
      "loss": 2.7237,
      "step": 61
    },
    {
      "epoch": 0.014246323529411764,
      "grad_norm": 2.4345200061798096,
      "learning_rate": 4.670750382848392e-07,
      "loss": 2.8703,
      "step": 62
    },
    {
      "epoch": 0.014476102941176471,
      "grad_norm": 2.1652281284332275,
      "learning_rate": 4.747320061255743e-07,
      "loss": 2.9331,
      "step": 63
    },
    {
      "epoch": 0.014705882352941176,
      "grad_norm": 2.3241584300994873,
      "learning_rate": 4.823889739663093e-07,
      "loss": 2.5975,
      "step": 64
    },
    {
      "epoch": 0.014935661764705883,
      "grad_norm": 2.4108145236968994,
      "learning_rate": 4.900459418070445e-07,
      "loss": 3.0538,
      "step": 65
    },
    {
      "epoch": 0.015165441176470588,
      "grad_norm": 2.1221697330474854,
      "learning_rate": 4.977029096477795e-07,
      "loss": 2.6473,
      "step": 66
    },
    {
      "epoch": 0.015395220588235295,
      "grad_norm": 2.061108112335205,
      "learning_rate": 5.053598774885146e-07,
      "loss": 2.9658,
      "step": 67
    },
    {
      "epoch": 0.015625,
      "grad_norm": 2.1972877979278564,
      "learning_rate": 5.130168453292497e-07,
      "loss": 2.8348,
      "step": 68
    },
    {
      "epoch": 0.015854779411764705,
      "grad_norm": 2.3820338249206543,
      "learning_rate": 5.206738131699847e-07,
      "loss": 2.8959,
      "step": 69
    },
    {
      "epoch": 0.01608455882352941,
      "grad_norm": 2.1949737071990967,
      "learning_rate": 5.283307810107198e-07,
      "loss": 2.7623,
      "step": 70
    },
    {
      "epoch": 0.01631433823529412,
      "grad_norm": 2.1529035568237305,
      "learning_rate": 5.359877488514548e-07,
      "loss": 2.7455,
      "step": 71
    },
    {
      "epoch": 0.016544117647058824,
      "grad_norm": 2.557877540588379,
      "learning_rate": 5.436447166921899e-07,
      "loss": 3.148,
      "step": 72
    },
    {
      "epoch": 0.01677389705882353,
      "grad_norm": 2.1077816486358643,
      "learning_rate": 5.51301684532925e-07,
      "loss": 2.8639,
      "step": 73
    },
    {
      "epoch": 0.017003676470588234,
      "grad_norm": 1.8930538892745972,
      "learning_rate": 5.589586523736601e-07,
      "loss": 2.3558,
      "step": 74
    },
    {
      "epoch": 0.017233455882352942,
      "grad_norm": 2.701000452041626,
      "learning_rate": 5.666156202143952e-07,
      "loss": 3.0396,
      "step": 75
    },
    {
      "epoch": 0.017463235294117647,
      "grad_norm": 2.377880096435547,
      "learning_rate": 5.742725880551302e-07,
      "loss": 2.9267,
      "step": 76
    },
    {
      "epoch": 0.017693014705882353,
      "grad_norm": 2.916872262954712,
      "learning_rate": 5.819295558958653e-07,
      "loss": 3.3866,
      "step": 77
    },
    {
      "epoch": 0.017922794117647058,
      "grad_norm": 2.3682422637939453,
      "learning_rate": 5.895865237366004e-07,
      "loss": 2.7742,
      "step": 78
    },
    {
      "epoch": 0.018152573529411766,
      "grad_norm": 2.162537097930908,
      "learning_rate": 5.972434915773354e-07,
      "loss": 2.7521,
      "step": 79
    },
    {
      "epoch": 0.01838235294117647,
      "grad_norm": 2.5420985221862793,
      "learning_rate": 6.049004594180705e-07,
      "loss": 3.275,
      "step": 80
    },
    {
      "epoch": 0.018612132352941176,
      "grad_norm": 2.563002109527588,
      "learning_rate": 6.125574272588055e-07,
      "loss": 3.0706,
      "step": 81
    },
    {
      "epoch": 0.01884191176470588,
      "grad_norm": 2.49257755279541,
      "learning_rate": 6.202143950995406e-07,
      "loss": 2.9754,
      "step": 82
    },
    {
      "epoch": 0.01907169117647059,
      "grad_norm": 2.4987845420837402,
      "learning_rate": 6.278713629402756e-07,
      "loss": 3.0733,
      "step": 83
    },
    {
      "epoch": 0.019301470588235295,
      "grad_norm": 2.116124153137207,
      "learning_rate": 6.355283307810107e-07,
      "loss": 2.7871,
      "step": 84
    },
    {
      "epoch": 0.01953125,
      "grad_norm": 2.0077357292175293,
      "learning_rate": 6.431852986217459e-07,
      "loss": 2.6709,
      "step": 85
    },
    {
      "epoch": 0.019761029411764705,
      "grad_norm": 2.4667317867279053,
      "learning_rate": 6.508422664624809e-07,
      "loss": 3.0676,
      "step": 86
    },
    {
      "epoch": 0.01999080882352941,
      "grad_norm": 2.3272838592529297,
      "learning_rate": 6.58499234303216e-07,
      "loss": 2.7379,
      "step": 87
    },
    {
      "epoch": 0.02022058823529412,
      "grad_norm": 2.109848976135254,
      "learning_rate": 6.66156202143951e-07,
      "loss": 2.6883,
      "step": 88
    },
    {
      "epoch": 0.020450367647058824,
      "grad_norm": 2.7512078285217285,
      "learning_rate": 6.738131699846862e-07,
      "loss": 3.0776,
      "step": 89
    },
    {
      "epoch": 0.02068014705882353,
      "grad_norm": 2.4588429927825928,
      "learning_rate": 6.814701378254212e-07,
      "loss": 2.974,
      "step": 90
    },
    {
      "epoch": 0.020909926470588234,
      "grad_norm": 2.2460691928863525,
      "learning_rate": 6.891271056661562e-07,
      "loss": 2.8272,
      "step": 91
    },
    {
      "epoch": 0.021139705882352942,
      "grad_norm": 2.035900592803955,
      "learning_rate": 6.967840735068914e-07,
      "loss": 2.6068,
      "step": 92
    },
    {
      "epoch": 0.021369485294117647,
      "grad_norm": 2.3829102516174316,
      "learning_rate": 7.044410413476264e-07,
      "loss": 2.951,
      "step": 93
    },
    {
      "epoch": 0.021599264705882353,
      "grad_norm": 2.3292641639709473,
      "learning_rate": 7.120980091883614e-07,
      "loss": 2.8619,
      "step": 94
    },
    {
      "epoch": 0.021829044117647058,
      "grad_norm": 2.1586289405822754,
      "learning_rate": 7.197549770290966e-07,
      "loss": 2.8296,
      "step": 95
    },
    {
      "epoch": 0.022058823529411766,
      "grad_norm": 2.698765516281128,
      "learning_rate": 7.274119448698316e-07,
      "loss": 3.1964,
      "step": 96
    },
    {
      "epoch": 0.02228860294117647,
      "grad_norm": 2.326925277709961,
      "learning_rate": 7.350689127105668e-07,
      "loss": 2.7843,
      "step": 97
    },
    {
      "epoch": 0.022518382352941176,
      "grad_norm": 3.2454681396484375,
      "learning_rate": 7.427258805513017e-07,
      "loss": 3.2306,
      "step": 98
    },
    {
      "epoch": 0.02274816176470588,
      "grad_norm": 2.2324986457824707,
      "learning_rate": 7.503828483920368e-07,
      "loss": 2.9146,
      "step": 99
    },
    {
      "epoch": 0.02297794117647059,
      "grad_norm": 3.077105760574341,
      "learning_rate": 7.58039816232772e-07,
      "loss": 2.9494,
      "step": 100
    },
    {
      "epoch": 0.023207720588235295,
      "grad_norm": 2.2568907737731934,
      "learning_rate": 7.656967840735069e-07,
      "loss": 2.8905,
      "step": 101
    },
    {
      "epoch": 0.0234375,
      "grad_norm": 2.1727538108825684,
      "learning_rate": 7.73353751914242e-07,
      "loss": 2.7655,
      "step": 102
    },
    {
      "epoch": 0.023667279411764705,
      "grad_norm": 2.2179200649261475,
      "learning_rate": 7.810107197549771e-07,
      "loss": 2.8113,
      "step": 103
    },
    {
      "epoch": 0.02389705882352941,
      "grad_norm": 2.138394355773926,
      "learning_rate": 7.886676875957122e-07,
      "loss": 2.8087,
      "step": 104
    },
    {
      "epoch": 0.02412683823529412,
      "grad_norm": 2.795879602432251,
      "learning_rate": 7.963246554364471e-07,
      "loss": 2.9509,
      "step": 105
    },
    {
      "epoch": 0.024356617647058824,
      "grad_norm": 2.342801809310913,
      "learning_rate": 8.039816232771823e-07,
      "loss": 2.8417,
      "step": 106
    },
    {
      "epoch": 0.02458639705882353,
      "grad_norm": 2.3811254501342773,
      "learning_rate": 8.116385911179174e-07,
      "loss": 2.9348,
      "step": 107
    },
    {
      "epoch": 0.024816176470588234,
      "grad_norm": 2.262171745300293,
      "learning_rate": 8.192955589586525e-07,
      "loss": 2.8652,
      "step": 108
    },
    {
      "epoch": 0.025045955882352942,
      "grad_norm": 2.1692864894866943,
      "learning_rate": 8.269525267993875e-07,
      "loss": 2.7396,
      "step": 109
    },
    {
      "epoch": 0.025275735294117647,
      "grad_norm": 2.455690622329712,
      "learning_rate": 8.346094946401225e-07,
      "loss": 2.9529,
      "step": 110
    },
    {
      "epoch": 0.025505514705882353,
      "grad_norm": 2.285836935043335,
      "learning_rate": 8.422664624808577e-07,
      "loss": 2.7179,
      "step": 111
    },
    {
      "epoch": 0.025735294117647058,
      "grad_norm": 2.0257647037506104,
      "learning_rate": 8.499234303215927e-07,
      "loss": 2.6791,
      "step": 112
    },
    {
      "epoch": 0.025965073529411766,
      "grad_norm": 2.3825788497924805,
      "learning_rate": 8.575803981623277e-07,
      "loss": 2.7798,
      "step": 113
    },
    {
      "epoch": 0.02619485294117647,
      "grad_norm": 2.494429111480713,
      "learning_rate": 8.652373660030629e-07,
      "loss": 2.965,
      "step": 114
    },
    {
      "epoch": 0.026424632352941176,
      "grad_norm": 2.562636375427246,
      "learning_rate": 8.728943338437979e-07,
      "loss": 3.0907,
      "step": 115
    },
    {
      "epoch": 0.02665441176470588,
      "grad_norm": 2.7020673751831055,
      "learning_rate": 8.80551301684533e-07,
      "loss": 2.9645,
      "step": 116
    },
    {
      "epoch": 0.02688419117647059,
      "grad_norm": 2.0744197368621826,
      "learning_rate": 8.882082695252681e-07,
      "loss": 2.7352,
      "step": 117
    },
    {
      "epoch": 0.027113970588235295,
      "grad_norm": 2.645709753036499,
      "learning_rate": 8.958652373660032e-07,
      "loss": 3.1255,
      "step": 118
    },
    {
      "epoch": 0.02734375,
      "grad_norm": 2.1677589416503906,
      "learning_rate": 9.035222052067382e-07,
      "loss": 2.7638,
      "step": 119
    },
    {
      "epoch": 0.027573529411764705,
      "grad_norm": 2.021156072616577,
      "learning_rate": 9.111791730474732e-07,
      "loss": 2.6204,
      "step": 120
    },
    {
      "epoch": 0.02780330882352941,
      "grad_norm": 2.3078596591949463,
      "learning_rate": 9.188361408882084e-07,
      "loss": 2.8015,
      "step": 121
    },
    {
      "epoch": 0.02803308823529412,
      "grad_norm": 2.3481297492980957,
      "learning_rate": 9.264931087289435e-07,
      "loss": 2.9,
      "step": 122
    },
    {
      "epoch": 0.028262867647058824,
      "grad_norm": 2.141026735305786,
      "learning_rate": 9.341500765696784e-07,
      "loss": 2.8257,
      "step": 123
    },
    {
      "epoch": 0.02849264705882353,
      "grad_norm": 2.314326047897339,
      "learning_rate": 9.418070444104136e-07,
      "loss": 2.8777,
      "step": 124
    },
    {
      "epoch": 0.028722426470588234,
      "grad_norm": 2.3989388942718506,
      "learning_rate": 9.494640122511486e-07,
      "loss": 2.8175,
      "step": 125
    },
    {
      "epoch": 0.028952205882352942,
      "grad_norm": 2.0333540439605713,
      "learning_rate": 9.571209800918838e-07,
      "loss": 2.6253,
      "step": 126
    },
    {
      "epoch": 0.029181985294117647,
      "grad_norm": 2.390294075012207,
      "learning_rate": 9.647779479326186e-07,
      "loss": 2.8041,
      "step": 127
    },
    {
      "epoch": 0.029411764705882353,
      "grad_norm": 2.4016036987304688,
      "learning_rate": 9.72434915773354e-07,
      "loss": 2.9553,
      "step": 128
    },
    {
      "epoch": 0.029641544117647058,
      "grad_norm": 2.474012613296509,
      "learning_rate": 9.80091883614089e-07,
      "loss": 2.9015,
      "step": 129
    },
    {
      "epoch": 0.029871323529411766,
      "grad_norm": 2.423772096633911,
      "learning_rate": 9.877488514548238e-07,
      "loss": 2.8093,
      "step": 130
    },
    {
      "epoch": 0.03010110294117647,
      "grad_norm": 2.6183300018310547,
      "learning_rate": 9.95405819295559e-07,
      "loss": 2.9073,
      "step": 131
    },
    {
      "epoch": 0.030330882352941176,
      "grad_norm": 2.1420652866363525,
      "learning_rate": 1.0030627871362941e-06,
      "loss": 2.7956,
      "step": 132
    },
    {
      "epoch": 0.03056066176470588,
      "grad_norm": 2.338951826095581,
      "learning_rate": 1.0107197549770292e-06,
      "loss": 2.7559,
      "step": 133
    },
    {
      "epoch": 0.03079044117647059,
      "grad_norm": 2.5076916217803955,
      "learning_rate": 1.0183767228177643e-06,
      "loss": 2.9545,
      "step": 134
    },
    {
      "epoch": 0.031020220588235295,
      "grad_norm": 2.4941964149475098,
      "learning_rate": 1.0260336906584993e-06,
      "loss": 2.9038,
      "step": 135
    },
    {
      "epoch": 0.03125,
      "grad_norm": 2.4643399715423584,
      "learning_rate": 1.0336906584992344e-06,
      "loss": 2.8921,
      "step": 136
    },
    {
      "epoch": 0.031479779411764705,
      "grad_norm": 2.484745740890503,
      "learning_rate": 1.0413476263399694e-06,
      "loss": 3.0105,
      "step": 137
    },
    {
      "epoch": 0.03170955882352941,
      "grad_norm": 2.6396090984344482,
      "learning_rate": 1.0490045941807045e-06,
      "loss": 2.947,
      "step": 138
    },
    {
      "epoch": 0.031939338235294115,
      "grad_norm": 2.224001407623291,
      "learning_rate": 1.0566615620214396e-06,
      "loss": 2.728,
      "step": 139
    },
    {
      "epoch": 0.03216911764705882,
      "grad_norm": 2.619037628173828,
      "learning_rate": 1.0643185298621746e-06,
      "loss": 2.8556,
      "step": 140
    },
    {
      "epoch": 0.03239889705882353,
      "grad_norm": 2.228858232498169,
      "learning_rate": 1.0719754977029097e-06,
      "loss": 2.6049,
      "step": 141
    },
    {
      "epoch": 0.03262867647058824,
      "grad_norm": 2.596179246902466,
      "learning_rate": 1.0796324655436447e-06,
      "loss": 2.7984,
      "step": 142
    },
    {
      "epoch": 0.03285845588235294,
      "grad_norm": 3.04352068901062,
      "learning_rate": 1.0872894333843798e-06,
      "loss": 3.2573,
      "step": 143
    },
    {
      "epoch": 0.03308823529411765,
      "grad_norm": 2.333728313446045,
      "learning_rate": 1.094946401225115e-06,
      "loss": 2.8157,
      "step": 144
    },
    {
      "epoch": 0.03331801470588235,
      "grad_norm": 2.3686015605926514,
      "learning_rate": 1.10260336906585e-06,
      "loss": 2.8455,
      "step": 145
    },
    {
      "epoch": 0.03354779411764706,
      "grad_norm": 2.7602319717407227,
      "learning_rate": 1.1102603369065852e-06,
      "loss": 2.9371,
      "step": 146
    },
    {
      "epoch": 0.03377757352941176,
      "grad_norm": 2.512169599533081,
      "learning_rate": 1.1179173047473202e-06,
      "loss": 2.9472,
      "step": 147
    },
    {
      "epoch": 0.03400735294117647,
      "grad_norm": 2.2798008918762207,
      "learning_rate": 1.125574272588055e-06,
      "loss": 2.8547,
      "step": 148
    },
    {
      "epoch": 0.03423713235294118,
      "grad_norm": 2.250885486602783,
      "learning_rate": 1.1332312404287904e-06,
      "loss": 2.787,
      "step": 149
    },
    {
      "epoch": 0.034466911764705885,
      "grad_norm": 2.1534006595611572,
      "learning_rate": 1.1408882082695254e-06,
      "loss": 2.5909,
      "step": 150
    },
    {
      "epoch": 0.03469669117647059,
      "grad_norm": 2.8758726119995117,
      "learning_rate": 1.1485451761102605e-06,
      "loss": 2.8913,
      "step": 151
    },
    {
      "epoch": 0.034926470588235295,
      "grad_norm": 2.2484374046325684,
      "learning_rate": 1.1562021439509955e-06,
      "loss": 2.6349,
      "step": 152
    },
    {
      "epoch": 0.03515625,
      "grad_norm": 2.5455126762390137,
      "learning_rate": 1.1638591117917306e-06,
      "loss": 2.8012,
      "step": 153
    },
    {
      "epoch": 0.035386029411764705,
      "grad_norm": 2.5113770961761475,
      "learning_rate": 1.1715160796324656e-06,
      "loss": 2.9112,
      "step": 154
    },
    {
      "epoch": 0.03561580882352941,
      "grad_norm": 2.5569183826446533,
      "learning_rate": 1.1791730474732007e-06,
      "loss": 2.7249,
      "step": 155
    },
    {
      "epoch": 0.035845588235294115,
      "grad_norm": 2.3798656463623047,
      "learning_rate": 1.1868300153139358e-06,
      "loss": 2.6289,
      "step": 156
    },
    {
      "epoch": 0.03607536764705882,
      "grad_norm": 2.379796266555786,
      "learning_rate": 1.1944869831546708e-06,
      "loss": 2.7556,
      "step": 157
    },
    {
      "epoch": 0.03630514705882353,
      "grad_norm": 2.514413833618164,
      "learning_rate": 1.2021439509954059e-06,
      "loss": 2.9089,
      "step": 158
    },
    {
      "epoch": 0.03653492647058824,
      "grad_norm": 2.6351001262664795,
      "learning_rate": 1.209800918836141e-06,
      "loss": 2.7324,
      "step": 159
    },
    {
      "epoch": 0.03676470588235294,
      "grad_norm": 2.208750009536743,
      "learning_rate": 1.217457886676876e-06,
      "loss": 2.7867,
      "step": 160
    },
    {
      "epoch": 0.03699448529411765,
      "grad_norm": 2.4283392429351807,
      "learning_rate": 1.225114854517611e-06,
      "loss": 2.9961,
      "step": 161
    },
    {
      "epoch": 0.03722426470588235,
      "grad_norm": 2.1787173748016357,
      "learning_rate": 1.2327718223583463e-06,
      "loss": 2.7291,
      "step": 162
    },
    {
      "epoch": 0.03745404411764706,
      "grad_norm": 2.404860019683838,
      "learning_rate": 1.2404287901990812e-06,
      "loss": 2.8505,
      "step": 163
    },
    {
      "epoch": 0.03768382352941176,
      "grad_norm": 2.112687587738037,
      "learning_rate": 1.2480857580398162e-06,
      "loss": 2.6787,
      "step": 164
    },
    {
      "epoch": 0.03791360294117647,
      "grad_norm": 2.577756643295288,
      "learning_rate": 1.2557427258805513e-06,
      "loss": 2.636,
      "step": 165
    },
    {
      "epoch": 0.03814338235294118,
      "grad_norm": 2.1167922019958496,
      "learning_rate": 1.2633996937212863e-06,
      "loss": 2.7927,
      "step": 166
    },
    {
      "epoch": 0.038373161764705885,
      "grad_norm": 1.8406962156295776,
      "learning_rate": 1.2710566615620214e-06,
      "loss": 2.5907,
      "step": 167
    },
    {
      "epoch": 0.03860294117647059,
      "grad_norm": 1.9011131525039673,
      "learning_rate": 1.2787136294027567e-06,
      "loss": 2.5457,
      "step": 168
    },
    {
      "epoch": 0.038832720588235295,
      "grad_norm": 2.1897201538085938,
      "learning_rate": 1.2863705972434917e-06,
      "loss": 2.6711,
      "step": 169
    },
    {
      "epoch": 0.0390625,
      "grad_norm": 2.279329299926758,
      "learning_rate": 1.2940275650842268e-06,
      "loss": 2.7686,
      "step": 170
    },
    {
      "epoch": 0.039292279411764705,
      "grad_norm": 2.0499303340911865,
      "learning_rate": 1.3016845329249619e-06,
      "loss": 2.6905,
      "step": 171
    },
    {
      "epoch": 0.03952205882352941,
      "grad_norm": 2.6260440349578857,
      "learning_rate": 1.3093415007656967e-06,
      "loss": 2.7554,
      "step": 172
    },
    {
      "epoch": 0.039751838235294115,
      "grad_norm": 2.353501558303833,
      "learning_rate": 1.316998468606432e-06,
      "loss": 2.6901,
      "step": 173
    },
    {
      "epoch": 0.03998161764705882,
      "grad_norm": 2.7289321422576904,
      "learning_rate": 1.324655436447167e-06,
      "loss": 2.929,
      "step": 174
    },
    {
      "epoch": 0.04021139705882353,
      "grad_norm": 2.5363821983337402,
      "learning_rate": 1.332312404287902e-06,
      "loss": 3.0004,
      "step": 175
    },
    {
      "epoch": 0.04044117647058824,
      "grad_norm": 2.4183146953582764,
      "learning_rate": 1.3399693721286371e-06,
      "loss": 2.6523,
      "step": 176
    },
    {
      "epoch": 0.04067095588235294,
      "grad_norm": 2.24466872215271,
      "learning_rate": 1.3476263399693724e-06,
      "loss": 2.8531,
      "step": 177
    },
    {
      "epoch": 0.04090073529411765,
      "grad_norm": 2.4065892696380615,
      "learning_rate": 1.3552833078101075e-06,
      "loss": 2.5602,
      "step": 178
    },
    {
      "epoch": 0.04113051470588235,
      "grad_norm": 2.066706418991089,
      "learning_rate": 1.3629402756508423e-06,
      "loss": 2.673,
      "step": 179
    },
    {
      "epoch": 0.04136029411764706,
      "grad_norm": 2.0653951168060303,
      "learning_rate": 1.3705972434915774e-06,
      "loss": 2.6214,
      "step": 180
    },
    {
      "epoch": 0.04159007352941176,
      "grad_norm": 1.8295303583145142,
      "learning_rate": 1.3782542113323124e-06,
      "loss": 2.3908,
      "step": 181
    },
    {
      "epoch": 0.04181985294117647,
      "grad_norm": 2.1229610443115234,
      "learning_rate": 1.3859111791730475e-06,
      "loss": 2.7842,
      "step": 182
    },
    {
      "epoch": 0.04204963235294118,
      "grad_norm": 2.2545387744903564,
      "learning_rate": 1.3935681470137828e-06,
      "loss": 2.7589,
      "step": 183
    },
    {
      "epoch": 0.042279411764705885,
      "grad_norm": 2.7287685871124268,
      "learning_rate": 1.4012251148545178e-06,
      "loss": 2.838,
      "step": 184
    },
    {
      "epoch": 0.04250919117647059,
      "grad_norm": 2.2528231143951416,
      "learning_rate": 1.4088820826952529e-06,
      "loss": 2.6969,
      "step": 185
    },
    {
      "epoch": 0.042738970588235295,
      "grad_norm": 2.377823829650879,
      "learning_rate": 1.416539050535988e-06,
      "loss": 2.8554,
      "step": 186
    },
    {
      "epoch": 0.04296875,
      "grad_norm": 2.133169412612915,
      "learning_rate": 1.4241960183767228e-06,
      "loss": 2.7467,
      "step": 187
    },
    {
      "epoch": 0.043198529411764705,
      "grad_norm": 2.346952199935913,
      "learning_rate": 1.4318529862174578e-06,
      "loss": 2.7111,
      "step": 188
    },
    {
      "epoch": 0.04342830882352941,
      "grad_norm": 2.2849249839782715,
      "learning_rate": 1.4395099540581931e-06,
      "loss": 2.7719,
      "step": 189
    },
    {
      "epoch": 0.043658088235294115,
      "grad_norm": 2.070035934448242,
      "learning_rate": 1.4471669218989282e-06,
      "loss": 2.3413,
      "step": 190
    },
    {
      "epoch": 0.04388786764705882,
      "grad_norm": 2.0481796264648438,
      "learning_rate": 1.4548238897396632e-06,
      "loss": 2.4319,
      "step": 191
    },
    {
      "epoch": 0.04411764705882353,
      "grad_norm": 2.2226293087005615,
      "learning_rate": 1.4624808575803983e-06,
      "loss": 2.6673,
      "step": 192
    },
    {
      "epoch": 0.04434742647058824,
      "grad_norm": 2.4303884506225586,
      "learning_rate": 1.4701378254211336e-06,
      "loss": 2.8528,
      "step": 193
    },
    {
      "epoch": 0.04457720588235294,
      "grad_norm": 2.2224762439727783,
      "learning_rate": 1.4777947932618684e-06,
      "loss": 2.522,
      "step": 194
    },
    {
      "epoch": 0.04480698529411765,
      "grad_norm": 2.0013816356658936,
      "learning_rate": 1.4854517611026035e-06,
      "loss": 2.455,
      "step": 195
    },
    {
      "epoch": 0.04503676470588235,
      "grad_norm": 2.485762596130371,
      "learning_rate": 1.4931087289433385e-06,
      "loss": 2.8173,
      "step": 196
    },
    {
      "epoch": 0.04526654411764706,
      "grad_norm": 2.180846929550171,
      "learning_rate": 1.5007656967840736e-06,
      "loss": 2.4424,
      "step": 197
    },
    {
      "epoch": 0.04549632352941176,
      "grad_norm": 2.2376503944396973,
      "learning_rate": 1.5084226646248086e-06,
      "loss": 2.6144,
      "step": 198
    },
    {
      "epoch": 0.04572610294117647,
      "grad_norm": 1.9989184141159058,
      "learning_rate": 1.516079632465544e-06,
      "loss": 2.5141,
      "step": 199
    },
    {
      "epoch": 0.04595588235294118,
      "grad_norm": 2.026609182357788,
      "learning_rate": 1.523736600306279e-06,
      "loss": 2.6612,
      "step": 200
    },
    {
      "epoch": 0.046185661764705885,
      "grad_norm": 2.1106185913085938,
      "learning_rate": 1.5313935681470138e-06,
      "loss": 2.6066,
      "step": 201
    },
    {
      "epoch": 0.04641544117647059,
      "grad_norm": 2.268460512161255,
      "learning_rate": 1.5390505359877489e-06,
      "loss": 2.7062,
      "step": 202
    },
    {
      "epoch": 0.046645220588235295,
      "grad_norm": 2.294201135635376,
      "learning_rate": 1.546707503828484e-06,
      "loss": 2.5225,
      "step": 203
    },
    {
      "epoch": 0.046875,
      "grad_norm": 2.006009101867676,
      "learning_rate": 1.5543644716692192e-06,
      "loss": 2.4885,
      "step": 204
    },
    {
      "epoch": 0.047104779411764705,
      "grad_norm": 2.1493492126464844,
      "learning_rate": 1.5620214395099543e-06,
      "loss": 2.4304,
      "step": 205
    },
    {
      "epoch": 0.04733455882352941,
      "grad_norm": 2.192115545272827,
      "learning_rate": 1.5696784073506893e-06,
      "loss": 2.4899,
      "step": 206
    },
    {
      "epoch": 0.047564338235294115,
      "grad_norm": 2.4735000133514404,
      "learning_rate": 1.5773353751914244e-06,
      "loss": 2.5656,
      "step": 207
    },
    {
      "epoch": 0.04779411764705882,
      "grad_norm": 1.98253333568573,
      "learning_rate": 1.5849923430321592e-06,
      "loss": 2.5935,
      "step": 208
    },
    {
      "epoch": 0.04802389705882353,
      "grad_norm": 2.4365625381469727,
      "learning_rate": 1.5926493108728943e-06,
      "loss": 2.8418,
      "step": 209
    },
    {
      "epoch": 0.04825367647058824,
      "grad_norm": 2.2607624530792236,
      "learning_rate": 1.6003062787136296e-06,
      "loss": 2.53,
      "step": 210
    },
    {
      "epoch": 0.04848345588235294,
      "grad_norm": 2.287419557571411,
      "learning_rate": 1.6079632465543646e-06,
      "loss": 2.5245,
      "step": 211
    },
    {
      "epoch": 0.04871323529411765,
      "grad_norm": 2.588458776473999,
      "learning_rate": 1.6156202143950997e-06,
      "loss": 2.5371,
      "step": 212
    },
    {
      "epoch": 0.04894301470588235,
      "grad_norm": 2.3074660301208496,
      "learning_rate": 1.6232771822358347e-06,
      "loss": 2.6362,
      "step": 213
    },
    {
      "epoch": 0.04917279411764706,
      "grad_norm": 2.235386610031128,
      "learning_rate": 1.63093415007657e-06,
      "loss": 2.7072,
      "step": 214
    },
    {
      "epoch": 0.04940257352941176,
      "grad_norm": 2.306550979614258,
      "learning_rate": 1.638591117917305e-06,
      "loss": 2.7767,
      "step": 215
    },
    {
      "epoch": 0.04963235294117647,
      "grad_norm": 2.174675703048706,
      "learning_rate": 1.64624808575804e-06,
      "loss": 2.6016,
      "step": 216
    },
    {
      "epoch": 0.04986213235294118,
      "grad_norm": 2.3074870109558105,
      "learning_rate": 1.653905053598775e-06,
      "loss": 2.6706,
      "step": 217
    },
    {
      "epoch": 0.050091911764705885,
      "grad_norm": 2.772761821746826,
      "learning_rate": 1.66156202143951e-06,
      "loss": 2.6112,
      "step": 218
    },
    {
      "epoch": 0.05032169117647059,
      "grad_norm": 2.1623382568359375,
      "learning_rate": 1.669218989280245e-06,
      "loss": 2.7309,
      "step": 219
    },
    {
      "epoch": 0.050551470588235295,
      "grad_norm": 2.19356632232666,
      "learning_rate": 1.6768759571209804e-06,
      "loss": 2.6292,
      "step": 220
    },
    {
      "epoch": 0.05078125,
      "grad_norm": 2.225954294204712,
      "learning_rate": 1.6845329249617154e-06,
      "loss": 2.5095,
      "step": 221
    },
    {
      "epoch": 0.051011029411764705,
      "grad_norm": 2.294717311859131,
      "learning_rate": 1.6921898928024505e-06,
      "loss": 2.713,
      "step": 222
    },
    {
      "epoch": 0.05124080882352941,
      "grad_norm": 2.2251570224761963,
      "learning_rate": 1.6998468606431853e-06,
      "loss": 2.5828,
      "step": 223
    },
    {
      "epoch": 0.051470588235294115,
      "grad_norm": 1.865640640258789,
      "learning_rate": 1.7075038284839204e-06,
      "loss": 2.389,
      "step": 224
    },
    {
      "epoch": 0.05170036764705882,
      "grad_norm": 2.2220137119293213,
      "learning_rate": 1.7151607963246554e-06,
      "loss": 2.6413,
      "step": 225
    },
    {
      "epoch": 0.05193014705882353,
      "grad_norm": 2.0941648483276367,
      "learning_rate": 1.7228177641653907e-06,
      "loss": 2.5233,
      "step": 226
    },
    {
      "epoch": 0.05215992647058824,
      "grad_norm": 1.8848954439163208,
      "learning_rate": 1.7304747320061258e-06,
      "loss": 2.3464,
      "step": 227
    },
    {
      "epoch": 0.05238970588235294,
      "grad_norm": 1.9022489786148071,
      "learning_rate": 1.7381316998468608e-06,
      "loss": 2.5168,
      "step": 228
    },
    {
      "epoch": 0.05261948529411765,
      "grad_norm": 2.313511610031128,
      "learning_rate": 1.7457886676875959e-06,
      "loss": 2.6733,
      "step": 229
    },
    {
      "epoch": 0.05284926470588235,
      "grad_norm": 2.2873053550720215,
      "learning_rate": 1.7534456355283307e-06,
      "loss": 2.6157,
      "step": 230
    },
    {
      "epoch": 0.05307904411764706,
      "grad_norm": 1.8187031745910645,
      "learning_rate": 1.761102603369066e-06,
      "loss": 2.3698,
      "step": 231
    },
    {
      "epoch": 0.05330882352941176,
      "grad_norm": 2.0614848136901855,
      "learning_rate": 1.768759571209801e-06,
      "loss": 2.6006,
      "step": 232
    },
    {
      "epoch": 0.05353860294117647,
      "grad_norm": 1.735693097114563,
      "learning_rate": 1.7764165390505361e-06,
      "loss": 2.1607,
      "step": 233
    },
    {
      "epoch": 0.05376838235294118,
      "grad_norm": 1.790686845779419,
      "learning_rate": 1.7840735068912712e-06,
      "loss": 2.32,
      "step": 234
    },
    {
      "epoch": 0.053998161764705885,
      "grad_norm": 2.275644063949585,
      "learning_rate": 1.7917304747320064e-06,
      "loss": 2.4061,
      "step": 235
    },
    {
      "epoch": 0.05422794117647059,
      "grad_norm": 2.1310837268829346,
      "learning_rate": 1.7993874425727415e-06,
      "loss": 2.5706,
      "step": 236
    },
    {
      "epoch": 0.054457720588235295,
      "grad_norm": 2.3456740379333496,
      "learning_rate": 1.8070444104134764e-06,
      "loss": 2.4442,
      "step": 237
    },
    {
      "epoch": 0.0546875,
      "grad_norm": 1.8543403148651123,
      "learning_rate": 1.8147013782542114e-06,
      "loss": 2.3236,
      "step": 238
    },
    {
      "epoch": 0.054917279411764705,
      "grad_norm": 2.3519320487976074,
      "learning_rate": 1.8223583460949465e-06,
      "loss": 2.5257,
      "step": 239
    },
    {
      "epoch": 0.05514705882352941,
      "grad_norm": 2.2899746894836426,
      "learning_rate": 1.8300153139356815e-06,
      "loss": 2.6831,
      "step": 240
    },
    {
      "epoch": 0.055376838235294115,
      "grad_norm": 2.200477361679077,
      "learning_rate": 1.8376722817764168e-06,
      "loss": 2.4246,
      "step": 241
    },
    {
      "epoch": 0.05560661764705882,
      "grad_norm": 2.1722354888916016,
      "learning_rate": 1.8453292496171519e-06,
      "loss": 2.3979,
      "step": 242
    },
    {
      "epoch": 0.05583639705882353,
      "grad_norm": 2.3932018280029297,
      "learning_rate": 1.852986217457887e-06,
      "loss": 2.558,
      "step": 243
    },
    {
      "epoch": 0.05606617647058824,
      "grad_norm": 2.1827502250671387,
      "learning_rate": 1.860643185298622e-06,
      "loss": 2.3516,
      "step": 244
    },
    {
      "epoch": 0.05629595588235294,
      "grad_norm": 2.267338514328003,
      "learning_rate": 1.8683001531393568e-06,
      "loss": 2.5857,
      "step": 245
    },
    {
      "epoch": 0.05652573529411765,
      "grad_norm": 1.9243355989456177,
      "learning_rate": 1.8759571209800919e-06,
      "loss": 2.3954,
      "step": 246
    },
    {
      "epoch": 0.05675551470588235,
      "grad_norm": 2.3266353607177734,
      "learning_rate": 1.8836140888208271e-06,
      "loss": 2.4215,
      "step": 247
    },
    {
      "epoch": 0.05698529411764706,
      "grad_norm": 2.1353206634521484,
      "learning_rate": 1.8912710566615622e-06,
      "loss": 2.5515,
      "step": 248
    },
    {
      "epoch": 0.05721507352941176,
      "grad_norm": 1.9190696477890015,
      "learning_rate": 1.8989280245022973e-06,
      "loss": 2.2586,
      "step": 249
    },
    {
      "epoch": 0.05744485294117647,
      "grad_norm": 1.8761839866638184,
      "learning_rate": 1.9065849923430323e-06,
      "loss": 2.2054,
      "step": 250
    },
    {
      "epoch": 0.05767463235294118,
      "grad_norm": 2.0608019828796387,
      "learning_rate": 1.9142419601837676e-06,
      "loss": 2.2715,
      "step": 251
    },
    {
      "epoch": 0.057904411764705885,
      "grad_norm": 2.0434868335723877,
      "learning_rate": 1.9218989280245022e-06,
      "loss": 2.3487,
      "step": 252
    },
    {
      "epoch": 0.05813419117647059,
      "grad_norm": 2.4267449378967285,
      "learning_rate": 1.9295558958652373e-06,
      "loss": 2.4895,
      "step": 253
    },
    {
      "epoch": 0.058363970588235295,
      "grad_norm": 1.7220484018325806,
      "learning_rate": 1.9372128637059728e-06,
      "loss": 2.1284,
      "step": 254
    },
    {
      "epoch": 0.05859375,
      "grad_norm": 2.2601945400238037,
      "learning_rate": 1.944869831546708e-06,
      "loss": 2.5551,
      "step": 255
    },
    {
      "epoch": 0.058823529411764705,
      "grad_norm": 1.9539477825164795,
      "learning_rate": 1.952526799387443e-06,
      "loss": 2.3926,
      "step": 256
    },
    {
      "epoch": 0.05905330882352941,
      "grad_norm": 1.9137632846832275,
      "learning_rate": 1.960183767228178e-06,
      "loss": 2.3969,
      "step": 257
    },
    {
      "epoch": 0.059283088235294115,
      "grad_norm": 2.115333318710327,
      "learning_rate": 1.967840735068913e-06,
      "loss": 2.3892,
      "step": 258
    },
    {
      "epoch": 0.05951286764705882,
      "grad_norm": 2.407285213470459,
      "learning_rate": 1.9754977029096476e-06,
      "loss": 2.5866,
      "step": 259
    },
    {
      "epoch": 0.05974264705882353,
      "grad_norm": 2.046645402908325,
      "learning_rate": 1.983154670750383e-06,
      "loss": 2.2524,
      "step": 260
    },
    {
      "epoch": 0.05997242647058824,
      "grad_norm": 2.7407639026641846,
      "learning_rate": 1.990811638591118e-06,
      "loss": 2.6751,
      "step": 261
    },
    {
      "epoch": 0.06020220588235294,
      "grad_norm": 1.807521104812622,
      "learning_rate": 1.9984686064318532e-06,
      "loss": 2.2379,
      "step": 262
    },
    {
      "epoch": 0.06043198529411765,
      "grad_norm": 2.095876693725586,
      "learning_rate": 2.0061255742725883e-06,
      "loss": 2.35,
      "step": 263
    },
    {
      "epoch": 0.06066176470588235,
      "grad_norm": 1.9245786666870117,
      "learning_rate": 2.0137825421133234e-06,
      "loss": 2.3282,
      "step": 264
    },
    {
      "epoch": 0.06089154411764706,
      "grad_norm": 1.9535800218582153,
      "learning_rate": 2.0214395099540584e-06,
      "loss": 2.2635,
      "step": 265
    },
    {
      "epoch": 0.06112132352941176,
      "grad_norm": 2.1721174716949463,
      "learning_rate": 2.0290964777947935e-06,
      "loss": 2.3441,
      "step": 266
    },
    {
      "epoch": 0.06135110294117647,
      "grad_norm": 2.0030465126037598,
      "learning_rate": 2.0367534456355285e-06,
      "loss": 2.2859,
      "step": 267
    },
    {
      "epoch": 0.06158088235294118,
      "grad_norm": 1.9833192825317383,
      "learning_rate": 2.0444104134762636e-06,
      "loss": 2.2559,
      "step": 268
    },
    {
      "epoch": 0.061810661764705885,
      "grad_norm": 2.2160072326660156,
      "learning_rate": 2.0520673813169986e-06,
      "loss": 2.5238,
      "step": 269
    },
    {
      "epoch": 0.06204044117647059,
      "grad_norm": 2.1729736328125,
      "learning_rate": 2.0597243491577337e-06,
      "loss": 2.348,
      "step": 270
    },
    {
      "epoch": 0.062270220588235295,
      "grad_norm": 1.678853154182434,
      "learning_rate": 2.0673813169984688e-06,
      "loss": 2.1332,
      "step": 271
    },
    {
      "epoch": 0.0625,
      "grad_norm": 2.0380585193634033,
      "learning_rate": 2.075038284839204e-06,
      "loss": 2.2732,
      "step": 272
    },
    {
      "epoch": 0.0627297794117647,
      "grad_norm": 2.0233001708984375,
      "learning_rate": 2.082695252679939e-06,
      "loss": 2.1631,
      "step": 273
    },
    {
      "epoch": 0.06295955882352941,
      "grad_norm": 1.998415470123291,
      "learning_rate": 2.090352220520674e-06,
      "loss": 2.3094,
      "step": 274
    },
    {
      "epoch": 0.06318933823529412,
      "grad_norm": 2.141355514526367,
      "learning_rate": 2.098009188361409e-06,
      "loss": 2.2757,
      "step": 275
    },
    {
      "epoch": 0.06341911764705882,
      "grad_norm": 2.291422128677368,
      "learning_rate": 2.105666156202144e-06,
      "loss": 2.6545,
      "step": 276
    },
    {
      "epoch": 0.06364889705882353,
      "grad_norm": 1.891970157623291,
      "learning_rate": 2.113323124042879e-06,
      "loss": 2.2077,
      "step": 277
    },
    {
      "epoch": 0.06387867647058823,
      "grad_norm": 2.3585846424102783,
      "learning_rate": 2.120980091883614e-06,
      "loss": 2.4445,
      "step": 278
    },
    {
      "epoch": 0.06410845588235294,
      "grad_norm": 1.9450130462646484,
      "learning_rate": 2.1286370597243492e-06,
      "loss": 2.339,
      "step": 279
    },
    {
      "epoch": 0.06433823529411764,
      "grad_norm": 1.9560604095458984,
      "learning_rate": 2.1362940275650847e-06,
      "loss": 2.3547,
      "step": 280
    },
    {
      "epoch": 0.06456801470588236,
      "grad_norm": 1.8534965515136719,
      "learning_rate": 2.1439509954058193e-06,
      "loss": 2.2075,
      "step": 281
    },
    {
      "epoch": 0.06479779411764706,
      "grad_norm": 2.1908576488494873,
      "learning_rate": 2.1516079632465544e-06,
      "loss": 2.2488,
      "step": 282
    },
    {
      "epoch": 0.06502757352941177,
      "grad_norm": 2.3008737564086914,
      "learning_rate": 2.1592649310872895e-06,
      "loss": 2.2782,
      "step": 283
    },
    {
      "epoch": 0.06525735294117647,
      "grad_norm": 1.930809497833252,
      "learning_rate": 2.1669218989280245e-06,
      "loss": 2.3437,
      "step": 284
    },
    {
      "epoch": 0.06548713235294118,
      "grad_norm": 1.7365509271621704,
      "learning_rate": 2.1745788667687596e-06,
      "loss": 1.9819,
      "step": 285
    },
    {
      "epoch": 0.06571691176470588,
      "grad_norm": 1.8532419204711914,
      "learning_rate": 2.182235834609495e-06,
      "loss": 2.106,
      "step": 286
    },
    {
      "epoch": 0.06594669117647059,
      "grad_norm": 1.9302899837493896,
      "learning_rate": 2.18989280245023e-06,
      "loss": 2.2754,
      "step": 287
    },
    {
      "epoch": 0.0661764705882353,
      "grad_norm": 1.786864995956421,
      "learning_rate": 2.1975497702909648e-06,
      "loss": 2.1627,
      "step": 288
    },
    {
      "epoch": 0.06640625,
      "grad_norm": 2.1737992763519287,
      "learning_rate": 2.2052067381317e-06,
      "loss": 2.3396,
      "step": 289
    },
    {
      "epoch": 0.0666360294117647,
      "grad_norm": 1.9360071420669556,
      "learning_rate": 2.212863705972435e-06,
      "loss": 2.3215,
      "step": 290
    },
    {
      "epoch": 0.06686580882352941,
      "grad_norm": 1.9731183052062988,
      "learning_rate": 2.2205206738131704e-06,
      "loss": 2.3166,
      "step": 291
    },
    {
      "epoch": 0.06709558823529412,
      "grad_norm": 2.026334524154663,
      "learning_rate": 2.2281776416539054e-06,
      "loss": 2.3603,
      "step": 292
    },
    {
      "epoch": 0.06732536764705882,
      "grad_norm": 1.8724623918533325,
      "learning_rate": 2.2358346094946405e-06,
      "loss": 2.0855,
      "step": 293
    },
    {
      "epoch": 0.06755514705882353,
      "grad_norm": 1.8940784931182861,
      "learning_rate": 2.2434915773353755e-06,
      "loss": 2.1493,
      "step": 294
    },
    {
      "epoch": 0.06778492647058823,
      "grad_norm": 1.9843167066574097,
      "learning_rate": 2.25114854517611e-06,
      "loss": 2.2513,
      "step": 295
    },
    {
      "epoch": 0.06801470588235294,
      "grad_norm": 2.1541128158569336,
      "learning_rate": 2.2588055130168452e-06,
      "loss": 2.335,
      "step": 296
    },
    {
      "epoch": 0.06824448529411764,
      "grad_norm": 2.073925018310547,
      "learning_rate": 2.2664624808575807e-06,
      "loss": 2.3076,
      "step": 297
    },
    {
      "epoch": 0.06847426470588236,
      "grad_norm": 1.775264024734497,
      "learning_rate": 2.2741194486983158e-06,
      "loss": 2.189,
      "step": 298
    },
    {
      "epoch": 0.06870404411764706,
      "grad_norm": 2.065979480743408,
      "learning_rate": 2.281776416539051e-06,
      "loss": 2.2937,
      "step": 299
    },
    {
      "epoch": 0.06893382352941177,
      "grad_norm": 1.8825843334197998,
      "learning_rate": 2.289433384379786e-06,
      "loss": 2.1422,
      "step": 300
    },
    {
      "epoch": 0.06916360294117647,
      "grad_norm": 2.285686731338501,
      "learning_rate": 2.297090352220521e-06,
      "loss": 2.3561,
      "step": 301
    },
    {
      "epoch": 0.06939338235294118,
      "grad_norm": 1.748541235923767,
      "learning_rate": 2.304747320061256e-06,
      "loss": 2.0848,
      "step": 302
    },
    {
      "epoch": 0.06962316176470588,
      "grad_norm": 2.1608009338378906,
      "learning_rate": 2.312404287901991e-06,
      "loss": 2.3153,
      "step": 303
    },
    {
      "epoch": 0.06985294117647059,
      "grad_norm": 1.9123177528381348,
      "learning_rate": 2.320061255742726e-06,
      "loss": 2.1983,
      "step": 304
    },
    {
      "epoch": 0.0700827205882353,
      "grad_norm": 1.926703929901123,
      "learning_rate": 2.327718223583461e-06,
      "loss": 2.2657,
      "step": 305
    },
    {
      "epoch": 0.0703125,
      "grad_norm": 2.1356632709503174,
      "learning_rate": 2.3353751914241962e-06,
      "loss": 2.2339,
      "step": 306
    },
    {
      "epoch": 0.0705422794117647,
      "grad_norm": 2.132415294647217,
      "learning_rate": 2.3430321592649313e-06,
      "loss": 2.2344,
      "step": 307
    },
    {
      "epoch": 0.07077205882352941,
      "grad_norm": 2.0503668785095215,
      "learning_rate": 2.3506891271056664e-06,
      "loss": 2.1041,
      "step": 308
    },
    {
      "epoch": 0.07100183823529412,
      "grad_norm": 1.6416869163513184,
      "learning_rate": 2.3583460949464014e-06,
      "loss": 1.9772,
      "step": 309
    },
    {
      "epoch": 0.07123161764705882,
      "grad_norm": 2.3186299800872803,
      "learning_rate": 2.3660030627871365e-06,
      "loss": 2.2522,
      "step": 310
    },
    {
      "epoch": 0.07146139705882353,
      "grad_norm": 2.003770351409912,
      "learning_rate": 2.3736600306278715e-06,
      "loss": 2.1746,
      "step": 311
    },
    {
      "epoch": 0.07169117647058823,
      "grad_norm": 2.0839662551879883,
      "learning_rate": 2.3813169984686066e-06,
      "loss": 2.1988,
      "step": 312
    },
    {
      "epoch": 0.07192095588235294,
      "grad_norm": 1.8763151168823242,
      "learning_rate": 2.3889739663093416e-06,
      "loss": 2.1091,
      "step": 313
    },
    {
      "epoch": 0.07215073529411764,
      "grad_norm": 2.190833806991577,
      "learning_rate": 2.3966309341500767e-06,
      "loss": 2.3603,
      "step": 314
    },
    {
      "epoch": 0.07238051470588236,
      "grad_norm": 1.7471586465835571,
      "learning_rate": 2.4042879019908118e-06,
      "loss": 1.9414,
      "step": 315
    },
    {
      "epoch": 0.07261029411764706,
      "grad_norm": 1.7756420373916626,
      "learning_rate": 2.411944869831547e-06,
      "loss": 2.013,
      "step": 316
    },
    {
      "epoch": 0.07284007352941177,
      "grad_norm": 1.842073917388916,
      "learning_rate": 2.419601837672282e-06,
      "loss": 2.059,
      "step": 317
    },
    {
      "epoch": 0.07306985294117647,
      "grad_norm": 2.0382473468780518,
      "learning_rate": 2.427258805513017e-06,
      "loss": 2.151,
      "step": 318
    },
    {
      "epoch": 0.07329963235294118,
      "grad_norm": 1.7626914978027344,
      "learning_rate": 2.434915773353752e-06,
      "loss": 2.0194,
      "step": 319
    },
    {
      "epoch": 0.07352941176470588,
      "grad_norm": 1.4668664932250977,
      "learning_rate": 2.442572741194487e-06,
      "loss": 1.8661,
      "step": 320
    },
    {
      "epoch": 0.07375919117647059,
      "grad_norm": 2.09191632270813,
      "learning_rate": 2.450229709035222e-06,
      "loss": 2.1073,
      "step": 321
    },
    {
      "epoch": 0.0739889705882353,
      "grad_norm": 2.0111637115478516,
      "learning_rate": 2.4578866768759576e-06,
      "loss": 2.1314,
      "step": 322
    },
    {
      "epoch": 0.07421875,
      "grad_norm": 2.1499245166778564,
      "learning_rate": 2.4655436447166927e-06,
      "loss": 2.125,
      "step": 323
    },
    {
      "epoch": 0.0744485294117647,
      "grad_norm": 1.6938579082489014,
      "learning_rate": 2.4732006125574273e-06,
      "loss": 1.9924,
      "step": 324
    },
    {
      "epoch": 0.07467830882352941,
      "grad_norm": 1.7301870584487915,
      "learning_rate": 2.4808575803981623e-06,
      "loss": 1.9094,
      "step": 325
    },
    {
      "epoch": 0.07490808823529412,
      "grad_norm": 2.1067755222320557,
      "learning_rate": 2.4885145482388974e-06,
      "loss": 2.1609,
      "step": 326
    },
    {
      "epoch": 0.07513786764705882,
      "grad_norm": 2.5946459770202637,
      "learning_rate": 2.4961715160796325e-06,
      "loss": 2.4089,
      "step": 327
    },
    {
      "epoch": 0.07536764705882353,
      "grad_norm": 1.9346801042556763,
      "learning_rate": 2.5038284839203675e-06,
      "loss": 2.0647,
      "step": 328
    },
    {
      "epoch": 0.07559742647058823,
      "grad_norm": 2.1434500217437744,
      "learning_rate": 2.5114854517611026e-06,
      "loss": 2.1415,
      "step": 329
    },
    {
      "epoch": 0.07582720588235294,
      "grad_norm": 1.7885267734527588,
      "learning_rate": 2.5191424196018376e-06,
      "loss": 1.9027,
      "step": 330
    },
    {
      "epoch": 0.07605698529411764,
      "grad_norm": 1.879801869392395,
      "learning_rate": 2.5267993874425727e-06,
      "loss": 2.1303,
      "step": 331
    },
    {
      "epoch": 0.07628676470588236,
      "grad_norm": 1.922457218170166,
      "learning_rate": 2.5344563552833078e-06,
      "loss": 1.9092,
      "step": 332
    },
    {
      "epoch": 0.07651654411764706,
      "grad_norm": 1.9890722036361694,
      "learning_rate": 2.542113323124043e-06,
      "loss": 1.9734,
      "step": 333
    },
    {
      "epoch": 0.07674632352941177,
      "grad_norm": 1.7124862670898438,
      "learning_rate": 2.5497702909647783e-06,
      "loss": 1.8497,
      "step": 334
    },
    {
      "epoch": 0.07697610294117647,
      "grad_norm": 1.6152719259262085,
      "learning_rate": 2.5574272588055134e-06,
      "loss": 1.7863,
      "step": 335
    },
    {
      "epoch": 0.07720588235294118,
      "grad_norm": 1.7495698928833008,
      "learning_rate": 2.5650842266462484e-06,
      "loss": 1.8423,
      "step": 336
    },
    {
      "epoch": 0.07743566176470588,
      "grad_norm": 1.9718966484069824,
      "learning_rate": 2.5727411944869835e-06,
      "loss": 2.0262,
      "step": 337
    },
    {
      "epoch": 0.07766544117647059,
      "grad_norm": 1.6682548522949219,
      "learning_rate": 2.5803981623277185e-06,
      "loss": 1.8943,
      "step": 338
    },
    {
      "epoch": 0.0778952205882353,
      "grad_norm": 1.911359190940857,
      "learning_rate": 2.5880551301684536e-06,
      "loss": 1.9053,
      "step": 339
    },
    {
      "epoch": 0.078125,
      "grad_norm": 1.831655740737915,
      "learning_rate": 2.5957120980091886e-06,
      "loss": 1.9395,
      "step": 340
    },
    {
      "epoch": 0.0783547794117647,
      "grad_norm": 1.8630484342575073,
      "learning_rate": 2.6033690658499237e-06,
      "loss": 1.9831,
      "step": 341
    },
    {
      "epoch": 0.07858455882352941,
      "grad_norm": 1.7613693475723267,
      "learning_rate": 2.611026033690659e-06,
      "loss": 1.98,
      "step": 342
    },
    {
      "epoch": 0.07881433823529412,
      "grad_norm": 1.7996301651000977,
      "learning_rate": 2.6186830015313934e-06,
      "loss": 1.9667,
      "step": 343
    },
    {
      "epoch": 0.07904411764705882,
      "grad_norm": 1.8439764976501465,
      "learning_rate": 2.6263399693721285e-06,
      "loss": 1.8718,
      "step": 344
    },
    {
      "epoch": 0.07927389705882353,
      "grad_norm": 2.288653612136841,
      "learning_rate": 2.633996937212864e-06,
      "loss": 2.0817,
      "step": 345
    },
    {
      "epoch": 0.07950367647058823,
      "grad_norm": 1.9727060794830322,
      "learning_rate": 2.641653905053599e-06,
      "loss": 1.9025,
      "step": 346
    },
    {
      "epoch": 0.07973345588235294,
      "grad_norm": 1.526536226272583,
      "learning_rate": 2.649310872894334e-06,
      "loss": 1.7814,
      "step": 347
    },
    {
      "epoch": 0.07996323529411764,
      "grad_norm": 2.4909603595733643,
      "learning_rate": 2.656967840735069e-06,
      "loss": 2.0444,
      "step": 348
    },
    {
      "epoch": 0.08019301470588236,
      "grad_norm": 1.84552001953125,
      "learning_rate": 2.664624808575804e-06,
      "loss": 1.8295,
      "step": 349
    },
    {
      "epoch": 0.08042279411764706,
      "grad_norm": 1.9498207569122314,
      "learning_rate": 2.6722817764165392e-06,
      "loss": 1.9031,
      "step": 350
    },
    {
      "epoch": 0.08065257352941177,
      "grad_norm": 2.3889031410217285,
      "learning_rate": 2.6799387442572743e-06,
      "loss": 1.9564,
      "step": 351
    },
    {
      "epoch": 0.08088235294117647,
      "grad_norm": 2.07387375831604,
      "learning_rate": 2.6875957120980093e-06,
      "loss": 1.7736,
      "step": 352
    },
    {
      "epoch": 0.08111213235294118,
      "grad_norm": 2.1626029014587402,
      "learning_rate": 2.695252679938745e-06,
      "loss": 2.0585,
      "step": 353
    },
    {
      "epoch": 0.08134191176470588,
      "grad_norm": 1.919172763824463,
      "learning_rate": 2.70290964777948e-06,
      "loss": 1.8648,
      "step": 354
    },
    {
      "epoch": 0.08157169117647059,
      "grad_norm": 2.247734785079956,
      "learning_rate": 2.710566615620215e-06,
      "loss": 2.0443,
      "step": 355
    },
    {
      "epoch": 0.0818014705882353,
      "grad_norm": 1.8282365798950195,
      "learning_rate": 2.71822358346095e-06,
      "loss": 1.9552,
      "step": 356
    },
    {
      "epoch": 0.08203125,
      "grad_norm": 1.8125911951065063,
      "learning_rate": 2.7258805513016846e-06,
      "loss": 1.8733,
      "step": 357
    },
    {
      "epoch": 0.0822610294117647,
      "grad_norm": 1.9108173847198486,
      "learning_rate": 2.7335375191424197e-06,
      "loss": 1.9393,
      "step": 358
    },
    {
      "epoch": 0.08249080882352941,
      "grad_norm": 1.8323805332183838,
      "learning_rate": 2.7411944869831548e-06,
      "loss": 1.8481,
      "step": 359
    },
    {
      "epoch": 0.08272058823529412,
      "grad_norm": 2.3025364875793457,
      "learning_rate": 2.74885145482389e-06,
      "loss": 1.8469,
      "step": 360
    },
    {
      "epoch": 0.08295036764705882,
      "grad_norm": 1.534771203994751,
      "learning_rate": 2.756508422664625e-06,
      "loss": 1.6626,
      "step": 361
    },
    {
      "epoch": 0.08318014705882353,
      "grad_norm": 2.0017693042755127,
      "learning_rate": 2.76416539050536e-06,
      "loss": 1.8138,
      "step": 362
    },
    {
      "epoch": 0.08340992647058823,
      "grad_norm": 1.8403284549713135,
      "learning_rate": 2.771822358346095e-06,
      "loss": 1.7208,
      "step": 363
    },
    {
      "epoch": 0.08363970588235294,
      "grad_norm": 1.9836862087249756,
      "learning_rate": 2.77947932618683e-06,
      "loss": 1.9341,
      "step": 364
    },
    {
      "epoch": 0.08386948529411764,
      "grad_norm": 1.739298701286316,
      "learning_rate": 2.7871362940275655e-06,
      "loss": 1.6834,
      "step": 365
    },
    {
      "epoch": 0.08409926470588236,
      "grad_norm": 1.8285092115402222,
      "learning_rate": 2.7947932618683006e-06,
      "loss": 1.8745,
      "step": 366
    },
    {
      "epoch": 0.08432904411764706,
      "grad_norm": 1.6417139768600464,
      "learning_rate": 2.8024502297090357e-06,
      "loss": 1.7261,
      "step": 367
    },
    {
      "epoch": 0.08455882352941177,
      "grad_norm": 1.9466233253479004,
      "learning_rate": 2.8101071975497707e-06,
      "loss": 1.7668,
      "step": 368
    },
    {
      "epoch": 0.08478860294117647,
      "grad_norm": 2.056882619857788,
      "learning_rate": 2.8177641653905058e-06,
      "loss": 1.8438,
      "step": 369
    },
    {
      "epoch": 0.08501838235294118,
      "grad_norm": 1.8126606941223145,
      "learning_rate": 2.825421133231241e-06,
      "loss": 1.7288,
      "step": 370
    },
    {
      "epoch": 0.08524816176470588,
      "grad_norm": 1.9517532587051392,
      "learning_rate": 2.833078101071976e-06,
      "loss": 1.7614,
      "step": 371
    },
    {
      "epoch": 0.08547794117647059,
      "grad_norm": 1.9710694551467896,
      "learning_rate": 2.8407350689127105e-06,
      "loss": 1.7857,
      "step": 372
    },
    {
      "epoch": 0.0857077205882353,
      "grad_norm": 2.2820043563842773,
      "learning_rate": 2.8483920367534456e-06,
      "loss": 1.7173,
      "step": 373
    },
    {
      "epoch": 0.0859375,
      "grad_norm": 1.9343113899230957,
      "learning_rate": 2.8560490045941806e-06,
      "loss": 1.7667,
      "step": 374
    },
    {
      "epoch": 0.0861672794117647,
      "grad_norm": 2.4327361583709717,
      "learning_rate": 2.8637059724349157e-06,
      "loss": 1.8158,
      "step": 375
    },
    {
      "epoch": 0.08639705882352941,
      "grad_norm": 1.9715466499328613,
      "learning_rate": 2.871362940275651e-06,
      "loss": 1.808,
      "step": 376
    },
    {
      "epoch": 0.08662683823529412,
      "grad_norm": 2.1512510776519775,
      "learning_rate": 2.8790199081163862e-06,
      "loss": 1.7929,
      "step": 377
    },
    {
      "epoch": 0.08685661764705882,
      "grad_norm": 1.7148360013961792,
      "learning_rate": 2.8866768759571213e-06,
      "loss": 1.7202,
      "step": 378
    },
    {
      "epoch": 0.08708639705882353,
      "grad_norm": 1.7425153255462646,
      "learning_rate": 2.8943338437978564e-06,
      "loss": 1.7092,
      "step": 379
    },
    {
      "epoch": 0.08731617647058823,
      "grad_norm": 2.295478582382202,
      "learning_rate": 2.9019908116385914e-06,
      "loss": 1.9158,
      "step": 380
    },
    {
      "epoch": 0.08754595588235294,
      "grad_norm": 1.5954413414001465,
      "learning_rate": 2.9096477794793265e-06,
      "loss": 1.6333,
      "step": 381
    },
    {
      "epoch": 0.08777573529411764,
      "grad_norm": 1.9488790035247803,
      "learning_rate": 2.9173047473200615e-06,
      "loss": 1.6767,
      "step": 382
    },
    {
      "epoch": 0.08800551470588236,
      "grad_norm": 2.0304925441741943,
      "learning_rate": 2.9249617151607966e-06,
      "loss": 1.6905,
      "step": 383
    },
    {
      "epoch": 0.08823529411764706,
      "grad_norm": 1.8467704057693481,
      "learning_rate": 2.9326186830015316e-06,
      "loss": 1.6534,
      "step": 384
    },
    {
      "epoch": 0.08846507352941177,
      "grad_norm": 1.903735637664795,
      "learning_rate": 2.940275650842267e-06,
      "loss": 1.7009,
      "step": 385
    },
    {
      "epoch": 0.08869485294117647,
      "grad_norm": 1.954923391342163,
      "learning_rate": 2.9479326186830013e-06,
      "loss": 1.6777,
      "step": 386
    },
    {
      "epoch": 0.08892463235294118,
      "grad_norm": 1.6665247678756714,
      "learning_rate": 2.955589586523737e-06,
      "loss": 1.6107,
      "step": 387
    },
    {
      "epoch": 0.08915441176470588,
      "grad_norm": 1.7881649732589722,
      "learning_rate": 2.963246554364472e-06,
      "loss": 1.5297,
      "step": 388
    },
    {
      "epoch": 0.08938419117647059,
      "grad_norm": 1.9966014623641968,
      "learning_rate": 2.970903522205207e-06,
      "loss": 1.7345,
      "step": 389
    },
    {
      "epoch": 0.0896139705882353,
      "grad_norm": 1.7613824605941772,
      "learning_rate": 2.978560490045942e-06,
      "loss": 1.59,
      "step": 390
    },
    {
      "epoch": 0.08984375,
      "grad_norm": 1.7342568635940552,
      "learning_rate": 2.986217457886677e-06,
      "loss": 1.5599,
      "step": 391
    },
    {
      "epoch": 0.0900735294117647,
      "grad_norm": 1.6989309787750244,
      "learning_rate": 2.993874425727412e-06,
      "loss": 1.526,
      "step": 392
    },
    {
      "epoch": 0.09030330882352941,
      "grad_norm": 1.7870112657546997,
      "learning_rate": 3.001531393568147e-06,
      "loss": 1.6537,
      "step": 393
    },
    {
      "epoch": 0.09053308823529412,
      "grad_norm": 1.4903067350387573,
      "learning_rate": 3.0091883614088822e-06,
      "loss": 1.5568,
      "step": 394
    },
    {
      "epoch": 0.09076286764705882,
      "grad_norm": 1.8084312677383423,
      "learning_rate": 3.0168453292496173e-06,
      "loss": 1.6063,
      "step": 395
    },
    {
      "epoch": 0.09099264705882353,
      "grad_norm": 1.8757073879241943,
      "learning_rate": 3.0245022970903528e-06,
      "loss": 1.623,
      "step": 396
    },
    {
      "epoch": 0.09122242647058823,
      "grad_norm": 1.611824631690979,
      "learning_rate": 3.032159264931088e-06,
      "loss": 1.5194,
      "step": 397
    },
    {
      "epoch": 0.09145220588235294,
      "grad_norm": 1.8432389497756958,
      "learning_rate": 3.039816232771823e-06,
      "loss": 1.6007,
      "step": 398
    },
    {
      "epoch": 0.09168198529411764,
      "grad_norm": 1.9093106985092163,
      "learning_rate": 3.047473200612558e-06,
      "loss": 1.5978,
      "step": 399
    },
    {
      "epoch": 0.09191176470588236,
      "grad_norm": 1.6326346397399902,
      "learning_rate": 3.055130168453293e-06,
      "loss": 1.5087,
      "step": 400
    },
    {
      "epoch": 0.09214154411764706,
      "grad_norm": 1.807114839553833,
      "learning_rate": 3.0627871362940276e-06,
      "loss": 1.5201,
      "step": 401
    },
    {
      "epoch": 0.09237132352941177,
      "grad_norm": 1.877950668334961,
      "learning_rate": 3.0704441041347627e-06,
      "loss": 1.6386,
      "step": 402
    },
    {
      "epoch": 0.09260110294117647,
      "grad_norm": 1.8633267879486084,
      "learning_rate": 3.0781010719754978e-06,
      "loss": 1.5549,
      "step": 403
    },
    {
      "epoch": 0.09283088235294118,
      "grad_norm": 1.5589135885238647,
      "learning_rate": 3.085758039816233e-06,
      "loss": 1.4866,
      "step": 404
    },
    {
      "epoch": 0.09306066176470588,
      "grad_norm": 1.6713917255401611,
      "learning_rate": 3.093415007656968e-06,
      "loss": 1.4681,
      "step": 405
    },
    {
      "epoch": 0.09329044117647059,
      "grad_norm": 1.8142485618591309,
      "learning_rate": 3.101071975497703e-06,
      "loss": 1.5602,
      "step": 406
    },
    {
      "epoch": 0.0935202205882353,
      "grad_norm": 1.6728568077087402,
      "learning_rate": 3.1087289433384384e-06,
      "loss": 1.4592,
      "step": 407
    },
    {
      "epoch": 0.09375,
      "grad_norm": 1.5075141191482544,
      "learning_rate": 3.1163859111791735e-06,
      "loss": 1.431,
      "step": 408
    },
    {
      "epoch": 0.0939797794117647,
      "grad_norm": 2.266221046447754,
      "learning_rate": 3.1240428790199085e-06,
      "loss": 1.7458,
      "step": 409
    },
    {
      "epoch": 0.09420955882352941,
      "grad_norm": 1.6473414897918701,
      "learning_rate": 3.1316998468606436e-06,
      "loss": 1.4833,
      "step": 410
    },
    {
      "epoch": 0.09443933823529412,
      "grad_norm": 1.7731064558029175,
      "learning_rate": 3.1393568147013786e-06,
      "loss": 1.4708,
      "step": 411
    },
    {
      "epoch": 0.09466911764705882,
      "grad_norm": 1.5449962615966797,
      "learning_rate": 3.1470137825421137e-06,
      "loss": 1.5242,
      "step": 412
    },
    {
      "epoch": 0.09489889705882353,
      "grad_norm": 1.8856992721557617,
      "learning_rate": 3.1546707503828488e-06,
      "loss": 1.4671,
      "step": 413
    },
    {
      "epoch": 0.09512867647058823,
      "grad_norm": 1.7286385297775269,
      "learning_rate": 3.162327718223584e-06,
      "loss": 1.4275,
      "step": 414
    },
    {
      "epoch": 0.09535845588235294,
      "grad_norm": 1.7514076232910156,
      "learning_rate": 3.1699846860643185e-06,
      "loss": 1.5031,
      "step": 415
    },
    {
      "epoch": 0.09558823529411764,
      "grad_norm": 1.7509204149246216,
      "learning_rate": 3.1776416539050535e-06,
      "loss": 1.4067,
      "step": 416
    },
    {
      "epoch": 0.09581801470588236,
      "grad_norm": 1.7744723558425903,
      "learning_rate": 3.1852986217457886e-06,
      "loss": 1.4845,
      "step": 417
    },
    {
      "epoch": 0.09604779411764706,
      "grad_norm": 1.5696666240692139,
      "learning_rate": 3.192955589586524e-06,
      "loss": 1.4384,
      "step": 418
    },
    {
      "epoch": 0.09627757352941177,
      "grad_norm": 1.5093914270401,
      "learning_rate": 3.200612557427259e-06,
      "loss": 1.4565,
      "step": 419
    },
    {
      "epoch": 0.09650735294117647,
      "grad_norm": 1.8069876432418823,
      "learning_rate": 3.208269525267994e-06,
      "loss": 1.5707,
      "step": 420
    },
    {
      "epoch": 0.09673713235294118,
      "grad_norm": 1.5182607173919678,
      "learning_rate": 3.2159264931087292e-06,
      "loss": 1.3002,
      "step": 421
    },
    {
      "epoch": 0.09696691176470588,
      "grad_norm": 1.5094486474990845,
      "learning_rate": 3.2235834609494643e-06,
      "loss": 1.4148,
      "step": 422
    },
    {
      "epoch": 0.09719669117647059,
      "grad_norm": 1.670164942741394,
      "learning_rate": 3.2312404287901994e-06,
      "loss": 1.3813,
      "step": 423
    },
    {
      "epoch": 0.0974264705882353,
      "grad_norm": 1.5661293268203735,
      "learning_rate": 3.2388973966309344e-06,
      "loss": 1.4158,
      "step": 424
    },
    {
      "epoch": 0.09765625,
      "grad_norm": 1.539616346359253,
      "learning_rate": 3.2465543644716695e-06,
      "loss": 1.4303,
      "step": 425
    },
    {
      "epoch": 0.0978860294117647,
      "grad_norm": 1.5577324628829956,
      "learning_rate": 3.2542113323124045e-06,
      "loss": 1.3673,
      "step": 426
    },
    {
      "epoch": 0.09811580882352941,
      "grad_norm": 1.2719776630401611,
      "learning_rate": 3.26186830015314e-06,
      "loss": 1.3101,
      "step": 427
    },
    {
      "epoch": 0.09834558823529412,
      "grad_norm": 1.5509707927703857,
      "learning_rate": 3.269525267993875e-06,
      "loss": 1.4032,
      "step": 428
    },
    {
      "epoch": 0.09857536764705882,
      "grad_norm": 1.5013283491134644,
      "learning_rate": 3.27718223583461e-06,
      "loss": 1.3312,
      "step": 429
    },
    {
      "epoch": 0.09880514705882353,
      "grad_norm": 1.3669898509979248,
      "learning_rate": 3.2848392036753448e-06,
      "loss": 1.2968,
      "step": 430
    },
    {
      "epoch": 0.09903492647058823,
      "grad_norm": 1.5075711011886597,
      "learning_rate": 3.29249617151608e-06,
      "loss": 1.3338,
      "step": 431
    },
    {
      "epoch": 0.09926470588235294,
      "grad_norm": 1.5800752639770508,
      "learning_rate": 3.300153139356815e-06,
      "loss": 1.3613,
      "step": 432
    },
    {
      "epoch": 0.09949448529411764,
      "grad_norm": 1.6205050945281982,
      "learning_rate": 3.30781010719755e-06,
      "loss": 1.3105,
      "step": 433
    },
    {
      "epoch": 0.09972426470588236,
      "grad_norm": 1.5375289916992188,
      "learning_rate": 3.315467075038285e-06,
      "loss": 1.3749,
      "step": 434
    },
    {
      "epoch": 0.09995404411764706,
      "grad_norm": 1.4609670639038086,
      "learning_rate": 3.32312404287902e-06,
      "loss": 1.3017,
      "step": 435
    },
    {
      "epoch": 0.10018382352941177,
      "grad_norm": 1.4865262508392334,
      "learning_rate": 3.330781010719755e-06,
      "loss": 1.3088,
      "step": 436
    },
    {
      "epoch": 0.10041360294117647,
      "grad_norm": 1.639006495475769,
      "learning_rate": 3.33843797856049e-06,
      "loss": 1.2855,
      "step": 437
    },
    {
      "epoch": 0.10064338235294118,
      "grad_norm": 1.345940351486206,
      "learning_rate": 3.3460949464012257e-06,
      "loss": 1.3268,
      "step": 438
    },
    {
      "epoch": 0.10087316176470588,
      "grad_norm": 1.473878264427185,
      "learning_rate": 3.3537519142419607e-06,
      "loss": 1.4001,
      "step": 439
    },
    {
      "epoch": 0.10110294117647059,
      "grad_norm": 1.3792866468429565,
      "learning_rate": 3.3614088820826958e-06,
      "loss": 1.3612,
      "step": 440
    },
    {
      "epoch": 0.1013327205882353,
      "grad_norm": 1.4883232116699219,
      "learning_rate": 3.369065849923431e-06,
      "loss": 1.278,
      "step": 441
    },
    {
      "epoch": 0.1015625,
      "grad_norm": 1.983957290649414,
      "learning_rate": 3.376722817764166e-06,
      "loss": 1.41,
      "step": 442
    },
    {
      "epoch": 0.1017922794117647,
      "grad_norm": 1.4097416400909424,
      "learning_rate": 3.384379785604901e-06,
      "loss": 1.2807,
      "step": 443
    },
    {
      "epoch": 0.10202205882352941,
      "grad_norm": 1.4864697456359863,
      "learning_rate": 3.3920367534456356e-06,
      "loss": 1.327,
      "step": 444
    },
    {
      "epoch": 0.10225183823529412,
      "grad_norm": 1.5832411050796509,
      "learning_rate": 3.3996937212863706e-06,
      "loss": 1.2304,
      "step": 445
    },
    {
      "epoch": 0.10248161764705882,
      "grad_norm": 1.7169318199157715,
      "learning_rate": 3.4073506891271057e-06,
      "loss": 1.3019,
      "step": 446
    },
    {
      "epoch": 0.10271139705882353,
      "grad_norm": 1.4734416007995605,
      "learning_rate": 3.4150076569678408e-06,
      "loss": 1.2271,
      "step": 447
    },
    {
      "epoch": 0.10294117647058823,
      "grad_norm": 1.6618456840515137,
      "learning_rate": 3.422664624808576e-06,
      "loss": 1.3473,
      "step": 448
    },
    {
      "epoch": 0.10317095588235294,
      "grad_norm": 1.4081627130508423,
      "learning_rate": 3.430321592649311e-06,
      "loss": 1.2106,
      "step": 449
    },
    {
      "epoch": 0.10340073529411764,
      "grad_norm": 1.2975351810455322,
      "learning_rate": 3.4379785604900464e-06,
      "loss": 1.1908,
      "step": 450
    },
    {
      "epoch": 0.10363051470588236,
      "grad_norm": 1.5281248092651367,
      "learning_rate": 3.4456355283307814e-06,
      "loss": 1.2738,
      "step": 451
    },
    {
      "epoch": 0.10386029411764706,
      "grad_norm": 1.600077509880066,
      "learning_rate": 3.4532924961715165e-06,
      "loss": 1.2389,
      "step": 452
    },
    {
      "epoch": 0.10409007352941177,
      "grad_norm": 1.4401490688323975,
      "learning_rate": 3.4609494640122515e-06,
      "loss": 1.3503,
      "step": 453
    },
    {
      "epoch": 0.10431985294117647,
      "grad_norm": 1.4550023078918457,
      "learning_rate": 3.4686064318529866e-06,
      "loss": 1.3142,
      "step": 454
    },
    {
      "epoch": 0.10454963235294118,
      "grad_norm": 1.6054160594940186,
      "learning_rate": 3.4762633996937216e-06,
      "loss": 1.1631,
      "step": 455
    },
    {
      "epoch": 0.10477941176470588,
      "grad_norm": 1.4812582731246948,
      "learning_rate": 3.4839203675344567e-06,
      "loss": 1.1905,
      "step": 456
    },
    {
      "epoch": 0.10500919117647059,
      "grad_norm": 1.5488334894180298,
      "learning_rate": 3.4915773353751918e-06,
      "loss": 1.27,
      "step": 457
    },
    {
      "epoch": 0.1052389705882353,
      "grad_norm": 1.5313800573349,
      "learning_rate": 3.4992343032159272e-06,
      "loss": 1.2758,
      "step": 458
    },
    {
      "epoch": 0.10546875,
      "grad_norm": 1.3271968364715576,
      "learning_rate": 3.5068912710566615e-06,
      "loss": 1.263,
      "step": 459
    },
    {
      "epoch": 0.1056985294117647,
      "grad_norm": 1.3347752094268799,
      "learning_rate": 3.5145482388973965e-06,
      "loss": 1.1796,
      "step": 460
    },
    {
      "epoch": 0.10592830882352941,
      "grad_norm": 1.4107547998428345,
      "learning_rate": 3.522205206738132e-06,
      "loss": 1.1947,
      "step": 461
    },
    {
      "epoch": 0.10615808823529412,
      "grad_norm": 1.2709068059921265,
      "learning_rate": 3.529862174578867e-06,
      "loss": 1.19,
      "step": 462
    },
    {
      "epoch": 0.10638786764705882,
      "grad_norm": 1.505537748336792,
      "learning_rate": 3.537519142419602e-06,
      "loss": 1.1397,
      "step": 463
    },
    {
      "epoch": 0.10661764705882353,
      "grad_norm": 1.5837035179138184,
      "learning_rate": 3.545176110260337e-06,
      "loss": 1.1138,
      "step": 464
    },
    {
      "epoch": 0.10684742647058823,
      "grad_norm": 1.4319889545440674,
      "learning_rate": 3.5528330781010722e-06,
      "loss": 1.1348,
      "step": 465
    },
    {
      "epoch": 0.10707720588235294,
      "grad_norm": 1.4727756977081299,
      "learning_rate": 3.5604900459418073e-06,
      "loss": 1.1761,
      "step": 466
    },
    {
      "epoch": 0.10730698529411764,
      "grad_norm": 1.5354870557785034,
      "learning_rate": 3.5681470137825423e-06,
      "loss": 1.0769,
      "step": 467
    },
    {
      "epoch": 0.10753676470588236,
      "grad_norm": 1.5315806865692139,
      "learning_rate": 3.5758039816232774e-06,
      "loss": 1.1563,
      "step": 468
    },
    {
      "epoch": 0.10776654411764706,
      "grad_norm": 1.485456109046936,
      "learning_rate": 3.583460949464013e-06,
      "loss": 1.1932,
      "step": 469
    },
    {
      "epoch": 0.10799632352941177,
      "grad_norm": 1.305438756942749,
      "learning_rate": 3.591117917304748e-06,
      "loss": 1.0701,
      "step": 470
    },
    {
      "epoch": 0.10822610294117647,
      "grad_norm": 1.4971277713775635,
      "learning_rate": 3.598774885145483e-06,
      "loss": 1.1643,
      "step": 471
    },
    {
      "epoch": 0.10845588235294118,
      "grad_norm": 1.979385495185852,
      "learning_rate": 3.606431852986218e-06,
      "loss": 1.1163,
      "step": 472
    },
    {
      "epoch": 0.10868566176470588,
      "grad_norm": 1.2552558183670044,
      "learning_rate": 3.6140888208269527e-06,
      "loss": 1.0537,
      "step": 473
    },
    {
      "epoch": 0.10891544117647059,
      "grad_norm": 1.167103886604309,
      "learning_rate": 3.6217457886676878e-06,
      "loss": 1.1495,
      "step": 474
    },
    {
      "epoch": 0.1091452205882353,
      "grad_norm": 1.502172827720642,
      "learning_rate": 3.629402756508423e-06,
      "loss": 1.2019,
      "step": 475
    },
    {
      "epoch": 0.109375,
      "grad_norm": 1.394030213356018,
      "learning_rate": 3.637059724349158e-06,
      "loss": 1.1224,
      "step": 476
    },
    {
      "epoch": 0.1096047794117647,
      "grad_norm": 1.481812834739685,
      "learning_rate": 3.644716692189893e-06,
      "loss": 1.164,
      "step": 477
    },
    {
      "epoch": 0.10983455882352941,
      "grad_norm": 1.5948909521102905,
      "learning_rate": 3.652373660030628e-06,
      "loss": 1.1336,
      "step": 478
    },
    {
      "epoch": 0.11006433823529412,
      "grad_norm": 1.5704761743545532,
      "learning_rate": 3.660030627871363e-06,
      "loss": 1.0967,
      "step": 479
    },
    {
      "epoch": 0.11029411764705882,
      "grad_norm": 1.3479493856430054,
      "learning_rate": 3.667687595712098e-06,
      "loss": 1.0224,
      "step": 480
    },
    {
      "epoch": 0.11052389705882353,
      "grad_norm": 1.4663851261138916,
      "learning_rate": 3.6753445635528336e-06,
      "loss": 1.0498,
      "step": 481
    },
    {
      "epoch": 0.11075367647058823,
      "grad_norm": 1.4404994249343872,
      "learning_rate": 3.6830015313935687e-06,
      "loss": 1.0483,
      "step": 482
    },
    {
      "epoch": 0.11098345588235294,
      "grad_norm": 1.3901896476745605,
      "learning_rate": 3.6906584992343037e-06,
      "loss": 1.1323,
      "step": 483
    },
    {
      "epoch": 0.11121323529411764,
      "grad_norm": 1.5300947427749634,
      "learning_rate": 3.6983154670750388e-06,
      "loss": 1.1805,
      "step": 484
    },
    {
      "epoch": 0.11144301470588236,
      "grad_norm": 1.3988580703735352,
      "learning_rate": 3.705972434915774e-06,
      "loss": 0.9835,
      "step": 485
    },
    {
      "epoch": 0.11167279411764706,
      "grad_norm": 1.5145338773727417,
      "learning_rate": 3.713629402756509e-06,
      "loss": 1.0699,
      "step": 486
    },
    {
      "epoch": 0.11190257352941177,
      "grad_norm": 1.456239104270935,
      "learning_rate": 3.721286370597244e-06,
      "loss": 1.1219,
      "step": 487
    },
    {
      "epoch": 0.11213235294117647,
      "grad_norm": 1.2420134544372559,
      "learning_rate": 3.7289433384379786e-06,
      "loss": 0.9811,
      "step": 488
    },
    {
      "epoch": 0.11236213235294118,
      "grad_norm": 1.3910959959030151,
      "learning_rate": 3.7366003062787136e-06,
      "loss": 1.0789,
      "step": 489
    },
    {
      "epoch": 0.11259191176470588,
      "grad_norm": 1.2960015535354614,
      "learning_rate": 3.7442572741194487e-06,
      "loss": 1.0537,
      "step": 490
    },
    {
      "epoch": 0.11282169117647059,
      "grad_norm": 1.5088108777999878,
      "learning_rate": 3.7519142419601838e-06,
      "loss": 1.018,
      "step": 491
    },
    {
      "epoch": 0.1130514705882353,
      "grad_norm": 1.2221678495407104,
      "learning_rate": 3.7595712098009192e-06,
      "loss": 0.9958,
      "step": 492
    },
    {
      "epoch": 0.11328125,
      "grad_norm": 1.5350316762924194,
      "learning_rate": 3.7672281776416543e-06,
      "loss": 1.0055,
      "step": 493
    },
    {
      "epoch": 0.1135110294117647,
      "grad_norm": 1.403223991394043,
      "learning_rate": 3.7748851454823894e-06,
      "loss": 0.9819,
      "step": 494
    },
    {
      "epoch": 0.11374080882352941,
      "grad_norm": 1.3047109842300415,
      "learning_rate": 3.7825421133231244e-06,
      "loss": 1.0457,
      "step": 495
    },
    {
      "epoch": 0.11397058823529412,
      "grad_norm": 1.4856904745101929,
      "learning_rate": 3.7901990811638595e-06,
      "loss": 0.9668,
      "step": 496
    },
    {
      "epoch": 0.11420036764705882,
      "grad_norm": 1.4393558502197266,
      "learning_rate": 3.7978560490045945e-06,
      "loss": 1.0079,
      "step": 497
    },
    {
      "epoch": 0.11443014705882353,
      "grad_norm": 1.3253569602966309,
      "learning_rate": 3.8055130168453296e-06,
      "loss": 1.0241,
      "step": 498
    },
    {
      "epoch": 0.11465992647058823,
      "grad_norm": 1.5211735963821411,
      "learning_rate": 3.8131699846860646e-06,
      "loss": 1.0725,
      "step": 499
    },
    {
      "epoch": 0.11488970588235294,
      "grad_norm": 1.477620244026184,
      "learning_rate": 3.8208269525268e-06,
      "loss": 0.9374,
      "step": 500
    },
    {
      "epoch": 0.11488970588235294,
      "eval_loss": 0.9699496030807495,
      "eval_runtime": 1967.1719,
      "eval_samples_per_second": 4.527,
      "eval_steps_per_second": 2.264,
      "step": 500
    },
    {
      "epoch": 0.11511948529411764,
      "grad_norm": 1.2233065366744995,
      "learning_rate": 3.828483920367535e-06,
      "loss": 0.945,
      "step": 501
    },
    {
      "epoch": 0.11534926470588236,
      "grad_norm": 1.3762847185134888,
      "learning_rate": 3.83614088820827e-06,
      "loss": 0.9611,
      "step": 502
    },
    {
      "epoch": 0.11557904411764706,
      "grad_norm": 1.403493881225586,
      "learning_rate": 3.8437978560490045e-06,
      "loss": 0.9056,
      "step": 503
    },
    {
      "epoch": 0.11580882352941177,
      "grad_norm": 1.4869208335876465,
      "learning_rate": 3.85145482388974e-06,
      "loss": 1.0322,
      "step": 504
    },
    {
      "epoch": 0.11603860294117647,
      "grad_norm": 1.3227975368499756,
      "learning_rate": 3.8591117917304746e-06,
      "loss": 0.9061,
      "step": 505
    },
    {
      "epoch": 0.11626838235294118,
      "grad_norm": 1.576102614402771,
      "learning_rate": 3.86676875957121e-06,
      "loss": 1.018,
      "step": 506
    },
    {
      "epoch": 0.11649816176470588,
      "grad_norm": 1.390834093093872,
      "learning_rate": 3.8744257274119455e-06,
      "loss": 0.8999,
      "step": 507
    },
    {
      "epoch": 0.11672794117647059,
      "grad_norm": 1.232359766960144,
      "learning_rate": 3.88208269525268e-06,
      "loss": 0.9677,
      "step": 508
    },
    {
      "epoch": 0.1169577205882353,
      "grad_norm": 1.489866852760315,
      "learning_rate": 3.889739663093416e-06,
      "loss": 0.9139,
      "step": 509
    },
    {
      "epoch": 0.1171875,
      "grad_norm": 1.3186941146850586,
      "learning_rate": 3.89739663093415e-06,
      "loss": 0.9472,
      "step": 510
    },
    {
      "epoch": 0.1174172794117647,
      "grad_norm": 1.3498451709747314,
      "learning_rate": 3.905053598774886e-06,
      "loss": 0.9363,
      "step": 511
    },
    {
      "epoch": 0.11764705882352941,
      "grad_norm": 1.3191649913787842,
      "learning_rate": 3.91271056661562e-06,
      "loss": 0.9194,
      "step": 512
    },
    {
      "epoch": 0.11787683823529412,
      "grad_norm": 1.3301128149032593,
      "learning_rate": 3.920367534456356e-06,
      "loss": 0.9633,
      "step": 513
    },
    {
      "epoch": 0.11810661764705882,
      "grad_norm": 1.384323239326477,
      "learning_rate": 3.9280245022970905e-06,
      "loss": 0.9149,
      "step": 514
    },
    {
      "epoch": 0.11833639705882353,
      "grad_norm": 1.3804656267166138,
      "learning_rate": 3.935681470137826e-06,
      "loss": 0.8924,
      "step": 515
    },
    {
      "epoch": 0.11856617647058823,
      "grad_norm": 1.4651799201965332,
      "learning_rate": 3.9433384379785615e-06,
      "loss": 0.9624,
      "step": 516
    },
    {
      "epoch": 0.11879595588235294,
      "grad_norm": 1.546999454498291,
      "learning_rate": 3.950995405819295e-06,
      "loss": 0.9802,
      "step": 517
    },
    {
      "epoch": 0.11902573529411764,
      "grad_norm": 1.3897699117660522,
      "learning_rate": 3.958652373660031e-06,
      "loss": 0.9261,
      "step": 518
    },
    {
      "epoch": 0.11925551470588236,
      "grad_norm": 1.373165488243103,
      "learning_rate": 3.966309341500766e-06,
      "loss": 0.853,
      "step": 519
    },
    {
      "epoch": 0.11948529411764706,
      "grad_norm": 1.1155716180801392,
      "learning_rate": 3.973966309341501e-06,
      "loss": 0.9284,
      "step": 520
    },
    {
      "epoch": 0.11971507352941177,
      "grad_norm": 1.2200838327407837,
      "learning_rate": 3.981623277182236e-06,
      "loss": 0.9575,
      "step": 521
    },
    {
      "epoch": 0.11994485294117647,
      "grad_norm": 1.1302727460861206,
      "learning_rate": 3.989280245022971e-06,
      "loss": 0.9528,
      "step": 522
    },
    {
      "epoch": 0.12017463235294118,
      "grad_norm": 1.3108570575714111,
      "learning_rate": 3.9969372128637065e-06,
      "loss": 0.8551,
      "step": 523
    },
    {
      "epoch": 0.12040441176470588,
      "grad_norm": 1.1424669027328491,
      "learning_rate": 4.004594180704441e-06,
      "loss": 0.864,
      "step": 524
    },
    {
      "epoch": 0.12063419117647059,
      "grad_norm": 1.2308858633041382,
      "learning_rate": 4.012251148545177e-06,
      "loss": 0.9605,
      "step": 525
    },
    {
      "epoch": 0.1208639705882353,
      "grad_norm": 1.363602876663208,
      "learning_rate": 4.019908116385911e-06,
      "loss": 0.8198,
      "step": 526
    },
    {
      "epoch": 0.12109375,
      "grad_norm": 1.273589015007019,
      "learning_rate": 4.027565084226647e-06,
      "loss": 0.8943,
      "step": 527
    },
    {
      "epoch": 0.1213235294117647,
      "grad_norm": 1.2984956502914429,
      "learning_rate": 4.035222052067382e-06,
      "loss": 0.8536,
      "step": 528
    },
    {
      "epoch": 0.12155330882352941,
      "grad_norm": 1.1886128187179565,
      "learning_rate": 4.042879019908117e-06,
      "loss": 0.8939,
      "step": 529
    },
    {
      "epoch": 0.12178308823529412,
      "grad_norm": 1.65804123878479,
      "learning_rate": 4.050535987748852e-06,
      "loss": 0.9499,
      "step": 530
    },
    {
      "epoch": 0.12201286764705882,
      "grad_norm": 1.292820930480957,
      "learning_rate": 4.058192955589587e-06,
      "loss": 0.8877,
      "step": 531
    },
    {
      "epoch": 0.12224264705882353,
      "grad_norm": 1.291300654411316,
      "learning_rate": 4.0658499234303216e-06,
      "loss": 0.8816,
      "step": 532
    },
    {
      "epoch": 0.12247242647058823,
      "grad_norm": 1.5193177461624146,
      "learning_rate": 4.073506891271057e-06,
      "loss": 0.8682,
      "step": 533
    },
    {
      "epoch": 0.12270220588235294,
      "grad_norm": 1.3422582149505615,
      "learning_rate": 4.081163859111792e-06,
      "loss": 0.8275,
      "step": 534
    },
    {
      "epoch": 0.12293198529411764,
      "grad_norm": 1.4188487529754639,
      "learning_rate": 4.088820826952527e-06,
      "loss": 0.868,
      "step": 535
    },
    {
      "epoch": 0.12316176470588236,
      "grad_norm": 1.4676560163497925,
      "learning_rate": 4.096477794793262e-06,
      "loss": 0.8982,
      "step": 536
    },
    {
      "epoch": 0.12339154411764706,
      "grad_norm": 1.216968297958374,
      "learning_rate": 4.104134762633997e-06,
      "loss": 0.8523,
      "step": 537
    },
    {
      "epoch": 0.12362132352941177,
      "grad_norm": 1.5327448844909668,
      "learning_rate": 4.111791730474732e-06,
      "loss": 0.8262,
      "step": 538
    },
    {
      "epoch": 0.12385110294117647,
      "grad_norm": 1.3315616846084595,
      "learning_rate": 4.119448698315467e-06,
      "loss": 0.8295,
      "step": 539
    },
    {
      "epoch": 0.12408088235294118,
      "grad_norm": 1.1436105966567993,
      "learning_rate": 4.127105666156203e-06,
      "loss": 0.7353,
      "step": 540
    },
    {
      "epoch": 0.12431066176470588,
      "grad_norm": 1.3057504892349243,
      "learning_rate": 4.1347626339969375e-06,
      "loss": 0.8744,
      "step": 541
    },
    {
      "epoch": 0.12454044117647059,
      "grad_norm": 1.3004363775253296,
      "learning_rate": 4.142419601837673e-06,
      "loss": 0.8243,
      "step": 542
    },
    {
      "epoch": 0.1247702205882353,
      "grad_norm": 1.2100856304168701,
      "learning_rate": 4.150076569678408e-06,
      "loss": 0.8042,
      "step": 543
    },
    {
      "epoch": 0.125,
      "grad_norm": 1.2231218814849854,
      "learning_rate": 4.157733537519143e-06,
      "loss": 0.8461,
      "step": 544
    },
    {
      "epoch": 0.12522977941176472,
      "grad_norm": 1.5150439739227295,
      "learning_rate": 4.165390505359878e-06,
      "loss": 0.7955,
      "step": 545
    },
    {
      "epoch": 0.1254595588235294,
      "grad_norm": 1.3666085004806519,
      "learning_rate": 4.173047473200612e-06,
      "loss": 0.8962,
      "step": 546
    },
    {
      "epoch": 0.12568933823529413,
      "grad_norm": 1.1442010402679443,
      "learning_rate": 4.180704441041348e-06,
      "loss": 0.8806,
      "step": 547
    },
    {
      "epoch": 0.12591911764705882,
      "grad_norm": 1.2561659812927246,
      "learning_rate": 4.1883614088820825e-06,
      "loss": 0.8061,
      "step": 548
    },
    {
      "epoch": 0.12614889705882354,
      "grad_norm": 1.1502450704574585,
      "learning_rate": 4.196018376722818e-06,
      "loss": 0.8071,
      "step": 549
    },
    {
      "epoch": 0.12637867647058823,
      "grad_norm": 1.4261573553085327,
      "learning_rate": 4.2036753445635535e-06,
      "loss": 0.9269,
      "step": 550
    },
    {
      "epoch": 0.12660845588235295,
      "grad_norm": 1.3247932195663452,
      "learning_rate": 4.211332312404288e-06,
      "loss": 0.7896,
      "step": 551
    },
    {
      "epoch": 0.12683823529411764,
      "grad_norm": 1.4330220222473145,
      "learning_rate": 4.218989280245024e-06,
      "loss": 0.9369,
      "step": 552
    },
    {
      "epoch": 0.12706801470588236,
      "grad_norm": 1.1679325103759766,
      "learning_rate": 4.226646248085758e-06,
      "loss": 0.8187,
      "step": 553
    },
    {
      "epoch": 0.12729779411764705,
      "grad_norm": 1.150973916053772,
      "learning_rate": 4.234303215926494e-06,
      "loss": 0.8302,
      "step": 554
    },
    {
      "epoch": 0.12752757352941177,
      "grad_norm": 1.4075685739517212,
      "learning_rate": 4.241960183767228e-06,
      "loss": 0.7756,
      "step": 555
    },
    {
      "epoch": 0.12775735294117646,
      "grad_norm": 1.2817044258117676,
      "learning_rate": 4.249617151607964e-06,
      "loss": 0.8134,
      "step": 556
    },
    {
      "epoch": 0.12798713235294118,
      "grad_norm": 1.1673848628997803,
      "learning_rate": 4.2572741194486985e-06,
      "loss": 0.8622,
      "step": 557
    },
    {
      "epoch": 0.12821691176470587,
      "grad_norm": 1.1473736763000488,
      "learning_rate": 4.264931087289434e-06,
      "loss": 0.7978,
      "step": 558
    },
    {
      "epoch": 0.1284466911764706,
      "grad_norm": 1.0535497665405273,
      "learning_rate": 4.2725880551301694e-06,
      "loss": 0.7883,
      "step": 559
    },
    {
      "epoch": 0.12867647058823528,
      "grad_norm": 1.3863483667373657,
      "learning_rate": 4.280245022970903e-06,
      "loss": 0.7726,
      "step": 560
    },
    {
      "epoch": 0.12890625,
      "grad_norm": 1.1876834630966187,
      "learning_rate": 4.287901990811639e-06,
      "loss": 0.678,
      "step": 561
    },
    {
      "epoch": 0.12913602941176472,
      "grad_norm": 1.2021218538284302,
      "learning_rate": 4.295558958652374e-06,
      "loss": 0.7497,
      "step": 562
    },
    {
      "epoch": 0.1293658088235294,
      "grad_norm": 1.2796685695648193,
      "learning_rate": 4.303215926493109e-06,
      "loss": 0.7865,
      "step": 563
    },
    {
      "epoch": 0.12959558823529413,
      "grad_norm": 1.4167474508285522,
      "learning_rate": 4.310872894333844e-06,
      "loss": 0.7667,
      "step": 564
    },
    {
      "epoch": 0.12982536764705882,
      "grad_norm": 1.3923325538635254,
      "learning_rate": 4.318529862174579e-06,
      "loss": 0.7868,
      "step": 565
    },
    {
      "epoch": 0.13005514705882354,
      "grad_norm": 1.4531399011611938,
      "learning_rate": 4.326186830015314e-06,
      "loss": 0.7267,
      "step": 566
    },
    {
      "epoch": 0.13028492647058823,
      "grad_norm": 1.2690414190292358,
      "learning_rate": 4.333843797856049e-06,
      "loss": 0.7074,
      "step": 567
    },
    {
      "epoch": 0.13051470588235295,
      "grad_norm": NaN,
      "learning_rate": 4.3415007656967845e-06,
      "loss": 0.6641,
      "step": 568
    },
    {
      "epoch": 0.13074448529411764,
      "grad_norm": 1.353394627571106,
      "learning_rate": 4.3415007656967845e-06,
      "loss": 0.7736,
      "step": 569
    },
    {
      "epoch": 0.13097426470588236,
      "grad_norm": 1.439932107925415,
      "learning_rate": 4.349157733537519e-06,
      "loss": 0.7178,
      "step": 570
    },
    {
      "epoch": 0.13120404411764705,
      "grad_norm": 1.2403656244277954,
      "learning_rate": 4.356814701378255e-06,
      "loss": 0.7259,
      "step": 571
    },
    {
      "epoch": 0.13143382352941177,
      "grad_norm": 1.1629902124404907,
      "learning_rate": 4.36447166921899e-06,
      "loss": 0.7613,
      "step": 572
    },
    {
      "epoch": 0.13166360294117646,
      "grad_norm": 1.4482464790344238,
      "learning_rate": 4.372128637059725e-06,
      "loss": 0.7046,
      "step": 573
    },
    {
      "epoch": 0.13189338235294118,
      "grad_norm": 1.5047845840454102,
      "learning_rate": 4.37978560490046e-06,
      "loss": 0.8329,
      "step": 574
    },
    {
      "epoch": 0.13212316176470587,
      "grad_norm": 1.3483277559280396,
      "learning_rate": 4.387442572741195e-06,
      "loss": 0.7403,
      "step": 575
    },
    {
      "epoch": 0.1323529411764706,
      "grad_norm": 1.2120226621627808,
      "learning_rate": 4.3950995405819295e-06,
      "loss": 0.8573,
      "step": 576
    },
    {
      "epoch": 0.13258272058823528,
      "grad_norm": 1.2850857973098755,
      "learning_rate": 4.402756508422665e-06,
      "loss": 0.7789,
      "step": 577
    },
    {
      "epoch": 0.1328125,
      "grad_norm": 1.2181956768035889,
      "learning_rate": 4.4104134762634e-06,
      "loss": 0.7222,
      "step": 578
    },
    {
      "epoch": 0.13304227941176472,
      "grad_norm": 1.3686186075210571,
      "learning_rate": 4.418070444104135e-06,
      "loss": 0.6628,
      "step": 579
    },
    {
      "epoch": 0.1332720588235294,
      "grad_norm": 1.484254240989685,
      "learning_rate": 4.42572741194487e-06,
      "loss": 0.7116,
      "step": 580
    },
    {
      "epoch": 0.13350183823529413,
      "grad_norm": 1.2183105945587158,
      "learning_rate": 4.433384379785605e-06,
      "loss": 0.6817,
      "step": 581
    },
    {
      "epoch": 0.13373161764705882,
      "grad_norm": 1.44841468334198,
      "learning_rate": 4.441041347626341e-06,
      "loss": 0.7886,
      "step": 582
    },
    {
      "epoch": 0.13396139705882354,
      "grad_norm": 1.1090731620788574,
      "learning_rate": 4.448698315467075e-06,
      "loss": 0.6783,
      "step": 583
    },
    {
      "epoch": 0.13419117647058823,
      "grad_norm": 1.5800856351852417,
      "learning_rate": 4.456355283307811e-06,
      "loss": 0.7059,
      "step": 584
    },
    {
      "epoch": 0.13442095588235295,
      "grad_norm": 1.382357120513916,
      "learning_rate": 4.4640122511485455e-06,
      "loss": 0.6698,
      "step": 585
    },
    {
      "epoch": 0.13465073529411764,
      "grad_norm": 1.4403507709503174,
      "learning_rate": 4.471669218989281e-06,
      "loss": 0.7252,
      "step": 586
    },
    {
      "epoch": 0.13488051470588236,
      "grad_norm": 1.552274465560913,
      "learning_rate": 4.479326186830016e-06,
      "loss": 0.8238,
      "step": 587
    },
    {
      "epoch": 0.13511029411764705,
      "grad_norm": 1.4395657777786255,
      "learning_rate": 4.486983154670751e-06,
      "loss": 0.7587,
      "step": 588
    },
    {
      "epoch": 0.13534007352941177,
      "grad_norm": 1.336495041847229,
      "learning_rate": 4.494640122511486e-06,
      "loss": 0.7266,
      "step": 589
    },
    {
      "epoch": 0.13556985294117646,
      "grad_norm": 1.2333039045333862,
      "learning_rate": 4.50229709035222e-06,
      "loss": 0.7036,
      "step": 590
    },
    {
      "epoch": 0.13579963235294118,
      "grad_norm": 1.309755802154541,
      "learning_rate": 4.509954058192956e-06,
      "loss": 0.6709,
      "step": 591
    },
    {
      "epoch": 0.13602941176470587,
      "grad_norm": 1.2640091180801392,
      "learning_rate": 4.5176110260336905e-06,
      "loss": 0.7505,
      "step": 592
    },
    {
      "epoch": 0.1362591911764706,
      "grad_norm": 1.2627722024917603,
      "learning_rate": 4.525267993874426e-06,
      "loss": 0.6396,
      "step": 593
    },
    {
      "epoch": 0.13648897058823528,
      "grad_norm": 1.2799922227859497,
      "learning_rate": 4.532924961715161e-06,
      "loss": 0.762,
      "step": 594
    },
    {
      "epoch": 0.13671875,
      "grad_norm": 1.2690038681030273,
      "learning_rate": 4.540581929555896e-06,
      "loss": 0.7507,
      "step": 595
    },
    {
      "epoch": 0.13694852941176472,
      "grad_norm": 1.3445117473602295,
      "learning_rate": 4.5482388973966315e-06,
      "loss": 0.7497,
      "step": 596
    },
    {
      "epoch": 0.1371783088235294,
      "grad_norm": 1.1853559017181396,
      "learning_rate": 4.555895865237366e-06,
      "loss": 0.689,
      "step": 597
    },
    {
      "epoch": 0.13740808823529413,
      "grad_norm": 1.3514505624771118,
      "learning_rate": 4.563552833078102e-06,
      "loss": 0.6887,
      "step": 598
    },
    {
      "epoch": 0.13763786764705882,
      "grad_norm": 1.322709560394287,
      "learning_rate": 4.571209800918836e-06,
      "loss": 0.7626,
      "step": 599
    },
    {
      "epoch": 0.13786764705882354,
      "grad_norm": 1.3060394525527954,
      "learning_rate": 4.578866768759572e-06,
      "loss": 0.6658,
      "step": 600
    },
    {
      "epoch": 0.13809742647058823,
      "grad_norm": 1.0482221841812134,
      "learning_rate": 4.586523736600306e-06,
      "loss": 0.6896,
      "step": 601
    },
    {
      "epoch": 0.13832720588235295,
      "grad_norm": 1.1843699216842651,
      "learning_rate": 4.594180704441042e-06,
      "loss": 0.7311,
      "step": 602
    },
    {
      "epoch": 0.13855698529411764,
      "grad_norm": 1.4061702489852905,
      "learning_rate": 4.601837672281777e-06,
      "loss": 0.8009,
      "step": 603
    },
    {
      "epoch": 0.13878676470588236,
      "grad_norm": 1.1640584468841553,
      "learning_rate": 4.609494640122512e-06,
      "loss": 0.6624,
      "step": 604
    },
    {
      "epoch": 0.13901654411764705,
      "grad_norm": 1.220522403717041,
      "learning_rate": 4.617151607963247e-06,
      "loss": 0.6824,
      "step": 605
    },
    {
      "epoch": 0.13924632352941177,
      "grad_norm": 1.5410659313201904,
      "learning_rate": 4.624808575803982e-06,
      "loss": 0.6711,
      "step": 606
    },
    {
      "epoch": 0.13947610294117646,
      "grad_norm": 1.2578915357589722,
      "learning_rate": 4.632465543644717e-06,
      "loss": 0.6992,
      "step": 607
    },
    {
      "epoch": 0.13970588235294118,
      "grad_norm": 1.2262297868728638,
      "learning_rate": 4.640122511485452e-06,
      "loss": 0.6693,
      "step": 608
    },
    {
      "epoch": 0.13993566176470587,
      "grad_norm": 1.2161076068878174,
      "learning_rate": 4.647779479326187e-06,
      "loss": 0.6467,
      "step": 609
    },
    {
      "epoch": 0.1401654411764706,
      "grad_norm": 1.1093426942825317,
      "learning_rate": 4.655436447166922e-06,
      "loss": 0.761,
      "step": 610
    },
    {
      "epoch": 0.14039522058823528,
      "grad_norm": 1.4052027463912964,
      "learning_rate": 4.663093415007657e-06,
      "loss": 0.6825,
      "step": 611
    },
    {
      "epoch": 0.140625,
      "grad_norm": 1.2055989503860474,
      "learning_rate": 4.6707503828483925e-06,
      "loss": 0.6663,
      "step": 612
    },
    {
      "epoch": 0.14085477941176472,
      "grad_norm": 1.28057861328125,
      "learning_rate": 4.678407350689128e-06,
      "loss": 0.6454,
      "step": 613
    },
    {
      "epoch": 0.1410845588235294,
      "grad_norm": 1.3559178113937378,
      "learning_rate": 4.686064318529863e-06,
      "loss": 0.6855,
      "step": 614
    },
    {
      "epoch": 0.14131433823529413,
      "grad_norm": 1.4737513065338135,
      "learning_rate": 4.693721286370598e-06,
      "loss": 0.5868,
      "step": 615
    },
    {
      "epoch": 0.14154411764705882,
      "grad_norm": 1.5066866874694824,
      "learning_rate": 4.701378254211333e-06,
      "loss": 0.7162,
      "step": 616
    },
    {
      "epoch": 0.14177389705882354,
      "grad_norm": 1.2516944408416748,
      "learning_rate": 4.709035222052068e-06,
      "loss": 0.6597,
      "step": 617
    },
    {
      "epoch": 0.14200367647058823,
      "grad_norm": 1.0424692630767822,
      "learning_rate": 4.716692189892803e-06,
      "loss": 0.6695,
      "step": 618
    },
    {
      "epoch": 0.14223345588235295,
      "grad_norm": 1.3005239963531494,
      "learning_rate": 4.7243491577335375e-06,
      "loss": 0.6203,
      "step": 619
    },
    {
      "epoch": 0.14246323529411764,
      "grad_norm": 1.1050961017608643,
      "learning_rate": 4.732006125574273e-06,
      "loss": 0.6206,
      "step": 620
    },
    {
      "epoch": 0.14269301470588236,
      "grad_norm": 1.2084746360778809,
      "learning_rate": 4.7396630934150076e-06,
      "loss": 0.6198,
      "step": 621
    },
    {
      "epoch": 0.14292279411764705,
      "grad_norm": 1.4632134437561035,
      "learning_rate": 4.747320061255743e-06,
      "loss": 0.7189,
      "step": 622
    },
    {
      "epoch": 0.14315257352941177,
      "grad_norm": 1.2138234376907349,
      "learning_rate": 4.754977029096478e-06,
      "loss": 0.5925,
      "step": 623
    },
    {
      "epoch": 0.14338235294117646,
      "grad_norm": 1.1910499334335327,
      "learning_rate": 4.762633996937213e-06,
      "loss": 0.707,
      "step": 624
    },
    {
      "epoch": 0.14361213235294118,
      "grad_norm": 1.196106195449829,
      "learning_rate": 4.770290964777949e-06,
      "loss": 0.6395,
      "step": 625
    },
    {
      "epoch": 0.14384191176470587,
      "grad_norm": 1.3239338397979736,
      "learning_rate": 4.777947932618683e-06,
      "loss": 0.5483,
      "step": 626
    },
    {
      "epoch": 0.1440716911764706,
      "grad_norm": 1.3966599702835083,
      "learning_rate": 4.785604900459419e-06,
      "loss": 0.5683,
      "step": 627
    },
    {
      "epoch": 0.14430147058823528,
      "grad_norm": 1.9534248113632202,
      "learning_rate": 4.793261868300153e-06,
      "loss": 0.6291,
      "step": 628
    },
    {
      "epoch": 0.14453125,
      "grad_norm": 1.4954280853271484,
      "learning_rate": 4.800918836140889e-06,
      "loss": 0.7082,
      "step": 629
    },
    {
      "epoch": 0.14476102941176472,
      "grad_norm": 1.3941296339035034,
      "learning_rate": 4.8085758039816235e-06,
      "loss": 0.6953,
      "step": 630
    },
    {
      "epoch": 0.1449908088235294,
      "grad_norm": 1.3733328580856323,
      "learning_rate": 4.816232771822359e-06,
      "loss": 0.5206,
      "step": 631
    },
    {
      "epoch": 0.14522058823529413,
      "grad_norm": 1.547239899635315,
      "learning_rate": 4.823889739663094e-06,
      "loss": 0.6631,
      "step": 632
    },
    {
      "epoch": 0.14545036764705882,
      "grad_norm": 1.1736384630203247,
      "learning_rate": 4.831546707503829e-06,
      "loss": 0.6783,
      "step": 633
    },
    {
      "epoch": 0.14568014705882354,
      "grad_norm": 1.1649291515350342,
      "learning_rate": 4.839203675344564e-06,
      "loss": 0.6012,
      "step": 634
    },
    {
      "epoch": 0.14590992647058823,
      "grad_norm": 1.4548096656799316,
      "learning_rate": 4.846860643185298e-06,
      "loss": 0.5563,
      "step": 635
    },
    {
      "epoch": 0.14613970588235295,
      "grad_norm": 1.3083882331848145,
      "learning_rate": 4.854517611026034e-06,
      "loss": 0.6686,
      "step": 636
    },
    {
      "epoch": 0.14636948529411764,
      "grad_norm": 1.399916410446167,
      "learning_rate": 4.862174578866769e-06,
      "loss": 0.6718,
      "step": 637
    },
    {
      "epoch": 0.14659926470588236,
      "grad_norm": 1.129986047744751,
      "learning_rate": 4.869831546707504e-06,
      "loss": 0.5801,
      "step": 638
    },
    {
      "epoch": 0.14682904411764705,
      "grad_norm": 1.0848844051361084,
      "learning_rate": 4.8774885145482395e-06,
      "loss": 0.605,
      "step": 639
    },
    {
      "epoch": 0.14705882352941177,
      "grad_norm": 1.1350228786468506,
      "learning_rate": 4.885145482388974e-06,
      "loss": 0.7055,
      "step": 640
    },
    {
      "epoch": 0.14728860294117646,
      "grad_norm": 1.270115852355957,
      "learning_rate": 4.89280245022971e-06,
      "loss": 0.6277,
      "step": 641
    },
    {
      "epoch": 0.14751838235294118,
      "grad_norm": 1.242221713066101,
      "learning_rate": 4.900459418070444e-06,
      "loss": 0.6449,
      "step": 642
    },
    {
      "epoch": 0.14774816176470587,
      "grad_norm": 1.2614513635635376,
      "learning_rate": 4.90811638591118e-06,
      "loss": 0.593,
      "step": 643
    },
    {
      "epoch": 0.1479779411764706,
      "grad_norm": 1.1841400861740112,
      "learning_rate": 4.915773353751915e-06,
      "loss": 0.5892,
      "step": 644
    },
    {
      "epoch": 0.14820772058823528,
      "grad_norm": 1.1990729570388794,
      "learning_rate": 4.92343032159265e-06,
      "loss": 0.5947,
      "step": 645
    },
    {
      "epoch": 0.1484375,
      "grad_norm": 1.3978979587554932,
      "learning_rate": 4.931087289433385e-06,
      "loss": 0.6134,
      "step": 646
    },
    {
      "epoch": 0.14866727941176472,
      "grad_norm": 1.3349443674087524,
      "learning_rate": 4.93874425727412e-06,
      "loss": 0.5974,
      "step": 647
    },
    {
      "epoch": 0.1488970588235294,
      "grad_norm": 1.7460273504257202,
      "learning_rate": 4.9464012251148546e-06,
      "loss": 0.7511,
      "step": 648
    },
    {
      "epoch": 0.14912683823529413,
      "grad_norm": 1.2824273109436035,
      "learning_rate": 4.95405819295559e-06,
      "loss": 0.6125,
      "step": 649
    },
    {
      "epoch": 0.14935661764705882,
      "grad_norm": 1.339489459991455,
      "learning_rate": 4.961715160796325e-06,
      "loss": 0.7044,
      "step": 650
    },
    {
      "epoch": 0.14958639705882354,
      "grad_norm": 1.2353096008300781,
      "learning_rate": 4.96937212863706e-06,
      "loss": 0.5944,
      "step": 651
    },
    {
      "epoch": 0.14981617647058823,
      "grad_norm": 1.419328212738037,
      "learning_rate": 4.977029096477795e-06,
      "loss": 0.642,
      "step": 652
    },
    {
      "epoch": 0.15004595588235295,
      "grad_norm": 1.4751958847045898,
      "learning_rate": 4.98468606431853e-06,
      "loss": 0.6495,
      "step": 653
    },
    {
      "epoch": 0.15027573529411764,
      "grad_norm": 0.9607223868370056,
      "learning_rate": 4.992343032159265e-06,
      "loss": 0.5746,
      "step": 654
    },
    {
      "epoch": 0.15050551470588236,
      "grad_norm": 1.254632592201233,
      "learning_rate": 5e-06,
      "loss": 0.6542,
      "step": 655
    },
    {
      "epoch": 0.15073529411764705,
      "grad_norm": 1.4511646032333374,
      "learning_rate": 5.007656967840735e-06,
      "loss": 0.6153,
      "step": 656
    },
    {
      "epoch": 0.15096507352941177,
      "grad_norm": 1.324832797050476,
      "learning_rate": 5.0153139356814705e-06,
      "loss": 0.5986,
      "step": 657
    },
    {
      "epoch": 0.15119485294117646,
      "grad_norm": 1.6796181201934814,
      "learning_rate": 5.022970903522205e-06,
      "loss": 0.5838,
      "step": 658
    },
    {
      "epoch": 0.15142463235294118,
      "grad_norm": 1.4013433456420898,
      "learning_rate": 5.030627871362941e-06,
      "loss": 0.5349,
      "step": 659
    },
    {
      "epoch": 0.15165441176470587,
      "grad_norm": 1.3485891819000244,
      "learning_rate": 5.038284839203675e-06,
      "loss": 0.5215,
      "step": 660
    },
    {
      "epoch": 0.1518841911764706,
      "grad_norm": 1.2231744527816772,
      "learning_rate": 5.045941807044411e-06,
      "loss": 0.6164,
      "step": 661
    },
    {
      "epoch": 0.15211397058823528,
      "grad_norm": 1.4100662469863892,
      "learning_rate": 5.053598774885145e-06,
      "loss": 0.5772,
      "step": 662
    },
    {
      "epoch": 0.15234375,
      "grad_norm": 1.2759186029434204,
      "learning_rate": 5.061255742725881e-06,
      "loss": 0.5725,
      "step": 663
    },
    {
      "epoch": 0.15257352941176472,
      "grad_norm": 1.57106614112854,
      "learning_rate": 5.0689127105666155e-06,
      "loss": 0.5358,
      "step": 664
    },
    {
      "epoch": 0.1528033088235294,
      "grad_norm": 1.0735214948654175,
      "learning_rate": 5.076569678407352e-06,
      "loss": 0.6248,
      "step": 665
    },
    {
      "epoch": 0.15303308823529413,
      "grad_norm": 1.2410658597946167,
      "learning_rate": 5.084226646248086e-06,
      "loss": 0.6198,
      "step": 666
    },
    {
      "epoch": 0.15326286764705882,
      "grad_norm": 1.1712126731872559,
      "learning_rate": 5.091883614088822e-06,
      "loss": 0.5701,
      "step": 667
    },
    {
      "epoch": 0.15349264705882354,
      "grad_norm": 1.1255745887756348,
      "learning_rate": 5.099540581929557e-06,
      "loss": 0.56,
      "step": 668
    },
    {
      "epoch": 0.15372242647058823,
      "grad_norm": 1.3433009386062622,
      "learning_rate": 5.107197549770292e-06,
      "loss": 0.6807,
      "step": 669
    },
    {
      "epoch": 0.15395220588235295,
      "grad_norm": 1.5470749139785767,
      "learning_rate": 5.114854517611027e-06,
      "loss": 0.5987,
      "step": 670
    },
    {
      "epoch": 0.15418198529411764,
      "grad_norm": 1.4881829023361206,
      "learning_rate": 5.122511485451761e-06,
      "loss": 0.5624,
      "step": 671
    },
    {
      "epoch": 0.15441176470588236,
      "grad_norm": 1.1094516515731812,
      "learning_rate": 5.130168453292497e-06,
      "loss": 0.5682,
      "step": 672
    },
    {
      "epoch": 0.15464154411764705,
      "grad_norm": 1.1713465452194214,
      "learning_rate": 5.1378254211332315e-06,
      "loss": 0.5797,
      "step": 673
    },
    {
      "epoch": 0.15487132352941177,
      "grad_norm": 1.3961460590362549,
      "learning_rate": 5.145482388973967e-06,
      "loss": 0.5754,
      "step": 674
    },
    {
      "epoch": 0.15510110294117646,
      "grad_norm": 1.4281543493270874,
      "learning_rate": 5.153139356814702e-06,
      "loss": 0.5839,
      "step": 675
    },
    {
      "epoch": 0.15533088235294118,
      "grad_norm": 1.225775957107544,
      "learning_rate": 5.160796324655437e-06,
      "loss": 0.6551,
      "step": 676
    },
    {
      "epoch": 0.15556066176470587,
      "grad_norm": 1.1890952587127686,
      "learning_rate": 5.168453292496172e-06,
      "loss": 0.5687,
      "step": 677
    },
    {
      "epoch": 0.1557904411764706,
      "grad_norm": 0.9593426585197449,
      "learning_rate": 5.176110260336907e-06,
      "loss": 0.494,
      "step": 678
    },
    {
      "epoch": 0.15602022058823528,
      "grad_norm": 1.207581877708435,
      "learning_rate": 5.183767228177642e-06,
      "loss": 0.559,
      "step": 679
    },
    {
      "epoch": 0.15625,
      "grad_norm": 1.441642165184021,
      "learning_rate": 5.191424196018377e-06,
      "loss": 0.573,
      "step": 680
    },
    {
      "epoch": 0.15647977941176472,
      "grad_norm": 1.2178775072097778,
      "learning_rate": 5.199081163859112e-06,
      "loss": 0.6594,
      "step": 681
    },
    {
      "epoch": 0.1567095588235294,
      "grad_norm": 1.1107350587844849,
      "learning_rate": 5.206738131699847e-06,
      "loss": 0.5076,
      "step": 682
    },
    {
      "epoch": 0.15693933823529413,
      "grad_norm": 1.254802942276001,
      "learning_rate": 5.214395099540582e-06,
      "loss": 0.5663,
      "step": 683
    },
    {
      "epoch": 0.15716911764705882,
      "grad_norm": 1.2533152103424072,
      "learning_rate": 5.222052067381318e-06,
      "loss": 0.501,
      "step": 684
    },
    {
      "epoch": 0.15739889705882354,
      "grad_norm": 1.603144884109497,
      "learning_rate": 5.229709035222052e-06,
      "loss": 0.5718,
      "step": 685
    },
    {
      "epoch": 0.15762867647058823,
      "grad_norm": 1.2455127239227295,
      "learning_rate": 5.237366003062787e-06,
      "loss": 0.6079,
      "step": 686
    },
    {
      "epoch": 0.15785845588235295,
      "grad_norm": 1.1960268020629883,
      "learning_rate": 5.245022970903523e-06,
      "loss": 0.5361,
      "step": 687
    },
    {
      "epoch": 0.15808823529411764,
      "grad_norm": 1.4520914554595947,
      "learning_rate": 5.252679938744257e-06,
      "loss": 0.5963,
      "step": 688
    },
    {
      "epoch": 0.15831801470588236,
      "grad_norm": 1.4043296575546265,
      "learning_rate": 5.260336906584993e-06,
      "loss": 0.573,
      "step": 689
    },
    {
      "epoch": 0.15854779411764705,
      "grad_norm": 1.415408730506897,
      "learning_rate": 5.267993874425728e-06,
      "loss": 0.5966,
      "step": 690
    },
    {
      "epoch": 0.15877757352941177,
      "grad_norm": 1.383887767791748,
      "learning_rate": 5.275650842266463e-06,
      "loss": 0.5016,
      "step": 691
    },
    {
      "epoch": 0.15900735294117646,
      "grad_norm": 1.3337674140930176,
      "learning_rate": 5.283307810107198e-06,
      "loss": 0.5575,
      "step": 692
    },
    {
      "epoch": 0.15923713235294118,
      "grad_norm": 1.0710768699645996,
      "learning_rate": 5.2909647779479335e-06,
      "loss": 0.638,
      "step": 693
    },
    {
      "epoch": 0.15946691176470587,
      "grad_norm": 1.2308887243270874,
      "learning_rate": 5.298621745788668e-06,
      "loss": 0.5463,
      "step": 694
    },
    {
      "epoch": 0.1596966911764706,
      "grad_norm": 1.2131048440933228,
      "learning_rate": 5.306278713629404e-06,
      "loss": 0.556,
      "step": 695
    },
    {
      "epoch": 0.15992647058823528,
      "grad_norm": 1.0879193544387817,
      "learning_rate": 5.313935681470138e-06,
      "loss": 0.5897,
      "step": 696
    },
    {
      "epoch": 0.16015625,
      "grad_norm": 1.5346617698669434,
      "learning_rate": 5.321592649310874e-06,
      "loss": 0.5652,
      "step": 697
    },
    {
      "epoch": 0.16038602941176472,
      "grad_norm": 1.2373124361038208,
      "learning_rate": 5.329249617151608e-06,
      "loss": 0.5946,
      "step": 698
    },
    {
      "epoch": 0.1606158088235294,
      "grad_norm": 1.2411435842514038,
      "learning_rate": 5.336906584992343e-06,
      "loss": 0.5979,
      "step": 699
    },
    {
      "epoch": 0.16084558823529413,
      "grad_norm": 1.0931910276412964,
      "learning_rate": 5.3445635528330785e-06,
      "loss": 0.5833,
      "step": 700
    },
    {
      "epoch": 0.16107536764705882,
      "grad_norm": 1.2836482524871826,
      "learning_rate": 5.352220520673813e-06,
      "loss": 0.5615,
      "step": 701
    },
    {
      "epoch": 0.16130514705882354,
      "grad_norm": 1.2821524143218994,
      "learning_rate": 5.359877488514549e-06,
      "loss": 0.5332,
      "step": 702
    },
    {
      "epoch": 0.16153492647058823,
      "grad_norm": 1.0734021663665771,
      "learning_rate": 5.367534456355283e-06,
      "loss": 0.4775,
      "step": 703
    },
    {
      "epoch": 0.16176470588235295,
      "grad_norm": 1.4173551797866821,
      "learning_rate": 5.375191424196019e-06,
      "loss": 0.5139,
      "step": 704
    },
    {
      "epoch": 0.16199448529411764,
      "grad_norm": 1.4461965560913086,
      "learning_rate": 5.382848392036753e-06,
      "loss": 0.5212,
      "step": 705
    },
    {
      "epoch": 0.16222426470588236,
      "grad_norm": 1.2399314641952515,
      "learning_rate": 5.39050535987749e-06,
      "loss": 0.5362,
      "step": 706
    },
    {
      "epoch": 0.16245404411764705,
      "grad_norm": 1.3860819339752197,
      "learning_rate": 5.3981623277182235e-06,
      "loss": 0.5694,
      "step": 707
    },
    {
      "epoch": 0.16268382352941177,
      "grad_norm": 1.5857080221176147,
      "learning_rate": 5.40581929555896e-06,
      "loss": 0.4934,
      "step": 708
    },
    {
      "epoch": 0.16291360294117646,
      "grad_norm": 1.4907505512237549,
      "learning_rate": 5.413476263399694e-06,
      "loss": 0.5474,
      "step": 709
    },
    {
      "epoch": 0.16314338235294118,
      "grad_norm": 1.461290955543518,
      "learning_rate": 5.42113323124043e-06,
      "loss": 0.5313,
      "step": 710
    },
    {
      "epoch": 0.16337316176470587,
      "grad_norm": 1.0759704113006592,
      "learning_rate": 5.4287901990811645e-06,
      "loss": 0.6212,
      "step": 711
    },
    {
      "epoch": 0.1636029411764706,
      "grad_norm": 1.4921613931655884,
      "learning_rate": 5.4364471669219e-06,
      "loss": 0.5295,
      "step": 712
    },
    {
      "epoch": 0.16383272058823528,
      "grad_norm": 1.2152202129364014,
      "learning_rate": 5.444104134762635e-06,
      "loss": 0.5323,
      "step": 713
    },
    {
      "epoch": 0.1640625,
      "grad_norm": 1.8052067756652832,
      "learning_rate": 5.451761102603369e-06,
      "loss": 0.5919,
      "step": 714
    },
    {
      "epoch": 0.16429227941176472,
      "grad_norm": 1.1246401071548462,
      "learning_rate": 5.459418070444105e-06,
      "loss": 0.4903,
      "step": 715
    },
    {
      "epoch": 0.1645220588235294,
      "grad_norm": 1.2321982383728027,
      "learning_rate": 5.467075038284839e-06,
      "loss": 0.485,
      "step": 716
    },
    {
      "epoch": 0.16475183823529413,
      "grad_norm": 1.2826482057571411,
      "learning_rate": 5.474732006125575e-06,
      "loss": 0.5379,
      "step": 717
    },
    {
      "epoch": 0.16498161764705882,
      "grad_norm": 1.4164141416549683,
      "learning_rate": 5.4823889739663095e-06,
      "loss": 0.5128,
      "step": 718
    },
    {
      "epoch": 0.16521139705882354,
      "grad_norm": 1.266405701637268,
      "learning_rate": 5.490045941807045e-06,
      "loss": 0.4838,
      "step": 719
    },
    {
      "epoch": 0.16544117647058823,
      "grad_norm": 1.373279333114624,
      "learning_rate": 5.49770290964778e-06,
      "loss": 0.4922,
      "step": 720
    },
    {
      "epoch": 0.16567095588235295,
      "grad_norm": 1.264308214187622,
      "learning_rate": 5.505359877488515e-06,
      "loss": 0.5842,
      "step": 721
    },
    {
      "epoch": 0.16590073529411764,
      "grad_norm": 1.2007652521133423,
      "learning_rate": 5.51301684532925e-06,
      "loss": 0.5594,
      "step": 722
    },
    {
      "epoch": 0.16613051470588236,
      "grad_norm": 1.4535824060440063,
      "learning_rate": 5.520673813169985e-06,
      "loss": 0.5027,
      "step": 723
    },
    {
      "epoch": 0.16636029411764705,
      "grad_norm": 1.2372148036956787,
      "learning_rate": 5.52833078101072e-06,
      "loss": 0.5657,
      "step": 724
    },
    {
      "epoch": 0.16659007352941177,
      "grad_norm": 1.3551050424575806,
      "learning_rate": 5.535987748851455e-06,
      "loss": 0.5569,
      "step": 725
    },
    {
      "epoch": 0.16681985294117646,
      "grad_norm": 1.477676510810852,
      "learning_rate": 5.54364471669219e-06,
      "loss": 0.5267,
      "step": 726
    },
    {
      "epoch": 0.16704963235294118,
      "grad_norm": 1.2964435815811157,
      "learning_rate": 5.551301684532926e-06,
      "loss": 0.5462,
      "step": 727
    },
    {
      "epoch": 0.16727941176470587,
      "grad_norm": 1.3127248287200928,
      "learning_rate": 5.55895865237366e-06,
      "loss": 0.4924,
      "step": 728
    },
    {
      "epoch": 0.1675091911764706,
      "grad_norm": 1.2034244537353516,
      "learning_rate": 5.566615620214395e-06,
      "loss": 0.58,
      "step": 729
    },
    {
      "epoch": 0.16773897058823528,
      "grad_norm": 1.0112136602401733,
      "learning_rate": 5.574272588055131e-06,
      "loss": 0.471,
      "step": 730
    },
    {
      "epoch": 0.16796875,
      "grad_norm": 1.0636481046676636,
      "learning_rate": 5.581929555895865e-06,
      "loss": 0.5158,
      "step": 731
    },
    {
      "epoch": 0.16819852941176472,
      "grad_norm": 1.0502173900604248,
      "learning_rate": 5.589586523736601e-06,
      "loss": 0.5118,
      "step": 732
    },
    {
      "epoch": 0.1684283088235294,
      "grad_norm": 1.2354400157928467,
      "learning_rate": 5.597243491577336e-06,
      "loss": 0.4548,
      "step": 733
    },
    {
      "epoch": 0.16865808823529413,
      "grad_norm": 1.1990188360214233,
      "learning_rate": 5.604900459418071e-06,
      "loss": 0.5313,
      "step": 734
    },
    {
      "epoch": 0.16888786764705882,
      "grad_norm": 1.816857933998108,
      "learning_rate": 5.612557427258806e-06,
      "loss": 0.5363,
      "step": 735
    },
    {
      "epoch": 0.16911764705882354,
      "grad_norm": 1.178864598274231,
      "learning_rate": 5.620214395099541e-06,
      "loss": 0.5146,
      "step": 736
    },
    {
      "epoch": 0.16934742647058823,
      "grad_norm": 1.7885786294937134,
      "learning_rate": 5.627871362940276e-06,
      "loss": 0.5093,
      "step": 737
    },
    {
      "epoch": 0.16957720588235295,
      "grad_norm": 1.1801410913467407,
      "learning_rate": 5.6355283307810115e-06,
      "loss": 0.5178,
      "step": 738
    },
    {
      "epoch": 0.16980698529411764,
      "grad_norm": 1.257970929145813,
      "learning_rate": 5.643185298621746e-06,
      "loss": 0.4385,
      "step": 739
    },
    {
      "epoch": 0.17003676470588236,
      "grad_norm": 1.228058934211731,
      "learning_rate": 5.650842266462482e-06,
      "loss": 0.6055,
      "step": 740
    },
    {
      "epoch": 0.17026654411764705,
      "grad_norm": 1.233938455581665,
      "learning_rate": 5.658499234303216e-06,
      "loss": 0.5495,
      "step": 741
    },
    {
      "epoch": 0.17049632352941177,
      "grad_norm": 1.380713701248169,
      "learning_rate": 5.666156202143952e-06,
      "loss": 0.4649,
      "step": 742
    },
    {
      "epoch": 0.17072610294117646,
      "grad_norm": 1.603115439414978,
      "learning_rate": 5.673813169984686e-06,
      "loss": 0.4231,
      "step": 743
    },
    {
      "epoch": 0.17095588235294118,
      "grad_norm": 1.372377634048462,
      "learning_rate": 5.681470137825421e-06,
      "loss": 0.5679,
      "step": 744
    },
    {
      "epoch": 0.17118566176470587,
      "grad_norm": 1.3595613241195679,
      "learning_rate": 5.6891271056661565e-06,
      "loss": 0.5361,
      "step": 745
    },
    {
      "epoch": 0.1714154411764706,
      "grad_norm": 1.3959990739822388,
      "learning_rate": 5.696784073506891e-06,
      "loss": 0.4353,
      "step": 746
    },
    {
      "epoch": 0.17164522058823528,
      "grad_norm": 1.3353550434112549,
      "learning_rate": 5.704441041347627e-06,
      "loss": 0.5009,
      "step": 747
    },
    {
      "epoch": 0.171875,
      "grad_norm": 1.1074225902557373,
      "learning_rate": 5.712098009188361e-06,
      "loss": 0.4881,
      "step": 748
    },
    {
      "epoch": 0.17210477941176472,
      "grad_norm": 1.3502607345581055,
      "learning_rate": 5.719754977029098e-06,
      "loss": 0.5342,
      "step": 749
    },
    {
      "epoch": 0.1723345588235294,
      "grad_norm": 1.472930669784546,
      "learning_rate": 5.727411944869831e-06,
      "loss": 0.5023,
      "step": 750
    },
    {
      "epoch": 0.17256433823529413,
      "grad_norm": 1.1073559522628784,
      "learning_rate": 5.735068912710568e-06,
      "loss": 0.4901,
      "step": 751
    },
    {
      "epoch": 0.17279411764705882,
      "grad_norm": 1.5659875869750977,
      "learning_rate": 5.742725880551302e-06,
      "loss": 0.5414,
      "step": 752
    },
    {
      "epoch": 0.17302389705882354,
      "grad_norm": 1.73307204246521,
      "learning_rate": 5.750382848392038e-06,
      "loss": 0.5482,
      "step": 753
    },
    {
      "epoch": 0.17325367647058823,
      "grad_norm": 1.494611144065857,
      "learning_rate": 5.7580398162327725e-06,
      "loss": 0.4879,
      "step": 754
    },
    {
      "epoch": 0.17348345588235295,
      "grad_norm": 1.1061196327209473,
      "learning_rate": 5.765696784073508e-06,
      "loss": 0.4307,
      "step": 755
    },
    {
      "epoch": 0.17371323529411764,
      "grad_norm": 1.491885781288147,
      "learning_rate": 5.773353751914243e-06,
      "loss": 0.3727,
      "step": 756
    },
    {
      "epoch": 0.17394301470588236,
      "grad_norm": 1.4518191814422607,
      "learning_rate": 5.781010719754977e-06,
      "loss": 0.6041,
      "step": 757
    },
    {
      "epoch": 0.17417279411764705,
      "grad_norm": 1.4714447259902954,
      "learning_rate": 5.788667687595713e-06,
      "loss": 0.5864,
      "step": 758
    },
    {
      "epoch": 0.17440257352941177,
      "grad_norm": 1.1152422428131104,
      "learning_rate": 5.796324655436447e-06,
      "loss": 0.4487,
      "step": 759
    },
    {
      "epoch": 0.17463235294117646,
      "grad_norm": 1.1469030380249023,
      "learning_rate": 5.803981623277183e-06,
      "loss": 0.5397,
      "step": 760
    },
    {
      "epoch": 0.17486213235294118,
      "grad_norm": 1.038438320159912,
      "learning_rate": 5.8116385911179175e-06,
      "loss": 0.4916,
      "step": 761
    },
    {
      "epoch": 0.17509191176470587,
      "grad_norm": 1.334900140762329,
      "learning_rate": 5.819295558958653e-06,
      "loss": 0.4058,
      "step": 762
    },
    {
      "epoch": 0.1753216911764706,
      "grad_norm": 0.9891058802604675,
      "learning_rate": 5.8269525267993876e-06,
      "loss": 0.4365,
      "step": 763
    },
    {
      "epoch": 0.17555147058823528,
      "grad_norm": 1.3501965999603271,
      "learning_rate": 5.834609494640123e-06,
      "loss": 0.5158,
      "step": 764
    },
    {
      "epoch": 0.17578125,
      "grad_norm": 1.2635693550109863,
      "learning_rate": 5.842266462480858e-06,
      "loss": 0.4708,
      "step": 765
    },
    {
      "epoch": 0.17601102941176472,
      "grad_norm": 1.48408043384552,
      "learning_rate": 5.849923430321593e-06,
      "loss": 0.4171,
      "step": 766
    },
    {
      "epoch": 0.1762408088235294,
      "grad_norm": 1.2976045608520508,
      "learning_rate": 5.857580398162328e-06,
      "loss": 0.4491,
      "step": 767
    },
    {
      "epoch": 0.17647058823529413,
      "grad_norm": 1.2458378076553345,
      "learning_rate": 5.865237366003063e-06,
      "loss": 0.4387,
      "step": 768
    },
    {
      "epoch": 0.17670036764705882,
      "grad_norm": 1.1112638711929321,
      "learning_rate": 5.872894333843798e-06,
      "loss": 0.4751,
      "step": 769
    },
    {
      "epoch": 0.17693014705882354,
      "grad_norm": 1.261290192604065,
      "learning_rate": 5.880551301684534e-06,
      "loss": 0.4574,
      "step": 770
    },
    {
      "epoch": 0.17715992647058823,
      "grad_norm": 1.5006312131881714,
      "learning_rate": 5.888208269525269e-06,
      "loss": 0.4806,
      "step": 771
    },
    {
      "epoch": 0.17738970588235295,
      "grad_norm": 1.1576504707336426,
      "learning_rate": 5.895865237366003e-06,
      "loss": 0.4705,
      "step": 772
    },
    {
      "epoch": 0.17761948529411764,
      "grad_norm": 1.2062263488769531,
      "learning_rate": 5.903522205206739e-06,
      "loss": 0.417,
      "step": 773
    },
    {
      "epoch": 0.17784926470588236,
      "grad_norm": 1.4165596961975098,
      "learning_rate": 5.911179173047474e-06,
      "loss": 0.497,
      "step": 774
    },
    {
      "epoch": 0.17807904411764705,
      "grad_norm": 1.1477313041687012,
      "learning_rate": 5.918836140888209e-06,
      "loss": 0.5108,
      "step": 775
    },
    {
      "epoch": 0.17830882352941177,
      "grad_norm": 1.3968008756637573,
      "learning_rate": 5.926493108728944e-06,
      "loss": 0.4635,
      "step": 776
    },
    {
      "epoch": 0.17853860294117646,
      "grad_norm": 1.1994460821151733,
      "learning_rate": 5.934150076569679e-06,
      "loss": 0.4716,
      "step": 777
    },
    {
      "epoch": 0.17876838235294118,
      "grad_norm": 1.2791608572006226,
      "learning_rate": 5.941807044410414e-06,
      "loss": 0.5086,
      "step": 778
    },
    {
      "epoch": 0.17899816176470587,
      "grad_norm": 1.4616566896438599,
      "learning_rate": 5.949464012251149e-06,
      "loss": 0.4321,
      "step": 779
    },
    {
      "epoch": 0.1792279411764706,
      "grad_norm": 1.3225417137145996,
      "learning_rate": 5.957120980091884e-06,
      "loss": 0.4301,
      "step": 780
    },
    {
      "epoch": 0.17945772058823528,
      "grad_norm": 1.2209813594818115,
      "learning_rate": 5.9647779479326195e-06,
      "loss": 0.4119,
      "step": 781
    },
    {
      "epoch": 0.1796875,
      "grad_norm": 1.0981578826904297,
      "learning_rate": 5.972434915773354e-06,
      "loss": 0.4875,
      "step": 782
    },
    {
      "epoch": 0.17991727941176472,
      "grad_norm": 1.6175885200500488,
      "learning_rate": 5.98009188361409e-06,
      "loss": 0.4593,
      "step": 783
    },
    {
      "epoch": 0.1801470588235294,
      "grad_norm": 1.128844976425171,
      "learning_rate": 5.987748851454824e-06,
      "loss": 0.4138,
      "step": 784
    },
    {
      "epoch": 0.18037683823529413,
      "grad_norm": 1.575493335723877,
      "learning_rate": 5.99540581929556e-06,
      "loss": 0.4178,
      "step": 785
    },
    {
      "epoch": 0.18060661764705882,
      "grad_norm": 1.5967117547988892,
      "learning_rate": 6.003062787136294e-06,
      "loss": 0.4948,
      "step": 786
    },
    {
      "epoch": 0.18083639705882354,
      "grad_norm": 1.2850842475891113,
      "learning_rate": 6.010719754977029e-06,
      "loss": 0.4578,
      "step": 787
    },
    {
      "epoch": 0.18106617647058823,
      "grad_norm": 1.2426830530166626,
      "learning_rate": 6.0183767228177645e-06,
      "loss": 0.4535,
      "step": 788
    },
    {
      "epoch": 0.18129595588235295,
      "grad_norm": 1.3601744174957275,
      "learning_rate": 6.026033690658499e-06,
      "loss": 0.5033,
      "step": 789
    },
    {
      "epoch": 0.18152573529411764,
      "grad_norm": 1.1061363220214844,
      "learning_rate": 6.033690658499235e-06,
      "loss": 0.4478,
      "step": 790
    },
    {
      "epoch": 0.18175551470588236,
      "grad_norm": 1.3322259187698364,
      "learning_rate": 6.041347626339969e-06,
      "loss": 0.4033,
      "step": 791
    },
    {
      "epoch": 0.18198529411764705,
      "grad_norm": 1.5858930349349976,
      "learning_rate": 6.0490045941807055e-06,
      "loss": 0.453,
      "step": 792
    },
    {
      "epoch": 0.18221507352941177,
      "grad_norm": 1.25533926486969,
      "learning_rate": 6.056661562021439e-06,
      "loss": 0.4242,
      "step": 793
    },
    {
      "epoch": 0.18244485294117646,
      "grad_norm": 1.2520502805709839,
      "learning_rate": 6.064318529862176e-06,
      "loss": 0.4376,
      "step": 794
    },
    {
      "epoch": 0.18267463235294118,
      "grad_norm": 1.2573902606964111,
      "learning_rate": 6.07197549770291e-06,
      "loss": 0.3716,
      "step": 795
    },
    {
      "epoch": 0.18290441176470587,
      "grad_norm": 1.266912579536438,
      "learning_rate": 6.079632465543646e-06,
      "loss": 0.4509,
      "step": 796
    },
    {
      "epoch": 0.1831341911764706,
      "grad_norm": 1.4309242963790894,
      "learning_rate": 6.08728943338438e-06,
      "loss": 0.4132,
      "step": 797
    },
    {
      "epoch": 0.18336397058823528,
      "grad_norm": 1.4375580549240112,
      "learning_rate": 6.094946401225116e-06,
      "loss": 0.5172,
      "step": 798
    },
    {
      "epoch": 0.18359375,
      "grad_norm": 1.2305972576141357,
      "learning_rate": 6.1026033690658505e-06,
      "loss": 0.444,
      "step": 799
    },
    {
      "epoch": 0.18382352941176472,
      "grad_norm": 1.3925787210464478,
      "learning_rate": 6.110260336906586e-06,
      "loss": 0.4823,
      "step": 800
    },
    {
      "epoch": 0.1840533088235294,
      "grad_norm": 1.4121166467666626,
      "learning_rate": 6.117917304747321e-06,
      "loss": 0.5353,
      "step": 801
    },
    {
      "epoch": 0.18428308823529413,
      "grad_norm": 1.2497121095657349,
      "learning_rate": 6.125574272588055e-06,
      "loss": 0.4527,
      "step": 802
    },
    {
      "epoch": 0.18451286764705882,
      "grad_norm": 1.235963225364685,
      "learning_rate": 6.133231240428791e-06,
      "loss": 0.4636,
      "step": 803
    },
    {
      "epoch": 0.18474264705882354,
      "grad_norm": 1.2172542810440063,
      "learning_rate": 6.140888208269525e-06,
      "loss": 0.4271,
      "step": 804
    },
    {
      "epoch": 0.18497242647058823,
      "grad_norm": 1.3128280639648438,
      "learning_rate": 6.148545176110261e-06,
      "loss": 0.4667,
      "step": 805
    },
    {
      "epoch": 0.18520220588235295,
      "grad_norm": 1.3820860385894775,
      "learning_rate": 6.1562021439509955e-06,
      "loss": 0.5178,
      "step": 806
    },
    {
      "epoch": 0.18543198529411764,
      "grad_norm": 1.3706451654434204,
      "learning_rate": 6.163859111791731e-06,
      "loss": 0.446,
      "step": 807
    },
    {
      "epoch": 0.18566176470588236,
      "grad_norm": 1.446384310722351,
      "learning_rate": 6.171516079632466e-06,
      "loss": 0.4526,
      "step": 808
    },
    {
      "epoch": 0.18589154411764705,
      "grad_norm": 1.316907525062561,
      "learning_rate": 6.179173047473201e-06,
      "loss": 0.4115,
      "step": 809
    },
    {
      "epoch": 0.18612132352941177,
      "grad_norm": 1.3272449970245361,
      "learning_rate": 6.186830015313936e-06,
      "loss": 0.4285,
      "step": 810
    },
    {
      "epoch": 0.18635110294117646,
      "grad_norm": 1.3937746286392212,
      "learning_rate": 6.194486983154672e-06,
      "loss": 0.4034,
      "step": 811
    },
    {
      "epoch": 0.18658088235294118,
      "grad_norm": 1.6269289255142212,
      "learning_rate": 6.202143950995406e-06,
      "loss": 0.4149,
      "step": 812
    },
    {
      "epoch": 0.18681066176470587,
      "grad_norm": 1.8853240013122559,
      "learning_rate": 6.209800918836142e-06,
      "loss": 0.4682,
      "step": 813
    },
    {
      "epoch": 0.1870404411764706,
      "grad_norm": 2.010326862335205,
      "learning_rate": 6.217457886676877e-06,
      "loss": 0.4922,
      "step": 814
    },
    {
      "epoch": 0.18727022058823528,
      "grad_norm": 1.347512125968933,
      "learning_rate": 6.225114854517611e-06,
      "loss": 0.4501,
      "step": 815
    },
    {
      "epoch": 0.1875,
      "grad_norm": 1.3192682266235352,
      "learning_rate": 6.232771822358347e-06,
      "loss": 0.4234,
      "step": 816
    },
    {
      "epoch": 0.18772977941176472,
      "grad_norm": 1.307600736618042,
      "learning_rate": 6.240428790199082e-06,
      "loss": 0.4852,
      "step": 817
    },
    {
      "epoch": 0.1879595588235294,
      "grad_norm": 1.1785224676132202,
      "learning_rate": 6.248085758039817e-06,
      "loss": 0.4211,
      "step": 818
    },
    {
      "epoch": 0.18818933823529413,
      "grad_norm": 1.4489175081253052,
      "learning_rate": 6.255742725880552e-06,
      "loss": 0.436,
      "step": 819
    },
    {
      "epoch": 0.18841911764705882,
      "grad_norm": 1.350262999534607,
      "learning_rate": 6.263399693721287e-06,
      "loss": 0.3983,
      "step": 820
    },
    {
      "epoch": 0.18864889705882354,
      "grad_norm": 1.306259274482727,
      "learning_rate": 6.271056661562022e-06,
      "loss": 0.3774,
      "step": 821
    },
    {
      "epoch": 0.18887867647058823,
      "grad_norm": 1.2294634580612183,
      "learning_rate": 6.278713629402757e-06,
      "loss": 0.4295,
      "step": 822
    },
    {
      "epoch": 0.18910845588235295,
      "grad_norm": 1.5935105085372925,
      "learning_rate": 6.286370597243492e-06,
      "loss": 0.4765,
      "step": 823
    },
    {
      "epoch": 0.18933823529411764,
      "grad_norm": 1.3607054948806763,
      "learning_rate": 6.294027565084227e-06,
      "loss": 0.4388,
      "step": 824
    },
    {
      "epoch": 0.18956801470588236,
      "grad_norm": 1.3137164115905762,
      "learning_rate": 6.301684532924962e-06,
      "loss": 0.3892,
      "step": 825
    },
    {
      "epoch": 0.18979779411764705,
      "grad_norm": 1.535109043121338,
      "learning_rate": 6.3093415007656975e-06,
      "loss": 0.5016,
      "step": 826
    },
    {
      "epoch": 0.19002757352941177,
      "grad_norm": 1.5641820430755615,
      "learning_rate": 6.316998468606432e-06,
      "loss": 0.4676,
      "step": 827
    },
    {
      "epoch": 0.19025735294117646,
      "grad_norm": 1.5108190774917603,
      "learning_rate": 6.324655436447168e-06,
      "loss": 0.4369,
      "step": 828
    },
    {
      "epoch": 0.19048713235294118,
      "grad_norm": 1.2785422801971436,
      "learning_rate": 6.332312404287902e-06,
      "loss": 0.4055,
      "step": 829
    },
    {
      "epoch": 0.19071691176470587,
      "grad_norm": 1.1173582077026367,
      "learning_rate": 6.339969372128637e-06,
      "loss": 0.4196,
      "step": 830
    },
    {
      "epoch": 0.1909466911764706,
      "grad_norm": 0.9731812477111816,
      "learning_rate": 6.347626339969372e-06,
      "loss": 0.4055,
      "step": 831
    },
    {
      "epoch": 0.19117647058823528,
      "grad_norm": 1.1729669570922852,
      "learning_rate": 6.355283307810107e-06,
      "loss": 0.4927,
      "step": 832
    },
    {
      "epoch": 0.19140625,
      "grad_norm": 1.1326090097427368,
      "learning_rate": 6.3629402756508425e-06,
      "loss": 0.4335,
      "step": 833
    },
    {
      "epoch": 0.19163602941176472,
      "grad_norm": 1.1603620052337646,
      "learning_rate": 6.370597243491577e-06,
      "loss": 0.4381,
      "step": 834
    },
    {
      "epoch": 0.1918658088235294,
      "grad_norm": 1.369459629058838,
      "learning_rate": 6.3782542113323135e-06,
      "loss": 0.5031,
      "step": 835
    },
    {
      "epoch": 0.19209558823529413,
      "grad_norm": 1.0851409435272217,
      "learning_rate": 6.385911179173048e-06,
      "loss": 0.4128,
      "step": 836
    },
    {
      "epoch": 0.19232536764705882,
      "grad_norm": 1.540108561515808,
      "learning_rate": 6.393568147013784e-06,
      "loss": 0.4737,
      "step": 837
    },
    {
      "epoch": 0.19255514705882354,
      "grad_norm": 1.0527366399765015,
      "learning_rate": 6.401225114854518e-06,
      "loss": 0.3777,
      "step": 838
    },
    {
      "epoch": 0.19278492647058823,
      "grad_norm": 1.0523388385772705,
      "learning_rate": 6.408882082695254e-06,
      "loss": 0.3797,
      "step": 839
    },
    {
      "epoch": 0.19301470588235295,
      "grad_norm": 1.1330171823501587,
      "learning_rate": 6.416539050535988e-06,
      "loss": 0.3868,
      "step": 840
    },
    {
      "epoch": 0.19324448529411764,
      "grad_norm": 1.2278095483779907,
      "learning_rate": 6.424196018376724e-06,
      "loss": 0.4028,
      "step": 841
    },
    {
      "epoch": 0.19347426470588236,
      "grad_norm": 1.6623094081878662,
      "learning_rate": 6.4318529862174585e-06,
      "loss": 0.4618,
      "step": 842
    },
    {
      "epoch": 0.19370404411764705,
      "grad_norm": 1.3834253549575806,
      "learning_rate": 6.439509954058194e-06,
      "loss": 0.3672,
      "step": 843
    },
    {
      "epoch": 0.19393382352941177,
      "grad_norm": 1.164692997932434,
      "learning_rate": 6.447166921898929e-06,
      "loss": 0.4692,
      "step": 844
    },
    {
      "epoch": 0.19416360294117646,
      "grad_norm": 1.360211968421936,
      "learning_rate": 6.454823889739663e-06,
      "loss": 0.3921,
      "step": 845
    },
    {
      "epoch": 0.19439338235294118,
      "grad_norm": 2.0558512210845947,
      "learning_rate": 6.462480857580399e-06,
      "loss": 0.5455,
      "step": 846
    },
    {
      "epoch": 0.19462316176470587,
      "grad_norm": 1.3090808391571045,
      "learning_rate": 6.470137825421133e-06,
      "loss": 0.4392,
      "step": 847
    },
    {
      "epoch": 0.1948529411764706,
      "grad_norm": 1.0335108041763306,
      "learning_rate": 6.477794793261869e-06,
      "loss": 0.4213,
      "step": 848
    },
    {
      "epoch": 0.19508272058823528,
      "grad_norm": 1.1709587574005127,
      "learning_rate": 6.4854517611026035e-06,
      "loss": 0.3371,
      "step": 849
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 1.3332828283309937,
      "learning_rate": 6.493108728943339e-06,
      "loss": 0.3788,
      "step": 850
    },
    {
      "epoch": 0.19554227941176472,
      "grad_norm": 1.258589744567871,
      "learning_rate": 6.5007656967840736e-06,
      "loss": 0.3889,
      "step": 851
    },
    {
      "epoch": 0.1957720588235294,
      "grad_norm": 1.1261347532272339,
      "learning_rate": 6.508422664624809e-06,
      "loss": 0.389,
      "step": 852
    },
    {
      "epoch": 0.19600183823529413,
      "grad_norm": 1.1922661066055298,
      "learning_rate": 6.516079632465544e-06,
      "loss": 0.3915,
      "step": 853
    },
    {
      "epoch": 0.19623161764705882,
      "grad_norm": 1.0862832069396973,
      "learning_rate": 6.52373660030628e-06,
      "loss": 0.3688,
      "step": 854
    },
    {
      "epoch": 0.19646139705882354,
      "grad_norm": 1.1931402683258057,
      "learning_rate": 6.531393568147014e-06,
      "loss": 0.449,
      "step": 855
    },
    {
      "epoch": 0.19669117647058823,
      "grad_norm": 1.33921480178833,
      "learning_rate": 6.53905053598775e-06,
      "loss": 0.4821,
      "step": 856
    },
    {
      "epoch": 0.19692095588235295,
      "grad_norm": 1.130653738975525,
      "learning_rate": 6.546707503828485e-06,
      "loss": 0.4374,
      "step": 857
    },
    {
      "epoch": 0.19715073529411764,
      "grad_norm": 1.327785611152649,
      "learning_rate": 6.55436447166922e-06,
      "loss": 0.3942,
      "step": 858
    },
    {
      "epoch": 0.19738051470588236,
      "grad_norm": 1.058657169342041,
      "learning_rate": 6.562021439509955e-06,
      "loss": 0.3728,
      "step": 859
    },
    {
      "epoch": 0.19761029411764705,
      "grad_norm": 1.4079722166061401,
      "learning_rate": 6.5696784073506895e-06,
      "loss": 0.346,
      "step": 860
    },
    {
      "epoch": 0.19784007352941177,
      "grad_norm": 1.2415283918380737,
      "learning_rate": 6.577335375191425e-06,
      "loss": 0.3967,
      "step": 861
    },
    {
      "epoch": 0.19806985294117646,
      "grad_norm": 1.3969941139221191,
      "learning_rate": 6.58499234303216e-06,
      "loss": 0.4614,
      "step": 862
    },
    {
      "epoch": 0.19829963235294118,
      "grad_norm": 1.295676827430725,
      "learning_rate": 6.592649310872895e-06,
      "loss": 0.4028,
      "step": 863
    },
    {
      "epoch": 0.19852941176470587,
      "grad_norm": 1.4254682064056396,
      "learning_rate": 6.60030627871363e-06,
      "loss": 0.3885,
      "step": 864
    },
    {
      "epoch": 0.1987591911764706,
      "grad_norm": 1.2999956607818604,
      "learning_rate": 6.607963246554365e-06,
      "loss": 0.4987,
      "step": 865
    },
    {
      "epoch": 0.19898897058823528,
      "grad_norm": 1.443284273147583,
      "learning_rate": 6.6156202143951e-06,
      "loss": 0.4134,
      "step": 866
    },
    {
      "epoch": 0.19921875,
      "grad_norm": 1.2103242874145508,
      "learning_rate": 6.623277182235835e-06,
      "loss": 0.4331,
      "step": 867
    },
    {
      "epoch": 0.19944852941176472,
      "grad_norm": 1.2386977672576904,
      "learning_rate": 6.63093415007657e-06,
      "loss": 0.3497,
      "step": 868
    },
    {
      "epoch": 0.1996783088235294,
      "grad_norm": 1.4016462564468384,
      "learning_rate": 6.6385911179173055e-06,
      "loss": 0.3985,
      "step": 869
    },
    {
      "epoch": 0.19990808823529413,
      "grad_norm": 1.4259836673736572,
      "learning_rate": 6.64624808575804e-06,
      "loss": 0.3708,
      "step": 870
    },
    {
      "epoch": 0.20013786764705882,
      "grad_norm": 1.538511037826538,
      "learning_rate": 6.653905053598776e-06,
      "loss": 0.4263,
      "step": 871
    },
    {
      "epoch": 0.20036764705882354,
      "grad_norm": 1.420643925666809,
      "learning_rate": 6.66156202143951e-06,
      "loss": 0.4047,
      "step": 872
    },
    {
      "epoch": 0.20059742647058823,
      "grad_norm": 1.5682843923568726,
      "learning_rate": 6.669218989280245e-06,
      "loss": 0.4172,
      "step": 873
    },
    {
      "epoch": 0.20082720588235295,
      "grad_norm": 1.521528720855713,
      "learning_rate": 6.67687595712098e-06,
      "loss": 0.4299,
      "step": 874
    },
    {
      "epoch": 0.20105698529411764,
      "grad_norm": 1.3508071899414062,
      "learning_rate": 6.684532924961715e-06,
      "loss": 0.4231,
      "step": 875
    },
    {
      "epoch": 0.20128676470588236,
      "grad_norm": 1.2239770889282227,
      "learning_rate": 6.692189892802451e-06,
      "loss": 0.3509,
      "step": 876
    },
    {
      "epoch": 0.20151654411764705,
      "grad_norm": 1.7320241928100586,
      "learning_rate": 6.699846860643185e-06,
      "loss": 0.3876,
      "step": 877
    },
    {
      "epoch": 0.20174632352941177,
      "grad_norm": 1.2834751605987549,
      "learning_rate": 6.707503828483921e-06,
      "loss": 0.4568,
      "step": 878
    },
    {
      "epoch": 0.20197610294117646,
      "grad_norm": 1.521838665008545,
      "learning_rate": 6.715160796324656e-06,
      "loss": 0.3814,
      "step": 879
    },
    {
      "epoch": 0.20220588235294118,
      "grad_norm": 1.3953895568847656,
      "learning_rate": 6.7228177641653915e-06,
      "loss": 0.361,
      "step": 880
    },
    {
      "epoch": 0.20243566176470587,
      "grad_norm": 1.4173084497451782,
      "learning_rate": 6.730474732006126e-06,
      "loss": 0.4489,
      "step": 881
    },
    {
      "epoch": 0.2026654411764706,
      "grad_norm": 1.222888708114624,
      "learning_rate": 6.738131699846862e-06,
      "loss": 0.4012,
      "step": 882
    },
    {
      "epoch": 0.20289522058823528,
      "grad_norm": 1.2577491998672485,
      "learning_rate": 6.745788667687596e-06,
      "loss": 0.3405,
      "step": 883
    },
    {
      "epoch": 0.203125,
      "grad_norm": 1.3643279075622559,
      "learning_rate": 6.753445635528332e-06,
      "loss": 0.3487,
      "step": 884
    },
    {
      "epoch": 0.20335477941176472,
      "grad_norm": 1.6836459636688232,
      "learning_rate": 6.761102603369066e-06,
      "loss": 0.437,
      "step": 885
    },
    {
      "epoch": 0.2035845588235294,
      "grad_norm": 1.5354105234146118,
      "learning_rate": 6.768759571209802e-06,
      "loss": 0.3349,
      "step": 886
    },
    {
      "epoch": 0.20381433823529413,
      "grad_norm": 1.452722430229187,
      "learning_rate": 6.7764165390505365e-06,
      "loss": 0.4138,
      "step": 887
    },
    {
      "epoch": 0.20404411764705882,
      "grad_norm": 1.5295568704605103,
      "learning_rate": 6.784073506891271e-06,
      "loss": 0.4299,
      "step": 888
    },
    {
      "epoch": 0.20427389705882354,
      "grad_norm": 1.359696388244629,
      "learning_rate": 6.791730474732007e-06,
      "loss": 0.495,
      "step": 889
    },
    {
      "epoch": 0.20450367647058823,
      "grad_norm": 1.3132950067520142,
      "learning_rate": 6.799387442572741e-06,
      "loss": 0.4494,
      "step": 890
    },
    {
      "epoch": 0.20473345588235295,
      "grad_norm": 1.4275020360946655,
      "learning_rate": 6.807044410413477e-06,
      "loss": 0.4385,
      "step": 891
    },
    {
      "epoch": 0.20496323529411764,
      "grad_norm": 1.143511176109314,
      "learning_rate": 6.814701378254211e-06,
      "loss": 0.4088,
      "step": 892
    },
    {
      "epoch": 0.20519301470588236,
      "grad_norm": 1.4371479749679565,
      "learning_rate": 6.822358346094947e-06,
      "loss": 0.3762,
      "step": 893
    },
    {
      "epoch": 0.20542279411764705,
      "grad_norm": 1.4509985446929932,
      "learning_rate": 6.8300153139356815e-06,
      "loss": 0.3642,
      "step": 894
    },
    {
      "epoch": 0.20565257352941177,
      "grad_norm": 1.237537145614624,
      "learning_rate": 6.837672281776417e-06,
      "loss": 0.4453,
      "step": 895
    },
    {
      "epoch": 0.20588235294117646,
      "grad_norm": 1.6620231866836548,
      "learning_rate": 6.845329249617152e-06,
      "loss": 0.409,
      "step": 896
    },
    {
      "epoch": 0.20611213235294118,
      "grad_norm": 1.1850228309631348,
      "learning_rate": 6.852986217457888e-06,
      "loss": 0.3434,
      "step": 897
    },
    {
      "epoch": 0.20634191176470587,
      "grad_norm": 1.379915714263916,
      "learning_rate": 6.860643185298622e-06,
      "loss": 0.4638,
      "step": 898
    },
    {
      "epoch": 0.2065716911764706,
      "grad_norm": 1.2208256721496582,
      "learning_rate": 6.868300153139358e-06,
      "loss": 0.412,
      "step": 899
    },
    {
      "epoch": 0.20680147058823528,
      "grad_norm": 1.1131678819656372,
      "learning_rate": 6.875957120980093e-06,
      "loss": 0.3431,
      "step": 900
    },
    {
      "epoch": 0.20703125,
      "grad_norm": 1.456944465637207,
      "learning_rate": 6.883614088820828e-06,
      "loss": 0.3094,
      "step": 901
    },
    {
      "epoch": 0.20726102941176472,
      "grad_norm": 1.1517102718353271,
      "learning_rate": 6.891271056661563e-06,
      "loss": 0.373,
      "step": 902
    },
    {
      "epoch": 0.2074908088235294,
      "grad_norm": 1.1798839569091797,
      "learning_rate": 6.8989280245022975e-06,
      "loss": 0.3243,
      "step": 903
    },
    {
      "epoch": 0.20772058823529413,
      "grad_norm": 1.6526615619659424,
      "learning_rate": 6.906584992343033e-06,
      "loss": 0.423,
      "step": 904
    },
    {
      "epoch": 0.20795036764705882,
      "grad_norm": 1.3951239585876465,
      "learning_rate": 6.914241960183768e-06,
      "loss": 0.4719,
      "step": 905
    },
    {
      "epoch": 0.20818014705882354,
      "grad_norm": 1.3530462980270386,
      "learning_rate": 6.921898928024503e-06,
      "loss": 0.3441,
      "step": 906
    },
    {
      "epoch": 0.20840992647058823,
      "grad_norm": 1.3249679803848267,
      "learning_rate": 6.929555895865238e-06,
      "loss": 0.3484,
      "step": 907
    },
    {
      "epoch": 0.20863970588235295,
      "grad_norm": 1.292697787284851,
      "learning_rate": 6.937212863705973e-06,
      "loss": 0.4237,
      "step": 908
    },
    {
      "epoch": 0.20886948529411764,
      "grad_norm": 1.628945231437683,
      "learning_rate": 6.944869831546708e-06,
      "loss": 0.4461,
      "step": 909
    },
    {
      "epoch": 0.20909926470588236,
      "grad_norm": 1.3831206560134888,
      "learning_rate": 6.952526799387443e-06,
      "loss": 0.3478,
      "step": 910
    },
    {
      "epoch": 0.20932904411764705,
      "grad_norm": 1.2668806314468384,
      "learning_rate": 6.960183767228178e-06,
      "loss": 0.3533,
      "step": 911
    },
    {
      "epoch": 0.20955882352941177,
      "grad_norm": 1.3889222145080566,
      "learning_rate": 6.967840735068913e-06,
      "loss": 0.3915,
      "step": 912
    },
    {
      "epoch": 0.20978860294117646,
      "grad_norm": 1.2537106275558472,
      "learning_rate": 6.975497702909648e-06,
      "loss": 0.4322,
      "step": 913
    },
    {
      "epoch": 0.21001838235294118,
      "grad_norm": 1.5077422857284546,
      "learning_rate": 6.9831546707503835e-06,
      "loss": 0.4416,
      "step": 914
    },
    {
      "epoch": 0.21024816176470587,
      "grad_norm": 1.5120949745178223,
      "learning_rate": 6.990811638591118e-06,
      "loss": 0.3857,
      "step": 915
    },
    {
      "epoch": 0.2104779411764706,
      "grad_norm": 1.382863163948059,
      "learning_rate": 6.9984686064318545e-06,
      "loss": 0.3347,
      "step": 916
    },
    {
      "epoch": 0.21070772058823528,
      "grad_norm": 1.2674446105957031,
      "learning_rate": 7.006125574272588e-06,
      "loss": 0.3327,
      "step": 917
    },
    {
      "epoch": 0.2109375,
      "grad_norm": 1.3204113245010376,
      "learning_rate": 7.013782542113323e-06,
      "loss": 0.3171,
      "step": 918
    },
    {
      "epoch": 0.21116727941176472,
      "grad_norm": 1.476960301399231,
      "learning_rate": 7.021439509954059e-06,
      "loss": 0.4794,
      "step": 919
    },
    {
      "epoch": 0.2113970588235294,
      "grad_norm": 1.3010588884353638,
      "learning_rate": 7.029096477794793e-06,
      "loss": 0.3543,
      "step": 920
    },
    {
      "epoch": 0.21162683823529413,
      "grad_norm": 1.2362526655197144,
      "learning_rate": 7.036753445635529e-06,
      "loss": 0.3881,
      "step": 921
    },
    {
      "epoch": 0.21185661764705882,
      "grad_norm": 1.5260990858078003,
      "learning_rate": 7.044410413476264e-06,
      "loss": 0.3634,
      "step": 922
    },
    {
      "epoch": 0.21208639705882354,
      "grad_norm": 1.2314839363098145,
      "learning_rate": 7.0520673813169995e-06,
      "loss": 0.3817,
      "step": 923
    },
    {
      "epoch": 0.21231617647058823,
      "grad_norm": 1.4187194108963013,
      "learning_rate": 7.059724349157734e-06,
      "loss": 0.3261,
      "step": 924
    },
    {
      "epoch": 0.21254595588235295,
      "grad_norm": 1.2619279623031616,
      "learning_rate": 7.06738131699847e-06,
      "loss": 0.3785,
      "step": 925
    },
    {
      "epoch": 0.21277573529411764,
      "grad_norm": 1.7217999696731567,
      "learning_rate": 7.075038284839204e-06,
      "loss": 0.3913,
      "step": 926
    },
    {
      "epoch": 0.21300551470588236,
      "grad_norm": 1.3804852962493896,
      "learning_rate": 7.08269525267994e-06,
      "loss": 0.3825,
      "step": 927
    },
    {
      "epoch": 0.21323529411764705,
      "grad_norm": 1.1841710805892944,
      "learning_rate": 7.090352220520674e-06,
      "loss": 0.3541,
      "step": 928
    },
    {
      "epoch": 0.21346507352941177,
      "grad_norm": 1.2580288648605347,
      "learning_rate": 7.09800918836141e-06,
      "loss": 0.3795,
      "step": 929
    },
    {
      "epoch": 0.21369485294117646,
      "grad_norm": 1.3828858137130737,
      "learning_rate": 7.1056661562021445e-06,
      "loss": 0.3796,
      "step": 930
    },
    {
      "epoch": 0.21392463235294118,
      "grad_norm": 1.6061012744903564,
      "learning_rate": 7.113323124042879e-06,
      "loss": 0.4404,
      "step": 931
    },
    {
      "epoch": 0.21415441176470587,
      "grad_norm": 1.4894543886184692,
      "learning_rate": 7.120980091883615e-06,
      "loss": 0.2979,
      "step": 932
    },
    {
      "epoch": 0.2143841911764706,
      "grad_norm": 1.1602526903152466,
      "learning_rate": 7.128637059724349e-06,
      "loss": 0.4377,
      "step": 933
    },
    {
      "epoch": 0.21461397058823528,
      "grad_norm": 1.2407560348510742,
      "learning_rate": 7.136294027565085e-06,
      "loss": 0.3468,
      "step": 934
    },
    {
      "epoch": 0.21484375,
      "grad_norm": 1.3087478876113892,
      "learning_rate": 7.143950995405819e-06,
      "loss": 0.3669,
      "step": 935
    },
    {
      "epoch": 0.21507352941176472,
      "grad_norm": 1.265830636024475,
      "learning_rate": 7.151607963246555e-06,
      "loss": 0.3397,
      "step": 936
    },
    {
      "epoch": 0.2153033088235294,
      "grad_norm": 1.5798755884170532,
      "learning_rate": 7.1592649310872895e-06,
      "loss": 0.3307,
      "step": 937
    },
    {
      "epoch": 0.21553308823529413,
      "grad_norm": 1.5027610063552856,
      "learning_rate": 7.166921898928026e-06,
      "loss": 0.3968,
      "step": 938
    },
    {
      "epoch": 0.21576286764705882,
      "grad_norm": 1.3600378036499023,
      "learning_rate": 7.1745788667687596e-06,
      "loss": 0.3946,
      "step": 939
    },
    {
      "epoch": 0.21599264705882354,
      "grad_norm": 1.514029622077942,
      "learning_rate": 7.182235834609496e-06,
      "loss": 0.3397,
      "step": 940
    },
    {
      "epoch": 0.21622242647058823,
      "grad_norm": 1.2335915565490723,
      "learning_rate": 7.1898928024502305e-06,
      "loss": 0.2979,
      "step": 941
    },
    {
      "epoch": 0.21645220588235295,
      "grad_norm": 1.3873597383499146,
      "learning_rate": 7.197549770290966e-06,
      "loss": 0.4207,
      "step": 942
    },
    {
      "epoch": 0.21668198529411764,
      "grad_norm": 1.188529372215271,
      "learning_rate": 7.205206738131701e-06,
      "loss": 0.2906,
      "step": 943
    },
    {
      "epoch": 0.21691176470588236,
      "grad_norm": 1.2347972393035889,
      "learning_rate": 7.212863705972436e-06,
      "loss": 0.3447,
      "step": 944
    },
    {
      "epoch": 0.21714154411764705,
      "grad_norm": 1.2575221061706543,
      "learning_rate": 7.220520673813171e-06,
      "loss": 0.3287,
      "step": 945
    },
    {
      "epoch": 0.21737132352941177,
      "grad_norm": 1.2406947612762451,
      "learning_rate": 7.228177641653905e-06,
      "loss": 0.4144,
      "step": 946
    },
    {
      "epoch": 0.21760110294117646,
      "grad_norm": 1.3457562923431396,
      "learning_rate": 7.235834609494641e-06,
      "loss": 0.415,
      "step": 947
    },
    {
      "epoch": 0.21783088235294118,
      "grad_norm": 1.417859673500061,
      "learning_rate": 7.2434915773353755e-06,
      "loss": 0.2763,
      "step": 948
    },
    {
      "epoch": 0.21806066176470587,
      "grad_norm": 1.3035818338394165,
      "learning_rate": 7.251148545176111e-06,
      "loss": 0.4052,
      "step": 949
    },
    {
      "epoch": 0.2182904411764706,
      "grad_norm": 1.4296727180480957,
      "learning_rate": 7.258805513016846e-06,
      "loss": 0.3773,
      "step": 950
    },
    {
      "epoch": 0.21852022058823528,
      "grad_norm": 1.3915621042251587,
      "learning_rate": 7.266462480857581e-06,
      "loss": 0.2884,
      "step": 951
    },
    {
      "epoch": 0.21875,
      "grad_norm": 1.2092432975769043,
      "learning_rate": 7.274119448698316e-06,
      "loss": 0.3689,
      "step": 952
    },
    {
      "epoch": 0.21897977941176472,
      "grad_norm": 1.439773678779602,
      "learning_rate": 7.281776416539051e-06,
      "loss": 0.3224,
      "step": 953
    },
    {
      "epoch": 0.2192095588235294,
      "grad_norm": 1.3883557319641113,
      "learning_rate": 7.289433384379786e-06,
      "loss": 0.3422,
      "step": 954
    },
    {
      "epoch": 0.21943933823529413,
      "grad_norm": 1.5873229503631592,
      "learning_rate": 7.297090352220521e-06,
      "loss": 0.3676,
      "step": 955
    },
    {
      "epoch": 0.21966911764705882,
      "grad_norm": 1.5134612321853638,
      "learning_rate": 7.304747320061256e-06,
      "loss": 0.3744,
      "step": 956
    },
    {
      "epoch": 0.21989889705882354,
      "grad_norm": 1.2661240100860596,
      "learning_rate": 7.3124042879019915e-06,
      "loss": 0.3134,
      "step": 957
    },
    {
      "epoch": 0.22012867647058823,
      "grad_norm": 1.4268031120300293,
      "learning_rate": 7.320061255742726e-06,
      "loss": 0.3507,
      "step": 958
    },
    {
      "epoch": 0.22035845588235295,
      "grad_norm": 1.3153870105743408,
      "learning_rate": 7.3277182235834624e-06,
      "loss": 0.3743,
      "step": 959
    },
    {
      "epoch": 0.22058823529411764,
      "grad_norm": 1.4971967935562134,
      "learning_rate": 7.335375191424196e-06,
      "loss": 0.3941,
      "step": 960
    },
    {
      "epoch": 0.22081801470588236,
      "grad_norm": 1.5960899591445923,
      "learning_rate": 7.343032159264931e-06,
      "loss": 0.3619,
      "step": 961
    },
    {
      "epoch": 0.22104779411764705,
      "grad_norm": 1.2660821676254272,
      "learning_rate": 7.350689127105667e-06,
      "loss": 0.4066,
      "step": 962
    },
    {
      "epoch": 0.22127757352941177,
      "grad_norm": 1.3476589918136597,
      "learning_rate": 7.358346094946402e-06,
      "loss": 0.3911,
      "step": 963
    },
    {
      "epoch": 0.22150735294117646,
      "grad_norm": 1.2776011228561401,
      "learning_rate": 7.366003062787137e-06,
      "loss": 0.2949,
      "step": 964
    },
    {
      "epoch": 0.22173713235294118,
      "grad_norm": 1.0737792253494263,
      "learning_rate": 7.373660030627872e-06,
      "loss": 0.297,
      "step": 965
    },
    {
      "epoch": 0.22196691176470587,
      "grad_norm": 1.4443306922912598,
      "learning_rate": 7.381316998468607e-06,
      "loss": 0.39,
      "step": 966
    },
    {
      "epoch": 0.2221966911764706,
      "grad_norm": 1.2261766195297241,
      "learning_rate": 7.388973966309342e-06,
      "loss": 0.3192,
      "step": 967
    },
    {
      "epoch": 0.22242647058823528,
      "grad_norm": 1.2362861633300781,
      "learning_rate": 7.3966309341500775e-06,
      "loss": 0.3109,
      "step": 968
    },
    {
      "epoch": 0.22265625,
      "grad_norm": 1.2251826524734497,
      "learning_rate": 7.404287901990812e-06,
      "loss": 0.3692,
      "step": 969
    },
    {
      "epoch": 0.22288602941176472,
      "grad_norm": 1.5025660991668701,
      "learning_rate": 7.411944869831548e-06,
      "loss": 0.3338,
      "step": 970
    },
    {
      "epoch": 0.2231158088235294,
      "grad_norm": 1.3430819511413574,
      "learning_rate": 7.419601837672282e-06,
      "loss": 0.3328,
      "step": 971
    },
    {
      "epoch": 0.22334558823529413,
      "grad_norm": 1.403735876083374,
      "learning_rate": 7.427258805513018e-06,
      "loss": 0.3378,
      "step": 972
    },
    {
      "epoch": 0.22357536764705882,
      "grad_norm": 1.1377679109573364,
      "learning_rate": 7.434915773353752e-06,
      "loss": 0.3489,
      "step": 973
    },
    {
      "epoch": 0.22380514705882354,
      "grad_norm": 1.2290582656860352,
      "learning_rate": 7.442572741194488e-06,
      "loss": 0.3585,
      "step": 974
    },
    {
      "epoch": 0.22403492647058823,
      "grad_norm": 1.4401535987854004,
      "learning_rate": 7.4502297090352225e-06,
      "loss": 0.3265,
      "step": 975
    },
    {
      "epoch": 0.22426470588235295,
      "grad_norm": 1.378708839416504,
      "learning_rate": 7.457886676875957e-06,
      "loss": 0.3964,
      "step": 976
    },
    {
      "epoch": 0.22449448529411764,
      "grad_norm": 1.25846529006958,
      "learning_rate": 7.465543644716693e-06,
      "loss": 0.3431,
      "step": 977
    },
    {
      "epoch": 0.22472426470588236,
      "grad_norm": 1.397047996520996,
      "learning_rate": 7.473200612557427e-06,
      "loss": 0.3174,
      "step": 978
    },
    {
      "epoch": 0.22495404411764705,
      "grad_norm": 1.2283343076705933,
      "learning_rate": 7.480857580398163e-06,
      "loss": 0.3123,
      "step": 979
    },
    {
      "epoch": 0.22518382352941177,
      "grad_norm": 1.3334383964538574,
      "learning_rate": 7.488514548238897e-06,
      "loss": 0.3608,
      "step": 980
    },
    {
      "epoch": 0.22541360294117646,
      "grad_norm": 1.479454755783081,
      "learning_rate": 7.496171516079634e-06,
      "loss": 0.2878,
      "step": 981
    },
    {
      "epoch": 0.22564338235294118,
      "grad_norm": 1.0674666166305542,
      "learning_rate": 7.5038284839203675e-06,
      "loss": 0.298,
      "step": 982
    },
    {
      "epoch": 0.22587316176470587,
      "grad_norm": 1.3647499084472656,
      "learning_rate": 7.511485451761104e-06,
      "loss": 0.2926,
      "step": 983
    },
    {
      "epoch": 0.2261029411764706,
      "grad_norm": 1.3487640619277954,
      "learning_rate": 7.5191424196018385e-06,
      "loss": 0.3265,
      "step": 984
    },
    {
      "epoch": 0.22633272058823528,
      "grad_norm": 1.1058309078216553,
      "learning_rate": 7.526799387442574e-06,
      "loss": 0.3505,
      "step": 985
    },
    {
      "epoch": 0.2265625,
      "grad_norm": 1.407088041305542,
      "learning_rate": 7.534456355283309e-06,
      "loss": 0.4143,
      "step": 986
    },
    {
      "epoch": 0.22679227941176472,
      "grad_norm": 1.5918387174606323,
      "learning_rate": 7.542113323124044e-06,
      "loss": 0.3388,
      "step": 987
    },
    {
      "epoch": 0.2270220588235294,
      "grad_norm": 1.4690760374069214,
      "learning_rate": 7.549770290964779e-06,
      "loss": 0.343,
      "step": 988
    },
    {
      "epoch": 0.22725183823529413,
      "grad_norm": 1.5167371034622192,
      "learning_rate": 7.557427258805513e-06,
      "loss": 0.2877,
      "step": 989
    },
    {
      "epoch": 0.22748161764705882,
      "grad_norm": 1.1472898721694946,
      "learning_rate": 7.565084226646249e-06,
      "loss": 0.3204,
      "step": 990
    },
    {
      "epoch": 0.22771139705882354,
      "grad_norm": 1.5279898643493652,
      "learning_rate": 7.5727411944869835e-06,
      "loss": 0.3425,
      "step": 991
    },
    {
      "epoch": 0.22794117647058823,
      "grad_norm": 1.2404100894927979,
      "learning_rate": 7.580398162327719e-06,
      "loss": 0.3342,
      "step": 992
    },
    {
      "epoch": 0.22817095588235295,
      "grad_norm": 1.6566555500030518,
      "learning_rate": 7.5880551301684536e-06,
      "loss": 0.3744,
      "step": 993
    },
    {
      "epoch": 0.22840073529411764,
      "grad_norm": 1.077165961265564,
      "learning_rate": 7.595712098009189e-06,
      "loss": 0.3349,
      "step": 994
    },
    {
      "epoch": 0.22863051470588236,
      "grad_norm": 1.498608112335205,
      "learning_rate": 7.603369065849924e-06,
      "loss": 0.3158,
      "step": 995
    },
    {
      "epoch": 0.22886029411764705,
      "grad_norm": 1.335664987564087,
      "learning_rate": 7.611026033690659e-06,
      "loss": 0.3275,
      "step": 996
    },
    {
      "epoch": 0.22909007352941177,
      "grad_norm": 1.4274427890777588,
      "learning_rate": 7.618683001531394e-06,
      "loss": 0.2898,
      "step": 997
    },
    {
      "epoch": 0.22931985294117646,
      "grad_norm": 1.163527250289917,
      "learning_rate": 7.626339969372129e-06,
      "loss": 0.332,
      "step": 998
    },
    {
      "epoch": 0.22954963235294118,
      "grad_norm": 1.2979850769042969,
      "learning_rate": 7.633996937212865e-06,
      "loss": 0.2819,
      "step": 999
    },
    {
      "epoch": 0.22977941176470587,
      "grad_norm": 1.4749103784561157,
      "learning_rate": 7.6416539050536e-06,
      "loss": 0.348,
      "step": 1000
    },
    {
      "epoch": 0.22977941176470587,
      "eval_loss": 0.3339841961860657,
      "eval_runtime": 1965.5835,
      "eval_samples_per_second": 4.531,
      "eval_steps_per_second": 2.265,
      "step": 1000
    },
    {
      "epoch": 0.2300091911764706,
      "grad_norm": 1.288421630859375,
      "learning_rate": 7.649310872894334e-06,
      "loss": 0.2718,
      "step": 1001
    },
    {
      "epoch": 0.23023897058823528,
      "grad_norm": 1.2813993692398071,
      "learning_rate": 7.65696784073507e-06,
      "loss": 0.3899,
      "step": 1002
    },
    {
      "epoch": 0.23046875,
      "grad_norm": 1.6279999017715454,
      "learning_rate": 7.664624808575805e-06,
      "loss": 0.3658,
      "step": 1003
    },
    {
      "epoch": 0.23069852941176472,
      "grad_norm": 1.3055119514465332,
      "learning_rate": 7.67228177641654e-06,
      "loss": 0.2729,
      "step": 1004
    },
    {
      "epoch": 0.2309283088235294,
      "grad_norm": 1.4386988878250122,
      "learning_rate": 7.679938744257274e-06,
      "loss": 0.2647,
      "step": 1005
    },
    {
      "epoch": 0.23115808823529413,
      "grad_norm": 1.155989646911621,
      "learning_rate": 7.687595712098009e-06,
      "loss": 0.3115,
      "step": 1006
    },
    {
      "epoch": 0.23138786764705882,
      "grad_norm": 1.4350038766860962,
      "learning_rate": 7.695252679938745e-06,
      "loss": 0.3317,
      "step": 1007
    },
    {
      "epoch": 0.23161764705882354,
      "grad_norm": 1.346243977546692,
      "learning_rate": 7.70290964777948e-06,
      "loss": 0.3279,
      "step": 1008
    },
    {
      "epoch": 0.23184742647058823,
      "grad_norm": 2.0373854637145996,
      "learning_rate": 7.710566615620215e-06,
      "loss": 0.3732,
      "step": 1009
    },
    {
      "epoch": 0.23207720588235295,
      "grad_norm": 1.3861503601074219,
      "learning_rate": 7.718223583460949e-06,
      "loss": 0.3631,
      "step": 1010
    },
    {
      "epoch": 0.23230698529411764,
      "grad_norm": 1.259355902671814,
      "learning_rate": 7.725880551301685e-06,
      "loss": 0.3303,
      "step": 1011
    },
    {
      "epoch": 0.23253676470588236,
      "grad_norm": 1.3840997219085693,
      "learning_rate": 7.73353751914242e-06,
      "loss": 0.3228,
      "step": 1012
    },
    {
      "epoch": 0.23276654411764705,
      "grad_norm": 1.1949818134307861,
      "learning_rate": 7.741194486983156e-06,
      "loss": 0.3109,
      "step": 1013
    },
    {
      "epoch": 0.23299632352941177,
      "grad_norm": 1.372084617614746,
      "learning_rate": 7.748851454823891e-06,
      "loss": 0.3292,
      "step": 1014
    },
    {
      "epoch": 0.23322610294117646,
      "grad_norm": 1.5024627447128296,
      "learning_rate": 7.756508422664626e-06,
      "loss": 0.3386,
      "step": 1015
    },
    {
      "epoch": 0.23345588235294118,
      "grad_norm": 1.159001111984253,
      "learning_rate": 7.76416539050536e-06,
      "loss": 0.2694,
      "step": 1016
    },
    {
      "epoch": 0.23368566176470587,
      "grad_norm": 1.202574610710144,
      "learning_rate": 7.771822358346097e-06,
      "loss": 0.3281,
      "step": 1017
    },
    {
      "epoch": 0.2339154411764706,
      "grad_norm": 1.3752076625823975,
      "learning_rate": 7.779479326186831e-06,
      "loss": 0.2883,
      "step": 1018
    },
    {
      "epoch": 0.23414522058823528,
      "grad_norm": 1.361353874206543,
      "learning_rate": 7.787136294027566e-06,
      "loss": 0.299,
      "step": 1019
    },
    {
      "epoch": 0.234375,
      "grad_norm": 1.1957826614379883,
      "learning_rate": 7.7947932618683e-06,
      "loss": 0.4298,
      "step": 1020
    },
    {
      "epoch": 0.23460477941176472,
      "grad_norm": 1.2831857204437256,
      "learning_rate": 7.802450229709035e-06,
      "loss": 0.3125,
      "step": 1021
    },
    {
      "epoch": 0.2348345588235294,
      "grad_norm": 1.7725533246994019,
      "learning_rate": 7.810107197549772e-06,
      "loss": 0.2897,
      "step": 1022
    },
    {
      "epoch": 0.23506433823529413,
      "grad_norm": 1.6710913181304932,
      "learning_rate": 7.817764165390506e-06,
      "loss": 0.4165,
      "step": 1023
    },
    {
      "epoch": 0.23529411764705882,
      "grad_norm": 1.3989062309265137,
      "learning_rate": 7.82542113323124e-06,
      "loss": 0.3092,
      "step": 1024
    },
    {
      "epoch": 0.23552389705882354,
      "grad_norm": 1.1845555305480957,
      "learning_rate": 7.833078101071975e-06,
      "loss": 0.2888,
      "step": 1025
    },
    {
      "epoch": 0.23575367647058823,
      "grad_norm": 1.2269738912582397,
      "learning_rate": 7.840735068912712e-06,
      "loss": 0.3547,
      "step": 1026
    },
    {
      "epoch": 0.23598345588235295,
      "grad_norm": 1.4229964017868042,
      "learning_rate": 7.848392036753446e-06,
      "loss": 0.3343,
      "step": 1027
    },
    {
      "epoch": 0.23621323529411764,
      "grad_norm": 1.3038480281829834,
      "learning_rate": 7.856049004594181e-06,
      "loss": 0.3131,
      "step": 1028
    },
    {
      "epoch": 0.23644301470588236,
      "grad_norm": 1.4733458757400513,
      "learning_rate": 7.863705972434916e-06,
      "loss": 0.3649,
      "step": 1029
    },
    {
      "epoch": 0.23667279411764705,
      "grad_norm": 1.396040439605713,
      "learning_rate": 7.871362940275652e-06,
      "loss": 0.408,
      "step": 1030
    },
    {
      "epoch": 0.23690257352941177,
      "grad_norm": 1.111324429512024,
      "learning_rate": 7.879019908116387e-06,
      "loss": 0.3179,
      "step": 1031
    },
    {
      "epoch": 0.23713235294117646,
      "grad_norm": 1.6251922845840454,
      "learning_rate": 7.886676875957123e-06,
      "loss": 0.3193,
      "step": 1032
    },
    {
      "epoch": 0.23736213235294118,
      "grad_norm": 1.2194305658340454,
      "learning_rate": 7.894333843797856e-06,
      "loss": 0.3079,
      "step": 1033
    },
    {
      "epoch": 0.23759191176470587,
      "grad_norm": 1.6241592168807983,
      "learning_rate": 7.90199081163859e-06,
      "loss": 0.3855,
      "step": 1034
    },
    {
      "epoch": 0.2378216911764706,
      "grad_norm": 1.7003363370895386,
      "learning_rate": 7.909647779479327e-06,
      "loss": 0.3654,
      "step": 1035
    },
    {
      "epoch": 0.23805147058823528,
      "grad_norm": 1.397420048713684,
      "learning_rate": 7.917304747320062e-06,
      "loss": 0.2866,
      "step": 1036
    },
    {
      "epoch": 0.23828125,
      "grad_norm": 1.301112174987793,
      "learning_rate": 7.924961715160798e-06,
      "loss": 0.3365,
      "step": 1037
    },
    {
      "epoch": 0.23851102941176472,
      "grad_norm": 1.0791443586349487,
      "learning_rate": 7.932618683001532e-06,
      "loss": 0.3128,
      "step": 1038
    },
    {
      "epoch": 0.2387408088235294,
      "grad_norm": 1.347037434577942,
      "learning_rate": 7.940275650842267e-06,
      "loss": 0.2811,
      "step": 1039
    },
    {
      "epoch": 0.23897058823529413,
      "grad_norm": 1.2124049663543701,
      "learning_rate": 7.947932618683002e-06,
      "loss": 0.2837,
      "step": 1040
    },
    {
      "epoch": 0.23920036764705882,
      "grad_norm": 1.3101710081100464,
      "learning_rate": 7.955589586523738e-06,
      "loss": 0.2997,
      "step": 1041
    },
    {
      "epoch": 0.23943014705882354,
      "grad_norm": 1.379502534866333,
      "learning_rate": 7.963246554364473e-06,
      "loss": 0.2826,
      "step": 1042
    },
    {
      "epoch": 0.23965992647058823,
      "grad_norm": 1.2125922441482544,
      "learning_rate": 7.970903522205207e-06,
      "loss": 0.3033,
      "step": 1043
    },
    {
      "epoch": 0.23988970588235295,
      "grad_norm": 1.0346081256866455,
      "learning_rate": 7.978560490045942e-06,
      "loss": 0.3144,
      "step": 1044
    },
    {
      "epoch": 0.24011948529411764,
      "grad_norm": 1.1981607675552368,
      "learning_rate": 7.986217457886678e-06,
      "loss": 0.2564,
      "step": 1045
    },
    {
      "epoch": 0.24034926470588236,
      "grad_norm": 1.137428879737854,
      "learning_rate": 7.993874425727413e-06,
      "loss": 0.2797,
      "step": 1046
    },
    {
      "epoch": 0.24057904411764705,
      "grad_norm": 1.2779481410980225,
      "learning_rate": 8.001531393568148e-06,
      "loss": 0.3245,
      "step": 1047
    },
    {
      "epoch": 0.24080882352941177,
      "grad_norm": 1.40048086643219,
      "learning_rate": 8.009188361408882e-06,
      "loss": 0.3637,
      "step": 1048
    },
    {
      "epoch": 0.24103860294117646,
      "grad_norm": 1.6546869277954102,
      "learning_rate": 8.016845329249617e-06,
      "loss": 0.3115,
      "step": 1049
    },
    {
      "epoch": 0.24126838235294118,
      "grad_norm": 1.4083259105682373,
      "learning_rate": 8.024502297090353e-06,
      "loss": 0.2963,
      "step": 1050
    },
    {
      "epoch": 0.24149816176470587,
      "grad_norm": 1.248424768447876,
      "learning_rate": 8.032159264931088e-06,
      "loss": 0.3019,
      "step": 1051
    },
    {
      "epoch": 0.2417279411764706,
      "grad_norm": 1.5523395538330078,
      "learning_rate": 8.039816232771822e-06,
      "loss": 0.2726,
      "step": 1052
    },
    {
      "epoch": 0.24195772058823528,
      "grad_norm": 1.1033140420913696,
      "learning_rate": 8.047473200612557e-06,
      "loss": 0.2887,
      "step": 1053
    },
    {
      "epoch": 0.2421875,
      "grad_norm": 1.526843786239624,
      "learning_rate": 8.055130168453293e-06,
      "loss": 0.3268,
      "step": 1054
    },
    {
      "epoch": 0.24241727941176472,
      "grad_norm": 1.2835520505905151,
      "learning_rate": 8.062787136294028e-06,
      "loss": 0.2463,
      "step": 1055
    },
    {
      "epoch": 0.2426470588235294,
      "grad_norm": 1.663740873336792,
      "learning_rate": 8.070444104134764e-06,
      "loss": 0.3494,
      "step": 1056
    },
    {
      "epoch": 0.24287683823529413,
      "grad_norm": 1.5102531909942627,
      "learning_rate": 8.078101071975499e-06,
      "loss": 0.2895,
      "step": 1057
    },
    {
      "epoch": 0.24310661764705882,
      "grad_norm": 1.3473516702651978,
      "learning_rate": 8.085758039816234e-06,
      "loss": 0.24,
      "step": 1058
    },
    {
      "epoch": 0.24333639705882354,
      "grad_norm": 1.3142551183700562,
      "learning_rate": 8.093415007656968e-06,
      "loss": 0.3251,
      "step": 1059
    },
    {
      "epoch": 0.24356617647058823,
      "grad_norm": 1.8375999927520752,
      "learning_rate": 8.101071975497705e-06,
      "loss": 0.328,
      "step": 1060
    },
    {
      "epoch": 0.24379595588235295,
      "grad_norm": 1.2819905281066895,
      "learning_rate": 8.10872894333844e-06,
      "loss": 0.3091,
      "step": 1061
    },
    {
      "epoch": 0.24402573529411764,
      "grad_norm": 1.6838127374649048,
      "learning_rate": 8.116385911179174e-06,
      "loss": 0.3876,
      "step": 1062
    },
    {
      "epoch": 0.24425551470588236,
      "grad_norm": 1.7743661403656006,
      "learning_rate": 8.124042879019909e-06,
      "loss": 0.3326,
      "step": 1063
    },
    {
      "epoch": 0.24448529411764705,
      "grad_norm": 1.7036932706832886,
      "learning_rate": 8.131699846860643e-06,
      "loss": 0.2998,
      "step": 1064
    },
    {
      "epoch": 0.24471507352941177,
      "grad_norm": 1.3664469718933105,
      "learning_rate": 8.13935681470138e-06,
      "loss": 0.3091,
      "step": 1065
    },
    {
      "epoch": 0.24494485294117646,
      "grad_norm": 1.7652603387832642,
      "learning_rate": 8.147013782542114e-06,
      "loss": 0.2924,
      "step": 1066
    },
    {
      "epoch": 0.24517463235294118,
      "grad_norm": 1.3086574077606201,
      "learning_rate": 8.154670750382849e-06,
      "loss": 0.3446,
      "step": 1067
    },
    {
      "epoch": 0.24540441176470587,
      "grad_norm": 1.374089241027832,
      "learning_rate": 8.162327718223583e-06,
      "loss": 0.3049,
      "step": 1068
    },
    {
      "epoch": 0.2456341911764706,
      "grad_norm": 1.202666997909546,
      "learning_rate": 8.16998468606432e-06,
      "loss": 0.3028,
      "step": 1069
    },
    {
      "epoch": 0.24586397058823528,
      "grad_norm": 1.2771008014678955,
      "learning_rate": 8.177641653905054e-06,
      "loss": 0.2771,
      "step": 1070
    },
    {
      "epoch": 0.24609375,
      "grad_norm": 1.5625927448272705,
      "learning_rate": 8.185298621745789e-06,
      "loss": 0.2618,
      "step": 1071
    },
    {
      "epoch": 0.24632352941176472,
      "grad_norm": 1.8932485580444336,
      "learning_rate": 8.192955589586524e-06,
      "loss": 0.3382,
      "step": 1072
    },
    {
      "epoch": 0.2465533088235294,
      "grad_norm": 1.1287580728530884,
      "learning_rate": 8.20061255742726e-06,
      "loss": 0.2476,
      "step": 1073
    },
    {
      "epoch": 0.24678308823529413,
      "grad_norm": 1.5503407716751099,
      "learning_rate": 8.208269525267995e-06,
      "loss": 0.2621,
      "step": 1074
    },
    {
      "epoch": 0.24701286764705882,
      "grad_norm": 1.3463516235351562,
      "learning_rate": 8.215926493108731e-06,
      "loss": 0.276,
      "step": 1075
    },
    {
      "epoch": 0.24724264705882354,
      "grad_norm": 1.346635103225708,
      "learning_rate": 8.223583460949464e-06,
      "loss": 0.3145,
      "step": 1076
    },
    {
      "epoch": 0.24747242647058823,
      "grad_norm": 1.4241526126861572,
      "learning_rate": 8.231240428790198e-06,
      "loss": 0.3543,
      "step": 1077
    },
    {
      "epoch": 0.24770220588235295,
      "grad_norm": 1.4526561498641968,
      "learning_rate": 8.238897396630935e-06,
      "loss": 0.2997,
      "step": 1078
    },
    {
      "epoch": 0.24793198529411764,
      "grad_norm": 1.6781306266784668,
      "learning_rate": 8.24655436447167e-06,
      "loss": 0.4207,
      "step": 1079
    },
    {
      "epoch": 0.24816176470588236,
      "grad_norm": 1.1550724506378174,
      "learning_rate": 8.254211332312406e-06,
      "loss": 0.2629,
      "step": 1080
    },
    {
      "epoch": 0.24839154411764705,
      "grad_norm": 1.4280132055282593,
      "learning_rate": 8.26186830015314e-06,
      "loss": 0.3009,
      "step": 1081
    },
    {
      "epoch": 0.24862132352941177,
      "grad_norm": 1.2709671258926392,
      "learning_rate": 8.269525267993875e-06,
      "loss": 0.3123,
      "step": 1082
    },
    {
      "epoch": 0.24885110294117646,
      "grad_norm": 1.2658241987228394,
      "learning_rate": 8.27718223583461e-06,
      "loss": 0.2942,
      "step": 1083
    },
    {
      "epoch": 0.24908088235294118,
      "grad_norm": 1.4035074710845947,
      "learning_rate": 8.284839203675346e-06,
      "loss": 0.3265,
      "step": 1084
    },
    {
      "epoch": 0.24931066176470587,
      "grad_norm": 1.4552005529403687,
      "learning_rate": 8.29249617151608e-06,
      "loss": 0.3047,
      "step": 1085
    },
    {
      "epoch": 0.2495404411764706,
      "grad_norm": 1.2390822172164917,
      "learning_rate": 8.300153139356815e-06,
      "loss": 0.3131,
      "step": 1086
    },
    {
      "epoch": 0.24977022058823528,
      "grad_norm": 1.3388378620147705,
      "learning_rate": 8.30781010719755e-06,
      "loss": 0.348,
      "step": 1087
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.3496296405792236,
      "learning_rate": 8.315467075038286e-06,
      "loss": 0.2996,
      "step": 1088
    },
    {
      "epoch": 0.2502297794117647,
      "grad_norm": 1.582041621208191,
      "learning_rate": 8.323124042879021e-06,
      "loss": 0.271,
      "step": 1089
    },
    {
      "epoch": 0.25045955882352944,
      "grad_norm": 1.2521103620529175,
      "learning_rate": 8.330781010719756e-06,
      "loss": 0.3457,
      "step": 1090
    },
    {
      "epoch": 0.2506893382352941,
      "grad_norm": 1.5184272527694702,
      "learning_rate": 8.33843797856049e-06,
      "loss": 0.254,
      "step": 1091
    },
    {
      "epoch": 0.2509191176470588,
      "grad_norm": 1.7302621603012085,
      "learning_rate": 8.346094946401225e-06,
      "loss": 0.2878,
      "step": 1092
    },
    {
      "epoch": 0.25114889705882354,
      "grad_norm": 1.2773207426071167,
      "learning_rate": 8.353751914241961e-06,
      "loss": 0.3402,
      "step": 1093
    },
    {
      "epoch": 0.25137867647058826,
      "grad_norm": 1.195551872253418,
      "learning_rate": 8.361408882082696e-06,
      "loss": 0.2932,
      "step": 1094
    },
    {
      "epoch": 0.2516084558823529,
      "grad_norm": 1.4757598638534546,
      "learning_rate": 8.36906584992343e-06,
      "loss": 0.3024,
      "step": 1095
    },
    {
      "epoch": 0.25183823529411764,
      "grad_norm": 2.3180549144744873,
      "learning_rate": 8.376722817764165e-06,
      "loss": 0.3478,
      "step": 1096
    },
    {
      "epoch": 0.25206801470588236,
      "grad_norm": 1.6507813930511475,
      "learning_rate": 8.384379785604901e-06,
      "loss": 0.3335,
      "step": 1097
    },
    {
      "epoch": 0.2522977941176471,
      "grad_norm": 1.5904340744018555,
      "learning_rate": 8.392036753445636e-06,
      "loss": 0.2563,
      "step": 1098
    },
    {
      "epoch": 0.25252757352941174,
      "grad_norm": 1.3673059940338135,
      "learning_rate": 8.399693721286372e-06,
      "loss": 0.3429,
      "step": 1099
    },
    {
      "epoch": 0.25275735294117646,
      "grad_norm": 1.24459969997406,
      "learning_rate": 8.407350689127107e-06,
      "loss": 0.314,
      "step": 1100
    },
    {
      "epoch": 0.2529871323529412,
      "grad_norm": 1.524430513381958,
      "learning_rate": 8.415007656967842e-06,
      "loss": 0.2962,
      "step": 1101
    },
    {
      "epoch": 0.2532169117647059,
      "grad_norm": 1.202607274055481,
      "learning_rate": 8.422664624808576e-06,
      "loss": 0.3456,
      "step": 1102
    },
    {
      "epoch": 0.25344669117647056,
      "grad_norm": 1.237143874168396,
      "learning_rate": 8.430321592649313e-06,
      "loss": 0.3207,
      "step": 1103
    },
    {
      "epoch": 0.2536764705882353,
      "grad_norm": 1.528995156288147,
      "learning_rate": 8.437978560490047e-06,
      "loss": 0.2452,
      "step": 1104
    },
    {
      "epoch": 0.25390625,
      "grad_norm": 1.6462963819503784,
      "learning_rate": 8.445635528330782e-06,
      "loss": 0.3239,
      "step": 1105
    },
    {
      "epoch": 0.2541360294117647,
      "grad_norm": 1.292794942855835,
      "learning_rate": 8.453292496171516e-06,
      "loss": 0.2408,
      "step": 1106
    },
    {
      "epoch": 0.25436580882352944,
      "grad_norm": 1.1552749872207642,
      "learning_rate": 8.460949464012251e-06,
      "loss": 0.2975,
      "step": 1107
    },
    {
      "epoch": 0.2545955882352941,
      "grad_norm": 1.4210360050201416,
      "learning_rate": 8.468606431852987e-06,
      "loss": 0.2599,
      "step": 1108
    },
    {
      "epoch": 0.2548253676470588,
      "grad_norm": 1.270426869392395,
      "learning_rate": 8.476263399693722e-06,
      "loss": 0.2743,
      "step": 1109
    },
    {
      "epoch": 0.25505514705882354,
      "grad_norm": 1.4922335147857666,
      "learning_rate": 8.483920367534457e-06,
      "loss": 0.3252,
      "step": 1110
    },
    {
      "epoch": 0.25528492647058826,
      "grad_norm": 1.2497010231018066,
      "learning_rate": 8.491577335375191e-06,
      "loss": 0.2686,
      "step": 1111
    },
    {
      "epoch": 0.2555147058823529,
      "grad_norm": 1.5465362071990967,
      "learning_rate": 8.499234303215928e-06,
      "loss": 0.2912,
      "step": 1112
    },
    {
      "epoch": 0.25574448529411764,
      "grad_norm": 2.1616995334625244,
      "learning_rate": 8.506891271056662e-06,
      "loss": 0.2704,
      "step": 1113
    },
    {
      "epoch": 0.25597426470588236,
      "grad_norm": 1.4575048685073853,
      "learning_rate": 8.514548238897397e-06,
      "loss": 0.3371,
      "step": 1114
    },
    {
      "epoch": 0.2562040441176471,
      "grad_norm": 1.5283491611480713,
      "learning_rate": 8.522205206738132e-06,
      "loss": 0.2755,
      "step": 1115
    },
    {
      "epoch": 0.25643382352941174,
      "grad_norm": 1.416672945022583,
      "learning_rate": 8.529862174578868e-06,
      "loss": 0.3258,
      "step": 1116
    },
    {
      "epoch": 0.25666360294117646,
      "grad_norm": 1.0004878044128418,
      "learning_rate": 8.537519142419603e-06,
      "loss": 0.2625,
      "step": 1117
    },
    {
      "epoch": 0.2568933823529412,
      "grad_norm": 1.2649599313735962,
      "learning_rate": 8.545176110260339e-06,
      "loss": 0.2557,
      "step": 1118
    },
    {
      "epoch": 0.2571231617647059,
      "grad_norm": 1.346133828163147,
      "learning_rate": 8.552833078101073e-06,
      "loss": 0.2968,
      "step": 1119
    },
    {
      "epoch": 0.25735294117647056,
      "grad_norm": 1.275679349899292,
      "learning_rate": 8.560490045941806e-06,
      "loss": 0.3048,
      "step": 1120
    },
    {
      "epoch": 0.2575827205882353,
      "grad_norm": 1.5401300191879272,
      "learning_rate": 8.568147013782543e-06,
      "loss": 0.2734,
      "step": 1121
    },
    {
      "epoch": 0.2578125,
      "grad_norm": 1.3642252683639526,
      "learning_rate": 8.575803981623277e-06,
      "loss": 0.2664,
      "step": 1122
    },
    {
      "epoch": 0.2580422794117647,
      "grad_norm": 1.2062513828277588,
      "learning_rate": 8.583460949464014e-06,
      "loss": 0.2464,
      "step": 1123
    },
    {
      "epoch": 0.25827205882352944,
      "grad_norm": 1.4094634056091309,
      "learning_rate": 8.591117917304748e-06,
      "loss": 0.3496,
      "step": 1124
    },
    {
      "epoch": 0.2585018382352941,
      "grad_norm": 1.3315025568008423,
      "learning_rate": 8.598774885145483e-06,
      "loss": 0.1996,
      "step": 1125
    },
    {
      "epoch": 0.2587316176470588,
      "grad_norm": 1.5378313064575195,
      "learning_rate": 8.606431852986218e-06,
      "loss": 0.2625,
      "step": 1126
    },
    {
      "epoch": 0.25896139705882354,
      "grad_norm": 1.3024003505706787,
      "learning_rate": 8.614088820826954e-06,
      "loss": 0.2568,
      "step": 1127
    },
    {
      "epoch": 0.25919117647058826,
      "grad_norm": 1.4409070014953613,
      "learning_rate": 8.621745788667689e-06,
      "loss": 0.2397,
      "step": 1128
    },
    {
      "epoch": 0.2594209558823529,
      "grad_norm": 1.4086917638778687,
      "learning_rate": 8.629402756508423e-06,
      "loss": 0.338,
      "step": 1129
    },
    {
      "epoch": 0.25965073529411764,
      "grad_norm": 1.4184097051620483,
      "learning_rate": 8.637059724349158e-06,
      "loss": 0.3349,
      "step": 1130
    },
    {
      "epoch": 0.25988051470588236,
      "grad_norm": 1.3199886083602905,
      "learning_rate": 8.644716692189894e-06,
      "loss": 0.3386,
      "step": 1131
    },
    {
      "epoch": 0.2601102941176471,
      "grad_norm": 1.1540756225585938,
      "learning_rate": 8.652373660030629e-06,
      "loss": 0.2795,
      "step": 1132
    },
    {
      "epoch": 0.26034007352941174,
      "grad_norm": 1.3493759632110596,
      "learning_rate": 8.660030627871363e-06,
      "loss": 0.2935,
      "step": 1133
    },
    {
      "epoch": 0.26056985294117646,
      "grad_norm": 1.4679944515228271,
      "learning_rate": 8.667687595712098e-06,
      "loss": 0.3897,
      "step": 1134
    },
    {
      "epoch": 0.2607996323529412,
      "grad_norm": 1.2645654678344727,
      "learning_rate": 8.675344563552833e-06,
      "loss": 0.3399,
      "step": 1135
    },
    {
      "epoch": 0.2610294117647059,
      "grad_norm": 1.1547536849975586,
      "learning_rate": 8.683001531393569e-06,
      "loss": 0.2244,
      "step": 1136
    },
    {
      "epoch": 0.26125919117647056,
      "grad_norm": 1.2603751420974731,
      "learning_rate": 8.690658499234304e-06,
      "loss": 0.2867,
      "step": 1137
    },
    {
      "epoch": 0.2614889705882353,
      "grad_norm": 1.2565323114395142,
      "learning_rate": 8.698315467075038e-06,
      "loss": 0.2782,
      "step": 1138
    },
    {
      "epoch": 0.26171875,
      "grad_norm": 1.1661767959594727,
      "learning_rate": 8.705972434915773e-06,
      "loss": 0.3023,
      "step": 1139
    },
    {
      "epoch": 0.2619485294117647,
      "grad_norm": 1.347866177558899,
      "learning_rate": 8.71362940275651e-06,
      "loss": 0.2781,
      "step": 1140
    },
    {
      "epoch": 0.26217830882352944,
      "grad_norm": 1.265999436378479,
      "learning_rate": 8.721286370597244e-06,
      "loss": 0.2633,
      "step": 1141
    },
    {
      "epoch": 0.2624080882352941,
      "grad_norm": 1.2858492136001587,
      "learning_rate": 8.72894333843798e-06,
      "loss": 0.3104,
      "step": 1142
    },
    {
      "epoch": 0.2626378676470588,
      "grad_norm": 1.185455322265625,
      "learning_rate": 8.736600306278715e-06,
      "loss": 0.2971,
      "step": 1143
    },
    {
      "epoch": 0.26286764705882354,
      "grad_norm": 1.3523677587509155,
      "learning_rate": 8.74425727411945e-06,
      "loss": 0.2684,
      "step": 1144
    },
    {
      "epoch": 0.26309742647058826,
      "grad_norm": 1.4544001817703247,
      "learning_rate": 8.751914241960184e-06,
      "loss": 0.3153,
      "step": 1145
    },
    {
      "epoch": 0.2633272058823529,
      "grad_norm": 1.1218644380569458,
      "learning_rate": 8.75957120980092e-06,
      "loss": 0.2613,
      "step": 1146
    },
    {
      "epoch": 0.26355698529411764,
      "grad_norm": 1.5681369304656982,
      "learning_rate": 8.767228177641655e-06,
      "loss": 0.2608,
      "step": 1147
    },
    {
      "epoch": 0.26378676470588236,
      "grad_norm": 1.4248466491699219,
      "learning_rate": 8.77488514548239e-06,
      "loss": 0.264,
      "step": 1148
    },
    {
      "epoch": 0.2640165441176471,
      "grad_norm": 1.2620892524719238,
      "learning_rate": 8.782542113323124e-06,
      "loss": 0.3072,
      "step": 1149
    },
    {
      "epoch": 0.26424632352941174,
      "grad_norm": 1.70549476146698,
      "learning_rate": 8.790199081163859e-06,
      "loss": 0.2698,
      "step": 1150
    },
    {
      "epoch": 0.26447610294117646,
      "grad_norm": 1.1449223756790161,
      "learning_rate": 8.797856049004595e-06,
      "loss": 0.2752,
      "step": 1151
    },
    {
      "epoch": 0.2647058823529412,
      "grad_norm": 1.3677505254745483,
      "learning_rate": 8.80551301684533e-06,
      "loss": 0.3032,
      "step": 1152
    },
    {
      "epoch": 0.2649356617647059,
      "grad_norm": 1.1518070697784424,
      "learning_rate": 8.813169984686065e-06,
      "loss": 0.2685,
      "step": 1153
    },
    {
      "epoch": 0.26516544117647056,
      "grad_norm": 1.21550714969635,
      "learning_rate": 8.8208269525268e-06,
      "loss": 0.2602,
      "step": 1154
    },
    {
      "epoch": 0.2653952205882353,
      "grad_norm": 1.3861560821533203,
      "learning_rate": 8.828483920367536e-06,
      "loss": 0.293,
      "step": 1155
    },
    {
      "epoch": 0.265625,
      "grad_norm": 1.1993253231048584,
      "learning_rate": 8.83614088820827e-06,
      "loss": 0.2645,
      "step": 1156
    },
    {
      "epoch": 0.2658547794117647,
      "grad_norm": 1.6577516794204712,
      "learning_rate": 8.843797856049005e-06,
      "loss": 0.2569,
      "step": 1157
    },
    {
      "epoch": 0.26608455882352944,
      "grad_norm": 1.5035251379013062,
      "learning_rate": 8.85145482388974e-06,
      "loss": 0.2826,
      "step": 1158
    },
    {
      "epoch": 0.2663143382352941,
      "grad_norm": 1.210427165031433,
      "learning_rate": 8.859111791730476e-06,
      "loss": 0.242,
      "step": 1159
    },
    {
      "epoch": 0.2665441176470588,
      "grad_norm": 1.623491644859314,
      "learning_rate": 8.86676875957121e-06,
      "loss": 0.2686,
      "step": 1160
    },
    {
      "epoch": 0.26677389705882354,
      "grad_norm": 1.4708433151245117,
      "learning_rate": 8.874425727411947e-06,
      "loss": 0.2676,
      "step": 1161
    },
    {
      "epoch": 0.26700367647058826,
      "grad_norm": 1.0175944566726685,
      "learning_rate": 8.882082695252681e-06,
      "loss": 0.2133,
      "step": 1162
    },
    {
      "epoch": 0.2672334558823529,
      "grad_norm": 1.4086354970932007,
      "learning_rate": 8.889739663093414e-06,
      "loss": 0.2712,
      "step": 1163
    },
    {
      "epoch": 0.26746323529411764,
      "grad_norm": 1.2426599264144897,
      "learning_rate": 8.89739663093415e-06,
      "loss": 0.2673,
      "step": 1164
    },
    {
      "epoch": 0.26769301470588236,
      "grad_norm": 1.5269684791564941,
      "learning_rate": 8.905053598774885e-06,
      "loss": 0.3162,
      "step": 1165
    },
    {
      "epoch": 0.2679227941176471,
      "grad_norm": 1.3838615417480469,
      "learning_rate": 8.912710566615622e-06,
      "loss": 0.2487,
      "step": 1166
    },
    {
      "epoch": 0.26815257352941174,
      "grad_norm": 1.4354238510131836,
      "learning_rate": 8.920367534456356e-06,
      "loss": 0.2886,
      "step": 1167
    },
    {
      "epoch": 0.26838235294117646,
      "grad_norm": 1.366196870803833,
      "learning_rate": 8.928024502297091e-06,
      "loss": 0.2589,
      "step": 1168
    },
    {
      "epoch": 0.2686121323529412,
      "grad_norm": 1.3323172330856323,
      "learning_rate": 8.935681470137826e-06,
      "loss": 0.2511,
      "step": 1169
    },
    {
      "epoch": 0.2688419117647059,
      "grad_norm": 1.279700517654419,
      "learning_rate": 8.943338437978562e-06,
      "loss": 0.2592,
      "step": 1170
    },
    {
      "epoch": 0.26907169117647056,
      "grad_norm": 1.704127550125122,
      "learning_rate": 8.950995405819297e-06,
      "loss": 0.2875,
      "step": 1171
    },
    {
      "epoch": 0.2693014705882353,
      "grad_norm": 1.34597909450531,
      "learning_rate": 8.958652373660031e-06,
      "loss": 0.2869,
      "step": 1172
    },
    {
      "epoch": 0.26953125,
      "grad_norm": 1.7964363098144531,
      "learning_rate": 8.966309341500766e-06,
      "loss": 0.2412,
      "step": 1173
    },
    {
      "epoch": 0.2697610294117647,
      "grad_norm": 1.385533332824707,
      "learning_rate": 8.973966309341502e-06,
      "loss": 0.2338,
      "step": 1174
    },
    {
      "epoch": 0.26999080882352944,
      "grad_norm": 1.3696873188018799,
      "learning_rate": 8.981623277182237e-06,
      "loss": 0.2935,
      "step": 1175
    },
    {
      "epoch": 0.2702205882352941,
      "grad_norm": 1.4212816953659058,
      "learning_rate": 8.989280245022971e-06,
      "loss": 0.2966,
      "step": 1176
    },
    {
      "epoch": 0.2704503676470588,
      "grad_norm": 1.2639448642730713,
      "learning_rate": 8.996937212863706e-06,
      "loss": 0.2741,
      "step": 1177
    },
    {
      "epoch": 0.27068014705882354,
      "grad_norm": 1.4766712188720703,
      "learning_rate": 9.00459418070444e-06,
      "loss": 0.2623,
      "step": 1178
    },
    {
      "epoch": 0.27090992647058826,
      "grad_norm": 1.373358964920044,
      "learning_rate": 9.012251148545177e-06,
      "loss": 0.2512,
      "step": 1179
    },
    {
      "epoch": 0.2711397058823529,
      "grad_norm": 1.2593672275543213,
      "learning_rate": 9.019908116385912e-06,
      "loss": 0.2384,
      "step": 1180
    },
    {
      "epoch": 0.27136948529411764,
      "grad_norm": 1.7936601638793945,
      "learning_rate": 9.027565084226648e-06,
      "loss": 0.3007,
      "step": 1181
    },
    {
      "epoch": 0.27159926470588236,
      "grad_norm": 1.4084382057189941,
      "learning_rate": 9.035222052067381e-06,
      "loss": 0.2257,
      "step": 1182
    },
    {
      "epoch": 0.2718290441176471,
      "grad_norm": 1.4938017129898071,
      "learning_rate": 9.042879019908117e-06,
      "loss": 0.2419,
      "step": 1183
    },
    {
      "epoch": 0.27205882352941174,
      "grad_norm": 1.4958627223968506,
      "learning_rate": 9.050535987748852e-06,
      "loss": 0.2745,
      "step": 1184
    },
    {
      "epoch": 0.27228860294117646,
      "grad_norm": 1.5673373937606812,
      "learning_rate": 9.058192955589588e-06,
      "loss": 0.2835,
      "step": 1185
    },
    {
      "epoch": 0.2725183823529412,
      "grad_norm": 1.668074607849121,
      "learning_rate": 9.065849923430323e-06,
      "loss": 0.2643,
      "step": 1186
    },
    {
      "epoch": 0.2727481617647059,
      "grad_norm": 1.43377685546875,
      "learning_rate": 9.073506891271057e-06,
      "loss": 0.3042,
      "step": 1187
    },
    {
      "epoch": 0.27297794117647056,
      "grad_norm": 1.716220498085022,
      "learning_rate": 9.081163859111792e-06,
      "loss": 0.3549,
      "step": 1188
    },
    {
      "epoch": 0.2732077205882353,
      "grad_norm": 1.465400218963623,
      "learning_rate": 9.088820826952528e-06,
      "loss": 0.3129,
      "step": 1189
    },
    {
      "epoch": 0.2734375,
      "grad_norm": 1.182873249053955,
      "learning_rate": 9.096477794793263e-06,
      "loss": 0.2626,
      "step": 1190
    },
    {
      "epoch": 0.2736672794117647,
      "grad_norm": 1.3922611474990845,
      "learning_rate": 9.104134762633998e-06,
      "loss": 0.2444,
      "step": 1191
    },
    {
      "epoch": 0.27389705882352944,
      "grad_norm": 1.1902823448181152,
      "learning_rate": 9.111791730474732e-06,
      "loss": 0.2611,
      "step": 1192
    },
    {
      "epoch": 0.2741268382352941,
      "grad_norm": 1.4727685451507568,
      "learning_rate": 9.119448698315467e-06,
      "loss": 0.2144,
      "step": 1193
    },
    {
      "epoch": 0.2743566176470588,
      "grad_norm": 1.423374056816101,
      "learning_rate": 9.127105666156203e-06,
      "loss": 0.2093,
      "step": 1194
    },
    {
      "epoch": 0.27458639705882354,
      "grad_norm": 1.1503946781158447,
      "learning_rate": 9.134762633996938e-06,
      "loss": 0.2647,
      "step": 1195
    },
    {
      "epoch": 0.27481617647058826,
      "grad_norm": 1.326560378074646,
      "learning_rate": 9.142419601837673e-06,
      "loss": 0.2178,
      "step": 1196
    },
    {
      "epoch": 0.2750459558823529,
      "grad_norm": 1.9222586154937744,
      "learning_rate": 9.150076569678407e-06,
      "loss": 0.331,
      "step": 1197
    },
    {
      "epoch": 0.27527573529411764,
      "grad_norm": 1.5256363153457642,
      "learning_rate": 9.157733537519144e-06,
      "loss": 0.2118,
      "step": 1198
    },
    {
      "epoch": 0.27550551470588236,
      "grad_norm": 1.1099772453308105,
      "learning_rate": 9.165390505359878e-06,
      "loss": 0.2222,
      "step": 1199
    },
    {
      "epoch": 0.2757352941176471,
      "grad_norm": 1.5219831466674805,
      "learning_rate": 9.173047473200613e-06,
      "loss": 0.3226,
      "step": 1200
    },
    {
      "epoch": 0.27596507352941174,
      "grad_norm": 1.479635238647461,
      "learning_rate": 9.180704441041347e-06,
      "loss": 0.2536,
      "step": 1201
    },
    {
      "epoch": 0.27619485294117646,
      "grad_norm": 1.1824994087219238,
      "learning_rate": 9.188361408882084e-06,
      "loss": 0.2232,
      "step": 1202
    },
    {
      "epoch": 0.2764246323529412,
      "grad_norm": 2.0378408432006836,
      "learning_rate": 9.196018376722818e-06,
      "loss": 0.3701,
      "step": 1203
    },
    {
      "epoch": 0.2766544117647059,
      "grad_norm": 1.4456121921539307,
      "learning_rate": 9.203675344563555e-06,
      "loss": 0.2397,
      "step": 1204
    },
    {
      "epoch": 0.27688419117647056,
      "grad_norm": 1.3780405521392822,
      "learning_rate": 9.21133231240429e-06,
      "loss": 0.2522,
      "step": 1205
    },
    {
      "epoch": 0.2771139705882353,
      "grad_norm": 1.9067959785461426,
      "learning_rate": 9.218989280245024e-06,
      "loss": 0.3002,
      "step": 1206
    },
    {
      "epoch": 0.27734375,
      "grad_norm": 1.4042272567749023,
      "learning_rate": 9.226646248085759e-06,
      "loss": 0.2258,
      "step": 1207
    },
    {
      "epoch": 0.2775735294117647,
      "grad_norm": 1.4916263818740845,
      "learning_rate": 9.234303215926493e-06,
      "loss": 0.2658,
      "step": 1208
    },
    {
      "epoch": 0.27780330882352944,
      "grad_norm": 1.383998990058899,
      "learning_rate": 9.24196018376723e-06,
      "loss": 0.2577,
      "step": 1209
    },
    {
      "epoch": 0.2780330882352941,
      "grad_norm": 1.4216556549072266,
      "learning_rate": 9.249617151607964e-06,
      "loss": 0.2036,
      "step": 1210
    },
    {
      "epoch": 0.2782628676470588,
      "grad_norm": 1.368345022201538,
      "learning_rate": 9.257274119448699e-06,
      "loss": 0.2652,
      "step": 1211
    },
    {
      "epoch": 0.27849264705882354,
      "grad_norm": 1.2681725025177002,
      "learning_rate": 9.264931087289434e-06,
      "loss": 0.3195,
      "step": 1212
    },
    {
      "epoch": 0.27872242647058826,
      "grad_norm": 1.5927079916000366,
      "learning_rate": 9.27258805513017e-06,
      "loss": 0.2528,
      "step": 1213
    },
    {
      "epoch": 0.2789522058823529,
      "grad_norm": 1.7117588520050049,
      "learning_rate": 9.280245022970904e-06,
      "loss": 0.2871,
      "step": 1214
    },
    {
      "epoch": 0.27918198529411764,
      "grad_norm": 1.7681858539581299,
      "learning_rate": 9.287901990811639e-06,
      "loss": 0.2879,
      "step": 1215
    },
    {
      "epoch": 0.27941176470588236,
      "grad_norm": 1.2854455709457397,
      "learning_rate": 9.295558958652374e-06,
      "loss": 0.2782,
      "step": 1216
    },
    {
      "epoch": 0.2796415441176471,
      "grad_norm": 1.4778748750686646,
      "learning_rate": 9.30321592649311e-06,
      "loss": 0.2304,
      "step": 1217
    },
    {
      "epoch": 0.27987132352941174,
      "grad_norm": 1.2647180557250977,
      "learning_rate": 9.310872894333845e-06,
      "loss": 0.2706,
      "step": 1218
    },
    {
      "epoch": 0.28010110294117646,
      "grad_norm": 1.4403443336486816,
      "learning_rate": 9.31852986217458e-06,
      "loss": 0.3129,
      "step": 1219
    },
    {
      "epoch": 0.2803308823529412,
      "grad_norm": 1.2954092025756836,
      "learning_rate": 9.326186830015314e-06,
      "loss": 0.3595,
      "step": 1220
    },
    {
      "epoch": 0.2805606617647059,
      "grad_norm": 1.560104489326477,
      "learning_rate": 9.333843797856049e-06,
      "loss": 0.2962,
      "step": 1221
    },
    {
      "epoch": 0.28079044117647056,
      "grad_norm": 1.3242498636245728,
      "learning_rate": 9.341500765696785e-06,
      "loss": 0.2153,
      "step": 1222
    },
    {
      "epoch": 0.2810202205882353,
      "grad_norm": 1.9618405103683472,
      "learning_rate": 9.34915773353752e-06,
      "loss": 0.3517,
      "step": 1223
    },
    {
      "epoch": 0.28125,
      "grad_norm": 1.5303778648376465,
      "learning_rate": 9.356814701378256e-06,
      "loss": 0.2696,
      "step": 1224
    },
    {
      "epoch": 0.2814797794117647,
      "grad_norm": 1.5575370788574219,
      "learning_rate": 9.364471669218989e-06,
      "loss": 0.2765,
      "step": 1225
    },
    {
      "epoch": 0.28170955882352944,
      "grad_norm": 1.2339165210723877,
      "learning_rate": 9.372128637059725e-06,
      "loss": 0.2537,
      "step": 1226
    },
    {
      "epoch": 0.2819393382352941,
      "grad_norm": 1.5083813667297363,
      "learning_rate": 9.37978560490046e-06,
      "loss": 0.2884,
      "step": 1227
    },
    {
      "epoch": 0.2821691176470588,
      "grad_norm": 1.3848720788955688,
      "learning_rate": 9.387442572741196e-06,
      "loss": 0.29,
      "step": 1228
    },
    {
      "epoch": 0.28239889705882354,
      "grad_norm": 1.5329012870788574,
      "learning_rate": 9.39509954058193e-06,
      "loss": 0.2946,
      "step": 1229
    },
    {
      "epoch": 0.28262867647058826,
      "grad_norm": 1.462283968925476,
      "learning_rate": 9.402756508422665e-06,
      "loss": 0.2571,
      "step": 1230
    },
    {
      "epoch": 0.2828584558823529,
      "grad_norm": 1.2260911464691162,
      "learning_rate": 9.4104134762634e-06,
      "loss": 0.3055,
      "step": 1231
    },
    {
      "epoch": 0.28308823529411764,
      "grad_norm": 1.2992348670959473,
      "learning_rate": 9.418070444104136e-06,
      "loss": 0.3513,
      "step": 1232
    },
    {
      "epoch": 0.28331801470588236,
      "grad_norm": 1.070243000984192,
      "learning_rate": 9.425727411944871e-06,
      "loss": 0.2372,
      "step": 1233
    },
    {
      "epoch": 0.2835477941176471,
      "grad_norm": 1.2854499816894531,
      "learning_rate": 9.433384379785606e-06,
      "loss": 0.2285,
      "step": 1234
    },
    {
      "epoch": 0.28377757352941174,
      "grad_norm": 1.3050456047058105,
      "learning_rate": 9.44104134762634e-06,
      "loss": 0.2823,
      "step": 1235
    },
    {
      "epoch": 0.28400735294117646,
      "grad_norm": 1.3545998334884644,
      "learning_rate": 9.448698315467075e-06,
      "loss": 0.2302,
      "step": 1236
    },
    {
      "epoch": 0.2842371323529412,
      "grad_norm": 1.5777949094772339,
      "learning_rate": 9.456355283307811e-06,
      "loss": 0.288,
      "step": 1237
    },
    {
      "epoch": 0.2844669117647059,
      "grad_norm": 1.2992433309555054,
      "learning_rate": 9.464012251148546e-06,
      "loss": 0.2344,
      "step": 1238
    },
    {
      "epoch": 0.28469669117647056,
      "grad_norm": 1.3868228197097778,
      "learning_rate": 9.47166921898928e-06,
      "loss": 0.2339,
      "step": 1239
    },
    {
      "epoch": 0.2849264705882353,
      "grad_norm": 1.4683252573013306,
      "learning_rate": 9.479326186830015e-06,
      "loss": 0.2999,
      "step": 1240
    },
    {
      "epoch": 0.28515625,
      "grad_norm": 1.7720338106155396,
      "learning_rate": 9.486983154670751e-06,
      "loss": 0.2713,
      "step": 1241
    },
    {
      "epoch": 0.2853860294117647,
      "grad_norm": 1.2936251163482666,
      "learning_rate": 9.494640122511486e-06,
      "loss": 0.2632,
      "step": 1242
    },
    {
      "epoch": 0.28561580882352944,
      "grad_norm": 1.607269048690796,
      "learning_rate": 9.50229709035222e-06,
      "loss": 0.269,
      "step": 1243
    },
    {
      "epoch": 0.2858455882352941,
      "grad_norm": 0.9931782484054565,
      "learning_rate": 9.509954058192955e-06,
      "loss": 0.2434,
      "step": 1244
    },
    {
      "epoch": 0.2860753676470588,
      "grad_norm": 1.3740952014923096,
      "learning_rate": 9.517611026033692e-06,
      "loss": 0.2169,
      "step": 1245
    },
    {
      "epoch": 0.28630514705882354,
      "grad_norm": 1.155692219734192,
      "learning_rate": 9.525267993874426e-06,
      "loss": 0.2592,
      "step": 1246
    },
    {
      "epoch": 0.28653492647058826,
      "grad_norm": 1.2673414945602417,
      "learning_rate": 9.532924961715163e-06,
      "loss": 0.284,
      "step": 1247
    },
    {
      "epoch": 0.2867647058823529,
      "grad_norm": 1.2249466180801392,
      "learning_rate": 9.540581929555897e-06,
      "loss": 0.1952,
      "step": 1248
    },
    {
      "epoch": 0.28699448529411764,
      "grad_norm": 1.1944745779037476,
      "learning_rate": 9.548238897396632e-06,
      "loss": 0.2294,
      "step": 1249
    },
    {
      "epoch": 0.28722426470588236,
      "grad_norm": 1.2782397270202637,
      "learning_rate": 9.555895865237367e-06,
      "loss": 0.2541,
      "step": 1250
    },
    {
      "epoch": 0.2874540441176471,
      "grad_norm": 1.3532267808914185,
      "learning_rate": 9.563552833078101e-06,
      "loss": 0.2137,
      "step": 1251
    },
    {
      "epoch": 0.28768382352941174,
      "grad_norm": 1.416453242301941,
      "learning_rate": 9.571209800918838e-06,
      "loss": 0.2572,
      "step": 1252
    },
    {
      "epoch": 0.28791360294117646,
      "grad_norm": 1.5674697160720825,
      "learning_rate": 9.578866768759572e-06,
      "loss": 0.2859,
      "step": 1253
    },
    {
      "epoch": 0.2881433823529412,
      "grad_norm": 1.3662744760513306,
      "learning_rate": 9.586523736600307e-06,
      "loss": 0.2459,
      "step": 1254
    },
    {
      "epoch": 0.2883731617647059,
      "grad_norm": 1.3796427249908447,
      "learning_rate": 9.594180704441041e-06,
      "loss": 0.2437,
      "step": 1255
    },
    {
      "epoch": 0.28860294117647056,
      "grad_norm": 1.0796736478805542,
      "learning_rate": 9.601837672281778e-06,
      "loss": 0.2525,
      "step": 1256
    },
    {
      "epoch": 0.2888327205882353,
      "grad_norm": 1.387542963027954,
      "learning_rate": 9.609494640122512e-06,
      "loss": 0.2527,
      "step": 1257
    },
    {
      "epoch": 0.2890625,
      "grad_norm": 1.4150257110595703,
      "learning_rate": 9.617151607963247e-06,
      "loss": 0.2673,
      "step": 1258
    },
    {
      "epoch": 0.2892922794117647,
      "grad_norm": 1.201494574546814,
      "learning_rate": 9.624808575803982e-06,
      "loss": 0.2822,
      "step": 1259
    },
    {
      "epoch": 0.28952205882352944,
      "grad_norm": 1.5444910526275635,
      "learning_rate": 9.632465543644718e-06,
      "loss": 0.2286,
      "step": 1260
    },
    {
      "epoch": 0.2897518382352941,
      "grad_norm": 1.4134576320648193,
      "learning_rate": 9.640122511485453e-06,
      "loss": 0.274,
      "step": 1261
    },
    {
      "epoch": 0.2899816176470588,
      "grad_norm": 1.429740309715271,
      "learning_rate": 9.647779479326187e-06,
      "loss": 0.2324,
      "step": 1262
    },
    {
      "epoch": 0.29021139705882354,
      "grad_norm": 1.6978789567947388,
      "learning_rate": 9.655436447166922e-06,
      "loss": 0.2628,
      "step": 1263
    },
    {
      "epoch": 0.29044117647058826,
      "grad_norm": 1.2435001134872437,
      "learning_rate": 9.663093415007658e-06,
      "loss": 0.2298,
      "step": 1264
    },
    {
      "epoch": 0.2906709558823529,
      "grad_norm": 1.3904346227645874,
      "learning_rate": 9.670750382848393e-06,
      "loss": 0.2371,
      "step": 1265
    },
    {
      "epoch": 0.29090073529411764,
      "grad_norm": 1.1244797706604004,
      "learning_rate": 9.678407350689128e-06,
      "loss": 0.1991,
      "step": 1266
    },
    {
      "epoch": 0.29113051470588236,
      "grad_norm": 1.467334508895874,
      "learning_rate": 9.686064318529864e-06,
      "loss": 0.2296,
      "step": 1267
    },
    {
      "epoch": 0.2913602941176471,
      "grad_norm": 1.1849712133407593,
      "learning_rate": 9.693721286370597e-06,
      "loss": 0.1922,
      "step": 1268
    },
    {
      "epoch": 0.29159007352941174,
      "grad_norm": 1.6807866096496582,
      "learning_rate": 9.701378254211333e-06,
      "loss": 0.2287,
      "step": 1269
    },
    {
      "epoch": 0.29181985294117646,
      "grad_norm": 1.4239766597747803,
      "learning_rate": 9.709035222052068e-06,
      "loss": 0.2697,
      "step": 1270
    },
    {
      "epoch": 0.2920496323529412,
      "grad_norm": 1.075979232788086,
      "learning_rate": 9.716692189892804e-06,
      "loss": 0.2408,
      "step": 1271
    },
    {
      "epoch": 0.2922794117647059,
      "grad_norm": 1.487536907196045,
      "learning_rate": 9.724349157733539e-06,
      "loss": 0.1831,
      "step": 1272
    },
    {
      "epoch": 0.29250919117647056,
      "grad_norm": 1.4195162057876587,
      "learning_rate": 9.732006125574273e-06,
      "loss": 0.2191,
      "step": 1273
    },
    {
      "epoch": 0.2927389705882353,
      "grad_norm": 1.4060983657836914,
      "learning_rate": 9.739663093415008e-06,
      "loss": 0.2422,
      "step": 1274
    },
    {
      "epoch": 0.29296875,
      "grad_norm": 1.3002337217330933,
      "learning_rate": 9.747320061255744e-06,
      "loss": 0.2134,
      "step": 1275
    },
    {
      "epoch": 0.2931985294117647,
      "grad_norm": 1.35369074344635,
      "learning_rate": 9.754977029096479e-06,
      "loss": 0.2422,
      "step": 1276
    },
    {
      "epoch": 0.29342830882352944,
      "grad_norm": 1.3271640539169312,
      "learning_rate": 9.762633996937214e-06,
      "loss": 0.2573,
      "step": 1277
    },
    {
      "epoch": 0.2936580882352941,
      "grad_norm": 1.9670466184616089,
      "learning_rate": 9.770290964777948e-06,
      "loss": 0.3298,
      "step": 1278
    },
    {
      "epoch": 0.2938878676470588,
      "grad_norm": 1.4543795585632324,
      "learning_rate": 9.777947932618683e-06,
      "loss": 0.2124,
      "step": 1279
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 1.4817506074905396,
      "learning_rate": 9.78560490045942e-06,
      "loss": 0.2417,
      "step": 1280
    },
    {
      "epoch": 0.29434742647058826,
      "grad_norm": 1.7187604904174805,
      "learning_rate": 9.793261868300154e-06,
      "loss": 0.282,
      "step": 1281
    },
    {
      "epoch": 0.2945772058823529,
      "grad_norm": 1.424971342086792,
      "learning_rate": 9.800918836140888e-06,
      "loss": 0.2231,
      "step": 1282
    },
    {
      "epoch": 0.29480698529411764,
      "grad_norm": 1.6700485944747925,
      "learning_rate": 9.808575803981623e-06,
      "loss": 0.2423,
      "step": 1283
    },
    {
      "epoch": 0.29503676470588236,
      "grad_norm": 1.4934022426605225,
      "learning_rate": 9.81623277182236e-06,
      "loss": 0.2977,
      "step": 1284
    },
    {
      "epoch": 0.2952665441176471,
      "grad_norm": 1.8466588258743286,
      "learning_rate": 9.823889739663094e-06,
      "loss": 0.3234,
      "step": 1285
    },
    {
      "epoch": 0.29549632352941174,
      "grad_norm": 1.1940937042236328,
      "learning_rate": 9.83154670750383e-06,
      "loss": 0.2607,
      "step": 1286
    },
    {
      "epoch": 0.29572610294117646,
      "grad_norm": 1.7202328443527222,
      "learning_rate": 9.839203675344563e-06,
      "loss": 0.2629,
      "step": 1287
    },
    {
      "epoch": 0.2959558823529412,
      "grad_norm": 1.224170446395874,
      "learning_rate": 9.8468606431853e-06,
      "loss": 0.2921,
      "step": 1288
    },
    {
      "epoch": 0.2961856617647059,
      "grad_norm": 1.0883102416992188,
      "learning_rate": 9.854517611026034e-06,
      "loss": 0.2018,
      "step": 1289
    },
    {
      "epoch": 0.29641544117647056,
      "grad_norm": 1.532570242881775,
      "learning_rate": 9.86217457886677e-06,
      "loss": 0.307,
      "step": 1290
    },
    {
      "epoch": 0.2966452205882353,
      "grad_norm": 1.5258883237838745,
      "learning_rate": 9.869831546707505e-06,
      "loss": 0.2824,
      "step": 1291
    },
    {
      "epoch": 0.296875,
      "grad_norm": 1.268222689628601,
      "learning_rate": 9.87748851454824e-06,
      "loss": 0.2409,
      "step": 1292
    },
    {
      "epoch": 0.2971047794117647,
      "grad_norm": 1.0306826829910278,
      "learning_rate": 9.885145482388975e-06,
      "loss": 0.2132,
      "step": 1293
    },
    {
      "epoch": 0.29733455882352944,
      "grad_norm": 1.4620031118392944,
      "learning_rate": 9.892802450229709e-06,
      "loss": 0.1995,
      "step": 1294
    },
    {
      "epoch": 0.2975643382352941,
      "grad_norm": 1.2606614828109741,
      "learning_rate": 9.900459418070445e-06,
      "loss": 0.2365,
      "step": 1295
    },
    {
      "epoch": 0.2977941176470588,
      "grad_norm": 1.3319588899612427,
      "learning_rate": 9.90811638591118e-06,
      "loss": 0.2071,
      "step": 1296
    },
    {
      "epoch": 0.29802389705882354,
      "grad_norm": 1.309104084968567,
      "learning_rate": 9.915773353751915e-06,
      "loss": 0.3038,
      "step": 1297
    },
    {
      "epoch": 0.29825367647058826,
      "grad_norm": 1.4394960403442383,
      "learning_rate": 9.92343032159265e-06,
      "loss": 0.2869,
      "step": 1298
    },
    {
      "epoch": 0.2984834558823529,
      "grad_norm": 1.466574788093567,
      "learning_rate": 9.931087289433386e-06,
      "loss": 0.2575,
      "step": 1299
    },
    {
      "epoch": 0.29871323529411764,
      "grad_norm": 1.088107705116272,
      "learning_rate": 9.93874425727412e-06,
      "loss": 0.2182,
      "step": 1300
    },
    {
      "epoch": 0.29894301470588236,
      "grad_norm": 1.409996747970581,
      "learning_rate": 9.946401225114855e-06,
      "loss": 0.2379,
      "step": 1301
    },
    {
      "epoch": 0.2991727941176471,
      "grad_norm": 1.3691164255142212,
      "learning_rate": 9.95405819295559e-06,
      "loss": 0.2295,
      "step": 1302
    },
    {
      "epoch": 0.29940257352941174,
      "grad_norm": 1.3339006900787354,
      "learning_rate": 9.961715160796326e-06,
      "loss": 0.2301,
      "step": 1303
    },
    {
      "epoch": 0.29963235294117646,
      "grad_norm": 1.5311475992202759,
      "learning_rate": 9.96937212863706e-06,
      "loss": 0.1919,
      "step": 1304
    },
    {
      "epoch": 0.2998621323529412,
      "grad_norm": 1.2126442193984985,
      "learning_rate": 9.977029096477795e-06,
      "loss": 0.209,
      "step": 1305
    },
    {
      "epoch": 0.3000919117647059,
      "grad_norm": 1.3427760601043701,
      "learning_rate": 9.98468606431853e-06,
      "loss": 0.2626,
      "step": 1306
    },
    {
      "epoch": 0.30032169117647056,
      "grad_norm": 1.4626115560531616,
      "learning_rate": 9.992343032159266e-06,
      "loss": 0.289,
      "step": 1307
    },
    {
      "epoch": 0.3005514705882353,
      "grad_norm": 1.143425703048706,
      "learning_rate": 1e-05,
      "loss": 0.1971,
      "step": 1308
    },
    {
      "epoch": 0.30078125,
      "grad_norm": 1.457749605178833,
      "learning_rate": 9.999148936170214e-06,
      "loss": 0.2999,
      "step": 1309
    },
    {
      "epoch": 0.3010110294117647,
      "grad_norm": 1.6197502613067627,
      "learning_rate": 9.998297872340427e-06,
      "loss": 0.2511,
      "step": 1310
    },
    {
      "epoch": 0.30124080882352944,
      "grad_norm": 1.284977912902832,
      "learning_rate": 9.997446808510639e-06,
      "loss": 0.1799,
      "step": 1311
    },
    {
      "epoch": 0.3014705882352941,
      "grad_norm": 1.3645278215408325,
      "learning_rate": 9.996595744680852e-06,
      "loss": 0.2792,
      "step": 1312
    },
    {
      "epoch": 0.3017003676470588,
      "grad_norm": 1.3791658878326416,
      "learning_rate": 9.995744680851065e-06,
      "loss": 0.2137,
      "step": 1313
    },
    {
      "epoch": 0.30193014705882354,
      "grad_norm": 1.5721056461334229,
      "learning_rate": 9.994893617021278e-06,
      "loss": 0.3016,
      "step": 1314
    },
    {
      "epoch": 0.30215992647058826,
      "grad_norm": 1.4111595153808594,
      "learning_rate": 9.99404255319149e-06,
      "loss": 0.2793,
      "step": 1315
    },
    {
      "epoch": 0.3023897058823529,
      "grad_norm": 1.5364962816238403,
      "learning_rate": 9.993191489361703e-06,
      "loss": 0.2692,
      "step": 1316
    },
    {
      "epoch": 0.30261948529411764,
      "grad_norm": 1.8473751544952393,
      "learning_rate": 9.992340425531916e-06,
      "loss": 0.3355,
      "step": 1317
    },
    {
      "epoch": 0.30284926470588236,
      "grad_norm": 1.1060395240783691,
      "learning_rate": 9.991489361702127e-06,
      "loss": 0.1844,
      "step": 1318
    },
    {
      "epoch": 0.3030790441176471,
      "grad_norm": 1.3738268613815308,
      "learning_rate": 9.990638297872342e-06,
      "loss": 0.271,
      "step": 1319
    },
    {
      "epoch": 0.30330882352941174,
      "grad_norm": 1.1655961275100708,
      "learning_rate": 9.989787234042554e-06,
      "loss": 0.2188,
      "step": 1320
    },
    {
      "epoch": 0.30353860294117646,
      "grad_norm": 1.3729983568191528,
      "learning_rate": 9.988936170212767e-06,
      "loss": 0.241,
      "step": 1321
    },
    {
      "epoch": 0.3037683823529412,
      "grad_norm": 1.3169606924057007,
      "learning_rate": 9.98808510638298e-06,
      "loss": 0.2347,
      "step": 1322
    },
    {
      "epoch": 0.3039981617647059,
      "grad_norm": 1.1450132131576538,
      "learning_rate": 9.987234042553192e-06,
      "loss": 0.2472,
      "step": 1323
    },
    {
      "epoch": 0.30422794117647056,
      "grad_norm": 1.149972915649414,
      "learning_rate": 9.986382978723405e-06,
      "loss": 0.2794,
      "step": 1324
    },
    {
      "epoch": 0.3044577205882353,
      "grad_norm": 1.2447848320007324,
      "learning_rate": 9.985531914893618e-06,
      "loss": 0.1791,
      "step": 1325
    },
    {
      "epoch": 0.3046875,
      "grad_norm": 1.570346713066101,
      "learning_rate": 9.984680851063831e-06,
      "loss": 0.2536,
      "step": 1326
    },
    {
      "epoch": 0.3049172794117647,
      "grad_norm": 1.2855517864227295,
      "learning_rate": 9.983829787234043e-06,
      "loss": 0.2316,
      "step": 1327
    },
    {
      "epoch": 0.30514705882352944,
      "grad_norm": 1.550584316253662,
      "learning_rate": 9.982978723404256e-06,
      "loss": 0.2848,
      "step": 1328
    },
    {
      "epoch": 0.3053768382352941,
      "grad_norm": 1.27070951461792,
      "learning_rate": 9.982127659574469e-06,
      "loss": 0.232,
      "step": 1329
    },
    {
      "epoch": 0.3056066176470588,
      "grad_norm": 1.369158387184143,
      "learning_rate": 9.981276595744682e-06,
      "loss": 0.2656,
      "step": 1330
    },
    {
      "epoch": 0.30583639705882354,
      "grad_norm": 1.260841727256775,
      "learning_rate": 9.980425531914895e-06,
      "loss": 0.1893,
      "step": 1331
    },
    {
      "epoch": 0.30606617647058826,
      "grad_norm": 1.6218225955963135,
      "learning_rate": 9.979574468085107e-06,
      "loss": 0.3481,
      "step": 1332
    },
    {
      "epoch": 0.3062959558823529,
      "grad_norm": 1.4853342771530151,
      "learning_rate": 9.97872340425532e-06,
      "loss": 0.2626,
      "step": 1333
    },
    {
      "epoch": 0.30652573529411764,
      "grad_norm": 1.3839250802993774,
      "learning_rate": 9.977872340425533e-06,
      "loss": 0.212,
      "step": 1334
    },
    {
      "epoch": 0.30675551470588236,
      "grad_norm": 1.3283438682556152,
      "learning_rate": 9.977021276595745e-06,
      "loss": 0.2423,
      "step": 1335
    },
    {
      "epoch": 0.3069852941176471,
      "grad_norm": 1.4030648469924927,
      "learning_rate": 9.97617021276596e-06,
      "loss": 0.2733,
      "step": 1336
    },
    {
      "epoch": 0.30721507352941174,
      "grad_norm": 1.24470055103302,
      "learning_rate": 9.975319148936171e-06,
      "loss": 0.1899,
      "step": 1337
    },
    {
      "epoch": 0.30744485294117646,
      "grad_norm": 1.345246434211731,
      "learning_rate": 9.974468085106384e-06,
      "loss": 0.215,
      "step": 1338
    },
    {
      "epoch": 0.3076746323529412,
      "grad_norm": 1.0956623554229736,
      "learning_rate": 9.973617021276597e-06,
      "loss": 0.2385,
      "step": 1339
    },
    {
      "epoch": 0.3079044117647059,
      "grad_norm": 1.7215303182601929,
      "learning_rate": 9.972765957446809e-06,
      "loss": 0.1973,
      "step": 1340
    },
    {
      "epoch": 0.30813419117647056,
      "grad_norm": 1.1547186374664307,
      "learning_rate": 9.971914893617022e-06,
      "loss": 0.2076,
      "step": 1341
    },
    {
      "epoch": 0.3083639705882353,
      "grad_norm": 1.3108071088790894,
      "learning_rate": 9.971063829787235e-06,
      "loss": 0.183,
      "step": 1342
    },
    {
      "epoch": 0.30859375,
      "grad_norm": 1.3187028169631958,
      "learning_rate": 9.970212765957448e-06,
      "loss": 0.2505,
      "step": 1343
    },
    {
      "epoch": 0.3088235294117647,
      "grad_norm": 1.424038290977478,
      "learning_rate": 9.96936170212766e-06,
      "loss": 0.1836,
      "step": 1344
    },
    {
      "epoch": 0.30905330882352944,
      "grad_norm": 1.1792529821395874,
      "learning_rate": 9.968510638297873e-06,
      "loss": 0.2085,
      "step": 1345
    },
    {
      "epoch": 0.3092830882352941,
      "grad_norm": 1.138624668121338,
      "learning_rate": 9.967659574468086e-06,
      "loss": 0.1852,
      "step": 1346
    },
    {
      "epoch": 0.3095128676470588,
      "grad_norm": 1.8439397811889648,
      "learning_rate": 9.966808510638298e-06,
      "loss": 0.2492,
      "step": 1347
    },
    {
      "epoch": 0.30974264705882354,
      "grad_norm": 1.7726209163665771,
      "learning_rate": 9.965957446808512e-06,
      "loss": 0.2501,
      "step": 1348
    },
    {
      "epoch": 0.30997242647058826,
      "grad_norm": 1.3134126663208008,
      "learning_rate": 9.965106382978724e-06,
      "loss": 0.2276,
      "step": 1349
    },
    {
      "epoch": 0.3102022058823529,
      "grad_norm": 1.2660447359085083,
      "learning_rate": 9.964255319148937e-06,
      "loss": 0.22,
      "step": 1350
    },
    {
      "epoch": 0.31043198529411764,
      "grad_norm": 1.2097324132919312,
      "learning_rate": 9.96340425531915e-06,
      "loss": 0.2117,
      "step": 1351
    },
    {
      "epoch": 0.31066176470588236,
      "grad_norm": 1.4034491777420044,
      "learning_rate": 9.962553191489362e-06,
      "loss": 0.1722,
      "step": 1352
    },
    {
      "epoch": 0.3108915441176471,
      "grad_norm": 1.4023921489715576,
      "learning_rate": 9.961702127659575e-06,
      "loss": 0.2468,
      "step": 1353
    },
    {
      "epoch": 0.31112132352941174,
      "grad_norm": 1.1619278192520142,
      "learning_rate": 9.960851063829788e-06,
      "loss": 0.2541,
      "step": 1354
    },
    {
      "epoch": 0.31135110294117646,
      "grad_norm": 1.3242863416671753,
      "learning_rate": 9.960000000000001e-06,
      "loss": 0.2198,
      "step": 1355
    },
    {
      "epoch": 0.3115808823529412,
      "grad_norm": 1.1946603059768677,
      "learning_rate": 9.959148936170213e-06,
      "loss": 0.2683,
      "step": 1356
    },
    {
      "epoch": 0.3118106617647059,
      "grad_norm": 1.2114189863204956,
      "learning_rate": 9.958297872340426e-06,
      "loss": 0.2069,
      "step": 1357
    },
    {
      "epoch": 0.31204044117647056,
      "grad_norm": 1.177646279335022,
      "learning_rate": 9.957446808510639e-06,
      "loss": 0.2169,
      "step": 1358
    },
    {
      "epoch": 0.3122702205882353,
      "grad_norm": 1.628710150718689,
      "learning_rate": 9.956595744680852e-06,
      "loss": 0.2289,
      "step": 1359
    },
    {
      "epoch": 0.3125,
      "grad_norm": 1.4095027446746826,
      "learning_rate": 9.955744680851065e-06,
      "loss": 0.2523,
      "step": 1360
    },
    {
      "epoch": 0.3127297794117647,
      "grad_norm": 1.5766934156417847,
      "learning_rate": 9.954893617021277e-06,
      "loss": 0.2378,
      "step": 1361
    },
    {
      "epoch": 0.31295955882352944,
      "grad_norm": 1.7595126628875732,
      "learning_rate": 9.95404255319149e-06,
      "loss": 0.217,
      "step": 1362
    },
    {
      "epoch": 0.3131893382352941,
      "grad_norm": 1.3550140857696533,
      "learning_rate": 9.953191489361703e-06,
      "loss": 0.1858,
      "step": 1363
    },
    {
      "epoch": 0.3134191176470588,
      "grad_norm": 1.4239710569381714,
      "learning_rate": 9.952340425531916e-06,
      "loss": 0.2447,
      "step": 1364
    },
    {
      "epoch": 0.31364889705882354,
      "grad_norm": 1.4153964519500732,
      "learning_rate": 9.951489361702128e-06,
      "loss": 0.2115,
      "step": 1365
    },
    {
      "epoch": 0.31387867647058826,
      "grad_norm": 1.1141657829284668,
      "learning_rate": 9.950638297872341e-06,
      "loss": 0.1872,
      "step": 1366
    },
    {
      "epoch": 0.3141084558823529,
      "grad_norm": 1.8301109075546265,
      "learning_rate": 9.949787234042554e-06,
      "loss": 0.2203,
      "step": 1367
    },
    {
      "epoch": 0.31433823529411764,
      "grad_norm": 1.4271217584609985,
      "learning_rate": 9.948936170212766e-06,
      "loss": 0.2101,
      "step": 1368
    },
    {
      "epoch": 0.31456801470588236,
      "grad_norm": 1.6868895292282104,
      "learning_rate": 9.94808510638298e-06,
      "loss": 0.2504,
      "step": 1369
    },
    {
      "epoch": 0.3147977941176471,
      "grad_norm": 1.3584191799163818,
      "learning_rate": 9.947234042553192e-06,
      "loss": 0.1832,
      "step": 1370
    },
    {
      "epoch": 0.31502757352941174,
      "grad_norm": 1.232485294342041,
      "learning_rate": 9.946382978723405e-06,
      "loss": 0.2248,
      "step": 1371
    },
    {
      "epoch": 0.31525735294117646,
      "grad_norm": 1.7869075536727905,
      "learning_rate": 9.945531914893618e-06,
      "loss": 0.2948,
      "step": 1372
    },
    {
      "epoch": 0.3154871323529412,
      "grad_norm": 1.2035937309265137,
      "learning_rate": 9.94468085106383e-06,
      "loss": 0.2717,
      "step": 1373
    },
    {
      "epoch": 0.3157169117647059,
      "grad_norm": 1.3335082530975342,
      "learning_rate": 9.943829787234045e-06,
      "loss": 0.2662,
      "step": 1374
    },
    {
      "epoch": 0.31594669117647056,
      "grad_norm": 1.100271224975586,
      "learning_rate": 9.942978723404256e-06,
      "loss": 0.2103,
      "step": 1375
    },
    {
      "epoch": 0.3161764705882353,
      "grad_norm": 1.4029769897460938,
      "learning_rate": 9.94212765957447e-06,
      "loss": 0.2145,
      "step": 1376
    },
    {
      "epoch": 0.31640625,
      "grad_norm": 1.4788285493850708,
      "learning_rate": 9.941276595744682e-06,
      "loss": 0.2194,
      "step": 1377
    },
    {
      "epoch": 0.3166360294117647,
      "grad_norm": 1.4280651807785034,
      "learning_rate": 9.940425531914894e-06,
      "loss": 0.1638,
      "step": 1378
    },
    {
      "epoch": 0.31686580882352944,
      "grad_norm": 1.6209967136383057,
      "learning_rate": 9.939574468085107e-06,
      "loss": 0.2082,
      "step": 1379
    },
    {
      "epoch": 0.3170955882352941,
      "grad_norm": 1.8535585403442383,
      "learning_rate": 9.93872340425532e-06,
      "loss": 0.1814,
      "step": 1380
    },
    {
      "epoch": 0.3173253676470588,
      "grad_norm": 1.7586658000946045,
      "learning_rate": 9.937872340425533e-06,
      "loss": 0.2374,
      "step": 1381
    },
    {
      "epoch": 0.31755514705882354,
      "grad_norm": 1.3757892847061157,
      "learning_rate": 9.937021276595745e-06,
      "loss": 0.1861,
      "step": 1382
    },
    {
      "epoch": 0.31778492647058826,
      "grad_norm": 1.1568018198013306,
      "learning_rate": 9.936170212765958e-06,
      "loss": 0.2455,
      "step": 1383
    },
    {
      "epoch": 0.3180147058823529,
      "grad_norm": 1.5507278442382812,
      "learning_rate": 9.935319148936171e-06,
      "loss": 0.2383,
      "step": 1384
    },
    {
      "epoch": 0.31824448529411764,
      "grad_norm": 1.5288444757461548,
      "learning_rate": 9.934468085106383e-06,
      "loss": 0.2455,
      "step": 1385
    },
    {
      "epoch": 0.31847426470588236,
      "grad_norm": 1.5675275325775146,
      "learning_rate": 9.933617021276598e-06,
      "loss": 0.1872,
      "step": 1386
    },
    {
      "epoch": 0.3187040441176471,
      "grad_norm": 1.5302987098693848,
      "learning_rate": 9.932765957446809e-06,
      "loss": 0.2131,
      "step": 1387
    },
    {
      "epoch": 0.31893382352941174,
      "grad_norm": 1.1031949520111084,
      "learning_rate": 9.931914893617022e-06,
      "loss": 0.1519,
      "step": 1388
    },
    {
      "epoch": 0.31916360294117646,
      "grad_norm": 1.2524454593658447,
      "learning_rate": 9.931063829787235e-06,
      "loss": 0.2288,
      "step": 1389
    },
    {
      "epoch": 0.3193933823529412,
      "grad_norm": 1.7193603515625,
      "learning_rate": 9.930212765957447e-06,
      "loss": 0.2555,
      "step": 1390
    },
    {
      "epoch": 0.3196231617647059,
      "grad_norm": 1.035140872001648,
      "learning_rate": 9.92936170212766e-06,
      "loss": 0.1727,
      "step": 1391
    },
    {
      "epoch": 0.31985294117647056,
      "grad_norm": 1.320469856262207,
      "learning_rate": 9.928510638297873e-06,
      "loss": 0.1716,
      "step": 1392
    },
    {
      "epoch": 0.3200827205882353,
      "grad_norm": 1.3563894033432007,
      "learning_rate": 9.927659574468086e-06,
      "loss": 0.2155,
      "step": 1393
    },
    {
      "epoch": 0.3203125,
      "grad_norm": 1.6502413749694824,
      "learning_rate": 9.926808510638298e-06,
      "loss": 0.2178,
      "step": 1394
    },
    {
      "epoch": 0.3205422794117647,
      "grad_norm": 1.1957350969314575,
      "learning_rate": 9.925957446808511e-06,
      "loss": 0.2013,
      "step": 1395
    },
    {
      "epoch": 0.32077205882352944,
      "grad_norm": 1.4989324808120728,
      "learning_rate": 9.925106382978724e-06,
      "loss": 0.258,
      "step": 1396
    },
    {
      "epoch": 0.3210018382352941,
      "grad_norm": 1.4135050773620605,
      "learning_rate": 9.924255319148937e-06,
      "loss": 0.288,
      "step": 1397
    },
    {
      "epoch": 0.3212316176470588,
      "grad_norm": 1.5066298246383667,
      "learning_rate": 9.92340425531915e-06,
      "loss": 0.244,
      "step": 1398
    },
    {
      "epoch": 0.32146139705882354,
      "grad_norm": 1.3531794548034668,
      "learning_rate": 9.922553191489362e-06,
      "loss": 0.2163,
      "step": 1399
    },
    {
      "epoch": 0.32169117647058826,
      "grad_norm": 1.184613823890686,
      "learning_rate": 9.921702127659575e-06,
      "loss": 0.2541,
      "step": 1400
    },
    {
      "epoch": 0.3219209558823529,
      "grad_norm": 1.1657136678695679,
      "learning_rate": 9.920851063829788e-06,
      "loss": 0.1813,
      "step": 1401
    },
    {
      "epoch": 0.32215073529411764,
      "grad_norm": 1.2645858526229858,
      "learning_rate": 9.920000000000002e-06,
      "loss": 0.1814,
      "step": 1402
    },
    {
      "epoch": 0.32238051470588236,
      "grad_norm": 1.3038661479949951,
      "learning_rate": 9.919148936170213e-06,
      "loss": 0.2024,
      "step": 1403
    },
    {
      "epoch": 0.3226102941176471,
      "grad_norm": 1.388106346130371,
      "learning_rate": 9.918297872340426e-06,
      "loss": 0.2486,
      "step": 1404
    },
    {
      "epoch": 0.32284007352941174,
      "grad_norm": 1.2537505626678467,
      "learning_rate": 9.91744680851064e-06,
      "loss": 0.2132,
      "step": 1405
    },
    {
      "epoch": 0.32306985294117646,
      "grad_norm": 1.6690477132797241,
      "learning_rate": 9.916595744680851e-06,
      "loss": 0.1806,
      "step": 1406
    },
    {
      "epoch": 0.3232996323529412,
      "grad_norm": 1.3776965141296387,
      "learning_rate": 9.915744680851066e-06,
      "loss": 0.1979,
      "step": 1407
    },
    {
      "epoch": 0.3235294117647059,
      "grad_norm": 1.243537187576294,
      "learning_rate": 9.914893617021277e-06,
      "loss": 0.1872,
      "step": 1408
    },
    {
      "epoch": 0.32375919117647056,
      "grad_norm": 1.3416563272476196,
      "learning_rate": 9.91404255319149e-06,
      "loss": 0.246,
      "step": 1409
    },
    {
      "epoch": 0.3239889705882353,
      "grad_norm": 1.3660495281219482,
      "learning_rate": 9.913191489361704e-06,
      "loss": 0.1979,
      "step": 1410
    },
    {
      "epoch": 0.32421875,
      "grad_norm": 1.5869977474212646,
      "learning_rate": 9.912340425531915e-06,
      "loss": 0.2366,
      "step": 1411
    },
    {
      "epoch": 0.3244485294117647,
      "grad_norm": 1.1986597776412964,
      "learning_rate": 9.911489361702128e-06,
      "loss": 0.2182,
      "step": 1412
    },
    {
      "epoch": 0.32467830882352944,
      "grad_norm": 1.3260352611541748,
      "learning_rate": 9.910638297872341e-06,
      "loss": 0.2162,
      "step": 1413
    },
    {
      "epoch": 0.3249080882352941,
      "grad_norm": 1.5083884000778198,
      "learning_rate": 9.909787234042555e-06,
      "loss": 0.214,
      "step": 1414
    },
    {
      "epoch": 0.3251378676470588,
      "grad_norm": 1.3414585590362549,
      "learning_rate": 9.908936170212766e-06,
      "loss": 0.2183,
      "step": 1415
    },
    {
      "epoch": 0.32536764705882354,
      "grad_norm": 1.5905189514160156,
      "learning_rate": 9.90808510638298e-06,
      "loss": 0.2571,
      "step": 1416
    },
    {
      "epoch": 0.32559742647058826,
      "grad_norm": 1.1554161310195923,
      "learning_rate": 9.907234042553192e-06,
      "loss": 0.1812,
      "step": 1417
    },
    {
      "epoch": 0.3258272058823529,
      "grad_norm": 1.6784592866897583,
      "learning_rate": 9.906382978723406e-06,
      "loss": 0.2761,
      "step": 1418
    },
    {
      "epoch": 0.32605698529411764,
      "grad_norm": 1.88096284866333,
      "learning_rate": 9.905531914893619e-06,
      "loss": 0.2108,
      "step": 1419
    },
    {
      "epoch": 0.32628676470588236,
      "grad_norm": 1.274265170097351,
      "learning_rate": 9.90468085106383e-06,
      "loss": 0.1472,
      "step": 1420
    },
    {
      "epoch": 0.3265165441176471,
      "grad_norm": 1.7054944038391113,
      "learning_rate": 9.903829787234043e-06,
      "loss": 0.2742,
      "step": 1421
    },
    {
      "epoch": 0.32674632352941174,
      "grad_norm": 1.4847451448440552,
      "learning_rate": 9.902978723404257e-06,
      "loss": 0.2166,
      "step": 1422
    },
    {
      "epoch": 0.32697610294117646,
      "grad_norm": 1.0416028499603271,
      "learning_rate": 9.902127659574468e-06,
      "loss": 0.1739,
      "step": 1423
    },
    {
      "epoch": 0.3272058823529412,
      "grad_norm": 0.9833228588104248,
      "learning_rate": 9.901276595744683e-06,
      "loss": 0.1923,
      "step": 1424
    },
    {
      "epoch": 0.3274356617647059,
      "grad_norm": 1.294607400894165,
      "learning_rate": 9.900425531914894e-06,
      "loss": 0.2138,
      "step": 1425
    },
    {
      "epoch": 0.32766544117647056,
      "grad_norm": 1.6985543966293335,
      "learning_rate": 9.899574468085108e-06,
      "loss": 0.2725,
      "step": 1426
    },
    {
      "epoch": 0.3278952205882353,
      "grad_norm": 1.1190770864486694,
      "learning_rate": 9.89872340425532e-06,
      "loss": 0.2023,
      "step": 1427
    },
    {
      "epoch": 0.328125,
      "grad_norm": 1.5497448444366455,
      "learning_rate": 9.897872340425532e-06,
      "loss": 0.2894,
      "step": 1428
    },
    {
      "epoch": 0.3283547794117647,
      "grad_norm": 1.5681424140930176,
      "learning_rate": 9.897021276595745e-06,
      "loss": 0.2146,
      "step": 1429
    },
    {
      "epoch": 0.32858455882352944,
      "grad_norm": 1.2318392992019653,
      "learning_rate": 9.896170212765959e-06,
      "loss": 0.1375,
      "step": 1430
    },
    {
      "epoch": 0.3288143382352941,
      "grad_norm": 1.4399226903915405,
      "learning_rate": 9.895319148936172e-06,
      "loss": 0.2382,
      "step": 1431
    },
    {
      "epoch": 0.3290441176470588,
      "grad_norm": 1.5923911333084106,
      "learning_rate": 9.894468085106383e-06,
      "loss": 0.2169,
      "step": 1432
    },
    {
      "epoch": 0.32927389705882354,
      "grad_norm": 1.3728084564208984,
      "learning_rate": 9.893617021276596e-06,
      "loss": 0.2146,
      "step": 1433
    },
    {
      "epoch": 0.32950367647058826,
      "grad_norm": 1.1365526914596558,
      "learning_rate": 9.89276595744681e-06,
      "loss": 0.2068,
      "step": 1434
    },
    {
      "epoch": 0.3297334558823529,
      "grad_norm": 0.9948644638061523,
      "learning_rate": 9.891914893617021e-06,
      "loss": 0.1989,
      "step": 1435
    },
    {
      "epoch": 0.32996323529411764,
      "grad_norm": 1.5732189416885376,
      "learning_rate": 9.891063829787236e-06,
      "loss": 0.2608,
      "step": 1436
    },
    {
      "epoch": 0.33019301470588236,
      "grad_norm": 1.2102103233337402,
      "learning_rate": 9.890212765957447e-06,
      "loss": 0.1551,
      "step": 1437
    },
    {
      "epoch": 0.3304227941176471,
      "grad_norm": 1.7534749507904053,
      "learning_rate": 9.88936170212766e-06,
      "loss": 0.2272,
      "step": 1438
    },
    {
      "epoch": 0.33065257352941174,
      "grad_norm": 1.2424213886260986,
      "learning_rate": 9.888510638297874e-06,
      "loss": 0.1998,
      "step": 1439
    },
    {
      "epoch": 0.33088235294117646,
      "grad_norm": 1.209900975227356,
      "learning_rate": 9.887659574468085e-06,
      "loss": 0.1935,
      "step": 1440
    },
    {
      "epoch": 0.3311121323529412,
      "grad_norm": 1.5578763484954834,
      "learning_rate": 9.886808510638298e-06,
      "loss": 0.2977,
      "step": 1441
    },
    {
      "epoch": 0.3313419117647059,
      "grad_norm": 1.4303709268569946,
      "learning_rate": 9.885957446808511e-06,
      "loss": 0.2551,
      "step": 1442
    },
    {
      "epoch": 0.33157169117647056,
      "grad_norm": 1.4168634414672852,
      "learning_rate": 9.885106382978725e-06,
      "loss": 0.2207,
      "step": 1443
    },
    {
      "epoch": 0.3318014705882353,
      "grad_norm": 1.2085658311843872,
      "learning_rate": 9.884255319148936e-06,
      "loss": 0.1803,
      "step": 1444
    },
    {
      "epoch": 0.33203125,
      "grad_norm": 1.219443917274475,
      "learning_rate": 9.88340425531915e-06,
      "loss": 0.1462,
      "step": 1445
    },
    {
      "epoch": 0.3322610294117647,
      "grad_norm": 1.5461113452911377,
      "learning_rate": 9.882553191489362e-06,
      "loss": 0.1975,
      "step": 1446
    },
    {
      "epoch": 0.33249080882352944,
      "grad_norm": 1.2158710956573486,
      "learning_rate": 9.881702127659576e-06,
      "loss": 0.2302,
      "step": 1447
    },
    {
      "epoch": 0.3327205882352941,
      "grad_norm": 1.3370691537857056,
      "learning_rate": 9.880851063829789e-06,
      "loss": 0.2065,
      "step": 1448
    },
    {
      "epoch": 0.3329503676470588,
      "grad_norm": 1.1554230451583862,
      "learning_rate": 9.88e-06,
      "loss": 0.2175,
      "step": 1449
    },
    {
      "epoch": 0.33318014705882354,
      "grad_norm": 1.249038577079773,
      "learning_rate": 9.879148936170213e-06,
      "loss": 0.1982,
      "step": 1450
    },
    {
      "epoch": 0.33340992647058826,
      "grad_norm": 1.300068736076355,
      "learning_rate": 9.878297872340427e-06,
      "loss": 0.2264,
      "step": 1451
    },
    {
      "epoch": 0.3336397058823529,
      "grad_norm": 1.4325755834579468,
      "learning_rate": 9.87744680851064e-06,
      "loss": 0.2735,
      "step": 1452
    },
    {
      "epoch": 0.33386948529411764,
      "grad_norm": 1.1884721517562866,
      "learning_rate": 9.876595744680851e-06,
      "loss": 0.2457,
      "step": 1453
    },
    {
      "epoch": 0.33409926470588236,
      "grad_norm": 1.27823007106781,
      "learning_rate": 9.875744680851064e-06,
      "loss": 0.2201,
      "step": 1454
    },
    {
      "epoch": 0.3343290441176471,
      "grad_norm": 1.3802682161331177,
      "learning_rate": 9.874893617021278e-06,
      "loss": 0.2263,
      "step": 1455
    },
    {
      "epoch": 0.33455882352941174,
      "grad_norm": 1.735367774963379,
      "learning_rate": 9.874042553191489e-06,
      "loss": 0.2392,
      "step": 1456
    },
    {
      "epoch": 0.33478860294117646,
      "grad_norm": 1.034775972366333,
      "learning_rate": 9.873191489361704e-06,
      "loss": 0.1597,
      "step": 1457
    },
    {
      "epoch": 0.3350183823529412,
      "grad_norm": 1.2333800792694092,
      "learning_rate": 9.872340425531915e-06,
      "loss": 0.2122,
      "step": 1458
    },
    {
      "epoch": 0.3352481617647059,
      "grad_norm": 1.3531335592269897,
      "learning_rate": 9.871489361702129e-06,
      "loss": 0.2089,
      "step": 1459
    },
    {
      "epoch": 0.33547794117647056,
      "grad_norm": 1.7124980688095093,
      "learning_rate": 9.870638297872342e-06,
      "loss": 0.2029,
      "step": 1460
    },
    {
      "epoch": 0.3357077205882353,
      "grad_norm": 1.1527395248413086,
      "learning_rate": 9.869787234042553e-06,
      "loss": 0.2029,
      "step": 1461
    },
    {
      "epoch": 0.3359375,
      "grad_norm": 1.0311239957809448,
      "learning_rate": 9.868936170212768e-06,
      "loss": 0.1839,
      "step": 1462
    },
    {
      "epoch": 0.3361672794117647,
      "grad_norm": 1.3777117729187012,
      "learning_rate": 9.86808510638298e-06,
      "loss": 0.2222,
      "step": 1463
    },
    {
      "epoch": 0.33639705882352944,
      "grad_norm": 1.190253496170044,
      "learning_rate": 9.867234042553193e-06,
      "loss": 0.2402,
      "step": 1464
    },
    {
      "epoch": 0.3366268382352941,
      "grad_norm": 1.2841472625732422,
      "learning_rate": 9.866382978723406e-06,
      "loss": 0.1896,
      "step": 1465
    },
    {
      "epoch": 0.3368566176470588,
      "grad_norm": 1.3477972745895386,
      "learning_rate": 9.865531914893617e-06,
      "loss": 0.2248,
      "step": 1466
    },
    {
      "epoch": 0.33708639705882354,
      "grad_norm": 1.1774983406066895,
      "learning_rate": 9.86468085106383e-06,
      "loss": 0.2541,
      "step": 1467
    },
    {
      "epoch": 0.33731617647058826,
      "grad_norm": 0.9584966897964478,
      "learning_rate": 9.863829787234044e-06,
      "loss": 0.144,
      "step": 1468
    },
    {
      "epoch": 0.3375459558823529,
      "grad_norm": 1.39091956615448,
      "learning_rate": 9.862978723404257e-06,
      "loss": 0.2182,
      "step": 1469
    },
    {
      "epoch": 0.33777573529411764,
      "grad_norm": 1.2677332162857056,
      "learning_rate": 9.862127659574468e-06,
      "loss": 0.2164,
      "step": 1470
    },
    {
      "epoch": 0.33800551470588236,
      "grad_norm": 1.1409105062484741,
      "learning_rate": 9.861276595744682e-06,
      "loss": 0.1591,
      "step": 1471
    },
    {
      "epoch": 0.3382352941176471,
      "grad_norm": 2.0637574195861816,
      "learning_rate": 9.860425531914895e-06,
      "loss": 0.2455,
      "step": 1472
    },
    {
      "epoch": 0.33846507352941174,
      "grad_norm": 1.384589433670044,
      "learning_rate": 9.859574468085106e-06,
      "loss": 0.2216,
      "step": 1473
    },
    {
      "epoch": 0.33869485294117646,
      "grad_norm": 1.4876846075057983,
      "learning_rate": 9.858723404255321e-06,
      "loss": 0.1686,
      "step": 1474
    },
    {
      "epoch": 0.3389246323529412,
      "grad_norm": 1.1070101261138916,
      "learning_rate": 9.857872340425533e-06,
      "loss": 0.1943,
      "step": 1475
    },
    {
      "epoch": 0.3391544117647059,
      "grad_norm": 1.375568151473999,
      "learning_rate": 9.857021276595746e-06,
      "loss": 0.2664,
      "step": 1476
    },
    {
      "epoch": 0.33938419117647056,
      "grad_norm": 1.405241847038269,
      "learning_rate": 9.856170212765959e-06,
      "loss": 0.2318,
      "step": 1477
    },
    {
      "epoch": 0.3396139705882353,
      "grad_norm": 1.112542748451233,
      "learning_rate": 9.85531914893617e-06,
      "loss": 0.2083,
      "step": 1478
    },
    {
      "epoch": 0.33984375,
      "grad_norm": 1.3796749114990234,
      "learning_rate": 9.854468085106384e-06,
      "loss": 0.2012,
      "step": 1479
    },
    {
      "epoch": 0.3400735294117647,
      "grad_norm": 1.333962082862854,
      "learning_rate": 9.853617021276597e-06,
      "loss": 0.1915,
      "step": 1480
    },
    {
      "epoch": 0.34030330882352944,
      "grad_norm": 1.2165967226028442,
      "learning_rate": 9.85276595744681e-06,
      "loss": 0.1813,
      "step": 1481
    },
    {
      "epoch": 0.3405330882352941,
      "grad_norm": 1.539914608001709,
      "learning_rate": 9.851914893617021e-06,
      "loss": 0.2378,
      "step": 1482
    },
    {
      "epoch": 0.3407628676470588,
      "grad_norm": 1.3304890394210815,
      "learning_rate": 9.851063829787235e-06,
      "loss": 0.1695,
      "step": 1483
    },
    {
      "epoch": 0.34099264705882354,
      "grad_norm": 1.2446542978286743,
      "learning_rate": 9.850212765957448e-06,
      "loss": 0.2257,
      "step": 1484
    },
    {
      "epoch": 0.34122242647058826,
      "grad_norm": 1.1800775527954102,
      "learning_rate": 9.84936170212766e-06,
      "loss": 0.1945,
      "step": 1485
    },
    {
      "epoch": 0.3414522058823529,
      "grad_norm": 1.1057487726211548,
      "learning_rate": 9.848510638297874e-06,
      "loss": 0.1721,
      "step": 1486
    },
    {
      "epoch": 0.34168198529411764,
      "grad_norm": 1.1917861700057983,
      "learning_rate": 9.847659574468086e-06,
      "loss": 0.1831,
      "step": 1487
    },
    {
      "epoch": 0.34191176470588236,
      "grad_norm": 1.0479222536087036,
      "learning_rate": 9.846808510638299e-06,
      "loss": 0.1805,
      "step": 1488
    },
    {
      "epoch": 0.3421415441176471,
      "grad_norm": 1.1328932046890259,
      "learning_rate": 9.845957446808512e-06,
      "loss": 0.2045,
      "step": 1489
    },
    {
      "epoch": 0.34237132352941174,
      "grad_norm": 1.482078194618225,
      "learning_rate": 9.845106382978723e-06,
      "loss": 0.1861,
      "step": 1490
    },
    {
      "epoch": 0.34260110294117646,
      "grad_norm": 1.4645017385482788,
      "learning_rate": 9.844255319148936e-06,
      "loss": 0.2282,
      "step": 1491
    },
    {
      "epoch": 0.3428308823529412,
      "grad_norm": 1.2416808605194092,
      "learning_rate": 9.84340425531915e-06,
      "loss": 0.2057,
      "step": 1492
    },
    {
      "epoch": 0.3430606617647059,
      "grad_norm": 1.5285316705703735,
      "learning_rate": 9.842553191489363e-06,
      "loss": 0.1825,
      "step": 1493
    },
    {
      "epoch": 0.34329044117647056,
      "grad_norm": 1.3387036323547363,
      "learning_rate": 9.841702127659574e-06,
      "loss": 0.1989,
      "step": 1494
    },
    {
      "epoch": 0.3435202205882353,
      "grad_norm": 1.3066895008087158,
      "learning_rate": 9.840851063829787e-06,
      "loss": 0.1784,
      "step": 1495
    },
    {
      "epoch": 0.34375,
      "grad_norm": 1.1327446699142456,
      "learning_rate": 9.84e-06,
      "loss": 0.1975,
      "step": 1496
    },
    {
      "epoch": 0.3439797794117647,
      "grad_norm": 1.3536397218704224,
      "learning_rate": 9.839148936170214e-06,
      "loss": 0.1673,
      "step": 1497
    },
    {
      "epoch": 0.34420955882352944,
      "grad_norm": 1.480628490447998,
      "learning_rate": 9.838297872340427e-06,
      "loss": 0.2483,
      "step": 1498
    },
    {
      "epoch": 0.3444393382352941,
      "grad_norm": 1.418903112411499,
      "learning_rate": 9.837446808510638e-06,
      "loss": 0.2011,
      "step": 1499
    },
    {
      "epoch": 0.3446691176470588,
      "grad_norm": 1.4940478801727295,
      "learning_rate": 9.836595744680852e-06,
      "loss": 0.2884,
      "step": 1500
    },
    {
      "epoch": 0.3446691176470588,
      "eval_loss": 0.20543619990348816,
      "eval_runtime": 1968.4238,
      "eval_samples_per_second": 4.524,
      "eval_steps_per_second": 2.262,
      "step": 1500
    },
    {
      "epoch": 0.34489889705882354,
      "grad_norm": 1.4396637678146362,
      "learning_rate": 9.835744680851065e-06,
      "loss": 0.2866,
      "step": 1501
    },
    {
      "epoch": 0.34512867647058826,
      "grad_norm": 1.9233434200286865,
      "learning_rate": 9.834893617021278e-06,
      "loss": 0.2379,
      "step": 1502
    },
    {
      "epoch": 0.3453584558823529,
      "grad_norm": 1.5956708192825317,
      "learning_rate": 9.834042553191491e-06,
      "loss": 0.2308,
      "step": 1503
    },
    {
      "epoch": 0.34558823529411764,
      "grad_norm": 1.2380194664001465,
      "learning_rate": 9.833191489361703e-06,
      "loss": 0.2051,
      "step": 1504
    },
    {
      "epoch": 0.34581801470588236,
      "grad_norm": 1.3412604331970215,
      "learning_rate": 9.832340425531916e-06,
      "loss": 0.2032,
      "step": 1505
    },
    {
      "epoch": 0.3460477941176471,
      "grad_norm": 1.2157083749771118,
      "learning_rate": 9.831489361702129e-06,
      "loss": 0.2467,
      "step": 1506
    },
    {
      "epoch": 0.34627757352941174,
      "grad_norm": 1.4197113513946533,
      "learning_rate": 9.830638297872342e-06,
      "loss": 0.2017,
      "step": 1507
    },
    {
      "epoch": 0.34650735294117646,
      "grad_norm": 1.4481674432754517,
      "learning_rate": 9.829787234042554e-06,
      "loss": 0.1996,
      "step": 1508
    },
    {
      "epoch": 0.3467371323529412,
      "grad_norm": 1.1429030895233154,
      "learning_rate": 9.828936170212767e-06,
      "loss": 0.1753,
      "step": 1509
    },
    {
      "epoch": 0.3469669117647059,
      "grad_norm": 1.0657856464385986,
      "learning_rate": 9.82808510638298e-06,
      "loss": 0.1759,
      "step": 1510
    },
    {
      "epoch": 0.34719669117647056,
      "grad_norm": 1.5600138902664185,
      "learning_rate": 9.827234042553191e-06,
      "loss": 0.2338,
      "step": 1511
    },
    {
      "epoch": 0.3474264705882353,
      "grad_norm": 1.2663100957870483,
      "learning_rate": 9.826382978723406e-06,
      "loss": 0.1926,
      "step": 1512
    },
    {
      "epoch": 0.34765625,
      "grad_norm": 1.6092453002929688,
      "learning_rate": 9.825531914893618e-06,
      "loss": 0.1648,
      "step": 1513
    },
    {
      "epoch": 0.3478860294117647,
      "grad_norm": 1.231948733329773,
      "learning_rate": 9.824680851063831e-06,
      "loss": 0.186,
      "step": 1514
    },
    {
      "epoch": 0.34811580882352944,
      "grad_norm": 1.5367058515548706,
      "learning_rate": 9.823829787234044e-06,
      "loss": 0.1946,
      "step": 1515
    },
    {
      "epoch": 0.3483455882352941,
      "grad_norm": 1.3132659196853638,
      "learning_rate": 9.822978723404256e-06,
      "loss": 0.153,
      "step": 1516
    },
    {
      "epoch": 0.3485753676470588,
      "grad_norm": 1.2559361457824707,
      "learning_rate": 9.822127659574469e-06,
      "loss": 0.1973,
      "step": 1517
    },
    {
      "epoch": 0.34880514705882354,
      "grad_norm": 1.1966445446014404,
      "learning_rate": 9.821276595744682e-06,
      "loss": 0.1917,
      "step": 1518
    },
    {
      "epoch": 0.34903492647058826,
      "grad_norm": 1.145084261894226,
      "learning_rate": 9.820425531914895e-06,
      "loss": 0.1837,
      "step": 1519
    },
    {
      "epoch": 0.3492647058823529,
      "grad_norm": 1.4554502964019775,
      "learning_rate": 9.819574468085107e-06,
      "loss": 0.2371,
      "step": 1520
    },
    {
      "epoch": 0.34949448529411764,
      "grad_norm": 1.4291448593139648,
      "learning_rate": 9.81872340425532e-06,
      "loss": 0.1361,
      "step": 1521
    },
    {
      "epoch": 0.34972426470588236,
      "grad_norm": 1.5947948694229126,
      "learning_rate": 9.817872340425533e-06,
      "loss": 0.2181,
      "step": 1522
    },
    {
      "epoch": 0.3499540441176471,
      "grad_norm": 1.2733927965164185,
      "learning_rate": 9.817021276595744e-06,
      "loss": 0.1677,
      "step": 1523
    },
    {
      "epoch": 0.35018382352941174,
      "grad_norm": 1.330145001411438,
      "learning_rate": 9.81617021276596e-06,
      "loss": 0.2479,
      "step": 1524
    },
    {
      "epoch": 0.35041360294117646,
      "grad_norm": 1.39008367061615,
      "learning_rate": 9.81531914893617e-06,
      "loss": 0.1757,
      "step": 1525
    },
    {
      "epoch": 0.3506433823529412,
      "grad_norm": 1.5536468029022217,
      "learning_rate": 9.814468085106384e-06,
      "loss": 0.2119,
      "step": 1526
    },
    {
      "epoch": 0.3508731617647059,
      "grad_norm": 1.330216884613037,
      "learning_rate": 9.813617021276597e-06,
      "loss": 0.2197,
      "step": 1527
    },
    {
      "epoch": 0.35110294117647056,
      "grad_norm": 1.6593691110610962,
      "learning_rate": 9.812765957446809e-06,
      "loss": 0.2315,
      "step": 1528
    },
    {
      "epoch": 0.3513327205882353,
      "grad_norm": 1.879656195640564,
      "learning_rate": 9.811914893617022e-06,
      "loss": 0.247,
      "step": 1529
    },
    {
      "epoch": 0.3515625,
      "grad_norm": 1.4906516075134277,
      "learning_rate": 9.811063829787235e-06,
      "loss": 0.2583,
      "step": 1530
    },
    {
      "epoch": 0.3517922794117647,
      "grad_norm": 1.1845158338546753,
      "learning_rate": 9.810212765957448e-06,
      "loss": 0.2219,
      "step": 1531
    },
    {
      "epoch": 0.35202205882352944,
      "grad_norm": 2.055833578109741,
      "learning_rate": 9.80936170212766e-06,
      "loss": 0.2672,
      "step": 1532
    },
    {
      "epoch": 0.3522518382352941,
      "grad_norm": 0.925191342830658,
      "learning_rate": 9.808510638297873e-06,
      "loss": 0.1341,
      "step": 1533
    },
    {
      "epoch": 0.3524816176470588,
      "grad_norm": 1.786017656326294,
      "learning_rate": 9.807659574468086e-06,
      "loss": 0.2112,
      "step": 1534
    },
    {
      "epoch": 0.35271139705882354,
      "grad_norm": 1.872707724571228,
      "learning_rate": 9.806808510638297e-06,
      "loss": 0.2117,
      "step": 1535
    },
    {
      "epoch": 0.35294117647058826,
      "grad_norm": 1.6417697668075562,
      "learning_rate": 9.805957446808512e-06,
      "loss": 0.25,
      "step": 1536
    },
    {
      "epoch": 0.3531709558823529,
      "grad_norm": 1.1799577474594116,
      "learning_rate": 9.805106382978724e-06,
      "loss": 0.1588,
      "step": 1537
    },
    {
      "epoch": 0.35340073529411764,
      "grad_norm": 1.0234975814819336,
      "learning_rate": 9.804255319148937e-06,
      "loss": 0.1753,
      "step": 1538
    },
    {
      "epoch": 0.35363051470588236,
      "grad_norm": 1.238998532295227,
      "learning_rate": 9.80340425531915e-06,
      "loss": 0.1793,
      "step": 1539
    },
    {
      "epoch": 0.3538602941176471,
      "grad_norm": 1.2677967548370361,
      "learning_rate": 9.802553191489362e-06,
      "loss": 0.1838,
      "step": 1540
    },
    {
      "epoch": 0.35409007352941174,
      "grad_norm": 1.4961124658584595,
      "learning_rate": 9.801702127659575e-06,
      "loss": 0.1927,
      "step": 1541
    },
    {
      "epoch": 0.35431985294117646,
      "grad_norm": 1.1557221412658691,
      "learning_rate": 9.800851063829788e-06,
      "loss": 0.1767,
      "step": 1542
    },
    {
      "epoch": 0.3545496323529412,
      "grad_norm": 0.9265028238296509,
      "learning_rate": 9.800000000000001e-06,
      "loss": 0.1752,
      "step": 1543
    },
    {
      "epoch": 0.3547794117647059,
      "grad_norm": 1.3141388893127441,
      "learning_rate": 9.799148936170214e-06,
      "loss": 0.1801,
      "step": 1544
    },
    {
      "epoch": 0.35500919117647056,
      "grad_norm": 0.9027420878410339,
      "learning_rate": 9.798297872340426e-06,
      "loss": 0.1706,
      "step": 1545
    },
    {
      "epoch": 0.3552389705882353,
      "grad_norm": 1.7436946630477905,
      "learning_rate": 9.797446808510639e-06,
      "loss": 0.2225,
      "step": 1546
    },
    {
      "epoch": 0.35546875,
      "grad_norm": 1.586686372756958,
      "learning_rate": 9.796595744680852e-06,
      "loss": 0.2507,
      "step": 1547
    },
    {
      "epoch": 0.3556985294117647,
      "grad_norm": 1.137550711631775,
      "learning_rate": 9.795744680851065e-06,
      "loss": 0.2173,
      "step": 1548
    },
    {
      "epoch": 0.35592830882352944,
      "grad_norm": 1.432808756828308,
      "learning_rate": 9.794893617021277e-06,
      "loss": 0.2207,
      "step": 1549
    },
    {
      "epoch": 0.3561580882352941,
      "grad_norm": 1.7753251791000366,
      "learning_rate": 9.79404255319149e-06,
      "loss": 0.2264,
      "step": 1550
    },
    {
      "epoch": 0.3563878676470588,
      "grad_norm": 1.5087473392486572,
      "learning_rate": 9.793191489361703e-06,
      "loss": 0.1705,
      "step": 1551
    },
    {
      "epoch": 0.35661764705882354,
      "grad_norm": 1.422875165939331,
      "learning_rate": 9.792340425531916e-06,
      "loss": 0.1874,
      "step": 1552
    },
    {
      "epoch": 0.35684742647058826,
      "grad_norm": 1.2888848781585693,
      "learning_rate": 9.79148936170213e-06,
      "loss": 0.1964,
      "step": 1553
    },
    {
      "epoch": 0.3570772058823529,
      "grad_norm": 1.4988113641738892,
      "learning_rate": 9.79063829787234e-06,
      "loss": 0.2086,
      "step": 1554
    },
    {
      "epoch": 0.35730698529411764,
      "grad_norm": 1.3517625331878662,
      "learning_rate": 9.789787234042554e-06,
      "loss": 0.2204,
      "step": 1555
    },
    {
      "epoch": 0.35753676470588236,
      "grad_norm": 1.3901301622390747,
      "learning_rate": 9.788936170212767e-06,
      "loss": 0.1751,
      "step": 1556
    },
    {
      "epoch": 0.3577665441176471,
      "grad_norm": 1.593668818473816,
      "learning_rate": 9.78808510638298e-06,
      "loss": 0.2103,
      "step": 1557
    },
    {
      "epoch": 0.35799632352941174,
      "grad_norm": 1.5208680629730225,
      "learning_rate": 9.787234042553192e-06,
      "loss": 0.2067,
      "step": 1558
    },
    {
      "epoch": 0.35822610294117646,
      "grad_norm": 1.5509666204452515,
      "learning_rate": 9.786382978723405e-06,
      "loss": 0.236,
      "step": 1559
    },
    {
      "epoch": 0.3584558823529412,
      "grad_norm": 1.2671524286270142,
      "learning_rate": 9.785531914893618e-06,
      "loss": 0.1779,
      "step": 1560
    },
    {
      "epoch": 0.3586856617647059,
      "grad_norm": 1.4012168645858765,
      "learning_rate": 9.78468085106383e-06,
      "loss": 0.1353,
      "step": 1561
    },
    {
      "epoch": 0.35891544117647056,
      "grad_norm": 1.3633604049682617,
      "learning_rate": 9.783829787234045e-06,
      "loss": 0.2415,
      "step": 1562
    },
    {
      "epoch": 0.3591452205882353,
      "grad_norm": 1.1138603687286377,
      "learning_rate": 9.782978723404256e-06,
      "loss": 0.2056,
      "step": 1563
    },
    {
      "epoch": 0.359375,
      "grad_norm": 1.4979841709136963,
      "learning_rate": 9.782127659574469e-06,
      "loss": 0.1539,
      "step": 1564
    },
    {
      "epoch": 0.3596047794117647,
      "grad_norm": 1.3728113174438477,
      "learning_rate": 9.781276595744682e-06,
      "loss": 0.1845,
      "step": 1565
    },
    {
      "epoch": 0.35983455882352944,
      "grad_norm": 1.6267890930175781,
      "learning_rate": 9.780425531914894e-06,
      "loss": 0.2125,
      "step": 1566
    },
    {
      "epoch": 0.3600643382352941,
      "grad_norm": 1.4670628309249878,
      "learning_rate": 9.779574468085107e-06,
      "loss": 0.2047,
      "step": 1567
    },
    {
      "epoch": 0.3602941176470588,
      "grad_norm": 1.372153401374817,
      "learning_rate": 9.77872340425532e-06,
      "loss": 0.2224,
      "step": 1568
    },
    {
      "epoch": 0.36052389705882354,
      "grad_norm": 1.3039121627807617,
      "learning_rate": 9.777872340425533e-06,
      "loss": 0.1976,
      "step": 1569
    },
    {
      "epoch": 0.36075367647058826,
      "grad_norm": 1.245543122291565,
      "learning_rate": 9.777021276595745e-06,
      "loss": 0.2136,
      "step": 1570
    },
    {
      "epoch": 0.3609834558823529,
      "grad_norm": 1.3664577007293701,
      "learning_rate": 9.776170212765958e-06,
      "loss": 0.2247,
      "step": 1571
    },
    {
      "epoch": 0.36121323529411764,
      "grad_norm": 1.743068814277649,
      "learning_rate": 9.775319148936171e-06,
      "loss": 0.224,
      "step": 1572
    },
    {
      "epoch": 0.36144301470588236,
      "grad_norm": 1.567784309387207,
      "learning_rate": 9.774468085106383e-06,
      "loss": 0.2208,
      "step": 1573
    },
    {
      "epoch": 0.3616727941176471,
      "grad_norm": 1.3999526500701904,
      "learning_rate": 9.773617021276597e-06,
      "loss": 0.2055,
      "step": 1574
    },
    {
      "epoch": 0.36190257352941174,
      "grad_norm": 1.270345687866211,
      "learning_rate": 9.772765957446809e-06,
      "loss": 0.2076,
      "step": 1575
    },
    {
      "epoch": 0.36213235294117646,
      "grad_norm": 1.1323951482772827,
      "learning_rate": 9.771914893617022e-06,
      "loss": 0.1696,
      "step": 1576
    },
    {
      "epoch": 0.3623621323529412,
      "grad_norm": 1.5058786869049072,
      "learning_rate": 9.771063829787235e-06,
      "loss": 0.1707,
      "step": 1577
    },
    {
      "epoch": 0.3625919117647059,
      "grad_norm": 1.2417495250701904,
      "learning_rate": 9.770212765957447e-06,
      "loss": 0.1779,
      "step": 1578
    },
    {
      "epoch": 0.36282169117647056,
      "grad_norm": 1.2299730777740479,
      "learning_rate": 9.76936170212766e-06,
      "loss": 0.2031,
      "step": 1579
    },
    {
      "epoch": 0.3630514705882353,
      "grad_norm": 1.1409804821014404,
      "learning_rate": 9.768510638297873e-06,
      "loss": 0.1731,
      "step": 1580
    },
    {
      "epoch": 0.36328125,
      "grad_norm": 1.3277194499969482,
      "learning_rate": 9.767659574468086e-06,
      "loss": 0.1842,
      "step": 1581
    },
    {
      "epoch": 0.3635110294117647,
      "grad_norm": 1.547756314277649,
      "learning_rate": 9.766808510638298e-06,
      "loss": 0.2411,
      "step": 1582
    },
    {
      "epoch": 0.36374080882352944,
      "grad_norm": 1.7257004976272583,
      "learning_rate": 9.765957446808511e-06,
      "loss": 0.2274,
      "step": 1583
    },
    {
      "epoch": 0.3639705882352941,
      "grad_norm": 1.4134304523468018,
      "learning_rate": 9.765106382978724e-06,
      "loss": 0.1934,
      "step": 1584
    },
    {
      "epoch": 0.3642003676470588,
      "grad_norm": 1.4911504983901978,
      "learning_rate": 9.764255319148937e-06,
      "loss": 0.2002,
      "step": 1585
    },
    {
      "epoch": 0.36443014705882354,
      "grad_norm": 1.6868094205856323,
      "learning_rate": 9.76340425531915e-06,
      "loss": 0.2335,
      "step": 1586
    },
    {
      "epoch": 0.36465992647058826,
      "grad_norm": 1.2568336725234985,
      "learning_rate": 9.762553191489362e-06,
      "loss": 0.1653,
      "step": 1587
    },
    {
      "epoch": 0.3648897058823529,
      "grad_norm": 1.2366315126419067,
      "learning_rate": 9.761702127659575e-06,
      "loss": 0.1485,
      "step": 1588
    },
    {
      "epoch": 0.36511948529411764,
      "grad_norm": 1.4216312170028687,
      "learning_rate": 9.760851063829788e-06,
      "loss": 0.188,
      "step": 1589
    },
    {
      "epoch": 0.36534926470588236,
      "grad_norm": 1.2283635139465332,
      "learning_rate": 9.760000000000001e-06,
      "loss": 0.193,
      "step": 1590
    },
    {
      "epoch": 0.3655790441176471,
      "grad_norm": 1.4121520519256592,
      "learning_rate": 9.759148936170215e-06,
      "loss": 0.1644,
      "step": 1591
    },
    {
      "epoch": 0.36580882352941174,
      "grad_norm": 1.324029564857483,
      "learning_rate": 9.758297872340426e-06,
      "loss": 0.2021,
      "step": 1592
    },
    {
      "epoch": 0.36603860294117646,
      "grad_norm": 1.233254075050354,
      "learning_rate": 9.75744680851064e-06,
      "loss": 0.1894,
      "step": 1593
    },
    {
      "epoch": 0.3662683823529412,
      "grad_norm": 1.3496859073638916,
      "learning_rate": 9.756595744680852e-06,
      "loss": 0.1773,
      "step": 1594
    },
    {
      "epoch": 0.3664981617647059,
      "grad_norm": 1.1691691875457764,
      "learning_rate": 9.755744680851066e-06,
      "loss": 0.2349,
      "step": 1595
    },
    {
      "epoch": 0.36672794117647056,
      "grad_norm": 1.3509639501571655,
      "learning_rate": 9.754893617021277e-06,
      "loss": 0.15,
      "step": 1596
    },
    {
      "epoch": 0.3669577205882353,
      "grad_norm": 1.2982816696166992,
      "learning_rate": 9.75404255319149e-06,
      "loss": 0.2373,
      "step": 1597
    },
    {
      "epoch": 0.3671875,
      "grad_norm": 1.2009773254394531,
      "learning_rate": 9.753191489361703e-06,
      "loss": 0.1182,
      "step": 1598
    },
    {
      "epoch": 0.3674172794117647,
      "grad_norm": 1.4083404541015625,
      "learning_rate": 9.752340425531915e-06,
      "loss": 0.223,
      "step": 1599
    },
    {
      "epoch": 0.36764705882352944,
      "grad_norm": 1.0072975158691406,
      "learning_rate": 9.75148936170213e-06,
      "loss": 0.1551,
      "step": 1600
    },
    {
      "epoch": 0.3678768382352941,
      "grad_norm": 1.5684678554534912,
      "learning_rate": 9.750638297872341e-06,
      "loss": 0.2232,
      "step": 1601
    },
    {
      "epoch": 0.3681066176470588,
      "grad_norm": 1.2463831901550293,
      "learning_rate": 9.749787234042554e-06,
      "loss": 0.1983,
      "step": 1602
    },
    {
      "epoch": 0.36833639705882354,
      "grad_norm": 1.2308505773544312,
      "learning_rate": 9.748936170212768e-06,
      "loss": 0.2155,
      "step": 1603
    },
    {
      "epoch": 0.36856617647058826,
      "grad_norm": 1.0941522121429443,
      "learning_rate": 9.748085106382979e-06,
      "loss": 0.1689,
      "step": 1604
    },
    {
      "epoch": 0.3687959558823529,
      "grad_norm": 1.222224235534668,
      "learning_rate": 9.747234042553192e-06,
      "loss": 0.2357,
      "step": 1605
    },
    {
      "epoch": 0.36902573529411764,
      "grad_norm": 1.3274457454681396,
      "learning_rate": 9.746382978723405e-06,
      "loss": 0.1892,
      "step": 1606
    },
    {
      "epoch": 0.36925551470588236,
      "grad_norm": 1.3282153606414795,
      "learning_rate": 9.745531914893619e-06,
      "loss": 0.1832,
      "step": 1607
    },
    {
      "epoch": 0.3694852941176471,
      "grad_norm": 1.4708620309829712,
      "learning_rate": 9.74468085106383e-06,
      "loss": 0.1927,
      "step": 1608
    },
    {
      "epoch": 0.36971507352941174,
      "grad_norm": 1.6315897703170776,
      "learning_rate": 9.743829787234043e-06,
      "loss": 0.1931,
      "step": 1609
    },
    {
      "epoch": 0.36994485294117646,
      "grad_norm": 1.2799698114395142,
      "learning_rate": 9.742978723404256e-06,
      "loss": 0.1959,
      "step": 1610
    },
    {
      "epoch": 0.3701746323529412,
      "grad_norm": 1.198105812072754,
      "learning_rate": 9.742127659574468e-06,
      "loss": 0.1405,
      "step": 1611
    },
    {
      "epoch": 0.3704044117647059,
      "grad_norm": 1.494477391242981,
      "learning_rate": 9.741276595744683e-06,
      "loss": 0.2279,
      "step": 1612
    },
    {
      "epoch": 0.37063419117647056,
      "grad_norm": 1.2672796249389648,
      "learning_rate": 9.740425531914894e-06,
      "loss": 0.1908,
      "step": 1613
    },
    {
      "epoch": 0.3708639705882353,
      "grad_norm": 1.9197254180908203,
      "learning_rate": 9.739574468085107e-06,
      "loss": 0.2535,
      "step": 1614
    },
    {
      "epoch": 0.37109375,
      "grad_norm": 2.0051159858703613,
      "learning_rate": 9.73872340425532e-06,
      "loss": 0.1953,
      "step": 1615
    },
    {
      "epoch": 0.3713235294117647,
      "grad_norm": 1.8087129592895508,
      "learning_rate": 9.737872340425532e-06,
      "loss": 0.2298,
      "step": 1616
    },
    {
      "epoch": 0.37155330882352944,
      "grad_norm": 1.396601915359497,
      "learning_rate": 9.737021276595745e-06,
      "loss": 0.1671,
      "step": 1617
    },
    {
      "epoch": 0.3717830882352941,
      "grad_norm": 1.4699583053588867,
      "learning_rate": 9.736170212765958e-06,
      "loss": 0.2353,
      "step": 1618
    },
    {
      "epoch": 0.3720128676470588,
      "grad_norm": 1.190794825553894,
      "learning_rate": 9.735319148936172e-06,
      "loss": 0.2679,
      "step": 1619
    },
    {
      "epoch": 0.37224264705882354,
      "grad_norm": 1.150253415107727,
      "learning_rate": 9.734468085106383e-06,
      "loss": 0.1357,
      "step": 1620
    },
    {
      "epoch": 0.37247242647058826,
      "grad_norm": 1.4456305503845215,
      "learning_rate": 9.733617021276596e-06,
      "loss": 0.2416,
      "step": 1621
    },
    {
      "epoch": 0.3727022058823529,
      "grad_norm": 1.2288199663162231,
      "learning_rate": 9.73276595744681e-06,
      "loss": 0.1927,
      "step": 1622
    },
    {
      "epoch": 0.37293198529411764,
      "grad_norm": 1.4530220031738281,
      "learning_rate": 9.73191489361702e-06,
      "loss": 0.2406,
      "step": 1623
    },
    {
      "epoch": 0.37316176470588236,
      "grad_norm": 1.642755389213562,
      "learning_rate": 9.731063829787236e-06,
      "loss": 0.2279,
      "step": 1624
    },
    {
      "epoch": 0.3733915441176471,
      "grad_norm": 1.3790431022644043,
      "learning_rate": 9.730212765957447e-06,
      "loss": 0.1829,
      "step": 1625
    },
    {
      "epoch": 0.37362132352941174,
      "grad_norm": 1.3656045198440552,
      "learning_rate": 9.72936170212766e-06,
      "loss": 0.1835,
      "step": 1626
    },
    {
      "epoch": 0.37385110294117646,
      "grad_norm": 1.1450275182724,
      "learning_rate": 9.728510638297873e-06,
      "loss": 0.1383,
      "step": 1627
    },
    {
      "epoch": 0.3740808823529412,
      "grad_norm": 1.3497159481048584,
      "learning_rate": 9.727659574468085e-06,
      "loss": 0.1651,
      "step": 1628
    },
    {
      "epoch": 0.3743106617647059,
      "grad_norm": 1.342530369758606,
      "learning_rate": 9.726808510638298e-06,
      "loss": 0.2043,
      "step": 1629
    },
    {
      "epoch": 0.37454044117647056,
      "grad_norm": 1.1891292333602905,
      "learning_rate": 9.725957446808511e-06,
      "loss": 0.1847,
      "step": 1630
    },
    {
      "epoch": 0.3747702205882353,
      "grad_norm": 1.3735123872756958,
      "learning_rate": 9.725106382978724e-06,
      "loss": 0.1747,
      "step": 1631
    },
    {
      "epoch": 0.375,
      "grad_norm": 1.36379873752594,
      "learning_rate": 9.724255319148938e-06,
      "loss": 0.1864,
      "step": 1632
    },
    {
      "epoch": 0.3752297794117647,
      "grad_norm": 1.5380524396896362,
      "learning_rate": 9.723404255319149e-06,
      "loss": 0.234,
      "step": 1633
    },
    {
      "epoch": 0.37545955882352944,
      "grad_norm": 1.5046148300170898,
      "learning_rate": 9.722553191489362e-06,
      "loss": 0.1953,
      "step": 1634
    },
    {
      "epoch": 0.3756893382352941,
      "grad_norm": 1.268071174621582,
      "learning_rate": 9.721702127659575e-06,
      "loss": 0.2258,
      "step": 1635
    },
    {
      "epoch": 0.3759191176470588,
      "grad_norm": 1.4079618453979492,
      "learning_rate": 9.720851063829789e-06,
      "loss": 0.1524,
      "step": 1636
    },
    {
      "epoch": 0.37614889705882354,
      "grad_norm": 1.275875210762024,
      "learning_rate": 9.72e-06,
      "loss": 0.1331,
      "step": 1637
    },
    {
      "epoch": 0.37637867647058826,
      "grad_norm": 1.7226020097732544,
      "learning_rate": 9.719148936170213e-06,
      "loss": 0.2011,
      "step": 1638
    },
    {
      "epoch": 0.3766084558823529,
      "grad_norm": 1.0181549787521362,
      "learning_rate": 9.718297872340426e-06,
      "loss": 0.1661,
      "step": 1639
    },
    {
      "epoch": 0.37683823529411764,
      "grad_norm": 1.4097155332565308,
      "learning_rate": 9.71744680851064e-06,
      "loss": 0.1493,
      "step": 1640
    },
    {
      "epoch": 0.37706801470588236,
      "grad_norm": 1.2814987897872925,
      "learning_rate": 9.716595744680853e-06,
      "loss": 0.148,
      "step": 1641
    },
    {
      "epoch": 0.3772977941176471,
      "grad_norm": 1.207337737083435,
      "learning_rate": 9.715744680851064e-06,
      "loss": 0.1749,
      "step": 1642
    },
    {
      "epoch": 0.37752757352941174,
      "grad_norm": 1.3394750356674194,
      "learning_rate": 9.714893617021277e-06,
      "loss": 0.1672,
      "step": 1643
    },
    {
      "epoch": 0.37775735294117646,
      "grad_norm": 1.1138336658477783,
      "learning_rate": 9.71404255319149e-06,
      "loss": 0.1641,
      "step": 1644
    },
    {
      "epoch": 0.3779871323529412,
      "grad_norm": 1.369629979133606,
      "learning_rate": 9.713191489361704e-06,
      "loss": 0.2022,
      "step": 1645
    },
    {
      "epoch": 0.3782169117647059,
      "grad_norm": 1.1574262380599976,
      "learning_rate": 9.712340425531915e-06,
      "loss": 0.1386,
      "step": 1646
    },
    {
      "epoch": 0.37844669117647056,
      "grad_norm": 1.3293681144714355,
      "learning_rate": 9.711489361702128e-06,
      "loss": 0.1628,
      "step": 1647
    },
    {
      "epoch": 0.3786764705882353,
      "grad_norm": 1.4992330074310303,
      "learning_rate": 9.710638297872342e-06,
      "loss": 0.1908,
      "step": 1648
    },
    {
      "epoch": 0.37890625,
      "grad_norm": 1.3711209297180176,
      "learning_rate": 9.709787234042553e-06,
      "loss": 0.1942,
      "step": 1649
    },
    {
      "epoch": 0.3791360294117647,
      "grad_norm": 1.2461072206497192,
      "learning_rate": 9.708936170212768e-06,
      "loss": 0.1575,
      "step": 1650
    },
    {
      "epoch": 0.37936580882352944,
      "grad_norm": 1.1152938604354858,
      "learning_rate": 9.70808510638298e-06,
      "loss": 0.1583,
      "step": 1651
    },
    {
      "epoch": 0.3795955882352941,
      "grad_norm": 1.1673604249954224,
      "learning_rate": 9.707234042553193e-06,
      "loss": 0.1405,
      "step": 1652
    },
    {
      "epoch": 0.3798253676470588,
      "grad_norm": 1.3020451068878174,
      "learning_rate": 9.706382978723406e-06,
      "loss": 0.2119,
      "step": 1653
    },
    {
      "epoch": 0.38005514705882354,
      "grad_norm": 1.3130396604537964,
      "learning_rate": 9.705531914893617e-06,
      "loss": 0.1803,
      "step": 1654
    },
    {
      "epoch": 0.38028492647058826,
      "grad_norm": 1.1346049308776855,
      "learning_rate": 9.70468085106383e-06,
      "loss": 0.1373,
      "step": 1655
    },
    {
      "epoch": 0.3805147058823529,
      "grad_norm": 1.374651312828064,
      "learning_rate": 9.703829787234044e-06,
      "loss": 0.1694,
      "step": 1656
    },
    {
      "epoch": 0.38074448529411764,
      "grad_norm": 1.4328314065933228,
      "learning_rate": 9.702978723404257e-06,
      "loss": 0.1927,
      "step": 1657
    },
    {
      "epoch": 0.38097426470588236,
      "grad_norm": 1.4400297403335571,
      "learning_rate": 9.702127659574468e-06,
      "loss": 0.2707,
      "step": 1658
    },
    {
      "epoch": 0.3812040441176471,
      "grad_norm": 1.1421573162078857,
      "learning_rate": 9.701276595744681e-06,
      "loss": 0.1654,
      "step": 1659
    },
    {
      "epoch": 0.38143382352941174,
      "grad_norm": 1.6146602630615234,
      "learning_rate": 9.700425531914895e-06,
      "loss": 0.2263,
      "step": 1660
    },
    {
      "epoch": 0.38166360294117646,
      "grad_norm": 1.3121646642684937,
      "learning_rate": 9.699574468085106e-06,
      "loss": 0.1622,
      "step": 1661
    },
    {
      "epoch": 0.3818933823529412,
      "grad_norm": 1.3121051788330078,
      "learning_rate": 9.698723404255321e-06,
      "loss": 0.1823,
      "step": 1662
    },
    {
      "epoch": 0.3821231617647059,
      "grad_norm": 1.3456511497497559,
      "learning_rate": 9.697872340425532e-06,
      "loss": 0.1902,
      "step": 1663
    },
    {
      "epoch": 0.38235294117647056,
      "grad_norm": 1.015725016593933,
      "learning_rate": 9.697021276595746e-06,
      "loss": 0.2276,
      "step": 1664
    },
    {
      "epoch": 0.3825827205882353,
      "grad_norm": 1.2449028491973877,
      "learning_rate": 9.696170212765959e-06,
      "loss": 0.1818,
      "step": 1665
    },
    {
      "epoch": 0.3828125,
      "grad_norm": 1.4114352464675903,
      "learning_rate": 9.69531914893617e-06,
      "loss": 0.1276,
      "step": 1666
    },
    {
      "epoch": 0.3830422794117647,
      "grad_norm": 1.0991283655166626,
      "learning_rate": 9.694468085106383e-06,
      "loss": 0.187,
      "step": 1667
    },
    {
      "epoch": 0.38327205882352944,
      "grad_norm": 1.5306248664855957,
      "learning_rate": 9.693617021276597e-06,
      "loss": 0.1788,
      "step": 1668
    },
    {
      "epoch": 0.3835018382352941,
      "grad_norm": 1.4128508567810059,
      "learning_rate": 9.69276595744681e-06,
      "loss": 0.1858,
      "step": 1669
    },
    {
      "epoch": 0.3837316176470588,
      "grad_norm": 1.3997299671173096,
      "learning_rate": 9.691914893617021e-06,
      "loss": 0.1663,
      "step": 1670
    },
    {
      "epoch": 0.38396139705882354,
      "grad_norm": 0.9081500768661499,
      "learning_rate": 9.691063829787234e-06,
      "loss": 0.1665,
      "step": 1671
    },
    {
      "epoch": 0.38419117647058826,
      "grad_norm": 1.8490688800811768,
      "learning_rate": 9.690212765957448e-06,
      "loss": 0.2236,
      "step": 1672
    },
    {
      "epoch": 0.3844209558823529,
      "grad_norm": 1.4727317094802856,
      "learning_rate": 9.68936170212766e-06,
      "loss": 0.2046,
      "step": 1673
    },
    {
      "epoch": 0.38465073529411764,
      "grad_norm": 1.3884893655776978,
      "learning_rate": 9.688510638297874e-06,
      "loss": 0.1915,
      "step": 1674
    },
    {
      "epoch": 0.38488051470588236,
      "grad_norm": 1.8664703369140625,
      "learning_rate": 9.687659574468085e-06,
      "loss": 0.153,
      "step": 1675
    },
    {
      "epoch": 0.3851102941176471,
      "grad_norm": 1.7009694576263428,
      "learning_rate": 9.686808510638299e-06,
      "loss": 0.1876,
      "step": 1676
    },
    {
      "epoch": 0.38534007352941174,
      "grad_norm": 1.3593051433563232,
      "learning_rate": 9.685957446808512e-06,
      "loss": 0.176,
      "step": 1677
    },
    {
      "epoch": 0.38556985294117646,
      "grad_norm": 1.4199293851852417,
      "learning_rate": 9.685106382978723e-06,
      "loss": 0.1459,
      "step": 1678
    },
    {
      "epoch": 0.3857996323529412,
      "grad_norm": 1.8411823511123657,
      "learning_rate": 9.684255319148938e-06,
      "loss": 0.2942,
      "step": 1679
    },
    {
      "epoch": 0.3860294117647059,
      "grad_norm": 1.4443689584732056,
      "learning_rate": 9.68340425531915e-06,
      "loss": 0.1361,
      "step": 1680
    },
    {
      "epoch": 0.38625919117647056,
      "grad_norm": 1.853498935699463,
      "learning_rate": 9.682553191489363e-06,
      "loss": 0.2385,
      "step": 1681
    },
    {
      "epoch": 0.3864889705882353,
      "grad_norm": 1.7318636178970337,
      "learning_rate": 9.681702127659576e-06,
      "loss": 0.1903,
      "step": 1682
    },
    {
      "epoch": 0.38671875,
      "grad_norm": 1.3368785381317139,
      "learning_rate": 9.680851063829787e-06,
      "loss": 0.1951,
      "step": 1683
    },
    {
      "epoch": 0.3869485294117647,
      "grad_norm": 1.1956348419189453,
      "learning_rate": 9.68e-06,
      "loss": 0.1988,
      "step": 1684
    },
    {
      "epoch": 0.38717830882352944,
      "grad_norm": 1.0627059936523438,
      "learning_rate": 9.679148936170214e-06,
      "loss": 0.1922,
      "step": 1685
    },
    {
      "epoch": 0.3874080882352941,
      "grad_norm": 1.1385350227355957,
      "learning_rate": 9.678297872340427e-06,
      "loss": 0.2103,
      "step": 1686
    },
    {
      "epoch": 0.3876378676470588,
      "grad_norm": 1.0393718481063843,
      "learning_rate": 9.677446808510638e-06,
      "loss": 0.1574,
      "step": 1687
    },
    {
      "epoch": 0.38786764705882354,
      "grad_norm": 1.2997572422027588,
      "learning_rate": 9.676595744680851e-06,
      "loss": 0.155,
      "step": 1688
    },
    {
      "epoch": 0.38809742647058826,
      "grad_norm": 1.199539303779602,
      "learning_rate": 9.675744680851065e-06,
      "loss": 0.1905,
      "step": 1689
    },
    {
      "epoch": 0.3883272058823529,
      "grad_norm": 1.5465648174285889,
      "learning_rate": 9.674893617021278e-06,
      "loss": 0.1623,
      "step": 1690
    },
    {
      "epoch": 0.38855698529411764,
      "grad_norm": 1.47709321975708,
      "learning_rate": 9.674042553191491e-06,
      "loss": 0.2074,
      "step": 1691
    },
    {
      "epoch": 0.38878676470588236,
      "grad_norm": 1.038616418838501,
      "learning_rate": 9.673191489361702e-06,
      "loss": 0.1649,
      "step": 1692
    },
    {
      "epoch": 0.3890165441176471,
      "grad_norm": 1.4563218355178833,
      "learning_rate": 9.672340425531916e-06,
      "loss": 0.2155,
      "step": 1693
    },
    {
      "epoch": 0.38924632352941174,
      "grad_norm": 1.2977465391159058,
      "learning_rate": 9.671489361702129e-06,
      "loss": 0.2049,
      "step": 1694
    },
    {
      "epoch": 0.38947610294117646,
      "grad_norm": 1.102818250656128,
      "learning_rate": 9.670638297872342e-06,
      "loss": 0.1479,
      "step": 1695
    },
    {
      "epoch": 0.3897058823529412,
      "grad_norm": 1.3860760927200317,
      "learning_rate": 9.669787234042553e-06,
      "loss": 0.1836,
      "step": 1696
    },
    {
      "epoch": 0.3899356617647059,
      "grad_norm": 1.474600911140442,
      "learning_rate": 9.668936170212767e-06,
      "loss": 0.1919,
      "step": 1697
    },
    {
      "epoch": 0.39016544117647056,
      "grad_norm": 1.1814610958099365,
      "learning_rate": 9.66808510638298e-06,
      "loss": 0.1404,
      "step": 1698
    },
    {
      "epoch": 0.3903952205882353,
      "grad_norm": 1.4790669679641724,
      "learning_rate": 9.667234042553191e-06,
      "loss": 0.1525,
      "step": 1699
    },
    {
      "epoch": 0.390625,
      "grad_norm": 1.3380825519561768,
      "learning_rate": 9.666382978723406e-06,
      "loss": 0.1772,
      "step": 1700
    },
    {
      "epoch": 0.3908547794117647,
      "grad_norm": 1.2125630378723145,
      "learning_rate": 9.665531914893618e-06,
      "loss": 0.152,
      "step": 1701
    },
    {
      "epoch": 0.39108455882352944,
      "grad_norm": 1.2208136320114136,
      "learning_rate": 9.66468085106383e-06,
      "loss": 0.1582,
      "step": 1702
    },
    {
      "epoch": 0.3913143382352941,
      "grad_norm": 1.3178362846374512,
      "learning_rate": 9.663829787234044e-06,
      "loss": 0.1509,
      "step": 1703
    },
    {
      "epoch": 0.3915441176470588,
      "grad_norm": 1.1824228763580322,
      "learning_rate": 9.662978723404255e-06,
      "loss": 0.196,
      "step": 1704
    },
    {
      "epoch": 0.39177389705882354,
      "grad_norm": 1.3698559999465942,
      "learning_rate": 9.662127659574469e-06,
      "loss": 0.13,
      "step": 1705
    },
    {
      "epoch": 0.39200367647058826,
      "grad_norm": 1.6408860683441162,
      "learning_rate": 9.661276595744682e-06,
      "loss": 0.2119,
      "step": 1706
    },
    {
      "epoch": 0.3922334558823529,
      "grad_norm": 1.2628103494644165,
      "learning_rate": 9.660425531914895e-06,
      "loss": 0.2081,
      "step": 1707
    },
    {
      "epoch": 0.39246323529411764,
      "grad_norm": 1.4106557369232178,
      "learning_rate": 9.659574468085106e-06,
      "loss": 0.1706,
      "step": 1708
    },
    {
      "epoch": 0.39269301470588236,
      "grad_norm": 2.065995931625366,
      "learning_rate": 9.65872340425532e-06,
      "loss": 0.1427,
      "step": 1709
    },
    {
      "epoch": 0.3929227941176471,
      "grad_norm": 1.3134346008300781,
      "learning_rate": 9.657872340425533e-06,
      "loss": 0.1572,
      "step": 1710
    },
    {
      "epoch": 0.39315257352941174,
      "grad_norm": 1.3314443826675415,
      "learning_rate": 9.657021276595744e-06,
      "loss": 0.1642,
      "step": 1711
    },
    {
      "epoch": 0.39338235294117646,
      "grad_norm": 1.5071864128112793,
      "learning_rate": 9.656170212765959e-06,
      "loss": 0.1739,
      "step": 1712
    },
    {
      "epoch": 0.3936121323529412,
      "grad_norm": 1.683072805404663,
      "learning_rate": 9.65531914893617e-06,
      "loss": 0.1885,
      "step": 1713
    },
    {
      "epoch": 0.3938419117647059,
      "grad_norm": 1.4175822734832764,
      "learning_rate": 9.654468085106384e-06,
      "loss": 0.1313,
      "step": 1714
    },
    {
      "epoch": 0.39407169117647056,
      "grad_norm": 1.450797200202942,
      "learning_rate": 9.653617021276597e-06,
      "loss": 0.1441,
      "step": 1715
    },
    {
      "epoch": 0.3943014705882353,
      "grad_norm": 1.3490490913391113,
      "learning_rate": 9.652765957446808e-06,
      "loss": 0.1737,
      "step": 1716
    },
    {
      "epoch": 0.39453125,
      "grad_norm": 1.5817816257476807,
      "learning_rate": 9.651914893617023e-06,
      "loss": 0.2235,
      "step": 1717
    },
    {
      "epoch": 0.3947610294117647,
      "grad_norm": 1.1662930250167847,
      "learning_rate": 9.651063829787235e-06,
      "loss": 0.1419,
      "step": 1718
    },
    {
      "epoch": 0.39499080882352944,
      "grad_norm": 1.5449291467666626,
      "learning_rate": 9.650212765957448e-06,
      "loss": 0.1821,
      "step": 1719
    },
    {
      "epoch": 0.3952205882352941,
      "grad_norm": 1.5551291704177856,
      "learning_rate": 9.649361702127661e-06,
      "loss": 0.1901,
      "step": 1720
    },
    {
      "epoch": 0.3954503676470588,
      "grad_norm": 1.1142339706420898,
      "learning_rate": 9.648510638297873e-06,
      "loss": 0.1489,
      "step": 1721
    },
    {
      "epoch": 0.39568014705882354,
      "grad_norm": 1.7823944091796875,
      "learning_rate": 9.647659574468086e-06,
      "loss": 0.1267,
      "step": 1722
    },
    {
      "epoch": 0.39590992647058826,
      "grad_norm": 1.3424749374389648,
      "learning_rate": 9.646808510638299e-06,
      "loss": 0.1642,
      "step": 1723
    },
    {
      "epoch": 0.3961397058823529,
      "grad_norm": 1.3658376932144165,
      "learning_rate": 9.645957446808512e-06,
      "loss": 0.1616,
      "step": 1724
    },
    {
      "epoch": 0.39636948529411764,
      "grad_norm": 1.247287392616272,
      "learning_rate": 9.645106382978724e-06,
      "loss": 0.1675,
      "step": 1725
    },
    {
      "epoch": 0.39659926470588236,
      "grad_norm": 1.4640436172485352,
      "learning_rate": 9.644255319148937e-06,
      "loss": 0.1943,
      "step": 1726
    },
    {
      "epoch": 0.3968290441176471,
      "grad_norm": 1.9081568717956543,
      "learning_rate": 9.64340425531915e-06,
      "loss": 0.1894,
      "step": 1727
    },
    {
      "epoch": 0.39705882352941174,
      "grad_norm": 1.2147018909454346,
      "learning_rate": 9.642553191489361e-06,
      "loss": 0.1814,
      "step": 1728
    },
    {
      "epoch": 0.39728860294117646,
      "grad_norm": 1.2060189247131348,
      "learning_rate": 9.641702127659576e-06,
      "loss": 0.1517,
      "step": 1729
    },
    {
      "epoch": 0.3975183823529412,
      "grad_norm": 1.4421888589859009,
      "learning_rate": 9.640851063829788e-06,
      "loss": 0.2019,
      "step": 1730
    },
    {
      "epoch": 0.3977481617647059,
      "grad_norm": 1.1891790628433228,
      "learning_rate": 9.640000000000001e-06,
      "loss": 0.1247,
      "step": 1731
    },
    {
      "epoch": 0.39797794117647056,
      "grad_norm": 1.3192963600158691,
      "learning_rate": 9.639148936170214e-06,
      "loss": 0.1631,
      "step": 1732
    },
    {
      "epoch": 0.3982077205882353,
      "grad_norm": 1.2009515762329102,
      "learning_rate": 9.638297872340426e-06,
      "loss": 0.1801,
      "step": 1733
    },
    {
      "epoch": 0.3984375,
      "grad_norm": 1.2951250076293945,
      "learning_rate": 9.637446808510639e-06,
      "loss": 0.2093,
      "step": 1734
    },
    {
      "epoch": 0.3986672794117647,
      "grad_norm": 1.0300911664962769,
      "learning_rate": 9.636595744680852e-06,
      "loss": 0.1122,
      "step": 1735
    },
    {
      "epoch": 0.39889705882352944,
      "grad_norm": 1.112745761871338,
      "learning_rate": 9.635744680851065e-06,
      "loss": 0.1615,
      "step": 1736
    },
    {
      "epoch": 0.3991268382352941,
      "grad_norm": 1.5752778053283691,
      "learning_rate": 9.634893617021277e-06,
      "loss": 0.242,
      "step": 1737
    },
    {
      "epoch": 0.3993566176470588,
      "grad_norm": 1.0528712272644043,
      "learning_rate": 9.63404255319149e-06,
      "loss": 0.1545,
      "step": 1738
    },
    {
      "epoch": 0.39958639705882354,
      "grad_norm": 1.0429233312606812,
      "learning_rate": 9.633191489361703e-06,
      "loss": 0.1532,
      "step": 1739
    },
    {
      "epoch": 0.39981617647058826,
      "grad_norm": 1.6927837133407593,
      "learning_rate": 9.632340425531916e-06,
      "loss": 0.1944,
      "step": 1740
    },
    {
      "epoch": 0.4000459558823529,
      "grad_norm": 1.4616849422454834,
      "learning_rate": 9.63148936170213e-06,
      "loss": 0.1832,
      "step": 1741
    },
    {
      "epoch": 0.40027573529411764,
      "grad_norm": 1.6265004873275757,
      "learning_rate": 9.63063829787234e-06,
      "loss": 0.2157,
      "step": 1742
    },
    {
      "epoch": 0.40050551470588236,
      "grad_norm": 1.70185387134552,
      "learning_rate": 9.629787234042554e-06,
      "loss": 0.1964,
      "step": 1743
    },
    {
      "epoch": 0.4007352941176471,
      "grad_norm": 1.203511118888855,
      "learning_rate": 9.628936170212767e-06,
      "loss": 0.1752,
      "step": 1744
    },
    {
      "epoch": 0.40096507352941174,
      "grad_norm": 1.3910164833068848,
      "learning_rate": 9.62808510638298e-06,
      "loss": 0.1736,
      "step": 1745
    },
    {
      "epoch": 0.40119485294117646,
      "grad_norm": 1.4063085317611694,
      "learning_rate": 9.627234042553192e-06,
      "loss": 0.1496,
      "step": 1746
    },
    {
      "epoch": 0.4014246323529412,
      "grad_norm": 1.4791319370269775,
      "learning_rate": 9.626382978723405e-06,
      "loss": 0.16,
      "step": 1747
    },
    {
      "epoch": 0.4016544117647059,
      "grad_norm": 1.329291820526123,
      "learning_rate": 9.625531914893618e-06,
      "loss": 0.169,
      "step": 1748
    },
    {
      "epoch": 0.40188419117647056,
      "grad_norm": 1.453041911125183,
      "learning_rate": 9.62468085106383e-06,
      "loss": 0.1639,
      "step": 1749
    },
    {
      "epoch": 0.4021139705882353,
      "grad_norm": 1.398932695388794,
      "learning_rate": 9.623829787234044e-06,
      "loss": 0.2321,
      "step": 1750
    },
    {
      "epoch": 0.40234375,
      "grad_norm": 1.3983473777770996,
      "learning_rate": 9.622978723404256e-06,
      "loss": 0.1669,
      "step": 1751
    },
    {
      "epoch": 0.4025735294117647,
      "grad_norm": 1.303410530090332,
      "learning_rate": 9.622127659574469e-06,
      "loss": 0.1265,
      "step": 1752
    },
    {
      "epoch": 0.40280330882352944,
      "grad_norm": 1.4207483530044556,
      "learning_rate": 9.621276595744682e-06,
      "loss": 0.1793,
      "step": 1753
    },
    {
      "epoch": 0.4030330882352941,
      "grad_norm": 1.6064841747283936,
      "learning_rate": 9.620425531914894e-06,
      "loss": 0.202,
      "step": 1754
    },
    {
      "epoch": 0.4032628676470588,
      "grad_norm": 1.5449138879776,
      "learning_rate": 9.619574468085107e-06,
      "loss": 0.2646,
      "step": 1755
    },
    {
      "epoch": 0.40349264705882354,
      "grad_norm": 1.4987250566482544,
      "learning_rate": 9.61872340425532e-06,
      "loss": 0.1275,
      "step": 1756
    },
    {
      "epoch": 0.40372242647058826,
      "grad_norm": 1.561813473701477,
      "learning_rate": 9.617872340425533e-06,
      "loss": 0.2187,
      "step": 1757
    },
    {
      "epoch": 0.4039522058823529,
      "grad_norm": 1.1613729000091553,
      "learning_rate": 9.617021276595745e-06,
      "loss": 0.1801,
      "step": 1758
    },
    {
      "epoch": 0.40418198529411764,
      "grad_norm": 1.398134708404541,
      "learning_rate": 9.616170212765958e-06,
      "loss": 0.1434,
      "step": 1759
    },
    {
      "epoch": 0.40441176470588236,
      "grad_norm": 1.3396341800689697,
      "learning_rate": 9.615319148936171e-06,
      "loss": 0.1495,
      "step": 1760
    },
    {
      "epoch": 0.4046415441176471,
      "grad_norm": 1.168164849281311,
      "learning_rate": 9.614468085106384e-06,
      "loss": 0.1282,
      "step": 1761
    },
    {
      "epoch": 0.40487132352941174,
      "grad_norm": 1.3678770065307617,
      "learning_rate": 9.613617021276597e-06,
      "loss": 0.1286,
      "step": 1762
    },
    {
      "epoch": 0.40510110294117646,
      "grad_norm": 1.697489619255066,
      "learning_rate": 9.612765957446809e-06,
      "loss": 0.1501,
      "step": 1763
    },
    {
      "epoch": 0.4053308823529412,
      "grad_norm": 1.4871009588241577,
      "learning_rate": 9.611914893617022e-06,
      "loss": 0.1584,
      "step": 1764
    },
    {
      "epoch": 0.4055606617647059,
      "grad_norm": 1.336349368095398,
      "learning_rate": 9.611063829787235e-06,
      "loss": 0.1597,
      "step": 1765
    },
    {
      "epoch": 0.40579044117647056,
      "grad_norm": 1.29664945602417,
      "learning_rate": 9.610212765957447e-06,
      "loss": 0.1661,
      "step": 1766
    },
    {
      "epoch": 0.4060202205882353,
      "grad_norm": 1.2266910076141357,
      "learning_rate": 9.609361702127661e-06,
      "loss": 0.1676,
      "step": 1767
    },
    {
      "epoch": 0.40625,
      "grad_norm": 1.6342471837997437,
      "learning_rate": 9.608510638297873e-06,
      "loss": 0.1685,
      "step": 1768
    },
    {
      "epoch": 0.4064797794117647,
      "grad_norm": 1.4264875650405884,
      "learning_rate": 9.607659574468086e-06,
      "loss": 0.2424,
      "step": 1769
    },
    {
      "epoch": 0.40670955882352944,
      "grad_norm": 0.998356282711029,
      "learning_rate": 9.6068085106383e-06,
      "loss": 0.1864,
      "step": 1770
    },
    {
      "epoch": 0.4069393382352941,
      "grad_norm": 1.484816074371338,
      "learning_rate": 9.60595744680851e-06,
      "loss": 0.149,
      "step": 1771
    },
    {
      "epoch": 0.4071691176470588,
      "grad_norm": 1.0973355770111084,
      "learning_rate": 9.605106382978724e-06,
      "loss": 0.1182,
      "step": 1772
    },
    {
      "epoch": 0.40739889705882354,
      "grad_norm": 1.5449841022491455,
      "learning_rate": 9.604255319148937e-06,
      "loss": 0.2045,
      "step": 1773
    },
    {
      "epoch": 0.40762867647058826,
      "grad_norm": 1.0636413097381592,
      "learning_rate": 9.60340425531915e-06,
      "loss": 0.168,
      "step": 1774
    },
    {
      "epoch": 0.4078584558823529,
      "grad_norm": 1.1119376420974731,
      "learning_rate": 9.602553191489362e-06,
      "loss": 0.1489,
      "step": 1775
    },
    {
      "epoch": 0.40808823529411764,
      "grad_norm": 1.3608622550964355,
      "learning_rate": 9.601702127659575e-06,
      "loss": 0.1843,
      "step": 1776
    },
    {
      "epoch": 0.40831801470588236,
      "grad_norm": 1.4707212448120117,
      "learning_rate": 9.600851063829788e-06,
      "loss": 0.21,
      "step": 1777
    },
    {
      "epoch": 0.4085477941176471,
      "grad_norm": 1.378528118133545,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.1785,
      "step": 1778
    },
    {
      "epoch": 0.40877757352941174,
      "grad_norm": 1.4121525287628174,
      "learning_rate": 9.599148936170214e-06,
      "loss": 0.1525,
      "step": 1779
    },
    {
      "epoch": 0.40900735294117646,
      "grad_norm": 1.5308282375335693,
      "learning_rate": 9.598297872340426e-06,
      "loss": 0.1874,
      "step": 1780
    },
    {
      "epoch": 0.4092371323529412,
      "grad_norm": 1.1620817184448242,
      "learning_rate": 9.597446808510639e-06,
      "loss": 0.1319,
      "step": 1781
    },
    {
      "epoch": 0.4094669117647059,
      "grad_norm": 1.152029275894165,
      "learning_rate": 9.596595744680852e-06,
      "loss": 0.1523,
      "step": 1782
    },
    {
      "epoch": 0.40969669117647056,
      "grad_norm": 1.5503827333450317,
      "learning_rate": 9.595744680851065e-06,
      "loss": 0.1788,
      "step": 1783
    },
    {
      "epoch": 0.4099264705882353,
      "grad_norm": 1.3777132034301758,
      "learning_rate": 9.594893617021277e-06,
      "loss": 0.1366,
      "step": 1784
    },
    {
      "epoch": 0.41015625,
      "grad_norm": 1.2431678771972656,
      "learning_rate": 9.59404255319149e-06,
      "loss": 0.177,
      "step": 1785
    },
    {
      "epoch": 0.4103860294117647,
      "grad_norm": 1.241157054901123,
      "learning_rate": 9.593191489361703e-06,
      "loss": 0.1493,
      "step": 1786
    },
    {
      "epoch": 0.41061580882352944,
      "grad_norm": 1.1485307216644287,
      "learning_rate": 9.592340425531915e-06,
      "loss": 0.1682,
      "step": 1787
    },
    {
      "epoch": 0.4108455882352941,
      "grad_norm": 1.1118067502975464,
      "learning_rate": 9.59148936170213e-06,
      "loss": 0.1508,
      "step": 1788
    },
    {
      "epoch": 0.4110753676470588,
      "grad_norm": 1.3948719501495361,
      "learning_rate": 9.590638297872341e-06,
      "loss": 0.2,
      "step": 1789
    },
    {
      "epoch": 0.41130514705882354,
      "grad_norm": 1.458399772644043,
      "learning_rate": 9.589787234042554e-06,
      "loss": 0.1869,
      "step": 1790
    },
    {
      "epoch": 0.41153492647058826,
      "grad_norm": 1.6726484298706055,
      "learning_rate": 9.588936170212767e-06,
      "loss": 0.1876,
      "step": 1791
    },
    {
      "epoch": 0.4117647058823529,
      "grad_norm": 1.4006823301315308,
      "learning_rate": 9.588085106382979e-06,
      "loss": 0.136,
      "step": 1792
    },
    {
      "epoch": 0.41199448529411764,
      "grad_norm": 1.2993508577346802,
      "learning_rate": 9.587234042553192e-06,
      "loss": 0.1592,
      "step": 1793
    },
    {
      "epoch": 0.41222426470588236,
      "grad_norm": 1.3692375421524048,
      "learning_rate": 9.586382978723405e-06,
      "loss": 0.1623,
      "step": 1794
    },
    {
      "epoch": 0.4124540441176471,
      "grad_norm": 1.5330591201782227,
      "learning_rate": 9.585531914893618e-06,
      "loss": 0.2038,
      "step": 1795
    },
    {
      "epoch": 0.41268382352941174,
      "grad_norm": 1.364431381225586,
      "learning_rate": 9.58468085106383e-06,
      "loss": 0.1246,
      "step": 1796
    },
    {
      "epoch": 0.41291360294117646,
      "grad_norm": 1.3342695236206055,
      "learning_rate": 9.583829787234043e-06,
      "loss": 0.1411,
      "step": 1797
    },
    {
      "epoch": 0.4131433823529412,
      "grad_norm": 1.377318024635315,
      "learning_rate": 9.582978723404256e-06,
      "loss": 0.1512,
      "step": 1798
    },
    {
      "epoch": 0.4133731617647059,
      "grad_norm": 1.3054293394088745,
      "learning_rate": 9.582127659574468e-06,
      "loss": 0.1932,
      "step": 1799
    },
    {
      "epoch": 0.41360294117647056,
      "grad_norm": 1.4748876094818115,
      "learning_rate": 9.581276595744683e-06,
      "loss": 0.1462,
      "step": 1800
    },
    {
      "epoch": 0.4138327205882353,
      "grad_norm": 1.8771419525146484,
      "learning_rate": 9.580425531914894e-06,
      "loss": 0.2147,
      "step": 1801
    },
    {
      "epoch": 0.4140625,
      "grad_norm": 1.0545307397842407,
      "learning_rate": 9.579574468085107e-06,
      "loss": 0.1642,
      "step": 1802
    },
    {
      "epoch": 0.4142922794117647,
      "grad_norm": 1.2543175220489502,
      "learning_rate": 9.57872340425532e-06,
      "loss": 0.2213,
      "step": 1803
    },
    {
      "epoch": 0.41452205882352944,
      "grad_norm": 2.068938970565796,
      "learning_rate": 9.577872340425532e-06,
      "loss": 0.2085,
      "step": 1804
    },
    {
      "epoch": 0.4147518382352941,
      "grad_norm": 1.7217016220092773,
      "learning_rate": 9.577021276595747e-06,
      "loss": 0.1894,
      "step": 1805
    },
    {
      "epoch": 0.4149816176470588,
      "grad_norm": 1.3901602029800415,
      "learning_rate": 9.576170212765958e-06,
      "loss": 0.1963,
      "step": 1806
    },
    {
      "epoch": 0.41521139705882354,
      "grad_norm": 2.110095500946045,
      "learning_rate": 9.575319148936171e-06,
      "loss": 0.1719,
      "step": 1807
    },
    {
      "epoch": 0.41544117647058826,
      "grad_norm": 1.6555578708648682,
      "learning_rate": 9.574468085106385e-06,
      "loss": 0.2732,
      "step": 1808
    },
    {
      "epoch": 0.4156709558823529,
      "grad_norm": 1.4891623258590698,
      "learning_rate": 9.573617021276596e-06,
      "loss": 0.1483,
      "step": 1809
    },
    {
      "epoch": 0.41590073529411764,
      "grad_norm": 1.361959457397461,
      "learning_rate": 9.57276595744681e-06,
      "loss": 0.1652,
      "step": 1810
    },
    {
      "epoch": 0.41613051470588236,
      "grad_norm": 1.776265025138855,
      "learning_rate": 9.571914893617022e-06,
      "loss": 0.2089,
      "step": 1811
    },
    {
      "epoch": 0.4163602941176471,
      "grad_norm": 1.642310619354248,
      "learning_rate": 9.571063829787236e-06,
      "loss": 0.1796,
      "step": 1812
    },
    {
      "epoch": 0.41659007352941174,
      "grad_norm": 1.4170984029769897,
      "learning_rate": 9.570212765957447e-06,
      "loss": 0.1636,
      "step": 1813
    },
    {
      "epoch": 0.41681985294117646,
      "grad_norm": 1.0065051317214966,
      "learning_rate": 9.56936170212766e-06,
      "loss": 0.1385,
      "step": 1814
    },
    {
      "epoch": 0.4170496323529412,
      "grad_norm": 1.13188898563385,
      "learning_rate": 9.568510638297873e-06,
      "loss": 0.1421,
      "step": 1815
    },
    {
      "epoch": 0.4172794117647059,
      "grad_norm": 1.22707200050354,
      "learning_rate": 9.567659574468085e-06,
      "loss": 0.1861,
      "step": 1816
    },
    {
      "epoch": 0.41750919117647056,
      "grad_norm": 1.3544279336929321,
      "learning_rate": 9.5668085106383e-06,
      "loss": 0.1951,
      "step": 1817
    },
    {
      "epoch": 0.4177389705882353,
      "grad_norm": 1.2297364473342896,
      "learning_rate": 9.565957446808511e-06,
      "loss": 0.1499,
      "step": 1818
    },
    {
      "epoch": 0.41796875,
      "grad_norm": 1.4501004219055176,
      "learning_rate": 9.565106382978724e-06,
      "loss": 0.1769,
      "step": 1819
    },
    {
      "epoch": 0.4181985294117647,
      "grad_norm": 1.1298710107803345,
      "learning_rate": 9.564255319148937e-06,
      "loss": 0.1581,
      "step": 1820
    },
    {
      "epoch": 0.41842830882352944,
      "grad_norm": 1.262295126914978,
      "learning_rate": 9.563404255319149e-06,
      "loss": 0.1738,
      "step": 1821
    },
    {
      "epoch": 0.4186580882352941,
      "grad_norm": 1.3535796403884888,
      "learning_rate": 9.562553191489362e-06,
      "loss": 0.1854,
      "step": 1822
    },
    {
      "epoch": 0.4188878676470588,
      "grad_norm": 1.1956158876419067,
      "learning_rate": 9.561702127659575e-06,
      "loss": 0.1746,
      "step": 1823
    },
    {
      "epoch": 0.41911764705882354,
      "grad_norm": 1.259574294090271,
      "learning_rate": 9.560851063829788e-06,
      "loss": 0.1287,
      "step": 1824
    },
    {
      "epoch": 0.41934742647058826,
      "grad_norm": 1.3471477031707764,
      "learning_rate": 9.56e-06,
      "loss": 0.1512,
      "step": 1825
    },
    {
      "epoch": 0.4195772058823529,
      "grad_norm": 1.4226285219192505,
      "learning_rate": 9.559148936170213e-06,
      "loss": 0.1988,
      "step": 1826
    },
    {
      "epoch": 0.41980698529411764,
      "grad_norm": 1.3726948499679565,
      "learning_rate": 9.558297872340426e-06,
      "loss": 0.1954,
      "step": 1827
    },
    {
      "epoch": 0.42003676470588236,
      "grad_norm": 0.9488130211830139,
      "learning_rate": 9.55744680851064e-06,
      "loss": 0.1171,
      "step": 1828
    },
    {
      "epoch": 0.4202665441176471,
      "grad_norm": 1.4431225061416626,
      "learning_rate": 9.556595744680853e-06,
      "loss": 0.1358,
      "step": 1829
    },
    {
      "epoch": 0.42049632352941174,
      "grad_norm": 1.5640872716903687,
      "learning_rate": 9.555744680851064e-06,
      "loss": 0.1204,
      "step": 1830
    },
    {
      "epoch": 0.42072610294117646,
      "grad_norm": 1.2512178421020508,
      "learning_rate": 9.554893617021277e-06,
      "loss": 0.1653,
      "step": 1831
    },
    {
      "epoch": 0.4209558823529412,
      "grad_norm": 1.7275446653366089,
      "learning_rate": 9.55404255319149e-06,
      "loss": 0.1218,
      "step": 1832
    },
    {
      "epoch": 0.4211856617647059,
      "grad_norm": 1.516352891921997,
      "learning_rate": 9.553191489361704e-06,
      "loss": 0.1363,
      "step": 1833
    },
    {
      "epoch": 0.42141544117647056,
      "grad_norm": 1.6409037113189697,
      "learning_rate": 9.552340425531915e-06,
      "loss": 0.1793,
      "step": 1834
    },
    {
      "epoch": 0.4216452205882353,
      "grad_norm": 1.388826608657837,
      "learning_rate": 9.551489361702128e-06,
      "loss": 0.1676,
      "step": 1835
    },
    {
      "epoch": 0.421875,
      "grad_norm": 1.5611058473587036,
      "learning_rate": 9.550638297872341e-06,
      "loss": 0.1416,
      "step": 1836
    },
    {
      "epoch": 0.4221047794117647,
      "grad_norm": 1.1081126928329468,
      "learning_rate": 9.549787234042553e-06,
      "loss": 0.1517,
      "step": 1837
    },
    {
      "epoch": 0.42233455882352944,
      "grad_norm": 1.1551648378372192,
      "learning_rate": 9.548936170212768e-06,
      "loss": 0.1352,
      "step": 1838
    },
    {
      "epoch": 0.4225643382352941,
      "grad_norm": 1.6804739236831665,
      "learning_rate": 9.54808510638298e-06,
      "loss": 0.1306,
      "step": 1839
    },
    {
      "epoch": 0.4227941176470588,
      "grad_norm": 1.2429903745651245,
      "learning_rate": 9.547234042553192e-06,
      "loss": 0.1377,
      "step": 1840
    },
    {
      "epoch": 0.42302389705882354,
      "grad_norm": 1.7151812314987183,
      "learning_rate": 9.546382978723406e-06,
      "loss": 0.1885,
      "step": 1841
    },
    {
      "epoch": 0.42325367647058826,
      "grad_norm": 1.6311392784118652,
      "learning_rate": 9.545531914893617e-06,
      "loss": 0.1546,
      "step": 1842
    },
    {
      "epoch": 0.4234834558823529,
      "grad_norm": 1.8976038694381714,
      "learning_rate": 9.54468085106383e-06,
      "loss": 0.2316,
      "step": 1843
    },
    {
      "epoch": 0.42371323529411764,
      "grad_norm": 1.7791415452957153,
      "learning_rate": 9.543829787234043e-06,
      "loss": 0.21,
      "step": 1844
    },
    {
      "epoch": 0.42394301470588236,
      "grad_norm": 1.4568184614181519,
      "learning_rate": 9.542978723404257e-06,
      "loss": 0.1798,
      "step": 1845
    },
    {
      "epoch": 0.4241727941176471,
      "grad_norm": 1.4049590826034546,
      "learning_rate": 9.54212765957447e-06,
      "loss": 0.1378,
      "step": 1846
    },
    {
      "epoch": 0.42440257352941174,
      "grad_norm": 1.0626952648162842,
      "learning_rate": 9.541276595744681e-06,
      "loss": 0.1086,
      "step": 1847
    },
    {
      "epoch": 0.42463235294117646,
      "grad_norm": 1.2855805158615112,
      "learning_rate": 9.540425531914894e-06,
      "loss": 0.1649,
      "step": 1848
    },
    {
      "epoch": 0.4248621323529412,
      "grad_norm": 1.6060127019882202,
      "learning_rate": 9.539574468085108e-06,
      "loss": 0.1299,
      "step": 1849
    },
    {
      "epoch": 0.4250919117647059,
      "grad_norm": 1.0704874992370605,
      "learning_rate": 9.53872340425532e-06,
      "loss": 0.1362,
      "step": 1850
    },
    {
      "epoch": 0.42532169117647056,
      "grad_norm": 2.0111188888549805,
      "learning_rate": 9.537872340425532e-06,
      "loss": 0.2272,
      "step": 1851
    },
    {
      "epoch": 0.4255514705882353,
      "grad_norm": 1.3566319942474365,
      "learning_rate": 9.537021276595745e-06,
      "loss": 0.1945,
      "step": 1852
    },
    {
      "epoch": 0.42578125,
      "grad_norm": 1.2723890542984009,
      "learning_rate": 9.536170212765959e-06,
      "loss": 0.1616,
      "step": 1853
    },
    {
      "epoch": 0.4260110294117647,
      "grad_norm": 1.3305554389953613,
      "learning_rate": 9.53531914893617e-06,
      "loss": 0.1762,
      "step": 1854
    },
    {
      "epoch": 0.42624080882352944,
      "grad_norm": 1.906176209449768,
      "learning_rate": 9.534468085106385e-06,
      "loss": 0.2624,
      "step": 1855
    },
    {
      "epoch": 0.4264705882352941,
      "grad_norm": 1.1901671886444092,
      "learning_rate": 9.533617021276596e-06,
      "loss": 0.1188,
      "step": 1856
    },
    {
      "epoch": 0.4267003676470588,
      "grad_norm": 1.4458621740341187,
      "learning_rate": 9.53276595744681e-06,
      "loss": 0.121,
      "step": 1857
    },
    {
      "epoch": 0.42693014705882354,
      "grad_norm": 1.2227929830551147,
      "learning_rate": 9.531914893617023e-06,
      "loss": 0.1681,
      "step": 1858
    },
    {
      "epoch": 0.42715992647058826,
      "grad_norm": 1.2477943897247314,
      "learning_rate": 9.531063829787234e-06,
      "loss": 0.1575,
      "step": 1859
    },
    {
      "epoch": 0.4273897058823529,
      "grad_norm": 1.4792802333831787,
      "learning_rate": 9.530212765957447e-06,
      "loss": 0.2132,
      "step": 1860
    },
    {
      "epoch": 0.42761948529411764,
      "grad_norm": 1.3896180391311646,
      "learning_rate": 9.52936170212766e-06,
      "loss": 0.1848,
      "step": 1861
    },
    {
      "epoch": 0.42784926470588236,
      "grad_norm": 1.3713244199752808,
      "learning_rate": 9.528510638297874e-06,
      "loss": 0.1504,
      "step": 1862
    },
    {
      "epoch": 0.4280790441176471,
      "grad_norm": 1.467660903930664,
      "learning_rate": 9.527659574468085e-06,
      "loss": 0.1681,
      "step": 1863
    },
    {
      "epoch": 0.42830882352941174,
      "grad_norm": 1.4717004299163818,
      "learning_rate": 9.526808510638298e-06,
      "loss": 0.1856,
      "step": 1864
    },
    {
      "epoch": 0.42853860294117646,
      "grad_norm": 1.5147349834442139,
      "learning_rate": 9.525957446808512e-06,
      "loss": 0.1994,
      "step": 1865
    },
    {
      "epoch": 0.4287683823529412,
      "grad_norm": 1.527302861213684,
      "learning_rate": 9.525106382978723e-06,
      "loss": 0.1613,
      "step": 1866
    },
    {
      "epoch": 0.4289981617647059,
      "grad_norm": 1.8615003824234009,
      "learning_rate": 9.524255319148938e-06,
      "loss": 0.1827,
      "step": 1867
    },
    {
      "epoch": 0.42922794117647056,
      "grad_norm": 1.619986891746521,
      "learning_rate": 9.52340425531915e-06,
      "loss": 0.2363,
      "step": 1868
    },
    {
      "epoch": 0.4294577205882353,
      "grad_norm": 1.5261125564575195,
      "learning_rate": 9.522553191489363e-06,
      "loss": 0.1766,
      "step": 1869
    },
    {
      "epoch": 0.4296875,
      "grad_norm": 1.3298810720443726,
      "learning_rate": 9.521702127659576e-06,
      "loss": 0.2044,
      "step": 1870
    },
    {
      "epoch": 0.4299172794117647,
      "grad_norm": 1.3500571250915527,
      "learning_rate": 9.520851063829787e-06,
      "loss": 0.223,
      "step": 1871
    },
    {
      "epoch": 0.43014705882352944,
      "grad_norm": 1.27824068069458,
      "learning_rate": 9.52e-06,
      "loss": 0.1781,
      "step": 1872
    },
    {
      "epoch": 0.4303768382352941,
      "grad_norm": 1.4686278104782104,
      "learning_rate": 9.519148936170214e-06,
      "loss": 0.1478,
      "step": 1873
    },
    {
      "epoch": 0.4306066176470588,
      "grad_norm": 1.1151009798049927,
      "learning_rate": 9.518297872340427e-06,
      "loss": 0.1655,
      "step": 1874
    },
    {
      "epoch": 0.43083639705882354,
      "grad_norm": 1.4223726987838745,
      "learning_rate": 9.517446808510638e-06,
      "loss": 0.162,
      "step": 1875
    },
    {
      "epoch": 0.43106617647058826,
      "grad_norm": 1.0919269323349,
      "learning_rate": 9.516595744680851e-06,
      "loss": 0.1306,
      "step": 1876
    },
    {
      "epoch": 0.4312959558823529,
      "grad_norm": 1.2406892776489258,
      "learning_rate": 9.515744680851064e-06,
      "loss": 0.1752,
      "step": 1877
    },
    {
      "epoch": 0.43152573529411764,
      "grad_norm": 1.2385932207107544,
      "learning_rate": 9.514893617021278e-06,
      "loss": 0.1295,
      "step": 1878
    },
    {
      "epoch": 0.43175551470588236,
      "grad_norm": 1.1967239379882812,
      "learning_rate": 9.51404255319149e-06,
      "loss": 0.1651,
      "step": 1879
    },
    {
      "epoch": 0.4319852941176471,
      "grad_norm": 1.1161651611328125,
      "learning_rate": 9.513191489361702e-06,
      "loss": 0.137,
      "step": 1880
    },
    {
      "epoch": 0.43221507352941174,
      "grad_norm": 1.0808109045028687,
      "learning_rate": 9.512340425531915e-06,
      "loss": 0.1443,
      "step": 1881
    },
    {
      "epoch": 0.43244485294117646,
      "grad_norm": 1.5203075408935547,
      "learning_rate": 9.511489361702129e-06,
      "loss": 0.1827,
      "step": 1882
    },
    {
      "epoch": 0.4326746323529412,
      "grad_norm": 1.0469038486480713,
      "learning_rate": 9.510638297872342e-06,
      "loss": 0.1158,
      "step": 1883
    },
    {
      "epoch": 0.4329044117647059,
      "grad_norm": 1.3434126377105713,
      "learning_rate": 9.509787234042553e-06,
      "loss": 0.1321,
      "step": 1884
    },
    {
      "epoch": 0.43313419117647056,
      "grad_norm": 1.0205342769622803,
      "learning_rate": 9.508936170212766e-06,
      "loss": 0.142,
      "step": 1885
    },
    {
      "epoch": 0.4333639705882353,
      "grad_norm": 1.3004966974258423,
      "learning_rate": 9.50808510638298e-06,
      "loss": 0.1806,
      "step": 1886
    },
    {
      "epoch": 0.43359375,
      "grad_norm": 1.551606297492981,
      "learning_rate": 9.507234042553193e-06,
      "loss": 0.2155,
      "step": 1887
    },
    {
      "epoch": 0.4338235294117647,
      "grad_norm": 1.1302430629730225,
      "learning_rate": 9.506382978723406e-06,
      "loss": 0.1783,
      "step": 1888
    },
    {
      "epoch": 0.43405330882352944,
      "grad_norm": 1.4146690368652344,
      "learning_rate": 9.505531914893617e-06,
      "loss": 0.1689,
      "step": 1889
    },
    {
      "epoch": 0.4342830882352941,
      "grad_norm": 1.3340566158294678,
      "learning_rate": 9.50468085106383e-06,
      "loss": 0.2045,
      "step": 1890
    },
    {
      "epoch": 0.4345128676470588,
      "grad_norm": 1.1062670946121216,
      "learning_rate": 9.503829787234044e-06,
      "loss": 0.1361,
      "step": 1891
    },
    {
      "epoch": 0.43474264705882354,
      "grad_norm": 1.6666061878204346,
      "learning_rate": 9.502978723404255e-06,
      "loss": 0.1673,
      "step": 1892
    },
    {
      "epoch": 0.43497242647058826,
      "grad_norm": 1.5883015394210815,
      "learning_rate": 9.50212765957447e-06,
      "loss": 0.2112,
      "step": 1893
    },
    {
      "epoch": 0.4352022058823529,
      "grad_norm": 1.3102773427963257,
      "learning_rate": 9.501276595744682e-06,
      "loss": 0.1624,
      "step": 1894
    },
    {
      "epoch": 0.43543198529411764,
      "grad_norm": 1.3095556497573853,
      "learning_rate": 9.500425531914895e-06,
      "loss": 0.1963,
      "step": 1895
    },
    {
      "epoch": 0.43566176470588236,
      "grad_norm": 1.348434567451477,
      "learning_rate": 9.499574468085108e-06,
      "loss": 0.133,
      "step": 1896
    },
    {
      "epoch": 0.4358915441176471,
      "grad_norm": 1.3359723091125488,
      "learning_rate": 9.49872340425532e-06,
      "loss": 0.1504,
      "step": 1897
    },
    {
      "epoch": 0.43612132352941174,
      "grad_norm": 1.4172978401184082,
      "learning_rate": 9.497872340425533e-06,
      "loss": 0.1649,
      "step": 1898
    },
    {
      "epoch": 0.43635110294117646,
      "grad_norm": 1.3806606531143188,
      "learning_rate": 9.497021276595746e-06,
      "loss": 0.1569,
      "step": 1899
    },
    {
      "epoch": 0.4365808823529412,
      "grad_norm": 1.145729660987854,
      "learning_rate": 9.496170212765959e-06,
      "loss": 0.1628,
      "step": 1900
    },
    {
      "epoch": 0.4368106617647059,
      "grad_norm": 1.2013360261917114,
      "learning_rate": 9.49531914893617e-06,
      "loss": 0.1577,
      "step": 1901
    },
    {
      "epoch": 0.43704044117647056,
      "grad_norm": 1.0525728464126587,
      "learning_rate": 9.494468085106384e-06,
      "loss": 0.1307,
      "step": 1902
    },
    {
      "epoch": 0.4372702205882353,
      "grad_norm": 1.2187305688858032,
      "learning_rate": 9.493617021276597e-06,
      "loss": 0.1444,
      "step": 1903
    },
    {
      "epoch": 0.4375,
      "grad_norm": 1.1011967658996582,
      "learning_rate": 9.492765957446808e-06,
      "loss": 0.1296,
      "step": 1904
    },
    {
      "epoch": 0.4377297794117647,
      "grad_norm": 1.4695895910263062,
      "learning_rate": 9.491914893617023e-06,
      "loss": 0.1831,
      "step": 1905
    },
    {
      "epoch": 0.43795955882352944,
      "grad_norm": 1.3145015239715576,
      "learning_rate": 9.491063829787235e-06,
      "loss": 0.17,
      "step": 1906
    },
    {
      "epoch": 0.4381893382352941,
      "grad_norm": 1.338017463684082,
      "learning_rate": 9.490212765957448e-06,
      "loss": 0.1475,
      "step": 1907
    },
    {
      "epoch": 0.4384191176470588,
      "grad_norm": 1.2445064783096313,
      "learning_rate": 9.489361702127661e-06,
      "loss": 0.1422,
      "step": 1908
    },
    {
      "epoch": 0.43864889705882354,
      "grad_norm": 1.0970865488052368,
      "learning_rate": 9.488510638297872e-06,
      "loss": 0.1426,
      "step": 1909
    },
    {
      "epoch": 0.43887867647058826,
      "grad_norm": 1.5670480728149414,
      "learning_rate": 9.487659574468086e-06,
      "loss": 0.1788,
      "step": 1910
    },
    {
      "epoch": 0.4391084558823529,
      "grad_norm": 1.265963077545166,
      "learning_rate": 9.486808510638299e-06,
      "loss": 0.1177,
      "step": 1911
    },
    {
      "epoch": 0.43933823529411764,
      "grad_norm": 1.2759325504302979,
      "learning_rate": 9.485957446808512e-06,
      "loss": 0.123,
      "step": 1912
    },
    {
      "epoch": 0.43956801470588236,
      "grad_norm": 1.5441877841949463,
      "learning_rate": 9.485106382978723e-06,
      "loss": 0.1428,
      "step": 1913
    },
    {
      "epoch": 0.4397977941176471,
      "grad_norm": 1.395931601524353,
      "learning_rate": 9.484255319148937e-06,
      "loss": 0.1492,
      "step": 1914
    },
    {
      "epoch": 0.44002757352941174,
      "grad_norm": 1.5456820726394653,
      "learning_rate": 9.48340425531915e-06,
      "loss": 0.1562,
      "step": 1915
    },
    {
      "epoch": 0.44025735294117646,
      "grad_norm": 1.386210560798645,
      "learning_rate": 9.482553191489361e-06,
      "loss": 0.1298,
      "step": 1916
    },
    {
      "epoch": 0.4404871323529412,
      "grad_norm": 1.5192445516586304,
      "learning_rate": 9.481702127659576e-06,
      "loss": 0.1864,
      "step": 1917
    },
    {
      "epoch": 0.4407169117647059,
      "grad_norm": 1.0606869459152222,
      "learning_rate": 9.480851063829788e-06,
      "loss": 0.1489,
      "step": 1918
    },
    {
      "epoch": 0.44094669117647056,
      "grad_norm": 1.326316237449646,
      "learning_rate": 9.48e-06,
      "loss": 0.1776,
      "step": 1919
    },
    {
      "epoch": 0.4411764705882353,
      "grad_norm": 2.0490918159484863,
      "learning_rate": 9.479148936170214e-06,
      "loss": 0.1971,
      "step": 1920
    },
    {
      "epoch": 0.44140625,
      "grad_norm": 1.4648655652999878,
      "learning_rate": 9.478297872340425e-06,
      "loss": 0.2095,
      "step": 1921
    },
    {
      "epoch": 0.4416360294117647,
      "grad_norm": 1.4538861513137817,
      "learning_rate": 9.477446808510639e-06,
      "loss": 0.1915,
      "step": 1922
    },
    {
      "epoch": 0.44186580882352944,
      "grad_norm": 1.9807649850845337,
      "learning_rate": 9.476595744680852e-06,
      "loss": 0.2323,
      "step": 1923
    },
    {
      "epoch": 0.4420955882352941,
      "grad_norm": 1.3353489637374878,
      "learning_rate": 9.475744680851065e-06,
      "loss": 0.1749,
      "step": 1924
    },
    {
      "epoch": 0.4423253676470588,
      "grad_norm": 1.830520510673523,
      "learning_rate": 9.474893617021276e-06,
      "loss": 0.1612,
      "step": 1925
    },
    {
      "epoch": 0.44255514705882354,
      "grad_norm": 1.4142175912857056,
      "learning_rate": 9.47404255319149e-06,
      "loss": 0.1354,
      "step": 1926
    },
    {
      "epoch": 0.44278492647058826,
      "grad_norm": 1.4518553018569946,
      "learning_rate": 9.473191489361703e-06,
      "loss": 0.2252,
      "step": 1927
    },
    {
      "epoch": 0.4430147058823529,
      "grad_norm": 2.160364866256714,
      "learning_rate": 9.472340425531916e-06,
      "loss": 0.1979,
      "step": 1928
    },
    {
      "epoch": 0.44324448529411764,
      "grad_norm": 1.6338155269622803,
      "learning_rate": 9.471489361702129e-06,
      "loss": 0.1558,
      "step": 1929
    },
    {
      "epoch": 0.44347426470588236,
      "grad_norm": 1.715590476989746,
      "learning_rate": 9.47063829787234e-06,
      "loss": 0.2067,
      "step": 1930
    },
    {
      "epoch": 0.4437040441176471,
      "grad_norm": 1.3259713649749756,
      "learning_rate": 9.469787234042554e-06,
      "loss": 0.1523,
      "step": 1931
    },
    {
      "epoch": 0.44393382352941174,
      "grad_norm": 1.3544344902038574,
      "learning_rate": 9.468936170212767e-06,
      "loss": 0.1763,
      "step": 1932
    },
    {
      "epoch": 0.44416360294117646,
      "grad_norm": 1.3364087343215942,
      "learning_rate": 9.46808510638298e-06,
      "loss": 0.137,
      "step": 1933
    },
    {
      "epoch": 0.4443933823529412,
      "grad_norm": 1.2639394998550415,
      "learning_rate": 9.467234042553193e-06,
      "loss": 0.1874,
      "step": 1934
    },
    {
      "epoch": 0.4446231617647059,
      "grad_norm": 1.2313270568847656,
      "learning_rate": 9.466382978723405e-06,
      "loss": 0.1613,
      "step": 1935
    },
    {
      "epoch": 0.44485294117647056,
      "grad_norm": 1.1835098266601562,
      "learning_rate": 9.465531914893618e-06,
      "loss": 0.1801,
      "step": 1936
    },
    {
      "epoch": 0.4450827205882353,
      "grad_norm": 1.2962583303451538,
      "learning_rate": 9.464680851063831e-06,
      "loss": 0.1665,
      "step": 1937
    },
    {
      "epoch": 0.4453125,
      "grad_norm": 1.5411744117736816,
      "learning_rate": 9.463829787234044e-06,
      "loss": 0.2073,
      "step": 1938
    },
    {
      "epoch": 0.4455422794117647,
      "grad_norm": 1.5770243406295776,
      "learning_rate": 9.462978723404256e-06,
      "loss": 0.1499,
      "step": 1939
    },
    {
      "epoch": 0.44577205882352944,
      "grad_norm": 1.294747233390808,
      "learning_rate": 9.462127659574469e-06,
      "loss": 0.1597,
      "step": 1940
    },
    {
      "epoch": 0.4460018382352941,
      "grad_norm": 1.6706565618515015,
      "learning_rate": 9.461276595744682e-06,
      "loss": 0.1386,
      "step": 1941
    },
    {
      "epoch": 0.4462316176470588,
      "grad_norm": 1.200042486190796,
      "learning_rate": 9.460425531914893e-06,
      "loss": 0.1899,
      "step": 1942
    },
    {
      "epoch": 0.44646139705882354,
      "grad_norm": 1.2190221548080444,
      "learning_rate": 9.459574468085108e-06,
      "loss": 0.1262,
      "step": 1943
    },
    {
      "epoch": 0.44669117647058826,
      "grad_norm": 1.1260550022125244,
      "learning_rate": 9.45872340425532e-06,
      "loss": 0.1473,
      "step": 1944
    },
    {
      "epoch": 0.4469209558823529,
      "grad_norm": 1.0625821352005005,
      "learning_rate": 9.457872340425533e-06,
      "loss": 0.1064,
      "step": 1945
    },
    {
      "epoch": 0.44715073529411764,
      "grad_norm": 1.231583833694458,
      "learning_rate": 9.457021276595746e-06,
      "loss": 0.1547,
      "step": 1946
    },
    {
      "epoch": 0.44738051470588236,
      "grad_norm": 1.3525056838989258,
      "learning_rate": 9.456170212765958e-06,
      "loss": 0.1278,
      "step": 1947
    },
    {
      "epoch": 0.4476102941176471,
      "grad_norm": 1.6081784963607788,
      "learning_rate": 9.45531914893617e-06,
      "loss": 0.1602,
      "step": 1948
    },
    {
      "epoch": 0.44784007352941174,
      "grad_norm": 1.2018007040023804,
      "learning_rate": 9.454468085106384e-06,
      "loss": 0.1282,
      "step": 1949
    },
    {
      "epoch": 0.44806985294117646,
      "grad_norm": 1.2967585325241089,
      "learning_rate": 9.453617021276597e-06,
      "loss": 0.1587,
      "step": 1950
    },
    {
      "epoch": 0.4482996323529412,
      "grad_norm": 1.2110544443130493,
      "learning_rate": 9.452765957446809e-06,
      "loss": 0.109,
      "step": 1951
    },
    {
      "epoch": 0.4485294117647059,
      "grad_norm": 1.1579104661941528,
      "learning_rate": 9.451914893617022e-06,
      "loss": 0.1581,
      "step": 1952
    },
    {
      "epoch": 0.44875919117647056,
      "grad_norm": 1.363071322441101,
      "learning_rate": 9.451063829787235e-06,
      "loss": 0.1926,
      "step": 1953
    },
    {
      "epoch": 0.4489889705882353,
      "grad_norm": 1.1316523551940918,
      "learning_rate": 9.450212765957446e-06,
      "loss": 0.1335,
      "step": 1954
    },
    {
      "epoch": 0.44921875,
      "grad_norm": 1.3633705377578735,
      "learning_rate": 9.449361702127661e-06,
      "loss": 0.1529,
      "step": 1955
    },
    {
      "epoch": 0.4494485294117647,
      "grad_norm": 1.642857313156128,
      "learning_rate": 9.448510638297873e-06,
      "loss": 0.1437,
      "step": 1956
    },
    {
      "epoch": 0.44967830882352944,
      "grad_norm": 1.0599771738052368,
      "learning_rate": 9.447659574468086e-06,
      "loss": 0.1291,
      "step": 1957
    },
    {
      "epoch": 0.4499080882352941,
      "grad_norm": 1.6607192754745483,
      "learning_rate": 9.446808510638299e-06,
      "loss": 0.1918,
      "step": 1958
    },
    {
      "epoch": 0.4501378676470588,
      "grad_norm": 1.2349001169204712,
      "learning_rate": 9.44595744680851e-06,
      "loss": 0.1863,
      "step": 1959
    },
    {
      "epoch": 0.45036764705882354,
      "grad_norm": 1.2633452415466309,
      "learning_rate": 9.445106382978724e-06,
      "loss": 0.1346,
      "step": 1960
    },
    {
      "epoch": 0.45059742647058826,
      "grad_norm": 1.3118308782577515,
      "learning_rate": 9.444255319148937e-06,
      "loss": 0.172,
      "step": 1961
    },
    {
      "epoch": 0.4508272058823529,
      "grad_norm": 1.3121803998947144,
      "learning_rate": 9.44340425531915e-06,
      "loss": 0.1245,
      "step": 1962
    },
    {
      "epoch": 0.45105698529411764,
      "grad_norm": 1.1630444526672363,
      "learning_rate": 9.442553191489362e-06,
      "loss": 0.1209,
      "step": 1963
    },
    {
      "epoch": 0.45128676470588236,
      "grad_norm": 1.8667776584625244,
      "learning_rate": 9.441702127659575e-06,
      "loss": 0.1469,
      "step": 1964
    },
    {
      "epoch": 0.4515165441176471,
      "grad_norm": 1.2247083187103271,
      "learning_rate": 9.440851063829788e-06,
      "loss": 0.1323,
      "step": 1965
    },
    {
      "epoch": 0.45174632352941174,
      "grad_norm": 1.0431060791015625,
      "learning_rate": 9.440000000000001e-06,
      "loss": 0.1145,
      "step": 1966
    },
    {
      "epoch": 0.45197610294117646,
      "grad_norm": 1.0349117517471313,
      "learning_rate": 9.439148936170214e-06,
      "loss": 0.1446,
      "step": 1967
    },
    {
      "epoch": 0.4522058823529412,
      "grad_norm": 1.5719373226165771,
      "learning_rate": 9.438297872340426e-06,
      "loss": 0.1696,
      "step": 1968
    },
    {
      "epoch": 0.4524356617647059,
      "grad_norm": 1.2632408142089844,
      "learning_rate": 9.437446808510639e-06,
      "loss": 0.1315,
      "step": 1969
    },
    {
      "epoch": 0.45266544117647056,
      "grad_norm": 1.494214653968811,
      "learning_rate": 9.436595744680852e-06,
      "loss": 0.2072,
      "step": 1970
    },
    {
      "epoch": 0.4528952205882353,
      "grad_norm": 0.9922062158584595,
      "learning_rate": 9.435744680851065e-06,
      "loss": 0.1152,
      "step": 1971
    },
    {
      "epoch": 0.453125,
      "grad_norm": 1.4135693311691284,
      "learning_rate": 9.434893617021277e-06,
      "loss": 0.1548,
      "step": 1972
    },
    {
      "epoch": 0.4533547794117647,
      "grad_norm": 0.9808539748191833,
      "learning_rate": 9.43404255319149e-06,
      "loss": 0.133,
      "step": 1973
    },
    {
      "epoch": 0.45358455882352944,
      "grad_norm": 1.4669749736785889,
      "learning_rate": 9.433191489361703e-06,
      "loss": 0.1292,
      "step": 1974
    },
    {
      "epoch": 0.4538143382352941,
      "grad_norm": 1.611781120300293,
      "learning_rate": 9.432340425531916e-06,
      "loss": 0.1304,
      "step": 1975
    },
    {
      "epoch": 0.4540441176470588,
      "grad_norm": 1.0568056106567383,
      "learning_rate": 9.43148936170213e-06,
      "loss": 0.124,
      "step": 1976
    },
    {
      "epoch": 0.45427389705882354,
      "grad_norm": 1.453946590423584,
      "learning_rate": 9.430638297872341e-06,
      "loss": 0.1876,
      "step": 1977
    },
    {
      "epoch": 0.45450367647058826,
      "grad_norm": 1.4250493049621582,
      "learning_rate": 9.429787234042554e-06,
      "loss": 0.1509,
      "step": 1978
    },
    {
      "epoch": 0.4547334558823529,
      "grad_norm": 1.3044929504394531,
      "learning_rate": 9.428936170212767e-06,
      "loss": 0.133,
      "step": 1979
    },
    {
      "epoch": 0.45496323529411764,
      "grad_norm": 1.157518744468689,
      "learning_rate": 9.428085106382979e-06,
      "loss": 0.1673,
      "step": 1980
    },
    {
      "epoch": 0.45519301470588236,
      "grad_norm": 1.1821489334106445,
      "learning_rate": 9.427234042553194e-06,
      "loss": 0.1451,
      "step": 1981
    },
    {
      "epoch": 0.4554227941176471,
      "grad_norm": 1.629042625427246,
      "learning_rate": 9.426382978723405e-06,
      "loss": 0.116,
      "step": 1982
    },
    {
      "epoch": 0.45565257352941174,
      "grad_norm": 1.252713918685913,
      "learning_rate": 9.425531914893618e-06,
      "loss": 0.1428,
      "step": 1983
    },
    {
      "epoch": 0.45588235294117646,
      "grad_norm": 1.1381933689117432,
      "learning_rate": 9.424680851063831e-06,
      "loss": 0.1679,
      "step": 1984
    },
    {
      "epoch": 0.4561121323529412,
      "grad_norm": 1.3702112436294556,
      "learning_rate": 9.423829787234043e-06,
      "loss": 0.1333,
      "step": 1985
    },
    {
      "epoch": 0.4563419117647059,
      "grad_norm": 1.045830488204956,
      "learning_rate": 9.422978723404256e-06,
      "loss": 0.1462,
      "step": 1986
    },
    {
      "epoch": 0.45657169117647056,
      "grad_norm": 1.2007770538330078,
      "learning_rate": 9.42212765957447e-06,
      "loss": 0.1613,
      "step": 1987
    },
    {
      "epoch": 0.4568014705882353,
      "grad_norm": 1.231306791305542,
      "learning_rate": 9.421276595744682e-06,
      "loss": 0.2085,
      "step": 1988
    },
    {
      "epoch": 0.45703125,
      "grad_norm": 1.400308609008789,
      "learning_rate": 9.420425531914894e-06,
      "loss": 0.1471,
      "step": 1989
    },
    {
      "epoch": 0.4572610294117647,
      "grad_norm": 1.2452071905136108,
      "learning_rate": 9.419574468085107e-06,
      "loss": 0.1682,
      "step": 1990
    },
    {
      "epoch": 0.45749080882352944,
      "grad_norm": 1.1282293796539307,
      "learning_rate": 9.41872340425532e-06,
      "loss": 0.1392,
      "step": 1991
    },
    {
      "epoch": 0.4577205882352941,
      "grad_norm": 1.318791389465332,
      "learning_rate": 9.417872340425532e-06,
      "loss": 0.1269,
      "step": 1992
    },
    {
      "epoch": 0.4579503676470588,
      "grad_norm": 1.342252254486084,
      "learning_rate": 9.417021276595747e-06,
      "loss": 0.1638,
      "step": 1993
    },
    {
      "epoch": 0.45818014705882354,
      "grad_norm": 1.3530399799346924,
      "learning_rate": 9.416170212765958e-06,
      "loss": 0.1699,
      "step": 1994
    },
    {
      "epoch": 0.45840992647058826,
      "grad_norm": 1.059556245803833,
      "learning_rate": 9.415319148936171e-06,
      "loss": 0.1704,
      "step": 1995
    },
    {
      "epoch": 0.4586397058823529,
      "grad_norm": 1.0582506656646729,
      "learning_rate": 9.414468085106384e-06,
      "loss": 0.16,
      "step": 1996
    },
    {
      "epoch": 0.45886948529411764,
      "grad_norm": 1.446970820426941,
      "learning_rate": 9.413617021276596e-06,
      "loss": 0.1897,
      "step": 1997
    },
    {
      "epoch": 0.45909926470588236,
      "grad_norm": 1.5164599418640137,
      "learning_rate": 9.412765957446809e-06,
      "loss": 0.1783,
      "step": 1998
    },
    {
      "epoch": 0.4593290441176471,
      "grad_norm": 1.442204236984253,
      "learning_rate": 9.411914893617022e-06,
      "loss": 0.1718,
      "step": 1999
    },
    {
      "epoch": 0.45955882352941174,
      "grad_norm": 1.3121187686920166,
      "learning_rate": 9.411063829787235e-06,
      "loss": 0.1655,
      "step": 2000
    },
    {
      "epoch": 0.45955882352941174,
      "eval_loss": 0.15675178170204163,
      "eval_runtime": 1968.5066,
      "eval_samples_per_second": 4.524,
      "eval_steps_per_second": 2.262,
      "step": 2000
    },
    {
      "epoch": 0.45978860294117646,
      "grad_norm": 1.0886240005493164,
      "learning_rate": 9.410212765957447e-06,
      "loss": 0.1301,
      "step": 2001
    },
    {
      "epoch": 0.4600183823529412,
      "grad_norm": 1.4653767347335815,
      "learning_rate": 9.40936170212766e-06,
      "loss": 0.1916,
      "step": 2002
    },
    {
      "epoch": 0.4602481617647059,
      "grad_norm": 1.0275107622146606,
      "learning_rate": 9.408510638297873e-06,
      "loss": 0.1171,
      "step": 2003
    },
    {
      "epoch": 0.46047794117647056,
      "grad_norm": 1.1793447732925415,
      "learning_rate": 9.407659574468085e-06,
      "loss": 0.2015,
      "step": 2004
    },
    {
      "epoch": 0.4607077205882353,
      "grad_norm": 1.3985097408294678,
      "learning_rate": 9.4068085106383e-06,
      "loss": 0.178,
      "step": 2005
    },
    {
      "epoch": 0.4609375,
      "grad_norm": 1.492552399635315,
      "learning_rate": 9.405957446808511e-06,
      "loss": 0.1885,
      "step": 2006
    },
    {
      "epoch": 0.4611672794117647,
      "grad_norm": 1.3423727750778198,
      "learning_rate": 9.405106382978724e-06,
      "loss": 0.1344,
      "step": 2007
    },
    {
      "epoch": 0.46139705882352944,
      "grad_norm": 1.4160280227661133,
      "learning_rate": 9.404255319148937e-06,
      "loss": 0.2021,
      "step": 2008
    },
    {
      "epoch": 0.4616268382352941,
      "grad_norm": 1.4812442064285278,
      "learning_rate": 9.403404255319149e-06,
      "loss": 0.1748,
      "step": 2009
    },
    {
      "epoch": 0.4618566176470588,
      "grad_norm": 1.3368154764175415,
      "learning_rate": 9.402553191489362e-06,
      "loss": 0.1473,
      "step": 2010
    },
    {
      "epoch": 0.46208639705882354,
      "grad_norm": 1.1853443384170532,
      "learning_rate": 9.401702127659575e-06,
      "loss": 0.1538,
      "step": 2011
    },
    {
      "epoch": 0.46231617647058826,
      "grad_norm": 1.2817842960357666,
      "learning_rate": 9.400851063829788e-06,
      "loss": 0.1372,
      "step": 2012
    },
    {
      "epoch": 0.4625459558823529,
      "grad_norm": 1.1057554483413696,
      "learning_rate": 9.4e-06,
      "loss": 0.1955,
      "step": 2013
    },
    {
      "epoch": 0.46277573529411764,
      "grad_norm": 1.3673737049102783,
      "learning_rate": 9.399148936170213e-06,
      "loss": 0.1157,
      "step": 2014
    },
    {
      "epoch": 0.46300551470588236,
      "grad_norm": 0.979741096496582,
      "learning_rate": 9.398297872340426e-06,
      "loss": 0.1368,
      "step": 2015
    },
    {
      "epoch": 0.4632352941176471,
      "grad_norm": 1.4795482158660889,
      "learning_rate": 9.39744680851064e-06,
      "loss": 0.1741,
      "step": 2016
    },
    {
      "epoch": 0.46346507352941174,
      "grad_norm": 1.3678327798843384,
      "learning_rate": 9.396595744680852e-06,
      "loss": 0.1641,
      "step": 2017
    },
    {
      "epoch": 0.46369485294117646,
      "grad_norm": 1.2175086736679077,
      "learning_rate": 9.395744680851064e-06,
      "loss": 0.1579,
      "step": 2018
    },
    {
      "epoch": 0.4639246323529412,
      "grad_norm": 1.106697916984558,
      "learning_rate": 9.394893617021277e-06,
      "loss": 0.2033,
      "step": 2019
    },
    {
      "epoch": 0.4641544117647059,
      "grad_norm": 1.4234821796417236,
      "learning_rate": 9.39404255319149e-06,
      "loss": 0.1359,
      "step": 2020
    },
    {
      "epoch": 0.46438419117647056,
      "grad_norm": 1.0445328950881958,
      "learning_rate": 9.393191489361703e-06,
      "loss": 0.1183,
      "step": 2021
    },
    {
      "epoch": 0.4646139705882353,
      "grad_norm": 1.7485816478729248,
      "learning_rate": 9.392340425531917e-06,
      "loss": 0.1578,
      "step": 2022
    },
    {
      "epoch": 0.46484375,
      "grad_norm": 1.1423332691192627,
      "learning_rate": 9.391489361702128e-06,
      "loss": 0.1573,
      "step": 2023
    },
    {
      "epoch": 0.4650735294117647,
      "grad_norm": 0.9980412721633911,
      "learning_rate": 9.390638297872341e-06,
      "loss": 0.1612,
      "step": 2024
    },
    {
      "epoch": 0.46530330882352944,
      "grad_norm": 1.5060505867004395,
      "learning_rate": 9.389787234042554e-06,
      "loss": 0.1457,
      "step": 2025
    },
    {
      "epoch": 0.4655330882352941,
      "grad_norm": 1.3562731742858887,
      "learning_rate": 9.388936170212768e-06,
      "loss": 0.1312,
      "step": 2026
    },
    {
      "epoch": 0.4657628676470588,
      "grad_norm": 1.7645092010498047,
      "learning_rate": 9.388085106382979e-06,
      "loss": 0.1707,
      "step": 2027
    },
    {
      "epoch": 0.46599264705882354,
      "grad_norm": 1.3106659650802612,
      "learning_rate": 9.387234042553192e-06,
      "loss": 0.1438,
      "step": 2028
    },
    {
      "epoch": 0.46622242647058826,
      "grad_norm": 1.4965314865112305,
      "learning_rate": 9.386382978723405e-06,
      "loss": 0.174,
      "step": 2029
    },
    {
      "epoch": 0.4664522058823529,
      "grad_norm": 1.4156222343444824,
      "learning_rate": 9.385531914893617e-06,
      "loss": 0.1754,
      "step": 2030
    },
    {
      "epoch": 0.46668198529411764,
      "grad_norm": 1.212809443473816,
      "learning_rate": 9.384680851063832e-06,
      "loss": 0.1784,
      "step": 2031
    },
    {
      "epoch": 0.46691176470588236,
      "grad_norm": 1.1388797760009766,
      "learning_rate": 9.383829787234043e-06,
      "loss": 0.1533,
      "step": 2032
    },
    {
      "epoch": 0.4671415441176471,
      "grad_norm": 1.1149836778640747,
      "learning_rate": 9.382978723404256e-06,
      "loss": 0.1741,
      "step": 2033
    },
    {
      "epoch": 0.46737132352941174,
      "grad_norm": 1.2280820608139038,
      "learning_rate": 9.38212765957447e-06,
      "loss": 0.1631,
      "step": 2034
    },
    {
      "epoch": 0.46760110294117646,
      "grad_norm": 1.3544657230377197,
      "learning_rate": 9.381276595744681e-06,
      "loss": 0.1679,
      "step": 2035
    },
    {
      "epoch": 0.4678308823529412,
      "grad_norm": 1.609276294708252,
      "learning_rate": 9.380425531914894e-06,
      "loss": 0.1747,
      "step": 2036
    },
    {
      "epoch": 0.4680606617647059,
      "grad_norm": 1.1156646013259888,
      "learning_rate": 9.379574468085107e-06,
      "loss": 0.1366,
      "step": 2037
    },
    {
      "epoch": 0.46829044117647056,
      "grad_norm": 1.3707438707351685,
      "learning_rate": 9.37872340425532e-06,
      "loss": 0.1461,
      "step": 2038
    },
    {
      "epoch": 0.4685202205882353,
      "grad_norm": 1.751718521118164,
      "learning_rate": 9.377872340425532e-06,
      "loss": 0.2177,
      "step": 2039
    },
    {
      "epoch": 0.46875,
      "grad_norm": 1.0665411949157715,
      "learning_rate": 9.377021276595745e-06,
      "loss": 0.1133,
      "step": 2040
    },
    {
      "epoch": 0.4689797794117647,
      "grad_norm": 1.7324929237365723,
      "learning_rate": 9.376170212765958e-06,
      "loss": 0.131,
      "step": 2041
    },
    {
      "epoch": 0.46920955882352944,
      "grad_norm": 1.0528075695037842,
      "learning_rate": 9.37531914893617e-06,
      "loss": 0.144,
      "step": 2042
    },
    {
      "epoch": 0.4694393382352941,
      "grad_norm": 1.200519323348999,
      "learning_rate": 9.374468085106385e-06,
      "loss": 0.1629,
      "step": 2043
    },
    {
      "epoch": 0.4696691176470588,
      "grad_norm": 1.0913304090499878,
      "learning_rate": 9.373617021276596e-06,
      "loss": 0.1254,
      "step": 2044
    },
    {
      "epoch": 0.46989889705882354,
      "grad_norm": 1.5363014936447144,
      "learning_rate": 9.37276595744681e-06,
      "loss": 0.1888,
      "step": 2045
    },
    {
      "epoch": 0.47012867647058826,
      "grad_norm": 1.409185767173767,
      "learning_rate": 9.371914893617023e-06,
      "loss": 0.1731,
      "step": 2046
    },
    {
      "epoch": 0.4703584558823529,
      "grad_norm": 1.28963303565979,
      "learning_rate": 9.371063829787234e-06,
      "loss": 0.1971,
      "step": 2047
    },
    {
      "epoch": 0.47058823529411764,
      "grad_norm": 1.1668415069580078,
      "learning_rate": 9.370212765957447e-06,
      "loss": 0.151,
      "step": 2048
    },
    {
      "epoch": 0.47081801470588236,
      "grad_norm": 1.8681262731552124,
      "learning_rate": 9.36936170212766e-06,
      "loss": 0.1739,
      "step": 2049
    },
    {
      "epoch": 0.4710477941176471,
      "grad_norm": 1.3492900133132935,
      "learning_rate": 9.368510638297874e-06,
      "loss": 0.1433,
      "step": 2050
    },
    {
      "epoch": 0.47127757352941174,
      "grad_norm": 1.1555354595184326,
      "learning_rate": 9.367659574468085e-06,
      "loss": 0.1282,
      "step": 2051
    },
    {
      "epoch": 0.47150735294117646,
      "grad_norm": 1.1633906364440918,
      "learning_rate": 9.366808510638298e-06,
      "loss": 0.1311,
      "step": 2052
    },
    {
      "epoch": 0.4717371323529412,
      "grad_norm": 1.384867548942566,
      "learning_rate": 9.365957446808511e-06,
      "loss": 0.1327,
      "step": 2053
    },
    {
      "epoch": 0.4719669117647059,
      "grad_norm": 1.0971392393112183,
      "learning_rate": 9.365106382978723e-06,
      "loss": 0.1272,
      "step": 2054
    },
    {
      "epoch": 0.47219669117647056,
      "grad_norm": 0.9363660216331482,
      "learning_rate": 9.364255319148938e-06,
      "loss": 0.1113,
      "step": 2055
    },
    {
      "epoch": 0.4724264705882353,
      "grad_norm": 1.5905660390853882,
      "learning_rate": 9.36340425531915e-06,
      "loss": 0.1615,
      "step": 2056
    },
    {
      "epoch": 0.47265625,
      "grad_norm": 1.5033310651779175,
      "learning_rate": 9.362553191489362e-06,
      "loss": 0.1426,
      "step": 2057
    },
    {
      "epoch": 0.4728860294117647,
      "grad_norm": 1.254887342453003,
      "learning_rate": 9.361702127659576e-06,
      "loss": 0.1327,
      "step": 2058
    },
    {
      "epoch": 0.47311580882352944,
      "grad_norm": 1.8149551153182983,
      "learning_rate": 9.360851063829787e-06,
      "loss": 0.1593,
      "step": 2059
    },
    {
      "epoch": 0.4733455882352941,
      "grad_norm": 0.9725525379180908,
      "learning_rate": 9.360000000000002e-06,
      "loss": 0.1165,
      "step": 2060
    },
    {
      "epoch": 0.4735753676470588,
      "grad_norm": 2.446183919906616,
      "learning_rate": 9.359148936170213e-06,
      "loss": 0.181,
      "step": 2061
    },
    {
      "epoch": 0.47380514705882354,
      "grad_norm": 1.2385551929473877,
      "learning_rate": 9.358297872340427e-06,
      "loss": 0.1124,
      "step": 2062
    },
    {
      "epoch": 0.47403492647058826,
      "grad_norm": 1.0124664306640625,
      "learning_rate": 9.35744680851064e-06,
      "loss": 0.1223,
      "step": 2063
    },
    {
      "epoch": 0.4742647058823529,
      "grad_norm": 1.281140923500061,
      "learning_rate": 9.356595744680851e-06,
      "loss": 0.1361,
      "step": 2064
    },
    {
      "epoch": 0.47449448529411764,
      "grad_norm": 1.2927582263946533,
      "learning_rate": 9.355744680851064e-06,
      "loss": 0.1713,
      "step": 2065
    },
    {
      "epoch": 0.47472426470588236,
      "grad_norm": 1.4471923112869263,
      "learning_rate": 9.354893617021277e-06,
      "loss": 0.1566,
      "step": 2066
    },
    {
      "epoch": 0.4749540441176471,
      "grad_norm": 1.5726321935653687,
      "learning_rate": 9.35404255319149e-06,
      "loss": 0.147,
      "step": 2067
    },
    {
      "epoch": 0.47518382352941174,
      "grad_norm": 1.0623934268951416,
      "learning_rate": 9.353191489361702e-06,
      "loss": 0.1511,
      "step": 2068
    },
    {
      "epoch": 0.47541360294117646,
      "grad_norm": 1.3679500818252563,
      "learning_rate": 9.352340425531915e-06,
      "loss": 0.1611,
      "step": 2069
    },
    {
      "epoch": 0.4756433823529412,
      "grad_norm": 1.7893356084823608,
      "learning_rate": 9.351489361702128e-06,
      "loss": 0.1677,
      "step": 2070
    },
    {
      "epoch": 0.4758731617647059,
      "grad_norm": 1.4075605869293213,
      "learning_rate": 9.350638297872342e-06,
      "loss": 0.1421,
      "step": 2071
    },
    {
      "epoch": 0.47610294117647056,
      "grad_norm": 1.2743159532546997,
      "learning_rate": 9.349787234042555e-06,
      "loss": 0.1302,
      "step": 2072
    },
    {
      "epoch": 0.4763327205882353,
      "grad_norm": 1.253635287284851,
      "learning_rate": 9.348936170212766e-06,
      "loss": 0.1727,
      "step": 2073
    },
    {
      "epoch": 0.4765625,
      "grad_norm": 1.069717288017273,
      "learning_rate": 9.34808510638298e-06,
      "loss": 0.1255,
      "step": 2074
    },
    {
      "epoch": 0.4767922794117647,
      "grad_norm": 1.3715065717697144,
      "learning_rate": 9.347234042553193e-06,
      "loss": 0.1638,
      "step": 2075
    },
    {
      "epoch": 0.47702205882352944,
      "grad_norm": 1.5042388439178467,
      "learning_rate": 9.346382978723406e-06,
      "loss": 0.1386,
      "step": 2076
    },
    {
      "epoch": 0.4772518382352941,
      "grad_norm": 1.3143671751022339,
      "learning_rate": 9.345531914893617e-06,
      "loss": 0.14,
      "step": 2077
    },
    {
      "epoch": 0.4774816176470588,
      "grad_norm": 1.0862560272216797,
      "learning_rate": 9.34468085106383e-06,
      "loss": 0.1095,
      "step": 2078
    },
    {
      "epoch": 0.47771139705882354,
      "grad_norm": 1.248430848121643,
      "learning_rate": 9.343829787234044e-06,
      "loss": 0.1631,
      "step": 2079
    },
    {
      "epoch": 0.47794117647058826,
      "grad_norm": 1.426417589187622,
      "learning_rate": 9.342978723404255e-06,
      "loss": 0.1729,
      "step": 2080
    },
    {
      "epoch": 0.4781709558823529,
      "grad_norm": 1.1685235500335693,
      "learning_rate": 9.34212765957447e-06,
      "loss": 0.1386,
      "step": 2081
    },
    {
      "epoch": 0.47840073529411764,
      "grad_norm": 1.672390103340149,
      "learning_rate": 9.341276595744681e-06,
      "loss": 0.167,
      "step": 2082
    },
    {
      "epoch": 0.47863051470588236,
      "grad_norm": 1.28195059299469,
      "learning_rate": 9.340425531914895e-06,
      "loss": 0.1393,
      "step": 2083
    },
    {
      "epoch": 0.4788602941176471,
      "grad_norm": 1.5880478620529175,
      "learning_rate": 9.339574468085108e-06,
      "loss": 0.1498,
      "step": 2084
    },
    {
      "epoch": 0.47909007352941174,
      "grad_norm": 1.195162057876587,
      "learning_rate": 9.33872340425532e-06,
      "loss": 0.1606,
      "step": 2085
    },
    {
      "epoch": 0.47931985294117646,
      "grad_norm": 1.1880258321762085,
      "learning_rate": 9.337872340425532e-06,
      "loss": 0.1413,
      "step": 2086
    },
    {
      "epoch": 0.4795496323529412,
      "grad_norm": 1.355636477470398,
      "learning_rate": 9.337021276595746e-06,
      "loss": 0.1293,
      "step": 2087
    },
    {
      "epoch": 0.4797794117647059,
      "grad_norm": 1.2894805669784546,
      "learning_rate": 9.336170212765959e-06,
      "loss": 0.1459,
      "step": 2088
    },
    {
      "epoch": 0.48000919117647056,
      "grad_norm": 1.6134803295135498,
      "learning_rate": 9.33531914893617e-06,
      "loss": 0.1679,
      "step": 2089
    },
    {
      "epoch": 0.4802389705882353,
      "grad_norm": 1.267196774482727,
      "learning_rate": 9.334468085106383e-06,
      "loss": 0.146,
      "step": 2090
    },
    {
      "epoch": 0.48046875,
      "grad_norm": 1.1496866941452026,
      "learning_rate": 9.333617021276597e-06,
      "loss": 0.1717,
      "step": 2091
    },
    {
      "epoch": 0.4806985294117647,
      "grad_norm": 1.3931641578674316,
      "learning_rate": 9.332765957446808e-06,
      "loss": 0.1822,
      "step": 2092
    },
    {
      "epoch": 0.48092830882352944,
      "grad_norm": 1.39577054977417,
      "learning_rate": 9.331914893617023e-06,
      "loss": 0.1559,
      "step": 2093
    },
    {
      "epoch": 0.4811580882352941,
      "grad_norm": 0.9747461080551147,
      "learning_rate": 9.331063829787234e-06,
      "loss": 0.1002,
      "step": 2094
    },
    {
      "epoch": 0.4813878676470588,
      "grad_norm": 1.4007786512374878,
      "learning_rate": 9.330212765957448e-06,
      "loss": 0.1272,
      "step": 2095
    },
    {
      "epoch": 0.48161764705882354,
      "grad_norm": 1.284407377243042,
      "learning_rate": 9.32936170212766e-06,
      "loss": 0.1621,
      "step": 2096
    },
    {
      "epoch": 0.48184742647058826,
      "grad_norm": 1.3462491035461426,
      "learning_rate": 9.328510638297872e-06,
      "loss": 0.1577,
      "step": 2097
    },
    {
      "epoch": 0.4820772058823529,
      "grad_norm": 1.0227534770965576,
      "learning_rate": 9.327659574468085e-06,
      "loss": 0.1145,
      "step": 2098
    },
    {
      "epoch": 0.48230698529411764,
      "grad_norm": 1.173134207725525,
      "learning_rate": 9.326808510638299e-06,
      "loss": 0.1363,
      "step": 2099
    },
    {
      "epoch": 0.48253676470588236,
      "grad_norm": 2.0165772438049316,
      "learning_rate": 9.325957446808512e-06,
      "loss": 0.1896,
      "step": 2100
    },
    {
      "epoch": 0.4827665441176471,
      "grad_norm": 1.2295395135879517,
      "learning_rate": 9.325106382978723e-06,
      "loss": 0.1312,
      "step": 2101
    },
    {
      "epoch": 0.48299632352941174,
      "grad_norm": 1.033511996269226,
      "learning_rate": 9.324255319148936e-06,
      "loss": 0.1449,
      "step": 2102
    },
    {
      "epoch": 0.48322610294117646,
      "grad_norm": 1.3320263624191284,
      "learning_rate": 9.32340425531915e-06,
      "loss": 0.156,
      "step": 2103
    },
    {
      "epoch": 0.4834558823529412,
      "grad_norm": 1.4835165739059448,
      "learning_rate": 9.322553191489363e-06,
      "loss": 0.1865,
      "step": 2104
    },
    {
      "epoch": 0.4836856617647059,
      "grad_norm": 1.5807840824127197,
      "learning_rate": 9.321702127659576e-06,
      "loss": 0.1389,
      "step": 2105
    },
    {
      "epoch": 0.48391544117647056,
      "grad_norm": 1.22502863407135,
      "learning_rate": 9.320851063829787e-06,
      "loss": 0.1233,
      "step": 2106
    },
    {
      "epoch": 0.4841452205882353,
      "grad_norm": 1.101669430732727,
      "learning_rate": 9.32e-06,
      "loss": 0.14,
      "step": 2107
    },
    {
      "epoch": 0.484375,
      "grad_norm": 1.2548573017120361,
      "learning_rate": 9.319148936170214e-06,
      "loss": 0.1647,
      "step": 2108
    },
    {
      "epoch": 0.4846047794117647,
      "grad_norm": 1.3713093996047974,
      "learning_rate": 9.318297872340425e-06,
      "loss": 0.1348,
      "step": 2109
    },
    {
      "epoch": 0.48483455882352944,
      "grad_norm": 1.432320237159729,
      "learning_rate": 9.31744680851064e-06,
      "loss": 0.1957,
      "step": 2110
    },
    {
      "epoch": 0.4850643382352941,
      "grad_norm": 1.228274941444397,
      "learning_rate": 9.316595744680852e-06,
      "loss": 0.116,
      "step": 2111
    },
    {
      "epoch": 0.4852941176470588,
      "grad_norm": 1.353367567062378,
      "learning_rate": 9.315744680851065e-06,
      "loss": 0.1369,
      "step": 2112
    },
    {
      "epoch": 0.48552389705882354,
      "grad_norm": 1.2149888277053833,
      "learning_rate": 9.314893617021278e-06,
      "loss": 0.1912,
      "step": 2113
    },
    {
      "epoch": 0.48575367647058826,
      "grad_norm": 1.3060489892959595,
      "learning_rate": 9.31404255319149e-06,
      "loss": 0.1823,
      "step": 2114
    },
    {
      "epoch": 0.4859834558823529,
      "grad_norm": 1.2046973705291748,
      "learning_rate": 9.313191489361703e-06,
      "loss": 0.1307,
      "step": 2115
    },
    {
      "epoch": 0.48621323529411764,
      "grad_norm": 1.0104212760925293,
      "learning_rate": 9.312340425531916e-06,
      "loss": 0.1281,
      "step": 2116
    },
    {
      "epoch": 0.48644301470588236,
      "grad_norm": 1.2069517374038696,
      "learning_rate": 9.311489361702129e-06,
      "loss": 0.1534,
      "step": 2117
    },
    {
      "epoch": 0.4866727941176471,
      "grad_norm": 1.1535717248916626,
      "learning_rate": 9.31063829787234e-06,
      "loss": 0.1212,
      "step": 2118
    },
    {
      "epoch": 0.48690257352941174,
      "grad_norm": 2.0770280361175537,
      "learning_rate": 9.309787234042554e-06,
      "loss": 0.2155,
      "step": 2119
    },
    {
      "epoch": 0.48713235294117646,
      "grad_norm": 1.0635859966278076,
      "learning_rate": 9.308936170212767e-06,
      "loss": 0.1408,
      "step": 2120
    },
    {
      "epoch": 0.4873621323529412,
      "grad_norm": 1.5208441019058228,
      "learning_rate": 9.30808510638298e-06,
      "loss": 0.1561,
      "step": 2121
    },
    {
      "epoch": 0.4875919117647059,
      "grad_norm": 1.2485032081604004,
      "learning_rate": 9.307234042553193e-06,
      "loss": 0.1412,
      "step": 2122
    },
    {
      "epoch": 0.48782169117647056,
      "grad_norm": 1.412941336631775,
      "learning_rate": 9.306382978723405e-06,
      "loss": 0.1315,
      "step": 2123
    },
    {
      "epoch": 0.4880514705882353,
      "grad_norm": 1.7407654523849487,
      "learning_rate": 9.305531914893618e-06,
      "loss": 0.2215,
      "step": 2124
    },
    {
      "epoch": 0.48828125,
      "grad_norm": 1.3078317642211914,
      "learning_rate": 9.30468085106383e-06,
      "loss": 0.1353,
      "step": 2125
    },
    {
      "epoch": 0.4885110294117647,
      "grad_norm": 1.119107961654663,
      "learning_rate": 9.303829787234044e-06,
      "loss": 0.15,
      "step": 2126
    },
    {
      "epoch": 0.48874080882352944,
      "grad_norm": 1.2652695178985596,
      "learning_rate": 9.302978723404255e-06,
      "loss": 0.1598,
      "step": 2127
    },
    {
      "epoch": 0.4889705882352941,
      "grad_norm": 1.0100841522216797,
      "learning_rate": 9.302127659574469e-06,
      "loss": 0.1251,
      "step": 2128
    },
    {
      "epoch": 0.4892003676470588,
      "grad_norm": 1.1889342069625854,
      "learning_rate": 9.301276595744682e-06,
      "loss": 0.1705,
      "step": 2129
    },
    {
      "epoch": 0.48943014705882354,
      "grad_norm": 1.2944637537002563,
      "learning_rate": 9.300425531914893e-06,
      "loss": 0.19,
      "step": 2130
    },
    {
      "epoch": 0.48965992647058826,
      "grad_norm": 1.6494932174682617,
      "learning_rate": 9.299574468085108e-06,
      "loss": 0.1486,
      "step": 2131
    },
    {
      "epoch": 0.4898897058823529,
      "grad_norm": 1.1962701082229614,
      "learning_rate": 9.29872340425532e-06,
      "loss": 0.1371,
      "step": 2132
    },
    {
      "epoch": 0.49011948529411764,
      "grad_norm": 1.3201063871383667,
      "learning_rate": 9.297872340425533e-06,
      "loss": 0.1475,
      "step": 2133
    },
    {
      "epoch": 0.49034926470588236,
      "grad_norm": 1.2912964820861816,
      "learning_rate": 9.297021276595746e-06,
      "loss": 0.1666,
      "step": 2134
    },
    {
      "epoch": 0.4905790441176471,
      "grad_norm": 1.4988174438476562,
      "learning_rate": 9.296170212765957e-06,
      "loss": 0.1405,
      "step": 2135
    },
    {
      "epoch": 0.49080882352941174,
      "grad_norm": 1.0216140747070312,
      "learning_rate": 9.29531914893617e-06,
      "loss": 0.1545,
      "step": 2136
    },
    {
      "epoch": 0.49103860294117646,
      "grad_norm": 1.0156445503234863,
      "learning_rate": 9.294468085106384e-06,
      "loss": 0.1048,
      "step": 2137
    },
    {
      "epoch": 0.4912683823529412,
      "grad_norm": 1.1392611265182495,
      "learning_rate": 9.293617021276597e-06,
      "loss": 0.1529,
      "step": 2138
    },
    {
      "epoch": 0.4914981617647059,
      "grad_norm": 1.0214364528656006,
      "learning_rate": 9.292765957446808e-06,
      "loss": 0.1382,
      "step": 2139
    },
    {
      "epoch": 0.49172794117647056,
      "grad_norm": 1.12943696975708,
      "learning_rate": 9.291914893617022e-06,
      "loss": 0.1505,
      "step": 2140
    },
    {
      "epoch": 0.4919577205882353,
      "grad_norm": 1.2945584058761597,
      "learning_rate": 9.291063829787235e-06,
      "loss": 0.1582,
      "step": 2141
    },
    {
      "epoch": 0.4921875,
      "grad_norm": 1.762556791305542,
      "learning_rate": 9.290212765957446e-06,
      "loss": 0.2353,
      "step": 2142
    },
    {
      "epoch": 0.4924172794117647,
      "grad_norm": 1.6416536569595337,
      "learning_rate": 9.289361702127661e-06,
      "loss": 0.1738,
      "step": 2143
    },
    {
      "epoch": 0.49264705882352944,
      "grad_norm": 1.4353911876678467,
      "learning_rate": 9.288510638297873e-06,
      "loss": 0.1541,
      "step": 2144
    },
    {
      "epoch": 0.4928768382352941,
      "grad_norm": 1.5139214992523193,
      "learning_rate": 9.287659574468086e-06,
      "loss": 0.1511,
      "step": 2145
    },
    {
      "epoch": 0.4931066176470588,
      "grad_norm": 1.6051901578903198,
      "learning_rate": 9.286808510638299e-06,
      "loss": 0.1303,
      "step": 2146
    },
    {
      "epoch": 0.49333639705882354,
      "grad_norm": 1.0468107461929321,
      "learning_rate": 9.28595744680851e-06,
      "loss": 0.1182,
      "step": 2147
    },
    {
      "epoch": 0.49356617647058826,
      "grad_norm": 1.7017745971679688,
      "learning_rate": 9.285106382978725e-06,
      "loss": 0.148,
      "step": 2148
    },
    {
      "epoch": 0.4937959558823529,
      "grad_norm": 1.178981900215149,
      "learning_rate": 9.284255319148937e-06,
      "loss": 0.1279,
      "step": 2149
    },
    {
      "epoch": 0.49402573529411764,
      "grad_norm": 1.1311434507369995,
      "learning_rate": 9.28340425531915e-06,
      "loss": 0.1566,
      "step": 2150
    },
    {
      "epoch": 0.49425551470588236,
      "grad_norm": 1.1596394777297974,
      "learning_rate": 9.282553191489363e-06,
      "loss": 0.1095,
      "step": 2151
    },
    {
      "epoch": 0.4944852941176471,
      "grad_norm": 1.2921535968780518,
      "learning_rate": 9.281702127659575e-06,
      "loss": 0.1353,
      "step": 2152
    },
    {
      "epoch": 0.49471507352941174,
      "grad_norm": 1.353683590888977,
      "learning_rate": 9.280851063829788e-06,
      "loss": 0.1199,
      "step": 2153
    },
    {
      "epoch": 0.49494485294117646,
      "grad_norm": 1.2719167470932007,
      "learning_rate": 9.280000000000001e-06,
      "loss": 0.1693,
      "step": 2154
    },
    {
      "epoch": 0.4951746323529412,
      "grad_norm": 1.1747488975524902,
      "learning_rate": 9.279148936170214e-06,
      "loss": 0.1373,
      "step": 2155
    },
    {
      "epoch": 0.4954044117647059,
      "grad_norm": 1.206708312034607,
      "learning_rate": 9.278297872340426e-06,
      "loss": 0.1205,
      "step": 2156
    },
    {
      "epoch": 0.49563419117647056,
      "grad_norm": 1.1361308097839355,
      "learning_rate": 9.277446808510639e-06,
      "loss": 0.1257,
      "step": 2157
    },
    {
      "epoch": 0.4958639705882353,
      "grad_norm": 1.4380929470062256,
      "learning_rate": 9.276595744680852e-06,
      "loss": 0.137,
      "step": 2158
    },
    {
      "epoch": 0.49609375,
      "grad_norm": 1.6880351305007935,
      "learning_rate": 9.275744680851065e-06,
      "loss": 0.2068,
      "step": 2159
    },
    {
      "epoch": 0.4963235294117647,
      "grad_norm": 1.1119287014007568,
      "learning_rate": 9.274893617021278e-06,
      "loss": 0.1493,
      "step": 2160
    },
    {
      "epoch": 0.49655330882352944,
      "grad_norm": 1.5414170026779175,
      "learning_rate": 9.27404255319149e-06,
      "loss": 0.1871,
      "step": 2161
    },
    {
      "epoch": 0.4967830882352941,
      "grad_norm": 1.6116430759429932,
      "learning_rate": 9.273191489361703e-06,
      "loss": 0.1515,
      "step": 2162
    },
    {
      "epoch": 0.4970128676470588,
      "grad_norm": 1.6353039741516113,
      "learning_rate": 9.272340425531916e-06,
      "loss": 0.1575,
      "step": 2163
    },
    {
      "epoch": 0.49724264705882354,
      "grad_norm": 1.4955471754074097,
      "learning_rate": 9.27148936170213e-06,
      "loss": 0.1399,
      "step": 2164
    },
    {
      "epoch": 0.49747242647058826,
      "grad_norm": 1.3629169464111328,
      "learning_rate": 9.27063829787234e-06,
      "loss": 0.1617,
      "step": 2165
    },
    {
      "epoch": 0.4977022058823529,
      "grad_norm": 1.2727166414260864,
      "learning_rate": 9.269787234042554e-06,
      "loss": 0.1367,
      "step": 2166
    },
    {
      "epoch": 0.49793198529411764,
      "grad_norm": 1.559273362159729,
      "learning_rate": 9.268936170212767e-06,
      "loss": 0.1738,
      "step": 2167
    },
    {
      "epoch": 0.49816176470588236,
      "grad_norm": 1.2769917249679565,
      "learning_rate": 9.268085106382979e-06,
      "loss": 0.1495,
      "step": 2168
    },
    {
      "epoch": 0.4983915441176471,
      "grad_norm": 1.0356615781784058,
      "learning_rate": 9.267234042553193e-06,
      "loss": 0.1383,
      "step": 2169
    },
    {
      "epoch": 0.49862132352941174,
      "grad_norm": 1.1387430429458618,
      "learning_rate": 9.266382978723405e-06,
      "loss": 0.1419,
      "step": 2170
    },
    {
      "epoch": 0.49885110294117646,
      "grad_norm": 1.4847599267959595,
      "learning_rate": 9.265531914893618e-06,
      "loss": 0.1891,
      "step": 2171
    },
    {
      "epoch": 0.4990808823529412,
      "grad_norm": 1.8630752563476562,
      "learning_rate": 9.264680851063831e-06,
      "loss": 0.1695,
      "step": 2172
    },
    {
      "epoch": 0.4993106617647059,
      "grad_norm": 1.255843162536621,
      "learning_rate": 9.263829787234043e-06,
      "loss": 0.1382,
      "step": 2173
    },
    {
      "epoch": 0.49954044117647056,
      "grad_norm": 1.0425262451171875,
      "learning_rate": 9.262978723404256e-06,
      "loss": 0.1222,
      "step": 2174
    },
    {
      "epoch": 0.4997702205882353,
      "grad_norm": 1.2963981628417969,
      "learning_rate": 9.262127659574469e-06,
      "loss": 0.1645,
      "step": 2175
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.9617617130279541,
      "learning_rate": 9.261276595744682e-06,
      "loss": 0.1243,
      "step": 2176
    },
    {
      "epoch": 0.5002297794117647,
      "grad_norm": 1.242375135421753,
      "learning_rate": 9.260425531914894e-06,
      "loss": 0.1824,
      "step": 2177
    },
    {
      "epoch": 0.5004595588235294,
      "grad_norm": 1.268239974975586,
      "learning_rate": 9.259574468085107e-06,
      "loss": 0.1449,
      "step": 2178
    },
    {
      "epoch": 0.5006893382352942,
      "grad_norm": 1.3899966478347778,
      "learning_rate": 9.25872340425532e-06,
      "loss": 0.1398,
      "step": 2179
    },
    {
      "epoch": 0.5009191176470589,
      "grad_norm": 1.375997543334961,
      "learning_rate": 9.257872340425532e-06,
      "loss": 0.1214,
      "step": 2180
    },
    {
      "epoch": 0.5011488970588235,
      "grad_norm": 1.1633694171905518,
      "learning_rate": 9.257021276595746e-06,
      "loss": 0.1451,
      "step": 2181
    },
    {
      "epoch": 0.5013786764705882,
      "grad_norm": 1.3398661613464355,
      "learning_rate": 9.256170212765958e-06,
      "loss": 0.143,
      "step": 2182
    },
    {
      "epoch": 0.5016084558823529,
      "grad_norm": 1.3413761854171753,
      "learning_rate": 9.255319148936171e-06,
      "loss": 0.1566,
      "step": 2183
    },
    {
      "epoch": 0.5018382352941176,
      "grad_norm": 0.9554640054702759,
      "learning_rate": 9.254468085106384e-06,
      "loss": 0.1175,
      "step": 2184
    },
    {
      "epoch": 0.5020680147058824,
      "grad_norm": 1.1374833583831787,
      "learning_rate": 9.253617021276596e-06,
      "loss": 0.1619,
      "step": 2185
    },
    {
      "epoch": 0.5022977941176471,
      "grad_norm": 1.182289481163025,
      "learning_rate": 9.252765957446809e-06,
      "loss": 0.1458,
      "step": 2186
    },
    {
      "epoch": 0.5025275735294118,
      "grad_norm": 1.6848843097686768,
      "learning_rate": 9.251914893617022e-06,
      "loss": 0.1609,
      "step": 2187
    },
    {
      "epoch": 0.5027573529411765,
      "grad_norm": 1.4522380828857422,
      "learning_rate": 9.251063829787235e-06,
      "loss": 0.1403,
      "step": 2188
    },
    {
      "epoch": 0.5029871323529411,
      "grad_norm": 1.3455969095230103,
      "learning_rate": 9.250212765957448e-06,
      "loss": 0.1454,
      "step": 2189
    },
    {
      "epoch": 0.5032169117647058,
      "grad_norm": 1.0304226875305176,
      "learning_rate": 9.24936170212766e-06,
      "loss": 0.119,
      "step": 2190
    },
    {
      "epoch": 0.5034466911764706,
      "grad_norm": 1.7990020513534546,
      "learning_rate": 9.248510638297873e-06,
      "loss": 0.1578,
      "step": 2191
    },
    {
      "epoch": 0.5036764705882353,
      "grad_norm": 1.1830145120620728,
      "learning_rate": 9.247659574468086e-06,
      "loss": 0.124,
      "step": 2192
    },
    {
      "epoch": 0.50390625,
      "grad_norm": 1.5830879211425781,
      "learning_rate": 9.2468085106383e-06,
      "loss": 0.1591,
      "step": 2193
    },
    {
      "epoch": 0.5041360294117647,
      "grad_norm": 1.3392874002456665,
      "learning_rate": 9.24595744680851e-06,
      "loss": 0.1382,
      "step": 2194
    },
    {
      "epoch": 0.5043658088235294,
      "grad_norm": 1.313633918762207,
      "learning_rate": 9.245106382978724e-06,
      "loss": 0.1183,
      "step": 2195
    },
    {
      "epoch": 0.5045955882352942,
      "grad_norm": 1.0888433456420898,
      "learning_rate": 9.244255319148937e-06,
      "loss": 0.1062,
      "step": 2196
    },
    {
      "epoch": 0.5048253676470589,
      "grad_norm": 1.5722874402999878,
      "learning_rate": 9.243404255319149e-06,
      "loss": 0.1759,
      "step": 2197
    },
    {
      "epoch": 0.5050551470588235,
      "grad_norm": 1.137056589126587,
      "learning_rate": 9.242553191489364e-06,
      "loss": 0.1279,
      "step": 2198
    },
    {
      "epoch": 0.5052849264705882,
      "grad_norm": 1.6603885889053345,
      "learning_rate": 9.241702127659575e-06,
      "loss": 0.1753,
      "step": 2199
    },
    {
      "epoch": 0.5055147058823529,
      "grad_norm": 1.3016525506973267,
      "learning_rate": 9.240851063829788e-06,
      "loss": 0.115,
      "step": 2200
    },
    {
      "epoch": 0.5057444852941176,
      "grad_norm": 1.2789902687072754,
      "learning_rate": 9.240000000000001e-06,
      "loss": 0.1484,
      "step": 2201
    },
    {
      "epoch": 0.5059742647058824,
      "grad_norm": 1.4661003351211548,
      "learning_rate": 9.239148936170213e-06,
      "loss": 0.1572,
      "step": 2202
    },
    {
      "epoch": 0.5062040441176471,
      "grad_norm": 1.2382864952087402,
      "learning_rate": 9.238297872340426e-06,
      "loss": 0.0926,
      "step": 2203
    },
    {
      "epoch": 0.5064338235294118,
      "grad_norm": 1.2716734409332275,
      "learning_rate": 9.237446808510639e-06,
      "loss": 0.106,
      "step": 2204
    },
    {
      "epoch": 0.5066636029411765,
      "grad_norm": 0.9985796809196472,
      "learning_rate": 9.236595744680852e-06,
      "loss": 0.1639,
      "step": 2205
    },
    {
      "epoch": 0.5068933823529411,
      "grad_norm": 1.3398056030273438,
      "learning_rate": 9.235744680851064e-06,
      "loss": 0.1626,
      "step": 2206
    },
    {
      "epoch": 0.5071231617647058,
      "grad_norm": 1.6406978368759155,
      "learning_rate": 9.234893617021277e-06,
      "loss": 0.2051,
      "step": 2207
    },
    {
      "epoch": 0.5073529411764706,
      "grad_norm": 1.3787463903427124,
      "learning_rate": 9.23404255319149e-06,
      "loss": 0.1528,
      "step": 2208
    },
    {
      "epoch": 0.5075827205882353,
      "grad_norm": 1.6066292524337769,
      "learning_rate": 9.233191489361703e-06,
      "loss": 0.1424,
      "step": 2209
    },
    {
      "epoch": 0.5078125,
      "grad_norm": 1.093851089477539,
      "learning_rate": 9.232340425531916e-06,
      "loss": 0.1087,
      "step": 2210
    },
    {
      "epoch": 0.5080422794117647,
      "grad_norm": 1.153425931930542,
      "learning_rate": 9.231489361702128e-06,
      "loss": 0.1296,
      "step": 2211
    },
    {
      "epoch": 0.5082720588235294,
      "grad_norm": 1.792540192604065,
      "learning_rate": 9.230638297872341e-06,
      "loss": 0.1652,
      "step": 2212
    },
    {
      "epoch": 0.5085018382352942,
      "grad_norm": 1.2103322744369507,
      "learning_rate": 9.229787234042554e-06,
      "loss": 0.128,
      "step": 2213
    },
    {
      "epoch": 0.5087316176470589,
      "grad_norm": 1.6195027828216553,
      "learning_rate": 9.228936170212767e-06,
      "loss": 0.1432,
      "step": 2214
    },
    {
      "epoch": 0.5089613970588235,
      "grad_norm": 1.7206393480300903,
      "learning_rate": 9.228085106382979e-06,
      "loss": 0.1779,
      "step": 2215
    },
    {
      "epoch": 0.5091911764705882,
      "grad_norm": 1.5149444341659546,
      "learning_rate": 9.227234042553192e-06,
      "loss": 0.1804,
      "step": 2216
    },
    {
      "epoch": 0.5094209558823529,
      "grad_norm": 1.632536768913269,
      "learning_rate": 9.226382978723405e-06,
      "loss": 0.1798,
      "step": 2217
    },
    {
      "epoch": 0.5096507352941176,
      "grad_norm": 1.654500126838684,
      "learning_rate": 9.225531914893617e-06,
      "loss": 0.1438,
      "step": 2218
    },
    {
      "epoch": 0.5098805147058824,
      "grad_norm": 1.4192895889282227,
      "learning_rate": 9.224680851063832e-06,
      "loss": 0.1292,
      "step": 2219
    },
    {
      "epoch": 0.5101102941176471,
      "grad_norm": 1.0602593421936035,
      "learning_rate": 9.223829787234043e-06,
      "loss": 0.1331,
      "step": 2220
    },
    {
      "epoch": 0.5103400735294118,
      "grad_norm": 1.7035070657730103,
      "learning_rate": 9.222978723404256e-06,
      "loss": 0.1763,
      "step": 2221
    },
    {
      "epoch": 0.5105698529411765,
      "grad_norm": 1.461493730545044,
      "learning_rate": 9.22212765957447e-06,
      "loss": 0.1937,
      "step": 2222
    },
    {
      "epoch": 0.5107996323529411,
      "grad_norm": 1.3082200288772583,
      "learning_rate": 9.221276595744681e-06,
      "loss": 0.1546,
      "step": 2223
    },
    {
      "epoch": 0.5110294117647058,
      "grad_norm": 1.0342626571655273,
      "learning_rate": 9.220425531914894e-06,
      "loss": 0.1139,
      "step": 2224
    },
    {
      "epoch": 0.5112591911764706,
      "grad_norm": 1.4526289701461792,
      "learning_rate": 9.219574468085107e-06,
      "loss": 0.1786,
      "step": 2225
    },
    {
      "epoch": 0.5114889705882353,
      "grad_norm": 1.0726635456085205,
      "learning_rate": 9.21872340425532e-06,
      "loss": 0.1322,
      "step": 2226
    },
    {
      "epoch": 0.51171875,
      "grad_norm": 0.991081178188324,
      "learning_rate": 9.217872340425532e-06,
      "loss": 0.1156,
      "step": 2227
    },
    {
      "epoch": 0.5119485294117647,
      "grad_norm": 1.0710577964782715,
      "learning_rate": 9.217021276595745e-06,
      "loss": 0.141,
      "step": 2228
    },
    {
      "epoch": 0.5121783088235294,
      "grad_norm": 1.6562390327453613,
      "learning_rate": 9.216170212765958e-06,
      "loss": 0.233,
      "step": 2229
    },
    {
      "epoch": 0.5124080882352942,
      "grad_norm": 1.2389572858810425,
      "learning_rate": 9.215319148936171e-06,
      "loss": 0.156,
      "step": 2230
    },
    {
      "epoch": 0.5126378676470589,
      "grad_norm": 1.0474663972854614,
      "learning_rate": 9.214468085106385e-06,
      "loss": 0.1236,
      "step": 2231
    },
    {
      "epoch": 0.5128676470588235,
      "grad_norm": 1.042680025100708,
      "learning_rate": 9.213617021276596e-06,
      "loss": 0.1422,
      "step": 2232
    },
    {
      "epoch": 0.5130974264705882,
      "grad_norm": 1.356370210647583,
      "learning_rate": 9.21276595744681e-06,
      "loss": 0.1437,
      "step": 2233
    },
    {
      "epoch": 0.5133272058823529,
      "grad_norm": 1.2774925231933594,
      "learning_rate": 9.211914893617022e-06,
      "loss": 0.11,
      "step": 2234
    },
    {
      "epoch": 0.5135569852941176,
      "grad_norm": 1.5244276523590088,
      "learning_rate": 9.211063829787234e-06,
      "loss": 0.2059,
      "step": 2235
    },
    {
      "epoch": 0.5137867647058824,
      "grad_norm": 1.266894817352295,
      "learning_rate": 9.210212765957449e-06,
      "loss": 0.1688,
      "step": 2236
    },
    {
      "epoch": 0.5140165441176471,
      "grad_norm": 1.295554757118225,
      "learning_rate": 9.20936170212766e-06,
      "loss": 0.1541,
      "step": 2237
    },
    {
      "epoch": 0.5142463235294118,
      "grad_norm": 1.5364567041397095,
      "learning_rate": 9.208510638297873e-06,
      "loss": 0.2039,
      "step": 2238
    },
    {
      "epoch": 0.5144761029411765,
      "grad_norm": 1.333173394203186,
      "learning_rate": 9.207659574468087e-06,
      "loss": 0.14,
      "step": 2239
    },
    {
      "epoch": 0.5147058823529411,
      "grad_norm": 1.2705042362213135,
      "learning_rate": 9.206808510638298e-06,
      "loss": 0.1412,
      "step": 2240
    },
    {
      "epoch": 0.5149356617647058,
      "grad_norm": 1.2147235870361328,
      "learning_rate": 9.205957446808511e-06,
      "loss": 0.165,
      "step": 2241
    },
    {
      "epoch": 0.5151654411764706,
      "grad_norm": 1.423140287399292,
      "learning_rate": 9.205106382978724e-06,
      "loss": 0.1731,
      "step": 2242
    },
    {
      "epoch": 0.5153952205882353,
      "grad_norm": 1.1780602931976318,
      "learning_rate": 9.204255319148938e-06,
      "loss": 0.1426,
      "step": 2243
    },
    {
      "epoch": 0.515625,
      "grad_norm": 1.4468810558319092,
      "learning_rate": 9.203404255319149e-06,
      "loss": 0.1885,
      "step": 2244
    },
    {
      "epoch": 0.5158547794117647,
      "grad_norm": 1.189319372177124,
      "learning_rate": 9.202553191489362e-06,
      "loss": 0.1395,
      "step": 2245
    },
    {
      "epoch": 0.5160845588235294,
      "grad_norm": 1.047582983970642,
      "learning_rate": 9.201702127659575e-06,
      "loss": 0.1364,
      "step": 2246
    },
    {
      "epoch": 0.5163143382352942,
      "grad_norm": 1.0288755893707275,
      "learning_rate": 9.200851063829787e-06,
      "loss": 0.1049,
      "step": 2247
    },
    {
      "epoch": 0.5165441176470589,
      "grad_norm": 1.0935746431350708,
      "learning_rate": 9.200000000000002e-06,
      "loss": 0.1093,
      "step": 2248
    },
    {
      "epoch": 0.5167738970588235,
      "grad_norm": 1.274582028388977,
      "learning_rate": 9.199148936170213e-06,
      "loss": 0.1522,
      "step": 2249
    },
    {
      "epoch": 0.5170036764705882,
      "grad_norm": 1.360145926475525,
      "learning_rate": 9.198297872340426e-06,
      "loss": 0.1579,
      "step": 2250
    },
    {
      "epoch": 0.5172334558823529,
      "grad_norm": 1.0685153007507324,
      "learning_rate": 9.19744680851064e-06,
      "loss": 0.119,
      "step": 2251
    },
    {
      "epoch": 0.5174632352941176,
      "grad_norm": 1.2221955060958862,
      "learning_rate": 9.196595744680851e-06,
      "loss": 0.1051,
      "step": 2252
    },
    {
      "epoch": 0.5176930147058824,
      "grad_norm": 1.4521470069885254,
      "learning_rate": 9.195744680851064e-06,
      "loss": 0.1579,
      "step": 2253
    },
    {
      "epoch": 0.5179227941176471,
      "grad_norm": 1.243666410446167,
      "learning_rate": 9.194893617021277e-06,
      "loss": 0.1646,
      "step": 2254
    },
    {
      "epoch": 0.5181525735294118,
      "grad_norm": 1.1315362453460693,
      "learning_rate": 9.19404255319149e-06,
      "loss": 0.1111,
      "step": 2255
    },
    {
      "epoch": 0.5183823529411765,
      "grad_norm": 1.215425968170166,
      "learning_rate": 9.193191489361702e-06,
      "loss": 0.1467,
      "step": 2256
    },
    {
      "epoch": 0.5186121323529411,
      "grad_norm": 1.377310872077942,
      "learning_rate": 9.192340425531915e-06,
      "loss": 0.0948,
      "step": 2257
    },
    {
      "epoch": 0.5188419117647058,
      "grad_norm": 1.2140603065490723,
      "learning_rate": 9.191489361702128e-06,
      "loss": 0.1312,
      "step": 2258
    },
    {
      "epoch": 0.5190716911764706,
      "grad_norm": 1.0779714584350586,
      "learning_rate": 9.190638297872341e-06,
      "loss": 0.1249,
      "step": 2259
    },
    {
      "epoch": 0.5193014705882353,
      "grad_norm": 1.757306456565857,
      "learning_rate": 9.189787234042555e-06,
      "loss": 0.1695,
      "step": 2260
    },
    {
      "epoch": 0.51953125,
      "grad_norm": 1.1467217206954956,
      "learning_rate": 9.188936170212766e-06,
      "loss": 0.1342,
      "step": 2261
    },
    {
      "epoch": 0.5197610294117647,
      "grad_norm": 1.4686259031295776,
      "learning_rate": 9.18808510638298e-06,
      "loss": 0.196,
      "step": 2262
    },
    {
      "epoch": 0.5199908088235294,
      "grad_norm": 1.3325716257095337,
      "learning_rate": 9.187234042553192e-06,
      "loss": 0.1819,
      "step": 2263
    },
    {
      "epoch": 0.5202205882352942,
      "grad_norm": 1.1111140251159668,
      "learning_rate": 9.186382978723406e-06,
      "loss": 0.1499,
      "step": 2264
    },
    {
      "epoch": 0.5204503676470589,
      "grad_norm": 1.4189170598983765,
      "learning_rate": 9.185531914893617e-06,
      "loss": 0.1104,
      "step": 2265
    },
    {
      "epoch": 0.5206801470588235,
      "grad_norm": 1.1749801635742188,
      "learning_rate": 9.18468085106383e-06,
      "loss": 0.1675,
      "step": 2266
    },
    {
      "epoch": 0.5209099264705882,
      "grad_norm": 1.3828017711639404,
      "learning_rate": 9.183829787234043e-06,
      "loss": 0.1239,
      "step": 2267
    },
    {
      "epoch": 0.5211397058823529,
      "grad_norm": 1.43916916847229,
      "learning_rate": 9.182978723404255e-06,
      "loss": 0.1721,
      "step": 2268
    },
    {
      "epoch": 0.5213694852941176,
      "grad_norm": 1.4666433334350586,
      "learning_rate": 9.18212765957447e-06,
      "loss": 0.1871,
      "step": 2269
    },
    {
      "epoch": 0.5215992647058824,
      "grad_norm": 1.1556837558746338,
      "learning_rate": 9.181276595744681e-06,
      "loss": 0.1425,
      "step": 2270
    },
    {
      "epoch": 0.5218290441176471,
      "grad_norm": 1.459081768989563,
      "learning_rate": 9.180425531914894e-06,
      "loss": 0.1371,
      "step": 2271
    },
    {
      "epoch": 0.5220588235294118,
      "grad_norm": 1.3127244710922241,
      "learning_rate": 9.179574468085108e-06,
      "loss": 0.1064,
      "step": 2272
    },
    {
      "epoch": 0.5222886029411765,
      "grad_norm": 1.2875717878341675,
      "learning_rate": 9.178723404255319e-06,
      "loss": 0.141,
      "step": 2273
    },
    {
      "epoch": 0.5225183823529411,
      "grad_norm": 1.6068166494369507,
      "learning_rate": 9.177872340425534e-06,
      "loss": 0.1398,
      "step": 2274
    },
    {
      "epoch": 0.5227481617647058,
      "grad_norm": 1.2003819942474365,
      "learning_rate": 9.177021276595745e-06,
      "loss": 0.1246,
      "step": 2275
    },
    {
      "epoch": 0.5229779411764706,
      "grad_norm": 1.6395562887191772,
      "learning_rate": 9.176170212765959e-06,
      "loss": 0.1706,
      "step": 2276
    },
    {
      "epoch": 0.5232077205882353,
      "grad_norm": 1.4582648277282715,
      "learning_rate": 9.175319148936172e-06,
      "loss": 0.1363,
      "step": 2277
    },
    {
      "epoch": 0.5234375,
      "grad_norm": 1.3702754974365234,
      "learning_rate": 9.174468085106383e-06,
      "loss": 0.1608,
      "step": 2278
    },
    {
      "epoch": 0.5236672794117647,
      "grad_norm": 1.1044739484786987,
      "learning_rate": 9.173617021276596e-06,
      "loss": 0.1405,
      "step": 2279
    },
    {
      "epoch": 0.5238970588235294,
      "grad_norm": 2.131964921951294,
      "learning_rate": 9.17276595744681e-06,
      "loss": 0.2342,
      "step": 2280
    },
    {
      "epoch": 0.5241268382352942,
      "grad_norm": 1.1501694917678833,
      "learning_rate": 9.171914893617023e-06,
      "loss": 0.1304,
      "step": 2281
    },
    {
      "epoch": 0.5243566176470589,
      "grad_norm": 1.004266381263733,
      "learning_rate": 9.171063829787234e-06,
      "loss": 0.1325,
      "step": 2282
    },
    {
      "epoch": 0.5245863970588235,
      "grad_norm": 1.1418533325195312,
      "learning_rate": 9.170212765957447e-06,
      "loss": 0.1027,
      "step": 2283
    },
    {
      "epoch": 0.5248161764705882,
      "grad_norm": 1.9461249113082886,
      "learning_rate": 9.16936170212766e-06,
      "loss": 0.2866,
      "step": 2284
    },
    {
      "epoch": 0.5250459558823529,
      "grad_norm": 1.1851797103881836,
      "learning_rate": 9.168510638297872e-06,
      "loss": 0.1535,
      "step": 2285
    },
    {
      "epoch": 0.5252757352941176,
      "grad_norm": 1.174607515335083,
      "learning_rate": 9.167659574468087e-06,
      "loss": 0.1519,
      "step": 2286
    },
    {
      "epoch": 0.5255055147058824,
      "grad_norm": 1.3574737310409546,
      "learning_rate": 9.166808510638298e-06,
      "loss": 0.1326,
      "step": 2287
    },
    {
      "epoch": 0.5257352941176471,
      "grad_norm": 1.4549565315246582,
      "learning_rate": 9.165957446808512e-06,
      "loss": 0.1461,
      "step": 2288
    },
    {
      "epoch": 0.5259650735294118,
      "grad_norm": 1.2054743766784668,
      "learning_rate": 9.165106382978725e-06,
      "loss": 0.1459,
      "step": 2289
    },
    {
      "epoch": 0.5261948529411765,
      "grad_norm": 1.458420991897583,
      "learning_rate": 9.164255319148936e-06,
      "loss": 0.1437,
      "step": 2290
    },
    {
      "epoch": 0.5264246323529411,
      "grad_norm": 1.4477519989013672,
      "learning_rate": 9.16340425531915e-06,
      "loss": 0.2114,
      "step": 2291
    },
    {
      "epoch": 0.5266544117647058,
      "grad_norm": 1.3026436567306519,
      "learning_rate": 9.162553191489363e-06,
      "loss": 0.1366,
      "step": 2292
    },
    {
      "epoch": 0.5268841911764706,
      "grad_norm": 1.4416226148605347,
      "learning_rate": 9.161702127659576e-06,
      "loss": 0.1332,
      "step": 2293
    },
    {
      "epoch": 0.5271139705882353,
      "grad_norm": 1.3988851308822632,
      "learning_rate": 9.160851063829787e-06,
      "loss": 0.1166,
      "step": 2294
    },
    {
      "epoch": 0.52734375,
      "grad_norm": 1.215956449508667,
      "learning_rate": 9.16e-06,
      "loss": 0.1378,
      "step": 2295
    },
    {
      "epoch": 0.5275735294117647,
      "grad_norm": 1.4438540935516357,
      "learning_rate": 9.159148936170214e-06,
      "loss": 0.1633,
      "step": 2296
    },
    {
      "epoch": 0.5278033088235294,
      "grad_norm": 1.6104576587677002,
      "learning_rate": 9.158297872340427e-06,
      "loss": 0.1218,
      "step": 2297
    },
    {
      "epoch": 0.5280330882352942,
      "grad_norm": 1.4764050245285034,
      "learning_rate": 9.15744680851064e-06,
      "loss": 0.1632,
      "step": 2298
    },
    {
      "epoch": 0.5282628676470589,
      "grad_norm": 1.337185263633728,
      "learning_rate": 9.156595744680851e-06,
      "loss": 0.1603,
      "step": 2299
    },
    {
      "epoch": 0.5284926470588235,
      "grad_norm": 1.1255885362625122,
      "learning_rate": 9.155744680851065e-06,
      "loss": 0.1021,
      "step": 2300
    },
    {
      "epoch": 0.5287224264705882,
      "grad_norm": 1.2694405317306519,
      "learning_rate": 9.154893617021278e-06,
      "loss": 0.1553,
      "step": 2301
    },
    {
      "epoch": 0.5289522058823529,
      "grad_norm": 1.3871495723724365,
      "learning_rate": 9.154042553191491e-06,
      "loss": 0.137,
      "step": 2302
    },
    {
      "epoch": 0.5291819852941176,
      "grad_norm": 1.5528181791305542,
      "learning_rate": 9.153191489361702e-06,
      "loss": 0.1464,
      "step": 2303
    },
    {
      "epoch": 0.5294117647058824,
      "grad_norm": 2.203195095062256,
      "learning_rate": 9.152340425531916e-06,
      "loss": 0.1434,
      "step": 2304
    },
    {
      "epoch": 0.5296415441176471,
      "grad_norm": 1.2681304216384888,
      "learning_rate": 9.151489361702129e-06,
      "loss": 0.1254,
      "step": 2305
    },
    {
      "epoch": 0.5298713235294118,
      "grad_norm": 1.211319088935852,
      "learning_rate": 9.15063829787234e-06,
      "loss": 0.1208,
      "step": 2306
    },
    {
      "epoch": 0.5301011029411765,
      "grad_norm": 1.2561049461364746,
      "learning_rate": 9.149787234042553e-06,
      "loss": 0.1371,
      "step": 2307
    },
    {
      "epoch": 0.5303308823529411,
      "grad_norm": 2.1276330947875977,
      "learning_rate": 9.148936170212767e-06,
      "loss": 0.171,
      "step": 2308
    },
    {
      "epoch": 0.5305606617647058,
      "grad_norm": 1.5261902809143066,
      "learning_rate": 9.14808510638298e-06,
      "loss": 0.1661,
      "step": 2309
    },
    {
      "epoch": 0.5307904411764706,
      "grad_norm": 1.2183812856674194,
      "learning_rate": 9.147234042553193e-06,
      "loss": 0.1134,
      "step": 2310
    },
    {
      "epoch": 0.5310202205882353,
      "grad_norm": 1.1658600568771362,
      "learning_rate": 9.146382978723404e-06,
      "loss": 0.1449,
      "step": 2311
    },
    {
      "epoch": 0.53125,
      "grad_norm": 1.1356847286224365,
      "learning_rate": 9.145531914893618e-06,
      "loss": 0.1244,
      "step": 2312
    },
    {
      "epoch": 0.5314797794117647,
      "grad_norm": 1.6522644758224487,
      "learning_rate": 9.14468085106383e-06,
      "loss": 0.1312,
      "step": 2313
    },
    {
      "epoch": 0.5317095588235294,
      "grad_norm": 1.7561206817626953,
      "learning_rate": 9.143829787234044e-06,
      "loss": 0.1424,
      "step": 2314
    },
    {
      "epoch": 0.5319393382352942,
      "grad_norm": 1.226290225982666,
      "learning_rate": 9.142978723404255e-06,
      "loss": 0.158,
      "step": 2315
    },
    {
      "epoch": 0.5321691176470589,
      "grad_norm": 1.789880633354187,
      "learning_rate": 9.142127659574469e-06,
      "loss": 0.1165,
      "step": 2316
    },
    {
      "epoch": 0.5323988970588235,
      "grad_norm": 1.6123722791671753,
      "learning_rate": 9.141276595744682e-06,
      "loss": 0.1566,
      "step": 2317
    },
    {
      "epoch": 0.5326286764705882,
      "grad_norm": 1.05068838596344,
      "learning_rate": 9.140425531914895e-06,
      "loss": 0.1219,
      "step": 2318
    },
    {
      "epoch": 0.5328584558823529,
      "grad_norm": 1.1559265851974487,
      "learning_rate": 9.139574468085108e-06,
      "loss": 0.0959,
      "step": 2319
    },
    {
      "epoch": 0.5330882352941176,
      "grad_norm": 1.4370763301849365,
      "learning_rate": 9.13872340425532e-06,
      "loss": 0.1574,
      "step": 2320
    },
    {
      "epoch": 0.5333180147058824,
      "grad_norm": 1.6471136808395386,
      "learning_rate": 9.137872340425533e-06,
      "loss": 0.1554,
      "step": 2321
    },
    {
      "epoch": 0.5335477941176471,
      "grad_norm": 0.9645295143127441,
      "learning_rate": 9.137021276595746e-06,
      "loss": 0.1423,
      "step": 2322
    },
    {
      "epoch": 0.5337775735294118,
      "grad_norm": 1.2577096223831177,
      "learning_rate": 9.136170212765957e-06,
      "loss": 0.1387,
      "step": 2323
    },
    {
      "epoch": 0.5340073529411765,
      "grad_norm": 1.1929532289505005,
      "learning_rate": 9.135319148936172e-06,
      "loss": 0.1168,
      "step": 2324
    },
    {
      "epoch": 0.5342371323529411,
      "grad_norm": 1.1524568796157837,
      "learning_rate": 9.134468085106384e-06,
      "loss": 0.1131,
      "step": 2325
    },
    {
      "epoch": 0.5344669117647058,
      "grad_norm": 1.2974287271499634,
      "learning_rate": 9.133617021276597e-06,
      "loss": 0.1558,
      "step": 2326
    },
    {
      "epoch": 0.5346966911764706,
      "grad_norm": 1.5266971588134766,
      "learning_rate": 9.13276595744681e-06,
      "loss": 0.1281,
      "step": 2327
    },
    {
      "epoch": 0.5349264705882353,
      "grad_norm": 1.2425514459609985,
      "learning_rate": 9.131914893617021e-06,
      "loss": 0.1219,
      "step": 2328
    },
    {
      "epoch": 0.53515625,
      "grad_norm": 1.5246460437774658,
      "learning_rate": 9.131063829787235e-06,
      "loss": 0.2281,
      "step": 2329
    },
    {
      "epoch": 0.5353860294117647,
      "grad_norm": 1.5652408599853516,
      "learning_rate": 9.130212765957448e-06,
      "loss": 0.1858,
      "step": 2330
    },
    {
      "epoch": 0.5356158088235294,
      "grad_norm": 1.7316848039627075,
      "learning_rate": 9.129361702127661e-06,
      "loss": 0.1906,
      "step": 2331
    },
    {
      "epoch": 0.5358455882352942,
      "grad_norm": 1.6646692752838135,
      "learning_rate": 9.128510638297872e-06,
      "loss": 0.1739,
      "step": 2332
    },
    {
      "epoch": 0.5360753676470589,
      "grad_norm": 1.0430394411087036,
      "learning_rate": 9.127659574468086e-06,
      "loss": 0.1137,
      "step": 2333
    },
    {
      "epoch": 0.5363051470588235,
      "grad_norm": 1.265403389930725,
      "learning_rate": 9.126808510638299e-06,
      "loss": 0.1326,
      "step": 2334
    },
    {
      "epoch": 0.5365349264705882,
      "grad_norm": 2.0395925045013428,
      "learning_rate": 9.12595744680851e-06,
      "loss": 0.1524,
      "step": 2335
    },
    {
      "epoch": 0.5367647058823529,
      "grad_norm": 2.066188335418701,
      "learning_rate": 9.125106382978725e-06,
      "loss": 0.1688,
      "step": 2336
    },
    {
      "epoch": 0.5369944852941176,
      "grad_norm": 1.1994330883026123,
      "learning_rate": 9.124255319148937e-06,
      "loss": 0.1349,
      "step": 2337
    },
    {
      "epoch": 0.5372242647058824,
      "grad_norm": 1.6044546365737915,
      "learning_rate": 9.12340425531915e-06,
      "loss": 0.1385,
      "step": 2338
    },
    {
      "epoch": 0.5374540441176471,
      "grad_norm": 1.5318121910095215,
      "learning_rate": 9.122553191489363e-06,
      "loss": 0.1482,
      "step": 2339
    },
    {
      "epoch": 0.5376838235294118,
      "grad_norm": 1.8998526334762573,
      "learning_rate": 9.121702127659574e-06,
      "loss": 0.1101,
      "step": 2340
    },
    {
      "epoch": 0.5379136029411765,
      "grad_norm": 1.2856429815292358,
      "learning_rate": 9.120851063829788e-06,
      "loss": 0.1564,
      "step": 2341
    },
    {
      "epoch": 0.5381433823529411,
      "grad_norm": 1.3480294942855835,
      "learning_rate": 9.12e-06,
      "loss": 0.1189,
      "step": 2342
    },
    {
      "epoch": 0.5383731617647058,
      "grad_norm": 1.4144619703292847,
      "learning_rate": 9.119148936170214e-06,
      "loss": 0.1622,
      "step": 2343
    },
    {
      "epoch": 0.5386029411764706,
      "grad_norm": 1.2774443626403809,
      "learning_rate": 9.118297872340425e-06,
      "loss": 0.0947,
      "step": 2344
    },
    {
      "epoch": 0.5388327205882353,
      "grad_norm": 1.276809573173523,
      "learning_rate": 9.117446808510639e-06,
      "loss": 0.1321,
      "step": 2345
    },
    {
      "epoch": 0.5390625,
      "grad_norm": 1.1755187511444092,
      "learning_rate": 9.116595744680852e-06,
      "loss": 0.1265,
      "step": 2346
    },
    {
      "epoch": 0.5392922794117647,
      "grad_norm": 1.3787630796432495,
      "learning_rate": 9.115744680851065e-06,
      "loss": 0.1214,
      "step": 2347
    },
    {
      "epoch": 0.5395220588235294,
      "grad_norm": 1.1840696334838867,
      "learning_rate": 9.114893617021278e-06,
      "loss": 0.0935,
      "step": 2348
    },
    {
      "epoch": 0.5397518382352942,
      "grad_norm": 1.1183425188064575,
      "learning_rate": 9.11404255319149e-06,
      "loss": 0.1018,
      "step": 2349
    },
    {
      "epoch": 0.5399816176470589,
      "grad_norm": 1.0826259851455688,
      "learning_rate": 9.113191489361703e-06,
      "loss": 0.1395,
      "step": 2350
    },
    {
      "epoch": 0.5402113970588235,
      "grad_norm": 1.1172280311584473,
      "learning_rate": 9.112340425531916e-06,
      "loss": 0.1494,
      "step": 2351
    },
    {
      "epoch": 0.5404411764705882,
      "grad_norm": 1.156027913093567,
      "learning_rate": 9.111489361702129e-06,
      "loss": 0.1708,
      "step": 2352
    },
    {
      "epoch": 0.5406709558823529,
      "grad_norm": 1.363599419593811,
      "learning_rate": 9.11063829787234e-06,
      "loss": 0.0936,
      "step": 2353
    },
    {
      "epoch": 0.5409007352941176,
      "grad_norm": 1.4534482955932617,
      "learning_rate": 9.109787234042554e-06,
      "loss": 0.1483,
      "step": 2354
    },
    {
      "epoch": 0.5411305147058824,
      "grad_norm": 1.7156178951263428,
      "learning_rate": 9.108936170212767e-06,
      "loss": 0.2753,
      "step": 2355
    },
    {
      "epoch": 0.5413602941176471,
      "grad_norm": 1.1175439357757568,
      "learning_rate": 9.108085106382978e-06,
      "loss": 0.1212,
      "step": 2356
    },
    {
      "epoch": 0.5415900735294118,
      "grad_norm": 1.2811095714569092,
      "learning_rate": 9.107234042553193e-06,
      "loss": 0.1704,
      "step": 2357
    },
    {
      "epoch": 0.5418198529411765,
      "grad_norm": 1.3032515048980713,
      "learning_rate": 9.106382978723405e-06,
      "loss": 0.1346,
      "step": 2358
    },
    {
      "epoch": 0.5420496323529411,
      "grad_norm": 1.2443723678588867,
      "learning_rate": 9.105531914893618e-06,
      "loss": 0.2061,
      "step": 2359
    },
    {
      "epoch": 0.5422794117647058,
      "grad_norm": 1.0560826063156128,
      "learning_rate": 9.104680851063831e-06,
      "loss": 0.1277,
      "step": 2360
    },
    {
      "epoch": 0.5425091911764706,
      "grad_norm": 1.1526391506195068,
      "learning_rate": 9.103829787234043e-06,
      "loss": 0.1322,
      "step": 2361
    },
    {
      "epoch": 0.5427389705882353,
      "grad_norm": 1.236254096031189,
      "learning_rate": 9.102978723404257e-06,
      "loss": 0.1016,
      "step": 2362
    },
    {
      "epoch": 0.54296875,
      "grad_norm": 1.322601079940796,
      "learning_rate": 9.102127659574469e-06,
      "loss": 0.1372,
      "step": 2363
    },
    {
      "epoch": 0.5431985294117647,
      "grad_norm": 1.4700307846069336,
      "learning_rate": 9.101276595744682e-06,
      "loss": 0.1562,
      "step": 2364
    },
    {
      "epoch": 0.5434283088235294,
      "grad_norm": 1.5651462078094482,
      "learning_rate": 9.100425531914895e-06,
      "loss": 0.204,
      "step": 2365
    },
    {
      "epoch": 0.5436580882352942,
      "grad_norm": 1.605506181716919,
      "learning_rate": 9.099574468085107e-06,
      "loss": 0.2022,
      "step": 2366
    },
    {
      "epoch": 0.5438878676470589,
      "grad_norm": 1.170593500137329,
      "learning_rate": 9.09872340425532e-06,
      "loss": 0.1072,
      "step": 2367
    },
    {
      "epoch": 0.5441176470588235,
      "grad_norm": 1.1256924867630005,
      "learning_rate": 9.097872340425533e-06,
      "loss": 0.1383,
      "step": 2368
    },
    {
      "epoch": 0.5443474264705882,
      "grad_norm": 1.4857043027877808,
      "learning_rate": 9.097021276595746e-06,
      "loss": 0.1467,
      "step": 2369
    },
    {
      "epoch": 0.5445772058823529,
      "grad_norm": 1.1473653316497803,
      "learning_rate": 9.096170212765958e-06,
      "loss": 0.1255,
      "step": 2370
    },
    {
      "epoch": 0.5448069852941176,
      "grad_norm": 1.0675982236862183,
      "learning_rate": 9.095319148936171e-06,
      "loss": 0.1337,
      "step": 2371
    },
    {
      "epoch": 0.5450367647058824,
      "grad_norm": 1.1750670671463013,
      "learning_rate": 9.094468085106384e-06,
      "loss": 0.1315,
      "step": 2372
    },
    {
      "epoch": 0.5452665441176471,
      "grad_norm": 1.619494915008545,
      "learning_rate": 9.093617021276596e-06,
      "loss": 0.1745,
      "step": 2373
    },
    {
      "epoch": 0.5454963235294118,
      "grad_norm": 1.4062676429748535,
      "learning_rate": 9.09276595744681e-06,
      "loss": 0.1691,
      "step": 2374
    },
    {
      "epoch": 0.5457261029411765,
      "grad_norm": 1.1540892124176025,
      "learning_rate": 9.091914893617022e-06,
      "loss": 0.0868,
      "step": 2375
    },
    {
      "epoch": 0.5459558823529411,
      "grad_norm": 1.2702299356460571,
      "learning_rate": 9.091063829787235e-06,
      "loss": 0.1773,
      "step": 2376
    },
    {
      "epoch": 0.5461856617647058,
      "grad_norm": 1.3256475925445557,
      "learning_rate": 9.090212765957448e-06,
      "loss": 0.1454,
      "step": 2377
    },
    {
      "epoch": 0.5464154411764706,
      "grad_norm": 1.276043176651001,
      "learning_rate": 9.08936170212766e-06,
      "loss": 0.1155,
      "step": 2378
    },
    {
      "epoch": 0.5466452205882353,
      "grad_norm": 1.3717401027679443,
      "learning_rate": 9.088510638297873e-06,
      "loss": 0.1269,
      "step": 2379
    },
    {
      "epoch": 0.546875,
      "grad_norm": 1.4930534362792969,
      "learning_rate": 9.087659574468086e-06,
      "loss": 0.1309,
      "step": 2380
    },
    {
      "epoch": 0.5471047794117647,
      "grad_norm": 1.36741304397583,
      "learning_rate": 9.0868085106383e-06,
      "loss": 0.1634,
      "step": 2381
    },
    {
      "epoch": 0.5473345588235294,
      "grad_norm": 1.28901207447052,
      "learning_rate": 9.08595744680851e-06,
      "loss": 0.1531,
      "step": 2382
    },
    {
      "epoch": 0.5475643382352942,
      "grad_norm": 1.3363572359085083,
      "learning_rate": 9.085106382978724e-06,
      "loss": 0.1357,
      "step": 2383
    },
    {
      "epoch": 0.5477941176470589,
      "grad_norm": 1.4417580366134644,
      "learning_rate": 9.084255319148937e-06,
      "loss": 0.1317,
      "step": 2384
    },
    {
      "epoch": 0.5480238970588235,
      "grad_norm": 1.4560010433197021,
      "learning_rate": 9.083404255319148e-06,
      "loss": 0.1424,
      "step": 2385
    },
    {
      "epoch": 0.5482536764705882,
      "grad_norm": 1.4407145977020264,
      "learning_rate": 9.082553191489363e-06,
      "loss": 0.1659,
      "step": 2386
    },
    {
      "epoch": 0.5484834558823529,
      "grad_norm": 1.1419965028762817,
      "learning_rate": 9.081702127659575e-06,
      "loss": 0.102,
      "step": 2387
    },
    {
      "epoch": 0.5487132352941176,
      "grad_norm": 1.4376662969589233,
      "learning_rate": 9.080851063829788e-06,
      "loss": 0.137,
      "step": 2388
    },
    {
      "epoch": 0.5489430147058824,
      "grad_norm": 1.2955355644226074,
      "learning_rate": 9.080000000000001e-06,
      "loss": 0.102,
      "step": 2389
    },
    {
      "epoch": 0.5491727941176471,
      "grad_norm": 1.5774006843566895,
      "learning_rate": 9.079148936170213e-06,
      "loss": 0.2561,
      "step": 2390
    },
    {
      "epoch": 0.5494025735294118,
      "grad_norm": 1.3705353736877441,
      "learning_rate": 9.078297872340426e-06,
      "loss": 0.1235,
      "step": 2391
    },
    {
      "epoch": 0.5496323529411765,
      "grad_norm": 1.340936541557312,
      "learning_rate": 9.077446808510639e-06,
      "loss": 0.1364,
      "step": 2392
    },
    {
      "epoch": 0.5498621323529411,
      "grad_norm": 1.402733564376831,
      "learning_rate": 9.076595744680852e-06,
      "loss": 0.1537,
      "step": 2393
    },
    {
      "epoch": 0.5500919117647058,
      "grad_norm": 1.0703234672546387,
      "learning_rate": 9.075744680851064e-06,
      "loss": 0.1589,
      "step": 2394
    },
    {
      "epoch": 0.5503216911764706,
      "grad_norm": 1.0885348320007324,
      "learning_rate": 9.074893617021277e-06,
      "loss": 0.1545,
      "step": 2395
    },
    {
      "epoch": 0.5505514705882353,
      "grad_norm": 1.18281090259552,
      "learning_rate": 9.07404255319149e-06,
      "loss": 0.1355,
      "step": 2396
    },
    {
      "epoch": 0.55078125,
      "grad_norm": 0.814413845539093,
      "learning_rate": 9.073191489361703e-06,
      "loss": 0.0864,
      "step": 2397
    },
    {
      "epoch": 0.5510110294117647,
      "grad_norm": 1.190852403640747,
      "learning_rate": 9.072340425531916e-06,
      "loss": 0.1214,
      "step": 2398
    },
    {
      "epoch": 0.5512408088235294,
      "grad_norm": 0.8739215731620789,
      "learning_rate": 9.071489361702128e-06,
      "loss": 0.098,
      "step": 2399
    },
    {
      "epoch": 0.5514705882352942,
      "grad_norm": 1.5464751720428467,
      "learning_rate": 9.070638297872341e-06,
      "loss": 0.1548,
      "step": 2400
    },
    {
      "epoch": 0.5517003676470589,
      "grad_norm": 1.1347088813781738,
      "learning_rate": 9.069787234042554e-06,
      "loss": 0.1252,
      "step": 2401
    },
    {
      "epoch": 0.5519301470588235,
      "grad_norm": 1.0573407411575317,
      "learning_rate": 9.068936170212767e-06,
      "loss": 0.0891,
      "step": 2402
    },
    {
      "epoch": 0.5521599264705882,
      "grad_norm": 1.5300486087799072,
      "learning_rate": 9.06808510638298e-06,
      "loss": 0.1244,
      "step": 2403
    },
    {
      "epoch": 0.5523897058823529,
      "grad_norm": 1.215309977531433,
      "learning_rate": 9.067234042553192e-06,
      "loss": 0.1257,
      "step": 2404
    },
    {
      "epoch": 0.5526194852941176,
      "grad_norm": 0.9786842465400696,
      "learning_rate": 9.066382978723405e-06,
      "loss": 0.1525,
      "step": 2405
    },
    {
      "epoch": 0.5528492647058824,
      "grad_norm": 1.423487663269043,
      "learning_rate": 9.065531914893618e-06,
      "loss": 0.166,
      "step": 2406
    },
    {
      "epoch": 0.5530790441176471,
      "grad_norm": 1.3408000469207764,
      "learning_rate": 9.064680851063831e-06,
      "loss": 0.1295,
      "step": 2407
    },
    {
      "epoch": 0.5533088235294118,
      "grad_norm": 1.2584954500198364,
      "learning_rate": 9.063829787234043e-06,
      "loss": 0.123,
      "step": 2408
    },
    {
      "epoch": 0.5535386029411765,
      "grad_norm": 1.2741199731826782,
      "learning_rate": 9.062978723404256e-06,
      "loss": 0.1346,
      "step": 2409
    },
    {
      "epoch": 0.5537683823529411,
      "grad_norm": 1.372176170349121,
      "learning_rate": 9.06212765957447e-06,
      "loss": 0.1164,
      "step": 2410
    },
    {
      "epoch": 0.5539981617647058,
      "grad_norm": 1.5213245153427124,
      "learning_rate": 9.06127659574468e-06,
      "loss": 0.1799,
      "step": 2411
    },
    {
      "epoch": 0.5542279411764706,
      "grad_norm": 1.5816948413848877,
      "learning_rate": 9.060425531914896e-06,
      "loss": 0.147,
      "step": 2412
    },
    {
      "epoch": 0.5544577205882353,
      "grad_norm": 1.2276854515075684,
      "learning_rate": 9.059574468085107e-06,
      "loss": 0.1156,
      "step": 2413
    },
    {
      "epoch": 0.5546875,
      "grad_norm": 1.26020085811615,
      "learning_rate": 9.05872340425532e-06,
      "loss": 0.1316,
      "step": 2414
    },
    {
      "epoch": 0.5549172794117647,
      "grad_norm": 1.2329753637313843,
      "learning_rate": 9.057872340425533e-06,
      "loss": 0.1626,
      "step": 2415
    },
    {
      "epoch": 0.5551470588235294,
      "grad_norm": 2.3398215770721436,
      "learning_rate": 9.057021276595745e-06,
      "loss": 0.2015,
      "step": 2416
    },
    {
      "epoch": 0.5553768382352942,
      "grad_norm": 1.244320034980774,
      "learning_rate": 9.056170212765958e-06,
      "loss": 0.1516,
      "step": 2417
    },
    {
      "epoch": 0.5556066176470589,
      "grad_norm": 1.4781649112701416,
      "learning_rate": 9.055319148936171e-06,
      "loss": 0.1342,
      "step": 2418
    },
    {
      "epoch": 0.5558363970588235,
      "grad_norm": 1.0360759496688843,
      "learning_rate": 9.054468085106384e-06,
      "loss": 0.124,
      "step": 2419
    },
    {
      "epoch": 0.5560661764705882,
      "grad_norm": 1.4514994621276855,
      "learning_rate": 9.053617021276596e-06,
      "loss": 0.159,
      "step": 2420
    },
    {
      "epoch": 0.5562959558823529,
      "grad_norm": 1.1583523750305176,
      "learning_rate": 9.052765957446809e-06,
      "loss": 0.106,
      "step": 2421
    },
    {
      "epoch": 0.5565257352941176,
      "grad_norm": 1.1377147436141968,
      "learning_rate": 9.051914893617022e-06,
      "loss": 0.1281,
      "step": 2422
    },
    {
      "epoch": 0.5567555147058824,
      "grad_norm": 1.0477409362792969,
      "learning_rate": 9.051063829787234e-06,
      "loss": 0.1168,
      "step": 2423
    },
    {
      "epoch": 0.5569852941176471,
      "grad_norm": 1.1698271036148071,
      "learning_rate": 9.050212765957449e-06,
      "loss": 0.1449,
      "step": 2424
    },
    {
      "epoch": 0.5572150735294118,
      "grad_norm": 1.0653572082519531,
      "learning_rate": 9.04936170212766e-06,
      "loss": 0.1075,
      "step": 2425
    },
    {
      "epoch": 0.5574448529411765,
      "grad_norm": 1.2138910293579102,
      "learning_rate": 9.048510638297873e-06,
      "loss": 0.1088,
      "step": 2426
    },
    {
      "epoch": 0.5576746323529411,
      "grad_norm": 1.8923286199569702,
      "learning_rate": 9.047659574468086e-06,
      "loss": 0.1413,
      "step": 2427
    },
    {
      "epoch": 0.5579044117647058,
      "grad_norm": 1.2006399631500244,
      "learning_rate": 9.046808510638298e-06,
      "loss": 0.1405,
      "step": 2428
    },
    {
      "epoch": 0.5581341911764706,
      "grad_norm": 1.4624547958374023,
      "learning_rate": 9.045957446808511e-06,
      "loss": 0.1263,
      "step": 2429
    },
    {
      "epoch": 0.5583639705882353,
      "grad_norm": 1.0354437828063965,
      "learning_rate": 9.045106382978724e-06,
      "loss": 0.1079,
      "step": 2430
    },
    {
      "epoch": 0.55859375,
      "grad_norm": 1.251836895942688,
      "learning_rate": 9.044255319148937e-06,
      "loss": 0.1416,
      "step": 2431
    },
    {
      "epoch": 0.5588235294117647,
      "grad_norm": 1.269735336303711,
      "learning_rate": 9.043404255319149e-06,
      "loss": 0.1218,
      "step": 2432
    },
    {
      "epoch": 0.5590533088235294,
      "grad_norm": 1.3012335300445557,
      "learning_rate": 9.042553191489362e-06,
      "loss": 0.1461,
      "step": 2433
    },
    {
      "epoch": 0.5592830882352942,
      "grad_norm": 1.3851823806762695,
      "learning_rate": 9.041702127659575e-06,
      "loss": 0.1421,
      "step": 2434
    },
    {
      "epoch": 0.5595128676470589,
      "grad_norm": 1.3766201734542847,
      "learning_rate": 9.040851063829787e-06,
      "loss": 0.1236,
      "step": 2435
    },
    {
      "epoch": 0.5597426470588235,
      "grad_norm": 1.234062671661377,
      "learning_rate": 9.040000000000002e-06,
      "loss": 0.123,
      "step": 2436
    },
    {
      "epoch": 0.5599724264705882,
      "grad_norm": 1.1724053621292114,
      "learning_rate": 9.039148936170213e-06,
      "loss": 0.1279,
      "step": 2437
    },
    {
      "epoch": 0.5602022058823529,
      "grad_norm": 1.3846102952957153,
      "learning_rate": 9.038297872340426e-06,
      "loss": 0.1134,
      "step": 2438
    },
    {
      "epoch": 0.5604319852941176,
      "grad_norm": 1.4926942586898804,
      "learning_rate": 9.03744680851064e-06,
      "loss": 0.1669,
      "step": 2439
    },
    {
      "epoch": 0.5606617647058824,
      "grad_norm": 1.1407310962677002,
      "learning_rate": 9.03659574468085e-06,
      "loss": 0.1222,
      "step": 2440
    },
    {
      "epoch": 0.5608915441176471,
      "grad_norm": 1.3279906511306763,
      "learning_rate": 9.035744680851064e-06,
      "loss": 0.122,
      "step": 2441
    },
    {
      "epoch": 0.5611213235294118,
      "grad_norm": 1.3682948350906372,
      "learning_rate": 9.034893617021277e-06,
      "loss": 0.1518,
      "step": 2442
    },
    {
      "epoch": 0.5613511029411765,
      "grad_norm": 1.5003339052200317,
      "learning_rate": 9.03404255319149e-06,
      "loss": 0.1227,
      "step": 2443
    },
    {
      "epoch": 0.5615808823529411,
      "grad_norm": 1.6937932968139648,
      "learning_rate": 9.033191489361702e-06,
      "loss": 0.1604,
      "step": 2444
    },
    {
      "epoch": 0.5618106617647058,
      "grad_norm": 1.0219743251800537,
      "learning_rate": 9.032340425531915e-06,
      "loss": 0.1041,
      "step": 2445
    },
    {
      "epoch": 0.5620404411764706,
      "grad_norm": 1.4082615375518799,
      "learning_rate": 9.031489361702128e-06,
      "loss": 0.1272,
      "step": 2446
    },
    {
      "epoch": 0.5622702205882353,
      "grad_norm": 1.6634854078292847,
      "learning_rate": 9.030638297872341e-06,
      "loss": 0.158,
      "step": 2447
    },
    {
      "epoch": 0.5625,
      "grad_norm": 0.9703645706176758,
      "learning_rate": 9.029787234042555e-06,
      "loss": 0.1344,
      "step": 2448
    },
    {
      "epoch": 0.5627297794117647,
      "grad_norm": 1.3235048055648804,
      "learning_rate": 9.028936170212766e-06,
      "loss": 0.1355,
      "step": 2449
    },
    {
      "epoch": 0.5629595588235294,
      "grad_norm": 1.4192626476287842,
      "learning_rate": 9.028085106382979e-06,
      "loss": 0.1271,
      "step": 2450
    },
    {
      "epoch": 0.5631893382352942,
      "grad_norm": 1.5022040605545044,
      "learning_rate": 9.027234042553192e-06,
      "loss": 0.1203,
      "step": 2451
    },
    {
      "epoch": 0.5634191176470589,
      "grad_norm": 0.9483230710029602,
      "learning_rate": 9.026382978723405e-06,
      "loss": 0.1181,
      "step": 2452
    },
    {
      "epoch": 0.5636488970588235,
      "grad_norm": 1.6666268110275269,
      "learning_rate": 9.025531914893619e-06,
      "loss": 0.1325,
      "step": 2453
    },
    {
      "epoch": 0.5638786764705882,
      "grad_norm": 1.3624917268753052,
      "learning_rate": 9.02468085106383e-06,
      "loss": 0.1876,
      "step": 2454
    },
    {
      "epoch": 0.5641084558823529,
      "grad_norm": 1.4346927404403687,
      "learning_rate": 9.023829787234043e-06,
      "loss": 0.1704,
      "step": 2455
    },
    {
      "epoch": 0.5643382352941176,
      "grad_norm": 1.048272967338562,
      "learning_rate": 9.022978723404256e-06,
      "loss": 0.1267,
      "step": 2456
    },
    {
      "epoch": 0.5645680147058824,
      "grad_norm": 1.3661563396453857,
      "learning_rate": 9.02212765957447e-06,
      "loss": 0.141,
      "step": 2457
    },
    {
      "epoch": 0.5647977941176471,
      "grad_norm": 1.3602522611618042,
      "learning_rate": 9.021276595744681e-06,
      "loss": 0.1787,
      "step": 2458
    },
    {
      "epoch": 0.5650275735294118,
      "grad_norm": 1.0203752517700195,
      "learning_rate": 9.020425531914894e-06,
      "loss": 0.0986,
      "step": 2459
    },
    {
      "epoch": 0.5652573529411765,
      "grad_norm": 1.6232260465621948,
      "learning_rate": 9.019574468085107e-06,
      "loss": 0.1251,
      "step": 2460
    },
    {
      "epoch": 0.5654871323529411,
      "grad_norm": 0.9730387330055237,
      "learning_rate": 9.018723404255319e-06,
      "loss": 0.1352,
      "step": 2461
    },
    {
      "epoch": 0.5657169117647058,
      "grad_norm": 1.335005283355713,
      "learning_rate": 9.017872340425534e-06,
      "loss": 0.1117,
      "step": 2462
    },
    {
      "epoch": 0.5659466911764706,
      "grad_norm": 1.3640769720077515,
      "learning_rate": 9.017021276595745e-06,
      "loss": 0.1217,
      "step": 2463
    },
    {
      "epoch": 0.5661764705882353,
      "grad_norm": 1.3203010559082031,
      "learning_rate": 9.016170212765958e-06,
      "loss": 0.0992,
      "step": 2464
    },
    {
      "epoch": 0.56640625,
      "grad_norm": 1.4501680135726929,
      "learning_rate": 9.015319148936172e-06,
      "loss": 0.156,
      "step": 2465
    },
    {
      "epoch": 0.5666360294117647,
      "grad_norm": 1.4721487760543823,
      "learning_rate": 9.014468085106383e-06,
      "loss": 0.1135,
      "step": 2466
    },
    {
      "epoch": 0.5668658088235294,
      "grad_norm": 1.3851500749588013,
      "learning_rate": 9.013617021276596e-06,
      "loss": 0.1147,
      "step": 2467
    },
    {
      "epoch": 0.5670955882352942,
      "grad_norm": 1.2944985628128052,
      "learning_rate": 9.01276595744681e-06,
      "loss": 0.1368,
      "step": 2468
    },
    {
      "epoch": 0.5673253676470589,
      "grad_norm": 0.9957671761512756,
      "learning_rate": 9.011914893617023e-06,
      "loss": 0.1191,
      "step": 2469
    },
    {
      "epoch": 0.5675551470588235,
      "grad_norm": 1.017098307609558,
      "learning_rate": 9.011063829787234e-06,
      "loss": 0.1069,
      "step": 2470
    },
    {
      "epoch": 0.5677849264705882,
      "grad_norm": 1.5343434810638428,
      "learning_rate": 9.010212765957447e-06,
      "loss": 0.13,
      "step": 2471
    },
    {
      "epoch": 0.5680147058823529,
      "grad_norm": 1.0269845724105835,
      "learning_rate": 9.00936170212766e-06,
      "loss": 0.0959,
      "step": 2472
    },
    {
      "epoch": 0.5682444852941176,
      "grad_norm": 1.348244309425354,
      "learning_rate": 9.008510638297872e-06,
      "loss": 0.1087,
      "step": 2473
    },
    {
      "epoch": 0.5684742647058824,
      "grad_norm": 1.1664999723434448,
      "learning_rate": 9.007659574468087e-06,
      "loss": 0.1128,
      "step": 2474
    },
    {
      "epoch": 0.5687040441176471,
      "grad_norm": 1.251504898071289,
      "learning_rate": 9.006808510638298e-06,
      "loss": 0.0878,
      "step": 2475
    },
    {
      "epoch": 0.5689338235294118,
      "grad_norm": 1.6208306550979614,
      "learning_rate": 9.005957446808511e-06,
      "loss": 0.1317,
      "step": 2476
    },
    {
      "epoch": 0.5691636029411765,
      "grad_norm": 1.5055841207504272,
      "learning_rate": 9.005106382978725e-06,
      "loss": 0.1124,
      "step": 2477
    },
    {
      "epoch": 0.5693933823529411,
      "grad_norm": 1.2104616165161133,
      "learning_rate": 9.004255319148936e-06,
      "loss": 0.1234,
      "step": 2478
    },
    {
      "epoch": 0.5696231617647058,
      "grad_norm": 1.1657426357269287,
      "learning_rate": 9.00340425531915e-06,
      "loss": 0.1027,
      "step": 2479
    },
    {
      "epoch": 0.5698529411764706,
      "grad_norm": 1.1591051816940308,
      "learning_rate": 9.002553191489362e-06,
      "loss": 0.1364,
      "step": 2480
    },
    {
      "epoch": 0.5700827205882353,
      "grad_norm": 1.1552904844284058,
      "learning_rate": 9.001702127659576e-06,
      "loss": 0.1413,
      "step": 2481
    },
    {
      "epoch": 0.5703125,
      "grad_norm": 1.2096452713012695,
      "learning_rate": 9.000851063829787e-06,
      "loss": 0.1293,
      "step": 2482
    },
    {
      "epoch": 0.5705422794117647,
      "grad_norm": 2.038597822189331,
      "learning_rate": 9e-06,
      "loss": 0.1691,
      "step": 2483
    },
    {
      "epoch": 0.5707720588235294,
      "grad_norm": 1.9200048446655273,
      "learning_rate": 8.999148936170213e-06,
      "loss": 0.1503,
      "step": 2484
    },
    {
      "epoch": 0.5710018382352942,
      "grad_norm": 0.9241666793823242,
      "learning_rate": 8.998297872340427e-06,
      "loss": 0.1019,
      "step": 2485
    },
    {
      "epoch": 0.5712316176470589,
      "grad_norm": 1.1515588760375977,
      "learning_rate": 8.99744680851064e-06,
      "loss": 0.152,
      "step": 2486
    },
    {
      "epoch": 0.5714613970588235,
      "grad_norm": 1.3674664497375488,
      "learning_rate": 8.996595744680851e-06,
      "loss": 0.1183,
      "step": 2487
    },
    {
      "epoch": 0.5716911764705882,
      "grad_norm": 1.3512017726898193,
      "learning_rate": 8.995744680851064e-06,
      "loss": 0.1293,
      "step": 2488
    },
    {
      "epoch": 0.5719209558823529,
      "grad_norm": 1.4496546983718872,
      "learning_rate": 8.994893617021278e-06,
      "loss": 0.1473,
      "step": 2489
    },
    {
      "epoch": 0.5721507352941176,
      "grad_norm": 1.389244794845581,
      "learning_rate": 8.99404255319149e-06,
      "loss": 0.1469,
      "step": 2490
    },
    {
      "epoch": 0.5723805147058824,
      "grad_norm": 1.42020583152771,
      "learning_rate": 8.993191489361704e-06,
      "loss": 0.1038,
      "step": 2491
    },
    {
      "epoch": 0.5726102941176471,
      "grad_norm": 1.9250637292861938,
      "learning_rate": 8.992340425531915e-06,
      "loss": 0.1509,
      "step": 2492
    },
    {
      "epoch": 0.5728400735294118,
      "grad_norm": 1.3832048177719116,
      "learning_rate": 8.991489361702129e-06,
      "loss": 0.1354,
      "step": 2493
    },
    {
      "epoch": 0.5730698529411765,
      "grad_norm": 1.3590666055679321,
      "learning_rate": 8.990638297872342e-06,
      "loss": 0.1293,
      "step": 2494
    },
    {
      "epoch": 0.5732996323529411,
      "grad_norm": 1.2051657438278198,
      "learning_rate": 8.989787234042555e-06,
      "loss": 0.1139,
      "step": 2495
    },
    {
      "epoch": 0.5735294117647058,
      "grad_norm": 1.5086421966552734,
      "learning_rate": 8.988936170212766e-06,
      "loss": 0.1054,
      "step": 2496
    },
    {
      "epoch": 0.5737591911764706,
      "grad_norm": 1.0347291231155396,
      "learning_rate": 8.98808510638298e-06,
      "loss": 0.1219,
      "step": 2497
    },
    {
      "epoch": 0.5739889705882353,
      "grad_norm": 1.325592279434204,
      "learning_rate": 8.987234042553193e-06,
      "loss": 0.1569,
      "step": 2498
    },
    {
      "epoch": 0.57421875,
      "grad_norm": 1.3652269840240479,
      "learning_rate": 8.986382978723404e-06,
      "loss": 0.1208,
      "step": 2499
    },
    {
      "epoch": 0.5744485294117647,
      "grad_norm": 1.481752872467041,
      "learning_rate": 8.985531914893619e-06,
      "loss": 0.1751,
      "step": 2500
    },
    {
      "epoch": 0.5744485294117647,
      "eval_loss": 0.13438905775547028,
      "eval_runtime": 1966.2684,
      "eval_samples_per_second": 4.529,
      "eval_steps_per_second": 2.265,
      "step": 2500
    },
    {
      "epoch": 0.5746783088235294,
      "grad_norm": 1.1959134340286255,
      "learning_rate": 8.98468085106383e-06,
      "loss": 0.127,
      "step": 2501
    },
    {
      "epoch": 0.5749080882352942,
      "grad_norm": 1.2137197256088257,
      "learning_rate": 8.983829787234044e-06,
      "loss": 0.1266,
      "step": 2502
    },
    {
      "epoch": 0.5751378676470589,
      "grad_norm": 1.2231953144073486,
      "learning_rate": 8.982978723404257e-06,
      "loss": 0.1001,
      "step": 2503
    },
    {
      "epoch": 0.5753676470588235,
      "grad_norm": 1.8073792457580566,
      "learning_rate": 8.982127659574468e-06,
      "loss": 0.209,
      "step": 2504
    },
    {
      "epoch": 0.5755974264705882,
      "grad_norm": 1.308311939239502,
      "learning_rate": 8.981276595744682e-06,
      "loss": 0.1458,
      "step": 2505
    },
    {
      "epoch": 0.5758272058823529,
      "grad_norm": 1.4364020824432373,
      "learning_rate": 8.980425531914895e-06,
      "loss": 0.146,
      "step": 2506
    },
    {
      "epoch": 0.5760569852941176,
      "grad_norm": 1.340589165687561,
      "learning_rate": 8.979574468085108e-06,
      "loss": 0.126,
      "step": 2507
    },
    {
      "epoch": 0.5762867647058824,
      "grad_norm": 1.208325982093811,
      "learning_rate": 8.97872340425532e-06,
      "loss": 0.1691,
      "step": 2508
    },
    {
      "epoch": 0.5765165441176471,
      "grad_norm": 1.0409691333770752,
      "learning_rate": 8.977872340425532e-06,
      "loss": 0.126,
      "step": 2509
    },
    {
      "epoch": 0.5767463235294118,
      "grad_norm": 1.1685289144515991,
      "learning_rate": 8.977021276595746e-06,
      "loss": 0.1165,
      "step": 2510
    },
    {
      "epoch": 0.5769761029411765,
      "grad_norm": 1.291696548461914,
      "learning_rate": 8.976170212765957e-06,
      "loss": 0.1132,
      "step": 2511
    },
    {
      "epoch": 0.5772058823529411,
      "grad_norm": 1.237858533859253,
      "learning_rate": 8.975319148936172e-06,
      "loss": 0.1338,
      "step": 2512
    },
    {
      "epoch": 0.5774356617647058,
      "grad_norm": 1.2616679668426514,
      "learning_rate": 8.974468085106383e-06,
      "loss": 0.1254,
      "step": 2513
    },
    {
      "epoch": 0.5776654411764706,
      "grad_norm": 1.140038013458252,
      "learning_rate": 8.973617021276597e-06,
      "loss": 0.109,
      "step": 2514
    },
    {
      "epoch": 0.5778952205882353,
      "grad_norm": 1.2232850790023804,
      "learning_rate": 8.97276595744681e-06,
      "loss": 0.1646,
      "step": 2515
    },
    {
      "epoch": 0.578125,
      "grad_norm": 1.2127856016159058,
      "learning_rate": 8.971914893617021e-06,
      "loss": 0.1115,
      "step": 2516
    },
    {
      "epoch": 0.5783547794117647,
      "grad_norm": 1.4369200468063354,
      "learning_rate": 8.971063829787234e-06,
      "loss": 0.1817,
      "step": 2517
    },
    {
      "epoch": 0.5785845588235294,
      "grad_norm": 1.213297963142395,
      "learning_rate": 8.970212765957448e-06,
      "loss": 0.1292,
      "step": 2518
    },
    {
      "epoch": 0.5788143382352942,
      "grad_norm": 1.2665438652038574,
      "learning_rate": 8.96936170212766e-06,
      "loss": 0.105,
      "step": 2519
    },
    {
      "epoch": 0.5790441176470589,
      "grad_norm": 1.4116979837417603,
      "learning_rate": 8.968510638297872e-06,
      "loss": 0.1172,
      "step": 2520
    },
    {
      "epoch": 0.5792738970588235,
      "grad_norm": 1.1808570623397827,
      "learning_rate": 8.967659574468085e-06,
      "loss": 0.1379,
      "step": 2521
    },
    {
      "epoch": 0.5795036764705882,
      "grad_norm": 0.900642454624176,
      "learning_rate": 8.966808510638299e-06,
      "loss": 0.1307,
      "step": 2522
    },
    {
      "epoch": 0.5797334558823529,
      "grad_norm": 1.2578264474868774,
      "learning_rate": 8.96595744680851e-06,
      "loss": 0.1537,
      "step": 2523
    },
    {
      "epoch": 0.5799632352941176,
      "grad_norm": 1.4859192371368408,
      "learning_rate": 8.965106382978725e-06,
      "loss": 0.1336,
      "step": 2524
    },
    {
      "epoch": 0.5801930147058824,
      "grad_norm": 0.9454990029335022,
      "learning_rate": 8.964255319148936e-06,
      "loss": 0.0944,
      "step": 2525
    },
    {
      "epoch": 0.5804227941176471,
      "grad_norm": 1.8629920482635498,
      "learning_rate": 8.96340425531915e-06,
      "loss": 0.1561,
      "step": 2526
    },
    {
      "epoch": 0.5806525735294118,
      "grad_norm": 1.4818663597106934,
      "learning_rate": 8.962553191489363e-06,
      "loss": 0.1232,
      "step": 2527
    },
    {
      "epoch": 0.5808823529411765,
      "grad_norm": 1.650206446647644,
      "learning_rate": 8.961702127659574e-06,
      "loss": 0.1378,
      "step": 2528
    },
    {
      "epoch": 0.5811121323529411,
      "grad_norm": 0.8815922141075134,
      "learning_rate": 8.960851063829787e-06,
      "loss": 0.0944,
      "step": 2529
    },
    {
      "epoch": 0.5813419117647058,
      "grad_norm": 1.1004323959350586,
      "learning_rate": 8.96e-06,
      "loss": 0.1151,
      "step": 2530
    },
    {
      "epoch": 0.5815716911764706,
      "grad_norm": 1.2847083806991577,
      "learning_rate": 8.959148936170214e-06,
      "loss": 0.1097,
      "step": 2531
    },
    {
      "epoch": 0.5818014705882353,
      "grad_norm": 1.3232078552246094,
      "learning_rate": 8.958297872340427e-06,
      "loss": 0.0994,
      "step": 2532
    },
    {
      "epoch": 0.58203125,
      "grad_norm": 1.2356778383255005,
      "learning_rate": 8.957446808510638e-06,
      "loss": 0.1006,
      "step": 2533
    },
    {
      "epoch": 0.5822610294117647,
      "grad_norm": 1.037954330444336,
      "learning_rate": 8.956595744680852e-06,
      "loss": 0.0823,
      "step": 2534
    },
    {
      "epoch": 0.5824908088235294,
      "grad_norm": 1.2068593502044678,
      "learning_rate": 8.955744680851065e-06,
      "loss": 0.1492,
      "step": 2535
    },
    {
      "epoch": 0.5827205882352942,
      "grad_norm": 1.450547695159912,
      "learning_rate": 8.954893617021278e-06,
      "loss": 0.1907,
      "step": 2536
    },
    {
      "epoch": 0.5829503676470589,
      "grad_norm": 1.6375586986541748,
      "learning_rate": 8.95404255319149e-06,
      "loss": 0.1765,
      "step": 2537
    },
    {
      "epoch": 0.5831801470588235,
      "grad_norm": 1.2251065969467163,
      "learning_rate": 8.953191489361703e-06,
      "loss": 0.1196,
      "step": 2538
    },
    {
      "epoch": 0.5834099264705882,
      "grad_norm": 1.1571108102798462,
      "learning_rate": 8.952340425531916e-06,
      "loss": 0.1276,
      "step": 2539
    },
    {
      "epoch": 0.5836397058823529,
      "grad_norm": 1.1143693923950195,
      "learning_rate": 8.951489361702129e-06,
      "loss": 0.1051,
      "step": 2540
    },
    {
      "epoch": 0.5838694852941176,
      "grad_norm": 1.164617657661438,
      "learning_rate": 8.950638297872342e-06,
      "loss": 0.1456,
      "step": 2541
    },
    {
      "epoch": 0.5840992647058824,
      "grad_norm": 1.2820024490356445,
      "learning_rate": 8.949787234042554e-06,
      "loss": 0.1268,
      "step": 2542
    },
    {
      "epoch": 0.5843290441176471,
      "grad_norm": 1.3818491697311401,
      "learning_rate": 8.948936170212767e-06,
      "loss": 0.1309,
      "step": 2543
    },
    {
      "epoch": 0.5845588235294118,
      "grad_norm": 1.2357279062271118,
      "learning_rate": 8.94808510638298e-06,
      "loss": 0.1397,
      "step": 2544
    },
    {
      "epoch": 0.5847886029411765,
      "grad_norm": 1.176169514656067,
      "learning_rate": 8.947234042553193e-06,
      "loss": 0.1215,
      "step": 2545
    },
    {
      "epoch": 0.5850183823529411,
      "grad_norm": 1.1239023208618164,
      "learning_rate": 8.946382978723405e-06,
      "loss": 0.1185,
      "step": 2546
    },
    {
      "epoch": 0.5852481617647058,
      "grad_norm": 1.4070618152618408,
      "learning_rate": 8.945531914893618e-06,
      "loss": 0.196,
      "step": 2547
    },
    {
      "epoch": 0.5854779411764706,
      "grad_norm": 1.0045976638793945,
      "learning_rate": 8.944680851063831e-06,
      "loss": 0.0805,
      "step": 2548
    },
    {
      "epoch": 0.5857077205882353,
      "grad_norm": 1.3867188692092896,
      "learning_rate": 8.943829787234042e-06,
      "loss": 0.1101,
      "step": 2549
    },
    {
      "epoch": 0.5859375,
      "grad_norm": 2.876293420791626,
      "learning_rate": 8.942978723404257e-06,
      "loss": 0.1606,
      "step": 2550
    },
    {
      "epoch": 0.5861672794117647,
      "grad_norm": 0.9554956555366516,
      "learning_rate": 8.942127659574469e-06,
      "loss": 0.097,
      "step": 2551
    },
    {
      "epoch": 0.5863970588235294,
      "grad_norm": 1.2711691856384277,
      "learning_rate": 8.941276595744682e-06,
      "loss": 0.1409,
      "step": 2552
    },
    {
      "epoch": 0.5866268382352942,
      "grad_norm": 1.080070972442627,
      "learning_rate": 8.940425531914895e-06,
      "loss": 0.1384,
      "step": 2553
    },
    {
      "epoch": 0.5868566176470589,
      "grad_norm": 1.4235212802886963,
      "learning_rate": 8.939574468085107e-06,
      "loss": 0.0915,
      "step": 2554
    },
    {
      "epoch": 0.5870863970588235,
      "grad_norm": 1.520017147064209,
      "learning_rate": 8.93872340425532e-06,
      "loss": 0.1333,
      "step": 2555
    },
    {
      "epoch": 0.5873161764705882,
      "grad_norm": 1.4031096696853638,
      "learning_rate": 8.937872340425533e-06,
      "loss": 0.1497,
      "step": 2556
    },
    {
      "epoch": 0.5875459558823529,
      "grad_norm": 1.1504921913146973,
      "learning_rate": 8.937021276595746e-06,
      "loss": 0.1216,
      "step": 2557
    },
    {
      "epoch": 0.5877757352941176,
      "grad_norm": 1.1774871349334717,
      "learning_rate": 8.936170212765958e-06,
      "loss": 0.1097,
      "step": 2558
    },
    {
      "epoch": 0.5880055147058824,
      "grad_norm": 1.2215412855148315,
      "learning_rate": 8.93531914893617e-06,
      "loss": 0.1205,
      "step": 2559
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 1.0037517547607422,
      "learning_rate": 8.934468085106384e-06,
      "loss": 0.0916,
      "step": 2560
    },
    {
      "epoch": 0.5884650735294118,
      "grad_norm": 1.1975491046905518,
      "learning_rate": 8.933617021276595e-06,
      "loss": 0.1381,
      "step": 2561
    },
    {
      "epoch": 0.5886948529411765,
      "grad_norm": 1.441192626953125,
      "learning_rate": 8.93276595744681e-06,
      "loss": 0.0923,
      "step": 2562
    },
    {
      "epoch": 0.5889246323529411,
      "grad_norm": 1.463797926902771,
      "learning_rate": 8.931914893617022e-06,
      "loss": 0.1492,
      "step": 2563
    },
    {
      "epoch": 0.5891544117647058,
      "grad_norm": 0.9701676964759827,
      "learning_rate": 8.931063829787235e-06,
      "loss": 0.0837,
      "step": 2564
    },
    {
      "epoch": 0.5893841911764706,
      "grad_norm": 1.1624993085861206,
      "learning_rate": 8.930212765957448e-06,
      "loss": 0.1075,
      "step": 2565
    },
    {
      "epoch": 0.5896139705882353,
      "grad_norm": 1.3640676736831665,
      "learning_rate": 8.92936170212766e-06,
      "loss": 0.1212,
      "step": 2566
    },
    {
      "epoch": 0.58984375,
      "grad_norm": 1.3053951263427734,
      "learning_rate": 8.928510638297873e-06,
      "loss": 0.1636,
      "step": 2567
    },
    {
      "epoch": 0.5900735294117647,
      "grad_norm": 1.3944172859191895,
      "learning_rate": 8.927659574468086e-06,
      "loss": 0.123,
      "step": 2568
    },
    {
      "epoch": 0.5903033088235294,
      "grad_norm": 1.5813956260681152,
      "learning_rate": 8.926808510638299e-06,
      "loss": 0.1251,
      "step": 2569
    },
    {
      "epoch": 0.5905330882352942,
      "grad_norm": 1.137546181678772,
      "learning_rate": 8.92595744680851e-06,
      "loss": 0.121,
      "step": 2570
    },
    {
      "epoch": 0.5907628676470589,
      "grad_norm": 0.9020032286643982,
      "learning_rate": 8.925106382978724e-06,
      "loss": 0.1016,
      "step": 2571
    },
    {
      "epoch": 0.5909926470588235,
      "grad_norm": 1.5021322965621948,
      "learning_rate": 8.924255319148937e-06,
      "loss": 0.1263,
      "step": 2572
    },
    {
      "epoch": 0.5912224264705882,
      "grad_norm": 1.2809889316558838,
      "learning_rate": 8.923404255319148e-06,
      "loss": 0.1197,
      "step": 2573
    },
    {
      "epoch": 0.5914522058823529,
      "grad_norm": 1.3268293142318726,
      "learning_rate": 8.922553191489363e-06,
      "loss": 0.0861,
      "step": 2574
    },
    {
      "epoch": 0.5916819852941176,
      "grad_norm": 1.1092034578323364,
      "learning_rate": 8.921702127659575e-06,
      "loss": 0.1537,
      "step": 2575
    },
    {
      "epoch": 0.5919117647058824,
      "grad_norm": 1.3350332975387573,
      "learning_rate": 8.920851063829788e-06,
      "loss": 0.1132,
      "step": 2576
    },
    {
      "epoch": 0.5921415441176471,
      "grad_norm": 1.2966265678405762,
      "learning_rate": 8.920000000000001e-06,
      "loss": 0.1173,
      "step": 2577
    },
    {
      "epoch": 0.5923713235294118,
      "grad_norm": 1.3113996982574463,
      "learning_rate": 8.919148936170212e-06,
      "loss": 0.1145,
      "step": 2578
    },
    {
      "epoch": 0.5926011029411765,
      "grad_norm": 1.1315022706985474,
      "learning_rate": 8.918297872340427e-06,
      "loss": 0.0954,
      "step": 2579
    },
    {
      "epoch": 0.5928308823529411,
      "grad_norm": 1.3505256175994873,
      "learning_rate": 8.917446808510639e-06,
      "loss": 0.1313,
      "step": 2580
    },
    {
      "epoch": 0.5930606617647058,
      "grad_norm": 1.6017316579818726,
      "learning_rate": 8.916595744680852e-06,
      "loss": 0.1378,
      "step": 2581
    },
    {
      "epoch": 0.5932904411764706,
      "grad_norm": 1.6424576044082642,
      "learning_rate": 8.915744680851065e-06,
      "loss": 0.1522,
      "step": 2582
    },
    {
      "epoch": 0.5935202205882353,
      "grad_norm": 1.1846061944961548,
      "learning_rate": 8.914893617021277e-06,
      "loss": 0.1407,
      "step": 2583
    },
    {
      "epoch": 0.59375,
      "grad_norm": 1.89411199092865,
      "learning_rate": 8.91404255319149e-06,
      "loss": 0.1826,
      "step": 2584
    },
    {
      "epoch": 0.5939797794117647,
      "grad_norm": 1.23568856716156,
      "learning_rate": 8.913191489361703e-06,
      "loss": 0.0987,
      "step": 2585
    },
    {
      "epoch": 0.5942095588235294,
      "grad_norm": 1.1301751136779785,
      "learning_rate": 8.912340425531916e-06,
      "loss": 0.1281,
      "step": 2586
    },
    {
      "epoch": 0.5944393382352942,
      "grad_norm": 1.496671199798584,
      "learning_rate": 8.911489361702128e-06,
      "loss": 0.1349,
      "step": 2587
    },
    {
      "epoch": 0.5946691176470589,
      "grad_norm": 1.1131144762039185,
      "learning_rate": 8.91063829787234e-06,
      "loss": 0.1005,
      "step": 2588
    },
    {
      "epoch": 0.5948988970588235,
      "grad_norm": 1.5066900253295898,
      "learning_rate": 8.909787234042554e-06,
      "loss": 0.162,
      "step": 2589
    },
    {
      "epoch": 0.5951286764705882,
      "grad_norm": 0.9933569431304932,
      "learning_rate": 8.908936170212767e-06,
      "loss": 0.1204,
      "step": 2590
    },
    {
      "epoch": 0.5953584558823529,
      "grad_norm": 1.2207320928573608,
      "learning_rate": 8.90808510638298e-06,
      "loss": 0.1163,
      "step": 2591
    },
    {
      "epoch": 0.5955882352941176,
      "grad_norm": 1.2854920625686646,
      "learning_rate": 8.907234042553192e-06,
      "loss": 0.1616,
      "step": 2592
    },
    {
      "epoch": 0.5958180147058824,
      "grad_norm": 1.360550045967102,
      "learning_rate": 8.906382978723405e-06,
      "loss": 0.1196,
      "step": 2593
    },
    {
      "epoch": 0.5960477941176471,
      "grad_norm": 1.166045904159546,
      "learning_rate": 8.905531914893618e-06,
      "loss": 0.114,
      "step": 2594
    },
    {
      "epoch": 0.5962775735294118,
      "grad_norm": 1.1956175565719604,
      "learning_rate": 8.904680851063831e-06,
      "loss": 0.1211,
      "step": 2595
    },
    {
      "epoch": 0.5965073529411765,
      "grad_norm": 1.4290817975997925,
      "learning_rate": 8.903829787234043e-06,
      "loss": 0.1706,
      "step": 2596
    },
    {
      "epoch": 0.5967371323529411,
      "grad_norm": 1.3732839822769165,
      "learning_rate": 8.902978723404256e-06,
      "loss": 0.1006,
      "step": 2597
    },
    {
      "epoch": 0.5969669117647058,
      "grad_norm": 1.2514622211456299,
      "learning_rate": 8.902127659574469e-06,
      "loss": 0.1218,
      "step": 2598
    },
    {
      "epoch": 0.5971966911764706,
      "grad_norm": 1.9011225700378418,
      "learning_rate": 8.90127659574468e-06,
      "loss": 0.126,
      "step": 2599
    },
    {
      "epoch": 0.5974264705882353,
      "grad_norm": 1.3774020671844482,
      "learning_rate": 8.900425531914895e-06,
      "loss": 0.1428,
      "step": 2600
    },
    {
      "epoch": 0.59765625,
      "grad_norm": 1.270734190940857,
      "learning_rate": 8.899574468085107e-06,
      "loss": 0.1326,
      "step": 2601
    },
    {
      "epoch": 0.5978860294117647,
      "grad_norm": 1.4204243421554565,
      "learning_rate": 8.89872340425532e-06,
      "loss": 0.1045,
      "step": 2602
    },
    {
      "epoch": 0.5981158088235294,
      "grad_norm": 1.1455962657928467,
      "learning_rate": 8.897872340425533e-06,
      "loss": 0.1684,
      "step": 2603
    },
    {
      "epoch": 0.5983455882352942,
      "grad_norm": 1.1361792087554932,
      "learning_rate": 8.897021276595745e-06,
      "loss": 0.1117,
      "step": 2604
    },
    {
      "epoch": 0.5985753676470589,
      "grad_norm": 0.8434588313102722,
      "learning_rate": 8.896170212765958e-06,
      "loss": 0.0775,
      "step": 2605
    },
    {
      "epoch": 0.5988051470588235,
      "grad_norm": 1.2401760816574097,
      "learning_rate": 8.895319148936171e-06,
      "loss": 0.1185,
      "step": 2606
    },
    {
      "epoch": 0.5990349264705882,
      "grad_norm": 1.5184143781661987,
      "learning_rate": 8.894468085106384e-06,
      "loss": 0.0945,
      "step": 2607
    },
    {
      "epoch": 0.5992647058823529,
      "grad_norm": 1.3948904275894165,
      "learning_rate": 8.893617021276596e-06,
      "loss": 0.1253,
      "step": 2608
    },
    {
      "epoch": 0.5994944852941176,
      "grad_norm": 1.5636851787567139,
      "learning_rate": 8.892765957446809e-06,
      "loss": 0.1421,
      "step": 2609
    },
    {
      "epoch": 0.5997242647058824,
      "grad_norm": 2.041947603225708,
      "learning_rate": 8.891914893617022e-06,
      "loss": 0.1395,
      "step": 2610
    },
    {
      "epoch": 0.5999540441176471,
      "grad_norm": 1.5716984272003174,
      "learning_rate": 8.891063829787234e-06,
      "loss": 0.1302,
      "step": 2611
    },
    {
      "epoch": 0.6001838235294118,
      "grad_norm": 1.3158996105194092,
      "learning_rate": 8.890212765957448e-06,
      "loss": 0.1328,
      "step": 2612
    },
    {
      "epoch": 0.6004136029411765,
      "grad_norm": 1.4212554693222046,
      "learning_rate": 8.88936170212766e-06,
      "loss": 0.1619,
      "step": 2613
    },
    {
      "epoch": 0.6006433823529411,
      "grad_norm": 1.2054874897003174,
      "learning_rate": 8.888510638297873e-06,
      "loss": 0.1163,
      "step": 2614
    },
    {
      "epoch": 0.6008731617647058,
      "grad_norm": 1.3140263557434082,
      "learning_rate": 8.887659574468086e-06,
      "loss": 0.1326,
      "step": 2615
    },
    {
      "epoch": 0.6011029411764706,
      "grad_norm": 1.0883934497833252,
      "learning_rate": 8.886808510638298e-06,
      "loss": 0.1016,
      "step": 2616
    },
    {
      "epoch": 0.6013327205882353,
      "grad_norm": 1.2703136205673218,
      "learning_rate": 8.885957446808513e-06,
      "loss": 0.1485,
      "step": 2617
    },
    {
      "epoch": 0.6015625,
      "grad_norm": 1.4290757179260254,
      "learning_rate": 8.885106382978724e-06,
      "loss": 0.122,
      "step": 2618
    },
    {
      "epoch": 0.6017922794117647,
      "grad_norm": 1.3373093605041504,
      "learning_rate": 8.884255319148937e-06,
      "loss": 0.122,
      "step": 2619
    },
    {
      "epoch": 0.6020220588235294,
      "grad_norm": 1.80846107006073,
      "learning_rate": 8.88340425531915e-06,
      "loss": 0.1255,
      "step": 2620
    },
    {
      "epoch": 0.6022518382352942,
      "grad_norm": 2.603245735168457,
      "learning_rate": 8.882553191489362e-06,
      "loss": 0.1562,
      "step": 2621
    },
    {
      "epoch": 0.6024816176470589,
      "grad_norm": 1.6532886028289795,
      "learning_rate": 8.881702127659575e-06,
      "loss": 0.1374,
      "step": 2622
    },
    {
      "epoch": 0.6027113970588235,
      "grad_norm": 1.3962749242782593,
      "learning_rate": 8.880851063829788e-06,
      "loss": 0.1223,
      "step": 2623
    },
    {
      "epoch": 0.6029411764705882,
      "grad_norm": 1.3838871717453003,
      "learning_rate": 8.880000000000001e-06,
      "loss": 0.1251,
      "step": 2624
    },
    {
      "epoch": 0.6031709558823529,
      "grad_norm": 1.0349372625350952,
      "learning_rate": 8.879148936170213e-06,
      "loss": 0.1051,
      "step": 2625
    },
    {
      "epoch": 0.6034007352941176,
      "grad_norm": 1.3280112743377686,
      "learning_rate": 8.878297872340426e-06,
      "loss": 0.1304,
      "step": 2626
    },
    {
      "epoch": 0.6036305147058824,
      "grad_norm": 1.370768666267395,
      "learning_rate": 8.87744680851064e-06,
      "loss": 0.1041,
      "step": 2627
    },
    {
      "epoch": 0.6038602941176471,
      "grad_norm": 1.3324596881866455,
      "learning_rate": 8.87659574468085e-06,
      "loss": 0.1297,
      "step": 2628
    },
    {
      "epoch": 0.6040900735294118,
      "grad_norm": 1.3815010786056519,
      "learning_rate": 8.875744680851066e-06,
      "loss": 0.1388,
      "step": 2629
    },
    {
      "epoch": 0.6043198529411765,
      "grad_norm": 1.0283764600753784,
      "learning_rate": 8.874893617021277e-06,
      "loss": 0.089,
      "step": 2630
    },
    {
      "epoch": 0.6045496323529411,
      "grad_norm": 1.5359728336334229,
      "learning_rate": 8.87404255319149e-06,
      "loss": 0.1181,
      "step": 2631
    },
    {
      "epoch": 0.6047794117647058,
      "grad_norm": 1.1861302852630615,
      "learning_rate": 8.873191489361703e-06,
      "loss": 0.1299,
      "step": 2632
    },
    {
      "epoch": 0.6050091911764706,
      "grad_norm": 1.152430534362793,
      "learning_rate": 8.872340425531915e-06,
      "loss": 0.1231,
      "step": 2633
    },
    {
      "epoch": 0.6052389705882353,
      "grad_norm": 1.0275828838348389,
      "learning_rate": 8.871489361702128e-06,
      "loss": 0.1127,
      "step": 2634
    },
    {
      "epoch": 0.60546875,
      "grad_norm": 1.434720516204834,
      "learning_rate": 8.870638297872341e-06,
      "loss": 0.1322,
      "step": 2635
    },
    {
      "epoch": 0.6056985294117647,
      "grad_norm": 1.2379815578460693,
      "learning_rate": 8.869787234042554e-06,
      "loss": 0.1059,
      "step": 2636
    },
    {
      "epoch": 0.6059283088235294,
      "grad_norm": 1.8139138221740723,
      "learning_rate": 8.868936170212766e-06,
      "loss": 0.1422,
      "step": 2637
    },
    {
      "epoch": 0.6061580882352942,
      "grad_norm": 1.2579154968261719,
      "learning_rate": 8.868085106382979e-06,
      "loss": 0.1377,
      "step": 2638
    },
    {
      "epoch": 0.6063878676470589,
      "grad_norm": 1.8949447870254517,
      "learning_rate": 8.867234042553192e-06,
      "loss": 0.1395,
      "step": 2639
    },
    {
      "epoch": 0.6066176470588235,
      "grad_norm": 0.8620058298110962,
      "learning_rate": 8.866382978723405e-06,
      "loss": 0.1106,
      "step": 2640
    },
    {
      "epoch": 0.6068474264705882,
      "grad_norm": 1.5755140781402588,
      "learning_rate": 8.865531914893619e-06,
      "loss": 0.1528,
      "step": 2641
    },
    {
      "epoch": 0.6070772058823529,
      "grad_norm": 1.4744783639907837,
      "learning_rate": 8.86468085106383e-06,
      "loss": 0.1249,
      "step": 2642
    },
    {
      "epoch": 0.6073069852941176,
      "grad_norm": 1.1579194068908691,
      "learning_rate": 8.863829787234043e-06,
      "loss": 0.1453,
      "step": 2643
    },
    {
      "epoch": 0.6075367647058824,
      "grad_norm": 1.1563230752944946,
      "learning_rate": 8.862978723404256e-06,
      "loss": 0.1181,
      "step": 2644
    },
    {
      "epoch": 0.6077665441176471,
      "grad_norm": 1.3731849193572998,
      "learning_rate": 8.86212765957447e-06,
      "loss": 0.1474,
      "step": 2645
    },
    {
      "epoch": 0.6079963235294118,
      "grad_norm": 1.4164644479751587,
      "learning_rate": 8.861276595744681e-06,
      "loss": 0.1354,
      "step": 2646
    },
    {
      "epoch": 0.6082261029411765,
      "grad_norm": 1.433690071105957,
      "learning_rate": 8.860425531914894e-06,
      "loss": 0.1121,
      "step": 2647
    },
    {
      "epoch": 0.6084558823529411,
      "grad_norm": 1.0130579471588135,
      "learning_rate": 8.859574468085107e-06,
      "loss": 0.1085,
      "step": 2648
    },
    {
      "epoch": 0.6086856617647058,
      "grad_norm": 1.17628812789917,
      "learning_rate": 8.858723404255319e-06,
      "loss": 0.1051,
      "step": 2649
    },
    {
      "epoch": 0.6089154411764706,
      "grad_norm": 1.2995048761367798,
      "learning_rate": 8.857872340425534e-06,
      "loss": 0.1691,
      "step": 2650
    },
    {
      "epoch": 0.6091452205882353,
      "grad_norm": 1.0482730865478516,
      "learning_rate": 8.857021276595745e-06,
      "loss": 0.1127,
      "step": 2651
    },
    {
      "epoch": 0.609375,
      "grad_norm": 1.0043612718582153,
      "learning_rate": 8.856170212765958e-06,
      "loss": 0.0999,
      "step": 2652
    },
    {
      "epoch": 0.6096047794117647,
      "grad_norm": 1.4630788564682007,
      "learning_rate": 8.855319148936171e-06,
      "loss": 0.1069,
      "step": 2653
    },
    {
      "epoch": 0.6098345588235294,
      "grad_norm": 1.5487887859344482,
      "learning_rate": 8.854468085106383e-06,
      "loss": 0.1415,
      "step": 2654
    },
    {
      "epoch": 0.6100643382352942,
      "grad_norm": 1.4310047626495361,
      "learning_rate": 8.853617021276596e-06,
      "loss": 0.1185,
      "step": 2655
    },
    {
      "epoch": 0.6102941176470589,
      "grad_norm": 1.4128578901290894,
      "learning_rate": 8.85276595744681e-06,
      "loss": 0.1297,
      "step": 2656
    },
    {
      "epoch": 0.6105238970588235,
      "grad_norm": 1.305553674697876,
      "learning_rate": 8.851914893617022e-06,
      "loss": 0.1268,
      "step": 2657
    },
    {
      "epoch": 0.6107536764705882,
      "grad_norm": 1.1154954433441162,
      "learning_rate": 8.851063829787234e-06,
      "loss": 0.1356,
      "step": 2658
    },
    {
      "epoch": 0.6109834558823529,
      "grad_norm": 1.4442681074142456,
      "learning_rate": 8.850212765957447e-06,
      "loss": 0.1386,
      "step": 2659
    },
    {
      "epoch": 0.6112132352941176,
      "grad_norm": 1.2035763263702393,
      "learning_rate": 8.84936170212766e-06,
      "loss": 0.1128,
      "step": 2660
    },
    {
      "epoch": 0.6114430147058824,
      "grad_norm": 0.9918310046195984,
      "learning_rate": 8.848510638297873e-06,
      "loss": 0.0999,
      "step": 2661
    },
    {
      "epoch": 0.6116727941176471,
      "grad_norm": 1.1700935363769531,
      "learning_rate": 8.847659574468087e-06,
      "loss": 0.1106,
      "step": 2662
    },
    {
      "epoch": 0.6119025735294118,
      "grad_norm": 1.321357250213623,
      "learning_rate": 8.846808510638298e-06,
      "loss": 0.1394,
      "step": 2663
    },
    {
      "epoch": 0.6121323529411765,
      "grad_norm": 1.7689176797866821,
      "learning_rate": 8.845957446808511e-06,
      "loss": 0.1172,
      "step": 2664
    },
    {
      "epoch": 0.6123621323529411,
      "grad_norm": 1.3082060813903809,
      "learning_rate": 8.845106382978724e-06,
      "loss": 0.1314,
      "step": 2665
    },
    {
      "epoch": 0.6125919117647058,
      "grad_norm": 1.2078468799591064,
      "learning_rate": 8.844255319148936e-06,
      "loss": 0.1494,
      "step": 2666
    },
    {
      "epoch": 0.6128216911764706,
      "grad_norm": 1.3924132585525513,
      "learning_rate": 8.84340425531915e-06,
      "loss": 0.1123,
      "step": 2667
    },
    {
      "epoch": 0.6130514705882353,
      "grad_norm": 0.9822233319282532,
      "learning_rate": 8.842553191489362e-06,
      "loss": 0.1031,
      "step": 2668
    },
    {
      "epoch": 0.61328125,
      "grad_norm": 1.5569392442703247,
      "learning_rate": 8.841702127659575e-06,
      "loss": 0.1293,
      "step": 2669
    },
    {
      "epoch": 0.6135110294117647,
      "grad_norm": 1.392503023147583,
      "learning_rate": 8.840851063829789e-06,
      "loss": 0.1246,
      "step": 2670
    },
    {
      "epoch": 0.6137408088235294,
      "grad_norm": 1.425920844078064,
      "learning_rate": 8.84e-06,
      "loss": 0.1167,
      "step": 2671
    },
    {
      "epoch": 0.6139705882352942,
      "grad_norm": 1.1607139110565186,
      "learning_rate": 8.839148936170213e-06,
      "loss": 0.1017,
      "step": 2672
    },
    {
      "epoch": 0.6142003676470589,
      "grad_norm": 1.0224140882492065,
      "learning_rate": 8.838297872340426e-06,
      "loss": 0.1008,
      "step": 2673
    },
    {
      "epoch": 0.6144301470588235,
      "grad_norm": 1.7157102823257446,
      "learning_rate": 8.83744680851064e-06,
      "loss": 0.1516,
      "step": 2674
    },
    {
      "epoch": 0.6146599264705882,
      "grad_norm": 1.4898141622543335,
      "learning_rate": 8.836595744680851e-06,
      "loss": 0.1262,
      "step": 2675
    },
    {
      "epoch": 0.6148897058823529,
      "grad_norm": 1.685417652130127,
      "learning_rate": 8.835744680851064e-06,
      "loss": 0.1139,
      "step": 2676
    },
    {
      "epoch": 0.6151194852941176,
      "grad_norm": 1.2580249309539795,
      "learning_rate": 8.834893617021277e-06,
      "loss": 0.1323,
      "step": 2677
    },
    {
      "epoch": 0.6153492647058824,
      "grad_norm": 1.6403911113739014,
      "learning_rate": 8.83404255319149e-06,
      "loss": 0.1389,
      "step": 2678
    },
    {
      "epoch": 0.6155790441176471,
      "grad_norm": 1.050902009010315,
      "learning_rate": 8.833191489361704e-06,
      "loss": 0.0865,
      "step": 2679
    },
    {
      "epoch": 0.6158088235294118,
      "grad_norm": 1.8475825786590576,
      "learning_rate": 8.832340425531915e-06,
      "loss": 0.1484,
      "step": 2680
    },
    {
      "epoch": 0.6160386029411765,
      "grad_norm": 1.1659595966339111,
      "learning_rate": 8.831489361702128e-06,
      "loss": 0.1325,
      "step": 2681
    },
    {
      "epoch": 0.6162683823529411,
      "grad_norm": 1.5231059789657593,
      "learning_rate": 8.830638297872342e-06,
      "loss": 0.1235,
      "step": 2682
    },
    {
      "epoch": 0.6164981617647058,
      "grad_norm": 1.5192922353744507,
      "learning_rate": 8.829787234042555e-06,
      "loss": 0.1423,
      "step": 2683
    },
    {
      "epoch": 0.6167279411764706,
      "grad_norm": 1.194989800453186,
      "learning_rate": 8.828936170212766e-06,
      "loss": 0.1391,
      "step": 2684
    },
    {
      "epoch": 0.6169577205882353,
      "grad_norm": 1.3559948205947876,
      "learning_rate": 8.82808510638298e-06,
      "loss": 0.1365,
      "step": 2685
    },
    {
      "epoch": 0.6171875,
      "grad_norm": 1.5585792064666748,
      "learning_rate": 8.827234042553193e-06,
      "loss": 0.1282,
      "step": 2686
    },
    {
      "epoch": 0.6174172794117647,
      "grad_norm": 1.2551770210266113,
      "learning_rate": 8.826382978723404e-06,
      "loss": 0.1405,
      "step": 2687
    },
    {
      "epoch": 0.6176470588235294,
      "grad_norm": 1.045109510421753,
      "learning_rate": 8.825531914893619e-06,
      "loss": 0.1025,
      "step": 2688
    },
    {
      "epoch": 0.6178768382352942,
      "grad_norm": 1.136684536933899,
      "learning_rate": 8.82468085106383e-06,
      "loss": 0.0936,
      "step": 2689
    },
    {
      "epoch": 0.6181066176470589,
      "grad_norm": 1.4699198007583618,
      "learning_rate": 8.823829787234044e-06,
      "loss": 0.1436,
      "step": 2690
    },
    {
      "epoch": 0.6183363970588235,
      "grad_norm": 1.1484721899032593,
      "learning_rate": 8.822978723404257e-06,
      "loss": 0.1577,
      "step": 2691
    },
    {
      "epoch": 0.6185661764705882,
      "grad_norm": 1.801112174987793,
      "learning_rate": 8.822127659574468e-06,
      "loss": 0.1345,
      "step": 2692
    },
    {
      "epoch": 0.6187959558823529,
      "grad_norm": 1.4388161897659302,
      "learning_rate": 8.821276595744681e-06,
      "loss": 0.1626,
      "step": 2693
    },
    {
      "epoch": 0.6190257352941176,
      "grad_norm": 1.2403548955917358,
      "learning_rate": 8.820425531914895e-06,
      "loss": 0.1093,
      "step": 2694
    },
    {
      "epoch": 0.6192555147058824,
      "grad_norm": 1.3074079751968384,
      "learning_rate": 8.819574468085108e-06,
      "loss": 0.0977,
      "step": 2695
    },
    {
      "epoch": 0.6194852941176471,
      "grad_norm": 1.2897752523422241,
      "learning_rate": 8.81872340425532e-06,
      "loss": 0.1144,
      "step": 2696
    },
    {
      "epoch": 0.6197150735294118,
      "grad_norm": 1.0322990417480469,
      "learning_rate": 8.817872340425532e-06,
      "loss": 0.0872,
      "step": 2697
    },
    {
      "epoch": 0.6199448529411765,
      "grad_norm": 1.440670132637024,
      "learning_rate": 8.817021276595746e-06,
      "loss": 0.1424,
      "step": 2698
    },
    {
      "epoch": 0.6201746323529411,
      "grad_norm": 1.3368669748306274,
      "learning_rate": 8.816170212765957e-06,
      "loss": 0.1004,
      "step": 2699
    },
    {
      "epoch": 0.6204044117647058,
      "grad_norm": 1.2198976278305054,
      "learning_rate": 8.815319148936172e-06,
      "loss": 0.1124,
      "step": 2700
    },
    {
      "epoch": 0.6206341911764706,
      "grad_norm": 1.4319798946380615,
      "learning_rate": 8.814468085106383e-06,
      "loss": 0.129,
      "step": 2701
    },
    {
      "epoch": 0.6208639705882353,
      "grad_norm": 0.9671040177345276,
      "learning_rate": 8.813617021276596e-06,
      "loss": 0.0939,
      "step": 2702
    },
    {
      "epoch": 0.62109375,
      "grad_norm": 1.224634051322937,
      "learning_rate": 8.81276595744681e-06,
      "loss": 0.1345,
      "step": 2703
    },
    {
      "epoch": 0.6213235294117647,
      "grad_norm": 1.4085392951965332,
      "learning_rate": 8.811914893617021e-06,
      "loss": 0.1212,
      "step": 2704
    },
    {
      "epoch": 0.6215533088235294,
      "grad_norm": 1.5129047632217407,
      "learning_rate": 8.811063829787236e-06,
      "loss": 0.1701,
      "step": 2705
    },
    {
      "epoch": 0.6217830882352942,
      "grad_norm": 1.6335656642913818,
      "learning_rate": 8.810212765957447e-06,
      "loss": 0.1365,
      "step": 2706
    },
    {
      "epoch": 0.6220128676470589,
      "grad_norm": 1.3304975032806396,
      "learning_rate": 8.80936170212766e-06,
      "loss": 0.1396,
      "step": 2707
    },
    {
      "epoch": 0.6222426470588235,
      "grad_norm": 1.3362699747085571,
      "learning_rate": 8.808510638297874e-06,
      "loss": 0.1396,
      "step": 2708
    },
    {
      "epoch": 0.6224724264705882,
      "grad_norm": 1.6434478759765625,
      "learning_rate": 8.807659574468085e-06,
      "loss": 0.1249,
      "step": 2709
    },
    {
      "epoch": 0.6227022058823529,
      "grad_norm": 1.184939980506897,
      "learning_rate": 8.806808510638298e-06,
      "loss": 0.1345,
      "step": 2710
    },
    {
      "epoch": 0.6229319852941176,
      "grad_norm": 1.2204604148864746,
      "learning_rate": 8.805957446808512e-06,
      "loss": 0.1078,
      "step": 2711
    },
    {
      "epoch": 0.6231617647058824,
      "grad_norm": 1.330396056175232,
      "learning_rate": 8.805106382978725e-06,
      "loss": 0.0958,
      "step": 2712
    },
    {
      "epoch": 0.6233915441176471,
      "grad_norm": 1.3416246175765991,
      "learning_rate": 8.804255319148936e-06,
      "loss": 0.1081,
      "step": 2713
    },
    {
      "epoch": 0.6236213235294118,
      "grad_norm": 0.9264417886734009,
      "learning_rate": 8.80340425531915e-06,
      "loss": 0.1011,
      "step": 2714
    },
    {
      "epoch": 0.6238511029411765,
      "grad_norm": 1.210763692855835,
      "learning_rate": 8.802553191489363e-06,
      "loss": 0.1937,
      "step": 2715
    },
    {
      "epoch": 0.6240808823529411,
      "grad_norm": 1.318039059638977,
      "learning_rate": 8.801702127659574e-06,
      "loss": 0.1483,
      "step": 2716
    },
    {
      "epoch": 0.6243106617647058,
      "grad_norm": 1.3629831075668335,
      "learning_rate": 8.800851063829789e-06,
      "loss": 0.1292,
      "step": 2717
    },
    {
      "epoch": 0.6245404411764706,
      "grad_norm": 1.5746623277664185,
      "learning_rate": 8.8e-06,
      "loss": 0.1004,
      "step": 2718
    },
    {
      "epoch": 0.6247702205882353,
      "grad_norm": 1.335085153579712,
      "learning_rate": 8.799148936170214e-06,
      "loss": 0.0969,
      "step": 2719
    },
    {
      "epoch": 0.625,
      "grad_norm": 1.4750151634216309,
      "learning_rate": 8.798297872340427e-06,
      "loss": 0.1272,
      "step": 2720
    },
    {
      "epoch": 0.6252297794117647,
      "grad_norm": 0.9204778075218201,
      "learning_rate": 8.797446808510638e-06,
      "loss": 0.1136,
      "step": 2721
    },
    {
      "epoch": 0.6254595588235294,
      "grad_norm": 1.3999842405319214,
      "learning_rate": 8.796595744680851e-06,
      "loss": 0.1485,
      "step": 2722
    },
    {
      "epoch": 0.6256893382352942,
      "grad_norm": 1.1706963777542114,
      "learning_rate": 8.795744680851065e-06,
      "loss": 0.1233,
      "step": 2723
    },
    {
      "epoch": 0.6259191176470589,
      "grad_norm": 1.182482361793518,
      "learning_rate": 8.794893617021278e-06,
      "loss": 0.129,
      "step": 2724
    },
    {
      "epoch": 0.6261488970588235,
      "grad_norm": 1.2315768003463745,
      "learning_rate": 8.79404255319149e-06,
      "loss": 0.1055,
      "step": 2725
    },
    {
      "epoch": 0.6263786764705882,
      "grad_norm": 1.0673078298568726,
      "learning_rate": 8.793191489361702e-06,
      "loss": 0.1316,
      "step": 2726
    },
    {
      "epoch": 0.6266084558823529,
      "grad_norm": 1.2223607301712036,
      "learning_rate": 8.792340425531916e-06,
      "loss": 0.1059,
      "step": 2727
    },
    {
      "epoch": 0.6268382352941176,
      "grad_norm": 1.3091946840286255,
      "learning_rate": 8.791489361702129e-06,
      "loss": 0.1493,
      "step": 2728
    },
    {
      "epoch": 0.6270680147058824,
      "grad_norm": 1.5535458326339722,
      "learning_rate": 8.790638297872342e-06,
      "loss": 0.1405,
      "step": 2729
    },
    {
      "epoch": 0.6272977941176471,
      "grad_norm": 1.24111807346344,
      "learning_rate": 8.789787234042553e-06,
      "loss": 0.1672,
      "step": 2730
    },
    {
      "epoch": 0.6275275735294118,
      "grad_norm": 1.5044714212417603,
      "learning_rate": 8.788936170212767e-06,
      "loss": 0.149,
      "step": 2731
    },
    {
      "epoch": 0.6277573529411765,
      "grad_norm": 1.2135039567947388,
      "learning_rate": 8.78808510638298e-06,
      "loss": 0.1126,
      "step": 2732
    },
    {
      "epoch": 0.6279871323529411,
      "grad_norm": 1.3770670890808105,
      "learning_rate": 8.787234042553193e-06,
      "loss": 0.1063,
      "step": 2733
    },
    {
      "epoch": 0.6282169117647058,
      "grad_norm": 1.3272546529769897,
      "learning_rate": 8.786382978723404e-06,
      "loss": 0.1463,
      "step": 2734
    },
    {
      "epoch": 0.6284466911764706,
      "grad_norm": 1.6735962629318237,
      "learning_rate": 8.785531914893618e-06,
      "loss": 0.1248,
      "step": 2735
    },
    {
      "epoch": 0.6286764705882353,
      "grad_norm": 1.615355372428894,
      "learning_rate": 8.78468085106383e-06,
      "loss": 0.1272,
      "step": 2736
    },
    {
      "epoch": 0.62890625,
      "grad_norm": 1.453027367591858,
      "learning_rate": 8.783829787234042e-06,
      "loss": 0.1499,
      "step": 2737
    },
    {
      "epoch": 0.6291360294117647,
      "grad_norm": 1.5412192344665527,
      "learning_rate": 8.782978723404257e-06,
      "loss": 0.1719,
      "step": 2738
    },
    {
      "epoch": 0.6293658088235294,
      "grad_norm": 1.3233227729797363,
      "learning_rate": 8.782127659574469e-06,
      "loss": 0.1055,
      "step": 2739
    },
    {
      "epoch": 0.6295955882352942,
      "grad_norm": 1.4499742984771729,
      "learning_rate": 8.781276595744682e-06,
      "loss": 0.147,
      "step": 2740
    },
    {
      "epoch": 0.6298253676470589,
      "grad_norm": 1.4754390716552734,
      "learning_rate": 8.780425531914895e-06,
      "loss": 0.1077,
      "step": 2741
    },
    {
      "epoch": 0.6300551470588235,
      "grad_norm": 1.0424336194992065,
      "learning_rate": 8.779574468085106e-06,
      "loss": 0.1389,
      "step": 2742
    },
    {
      "epoch": 0.6302849264705882,
      "grad_norm": 1.3951495885849,
      "learning_rate": 8.77872340425532e-06,
      "loss": 0.1081,
      "step": 2743
    },
    {
      "epoch": 0.6305147058823529,
      "grad_norm": 1.3222428560256958,
      "learning_rate": 8.777872340425533e-06,
      "loss": 0.1519,
      "step": 2744
    },
    {
      "epoch": 0.6307444852941176,
      "grad_norm": 1.3087644577026367,
      "learning_rate": 8.777021276595746e-06,
      "loss": 0.1419,
      "step": 2745
    },
    {
      "epoch": 0.6309742647058824,
      "grad_norm": 1.452806830406189,
      "learning_rate": 8.776170212765959e-06,
      "loss": 0.145,
      "step": 2746
    },
    {
      "epoch": 0.6312040441176471,
      "grad_norm": 1.2859256267547607,
      "learning_rate": 8.77531914893617e-06,
      "loss": 0.1145,
      "step": 2747
    },
    {
      "epoch": 0.6314338235294118,
      "grad_norm": 1.5792654752731323,
      "learning_rate": 8.774468085106384e-06,
      "loss": 0.1578,
      "step": 2748
    },
    {
      "epoch": 0.6316636029411765,
      "grad_norm": 1.3344531059265137,
      "learning_rate": 8.773617021276597e-06,
      "loss": 0.1216,
      "step": 2749
    },
    {
      "epoch": 0.6318933823529411,
      "grad_norm": 1.612991213798523,
      "learning_rate": 8.77276595744681e-06,
      "loss": 0.1374,
      "step": 2750
    },
    {
      "epoch": 0.6321231617647058,
      "grad_norm": 1.2124578952789307,
      "learning_rate": 8.771914893617022e-06,
      "loss": 0.1389,
      "step": 2751
    },
    {
      "epoch": 0.6323529411764706,
      "grad_norm": 1.1164631843566895,
      "learning_rate": 8.771063829787235e-06,
      "loss": 0.1068,
      "step": 2752
    },
    {
      "epoch": 0.6325827205882353,
      "grad_norm": 1.1708927154541016,
      "learning_rate": 8.770212765957448e-06,
      "loss": 0.0859,
      "step": 2753
    },
    {
      "epoch": 0.6328125,
      "grad_norm": 1.7684762477874756,
      "learning_rate": 8.76936170212766e-06,
      "loss": 0.1404,
      "step": 2754
    },
    {
      "epoch": 0.6330422794117647,
      "grad_norm": 1.2836203575134277,
      "learning_rate": 8.768510638297874e-06,
      "loss": 0.1249,
      "step": 2755
    },
    {
      "epoch": 0.6332720588235294,
      "grad_norm": 1.3012815713882446,
      "learning_rate": 8.767659574468086e-06,
      "loss": 0.1169,
      "step": 2756
    },
    {
      "epoch": 0.6335018382352942,
      "grad_norm": 1.811056137084961,
      "learning_rate": 8.766808510638299e-06,
      "loss": 0.1172,
      "step": 2757
    },
    {
      "epoch": 0.6337316176470589,
      "grad_norm": 1.2823569774627686,
      "learning_rate": 8.765957446808512e-06,
      "loss": 0.1368,
      "step": 2758
    },
    {
      "epoch": 0.6339613970588235,
      "grad_norm": 1.6649686098098755,
      "learning_rate": 8.765106382978724e-06,
      "loss": 0.1165,
      "step": 2759
    },
    {
      "epoch": 0.6341911764705882,
      "grad_norm": 1.9774738550186157,
      "learning_rate": 8.764255319148937e-06,
      "loss": 0.2071,
      "step": 2760
    },
    {
      "epoch": 0.6344209558823529,
      "grad_norm": 1.4152354001998901,
      "learning_rate": 8.76340425531915e-06,
      "loss": 0.1333,
      "step": 2761
    },
    {
      "epoch": 0.6346507352941176,
      "grad_norm": 1.0438649654388428,
      "learning_rate": 8.762553191489363e-06,
      "loss": 0.102,
      "step": 2762
    },
    {
      "epoch": 0.6348805147058824,
      "grad_norm": 1.1952722072601318,
      "learning_rate": 8.761702127659574e-06,
      "loss": 0.1187,
      "step": 2763
    },
    {
      "epoch": 0.6351102941176471,
      "grad_norm": 1.3231369256973267,
      "learning_rate": 8.760851063829788e-06,
      "loss": 0.121,
      "step": 2764
    },
    {
      "epoch": 0.6353400735294118,
      "grad_norm": 1.0950459241867065,
      "learning_rate": 8.76e-06,
      "loss": 0.1368,
      "step": 2765
    },
    {
      "epoch": 0.6355698529411765,
      "grad_norm": 1.2979090213775635,
      "learning_rate": 8.759148936170212e-06,
      "loss": 0.1308,
      "step": 2766
    },
    {
      "epoch": 0.6357996323529411,
      "grad_norm": 1.1720356941223145,
      "learning_rate": 8.758297872340427e-06,
      "loss": 0.1331,
      "step": 2767
    },
    {
      "epoch": 0.6360294117647058,
      "grad_norm": 1.0467653274536133,
      "learning_rate": 8.757446808510639e-06,
      "loss": 0.1568,
      "step": 2768
    },
    {
      "epoch": 0.6362591911764706,
      "grad_norm": 1.2153860330581665,
      "learning_rate": 8.756595744680852e-06,
      "loss": 0.137,
      "step": 2769
    },
    {
      "epoch": 0.6364889705882353,
      "grad_norm": 1.3311569690704346,
      "learning_rate": 8.755744680851065e-06,
      "loss": 0.1345,
      "step": 2770
    },
    {
      "epoch": 0.63671875,
      "grad_norm": 1.669870376586914,
      "learning_rate": 8.754893617021276e-06,
      "loss": 0.1403,
      "step": 2771
    },
    {
      "epoch": 0.6369485294117647,
      "grad_norm": 1.4020863771438599,
      "learning_rate": 8.75404255319149e-06,
      "loss": 0.1481,
      "step": 2772
    },
    {
      "epoch": 0.6371783088235294,
      "grad_norm": 1.3114304542541504,
      "learning_rate": 8.753191489361703e-06,
      "loss": 0.1521,
      "step": 2773
    },
    {
      "epoch": 0.6374080882352942,
      "grad_norm": 1.3491653203964233,
      "learning_rate": 8.752340425531916e-06,
      "loss": 0.0845,
      "step": 2774
    },
    {
      "epoch": 0.6376378676470589,
      "grad_norm": 1.6440775394439697,
      "learning_rate": 8.751489361702127e-06,
      "loss": 0.1343,
      "step": 2775
    },
    {
      "epoch": 0.6378676470588235,
      "grad_norm": 1.3909837007522583,
      "learning_rate": 8.75063829787234e-06,
      "loss": 0.1136,
      "step": 2776
    },
    {
      "epoch": 0.6380974264705882,
      "grad_norm": 1.6923434734344482,
      "learning_rate": 8.749787234042554e-06,
      "loss": 0.136,
      "step": 2777
    },
    {
      "epoch": 0.6383272058823529,
      "grad_norm": 1.0496240854263306,
      "learning_rate": 8.748936170212767e-06,
      "loss": 0.1166,
      "step": 2778
    },
    {
      "epoch": 0.6385569852941176,
      "grad_norm": 1.7104123830795288,
      "learning_rate": 8.74808510638298e-06,
      "loss": 0.137,
      "step": 2779
    },
    {
      "epoch": 0.6387867647058824,
      "grad_norm": 1.3504667282104492,
      "learning_rate": 8.747234042553192e-06,
      "loss": 0.134,
      "step": 2780
    },
    {
      "epoch": 0.6390165441176471,
      "grad_norm": 1.6400800943374634,
      "learning_rate": 8.746382978723405e-06,
      "loss": 0.1334,
      "step": 2781
    },
    {
      "epoch": 0.6392463235294118,
      "grad_norm": 1.7260618209838867,
      "learning_rate": 8.745531914893618e-06,
      "loss": 0.1124,
      "step": 2782
    },
    {
      "epoch": 0.6394761029411765,
      "grad_norm": 1.3816431760787964,
      "learning_rate": 8.744680851063831e-06,
      "loss": 0.1448,
      "step": 2783
    },
    {
      "epoch": 0.6397058823529411,
      "grad_norm": 1.395137071609497,
      "learning_rate": 8.743829787234043e-06,
      "loss": 0.1382,
      "step": 2784
    },
    {
      "epoch": 0.6399356617647058,
      "grad_norm": 1.1043543815612793,
      "learning_rate": 8.742978723404256e-06,
      "loss": 0.1141,
      "step": 2785
    },
    {
      "epoch": 0.6401654411764706,
      "grad_norm": 1.3736459016799927,
      "learning_rate": 8.742127659574469e-06,
      "loss": 0.11,
      "step": 2786
    },
    {
      "epoch": 0.6403952205882353,
      "grad_norm": 2.1665849685668945,
      "learning_rate": 8.74127659574468e-06,
      "loss": 0.1317,
      "step": 2787
    },
    {
      "epoch": 0.640625,
      "grad_norm": 2.057563543319702,
      "learning_rate": 8.740425531914895e-06,
      "loss": 0.1529,
      "step": 2788
    },
    {
      "epoch": 0.6408547794117647,
      "grad_norm": 1.5461430549621582,
      "learning_rate": 8.739574468085107e-06,
      "loss": 0.1004,
      "step": 2789
    },
    {
      "epoch": 0.6410845588235294,
      "grad_norm": 1.68666410446167,
      "learning_rate": 8.73872340425532e-06,
      "loss": 0.1181,
      "step": 2790
    },
    {
      "epoch": 0.6413143382352942,
      "grad_norm": 1.4818027019500732,
      "learning_rate": 8.737872340425533e-06,
      "loss": 0.1145,
      "step": 2791
    },
    {
      "epoch": 0.6415441176470589,
      "grad_norm": 1.535130262374878,
      "learning_rate": 8.737021276595745e-06,
      "loss": 0.1569,
      "step": 2792
    },
    {
      "epoch": 0.6417738970588235,
      "grad_norm": 1.3677220344543457,
      "learning_rate": 8.73617021276596e-06,
      "loss": 0.0985,
      "step": 2793
    },
    {
      "epoch": 0.6420036764705882,
      "grad_norm": 1.3647921085357666,
      "learning_rate": 8.735319148936171e-06,
      "loss": 0.1203,
      "step": 2794
    },
    {
      "epoch": 0.6422334558823529,
      "grad_norm": 1.2690109014511108,
      "learning_rate": 8.734468085106384e-06,
      "loss": 0.1272,
      "step": 2795
    },
    {
      "epoch": 0.6424632352941176,
      "grad_norm": 1.443113088607788,
      "learning_rate": 8.733617021276597e-06,
      "loss": 0.1527,
      "step": 2796
    },
    {
      "epoch": 0.6426930147058824,
      "grad_norm": 1.309964656829834,
      "learning_rate": 8.732765957446809e-06,
      "loss": 0.0989,
      "step": 2797
    },
    {
      "epoch": 0.6429227941176471,
      "grad_norm": 1.0945175886154175,
      "learning_rate": 8.731914893617022e-06,
      "loss": 0.096,
      "step": 2798
    },
    {
      "epoch": 0.6431525735294118,
      "grad_norm": 2.1928882598876953,
      "learning_rate": 8.731063829787235e-06,
      "loss": 0.1783,
      "step": 2799
    },
    {
      "epoch": 0.6433823529411765,
      "grad_norm": 1.4966762065887451,
      "learning_rate": 8.730212765957448e-06,
      "loss": 0.142,
      "step": 2800
    },
    {
      "epoch": 0.6436121323529411,
      "grad_norm": 1.3376842737197876,
      "learning_rate": 8.72936170212766e-06,
      "loss": 0.1126,
      "step": 2801
    },
    {
      "epoch": 0.6438419117647058,
      "grad_norm": 1.0084670782089233,
      "learning_rate": 8.728510638297873e-06,
      "loss": 0.104,
      "step": 2802
    },
    {
      "epoch": 0.6440716911764706,
      "grad_norm": 1.2221757173538208,
      "learning_rate": 8.727659574468086e-06,
      "loss": 0.1079,
      "step": 2803
    },
    {
      "epoch": 0.6443014705882353,
      "grad_norm": 1.236969232559204,
      "learning_rate": 8.726808510638298e-06,
      "loss": 0.1268,
      "step": 2804
    },
    {
      "epoch": 0.64453125,
      "grad_norm": 1.0800343751907349,
      "learning_rate": 8.725957446808512e-06,
      "loss": 0.1067,
      "step": 2805
    },
    {
      "epoch": 0.6447610294117647,
      "grad_norm": 1.2766027450561523,
      "learning_rate": 8.725106382978724e-06,
      "loss": 0.1413,
      "step": 2806
    },
    {
      "epoch": 0.6449908088235294,
      "grad_norm": 1.1980093717575073,
      "learning_rate": 8.724255319148937e-06,
      "loss": 0.1527,
      "step": 2807
    },
    {
      "epoch": 0.6452205882352942,
      "grad_norm": 1.0866141319274902,
      "learning_rate": 8.72340425531915e-06,
      "loss": 0.1071,
      "step": 2808
    },
    {
      "epoch": 0.6454503676470589,
      "grad_norm": 1.0994588136672974,
      "learning_rate": 8.722553191489362e-06,
      "loss": 0.1001,
      "step": 2809
    },
    {
      "epoch": 0.6456801470588235,
      "grad_norm": 1.2234083414077759,
      "learning_rate": 8.721702127659575e-06,
      "loss": 0.1186,
      "step": 2810
    },
    {
      "epoch": 0.6459099264705882,
      "grad_norm": 1.1507619619369507,
      "learning_rate": 8.720851063829788e-06,
      "loss": 0.1107,
      "step": 2811
    },
    {
      "epoch": 0.6461397058823529,
      "grad_norm": 1.5938963890075684,
      "learning_rate": 8.720000000000001e-06,
      "loss": 0.1436,
      "step": 2812
    },
    {
      "epoch": 0.6463694852941176,
      "grad_norm": 1.3843485116958618,
      "learning_rate": 8.719148936170213e-06,
      "loss": 0.1368,
      "step": 2813
    },
    {
      "epoch": 0.6465992647058824,
      "grad_norm": 1.4818527698516846,
      "learning_rate": 8.718297872340426e-06,
      "loss": 0.1534,
      "step": 2814
    },
    {
      "epoch": 0.6468290441176471,
      "grad_norm": 0.9999601244926453,
      "learning_rate": 8.717446808510639e-06,
      "loss": 0.0698,
      "step": 2815
    },
    {
      "epoch": 0.6470588235294118,
      "grad_norm": 1.1931490898132324,
      "learning_rate": 8.71659574468085e-06,
      "loss": 0.1178,
      "step": 2816
    },
    {
      "epoch": 0.6472886029411765,
      "grad_norm": 1.1922104358673096,
      "learning_rate": 8.715744680851065e-06,
      "loss": 0.1174,
      "step": 2817
    },
    {
      "epoch": 0.6475183823529411,
      "grad_norm": 1.1753504276275635,
      "learning_rate": 8.714893617021277e-06,
      "loss": 0.0981,
      "step": 2818
    },
    {
      "epoch": 0.6477481617647058,
      "grad_norm": 1.0373176336288452,
      "learning_rate": 8.71404255319149e-06,
      "loss": 0.1137,
      "step": 2819
    },
    {
      "epoch": 0.6479779411764706,
      "grad_norm": 1.199191689491272,
      "learning_rate": 8.713191489361703e-06,
      "loss": 0.149,
      "step": 2820
    },
    {
      "epoch": 0.6482077205882353,
      "grad_norm": 1.2670971155166626,
      "learning_rate": 8.712340425531915e-06,
      "loss": 0.135,
      "step": 2821
    },
    {
      "epoch": 0.6484375,
      "grad_norm": 1.3220399618148804,
      "learning_rate": 8.711489361702128e-06,
      "loss": 0.0911,
      "step": 2822
    },
    {
      "epoch": 0.6486672794117647,
      "grad_norm": 1.4878901243209839,
      "learning_rate": 8.710638297872341e-06,
      "loss": 0.1245,
      "step": 2823
    },
    {
      "epoch": 0.6488970588235294,
      "grad_norm": 2.0920603275299072,
      "learning_rate": 8.709787234042554e-06,
      "loss": 0.1727,
      "step": 2824
    },
    {
      "epoch": 0.6491268382352942,
      "grad_norm": 1.3537741899490356,
      "learning_rate": 8.708936170212766e-06,
      "loss": 0.1278,
      "step": 2825
    },
    {
      "epoch": 0.6493566176470589,
      "grad_norm": 1.3330479860305786,
      "learning_rate": 8.708085106382979e-06,
      "loss": 0.1008,
      "step": 2826
    },
    {
      "epoch": 0.6495863970588235,
      "grad_norm": 1.7378060817718506,
      "learning_rate": 8.707234042553192e-06,
      "loss": 0.1678,
      "step": 2827
    },
    {
      "epoch": 0.6498161764705882,
      "grad_norm": 1.4530670642852783,
      "learning_rate": 8.706382978723405e-06,
      "loss": 0.1442,
      "step": 2828
    },
    {
      "epoch": 0.6500459558823529,
      "grad_norm": 1.2005321979522705,
      "learning_rate": 8.705531914893618e-06,
      "loss": 0.1141,
      "step": 2829
    },
    {
      "epoch": 0.6502757352941176,
      "grad_norm": 1.386318564414978,
      "learning_rate": 8.70468085106383e-06,
      "loss": 0.1079,
      "step": 2830
    },
    {
      "epoch": 0.6505055147058824,
      "grad_norm": 1.259061336517334,
      "learning_rate": 8.703829787234043e-06,
      "loss": 0.1096,
      "step": 2831
    },
    {
      "epoch": 0.6507352941176471,
      "grad_norm": 1.1478931903839111,
      "learning_rate": 8.702978723404256e-06,
      "loss": 0.1213,
      "step": 2832
    },
    {
      "epoch": 0.6509650735294118,
      "grad_norm": 1.100653886795044,
      "learning_rate": 8.70212765957447e-06,
      "loss": 0.0966,
      "step": 2833
    },
    {
      "epoch": 0.6511948529411765,
      "grad_norm": 1.4132694005966187,
      "learning_rate": 8.701276595744682e-06,
      "loss": 0.1163,
      "step": 2834
    },
    {
      "epoch": 0.6514246323529411,
      "grad_norm": 1.2055524587631226,
      "learning_rate": 8.700425531914894e-06,
      "loss": 0.1069,
      "step": 2835
    },
    {
      "epoch": 0.6516544117647058,
      "grad_norm": 1.257531762123108,
      "learning_rate": 8.699574468085107e-06,
      "loss": 0.1307,
      "step": 2836
    },
    {
      "epoch": 0.6518841911764706,
      "grad_norm": 1.2421183586120605,
      "learning_rate": 8.69872340425532e-06,
      "loss": 0.1314,
      "step": 2837
    },
    {
      "epoch": 0.6521139705882353,
      "grad_norm": 1.1246477365493774,
      "learning_rate": 8.697872340425533e-06,
      "loss": 0.104,
      "step": 2838
    },
    {
      "epoch": 0.65234375,
      "grad_norm": 1.2379848957061768,
      "learning_rate": 8.697021276595745e-06,
      "loss": 0.1007,
      "step": 2839
    },
    {
      "epoch": 0.6525735294117647,
      "grad_norm": 1.705095648765564,
      "learning_rate": 8.696170212765958e-06,
      "loss": 0.1887,
      "step": 2840
    },
    {
      "epoch": 0.6528033088235294,
      "grad_norm": 1.1575580835342407,
      "learning_rate": 8.695319148936171e-06,
      "loss": 0.0929,
      "step": 2841
    },
    {
      "epoch": 0.6530330882352942,
      "grad_norm": 1.3869937658309937,
      "learning_rate": 8.694468085106383e-06,
      "loss": 0.125,
      "step": 2842
    },
    {
      "epoch": 0.6532628676470589,
      "grad_norm": 1.1056281328201294,
      "learning_rate": 8.693617021276598e-06,
      "loss": 0.1172,
      "step": 2843
    },
    {
      "epoch": 0.6534926470588235,
      "grad_norm": 1.3433960676193237,
      "learning_rate": 8.692765957446809e-06,
      "loss": 0.1648,
      "step": 2844
    },
    {
      "epoch": 0.6537224264705882,
      "grad_norm": 1.2011274099349976,
      "learning_rate": 8.691914893617022e-06,
      "loss": 0.153,
      "step": 2845
    },
    {
      "epoch": 0.6539522058823529,
      "grad_norm": 1.5882424116134644,
      "learning_rate": 8.691063829787235e-06,
      "loss": 0.1535,
      "step": 2846
    },
    {
      "epoch": 0.6541819852941176,
      "grad_norm": 1.759734034538269,
      "learning_rate": 8.690212765957447e-06,
      "loss": 0.1964,
      "step": 2847
    },
    {
      "epoch": 0.6544117647058824,
      "grad_norm": 1.0928367376327515,
      "learning_rate": 8.68936170212766e-06,
      "loss": 0.1066,
      "step": 2848
    },
    {
      "epoch": 0.6546415441176471,
      "grad_norm": 1.5680174827575684,
      "learning_rate": 8.688510638297873e-06,
      "loss": 0.1922,
      "step": 2849
    },
    {
      "epoch": 0.6548713235294118,
      "grad_norm": 1.2272869348526,
      "learning_rate": 8.687659574468086e-06,
      "loss": 0.0964,
      "step": 2850
    },
    {
      "epoch": 0.6551011029411765,
      "grad_norm": 1.4655299186706543,
      "learning_rate": 8.686808510638298e-06,
      "loss": 0.1024,
      "step": 2851
    },
    {
      "epoch": 0.6553308823529411,
      "grad_norm": 1.9709203243255615,
      "learning_rate": 8.685957446808511e-06,
      "loss": 0.1272,
      "step": 2852
    },
    {
      "epoch": 0.6555606617647058,
      "grad_norm": 1.2414740324020386,
      "learning_rate": 8.685106382978724e-06,
      "loss": 0.1558,
      "step": 2853
    },
    {
      "epoch": 0.6557904411764706,
      "grad_norm": 1.8276094198226929,
      "learning_rate": 8.684255319148936e-06,
      "loss": 0.1218,
      "step": 2854
    },
    {
      "epoch": 0.6560202205882353,
      "grad_norm": 1.1428132057189941,
      "learning_rate": 8.68340425531915e-06,
      "loss": 0.0966,
      "step": 2855
    },
    {
      "epoch": 0.65625,
      "grad_norm": 1.1082781553268433,
      "learning_rate": 8.682553191489362e-06,
      "loss": 0.1162,
      "step": 2856
    },
    {
      "epoch": 0.6564797794117647,
      "grad_norm": 1.3392301797866821,
      "learning_rate": 8.681702127659575e-06,
      "loss": 0.1217,
      "step": 2857
    },
    {
      "epoch": 0.6567095588235294,
      "grad_norm": 1.216416597366333,
      "learning_rate": 8.680851063829788e-06,
      "loss": 0.1037,
      "step": 2858
    },
    {
      "epoch": 0.6569393382352942,
      "grad_norm": 1.2261015176773071,
      "learning_rate": 8.68e-06,
      "loss": 0.1706,
      "step": 2859
    },
    {
      "epoch": 0.6571691176470589,
      "grad_norm": 0.9606441855430603,
      "learning_rate": 8.679148936170213e-06,
      "loss": 0.0837,
      "step": 2860
    },
    {
      "epoch": 0.6573988970588235,
      "grad_norm": 1.304641842842102,
      "learning_rate": 8.678297872340426e-06,
      "loss": 0.1045,
      "step": 2861
    },
    {
      "epoch": 0.6576286764705882,
      "grad_norm": 1.1108896732330322,
      "learning_rate": 8.67744680851064e-06,
      "loss": 0.1039,
      "step": 2862
    },
    {
      "epoch": 0.6578584558823529,
      "grad_norm": 1.471186637878418,
      "learning_rate": 8.676595744680851e-06,
      "loss": 0.149,
      "step": 2863
    },
    {
      "epoch": 0.6580882352941176,
      "grad_norm": 1.202649712562561,
      "learning_rate": 8.675744680851064e-06,
      "loss": 0.1145,
      "step": 2864
    },
    {
      "epoch": 0.6583180147058824,
      "grad_norm": 1.1618092060089111,
      "learning_rate": 8.674893617021277e-06,
      "loss": 0.1005,
      "step": 2865
    },
    {
      "epoch": 0.6585477941176471,
      "grad_norm": 1.6706262826919556,
      "learning_rate": 8.67404255319149e-06,
      "loss": 0.1815,
      "step": 2866
    },
    {
      "epoch": 0.6587775735294118,
      "grad_norm": 1.1876112222671509,
      "learning_rate": 8.673191489361704e-06,
      "loss": 0.1025,
      "step": 2867
    },
    {
      "epoch": 0.6590073529411765,
      "grad_norm": 1.2421647310256958,
      "learning_rate": 8.672340425531915e-06,
      "loss": 0.0909,
      "step": 2868
    },
    {
      "epoch": 0.6592371323529411,
      "grad_norm": 1.209122657775879,
      "learning_rate": 8.671489361702128e-06,
      "loss": 0.1161,
      "step": 2869
    },
    {
      "epoch": 0.6594669117647058,
      "grad_norm": 1.1038075685501099,
      "learning_rate": 8.670638297872341e-06,
      "loss": 0.1094,
      "step": 2870
    },
    {
      "epoch": 0.6596966911764706,
      "grad_norm": 1.6297528743743896,
      "learning_rate": 8.669787234042555e-06,
      "loss": 0.1244,
      "step": 2871
    },
    {
      "epoch": 0.6599264705882353,
      "grad_norm": 1.4031873941421509,
      "learning_rate": 8.668936170212766e-06,
      "loss": 0.1317,
      "step": 2872
    },
    {
      "epoch": 0.66015625,
      "grad_norm": 1.2767527103424072,
      "learning_rate": 8.66808510638298e-06,
      "loss": 0.1058,
      "step": 2873
    },
    {
      "epoch": 0.6603860294117647,
      "grad_norm": 1.0873627662658691,
      "learning_rate": 8.667234042553192e-06,
      "loss": 0.1098,
      "step": 2874
    },
    {
      "epoch": 0.6606158088235294,
      "grad_norm": 1.3143771886825562,
      "learning_rate": 8.666382978723406e-06,
      "loss": 0.1106,
      "step": 2875
    },
    {
      "epoch": 0.6608455882352942,
      "grad_norm": 1.5151876211166382,
      "learning_rate": 8.665531914893619e-06,
      "loss": 0.152,
      "step": 2876
    },
    {
      "epoch": 0.6610753676470589,
      "grad_norm": 1.4627777338027954,
      "learning_rate": 8.66468085106383e-06,
      "loss": 0.152,
      "step": 2877
    },
    {
      "epoch": 0.6613051470588235,
      "grad_norm": 1.142135739326477,
      "learning_rate": 8.663829787234043e-06,
      "loss": 0.0948,
      "step": 2878
    },
    {
      "epoch": 0.6615349264705882,
      "grad_norm": 1.488789439201355,
      "learning_rate": 8.662978723404257e-06,
      "loss": 0.1182,
      "step": 2879
    },
    {
      "epoch": 0.6617647058823529,
      "grad_norm": 1.3606587648391724,
      "learning_rate": 8.662127659574468e-06,
      "loss": 0.1094,
      "step": 2880
    },
    {
      "epoch": 0.6619944852941176,
      "grad_norm": 1.1607732772827148,
      "learning_rate": 8.661276595744683e-06,
      "loss": 0.095,
      "step": 2881
    },
    {
      "epoch": 0.6622242647058824,
      "grad_norm": 1.3092492818832397,
      "learning_rate": 8.660425531914894e-06,
      "loss": 0.1176,
      "step": 2882
    },
    {
      "epoch": 0.6624540441176471,
      "grad_norm": 1.265953779220581,
      "learning_rate": 8.659574468085108e-06,
      "loss": 0.1521,
      "step": 2883
    },
    {
      "epoch": 0.6626838235294118,
      "grad_norm": 1.2242058515548706,
      "learning_rate": 8.65872340425532e-06,
      "loss": 0.1232,
      "step": 2884
    },
    {
      "epoch": 0.6629136029411765,
      "grad_norm": 1.201826810836792,
      "learning_rate": 8.657872340425532e-06,
      "loss": 0.1265,
      "step": 2885
    },
    {
      "epoch": 0.6631433823529411,
      "grad_norm": 1.0841577053070068,
      "learning_rate": 8.657021276595745e-06,
      "loss": 0.1051,
      "step": 2886
    },
    {
      "epoch": 0.6633731617647058,
      "grad_norm": 1.2206588983535767,
      "learning_rate": 8.656170212765959e-06,
      "loss": 0.1052,
      "step": 2887
    },
    {
      "epoch": 0.6636029411764706,
      "grad_norm": 1.204535961151123,
      "learning_rate": 8.655319148936172e-06,
      "loss": 0.1285,
      "step": 2888
    },
    {
      "epoch": 0.6638327205882353,
      "grad_norm": 1.7620835304260254,
      "learning_rate": 8.654468085106383e-06,
      "loss": 0.1538,
      "step": 2889
    },
    {
      "epoch": 0.6640625,
      "grad_norm": 1.2777683734893799,
      "learning_rate": 8.653617021276596e-06,
      "loss": 0.1222,
      "step": 2890
    },
    {
      "epoch": 0.6642922794117647,
      "grad_norm": 1.297884464263916,
      "learning_rate": 8.65276595744681e-06,
      "loss": 0.1051,
      "step": 2891
    },
    {
      "epoch": 0.6645220588235294,
      "grad_norm": 1.241926670074463,
      "learning_rate": 8.651914893617021e-06,
      "loss": 0.1222,
      "step": 2892
    },
    {
      "epoch": 0.6647518382352942,
      "grad_norm": 1.1761507987976074,
      "learning_rate": 8.651063829787236e-06,
      "loss": 0.098,
      "step": 2893
    },
    {
      "epoch": 0.6649816176470589,
      "grad_norm": 1.1975921392440796,
      "learning_rate": 8.650212765957447e-06,
      "loss": 0.1522,
      "step": 2894
    },
    {
      "epoch": 0.6652113970588235,
      "grad_norm": 1.0824038982391357,
      "learning_rate": 8.64936170212766e-06,
      "loss": 0.1581,
      "step": 2895
    },
    {
      "epoch": 0.6654411764705882,
      "grad_norm": 1.1738661527633667,
      "learning_rate": 8.648510638297874e-06,
      "loss": 0.0956,
      "step": 2896
    },
    {
      "epoch": 0.6656709558823529,
      "grad_norm": 1.1482105255126953,
      "learning_rate": 8.647659574468085e-06,
      "loss": 0.1235,
      "step": 2897
    },
    {
      "epoch": 0.6659007352941176,
      "grad_norm": 1.224665880203247,
      "learning_rate": 8.646808510638298e-06,
      "loss": 0.0958,
      "step": 2898
    },
    {
      "epoch": 0.6661305147058824,
      "grad_norm": 1.3094607591629028,
      "learning_rate": 8.645957446808511e-06,
      "loss": 0.0918,
      "step": 2899
    },
    {
      "epoch": 0.6663602941176471,
      "grad_norm": 1.2681381702423096,
      "learning_rate": 8.645106382978725e-06,
      "loss": 0.1109,
      "step": 2900
    },
    {
      "epoch": 0.6665900735294118,
      "grad_norm": 1.3812880516052246,
      "learning_rate": 8.644255319148936e-06,
      "loss": 0.1164,
      "step": 2901
    },
    {
      "epoch": 0.6668198529411765,
      "grad_norm": 1.3010410070419312,
      "learning_rate": 8.64340425531915e-06,
      "loss": 0.1164,
      "step": 2902
    },
    {
      "epoch": 0.6670496323529411,
      "grad_norm": 1.3606935739517212,
      "learning_rate": 8.642553191489362e-06,
      "loss": 0.1384,
      "step": 2903
    },
    {
      "epoch": 0.6672794117647058,
      "grad_norm": 1.7443877458572388,
      "learning_rate": 8.641702127659574e-06,
      "loss": 0.1306,
      "step": 2904
    },
    {
      "epoch": 0.6675091911764706,
      "grad_norm": 1.0918960571289062,
      "learning_rate": 8.640851063829789e-06,
      "loss": 0.1152,
      "step": 2905
    },
    {
      "epoch": 0.6677389705882353,
      "grad_norm": 1.4275121688842773,
      "learning_rate": 8.64e-06,
      "loss": 0.1524,
      "step": 2906
    },
    {
      "epoch": 0.66796875,
      "grad_norm": 1.6411718130111694,
      "learning_rate": 8.639148936170213e-06,
      "loss": 0.1344,
      "step": 2907
    },
    {
      "epoch": 0.6681985294117647,
      "grad_norm": 1.0485703945159912,
      "learning_rate": 8.638297872340427e-06,
      "loss": 0.1041,
      "step": 2908
    },
    {
      "epoch": 0.6684283088235294,
      "grad_norm": 1.1684011220932007,
      "learning_rate": 8.637446808510638e-06,
      "loss": 0.1189,
      "step": 2909
    },
    {
      "epoch": 0.6686580882352942,
      "grad_norm": 1.0263677835464478,
      "learning_rate": 8.636595744680851e-06,
      "loss": 0.0888,
      "step": 2910
    },
    {
      "epoch": 0.6688878676470589,
      "grad_norm": 1.0676089525222778,
      "learning_rate": 8.635744680851064e-06,
      "loss": 0.0973,
      "step": 2911
    },
    {
      "epoch": 0.6691176470588235,
      "grad_norm": 1.194998860359192,
      "learning_rate": 8.634893617021278e-06,
      "loss": 0.1235,
      "step": 2912
    },
    {
      "epoch": 0.6693474264705882,
      "grad_norm": 1.2100203037261963,
      "learning_rate": 8.634042553191489e-06,
      "loss": 0.1229,
      "step": 2913
    },
    {
      "epoch": 0.6695772058823529,
      "grad_norm": 1.3799511194229126,
      "learning_rate": 8.633191489361702e-06,
      "loss": 0.0737,
      "step": 2914
    },
    {
      "epoch": 0.6698069852941176,
      "grad_norm": 1.149727463722229,
      "learning_rate": 8.632340425531915e-06,
      "loss": 0.1013,
      "step": 2915
    },
    {
      "epoch": 0.6700367647058824,
      "grad_norm": 1.4130704402923584,
      "learning_rate": 8.631489361702129e-06,
      "loss": 0.0996,
      "step": 2916
    },
    {
      "epoch": 0.6702665441176471,
      "grad_norm": 1.0716103315353394,
      "learning_rate": 8.630638297872342e-06,
      "loss": 0.0942,
      "step": 2917
    },
    {
      "epoch": 0.6704963235294118,
      "grad_norm": 1.2784547805786133,
      "learning_rate": 8.629787234042553e-06,
      "loss": 0.16,
      "step": 2918
    },
    {
      "epoch": 0.6707261029411765,
      "grad_norm": 0.9664514660835266,
      "learning_rate": 8.628936170212766e-06,
      "loss": 0.1197,
      "step": 2919
    },
    {
      "epoch": 0.6709558823529411,
      "grad_norm": 1.1106293201446533,
      "learning_rate": 8.62808510638298e-06,
      "loss": 0.11,
      "step": 2920
    },
    {
      "epoch": 0.6711856617647058,
      "grad_norm": 1.2618110179901123,
      "learning_rate": 8.627234042553193e-06,
      "loss": 0.1192,
      "step": 2921
    },
    {
      "epoch": 0.6714154411764706,
      "grad_norm": 1.3548009395599365,
      "learning_rate": 8.626382978723406e-06,
      "loss": 0.1281,
      "step": 2922
    },
    {
      "epoch": 0.6716452205882353,
      "grad_norm": 1.2449618577957153,
      "learning_rate": 8.625531914893617e-06,
      "loss": 0.1331,
      "step": 2923
    },
    {
      "epoch": 0.671875,
      "grad_norm": 1.7115397453308105,
      "learning_rate": 8.62468085106383e-06,
      "loss": 0.1079,
      "step": 2924
    },
    {
      "epoch": 0.6721047794117647,
      "grad_norm": 1.1501902341842651,
      "learning_rate": 8.623829787234044e-06,
      "loss": 0.1426,
      "step": 2925
    },
    {
      "epoch": 0.6723345588235294,
      "grad_norm": 1.151046872138977,
      "learning_rate": 8.622978723404257e-06,
      "loss": 0.1051,
      "step": 2926
    },
    {
      "epoch": 0.6725643382352942,
      "grad_norm": 1.2674899101257324,
      "learning_rate": 8.622127659574468e-06,
      "loss": 0.1145,
      "step": 2927
    },
    {
      "epoch": 0.6727941176470589,
      "grad_norm": 1.176875114440918,
      "learning_rate": 8.621276595744682e-06,
      "loss": 0.1391,
      "step": 2928
    },
    {
      "epoch": 0.6730238970588235,
      "grad_norm": 1.2976739406585693,
      "learning_rate": 8.620425531914895e-06,
      "loss": 0.1417,
      "step": 2929
    },
    {
      "epoch": 0.6732536764705882,
      "grad_norm": 1.311723232269287,
      "learning_rate": 8.619574468085106e-06,
      "loss": 0.1311,
      "step": 2930
    },
    {
      "epoch": 0.6734834558823529,
      "grad_norm": 1.1131718158721924,
      "learning_rate": 8.618723404255321e-06,
      "loss": 0.098,
      "step": 2931
    },
    {
      "epoch": 0.6737132352941176,
      "grad_norm": 1.6193451881408691,
      "learning_rate": 8.617872340425533e-06,
      "loss": 0.177,
      "step": 2932
    },
    {
      "epoch": 0.6739430147058824,
      "grad_norm": 0.976972758769989,
      "learning_rate": 8.617021276595746e-06,
      "loss": 0.0945,
      "step": 2933
    },
    {
      "epoch": 0.6741727941176471,
      "grad_norm": 1.5016601085662842,
      "learning_rate": 8.616170212765959e-06,
      "loss": 0.1546,
      "step": 2934
    },
    {
      "epoch": 0.6744025735294118,
      "grad_norm": 1.099184274673462,
      "learning_rate": 8.61531914893617e-06,
      "loss": 0.1141,
      "step": 2935
    },
    {
      "epoch": 0.6746323529411765,
      "grad_norm": 1.3766947984695435,
      "learning_rate": 8.614468085106384e-06,
      "loss": 0.0915,
      "step": 2936
    },
    {
      "epoch": 0.6748621323529411,
      "grad_norm": 1.3438591957092285,
      "learning_rate": 8.613617021276597e-06,
      "loss": 0.1132,
      "step": 2937
    },
    {
      "epoch": 0.6750919117647058,
      "grad_norm": 1.464638113975525,
      "learning_rate": 8.61276595744681e-06,
      "loss": 0.1572,
      "step": 2938
    },
    {
      "epoch": 0.6753216911764706,
      "grad_norm": 1.1040174961090088,
      "learning_rate": 8.611914893617021e-06,
      "loss": 0.1168,
      "step": 2939
    },
    {
      "epoch": 0.6755514705882353,
      "grad_norm": 1.3779765367507935,
      "learning_rate": 8.611063829787235e-06,
      "loss": 0.1333,
      "step": 2940
    },
    {
      "epoch": 0.67578125,
      "grad_norm": 1.3645951747894287,
      "learning_rate": 8.610212765957448e-06,
      "loss": 0.1423,
      "step": 2941
    },
    {
      "epoch": 0.6760110294117647,
      "grad_norm": 0.9372868537902832,
      "learning_rate": 8.60936170212766e-06,
      "loss": 0.1255,
      "step": 2942
    },
    {
      "epoch": 0.6762408088235294,
      "grad_norm": 1.1740334033966064,
      "learning_rate": 8.608510638297874e-06,
      "loss": 0.105,
      "step": 2943
    },
    {
      "epoch": 0.6764705882352942,
      "grad_norm": 1.5499218702316284,
      "learning_rate": 8.607659574468086e-06,
      "loss": 0.1333,
      "step": 2944
    },
    {
      "epoch": 0.6767003676470589,
      "grad_norm": 1.205955147743225,
      "learning_rate": 8.606808510638299e-06,
      "loss": 0.1071,
      "step": 2945
    },
    {
      "epoch": 0.6769301470588235,
      "grad_norm": 1.7287768125534058,
      "learning_rate": 8.605957446808512e-06,
      "loss": 0.1011,
      "step": 2946
    },
    {
      "epoch": 0.6771599264705882,
      "grad_norm": 1.445056676864624,
      "learning_rate": 8.605106382978723e-06,
      "loss": 0.1643,
      "step": 2947
    },
    {
      "epoch": 0.6773897058823529,
      "grad_norm": 1.3063457012176514,
      "learning_rate": 8.604255319148937e-06,
      "loss": 0.1382,
      "step": 2948
    },
    {
      "epoch": 0.6776194852941176,
      "grad_norm": 1.1551827192306519,
      "learning_rate": 8.60340425531915e-06,
      "loss": 0.0933,
      "step": 2949
    },
    {
      "epoch": 0.6778492647058824,
      "grad_norm": 1.2744413614273071,
      "learning_rate": 8.602553191489363e-06,
      "loss": 0.1244,
      "step": 2950
    },
    {
      "epoch": 0.6780790441176471,
      "grad_norm": 0.9474741816520691,
      "learning_rate": 8.601702127659574e-06,
      "loss": 0.0951,
      "step": 2951
    },
    {
      "epoch": 0.6783088235294118,
      "grad_norm": 1.6299047470092773,
      "learning_rate": 8.600851063829787e-06,
      "loss": 0.1183,
      "step": 2952
    },
    {
      "epoch": 0.6785386029411765,
      "grad_norm": 1.0938559770584106,
      "learning_rate": 8.6e-06,
      "loss": 0.0719,
      "step": 2953
    },
    {
      "epoch": 0.6787683823529411,
      "grad_norm": 1.2758690118789673,
      "learning_rate": 8.599148936170212e-06,
      "loss": 0.1282,
      "step": 2954
    },
    {
      "epoch": 0.6789981617647058,
      "grad_norm": 1.4362993240356445,
      "learning_rate": 8.598297872340427e-06,
      "loss": 0.0978,
      "step": 2955
    },
    {
      "epoch": 0.6792279411764706,
      "grad_norm": 1.5773098468780518,
      "learning_rate": 8.597446808510638e-06,
      "loss": 0.1436,
      "step": 2956
    },
    {
      "epoch": 0.6794577205882353,
      "grad_norm": 1.2773553133010864,
      "learning_rate": 8.596595744680852e-06,
      "loss": 0.1053,
      "step": 2957
    },
    {
      "epoch": 0.6796875,
      "grad_norm": 1.6210240125656128,
      "learning_rate": 8.595744680851065e-06,
      "loss": 0.1031,
      "step": 2958
    },
    {
      "epoch": 0.6799172794117647,
      "grad_norm": 1.2746001482009888,
      "learning_rate": 8.594893617021276e-06,
      "loss": 0.1402,
      "step": 2959
    },
    {
      "epoch": 0.6801470588235294,
      "grad_norm": 1.0102053880691528,
      "learning_rate": 8.594042553191491e-06,
      "loss": 0.096,
      "step": 2960
    },
    {
      "epoch": 0.6803768382352942,
      "grad_norm": 1.1092162132263184,
      "learning_rate": 8.593191489361703e-06,
      "loss": 0.1019,
      "step": 2961
    },
    {
      "epoch": 0.6806066176470589,
      "grad_norm": 0.801784873008728,
      "learning_rate": 8.592340425531916e-06,
      "loss": 0.0856,
      "step": 2962
    },
    {
      "epoch": 0.6808363970588235,
      "grad_norm": 1.6707104444503784,
      "learning_rate": 8.591489361702129e-06,
      "loss": 0.1083,
      "step": 2963
    },
    {
      "epoch": 0.6810661764705882,
      "grad_norm": 1.1866135597229004,
      "learning_rate": 8.59063829787234e-06,
      "loss": 0.1413,
      "step": 2964
    },
    {
      "epoch": 0.6812959558823529,
      "grad_norm": 1.1077468395233154,
      "learning_rate": 8.589787234042554e-06,
      "loss": 0.0962,
      "step": 2965
    },
    {
      "epoch": 0.6815257352941176,
      "grad_norm": 1.135583519935608,
      "learning_rate": 8.588936170212767e-06,
      "loss": 0.1277,
      "step": 2966
    },
    {
      "epoch": 0.6817555147058824,
      "grad_norm": 1.4368581771850586,
      "learning_rate": 8.58808510638298e-06,
      "loss": 0.1364,
      "step": 2967
    },
    {
      "epoch": 0.6819852941176471,
      "grad_norm": 1.4191699028015137,
      "learning_rate": 8.587234042553191e-06,
      "loss": 0.1305,
      "step": 2968
    },
    {
      "epoch": 0.6822150735294118,
      "grad_norm": 1.7400181293487549,
      "learning_rate": 8.586382978723405e-06,
      "loss": 0.1278,
      "step": 2969
    },
    {
      "epoch": 0.6824448529411765,
      "grad_norm": 1.189150094985962,
      "learning_rate": 8.585531914893618e-06,
      "loss": 0.1181,
      "step": 2970
    },
    {
      "epoch": 0.6826746323529411,
      "grad_norm": 1.4823017120361328,
      "learning_rate": 8.584680851063831e-06,
      "loss": 0.1393,
      "step": 2971
    },
    {
      "epoch": 0.6829044117647058,
      "grad_norm": 1.2404978275299072,
      "learning_rate": 8.583829787234044e-06,
      "loss": 0.119,
      "step": 2972
    },
    {
      "epoch": 0.6831341911764706,
      "grad_norm": 1.315813660621643,
      "learning_rate": 8.582978723404256e-06,
      "loss": 0.0813,
      "step": 2973
    },
    {
      "epoch": 0.6833639705882353,
      "grad_norm": 1.432265043258667,
      "learning_rate": 8.582127659574469e-06,
      "loss": 0.1536,
      "step": 2974
    },
    {
      "epoch": 0.68359375,
      "grad_norm": 1.6409249305725098,
      "learning_rate": 8.581276595744682e-06,
      "loss": 0.1605,
      "step": 2975
    },
    {
      "epoch": 0.6838235294117647,
      "grad_norm": 0.9959948658943176,
      "learning_rate": 8.580425531914895e-06,
      "loss": 0.0764,
      "step": 2976
    },
    {
      "epoch": 0.6840533088235294,
      "grad_norm": 1.7623547315597534,
      "learning_rate": 8.579574468085107e-06,
      "loss": 0.1256,
      "step": 2977
    },
    {
      "epoch": 0.6842830882352942,
      "grad_norm": 0.9825007915496826,
      "learning_rate": 8.57872340425532e-06,
      "loss": 0.0998,
      "step": 2978
    },
    {
      "epoch": 0.6845128676470589,
      "grad_norm": 0.892351508140564,
      "learning_rate": 8.577872340425533e-06,
      "loss": 0.0906,
      "step": 2979
    },
    {
      "epoch": 0.6847426470588235,
      "grad_norm": 1.17851984500885,
      "learning_rate": 8.577021276595744e-06,
      "loss": 0.0933,
      "step": 2980
    },
    {
      "epoch": 0.6849724264705882,
      "grad_norm": 1.2513521909713745,
      "learning_rate": 8.57617021276596e-06,
      "loss": 0.1184,
      "step": 2981
    },
    {
      "epoch": 0.6852022058823529,
      "grad_norm": 1.037680745124817,
      "learning_rate": 8.57531914893617e-06,
      "loss": 0.0956,
      "step": 2982
    },
    {
      "epoch": 0.6854319852941176,
      "grad_norm": 1.6123911142349243,
      "learning_rate": 8.574468085106384e-06,
      "loss": 0.1313,
      "step": 2983
    },
    {
      "epoch": 0.6856617647058824,
      "grad_norm": 1.081679344177246,
      "learning_rate": 8.573617021276597e-06,
      "loss": 0.1135,
      "step": 2984
    },
    {
      "epoch": 0.6858915441176471,
      "grad_norm": 1.3827261924743652,
      "learning_rate": 8.572765957446809e-06,
      "loss": 0.1294,
      "step": 2985
    },
    {
      "epoch": 0.6861213235294118,
      "grad_norm": 1.1893795728683472,
      "learning_rate": 8.571914893617022e-06,
      "loss": 0.101,
      "step": 2986
    },
    {
      "epoch": 0.6863511029411765,
      "grad_norm": 0.9100797772407532,
      "learning_rate": 8.571063829787235e-06,
      "loss": 0.0897,
      "step": 2987
    },
    {
      "epoch": 0.6865808823529411,
      "grad_norm": 1.136741042137146,
      "learning_rate": 8.570212765957448e-06,
      "loss": 0.096,
      "step": 2988
    },
    {
      "epoch": 0.6868106617647058,
      "grad_norm": 1.7727773189544678,
      "learning_rate": 8.56936170212766e-06,
      "loss": 0.1812,
      "step": 2989
    },
    {
      "epoch": 0.6870404411764706,
      "grad_norm": 0.9664208292961121,
      "learning_rate": 8.568510638297873e-06,
      "loss": 0.1061,
      "step": 2990
    },
    {
      "epoch": 0.6872702205882353,
      "grad_norm": 1.4806854724884033,
      "learning_rate": 8.567659574468086e-06,
      "loss": 0.1298,
      "step": 2991
    },
    {
      "epoch": 0.6875,
      "grad_norm": 1.1328505277633667,
      "learning_rate": 8.566808510638297e-06,
      "loss": 0.0882,
      "step": 2992
    },
    {
      "epoch": 0.6877297794117647,
      "grad_norm": 1.4653292894363403,
      "learning_rate": 8.565957446808512e-06,
      "loss": 0.1284,
      "step": 2993
    },
    {
      "epoch": 0.6879595588235294,
      "grad_norm": 1.4584039449691772,
      "learning_rate": 8.565106382978724e-06,
      "loss": 0.1186,
      "step": 2994
    },
    {
      "epoch": 0.6881893382352942,
      "grad_norm": 1.2835462093353271,
      "learning_rate": 8.564255319148937e-06,
      "loss": 0.142,
      "step": 2995
    },
    {
      "epoch": 0.6884191176470589,
      "grad_norm": 1.1538764238357544,
      "learning_rate": 8.56340425531915e-06,
      "loss": 0.096,
      "step": 2996
    },
    {
      "epoch": 0.6886488970588235,
      "grad_norm": 1.3245335817337036,
      "learning_rate": 8.562553191489362e-06,
      "loss": 0.11,
      "step": 2997
    },
    {
      "epoch": 0.6888786764705882,
      "grad_norm": 1.11702561378479,
      "learning_rate": 8.561702127659575e-06,
      "loss": 0.1123,
      "step": 2998
    },
    {
      "epoch": 0.6891084558823529,
      "grad_norm": 1.1043611764907837,
      "learning_rate": 8.560851063829788e-06,
      "loss": 0.1279,
      "step": 2999
    },
    {
      "epoch": 0.6893382352941176,
      "grad_norm": 1.3532861471176147,
      "learning_rate": 8.560000000000001e-06,
      "loss": 0.1346,
      "step": 3000
    },
    {
      "epoch": 0.6893382352941176,
      "eval_loss": 0.12044993042945862,
      "eval_runtime": 1966.9353,
      "eval_samples_per_second": 4.528,
      "eval_steps_per_second": 2.264,
      "step": 3000
    },
    {
      "epoch": 0.6895680147058824,
      "grad_norm": 1.566704511642456,
      "learning_rate": 8.559148936170213e-06,
      "loss": 0.1375,
      "step": 3001
    },
    {
      "epoch": 0.6897977941176471,
      "grad_norm": 1.3768290281295776,
      "learning_rate": 8.558297872340426e-06,
      "loss": 0.1105,
      "step": 3002
    },
    {
      "epoch": 0.6900275735294118,
      "grad_norm": 1.234243631362915,
      "learning_rate": 8.557446808510639e-06,
      "loss": 0.1196,
      "step": 3003
    },
    {
      "epoch": 0.6902573529411765,
      "grad_norm": 1.2920091152191162,
      "learning_rate": 8.556595744680852e-06,
      "loss": 0.1153,
      "step": 3004
    },
    {
      "epoch": 0.6904871323529411,
      "grad_norm": 1.2198878526687622,
      "learning_rate": 8.555744680851065e-06,
      "loss": 0.1126,
      "step": 3005
    },
    {
      "epoch": 0.6907169117647058,
      "grad_norm": 1.5251147747039795,
      "learning_rate": 8.554893617021277e-06,
      "loss": 0.1022,
      "step": 3006
    },
    {
      "epoch": 0.6909466911764706,
      "grad_norm": 1.178629755973816,
      "learning_rate": 8.55404255319149e-06,
      "loss": 0.0987,
      "step": 3007
    },
    {
      "epoch": 0.6911764705882353,
      "grad_norm": 1.226836919784546,
      "learning_rate": 8.553191489361703e-06,
      "loss": 0.1184,
      "step": 3008
    },
    {
      "epoch": 0.69140625,
      "grad_norm": 1.6183717250823975,
      "learning_rate": 8.552340425531915e-06,
      "loss": 0.1696,
      "step": 3009
    },
    {
      "epoch": 0.6916360294117647,
      "grad_norm": 1.1694729328155518,
      "learning_rate": 8.55148936170213e-06,
      "loss": 0.1075,
      "step": 3010
    },
    {
      "epoch": 0.6918658088235294,
      "grad_norm": 1.3975865840911865,
      "learning_rate": 8.55063829787234e-06,
      "loss": 0.1129,
      "step": 3011
    },
    {
      "epoch": 0.6920955882352942,
      "grad_norm": 1.1215558052062988,
      "learning_rate": 8.549787234042554e-06,
      "loss": 0.0888,
      "step": 3012
    },
    {
      "epoch": 0.6923253676470589,
      "grad_norm": 1.3371703624725342,
      "learning_rate": 8.548936170212767e-06,
      "loss": 0.1222,
      "step": 3013
    },
    {
      "epoch": 0.6925551470588235,
      "grad_norm": 1.03118097782135,
      "learning_rate": 8.548085106382979e-06,
      "loss": 0.0945,
      "step": 3014
    },
    {
      "epoch": 0.6927849264705882,
      "grad_norm": 1.523520588874817,
      "learning_rate": 8.547234042553192e-06,
      "loss": 0.1294,
      "step": 3015
    },
    {
      "epoch": 0.6930147058823529,
      "grad_norm": 1.1265534162521362,
      "learning_rate": 8.546382978723405e-06,
      "loss": 0.0851,
      "step": 3016
    },
    {
      "epoch": 0.6932444852941176,
      "grad_norm": 1.1624497175216675,
      "learning_rate": 8.545531914893618e-06,
      "loss": 0.0876,
      "step": 3017
    },
    {
      "epoch": 0.6934742647058824,
      "grad_norm": 1.2823421955108643,
      "learning_rate": 8.54468085106383e-06,
      "loss": 0.1388,
      "step": 3018
    },
    {
      "epoch": 0.6937040441176471,
      "grad_norm": 1.545574426651001,
      "learning_rate": 8.543829787234043e-06,
      "loss": 0.1319,
      "step": 3019
    },
    {
      "epoch": 0.6939338235294118,
      "grad_norm": 1.292333960533142,
      "learning_rate": 8.542978723404256e-06,
      "loss": 0.1137,
      "step": 3020
    },
    {
      "epoch": 0.6941636029411765,
      "grad_norm": 1.1996203660964966,
      "learning_rate": 8.54212765957447e-06,
      "loss": 0.1217,
      "step": 3021
    },
    {
      "epoch": 0.6943933823529411,
      "grad_norm": 1.375266432762146,
      "learning_rate": 8.541276595744682e-06,
      "loss": 0.1214,
      "step": 3022
    },
    {
      "epoch": 0.6946231617647058,
      "grad_norm": 1.2037237882614136,
      "learning_rate": 8.540425531914894e-06,
      "loss": 0.1109,
      "step": 3023
    },
    {
      "epoch": 0.6948529411764706,
      "grad_norm": 1.0625555515289307,
      "learning_rate": 8.539574468085107e-06,
      "loss": 0.1428,
      "step": 3024
    },
    {
      "epoch": 0.6950827205882353,
      "grad_norm": 1.230681300163269,
      "learning_rate": 8.53872340425532e-06,
      "loss": 0.1117,
      "step": 3025
    },
    {
      "epoch": 0.6953125,
      "grad_norm": 1.144690752029419,
      "learning_rate": 8.537872340425533e-06,
      "loss": 0.1048,
      "step": 3026
    },
    {
      "epoch": 0.6955422794117647,
      "grad_norm": 1.5078870058059692,
      "learning_rate": 8.537021276595745e-06,
      "loss": 0.1171,
      "step": 3027
    },
    {
      "epoch": 0.6957720588235294,
      "grad_norm": 1.145079493522644,
      "learning_rate": 8.536170212765958e-06,
      "loss": 0.0805,
      "step": 3028
    },
    {
      "epoch": 0.6960018382352942,
      "grad_norm": 0.9712140560150146,
      "learning_rate": 8.535319148936171e-06,
      "loss": 0.1019,
      "step": 3029
    },
    {
      "epoch": 0.6962316176470589,
      "grad_norm": 1.3583928346633911,
      "learning_rate": 8.534468085106383e-06,
      "loss": 0.1609,
      "step": 3030
    },
    {
      "epoch": 0.6964613970588235,
      "grad_norm": 1.2659169435501099,
      "learning_rate": 8.533617021276597e-06,
      "loss": 0.0948,
      "step": 3031
    },
    {
      "epoch": 0.6966911764705882,
      "grad_norm": 1.6302467584609985,
      "learning_rate": 8.532765957446809e-06,
      "loss": 0.121,
      "step": 3032
    },
    {
      "epoch": 0.6969209558823529,
      "grad_norm": 1.737554669380188,
      "learning_rate": 8.531914893617022e-06,
      "loss": 0.121,
      "step": 3033
    },
    {
      "epoch": 0.6971507352941176,
      "grad_norm": 1.2211265563964844,
      "learning_rate": 8.531063829787235e-06,
      "loss": 0.0936,
      "step": 3034
    },
    {
      "epoch": 0.6973805147058824,
      "grad_norm": 0.9215906262397766,
      "learning_rate": 8.530212765957447e-06,
      "loss": 0.1015,
      "step": 3035
    },
    {
      "epoch": 0.6976102941176471,
      "grad_norm": 0.9047977328300476,
      "learning_rate": 8.52936170212766e-06,
      "loss": 0.0782,
      "step": 3036
    },
    {
      "epoch": 0.6978400735294118,
      "grad_norm": 1.4471516609191895,
      "learning_rate": 8.528510638297873e-06,
      "loss": 0.1081,
      "step": 3037
    },
    {
      "epoch": 0.6980698529411765,
      "grad_norm": 1.7084091901779175,
      "learning_rate": 8.527659574468086e-06,
      "loss": 0.1366,
      "step": 3038
    },
    {
      "epoch": 0.6982996323529411,
      "grad_norm": 1.2461134195327759,
      "learning_rate": 8.526808510638298e-06,
      "loss": 0.1112,
      "step": 3039
    },
    {
      "epoch": 0.6985294117647058,
      "grad_norm": 1.3343398571014404,
      "learning_rate": 8.525957446808511e-06,
      "loss": 0.1144,
      "step": 3040
    },
    {
      "epoch": 0.6987591911764706,
      "grad_norm": 1.629734992980957,
      "learning_rate": 8.525106382978724e-06,
      "loss": 0.1372,
      "step": 3041
    },
    {
      "epoch": 0.6989889705882353,
      "grad_norm": 1.1448944807052612,
      "learning_rate": 8.524255319148936e-06,
      "loss": 0.1161,
      "step": 3042
    },
    {
      "epoch": 0.69921875,
      "grad_norm": 1.4581446647644043,
      "learning_rate": 8.52340425531915e-06,
      "loss": 0.1419,
      "step": 3043
    },
    {
      "epoch": 0.6994485294117647,
      "grad_norm": 1.2143635749816895,
      "learning_rate": 8.522553191489362e-06,
      "loss": 0.1292,
      "step": 3044
    },
    {
      "epoch": 0.6996783088235294,
      "grad_norm": 1.7721177339553833,
      "learning_rate": 8.521702127659575e-06,
      "loss": 0.1644,
      "step": 3045
    },
    {
      "epoch": 0.6999080882352942,
      "grad_norm": 1.4945646524429321,
      "learning_rate": 8.520851063829788e-06,
      "loss": 0.1361,
      "step": 3046
    },
    {
      "epoch": 0.7001378676470589,
      "grad_norm": 1.5126609802246094,
      "learning_rate": 8.52e-06,
      "loss": 0.1396,
      "step": 3047
    },
    {
      "epoch": 0.7003676470588235,
      "grad_norm": 1.2887883186340332,
      "learning_rate": 8.519148936170215e-06,
      "loss": 0.17,
      "step": 3048
    },
    {
      "epoch": 0.7005974264705882,
      "grad_norm": 0.9632036089897156,
      "learning_rate": 8.518297872340426e-06,
      "loss": 0.0977,
      "step": 3049
    },
    {
      "epoch": 0.7008272058823529,
      "grad_norm": 1.4585071802139282,
      "learning_rate": 8.51744680851064e-06,
      "loss": 0.1283,
      "step": 3050
    },
    {
      "epoch": 0.7010569852941176,
      "grad_norm": 1.0341688394546509,
      "learning_rate": 8.516595744680852e-06,
      "loss": 0.08,
      "step": 3051
    },
    {
      "epoch": 0.7012867647058824,
      "grad_norm": 1.2864526510238647,
      "learning_rate": 8.515744680851064e-06,
      "loss": 0.1076,
      "step": 3052
    },
    {
      "epoch": 0.7015165441176471,
      "grad_norm": 1.1017073392868042,
      "learning_rate": 8.514893617021277e-06,
      "loss": 0.0968,
      "step": 3053
    },
    {
      "epoch": 0.7017463235294118,
      "grad_norm": 1.369524359703064,
      "learning_rate": 8.51404255319149e-06,
      "loss": 0.1237,
      "step": 3054
    },
    {
      "epoch": 0.7019761029411765,
      "grad_norm": 1.3281491994857788,
      "learning_rate": 8.513191489361703e-06,
      "loss": 0.0805,
      "step": 3055
    },
    {
      "epoch": 0.7022058823529411,
      "grad_norm": 1.2792683839797974,
      "learning_rate": 8.512340425531915e-06,
      "loss": 0.1444,
      "step": 3056
    },
    {
      "epoch": 0.7024356617647058,
      "grad_norm": 1.8377885818481445,
      "learning_rate": 8.511489361702128e-06,
      "loss": 0.148,
      "step": 3057
    },
    {
      "epoch": 0.7026654411764706,
      "grad_norm": 1.0593476295471191,
      "learning_rate": 8.510638297872341e-06,
      "loss": 0.0806,
      "step": 3058
    },
    {
      "epoch": 0.7028952205882353,
      "grad_norm": 1.1091958284378052,
      "learning_rate": 8.509787234042554e-06,
      "loss": 0.0886,
      "step": 3059
    },
    {
      "epoch": 0.703125,
      "grad_norm": 1.433028221130371,
      "learning_rate": 8.508936170212768e-06,
      "loss": 0.1148,
      "step": 3060
    },
    {
      "epoch": 0.7033547794117647,
      "grad_norm": 1.2604429721832275,
      "learning_rate": 8.508085106382979e-06,
      "loss": 0.1021,
      "step": 3061
    },
    {
      "epoch": 0.7035845588235294,
      "grad_norm": 1.2432693243026733,
      "learning_rate": 8.507234042553192e-06,
      "loss": 0.1419,
      "step": 3062
    },
    {
      "epoch": 0.7038143382352942,
      "grad_norm": 1.3696671724319458,
      "learning_rate": 8.506382978723405e-06,
      "loss": 0.1339,
      "step": 3063
    },
    {
      "epoch": 0.7040441176470589,
      "grad_norm": 1.306580662727356,
      "learning_rate": 8.505531914893619e-06,
      "loss": 0.1484,
      "step": 3064
    },
    {
      "epoch": 0.7042738970588235,
      "grad_norm": 0.9167200922966003,
      "learning_rate": 8.50468085106383e-06,
      "loss": 0.0829,
      "step": 3065
    },
    {
      "epoch": 0.7045036764705882,
      "grad_norm": 1.2668780088424683,
      "learning_rate": 8.503829787234043e-06,
      "loss": 0.1131,
      "step": 3066
    },
    {
      "epoch": 0.7047334558823529,
      "grad_norm": 1.9609524011611938,
      "learning_rate": 8.502978723404256e-06,
      "loss": 0.1122,
      "step": 3067
    },
    {
      "epoch": 0.7049632352941176,
      "grad_norm": 1.1485326290130615,
      "learning_rate": 8.502127659574468e-06,
      "loss": 0.1316,
      "step": 3068
    },
    {
      "epoch": 0.7051930147058824,
      "grad_norm": 1.145799160003662,
      "learning_rate": 8.501276595744683e-06,
      "loss": 0.0698,
      "step": 3069
    },
    {
      "epoch": 0.7054227941176471,
      "grad_norm": 0.9113340377807617,
      "learning_rate": 8.500425531914894e-06,
      "loss": 0.0863,
      "step": 3070
    },
    {
      "epoch": 0.7056525735294118,
      "grad_norm": 1.2979562282562256,
      "learning_rate": 8.499574468085107e-06,
      "loss": 0.1294,
      "step": 3071
    },
    {
      "epoch": 0.7058823529411765,
      "grad_norm": 1.2074604034423828,
      "learning_rate": 8.49872340425532e-06,
      "loss": 0.0911,
      "step": 3072
    },
    {
      "epoch": 0.7061121323529411,
      "grad_norm": 1.2568689584732056,
      "learning_rate": 8.497872340425532e-06,
      "loss": 0.1313,
      "step": 3073
    },
    {
      "epoch": 0.7063419117647058,
      "grad_norm": 1.3399430513381958,
      "learning_rate": 8.497021276595745e-06,
      "loss": 0.1282,
      "step": 3074
    },
    {
      "epoch": 0.7065716911764706,
      "grad_norm": 1.117470383644104,
      "learning_rate": 8.496170212765958e-06,
      "loss": 0.0777,
      "step": 3075
    },
    {
      "epoch": 0.7068014705882353,
      "grad_norm": 1.0383409261703491,
      "learning_rate": 8.495319148936172e-06,
      "loss": 0.0933,
      "step": 3076
    },
    {
      "epoch": 0.70703125,
      "grad_norm": 1.6034144163131714,
      "learning_rate": 8.494468085106383e-06,
      "loss": 0.1623,
      "step": 3077
    },
    {
      "epoch": 0.7072610294117647,
      "grad_norm": 1.3887706995010376,
      "learning_rate": 8.493617021276596e-06,
      "loss": 0.135,
      "step": 3078
    },
    {
      "epoch": 0.7074908088235294,
      "grad_norm": 1.1325725317001343,
      "learning_rate": 8.49276595744681e-06,
      "loss": 0.0996,
      "step": 3079
    },
    {
      "epoch": 0.7077205882352942,
      "grad_norm": 1.5387849807739258,
      "learning_rate": 8.49191489361702e-06,
      "loss": 0.0876,
      "step": 3080
    },
    {
      "epoch": 0.7079503676470589,
      "grad_norm": 1.4413392543792725,
      "learning_rate": 8.491063829787236e-06,
      "loss": 0.1458,
      "step": 3081
    },
    {
      "epoch": 0.7081801470588235,
      "grad_norm": 1.108670949935913,
      "learning_rate": 8.490212765957447e-06,
      "loss": 0.1003,
      "step": 3082
    },
    {
      "epoch": 0.7084099264705882,
      "grad_norm": 1.4527885913848877,
      "learning_rate": 8.48936170212766e-06,
      "loss": 0.1127,
      "step": 3083
    },
    {
      "epoch": 0.7086397058823529,
      "grad_norm": 1.2279243469238281,
      "learning_rate": 8.488510638297874e-06,
      "loss": 0.122,
      "step": 3084
    },
    {
      "epoch": 0.7088694852941176,
      "grad_norm": 1.0158672332763672,
      "learning_rate": 8.487659574468085e-06,
      "loss": 0.1036,
      "step": 3085
    },
    {
      "epoch": 0.7090992647058824,
      "grad_norm": 1.2834488153457642,
      "learning_rate": 8.486808510638298e-06,
      "loss": 0.1523,
      "step": 3086
    },
    {
      "epoch": 0.7093290441176471,
      "grad_norm": 1.0905137062072754,
      "learning_rate": 8.485957446808511e-06,
      "loss": 0.1435,
      "step": 3087
    },
    {
      "epoch": 0.7095588235294118,
      "grad_norm": 1.5072972774505615,
      "learning_rate": 8.485106382978724e-06,
      "loss": 0.1189,
      "step": 3088
    },
    {
      "epoch": 0.7097886029411765,
      "grad_norm": 1.0870290994644165,
      "learning_rate": 8.484255319148938e-06,
      "loss": 0.1284,
      "step": 3089
    },
    {
      "epoch": 0.7100183823529411,
      "grad_norm": 1.1518428325653076,
      "learning_rate": 8.483404255319149e-06,
      "loss": 0.1121,
      "step": 3090
    },
    {
      "epoch": 0.7102481617647058,
      "grad_norm": 1.2536081075668335,
      "learning_rate": 8.482553191489362e-06,
      "loss": 0.1169,
      "step": 3091
    },
    {
      "epoch": 0.7104779411764706,
      "grad_norm": 1.3179492950439453,
      "learning_rate": 8.481702127659575e-06,
      "loss": 0.1358,
      "step": 3092
    },
    {
      "epoch": 0.7107077205882353,
      "grad_norm": 1.2882581949234009,
      "learning_rate": 8.480851063829789e-06,
      "loss": 0.1119,
      "step": 3093
    },
    {
      "epoch": 0.7109375,
      "grad_norm": 1.475460410118103,
      "learning_rate": 8.48e-06,
      "loss": 0.1297,
      "step": 3094
    },
    {
      "epoch": 0.7111672794117647,
      "grad_norm": 1.361572504043579,
      "learning_rate": 8.479148936170213e-06,
      "loss": 0.1551,
      "step": 3095
    },
    {
      "epoch": 0.7113970588235294,
      "grad_norm": 1.3268022537231445,
      "learning_rate": 8.478297872340426e-06,
      "loss": 0.1343,
      "step": 3096
    },
    {
      "epoch": 0.7116268382352942,
      "grad_norm": 1.0861639976501465,
      "learning_rate": 8.477446808510638e-06,
      "loss": 0.1067,
      "step": 3097
    },
    {
      "epoch": 0.7118566176470589,
      "grad_norm": 1.5782173871994019,
      "learning_rate": 8.476595744680853e-06,
      "loss": 0.1234,
      "step": 3098
    },
    {
      "epoch": 0.7120863970588235,
      "grad_norm": 1.1356806755065918,
      "learning_rate": 8.475744680851064e-06,
      "loss": 0.1226,
      "step": 3099
    },
    {
      "epoch": 0.7123161764705882,
      "grad_norm": 1.196441650390625,
      "learning_rate": 8.474893617021277e-06,
      "loss": 0.1098,
      "step": 3100
    },
    {
      "epoch": 0.7125459558823529,
      "grad_norm": 1.1888073682785034,
      "learning_rate": 8.47404255319149e-06,
      "loss": 0.1038,
      "step": 3101
    },
    {
      "epoch": 0.7127757352941176,
      "grad_norm": 1.5730900764465332,
      "learning_rate": 8.473191489361702e-06,
      "loss": 0.1216,
      "step": 3102
    },
    {
      "epoch": 0.7130055147058824,
      "grad_norm": 0.9829314351081848,
      "learning_rate": 8.472340425531915e-06,
      "loss": 0.1131,
      "step": 3103
    },
    {
      "epoch": 0.7132352941176471,
      "grad_norm": 0.9585482478141785,
      "learning_rate": 8.471489361702128e-06,
      "loss": 0.0892,
      "step": 3104
    },
    {
      "epoch": 0.7134650735294118,
      "grad_norm": 1.2971893548965454,
      "learning_rate": 8.470638297872342e-06,
      "loss": 0.1115,
      "step": 3105
    },
    {
      "epoch": 0.7136948529411765,
      "grad_norm": 1.5061973333358765,
      "learning_rate": 8.469787234042553e-06,
      "loss": 0.1443,
      "step": 3106
    },
    {
      "epoch": 0.7139246323529411,
      "grad_norm": 1.4295810461044312,
      "learning_rate": 8.468936170212766e-06,
      "loss": 0.1493,
      "step": 3107
    },
    {
      "epoch": 0.7141544117647058,
      "grad_norm": 1.2550227642059326,
      "learning_rate": 8.46808510638298e-06,
      "loss": 0.1524,
      "step": 3108
    },
    {
      "epoch": 0.7143841911764706,
      "grad_norm": 1.3863911628723145,
      "learning_rate": 8.467234042553193e-06,
      "loss": 0.1153,
      "step": 3109
    },
    {
      "epoch": 0.7146139705882353,
      "grad_norm": 1.0870317220687866,
      "learning_rate": 8.466382978723406e-06,
      "loss": 0.082,
      "step": 3110
    },
    {
      "epoch": 0.71484375,
      "grad_norm": 1.1785714626312256,
      "learning_rate": 8.465531914893617e-06,
      "loss": 0.1154,
      "step": 3111
    },
    {
      "epoch": 0.7150735294117647,
      "grad_norm": 1.3844581842422485,
      "learning_rate": 8.46468085106383e-06,
      "loss": 0.0954,
      "step": 3112
    },
    {
      "epoch": 0.7153033088235294,
      "grad_norm": 1.56095552444458,
      "learning_rate": 8.463829787234044e-06,
      "loss": 0.1196,
      "step": 3113
    },
    {
      "epoch": 0.7155330882352942,
      "grad_norm": 1.6369779109954834,
      "learning_rate": 8.462978723404257e-06,
      "loss": 0.1017,
      "step": 3114
    },
    {
      "epoch": 0.7157628676470589,
      "grad_norm": 1.2329992055892944,
      "learning_rate": 8.462127659574468e-06,
      "loss": 0.0878,
      "step": 3115
    },
    {
      "epoch": 0.7159926470588235,
      "grad_norm": 1.3000582456588745,
      "learning_rate": 8.461276595744681e-06,
      "loss": 0.099,
      "step": 3116
    },
    {
      "epoch": 0.7162224264705882,
      "grad_norm": 1.275518536567688,
      "learning_rate": 8.460425531914895e-06,
      "loss": 0.1005,
      "step": 3117
    },
    {
      "epoch": 0.7164522058823529,
      "grad_norm": 1.3025671243667603,
      "learning_rate": 8.459574468085106e-06,
      "loss": 0.0986,
      "step": 3118
    },
    {
      "epoch": 0.7166819852941176,
      "grad_norm": 1.3012192249298096,
      "learning_rate": 8.458723404255321e-06,
      "loss": 0.1472,
      "step": 3119
    },
    {
      "epoch": 0.7169117647058824,
      "grad_norm": 1.7688775062561035,
      "learning_rate": 8.457872340425532e-06,
      "loss": 0.1459,
      "step": 3120
    },
    {
      "epoch": 0.7171415441176471,
      "grad_norm": 1.9566890001296997,
      "learning_rate": 8.457021276595746e-06,
      "loss": 0.188,
      "step": 3121
    },
    {
      "epoch": 0.7173713235294118,
      "grad_norm": 1.1137140989303589,
      "learning_rate": 8.456170212765959e-06,
      "loss": 0.0909,
      "step": 3122
    },
    {
      "epoch": 0.7176011029411765,
      "grad_norm": 1.0185377597808838,
      "learning_rate": 8.45531914893617e-06,
      "loss": 0.1104,
      "step": 3123
    },
    {
      "epoch": 0.7178308823529411,
      "grad_norm": 1.4082632064819336,
      "learning_rate": 8.454468085106383e-06,
      "loss": 0.1036,
      "step": 3124
    },
    {
      "epoch": 0.7180606617647058,
      "grad_norm": 1.406235933303833,
      "learning_rate": 8.453617021276597e-06,
      "loss": 0.1225,
      "step": 3125
    },
    {
      "epoch": 0.7182904411764706,
      "grad_norm": 1.211984634399414,
      "learning_rate": 8.45276595744681e-06,
      "loss": 0.1058,
      "step": 3126
    },
    {
      "epoch": 0.7185202205882353,
      "grad_norm": 1.2051265239715576,
      "learning_rate": 8.451914893617021e-06,
      "loss": 0.1242,
      "step": 3127
    },
    {
      "epoch": 0.71875,
      "grad_norm": 1.2365809679031372,
      "learning_rate": 8.451063829787234e-06,
      "loss": 0.1415,
      "step": 3128
    },
    {
      "epoch": 0.7189797794117647,
      "grad_norm": 1.8528265953063965,
      "learning_rate": 8.450212765957448e-06,
      "loss": 0.1648,
      "step": 3129
    },
    {
      "epoch": 0.7192095588235294,
      "grad_norm": 1.2256582975387573,
      "learning_rate": 8.449361702127659e-06,
      "loss": 0.1041,
      "step": 3130
    },
    {
      "epoch": 0.7194393382352942,
      "grad_norm": 1.3448314666748047,
      "learning_rate": 8.448510638297874e-06,
      "loss": 0.1676,
      "step": 3131
    },
    {
      "epoch": 0.7196691176470589,
      "grad_norm": 1.326937198638916,
      "learning_rate": 8.447659574468085e-06,
      "loss": 0.1347,
      "step": 3132
    },
    {
      "epoch": 0.7198988970588235,
      "grad_norm": 1.185468077659607,
      "learning_rate": 8.446808510638299e-06,
      "loss": 0.1206,
      "step": 3133
    },
    {
      "epoch": 0.7201286764705882,
      "grad_norm": 1.2732499837875366,
      "learning_rate": 8.445957446808512e-06,
      "loss": 0.1595,
      "step": 3134
    },
    {
      "epoch": 0.7203584558823529,
      "grad_norm": 0.9210976958274841,
      "learning_rate": 8.445106382978723e-06,
      "loss": 0.075,
      "step": 3135
    },
    {
      "epoch": 0.7205882352941176,
      "grad_norm": 0.9200597405433655,
      "learning_rate": 8.444255319148938e-06,
      "loss": 0.1067,
      "step": 3136
    },
    {
      "epoch": 0.7208180147058824,
      "grad_norm": 1.2942880392074585,
      "learning_rate": 8.44340425531915e-06,
      "loss": 0.1523,
      "step": 3137
    },
    {
      "epoch": 0.7210477941176471,
      "grad_norm": 0.9562761187553406,
      "learning_rate": 8.442553191489363e-06,
      "loss": 0.0961,
      "step": 3138
    },
    {
      "epoch": 0.7212775735294118,
      "grad_norm": 1.5204570293426514,
      "learning_rate": 8.441702127659576e-06,
      "loss": 0.1673,
      "step": 3139
    },
    {
      "epoch": 0.7215073529411765,
      "grad_norm": 1.516958236694336,
      "learning_rate": 8.440851063829787e-06,
      "loss": 0.1476,
      "step": 3140
    },
    {
      "epoch": 0.7217371323529411,
      "grad_norm": 1.2843393087387085,
      "learning_rate": 8.44e-06,
      "loss": 0.0834,
      "step": 3141
    },
    {
      "epoch": 0.7219669117647058,
      "grad_norm": 0.8607068061828613,
      "learning_rate": 8.439148936170214e-06,
      "loss": 0.0878,
      "step": 3142
    },
    {
      "epoch": 0.7221966911764706,
      "grad_norm": 1.028239130973816,
      "learning_rate": 8.438297872340427e-06,
      "loss": 0.0843,
      "step": 3143
    },
    {
      "epoch": 0.7224264705882353,
      "grad_norm": 1.1865719556808472,
      "learning_rate": 8.437446808510638e-06,
      "loss": 0.115,
      "step": 3144
    },
    {
      "epoch": 0.72265625,
      "grad_norm": 1.1107206344604492,
      "learning_rate": 8.436595744680851e-06,
      "loss": 0.0955,
      "step": 3145
    },
    {
      "epoch": 0.7228860294117647,
      "grad_norm": 1.2011299133300781,
      "learning_rate": 8.435744680851065e-06,
      "loss": 0.0959,
      "step": 3146
    },
    {
      "epoch": 0.7231158088235294,
      "grad_norm": 1.1536035537719727,
      "learning_rate": 8.434893617021276e-06,
      "loss": 0.0945,
      "step": 3147
    },
    {
      "epoch": 0.7233455882352942,
      "grad_norm": 1.1077954769134521,
      "learning_rate": 8.434042553191491e-06,
      "loss": 0.0877,
      "step": 3148
    },
    {
      "epoch": 0.7235753676470589,
      "grad_norm": 1.3086429834365845,
      "learning_rate": 8.433191489361702e-06,
      "loss": 0.0968,
      "step": 3149
    },
    {
      "epoch": 0.7238051470588235,
      "grad_norm": 0.9561461806297302,
      "learning_rate": 8.432340425531916e-06,
      "loss": 0.0736,
      "step": 3150
    },
    {
      "epoch": 0.7240349264705882,
      "grad_norm": 1.7429300546646118,
      "learning_rate": 8.431489361702129e-06,
      "loss": 0.1413,
      "step": 3151
    },
    {
      "epoch": 0.7242647058823529,
      "grad_norm": 1.4418058395385742,
      "learning_rate": 8.43063829787234e-06,
      "loss": 0.1292,
      "step": 3152
    },
    {
      "epoch": 0.7244944852941176,
      "grad_norm": 1.274376630783081,
      "learning_rate": 8.429787234042553e-06,
      "loss": 0.1312,
      "step": 3153
    },
    {
      "epoch": 0.7247242647058824,
      "grad_norm": 1.2061251401901245,
      "learning_rate": 8.428936170212767e-06,
      "loss": 0.1225,
      "step": 3154
    },
    {
      "epoch": 0.7249540441176471,
      "grad_norm": 1.2164533138275146,
      "learning_rate": 8.42808510638298e-06,
      "loss": 0.1239,
      "step": 3155
    },
    {
      "epoch": 0.7251838235294118,
      "grad_norm": 1.6166207790374756,
      "learning_rate": 8.427234042553191e-06,
      "loss": 0.1296,
      "step": 3156
    },
    {
      "epoch": 0.7254136029411765,
      "grad_norm": 1.2451188564300537,
      "learning_rate": 8.426382978723404e-06,
      "loss": 0.1176,
      "step": 3157
    },
    {
      "epoch": 0.7256433823529411,
      "grad_norm": 1.0255767107009888,
      "learning_rate": 8.425531914893618e-06,
      "loss": 0.1051,
      "step": 3158
    },
    {
      "epoch": 0.7258731617647058,
      "grad_norm": 0.8756278157234192,
      "learning_rate": 8.42468085106383e-06,
      "loss": 0.099,
      "step": 3159
    },
    {
      "epoch": 0.7261029411764706,
      "grad_norm": 1.3252580165863037,
      "learning_rate": 8.423829787234044e-06,
      "loss": 0.0938,
      "step": 3160
    },
    {
      "epoch": 0.7263327205882353,
      "grad_norm": 1.4200143814086914,
      "learning_rate": 8.422978723404255e-06,
      "loss": 0.1205,
      "step": 3161
    },
    {
      "epoch": 0.7265625,
      "grad_norm": 1.3510082960128784,
      "learning_rate": 8.422127659574469e-06,
      "loss": 0.0999,
      "step": 3162
    },
    {
      "epoch": 0.7267922794117647,
      "grad_norm": 1.6384061574935913,
      "learning_rate": 8.421276595744682e-06,
      "loss": 0.1619,
      "step": 3163
    },
    {
      "epoch": 0.7270220588235294,
      "grad_norm": 1.5483169555664062,
      "learning_rate": 8.420425531914895e-06,
      "loss": 0.1486,
      "step": 3164
    },
    {
      "epoch": 0.7272518382352942,
      "grad_norm": 1.0577919483184814,
      "learning_rate": 8.419574468085106e-06,
      "loss": 0.0832,
      "step": 3165
    },
    {
      "epoch": 0.7274816176470589,
      "grad_norm": 1.0560017824172974,
      "learning_rate": 8.41872340425532e-06,
      "loss": 0.0973,
      "step": 3166
    },
    {
      "epoch": 0.7277113970588235,
      "grad_norm": 1.2084773778915405,
      "learning_rate": 8.417872340425533e-06,
      "loss": 0.0858,
      "step": 3167
    },
    {
      "epoch": 0.7279411764705882,
      "grad_norm": 1.2966017723083496,
      "learning_rate": 8.417021276595744e-06,
      "loss": 0.1157,
      "step": 3168
    },
    {
      "epoch": 0.7281709558823529,
      "grad_norm": 1.032626748085022,
      "learning_rate": 8.416170212765959e-06,
      "loss": 0.0783,
      "step": 3169
    },
    {
      "epoch": 0.7284007352941176,
      "grad_norm": 1.0550224781036377,
      "learning_rate": 8.41531914893617e-06,
      "loss": 0.1011,
      "step": 3170
    },
    {
      "epoch": 0.7286305147058824,
      "grad_norm": 1.3681790828704834,
      "learning_rate": 8.414468085106384e-06,
      "loss": 0.124,
      "step": 3171
    },
    {
      "epoch": 0.7288602941176471,
      "grad_norm": 1.0218532085418701,
      "learning_rate": 8.413617021276597e-06,
      "loss": 0.0952,
      "step": 3172
    },
    {
      "epoch": 0.7290900735294118,
      "grad_norm": 1.0651144981384277,
      "learning_rate": 8.412765957446808e-06,
      "loss": 0.0982,
      "step": 3173
    },
    {
      "epoch": 0.7293198529411765,
      "grad_norm": 1.6617910861968994,
      "learning_rate": 8.411914893617023e-06,
      "loss": 0.1633,
      "step": 3174
    },
    {
      "epoch": 0.7295496323529411,
      "grad_norm": 1.6238062381744385,
      "learning_rate": 8.411063829787235e-06,
      "loss": 0.1251,
      "step": 3175
    },
    {
      "epoch": 0.7297794117647058,
      "grad_norm": 1.7823444604873657,
      "learning_rate": 8.410212765957448e-06,
      "loss": 0.1221,
      "step": 3176
    },
    {
      "epoch": 0.7300091911764706,
      "grad_norm": 1.3318111896514893,
      "learning_rate": 8.409361702127661e-06,
      "loss": 0.1337,
      "step": 3177
    },
    {
      "epoch": 0.7302389705882353,
      "grad_norm": 1.2662239074707031,
      "learning_rate": 8.408510638297873e-06,
      "loss": 0.1555,
      "step": 3178
    },
    {
      "epoch": 0.73046875,
      "grad_norm": 1.2636315822601318,
      "learning_rate": 8.407659574468086e-06,
      "loss": 0.1454,
      "step": 3179
    },
    {
      "epoch": 0.7306985294117647,
      "grad_norm": 1.2566349506378174,
      "learning_rate": 8.406808510638299e-06,
      "loss": 0.1101,
      "step": 3180
    },
    {
      "epoch": 0.7309283088235294,
      "grad_norm": 1.3141672611236572,
      "learning_rate": 8.405957446808512e-06,
      "loss": 0.1611,
      "step": 3181
    },
    {
      "epoch": 0.7311580882352942,
      "grad_norm": 1.8135669231414795,
      "learning_rate": 8.405106382978724e-06,
      "loss": 0.1471,
      "step": 3182
    },
    {
      "epoch": 0.7313878676470589,
      "grad_norm": 1.334320306777954,
      "learning_rate": 8.404255319148937e-06,
      "loss": 0.1096,
      "step": 3183
    },
    {
      "epoch": 0.7316176470588235,
      "grad_norm": 1.824369192123413,
      "learning_rate": 8.40340425531915e-06,
      "loss": 0.1101,
      "step": 3184
    },
    {
      "epoch": 0.7318474264705882,
      "grad_norm": 0.9005974531173706,
      "learning_rate": 8.402553191489361e-06,
      "loss": 0.1146,
      "step": 3185
    },
    {
      "epoch": 0.7320772058823529,
      "grad_norm": 1.4019405841827393,
      "learning_rate": 8.401702127659576e-06,
      "loss": 0.13,
      "step": 3186
    },
    {
      "epoch": 0.7323069852941176,
      "grad_norm": 1.0421804189682007,
      "learning_rate": 8.400851063829788e-06,
      "loss": 0.0974,
      "step": 3187
    },
    {
      "epoch": 0.7325367647058824,
      "grad_norm": 1.4755268096923828,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.1728,
      "step": 3188
    },
    {
      "epoch": 0.7327665441176471,
      "grad_norm": 1.0573209524154663,
      "learning_rate": 8.399148936170214e-06,
      "loss": 0.0809,
      "step": 3189
    },
    {
      "epoch": 0.7329963235294118,
      "grad_norm": 0.8371063470840454,
      "learning_rate": 8.398297872340426e-06,
      "loss": 0.0977,
      "step": 3190
    },
    {
      "epoch": 0.7332261029411765,
      "grad_norm": 1.435492992401123,
      "learning_rate": 8.397446808510639e-06,
      "loss": 0.1166,
      "step": 3191
    },
    {
      "epoch": 0.7334558823529411,
      "grad_norm": 1.3897709846496582,
      "learning_rate": 8.396595744680852e-06,
      "loss": 0.0959,
      "step": 3192
    },
    {
      "epoch": 0.7336856617647058,
      "grad_norm": 0.9124089479446411,
      "learning_rate": 8.395744680851065e-06,
      "loss": 0.0822,
      "step": 3193
    },
    {
      "epoch": 0.7339154411764706,
      "grad_norm": 1.1428173780441284,
      "learning_rate": 8.394893617021277e-06,
      "loss": 0.0967,
      "step": 3194
    },
    {
      "epoch": 0.7341452205882353,
      "grad_norm": 1.4672023057937622,
      "learning_rate": 8.39404255319149e-06,
      "loss": 0.107,
      "step": 3195
    },
    {
      "epoch": 0.734375,
      "grad_norm": 1.2195637226104736,
      "learning_rate": 8.393191489361703e-06,
      "loss": 0.1169,
      "step": 3196
    },
    {
      "epoch": 0.7346047794117647,
      "grad_norm": 1.3379206657409668,
      "learning_rate": 8.392340425531916e-06,
      "loss": 0.0977,
      "step": 3197
    },
    {
      "epoch": 0.7348345588235294,
      "grad_norm": 1.2834784984588623,
      "learning_rate": 8.39148936170213e-06,
      "loss": 0.0829,
      "step": 3198
    },
    {
      "epoch": 0.7350643382352942,
      "grad_norm": 1.3087917566299438,
      "learning_rate": 8.39063829787234e-06,
      "loss": 0.104,
      "step": 3199
    },
    {
      "epoch": 0.7352941176470589,
      "grad_norm": 1.5068769454956055,
      "learning_rate": 8.389787234042554e-06,
      "loss": 0.0943,
      "step": 3200
    },
    {
      "epoch": 0.7355238970588235,
      "grad_norm": 1.84418785572052,
      "learning_rate": 8.388936170212767e-06,
      "loss": 0.1439,
      "step": 3201
    },
    {
      "epoch": 0.7357536764705882,
      "grad_norm": 1.0352380275726318,
      "learning_rate": 8.388085106382979e-06,
      "loss": 0.1025,
      "step": 3202
    },
    {
      "epoch": 0.7359834558823529,
      "grad_norm": 1.846135139465332,
      "learning_rate": 8.387234042553192e-06,
      "loss": 0.1507,
      "step": 3203
    },
    {
      "epoch": 0.7362132352941176,
      "grad_norm": 1.206178069114685,
      "learning_rate": 8.386382978723405e-06,
      "loss": 0.1266,
      "step": 3204
    },
    {
      "epoch": 0.7364430147058824,
      "grad_norm": 1.0112358331680298,
      "learning_rate": 8.385531914893618e-06,
      "loss": 0.1157,
      "step": 3205
    },
    {
      "epoch": 0.7366727941176471,
      "grad_norm": 1.3176409006118774,
      "learning_rate": 8.38468085106383e-06,
      "loss": 0.117,
      "step": 3206
    },
    {
      "epoch": 0.7369025735294118,
      "grad_norm": 1.1517168283462524,
      "learning_rate": 8.383829787234043e-06,
      "loss": 0.1026,
      "step": 3207
    },
    {
      "epoch": 0.7371323529411765,
      "grad_norm": 1.3890784978866577,
      "learning_rate": 8.382978723404256e-06,
      "loss": 0.1355,
      "step": 3208
    },
    {
      "epoch": 0.7373621323529411,
      "grad_norm": 1.2163779735565186,
      "learning_rate": 8.382127659574469e-06,
      "loss": 0.0812,
      "step": 3209
    },
    {
      "epoch": 0.7375919117647058,
      "grad_norm": 1.2116894721984863,
      "learning_rate": 8.381276595744682e-06,
      "loss": 0.1109,
      "step": 3210
    },
    {
      "epoch": 0.7378216911764706,
      "grad_norm": 1.5361740589141846,
      "learning_rate": 8.380425531914894e-06,
      "loss": 0.1242,
      "step": 3211
    },
    {
      "epoch": 0.7380514705882353,
      "grad_norm": 1.1861323118209839,
      "learning_rate": 8.379574468085107e-06,
      "loss": 0.1638,
      "step": 3212
    },
    {
      "epoch": 0.73828125,
      "grad_norm": 1.0868891477584839,
      "learning_rate": 8.37872340425532e-06,
      "loss": 0.1038,
      "step": 3213
    },
    {
      "epoch": 0.7385110294117647,
      "grad_norm": 1.3619574308395386,
      "learning_rate": 8.377872340425533e-06,
      "loss": 0.1025,
      "step": 3214
    },
    {
      "epoch": 0.7387408088235294,
      "grad_norm": 1.0459458827972412,
      "learning_rate": 8.377021276595745e-06,
      "loss": 0.0867,
      "step": 3215
    },
    {
      "epoch": 0.7389705882352942,
      "grad_norm": 1.1261248588562012,
      "learning_rate": 8.376170212765958e-06,
      "loss": 0.0791,
      "step": 3216
    },
    {
      "epoch": 0.7392003676470589,
      "grad_norm": 1.340770959854126,
      "learning_rate": 8.375319148936171e-06,
      "loss": 0.1061,
      "step": 3217
    },
    {
      "epoch": 0.7394301470588235,
      "grad_norm": 1.3523328304290771,
      "learning_rate": 8.374468085106384e-06,
      "loss": 0.1075,
      "step": 3218
    },
    {
      "epoch": 0.7396599264705882,
      "grad_norm": 1.109904408454895,
      "learning_rate": 8.373617021276597e-06,
      "loss": 0.1318,
      "step": 3219
    },
    {
      "epoch": 0.7398897058823529,
      "grad_norm": 1.5484766960144043,
      "learning_rate": 8.372765957446809e-06,
      "loss": 0.1189,
      "step": 3220
    },
    {
      "epoch": 0.7401194852941176,
      "grad_norm": 1.6472433805465698,
      "learning_rate": 8.371914893617022e-06,
      "loss": 0.1705,
      "step": 3221
    },
    {
      "epoch": 0.7403492647058824,
      "grad_norm": 2.2786383628845215,
      "learning_rate": 8.371063829787235e-06,
      "loss": 0.2036,
      "step": 3222
    },
    {
      "epoch": 0.7405790441176471,
      "grad_norm": 1.224242925643921,
      "learning_rate": 8.370212765957447e-06,
      "loss": 0.1159,
      "step": 3223
    },
    {
      "epoch": 0.7408088235294118,
      "grad_norm": 1.0211042165756226,
      "learning_rate": 8.369361702127661e-06,
      "loss": 0.12,
      "step": 3224
    },
    {
      "epoch": 0.7410386029411765,
      "grad_norm": 0.9160317182540894,
      "learning_rate": 8.368510638297873e-06,
      "loss": 0.0936,
      "step": 3225
    },
    {
      "epoch": 0.7412683823529411,
      "grad_norm": 1.1007763147354126,
      "learning_rate": 8.367659574468086e-06,
      "loss": 0.0727,
      "step": 3226
    },
    {
      "epoch": 0.7414981617647058,
      "grad_norm": 1.3445258140563965,
      "learning_rate": 8.3668085106383e-06,
      "loss": 0.1126,
      "step": 3227
    },
    {
      "epoch": 0.7417279411764706,
      "grad_norm": 1.0438282489776611,
      "learning_rate": 8.36595744680851e-06,
      "loss": 0.1099,
      "step": 3228
    },
    {
      "epoch": 0.7419577205882353,
      "grad_norm": 1.2179045677185059,
      "learning_rate": 8.365106382978724e-06,
      "loss": 0.1234,
      "step": 3229
    },
    {
      "epoch": 0.7421875,
      "grad_norm": 1.140392541885376,
      "learning_rate": 8.364255319148937e-06,
      "loss": 0.093,
      "step": 3230
    },
    {
      "epoch": 0.7424172794117647,
      "grad_norm": 0.8167511224746704,
      "learning_rate": 8.36340425531915e-06,
      "loss": 0.0891,
      "step": 3231
    },
    {
      "epoch": 0.7426470588235294,
      "grad_norm": 1.0332430601119995,
      "learning_rate": 8.362553191489362e-06,
      "loss": 0.1086,
      "step": 3232
    },
    {
      "epoch": 0.7428768382352942,
      "grad_norm": 0.9740046262741089,
      "learning_rate": 8.361702127659575e-06,
      "loss": 0.0956,
      "step": 3233
    },
    {
      "epoch": 0.7431066176470589,
      "grad_norm": 1.6235065460205078,
      "learning_rate": 8.360851063829788e-06,
      "loss": 0.1514,
      "step": 3234
    },
    {
      "epoch": 0.7433363970588235,
      "grad_norm": 1.0213501453399658,
      "learning_rate": 8.36e-06,
      "loss": 0.0664,
      "step": 3235
    },
    {
      "epoch": 0.7435661764705882,
      "grad_norm": 1.3565142154693604,
      "learning_rate": 8.359148936170214e-06,
      "loss": 0.1414,
      "step": 3236
    },
    {
      "epoch": 0.7437959558823529,
      "grad_norm": 1.2330454587936401,
      "learning_rate": 8.358297872340426e-06,
      "loss": 0.1276,
      "step": 3237
    },
    {
      "epoch": 0.7440257352941176,
      "grad_norm": 1.8833422660827637,
      "learning_rate": 8.357446808510639e-06,
      "loss": 0.0924,
      "step": 3238
    },
    {
      "epoch": 0.7442555147058824,
      "grad_norm": 1.5185637474060059,
      "learning_rate": 8.356595744680852e-06,
      "loss": 0.1056,
      "step": 3239
    },
    {
      "epoch": 0.7444852941176471,
      "grad_norm": 1.028042197227478,
      "learning_rate": 8.355744680851064e-06,
      "loss": 0.1024,
      "step": 3240
    },
    {
      "epoch": 0.7447150735294118,
      "grad_norm": 1.2107890844345093,
      "learning_rate": 8.354893617021277e-06,
      "loss": 0.1177,
      "step": 3241
    },
    {
      "epoch": 0.7449448529411765,
      "grad_norm": 1.4083950519561768,
      "learning_rate": 8.35404255319149e-06,
      "loss": 0.1415,
      "step": 3242
    },
    {
      "epoch": 0.7451746323529411,
      "grad_norm": 1.1126232147216797,
      "learning_rate": 8.353191489361703e-06,
      "loss": 0.101,
      "step": 3243
    },
    {
      "epoch": 0.7454044117647058,
      "grad_norm": 1.0894496440887451,
      "learning_rate": 8.352340425531915e-06,
      "loss": 0.1079,
      "step": 3244
    },
    {
      "epoch": 0.7456341911764706,
      "grad_norm": 1.865282654762268,
      "learning_rate": 8.351489361702128e-06,
      "loss": 0.1888,
      "step": 3245
    },
    {
      "epoch": 0.7458639705882353,
      "grad_norm": 1.327913522720337,
      "learning_rate": 8.350638297872341e-06,
      "loss": 0.1098,
      "step": 3246
    },
    {
      "epoch": 0.74609375,
      "grad_norm": 1.4701247215270996,
      "learning_rate": 8.349787234042554e-06,
      "loss": 0.1132,
      "step": 3247
    },
    {
      "epoch": 0.7463235294117647,
      "grad_norm": 1.2905105352401733,
      "learning_rate": 8.348936170212767e-06,
      "loss": 0.1182,
      "step": 3248
    },
    {
      "epoch": 0.7465533088235294,
      "grad_norm": 1.2926539182662964,
      "learning_rate": 8.348085106382979e-06,
      "loss": 0.1091,
      "step": 3249
    },
    {
      "epoch": 0.7467830882352942,
      "grad_norm": 1.2268891334533691,
      "learning_rate": 8.347234042553192e-06,
      "loss": 0.093,
      "step": 3250
    },
    {
      "epoch": 0.7470128676470589,
      "grad_norm": 1.0935380458831787,
      "learning_rate": 8.346382978723405e-06,
      "loss": 0.1206,
      "step": 3251
    },
    {
      "epoch": 0.7472426470588235,
      "grad_norm": 0.8948447704315186,
      "learning_rate": 8.345531914893618e-06,
      "loss": 0.0927,
      "step": 3252
    },
    {
      "epoch": 0.7474724264705882,
      "grad_norm": 1.1434720754623413,
      "learning_rate": 8.34468085106383e-06,
      "loss": 0.1232,
      "step": 3253
    },
    {
      "epoch": 0.7477022058823529,
      "grad_norm": 0.9811424016952515,
      "learning_rate": 8.343829787234043e-06,
      "loss": 0.1157,
      "step": 3254
    },
    {
      "epoch": 0.7479319852941176,
      "grad_norm": 1.6797305345535278,
      "learning_rate": 8.342978723404256e-06,
      "loss": 0.1028,
      "step": 3255
    },
    {
      "epoch": 0.7481617647058824,
      "grad_norm": 1.6199290752410889,
      "learning_rate": 8.342127659574468e-06,
      "loss": 0.1386,
      "step": 3256
    },
    {
      "epoch": 0.7483915441176471,
      "grad_norm": 1.7946735620498657,
      "learning_rate": 8.341276595744683e-06,
      "loss": 0.2081,
      "step": 3257
    },
    {
      "epoch": 0.7486213235294118,
      "grad_norm": 1.3025109767913818,
      "learning_rate": 8.340425531914894e-06,
      "loss": 0.1247,
      "step": 3258
    },
    {
      "epoch": 0.7488511029411765,
      "grad_norm": 1.442777395248413,
      "learning_rate": 8.339574468085107e-06,
      "loss": 0.1193,
      "step": 3259
    },
    {
      "epoch": 0.7490808823529411,
      "grad_norm": 1.2244620323181152,
      "learning_rate": 8.33872340425532e-06,
      "loss": 0.1399,
      "step": 3260
    },
    {
      "epoch": 0.7493106617647058,
      "grad_norm": 1.4059704542160034,
      "learning_rate": 8.337872340425532e-06,
      "loss": 0.1141,
      "step": 3261
    },
    {
      "epoch": 0.7495404411764706,
      "grad_norm": 1.5598266124725342,
      "learning_rate": 8.337021276595747e-06,
      "loss": 0.1514,
      "step": 3262
    },
    {
      "epoch": 0.7497702205882353,
      "grad_norm": 1.0504881143569946,
      "learning_rate": 8.336170212765958e-06,
      "loss": 0.0934,
      "step": 3263
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.09839928150177,
      "learning_rate": 8.335319148936171e-06,
      "loss": 0.0941,
      "step": 3264
    },
    {
      "epoch": 0.7502297794117647,
      "grad_norm": 1.015637755393982,
      "learning_rate": 8.334468085106385e-06,
      "loss": 0.0889,
      "step": 3265
    },
    {
      "epoch": 0.7504595588235294,
      "grad_norm": 1.1161437034606934,
      "learning_rate": 8.333617021276596e-06,
      "loss": 0.1162,
      "step": 3266
    },
    {
      "epoch": 0.7506893382352942,
      "grad_norm": 1.360582947731018,
      "learning_rate": 8.33276595744681e-06,
      "loss": 0.1141,
      "step": 3267
    },
    {
      "epoch": 0.7509191176470589,
      "grad_norm": 1.0362728834152222,
      "learning_rate": 8.331914893617022e-06,
      "loss": 0.0823,
      "step": 3268
    },
    {
      "epoch": 0.7511488970588235,
      "grad_norm": 1.1496586799621582,
      "learning_rate": 8.331063829787236e-06,
      "loss": 0.0865,
      "step": 3269
    },
    {
      "epoch": 0.7513786764705882,
      "grad_norm": 1.2144410610198975,
      "learning_rate": 8.330212765957447e-06,
      "loss": 0.1089,
      "step": 3270
    },
    {
      "epoch": 0.7516084558823529,
      "grad_norm": 0.9738112688064575,
      "learning_rate": 8.32936170212766e-06,
      "loss": 0.0861,
      "step": 3271
    },
    {
      "epoch": 0.7518382352941176,
      "grad_norm": 1.552951455116272,
      "learning_rate": 8.328510638297873e-06,
      "loss": 0.1325,
      "step": 3272
    },
    {
      "epoch": 0.7520680147058824,
      "grad_norm": 0.9399147629737854,
      "learning_rate": 8.327659574468085e-06,
      "loss": 0.0915,
      "step": 3273
    },
    {
      "epoch": 0.7522977941176471,
      "grad_norm": 1.4709179401397705,
      "learning_rate": 8.3268085106383e-06,
      "loss": 0.1709,
      "step": 3274
    },
    {
      "epoch": 0.7525275735294118,
      "grad_norm": 1.0279539823532104,
      "learning_rate": 8.325957446808511e-06,
      "loss": 0.1166,
      "step": 3275
    },
    {
      "epoch": 0.7527573529411765,
      "grad_norm": 1.257847547531128,
      "learning_rate": 8.325106382978724e-06,
      "loss": 0.1261,
      "step": 3276
    },
    {
      "epoch": 0.7529871323529411,
      "grad_norm": 1.0581105947494507,
      "learning_rate": 8.324255319148937e-06,
      "loss": 0.1075,
      "step": 3277
    },
    {
      "epoch": 0.7532169117647058,
      "grad_norm": 1.456963062286377,
      "learning_rate": 8.323404255319149e-06,
      "loss": 0.1284,
      "step": 3278
    },
    {
      "epoch": 0.7534466911764706,
      "grad_norm": 1.2603873014450073,
      "learning_rate": 8.322553191489362e-06,
      "loss": 0.1151,
      "step": 3279
    },
    {
      "epoch": 0.7536764705882353,
      "grad_norm": 1.0252357721328735,
      "learning_rate": 8.321702127659575e-06,
      "loss": 0.0781,
      "step": 3280
    },
    {
      "epoch": 0.75390625,
      "grad_norm": 1.0561881065368652,
      "learning_rate": 8.320851063829788e-06,
      "loss": 0.1035,
      "step": 3281
    },
    {
      "epoch": 0.7541360294117647,
      "grad_norm": 1.533602237701416,
      "learning_rate": 8.32e-06,
      "loss": 0.0889,
      "step": 3282
    },
    {
      "epoch": 0.7543658088235294,
      "grad_norm": 1.1276533603668213,
      "learning_rate": 8.319148936170213e-06,
      "loss": 0.1055,
      "step": 3283
    },
    {
      "epoch": 0.7545955882352942,
      "grad_norm": 1.4916006326675415,
      "learning_rate": 8.318297872340426e-06,
      "loss": 0.1243,
      "step": 3284
    },
    {
      "epoch": 0.7548253676470589,
      "grad_norm": 1.5541094541549683,
      "learning_rate": 8.317446808510638e-06,
      "loss": 0.136,
      "step": 3285
    },
    {
      "epoch": 0.7550551470588235,
      "grad_norm": 1.4445466995239258,
      "learning_rate": 8.316595744680853e-06,
      "loss": 0.1497,
      "step": 3286
    },
    {
      "epoch": 0.7552849264705882,
      "grad_norm": 2.0548288822174072,
      "learning_rate": 8.315744680851064e-06,
      "loss": 0.1639,
      "step": 3287
    },
    {
      "epoch": 0.7555147058823529,
      "grad_norm": 1.0604729652404785,
      "learning_rate": 8.314893617021277e-06,
      "loss": 0.0911,
      "step": 3288
    },
    {
      "epoch": 0.7557444852941176,
      "grad_norm": 1.4560309648513794,
      "learning_rate": 8.31404255319149e-06,
      "loss": 0.1428,
      "step": 3289
    },
    {
      "epoch": 0.7559742647058824,
      "grad_norm": 0.8879456520080566,
      "learning_rate": 8.313191489361702e-06,
      "loss": 0.0776,
      "step": 3290
    },
    {
      "epoch": 0.7562040441176471,
      "grad_norm": 1.483818769454956,
      "learning_rate": 8.312340425531915e-06,
      "loss": 0.1042,
      "step": 3291
    },
    {
      "epoch": 0.7564338235294118,
      "grad_norm": 1.558344841003418,
      "learning_rate": 8.311489361702128e-06,
      "loss": 0.1001,
      "step": 3292
    },
    {
      "epoch": 0.7566636029411765,
      "grad_norm": 1.11835777759552,
      "learning_rate": 8.310638297872341e-06,
      "loss": 0.1073,
      "step": 3293
    },
    {
      "epoch": 0.7568933823529411,
      "grad_norm": 1.3203606605529785,
      "learning_rate": 8.309787234042553e-06,
      "loss": 0.1331,
      "step": 3294
    },
    {
      "epoch": 0.7571231617647058,
      "grad_norm": 1.3086730241775513,
      "learning_rate": 8.308936170212766e-06,
      "loss": 0.1189,
      "step": 3295
    },
    {
      "epoch": 0.7573529411764706,
      "grad_norm": 1.5029253959655762,
      "learning_rate": 8.30808510638298e-06,
      "loss": 0.1867,
      "step": 3296
    },
    {
      "epoch": 0.7575827205882353,
      "grad_norm": 1.3042793273925781,
      "learning_rate": 8.307234042553192e-06,
      "loss": 0.1043,
      "step": 3297
    },
    {
      "epoch": 0.7578125,
      "grad_norm": 1.7607359886169434,
      "learning_rate": 8.306382978723406e-06,
      "loss": 0.1332,
      "step": 3298
    },
    {
      "epoch": 0.7580422794117647,
      "grad_norm": 1.5080320835113525,
      "learning_rate": 8.305531914893617e-06,
      "loss": 0.0844,
      "step": 3299
    },
    {
      "epoch": 0.7582720588235294,
      "grad_norm": 1.3674794435501099,
      "learning_rate": 8.30468085106383e-06,
      "loss": 0.1234,
      "step": 3300
    },
    {
      "epoch": 0.7585018382352942,
      "grad_norm": 1.2502795457839966,
      "learning_rate": 8.303829787234043e-06,
      "loss": 0.1075,
      "step": 3301
    },
    {
      "epoch": 0.7587316176470589,
      "grad_norm": 1.0590460300445557,
      "learning_rate": 8.302978723404257e-06,
      "loss": 0.0826,
      "step": 3302
    },
    {
      "epoch": 0.7589613970588235,
      "grad_norm": 0.9258496165275574,
      "learning_rate": 8.30212765957447e-06,
      "loss": 0.0976,
      "step": 3303
    },
    {
      "epoch": 0.7591911764705882,
      "grad_norm": 1.2737524509429932,
      "learning_rate": 8.301276595744681e-06,
      "loss": 0.0838,
      "step": 3304
    },
    {
      "epoch": 0.7594209558823529,
      "grad_norm": 1.0920065641403198,
      "learning_rate": 8.300425531914894e-06,
      "loss": 0.0854,
      "step": 3305
    },
    {
      "epoch": 0.7596507352941176,
      "grad_norm": 1.5452343225479126,
      "learning_rate": 8.299574468085108e-06,
      "loss": 0.135,
      "step": 3306
    },
    {
      "epoch": 0.7598805147058824,
      "grad_norm": 1.1790804862976074,
      "learning_rate": 8.29872340425532e-06,
      "loss": 0.0958,
      "step": 3307
    },
    {
      "epoch": 0.7601102941176471,
      "grad_norm": 0.9350689649581909,
      "learning_rate": 8.297872340425532e-06,
      "loss": 0.0953,
      "step": 3308
    },
    {
      "epoch": 0.7603400735294118,
      "grad_norm": 1.1809749603271484,
      "learning_rate": 8.297021276595745e-06,
      "loss": 0.0841,
      "step": 3309
    },
    {
      "epoch": 0.7605698529411765,
      "grad_norm": 1.2857043743133545,
      "learning_rate": 8.296170212765959e-06,
      "loss": 0.1261,
      "step": 3310
    },
    {
      "epoch": 0.7607996323529411,
      "grad_norm": 1.3467590808868408,
      "learning_rate": 8.29531914893617e-06,
      "loss": 0.1138,
      "step": 3311
    },
    {
      "epoch": 0.7610294117647058,
      "grad_norm": 1.3713473081588745,
      "learning_rate": 8.294468085106385e-06,
      "loss": 0.1001,
      "step": 3312
    },
    {
      "epoch": 0.7612591911764706,
      "grad_norm": 1.090519666671753,
      "learning_rate": 8.293617021276596e-06,
      "loss": 0.102,
      "step": 3313
    },
    {
      "epoch": 0.7614889705882353,
      "grad_norm": 1.082269549369812,
      "learning_rate": 8.29276595744681e-06,
      "loss": 0.126,
      "step": 3314
    },
    {
      "epoch": 0.76171875,
      "grad_norm": 1.6659198999404907,
      "learning_rate": 8.291914893617023e-06,
      "loss": 0.1066,
      "step": 3315
    },
    {
      "epoch": 0.7619485294117647,
      "grad_norm": 0.9344365000724792,
      "learning_rate": 8.291063829787234e-06,
      "loss": 0.1056,
      "step": 3316
    },
    {
      "epoch": 0.7621783088235294,
      "grad_norm": 1.2368627786636353,
      "learning_rate": 8.290212765957447e-06,
      "loss": 0.0843,
      "step": 3317
    },
    {
      "epoch": 0.7624080882352942,
      "grad_norm": 1.0483235120773315,
      "learning_rate": 8.28936170212766e-06,
      "loss": 0.1344,
      "step": 3318
    },
    {
      "epoch": 0.7626378676470589,
      "grad_norm": 2.1798508167266846,
      "learning_rate": 8.288510638297874e-06,
      "loss": 0.2087,
      "step": 3319
    },
    {
      "epoch": 0.7628676470588235,
      "grad_norm": 1.1526775360107422,
      "learning_rate": 8.287659574468085e-06,
      "loss": 0.0934,
      "step": 3320
    },
    {
      "epoch": 0.7630974264705882,
      "grad_norm": 1.4415382146835327,
      "learning_rate": 8.286808510638298e-06,
      "loss": 0.1331,
      "step": 3321
    },
    {
      "epoch": 0.7633272058823529,
      "grad_norm": 1.1972519159317017,
      "learning_rate": 8.285957446808512e-06,
      "loss": 0.0778,
      "step": 3322
    },
    {
      "epoch": 0.7635569852941176,
      "grad_norm": 1.225439429283142,
      "learning_rate": 8.285106382978723e-06,
      "loss": 0.1133,
      "step": 3323
    },
    {
      "epoch": 0.7637867647058824,
      "grad_norm": 1.487296223640442,
      "learning_rate": 8.284255319148938e-06,
      "loss": 0.138,
      "step": 3324
    },
    {
      "epoch": 0.7640165441176471,
      "grad_norm": 1.209408164024353,
      "learning_rate": 8.28340425531915e-06,
      "loss": 0.1195,
      "step": 3325
    },
    {
      "epoch": 0.7642463235294118,
      "grad_norm": 1.0108497142791748,
      "learning_rate": 8.282553191489363e-06,
      "loss": 0.1232,
      "step": 3326
    },
    {
      "epoch": 0.7644761029411765,
      "grad_norm": 1.5514872074127197,
      "learning_rate": 8.281702127659576e-06,
      "loss": 0.0959,
      "step": 3327
    },
    {
      "epoch": 0.7647058823529411,
      "grad_norm": 1.2947818040847778,
      "learning_rate": 8.280851063829787e-06,
      "loss": 0.135,
      "step": 3328
    },
    {
      "epoch": 0.7649356617647058,
      "grad_norm": 1.3460392951965332,
      "learning_rate": 8.28e-06,
      "loss": 0.1163,
      "step": 3329
    },
    {
      "epoch": 0.7651654411764706,
      "grad_norm": 1.1338242292404175,
      "learning_rate": 8.279148936170214e-06,
      "loss": 0.0922,
      "step": 3330
    },
    {
      "epoch": 0.7653952205882353,
      "grad_norm": 1.6368731260299683,
      "learning_rate": 8.278297872340427e-06,
      "loss": 0.182,
      "step": 3331
    },
    {
      "epoch": 0.765625,
      "grad_norm": 1.2333886623382568,
      "learning_rate": 8.277446808510638e-06,
      "loss": 0.1169,
      "step": 3332
    },
    {
      "epoch": 0.7658547794117647,
      "grad_norm": 1.2273446321487427,
      "learning_rate": 8.276595744680851e-06,
      "loss": 0.0896,
      "step": 3333
    },
    {
      "epoch": 0.7660845588235294,
      "grad_norm": 1.064846158027649,
      "learning_rate": 8.275744680851065e-06,
      "loss": 0.0965,
      "step": 3334
    },
    {
      "epoch": 0.7663143382352942,
      "grad_norm": 1.3028428554534912,
      "learning_rate": 8.274893617021276e-06,
      "loss": 0.1082,
      "step": 3335
    },
    {
      "epoch": 0.7665441176470589,
      "grad_norm": 1.3113404512405396,
      "learning_rate": 8.27404255319149e-06,
      "loss": 0.1505,
      "step": 3336
    },
    {
      "epoch": 0.7667738970588235,
      "grad_norm": 1.5037237405776978,
      "learning_rate": 8.273191489361702e-06,
      "loss": 0.102,
      "step": 3337
    },
    {
      "epoch": 0.7670036764705882,
      "grad_norm": 1.4753628969192505,
      "learning_rate": 8.272340425531915e-06,
      "loss": 0.1537,
      "step": 3338
    },
    {
      "epoch": 0.7672334558823529,
      "grad_norm": 1.0953434705734253,
      "learning_rate": 8.271489361702129e-06,
      "loss": 0.133,
      "step": 3339
    },
    {
      "epoch": 0.7674632352941176,
      "grad_norm": 1.2841613292694092,
      "learning_rate": 8.27063829787234e-06,
      "loss": 0.1276,
      "step": 3340
    },
    {
      "epoch": 0.7676930147058824,
      "grad_norm": 1.1781353950500488,
      "learning_rate": 8.269787234042553e-06,
      "loss": 0.1301,
      "step": 3341
    },
    {
      "epoch": 0.7679227941176471,
      "grad_norm": 1.7981231212615967,
      "learning_rate": 8.268936170212766e-06,
      "loss": 0.1129,
      "step": 3342
    },
    {
      "epoch": 0.7681525735294118,
      "grad_norm": 1.2034063339233398,
      "learning_rate": 8.26808510638298e-06,
      "loss": 0.0854,
      "step": 3343
    },
    {
      "epoch": 0.7683823529411765,
      "grad_norm": 1.1531223058700562,
      "learning_rate": 8.267234042553191e-06,
      "loss": 0.0777,
      "step": 3344
    },
    {
      "epoch": 0.7686121323529411,
      "grad_norm": 1.1738836765289307,
      "learning_rate": 8.266382978723404e-06,
      "loss": 0.0981,
      "step": 3345
    },
    {
      "epoch": 0.7688419117647058,
      "grad_norm": 1.3049263954162598,
      "learning_rate": 8.265531914893617e-06,
      "loss": 0.1048,
      "step": 3346
    },
    {
      "epoch": 0.7690716911764706,
      "grad_norm": 1.368087649345398,
      "learning_rate": 8.26468085106383e-06,
      "loss": 0.1295,
      "step": 3347
    },
    {
      "epoch": 0.7693014705882353,
      "grad_norm": 1.0041887760162354,
      "learning_rate": 8.263829787234044e-06,
      "loss": 0.0741,
      "step": 3348
    },
    {
      "epoch": 0.76953125,
      "grad_norm": 1.4254430532455444,
      "learning_rate": 8.262978723404255e-06,
      "loss": 0.14,
      "step": 3349
    },
    {
      "epoch": 0.7697610294117647,
      "grad_norm": 1.3839287757873535,
      "learning_rate": 8.262127659574468e-06,
      "loss": 0.1036,
      "step": 3350
    },
    {
      "epoch": 0.7699908088235294,
      "grad_norm": 1.3900513648986816,
      "learning_rate": 8.261276595744682e-06,
      "loss": 0.1668,
      "step": 3351
    },
    {
      "epoch": 0.7702205882352942,
      "grad_norm": 1.3661657571792603,
      "learning_rate": 8.260425531914895e-06,
      "loss": 0.0914,
      "step": 3352
    },
    {
      "epoch": 0.7704503676470589,
      "grad_norm": 1.2571848630905151,
      "learning_rate": 8.259574468085108e-06,
      "loss": 0.0891,
      "step": 3353
    },
    {
      "epoch": 0.7706801470588235,
      "grad_norm": 1.5332868099212646,
      "learning_rate": 8.25872340425532e-06,
      "loss": 0.1184,
      "step": 3354
    },
    {
      "epoch": 0.7709099264705882,
      "grad_norm": 1.0504399538040161,
      "learning_rate": 8.257872340425533e-06,
      "loss": 0.1103,
      "step": 3355
    },
    {
      "epoch": 0.7711397058823529,
      "grad_norm": 1.7179855108261108,
      "learning_rate": 8.257021276595746e-06,
      "loss": 0.1003,
      "step": 3356
    },
    {
      "epoch": 0.7713694852941176,
      "grad_norm": 1.0810259580612183,
      "learning_rate": 8.256170212765959e-06,
      "loss": 0.0794,
      "step": 3357
    },
    {
      "epoch": 0.7715992647058824,
      "grad_norm": 1.101365566253662,
      "learning_rate": 8.25531914893617e-06,
      "loss": 0.1022,
      "step": 3358
    },
    {
      "epoch": 0.7718290441176471,
      "grad_norm": 1.611446499824524,
      "learning_rate": 8.254468085106384e-06,
      "loss": 0.117,
      "step": 3359
    },
    {
      "epoch": 0.7720588235294118,
      "grad_norm": 1.3814260959625244,
      "learning_rate": 8.253617021276597e-06,
      "loss": 0.0647,
      "step": 3360
    },
    {
      "epoch": 0.7722886029411765,
      "grad_norm": 1.4709068536758423,
      "learning_rate": 8.252765957446808e-06,
      "loss": 0.1293,
      "step": 3361
    },
    {
      "epoch": 0.7725183823529411,
      "grad_norm": 1.2918189764022827,
      "learning_rate": 8.251914893617023e-06,
      "loss": 0.1073,
      "step": 3362
    },
    {
      "epoch": 0.7727481617647058,
      "grad_norm": 1.3382320404052734,
      "learning_rate": 8.251063829787235e-06,
      "loss": 0.1217,
      "step": 3363
    },
    {
      "epoch": 0.7729779411764706,
      "grad_norm": 1.5726622343063354,
      "learning_rate": 8.250212765957448e-06,
      "loss": 0.093,
      "step": 3364
    },
    {
      "epoch": 0.7732077205882353,
      "grad_norm": 1.2566215991973877,
      "learning_rate": 8.249361702127661e-06,
      "loss": 0.116,
      "step": 3365
    },
    {
      "epoch": 0.7734375,
      "grad_norm": 1.5888943672180176,
      "learning_rate": 8.248510638297872e-06,
      "loss": 0.0973,
      "step": 3366
    },
    {
      "epoch": 0.7736672794117647,
      "grad_norm": 1.4633440971374512,
      "learning_rate": 8.247659574468086e-06,
      "loss": 0.1316,
      "step": 3367
    },
    {
      "epoch": 0.7738970588235294,
      "grad_norm": 1.3913389444351196,
      "learning_rate": 8.246808510638299e-06,
      "loss": 0.1012,
      "step": 3368
    },
    {
      "epoch": 0.7741268382352942,
      "grad_norm": 1.4032334089279175,
      "learning_rate": 8.245957446808512e-06,
      "loss": 0.0912,
      "step": 3369
    },
    {
      "epoch": 0.7743566176470589,
      "grad_norm": 1.1301697492599487,
      "learning_rate": 8.245106382978723e-06,
      "loss": 0.1364,
      "step": 3370
    },
    {
      "epoch": 0.7745863970588235,
      "grad_norm": 1.4062222242355347,
      "learning_rate": 8.244255319148937e-06,
      "loss": 0.1074,
      "step": 3371
    },
    {
      "epoch": 0.7748161764705882,
      "grad_norm": 1.4954403638839722,
      "learning_rate": 8.24340425531915e-06,
      "loss": 0.1172,
      "step": 3372
    },
    {
      "epoch": 0.7750459558823529,
      "grad_norm": 1.391756296157837,
      "learning_rate": 8.242553191489361e-06,
      "loss": 0.1417,
      "step": 3373
    },
    {
      "epoch": 0.7752757352941176,
      "grad_norm": 1.0434749126434326,
      "learning_rate": 8.241702127659576e-06,
      "loss": 0.0926,
      "step": 3374
    },
    {
      "epoch": 0.7755055147058824,
      "grad_norm": 1.5371983051300049,
      "learning_rate": 8.240851063829788e-06,
      "loss": 0.0862,
      "step": 3375
    },
    {
      "epoch": 0.7757352941176471,
      "grad_norm": 1.8443140983581543,
      "learning_rate": 8.24e-06,
      "loss": 0.1474,
      "step": 3376
    },
    {
      "epoch": 0.7759650735294118,
      "grad_norm": 1.4295207262039185,
      "learning_rate": 8.239148936170214e-06,
      "loss": 0.113,
      "step": 3377
    },
    {
      "epoch": 0.7761948529411765,
      "grad_norm": 1.4879285097122192,
      "learning_rate": 8.238297872340425e-06,
      "loss": 0.1336,
      "step": 3378
    },
    {
      "epoch": 0.7764246323529411,
      "grad_norm": 1.1001766920089722,
      "learning_rate": 8.237446808510639e-06,
      "loss": 0.1213,
      "step": 3379
    },
    {
      "epoch": 0.7766544117647058,
      "grad_norm": 1.262848138809204,
      "learning_rate": 8.236595744680852e-06,
      "loss": 0.1151,
      "step": 3380
    },
    {
      "epoch": 0.7768841911764706,
      "grad_norm": 1.063184380531311,
      "learning_rate": 8.235744680851065e-06,
      "loss": 0.0964,
      "step": 3381
    },
    {
      "epoch": 0.7771139705882353,
      "grad_norm": 1.464787244796753,
      "learning_rate": 8.234893617021276e-06,
      "loss": 0.1257,
      "step": 3382
    },
    {
      "epoch": 0.77734375,
      "grad_norm": 1.5612808465957642,
      "learning_rate": 8.23404255319149e-06,
      "loss": 0.1678,
      "step": 3383
    },
    {
      "epoch": 0.7775735294117647,
      "grad_norm": 1.3359296321868896,
      "learning_rate": 8.233191489361703e-06,
      "loss": 0.1247,
      "step": 3384
    },
    {
      "epoch": 0.7778033088235294,
      "grad_norm": 1.4031500816345215,
      "learning_rate": 8.232340425531916e-06,
      "loss": 0.129,
      "step": 3385
    },
    {
      "epoch": 0.7780330882352942,
      "grad_norm": 1.6077111959457397,
      "learning_rate": 8.231489361702129e-06,
      "loss": 0.1148,
      "step": 3386
    },
    {
      "epoch": 0.7782628676470589,
      "grad_norm": 1.1139591932296753,
      "learning_rate": 8.23063829787234e-06,
      "loss": 0.0979,
      "step": 3387
    },
    {
      "epoch": 0.7784926470588235,
      "grad_norm": 1.2174937725067139,
      "learning_rate": 8.229787234042554e-06,
      "loss": 0.0854,
      "step": 3388
    },
    {
      "epoch": 0.7787224264705882,
      "grad_norm": 1.3033603429794312,
      "learning_rate": 8.228936170212767e-06,
      "loss": 0.1186,
      "step": 3389
    },
    {
      "epoch": 0.7789522058823529,
      "grad_norm": 1.2269259691238403,
      "learning_rate": 8.22808510638298e-06,
      "loss": 0.1114,
      "step": 3390
    },
    {
      "epoch": 0.7791819852941176,
      "grad_norm": 0.9526474475860596,
      "learning_rate": 8.227234042553193e-06,
      "loss": 0.0587,
      "step": 3391
    },
    {
      "epoch": 0.7794117647058824,
      "grad_norm": 1.916070580482483,
      "learning_rate": 8.226382978723405e-06,
      "loss": 0.152,
      "step": 3392
    },
    {
      "epoch": 0.7796415441176471,
      "grad_norm": 1.015416145324707,
      "learning_rate": 8.225531914893618e-06,
      "loss": 0.1392,
      "step": 3393
    },
    {
      "epoch": 0.7798713235294118,
      "grad_norm": 1.5597314834594727,
      "learning_rate": 8.224680851063831e-06,
      "loss": 0.1164,
      "step": 3394
    },
    {
      "epoch": 0.7801011029411765,
      "grad_norm": 1.513896107673645,
      "learning_rate": 8.223829787234044e-06,
      "loss": 0.1281,
      "step": 3395
    },
    {
      "epoch": 0.7803308823529411,
      "grad_norm": 1.1220868825912476,
      "learning_rate": 8.222978723404256e-06,
      "loss": 0.1044,
      "step": 3396
    },
    {
      "epoch": 0.7805606617647058,
      "grad_norm": 1.1510695219039917,
      "learning_rate": 8.222127659574469e-06,
      "loss": 0.0849,
      "step": 3397
    },
    {
      "epoch": 0.7807904411764706,
      "grad_norm": 1.663442850112915,
      "learning_rate": 8.221276595744682e-06,
      "loss": 0.1426,
      "step": 3398
    },
    {
      "epoch": 0.7810202205882353,
      "grad_norm": 1.408011794090271,
      "learning_rate": 8.220425531914893e-06,
      "loss": 0.13,
      "step": 3399
    },
    {
      "epoch": 0.78125,
      "grad_norm": 1.1000312566757202,
      "learning_rate": 8.219574468085108e-06,
      "loss": 0.0978,
      "step": 3400
    },
    {
      "epoch": 0.7814797794117647,
      "grad_norm": 1.3879506587982178,
      "learning_rate": 8.21872340425532e-06,
      "loss": 0.1133,
      "step": 3401
    },
    {
      "epoch": 0.7817095588235294,
      "grad_norm": 1.4013649225234985,
      "learning_rate": 8.217872340425533e-06,
      "loss": 0.1329,
      "step": 3402
    },
    {
      "epoch": 0.7819393382352942,
      "grad_norm": 0.8890101909637451,
      "learning_rate": 8.217021276595746e-06,
      "loss": 0.0857,
      "step": 3403
    },
    {
      "epoch": 0.7821691176470589,
      "grad_norm": 1.2402405738830566,
      "learning_rate": 8.216170212765958e-06,
      "loss": 0.103,
      "step": 3404
    },
    {
      "epoch": 0.7823988970588235,
      "grad_norm": 1.507646918296814,
      "learning_rate": 8.21531914893617e-06,
      "loss": 0.1306,
      "step": 3405
    },
    {
      "epoch": 0.7826286764705882,
      "grad_norm": 1.340236783027649,
      "learning_rate": 8.214468085106384e-06,
      "loss": 0.1147,
      "step": 3406
    },
    {
      "epoch": 0.7828584558823529,
      "grad_norm": 0.9226607084274292,
      "learning_rate": 8.213617021276597e-06,
      "loss": 0.0901,
      "step": 3407
    },
    {
      "epoch": 0.7830882352941176,
      "grad_norm": 1.0482369661331177,
      "learning_rate": 8.212765957446809e-06,
      "loss": 0.1215,
      "step": 3408
    },
    {
      "epoch": 0.7833180147058824,
      "grad_norm": 1.1866847276687622,
      "learning_rate": 8.211914893617022e-06,
      "loss": 0.117,
      "step": 3409
    },
    {
      "epoch": 0.7835477941176471,
      "grad_norm": 1.8060030937194824,
      "learning_rate": 8.211063829787235e-06,
      "loss": 0.137,
      "step": 3410
    },
    {
      "epoch": 0.7837775735294118,
      "grad_norm": 1.0041325092315674,
      "learning_rate": 8.210212765957446e-06,
      "loss": 0.0753,
      "step": 3411
    },
    {
      "epoch": 0.7840073529411765,
      "grad_norm": 0.9169007539749146,
      "learning_rate": 8.209361702127661e-06,
      "loss": 0.1062,
      "step": 3412
    },
    {
      "epoch": 0.7842371323529411,
      "grad_norm": 1.0032745599746704,
      "learning_rate": 8.208510638297873e-06,
      "loss": 0.0771,
      "step": 3413
    },
    {
      "epoch": 0.7844669117647058,
      "grad_norm": 1.293129801750183,
      "learning_rate": 8.207659574468086e-06,
      "loss": 0.1101,
      "step": 3414
    },
    {
      "epoch": 0.7846966911764706,
      "grad_norm": 1.3300426006317139,
      "learning_rate": 8.206808510638299e-06,
      "loss": 0.0813,
      "step": 3415
    },
    {
      "epoch": 0.7849264705882353,
      "grad_norm": 1.1972278356552124,
      "learning_rate": 8.20595744680851e-06,
      "loss": 0.0963,
      "step": 3416
    },
    {
      "epoch": 0.78515625,
      "grad_norm": 1.1169649362564087,
      "learning_rate": 8.205106382978724e-06,
      "loss": 0.1199,
      "step": 3417
    },
    {
      "epoch": 0.7853860294117647,
      "grad_norm": 1.2317675352096558,
      "learning_rate": 8.204255319148937e-06,
      "loss": 0.1188,
      "step": 3418
    },
    {
      "epoch": 0.7856158088235294,
      "grad_norm": 1.4526660442352295,
      "learning_rate": 8.20340425531915e-06,
      "loss": 0.1262,
      "step": 3419
    },
    {
      "epoch": 0.7858455882352942,
      "grad_norm": 1.2551047801971436,
      "learning_rate": 8.202553191489362e-06,
      "loss": 0.1179,
      "step": 3420
    },
    {
      "epoch": 0.7860753676470589,
      "grad_norm": 1.3100887537002563,
      "learning_rate": 8.201702127659575e-06,
      "loss": 0.1176,
      "step": 3421
    },
    {
      "epoch": 0.7863051470588235,
      "grad_norm": 1.183310866355896,
      "learning_rate": 8.200851063829788e-06,
      "loss": 0.1288,
      "step": 3422
    },
    {
      "epoch": 0.7865349264705882,
      "grad_norm": 1.117920160293579,
      "learning_rate": 8.2e-06,
      "loss": 0.0811,
      "step": 3423
    },
    {
      "epoch": 0.7867647058823529,
      "grad_norm": 0.9914782047271729,
      "learning_rate": 8.199148936170214e-06,
      "loss": 0.1168,
      "step": 3424
    },
    {
      "epoch": 0.7869944852941176,
      "grad_norm": 1.3367503881454468,
      "learning_rate": 8.198297872340426e-06,
      "loss": 0.1302,
      "step": 3425
    },
    {
      "epoch": 0.7872242647058824,
      "grad_norm": 1.8646814823150635,
      "learning_rate": 8.197446808510639e-06,
      "loss": 0.1872,
      "step": 3426
    },
    {
      "epoch": 0.7874540441176471,
      "grad_norm": 1.2087125778198242,
      "learning_rate": 8.196595744680852e-06,
      "loss": 0.0952,
      "step": 3427
    },
    {
      "epoch": 0.7876838235294118,
      "grad_norm": 1.2887284755706787,
      "learning_rate": 8.195744680851064e-06,
      "loss": 0.1068,
      "step": 3428
    },
    {
      "epoch": 0.7879136029411765,
      "grad_norm": 1.1664327383041382,
      "learning_rate": 8.194893617021277e-06,
      "loss": 0.0772,
      "step": 3429
    },
    {
      "epoch": 0.7881433823529411,
      "grad_norm": 1.1066498756408691,
      "learning_rate": 8.19404255319149e-06,
      "loss": 0.0785,
      "step": 3430
    },
    {
      "epoch": 0.7883731617647058,
      "grad_norm": 1.148137092590332,
      "learning_rate": 8.193191489361703e-06,
      "loss": 0.1081,
      "step": 3431
    },
    {
      "epoch": 0.7886029411764706,
      "grad_norm": 1.202453851699829,
      "learning_rate": 8.192340425531916e-06,
      "loss": 0.1321,
      "step": 3432
    },
    {
      "epoch": 0.7888327205882353,
      "grad_norm": 1.5052381753921509,
      "learning_rate": 8.191489361702128e-06,
      "loss": 0.1393,
      "step": 3433
    },
    {
      "epoch": 0.7890625,
      "grad_norm": 1.2256869077682495,
      "learning_rate": 8.190638297872341e-06,
      "loss": 0.1031,
      "step": 3434
    },
    {
      "epoch": 0.7892922794117647,
      "grad_norm": 1.4168903827667236,
      "learning_rate": 8.189787234042554e-06,
      "loss": 0.0868,
      "step": 3435
    },
    {
      "epoch": 0.7895220588235294,
      "grad_norm": 1.639772653579712,
      "learning_rate": 8.188936170212767e-06,
      "loss": 0.1132,
      "step": 3436
    },
    {
      "epoch": 0.7897518382352942,
      "grad_norm": 0.8974197506904602,
      "learning_rate": 8.188085106382979e-06,
      "loss": 0.0911,
      "step": 3437
    },
    {
      "epoch": 0.7899816176470589,
      "grad_norm": 1.2335526943206787,
      "learning_rate": 8.187234042553192e-06,
      "loss": 0.1012,
      "step": 3438
    },
    {
      "epoch": 0.7902113970588235,
      "grad_norm": 1.3941664695739746,
      "learning_rate": 8.186382978723405e-06,
      "loss": 0.1352,
      "step": 3439
    },
    {
      "epoch": 0.7904411764705882,
      "grad_norm": 1.0872248411178589,
      "learning_rate": 8.185531914893618e-06,
      "loss": 0.1004,
      "step": 3440
    },
    {
      "epoch": 0.7906709558823529,
      "grad_norm": 0.9630239605903625,
      "learning_rate": 8.184680851063831e-06,
      "loss": 0.0635,
      "step": 3441
    },
    {
      "epoch": 0.7909007352941176,
      "grad_norm": 1.146005392074585,
      "learning_rate": 8.183829787234043e-06,
      "loss": 0.1303,
      "step": 3442
    },
    {
      "epoch": 0.7911305147058824,
      "grad_norm": 1.309226393699646,
      "learning_rate": 8.182978723404256e-06,
      "loss": 0.1371,
      "step": 3443
    },
    {
      "epoch": 0.7913602941176471,
      "grad_norm": 1.270588755607605,
      "learning_rate": 8.18212765957447e-06,
      "loss": 0.1144,
      "step": 3444
    },
    {
      "epoch": 0.7915900735294118,
      "grad_norm": 1.7816383838653564,
      "learning_rate": 8.181276595744682e-06,
      "loss": 0.091,
      "step": 3445
    },
    {
      "epoch": 0.7918198529411765,
      "grad_norm": 1.5342371463775635,
      "learning_rate": 8.180425531914894e-06,
      "loss": 0.137,
      "step": 3446
    },
    {
      "epoch": 0.7920496323529411,
      "grad_norm": 1.1198053359985352,
      "learning_rate": 8.179574468085107e-06,
      "loss": 0.1205,
      "step": 3447
    },
    {
      "epoch": 0.7922794117647058,
      "grad_norm": 1.0133163928985596,
      "learning_rate": 8.17872340425532e-06,
      "loss": 0.105,
      "step": 3448
    },
    {
      "epoch": 0.7925091911764706,
      "grad_norm": 1.103127360343933,
      "learning_rate": 8.177872340425532e-06,
      "loss": 0.1295,
      "step": 3449
    },
    {
      "epoch": 0.7927389705882353,
      "grad_norm": 1.0982580184936523,
      "learning_rate": 8.177021276595747e-06,
      "loss": 0.0989,
      "step": 3450
    },
    {
      "epoch": 0.79296875,
      "grad_norm": 1.7017428874969482,
      "learning_rate": 8.176170212765958e-06,
      "loss": 0.1285,
      "step": 3451
    },
    {
      "epoch": 0.7931985294117647,
      "grad_norm": 1.6822246313095093,
      "learning_rate": 8.175319148936171e-06,
      "loss": 0.1484,
      "step": 3452
    },
    {
      "epoch": 0.7934283088235294,
      "grad_norm": 1.4337399005889893,
      "learning_rate": 8.174468085106384e-06,
      "loss": 0.0991,
      "step": 3453
    },
    {
      "epoch": 0.7936580882352942,
      "grad_norm": 1.4722920656204224,
      "learning_rate": 8.173617021276596e-06,
      "loss": 0.1632,
      "step": 3454
    },
    {
      "epoch": 0.7938878676470589,
      "grad_norm": 1.385026216506958,
      "learning_rate": 8.172765957446809e-06,
      "loss": 0.101,
      "step": 3455
    },
    {
      "epoch": 0.7941176470588235,
      "grad_norm": 1.1796929836273193,
      "learning_rate": 8.171914893617022e-06,
      "loss": 0.1197,
      "step": 3456
    },
    {
      "epoch": 0.7943474264705882,
      "grad_norm": 1.4849746227264404,
      "learning_rate": 8.171063829787235e-06,
      "loss": 0.1292,
      "step": 3457
    },
    {
      "epoch": 0.7945772058823529,
      "grad_norm": 1.0448755025863647,
      "learning_rate": 8.170212765957447e-06,
      "loss": 0.1199,
      "step": 3458
    },
    {
      "epoch": 0.7948069852941176,
      "grad_norm": 1.323494791984558,
      "learning_rate": 8.16936170212766e-06,
      "loss": 0.1058,
      "step": 3459
    },
    {
      "epoch": 0.7950367647058824,
      "grad_norm": 1.1291413307189941,
      "learning_rate": 8.168510638297873e-06,
      "loss": 0.0963,
      "step": 3460
    },
    {
      "epoch": 0.7952665441176471,
      "grad_norm": 1.4376051425933838,
      "learning_rate": 8.167659574468085e-06,
      "loss": 0.0877,
      "step": 3461
    },
    {
      "epoch": 0.7954963235294118,
      "grad_norm": 1.414544939994812,
      "learning_rate": 8.1668085106383e-06,
      "loss": 0.0964,
      "step": 3462
    },
    {
      "epoch": 0.7957261029411765,
      "grad_norm": 1.1202199459075928,
      "learning_rate": 8.165957446808511e-06,
      "loss": 0.0988,
      "step": 3463
    },
    {
      "epoch": 0.7959558823529411,
      "grad_norm": 1.1444579362869263,
      "learning_rate": 8.165106382978724e-06,
      "loss": 0.1179,
      "step": 3464
    },
    {
      "epoch": 0.7961856617647058,
      "grad_norm": 1.1635425090789795,
      "learning_rate": 8.164255319148937e-06,
      "loss": 0.0848,
      "step": 3465
    },
    {
      "epoch": 0.7964154411764706,
      "grad_norm": 1.253952980041504,
      "learning_rate": 8.163404255319149e-06,
      "loss": 0.1068,
      "step": 3466
    },
    {
      "epoch": 0.7966452205882353,
      "grad_norm": 1.1736420392990112,
      "learning_rate": 8.162553191489362e-06,
      "loss": 0.1134,
      "step": 3467
    },
    {
      "epoch": 0.796875,
      "grad_norm": 1.4675132036209106,
      "learning_rate": 8.161702127659575e-06,
      "loss": 0.1223,
      "step": 3468
    },
    {
      "epoch": 0.7971047794117647,
      "grad_norm": 1.48209547996521,
      "learning_rate": 8.160851063829788e-06,
      "loss": 0.1573,
      "step": 3469
    },
    {
      "epoch": 0.7973345588235294,
      "grad_norm": 0.9446800351142883,
      "learning_rate": 8.16e-06,
      "loss": 0.0932,
      "step": 3470
    },
    {
      "epoch": 0.7975643382352942,
      "grad_norm": 2.084604024887085,
      "learning_rate": 8.159148936170213e-06,
      "loss": 0.141,
      "step": 3471
    },
    {
      "epoch": 0.7977941176470589,
      "grad_norm": 1.8219196796417236,
      "learning_rate": 8.158297872340426e-06,
      "loss": 0.0942,
      "step": 3472
    },
    {
      "epoch": 0.7980238970588235,
      "grad_norm": 1.1546244621276855,
      "learning_rate": 8.157446808510638e-06,
      "loss": 0.116,
      "step": 3473
    },
    {
      "epoch": 0.7982536764705882,
      "grad_norm": 1.3824090957641602,
      "learning_rate": 8.156595744680852e-06,
      "loss": 0.1021,
      "step": 3474
    },
    {
      "epoch": 0.7984834558823529,
      "grad_norm": 1.33865225315094,
      "learning_rate": 8.155744680851064e-06,
      "loss": 0.1118,
      "step": 3475
    },
    {
      "epoch": 0.7987132352941176,
      "grad_norm": 1.6232035160064697,
      "learning_rate": 8.154893617021277e-06,
      "loss": 0.1124,
      "step": 3476
    },
    {
      "epoch": 0.7989430147058824,
      "grad_norm": 1.216515064239502,
      "learning_rate": 8.15404255319149e-06,
      "loss": 0.0842,
      "step": 3477
    },
    {
      "epoch": 0.7991727941176471,
      "grad_norm": 1.0245003700256348,
      "learning_rate": 8.153191489361702e-06,
      "loss": 0.0854,
      "step": 3478
    },
    {
      "epoch": 0.7994025735294118,
      "grad_norm": 1.273505449295044,
      "learning_rate": 8.152340425531917e-06,
      "loss": 0.0895,
      "step": 3479
    },
    {
      "epoch": 0.7996323529411765,
      "grad_norm": 1.4158051013946533,
      "learning_rate": 8.151489361702128e-06,
      "loss": 0.1007,
      "step": 3480
    },
    {
      "epoch": 0.7998621323529411,
      "grad_norm": 1.2071832418441772,
      "learning_rate": 8.150638297872341e-06,
      "loss": 0.1192,
      "step": 3481
    },
    {
      "epoch": 0.8000919117647058,
      "grad_norm": 1.2724624872207642,
      "learning_rate": 8.149787234042554e-06,
      "loss": 0.0907,
      "step": 3482
    },
    {
      "epoch": 0.8003216911764706,
      "grad_norm": 2.1507387161254883,
      "learning_rate": 8.148936170212766e-06,
      "loss": 0.0977,
      "step": 3483
    },
    {
      "epoch": 0.8005514705882353,
      "grad_norm": 1.0347464084625244,
      "learning_rate": 8.148085106382979e-06,
      "loss": 0.1042,
      "step": 3484
    },
    {
      "epoch": 0.80078125,
      "grad_norm": 1.2099666595458984,
      "learning_rate": 8.147234042553192e-06,
      "loss": 0.1211,
      "step": 3485
    },
    {
      "epoch": 0.8010110294117647,
      "grad_norm": 1.4383833408355713,
      "learning_rate": 8.146382978723405e-06,
      "loss": 0.1374,
      "step": 3486
    },
    {
      "epoch": 0.8012408088235294,
      "grad_norm": 1.2195667028427124,
      "learning_rate": 8.145531914893617e-06,
      "loss": 0.1093,
      "step": 3487
    },
    {
      "epoch": 0.8014705882352942,
      "grad_norm": 1.2005921602249146,
      "learning_rate": 8.14468085106383e-06,
      "loss": 0.0678,
      "step": 3488
    },
    {
      "epoch": 0.8017003676470589,
      "grad_norm": 1.1515753269195557,
      "learning_rate": 8.143829787234043e-06,
      "loss": 0.1078,
      "step": 3489
    },
    {
      "epoch": 0.8019301470588235,
      "grad_norm": 1.2733592987060547,
      "learning_rate": 8.142978723404256e-06,
      "loss": 0.1122,
      "step": 3490
    },
    {
      "epoch": 0.8021599264705882,
      "grad_norm": 1.386008858680725,
      "learning_rate": 8.14212765957447e-06,
      "loss": 0.101,
      "step": 3491
    },
    {
      "epoch": 0.8023897058823529,
      "grad_norm": 1.1821413040161133,
      "learning_rate": 8.141276595744681e-06,
      "loss": 0.1016,
      "step": 3492
    },
    {
      "epoch": 0.8026194852941176,
      "grad_norm": 1.5567482709884644,
      "learning_rate": 8.140425531914894e-06,
      "loss": 0.144,
      "step": 3493
    },
    {
      "epoch": 0.8028492647058824,
      "grad_norm": 1.4078108072280884,
      "learning_rate": 8.139574468085107e-06,
      "loss": 0.1392,
      "step": 3494
    },
    {
      "epoch": 0.8030790441176471,
      "grad_norm": 1.2318140268325806,
      "learning_rate": 8.13872340425532e-06,
      "loss": 0.1307,
      "step": 3495
    },
    {
      "epoch": 0.8033088235294118,
      "grad_norm": 1.3231881856918335,
      "learning_rate": 8.137872340425532e-06,
      "loss": 0.1022,
      "step": 3496
    },
    {
      "epoch": 0.8035386029411765,
      "grad_norm": 1.4570173025131226,
      "learning_rate": 8.137021276595745e-06,
      "loss": 0.1493,
      "step": 3497
    },
    {
      "epoch": 0.8037683823529411,
      "grad_norm": 1.6143708229064941,
      "learning_rate": 8.136170212765958e-06,
      "loss": 0.1365,
      "step": 3498
    },
    {
      "epoch": 0.8039981617647058,
      "grad_norm": 1.3376933336257935,
      "learning_rate": 8.13531914893617e-06,
      "loss": 0.092,
      "step": 3499
    },
    {
      "epoch": 0.8042279411764706,
      "grad_norm": 1.5972877740859985,
      "learning_rate": 8.134468085106385e-06,
      "loss": 0.1608,
      "step": 3500
    },
    {
      "epoch": 0.8042279411764706,
      "eval_loss": 0.1114163026213646,
      "eval_runtime": 1967.4176,
      "eval_samples_per_second": 4.527,
      "eval_steps_per_second": 2.263,
      "step": 3500
    },
    {
      "epoch": 0.8044577205882353,
      "grad_norm": 1.2258241176605225,
      "learning_rate": 8.133617021276596e-06,
      "loss": 0.108,
      "step": 3501
    },
    {
      "epoch": 0.8046875,
      "grad_norm": 0.9739035964012146,
      "learning_rate": 8.13276595744681e-06,
      "loss": 0.0818,
      "step": 3502
    },
    {
      "epoch": 0.8049172794117647,
      "grad_norm": 1.6037487983703613,
      "learning_rate": 8.131914893617023e-06,
      "loss": 0.1529,
      "step": 3503
    },
    {
      "epoch": 0.8051470588235294,
      "grad_norm": 1.1743202209472656,
      "learning_rate": 8.131063829787234e-06,
      "loss": 0.1081,
      "step": 3504
    },
    {
      "epoch": 0.8053768382352942,
      "grad_norm": 2.4584360122680664,
      "learning_rate": 8.130212765957447e-06,
      "loss": 0.1436,
      "step": 3505
    },
    {
      "epoch": 0.8056066176470589,
      "grad_norm": 1.110548496246338,
      "learning_rate": 8.12936170212766e-06,
      "loss": 0.1069,
      "step": 3506
    },
    {
      "epoch": 0.8058363970588235,
      "grad_norm": 1.0397251844406128,
      "learning_rate": 8.128510638297874e-06,
      "loss": 0.1009,
      "step": 3507
    },
    {
      "epoch": 0.8060661764705882,
      "grad_norm": 1.0780616998672485,
      "learning_rate": 8.127659574468085e-06,
      "loss": 0.1239,
      "step": 3508
    },
    {
      "epoch": 0.8062959558823529,
      "grad_norm": 1.2100169658660889,
      "learning_rate": 8.126808510638298e-06,
      "loss": 0.1031,
      "step": 3509
    },
    {
      "epoch": 0.8065257352941176,
      "grad_norm": 1.501543641090393,
      "learning_rate": 8.125957446808511e-06,
      "loss": 0.1494,
      "step": 3510
    },
    {
      "epoch": 0.8067555147058824,
      "grad_norm": 1.5312291383743286,
      "learning_rate": 8.125106382978723e-06,
      "loss": 0.0998,
      "step": 3511
    },
    {
      "epoch": 0.8069852941176471,
      "grad_norm": 1.5729849338531494,
      "learning_rate": 8.124255319148938e-06,
      "loss": 0.1234,
      "step": 3512
    },
    {
      "epoch": 0.8072150735294118,
      "grad_norm": 1.2571170330047607,
      "learning_rate": 8.12340425531915e-06,
      "loss": 0.1082,
      "step": 3513
    },
    {
      "epoch": 0.8074448529411765,
      "grad_norm": 1.0717895030975342,
      "learning_rate": 8.122553191489362e-06,
      "loss": 0.0845,
      "step": 3514
    },
    {
      "epoch": 0.8076746323529411,
      "grad_norm": 1.2319997549057007,
      "learning_rate": 8.121702127659576e-06,
      "loss": 0.108,
      "step": 3515
    },
    {
      "epoch": 0.8079044117647058,
      "grad_norm": 1.4946622848510742,
      "learning_rate": 8.120851063829787e-06,
      "loss": 0.1069,
      "step": 3516
    },
    {
      "epoch": 0.8081341911764706,
      "grad_norm": 1.108870267868042,
      "learning_rate": 8.120000000000002e-06,
      "loss": 0.1169,
      "step": 3517
    },
    {
      "epoch": 0.8083639705882353,
      "grad_norm": 0.9786369800567627,
      "learning_rate": 8.119148936170213e-06,
      "loss": 0.0726,
      "step": 3518
    },
    {
      "epoch": 0.80859375,
      "grad_norm": 1.3412548303604126,
      "learning_rate": 8.118297872340427e-06,
      "loss": 0.0909,
      "step": 3519
    },
    {
      "epoch": 0.8088235294117647,
      "grad_norm": 1.3659205436706543,
      "learning_rate": 8.11744680851064e-06,
      "loss": 0.1276,
      "step": 3520
    },
    {
      "epoch": 0.8090533088235294,
      "grad_norm": 0.9376969337463379,
      "learning_rate": 8.116595744680851e-06,
      "loss": 0.1015,
      "step": 3521
    },
    {
      "epoch": 0.8092830882352942,
      "grad_norm": 1.7419583797454834,
      "learning_rate": 8.115744680851064e-06,
      "loss": 0.1113,
      "step": 3522
    },
    {
      "epoch": 0.8095128676470589,
      "grad_norm": 1.2830387353897095,
      "learning_rate": 8.114893617021278e-06,
      "loss": 0.0902,
      "step": 3523
    },
    {
      "epoch": 0.8097426470588235,
      "grad_norm": 1.3763495683670044,
      "learning_rate": 8.11404255319149e-06,
      "loss": 0.1335,
      "step": 3524
    },
    {
      "epoch": 0.8099724264705882,
      "grad_norm": 1.2640396356582642,
      "learning_rate": 8.113191489361702e-06,
      "loss": 0.0711,
      "step": 3525
    },
    {
      "epoch": 0.8102022058823529,
      "grad_norm": 1.3611010313034058,
      "learning_rate": 8.112340425531915e-06,
      "loss": 0.1243,
      "step": 3526
    },
    {
      "epoch": 0.8104319852941176,
      "grad_norm": 1.7507954835891724,
      "learning_rate": 8.111489361702129e-06,
      "loss": 0.1214,
      "step": 3527
    },
    {
      "epoch": 0.8106617647058824,
      "grad_norm": 1.0816658735275269,
      "learning_rate": 8.11063829787234e-06,
      "loss": 0.0999,
      "step": 3528
    },
    {
      "epoch": 0.8108915441176471,
      "grad_norm": 1.4414266347885132,
      "learning_rate": 8.109787234042555e-06,
      "loss": 0.1189,
      "step": 3529
    },
    {
      "epoch": 0.8111213235294118,
      "grad_norm": 1.3549169301986694,
      "learning_rate": 8.108936170212766e-06,
      "loss": 0.0983,
      "step": 3530
    },
    {
      "epoch": 0.8113511029411765,
      "grad_norm": 1.164432168006897,
      "learning_rate": 8.10808510638298e-06,
      "loss": 0.1216,
      "step": 3531
    },
    {
      "epoch": 0.8115808823529411,
      "grad_norm": 0.8817614316940308,
      "learning_rate": 8.107234042553193e-06,
      "loss": 0.1031,
      "step": 3532
    },
    {
      "epoch": 0.8118106617647058,
      "grad_norm": 1.1574373245239258,
      "learning_rate": 8.106382978723404e-06,
      "loss": 0.1083,
      "step": 3533
    },
    {
      "epoch": 0.8120404411764706,
      "grad_norm": 1.068877935409546,
      "learning_rate": 8.105531914893617e-06,
      "loss": 0.0637,
      "step": 3534
    },
    {
      "epoch": 0.8122702205882353,
      "grad_norm": 1.1800838708877563,
      "learning_rate": 8.10468085106383e-06,
      "loss": 0.0978,
      "step": 3535
    },
    {
      "epoch": 0.8125,
      "grad_norm": 1.0639115571975708,
      "learning_rate": 8.103829787234044e-06,
      "loss": 0.0997,
      "step": 3536
    },
    {
      "epoch": 0.8127297794117647,
      "grad_norm": 1.5453335046768188,
      "learning_rate": 8.102978723404255e-06,
      "loss": 0.151,
      "step": 3537
    },
    {
      "epoch": 0.8129595588235294,
      "grad_norm": 0.9598021507263184,
      "learning_rate": 8.102127659574468e-06,
      "loss": 0.074,
      "step": 3538
    },
    {
      "epoch": 0.8131893382352942,
      "grad_norm": 1.3010661602020264,
      "learning_rate": 8.101276595744681e-06,
      "loss": 0.0971,
      "step": 3539
    },
    {
      "epoch": 0.8134191176470589,
      "grad_norm": 1.0147287845611572,
      "learning_rate": 8.100425531914895e-06,
      "loss": 0.0973,
      "step": 3540
    },
    {
      "epoch": 0.8136488970588235,
      "grad_norm": 1.7722728252410889,
      "learning_rate": 8.099574468085108e-06,
      "loss": 0.1309,
      "step": 3541
    },
    {
      "epoch": 0.8138786764705882,
      "grad_norm": 0.8935593962669373,
      "learning_rate": 8.09872340425532e-06,
      "loss": 0.0726,
      "step": 3542
    },
    {
      "epoch": 0.8141084558823529,
      "grad_norm": 0.9879353046417236,
      "learning_rate": 8.097872340425532e-06,
      "loss": 0.0598,
      "step": 3543
    },
    {
      "epoch": 0.8143382352941176,
      "grad_norm": 0.9648256897926331,
      "learning_rate": 8.097021276595746e-06,
      "loss": 0.0987,
      "step": 3544
    },
    {
      "epoch": 0.8145680147058824,
      "grad_norm": 1.316750168800354,
      "learning_rate": 8.096170212765959e-06,
      "loss": 0.0874,
      "step": 3545
    },
    {
      "epoch": 0.8147977941176471,
      "grad_norm": 1.5047461986541748,
      "learning_rate": 8.09531914893617e-06,
      "loss": 0.1178,
      "step": 3546
    },
    {
      "epoch": 0.8150275735294118,
      "grad_norm": 1.4369478225708008,
      "learning_rate": 8.094468085106383e-06,
      "loss": 0.0966,
      "step": 3547
    },
    {
      "epoch": 0.8152573529411765,
      "grad_norm": 1.7515523433685303,
      "learning_rate": 8.093617021276597e-06,
      "loss": 0.1322,
      "step": 3548
    },
    {
      "epoch": 0.8154871323529411,
      "grad_norm": 1.2516738176345825,
      "learning_rate": 8.092765957446808e-06,
      "loss": 0.1148,
      "step": 3549
    },
    {
      "epoch": 0.8157169117647058,
      "grad_norm": 1.239219307899475,
      "learning_rate": 8.091914893617023e-06,
      "loss": 0.1353,
      "step": 3550
    },
    {
      "epoch": 0.8159466911764706,
      "grad_norm": 1.2133253812789917,
      "learning_rate": 8.091063829787234e-06,
      "loss": 0.1075,
      "step": 3551
    },
    {
      "epoch": 0.8161764705882353,
      "grad_norm": 1.1904529333114624,
      "learning_rate": 8.090212765957448e-06,
      "loss": 0.0913,
      "step": 3552
    },
    {
      "epoch": 0.81640625,
      "grad_norm": 1.4911836385726929,
      "learning_rate": 8.08936170212766e-06,
      "loss": 0.123,
      "step": 3553
    },
    {
      "epoch": 0.8166360294117647,
      "grad_norm": 1.7461034059524536,
      "learning_rate": 8.088510638297872e-06,
      "loss": 0.177,
      "step": 3554
    },
    {
      "epoch": 0.8168658088235294,
      "grad_norm": 0.9637414813041687,
      "learning_rate": 8.087659574468085e-06,
      "loss": 0.104,
      "step": 3555
    },
    {
      "epoch": 0.8170955882352942,
      "grad_norm": 1.0806881189346313,
      "learning_rate": 8.086808510638299e-06,
      "loss": 0.0914,
      "step": 3556
    },
    {
      "epoch": 0.8173253676470589,
      "grad_norm": 1.3492684364318848,
      "learning_rate": 8.085957446808512e-06,
      "loss": 0.1088,
      "step": 3557
    },
    {
      "epoch": 0.8175551470588235,
      "grad_norm": 1.5964508056640625,
      "learning_rate": 8.085106382978723e-06,
      "loss": 0.1195,
      "step": 3558
    },
    {
      "epoch": 0.8177849264705882,
      "grad_norm": 1.3940613269805908,
      "learning_rate": 8.084255319148936e-06,
      "loss": 0.1646,
      "step": 3559
    },
    {
      "epoch": 0.8180147058823529,
      "grad_norm": 1.0650078058242798,
      "learning_rate": 8.08340425531915e-06,
      "loss": 0.1185,
      "step": 3560
    },
    {
      "epoch": 0.8182444852941176,
      "grad_norm": 1.409950613975525,
      "learning_rate": 8.082553191489363e-06,
      "loss": 0.1707,
      "step": 3561
    },
    {
      "epoch": 0.8184742647058824,
      "grad_norm": 1.3107489347457886,
      "learning_rate": 8.081702127659576e-06,
      "loss": 0.0875,
      "step": 3562
    },
    {
      "epoch": 0.8187040441176471,
      "grad_norm": 1.0282647609710693,
      "learning_rate": 8.080851063829787e-06,
      "loss": 0.0957,
      "step": 3563
    },
    {
      "epoch": 0.8189338235294118,
      "grad_norm": 1.5217481851577759,
      "learning_rate": 8.08e-06,
      "loss": 0.1133,
      "step": 3564
    },
    {
      "epoch": 0.8191636029411765,
      "grad_norm": 1.5162357091903687,
      "learning_rate": 8.079148936170214e-06,
      "loss": 0.1282,
      "step": 3565
    },
    {
      "epoch": 0.8193933823529411,
      "grad_norm": 1.0631643533706665,
      "learning_rate": 8.078297872340425e-06,
      "loss": 0.0952,
      "step": 3566
    },
    {
      "epoch": 0.8196231617647058,
      "grad_norm": 1.1096545457839966,
      "learning_rate": 8.07744680851064e-06,
      "loss": 0.1231,
      "step": 3567
    },
    {
      "epoch": 0.8198529411764706,
      "grad_norm": 1.1541677713394165,
      "learning_rate": 8.076595744680852e-06,
      "loss": 0.109,
      "step": 3568
    },
    {
      "epoch": 0.8200827205882353,
      "grad_norm": 1.297759771347046,
      "learning_rate": 8.075744680851065e-06,
      "loss": 0.1135,
      "step": 3569
    },
    {
      "epoch": 0.8203125,
      "grad_norm": 1.6205044984817505,
      "learning_rate": 8.074893617021278e-06,
      "loss": 0.1404,
      "step": 3570
    },
    {
      "epoch": 0.8205422794117647,
      "grad_norm": 1.4734715223312378,
      "learning_rate": 8.07404255319149e-06,
      "loss": 0.1197,
      "step": 3571
    },
    {
      "epoch": 0.8207720588235294,
      "grad_norm": 1.122746467590332,
      "learning_rate": 8.073191489361703e-06,
      "loss": 0.1335,
      "step": 3572
    },
    {
      "epoch": 0.8210018382352942,
      "grad_norm": 1.5789810419082642,
      "learning_rate": 8.072340425531916e-06,
      "loss": 0.1306,
      "step": 3573
    },
    {
      "epoch": 0.8212316176470589,
      "grad_norm": 0.9261839985847473,
      "learning_rate": 8.071489361702129e-06,
      "loss": 0.0951,
      "step": 3574
    },
    {
      "epoch": 0.8214613970588235,
      "grad_norm": 0.9247492551803589,
      "learning_rate": 8.07063829787234e-06,
      "loss": 0.1093,
      "step": 3575
    },
    {
      "epoch": 0.8216911764705882,
      "grad_norm": 1.1382923126220703,
      "learning_rate": 8.069787234042554e-06,
      "loss": 0.0876,
      "step": 3576
    },
    {
      "epoch": 0.8219209558823529,
      "grad_norm": 1.091821312904358,
      "learning_rate": 8.068936170212767e-06,
      "loss": 0.0744,
      "step": 3577
    },
    {
      "epoch": 0.8221507352941176,
      "grad_norm": 1.0731223821640015,
      "learning_rate": 8.06808510638298e-06,
      "loss": 0.1014,
      "step": 3578
    },
    {
      "epoch": 0.8223805147058824,
      "grad_norm": 1.943335771560669,
      "learning_rate": 8.067234042553193e-06,
      "loss": 0.1335,
      "step": 3579
    },
    {
      "epoch": 0.8226102941176471,
      "grad_norm": 1.8335235118865967,
      "learning_rate": 8.066382978723405e-06,
      "loss": 0.1305,
      "step": 3580
    },
    {
      "epoch": 0.8228400735294118,
      "grad_norm": 1.344964861869812,
      "learning_rate": 8.065531914893618e-06,
      "loss": 0.1071,
      "step": 3581
    },
    {
      "epoch": 0.8230698529411765,
      "grad_norm": 1.312599539756775,
      "learning_rate": 8.064680851063831e-06,
      "loss": 0.0992,
      "step": 3582
    },
    {
      "epoch": 0.8232996323529411,
      "grad_norm": 1.4349701404571533,
      "learning_rate": 8.063829787234044e-06,
      "loss": 0.1027,
      "step": 3583
    },
    {
      "epoch": 0.8235294117647058,
      "grad_norm": 1.1029465198516846,
      "learning_rate": 8.062978723404256e-06,
      "loss": 0.1025,
      "step": 3584
    },
    {
      "epoch": 0.8237591911764706,
      "grad_norm": 1.352593183517456,
      "learning_rate": 8.062127659574469e-06,
      "loss": 0.0963,
      "step": 3585
    },
    {
      "epoch": 0.8239889705882353,
      "grad_norm": 1.1078685522079468,
      "learning_rate": 8.061276595744682e-06,
      "loss": 0.1058,
      "step": 3586
    },
    {
      "epoch": 0.82421875,
      "grad_norm": 1.577062964439392,
      "learning_rate": 8.060425531914893e-06,
      "loss": 0.1696,
      "step": 3587
    },
    {
      "epoch": 0.8244485294117647,
      "grad_norm": 1.8479992151260376,
      "learning_rate": 8.059574468085108e-06,
      "loss": 0.0937,
      "step": 3588
    },
    {
      "epoch": 0.8246783088235294,
      "grad_norm": 2.418161630630493,
      "learning_rate": 8.05872340425532e-06,
      "loss": 0.1164,
      "step": 3589
    },
    {
      "epoch": 0.8249080882352942,
      "grad_norm": 1.1625354290008545,
      "learning_rate": 8.057872340425533e-06,
      "loss": 0.0801,
      "step": 3590
    },
    {
      "epoch": 0.8251378676470589,
      "grad_norm": 1.3427841663360596,
      "learning_rate": 8.057021276595746e-06,
      "loss": 0.1112,
      "step": 3591
    },
    {
      "epoch": 0.8253676470588235,
      "grad_norm": 1.7669954299926758,
      "learning_rate": 8.056170212765957e-06,
      "loss": 0.1269,
      "step": 3592
    },
    {
      "epoch": 0.8255974264705882,
      "grad_norm": 1.3075686693191528,
      "learning_rate": 8.05531914893617e-06,
      "loss": 0.1016,
      "step": 3593
    },
    {
      "epoch": 0.8258272058823529,
      "grad_norm": 1.0708950757980347,
      "learning_rate": 8.054468085106384e-06,
      "loss": 0.0925,
      "step": 3594
    },
    {
      "epoch": 0.8260569852941176,
      "grad_norm": 1.5224882364273071,
      "learning_rate": 8.053617021276597e-06,
      "loss": 0.1188,
      "step": 3595
    },
    {
      "epoch": 0.8262867647058824,
      "grad_norm": 1.150259017944336,
      "learning_rate": 8.052765957446808e-06,
      "loss": 0.0954,
      "step": 3596
    },
    {
      "epoch": 0.8265165441176471,
      "grad_norm": 1.1898247003555298,
      "learning_rate": 8.051914893617022e-06,
      "loss": 0.1125,
      "step": 3597
    },
    {
      "epoch": 0.8267463235294118,
      "grad_norm": 1.1553161144256592,
      "learning_rate": 8.051063829787235e-06,
      "loss": 0.1078,
      "step": 3598
    },
    {
      "epoch": 0.8269761029411765,
      "grad_norm": 1.4859648942947388,
      "learning_rate": 8.050212765957446e-06,
      "loss": 0.0991,
      "step": 3599
    },
    {
      "epoch": 0.8272058823529411,
      "grad_norm": 1.2145813703536987,
      "learning_rate": 8.049361702127661e-06,
      "loss": 0.1189,
      "step": 3600
    },
    {
      "epoch": 0.8274356617647058,
      "grad_norm": 1.5039222240447998,
      "learning_rate": 8.048510638297873e-06,
      "loss": 0.1172,
      "step": 3601
    },
    {
      "epoch": 0.8276654411764706,
      "grad_norm": 1.1829651594161987,
      "learning_rate": 8.047659574468086e-06,
      "loss": 0.086,
      "step": 3602
    },
    {
      "epoch": 0.8278952205882353,
      "grad_norm": 1.5800442695617676,
      "learning_rate": 8.046808510638299e-06,
      "loss": 0.1745,
      "step": 3603
    },
    {
      "epoch": 0.828125,
      "grad_norm": 1.211788296699524,
      "learning_rate": 8.04595744680851e-06,
      "loss": 0.0577,
      "step": 3604
    },
    {
      "epoch": 0.8283547794117647,
      "grad_norm": 1.2924563884735107,
      "learning_rate": 8.045106382978725e-06,
      "loss": 0.0988,
      "step": 3605
    },
    {
      "epoch": 0.8285845588235294,
      "grad_norm": 1.133506178855896,
      "learning_rate": 8.044255319148937e-06,
      "loss": 0.0979,
      "step": 3606
    },
    {
      "epoch": 0.8288143382352942,
      "grad_norm": 1.8803883790969849,
      "learning_rate": 8.04340425531915e-06,
      "loss": 0.0752,
      "step": 3607
    },
    {
      "epoch": 0.8290441176470589,
      "grad_norm": 1.5250310897827148,
      "learning_rate": 8.042553191489363e-06,
      "loss": 0.0675,
      "step": 3608
    },
    {
      "epoch": 0.8292738970588235,
      "grad_norm": 1.8260481357574463,
      "learning_rate": 8.041702127659575e-06,
      "loss": 0.1293,
      "step": 3609
    },
    {
      "epoch": 0.8295036764705882,
      "grad_norm": 0.9612805843353271,
      "learning_rate": 8.040851063829788e-06,
      "loss": 0.0972,
      "step": 3610
    },
    {
      "epoch": 0.8297334558823529,
      "grad_norm": 1.0622451305389404,
      "learning_rate": 8.040000000000001e-06,
      "loss": 0.1028,
      "step": 3611
    },
    {
      "epoch": 0.8299632352941176,
      "grad_norm": 1.3704553842544556,
      "learning_rate": 8.039148936170214e-06,
      "loss": 0.1183,
      "step": 3612
    },
    {
      "epoch": 0.8301930147058824,
      "grad_norm": 1.5422930717468262,
      "learning_rate": 8.038297872340426e-06,
      "loss": 0.1013,
      "step": 3613
    },
    {
      "epoch": 0.8304227941176471,
      "grad_norm": 1.3703944683074951,
      "learning_rate": 8.037446808510639e-06,
      "loss": 0.1292,
      "step": 3614
    },
    {
      "epoch": 0.8306525735294118,
      "grad_norm": 1.1730400323867798,
      "learning_rate": 8.036595744680852e-06,
      "loss": 0.1164,
      "step": 3615
    },
    {
      "epoch": 0.8308823529411765,
      "grad_norm": 1.4474563598632812,
      "learning_rate": 8.035744680851063e-06,
      "loss": 0.0938,
      "step": 3616
    },
    {
      "epoch": 0.8311121323529411,
      "grad_norm": 1.5485422611236572,
      "learning_rate": 8.034893617021278e-06,
      "loss": 0.1438,
      "step": 3617
    },
    {
      "epoch": 0.8313419117647058,
      "grad_norm": 1.2539966106414795,
      "learning_rate": 8.03404255319149e-06,
      "loss": 0.1139,
      "step": 3618
    },
    {
      "epoch": 0.8315716911764706,
      "grad_norm": 1.226142168045044,
      "learning_rate": 8.033191489361703e-06,
      "loss": 0.1307,
      "step": 3619
    },
    {
      "epoch": 0.8318014705882353,
      "grad_norm": 0.9028171300888062,
      "learning_rate": 8.032340425531916e-06,
      "loss": 0.0813,
      "step": 3620
    },
    {
      "epoch": 0.83203125,
      "grad_norm": 1.1861162185668945,
      "learning_rate": 8.031489361702128e-06,
      "loss": 0.1333,
      "step": 3621
    },
    {
      "epoch": 0.8322610294117647,
      "grad_norm": 1.2846574783325195,
      "learning_rate": 8.03063829787234e-06,
      "loss": 0.1308,
      "step": 3622
    },
    {
      "epoch": 0.8324908088235294,
      "grad_norm": 2.075287103652954,
      "learning_rate": 8.029787234042554e-06,
      "loss": 0.1233,
      "step": 3623
    },
    {
      "epoch": 0.8327205882352942,
      "grad_norm": 1.084009051322937,
      "learning_rate": 8.028936170212767e-06,
      "loss": 0.13,
      "step": 3624
    },
    {
      "epoch": 0.8329503676470589,
      "grad_norm": 1.6188428401947021,
      "learning_rate": 8.028085106382979e-06,
      "loss": 0.0961,
      "step": 3625
    },
    {
      "epoch": 0.8331801470588235,
      "grad_norm": 2.0046515464782715,
      "learning_rate": 8.027234042553192e-06,
      "loss": 0.1436,
      "step": 3626
    },
    {
      "epoch": 0.8334099264705882,
      "grad_norm": 0.8973195552825928,
      "learning_rate": 8.026382978723405e-06,
      "loss": 0.0783,
      "step": 3627
    },
    {
      "epoch": 0.8336397058823529,
      "grad_norm": 0.9990322589874268,
      "learning_rate": 8.025531914893618e-06,
      "loss": 0.1035,
      "step": 3628
    },
    {
      "epoch": 0.8338694852941176,
      "grad_norm": 1.27278733253479,
      "learning_rate": 8.024680851063831e-06,
      "loss": 0.1253,
      "step": 3629
    },
    {
      "epoch": 0.8340992647058824,
      "grad_norm": 1.6454215049743652,
      "learning_rate": 8.023829787234043e-06,
      "loss": 0.1245,
      "step": 3630
    },
    {
      "epoch": 0.8343290441176471,
      "grad_norm": 1.0259068012237549,
      "learning_rate": 8.022978723404256e-06,
      "loss": 0.1044,
      "step": 3631
    },
    {
      "epoch": 0.8345588235294118,
      "grad_norm": 0.9845973253250122,
      "learning_rate": 8.022127659574469e-06,
      "loss": 0.1039,
      "step": 3632
    },
    {
      "epoch": 0.8347886029411765,
      "grad_norm": 1.8228223323822021,
      "learning_rate": 8.021276595744682e-06,
      "loss": 0.1302,
      "step": 3633
    },
    {
      "epoch": 0.8350183823529411,
      "grad_norm": 1.1126630306243896,
      "learning_rate": 8.020425531914894e-06,
      "loss": 0.1083,
      "step": 3634
    },
    {
      "epoch": 0.8352481617647058,
      "grad_norm": 1.2614151239395142,
      "learning_rate": 8.019574468085107e-06,
      "loss": 0.0938,
      "step": 3635
    },
    {
      "epoch": 0.8354779411764706,
      "grad_norm": 1.2883856296539307,
      "learning_rate": 8.01872340425532e-06,
      "loss": 0.1112,
      "step": 3636
    },
    {
      "epoch": 0.8357077205882353,
      "grad_norm": 1.841105580329895,
      "learning_rate": 8.017872340425532e-06,
      "loss": 0.1196,
      "step": 3637
    },
    {
      "epoch": 0.8359375,
      "grad_norm": 1.2316808700561523,
      "learning_rate": 8.017021276595746e-06,
      "loss": 0.0939,
      "step": 3638
    },
    {
      "epoch": 0.8361672794117647,
      "grad_norm": 1.6462870836257935,
      "learning_rate": 8.016170212765958e-06,
      "loss": 0.1331,
      "step": 3639
    },
    {
      "epoch": 0.8363970588235294,
      "grad_norm": 1.1130620241165161,
      "learning_rate": 8.015319148936171e-06,
      "loss": 0.1364,
      "step": 3640
    },
    {
      "epoch": 0.8366268382352942,
      "grad_norm": 2.0667548179626465,
      "learning_rate": 8.014468085106384e-06,
      "loss": 0.139,
      "step": 3641
    },
    {
      "epoch": 0.8368566176470589,
      "grad_norm": 1.0546883344650269,
      "learning_rate": 8.013617021276596e-06,
      "loss": 0.0936,
      "step": 3642
    },
    {
      "epoch": 0.8370863970588235,
      "grad_norm": 1.7710689306259155,
      "learning_rate": 8.012765957446809e-06,
      "loss": 0.1254,
      "step": 3643
    },
    {
      "epoch": 0.8373161764705882,
      "grad_norm": 1.5893474817276,
      "learning_rate": 8.011914893617022e-06,
      "loss": 0.1363,
      "step": 3644
    },
    {
      "epoch": 0.8375459558823529,
      "grad_norm": 1.0790445804595947,
      "learning_rate": 8.011063829787235e-06,
      "loss": 0.0956,
      "step": 3645
    },
    {
      "epoch": 0.8377757352941176,
      "grad_norm": 1.2701761722564697,
      "learning_rate": 8.010212765957448e-06,
      "loss": 0.1075,
      "step": 3646
    },
    {
      "epoch": 0.8380055147058824,
      "grad_norm": 1.4349068403244019,
      "learning_rate": 8.00936170212766e-06,
      "loss": 0.1038,
      "step": 3647
    },
    {
      "epoch": 0.8382352941176471,
      "grad_norm": 1.9389506578445435,
      "learning_rate": 8.008510638297873e-06,
      "loss": 0.1042,
      "step": 3648
    },
    {
      "epoch": 0.8384650735294118,
      "grad_norm": 1.5456093549728394,
      "learning_rate": 8.007659574468086e-06,
      "loss": 0.1069,
      "step": 3649
    },
    {
      "epoch": 0.8386948529411765,
      "grad_norm": 1.2958524227142334,
      "learning_rate": 8.0068085106383e-06,
      "loss": 0.1314,
      "step": 3650
    },
    {
      "epoch": 0.8389246323529411,
      "grad_norm": 1.4482872486114502,
      "learning_rate": 8.00595744680851e-06,
      "loss": 0.1047,
      "step": 3651
    },
    {
      "epoch": 0.8391544117647058,
      "grad_norm": 1.3537418842315674,
      "learning_rate": 8.005106382978724e-06,
      "loss": 0.1593,
      "step": 3652
    },
    {
      "epoch": 0.8393841911764706,
      "grad_norm": 1.3720511198043823,
      "learning_rate": 8.004255319148937e-06,
      "loss": 0.11,
      "step": 3653
    },
    {
      "epoch": 0.8396139705882353,
      "grad_norm": 1.2476632595062256,
      "learning_rate": 8.003404255319149e-06,
      "loss": 0.0756,
      "step": 3654
    },
    {
      "epoch": 0.83984375,
      "grad_norm": 1.0413707494735718,
      "learning_rate": 8.002553191489364e-06,
      "loss": 0.0733,
      "step": 3655
    },
    {
      "epoch": 0.8400735294117647,
      "grad_norm": 1.089802622795105,
      "learning_rate": 8.001702127659575e-06,
      "loss": 0.1019,
      "step": 3656
    },
    {
      "epoch": 0.8403033088235294,
      "grad_norm": 1.3905800580978394,
      "learning_rate": 8.000851063829788e-06,
      "loss": 0.1054,
      "step": 3657
    },
    {
      "epoch": 0.8405330882352942,
      "grad_norm": 1.0967117547988892,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.1094,
      "step": 3658
    },
    {
      "epoch": 0.8407628676470589,
      "grad_norm": 0.8947856426239014,
      "learning_rate": 7.999148936170213e-06,
      "loss": 0.0943,
      "step": 3659
    },
    {
      "epoch": 0.8409926470588235,
      "grad_norm": 1.3801004886627197,
      "learning_rate": 7.998297872340426e-06,
      "loss": 0.1,
      "step": 3660
    },
    {
      "epoch": 0.8412224264705882,
      "grad_norm": 0.8940181136131287,
      "learning_rate": 7.997446808510639e-06,
      "loss": 0.0689,
      "step": 3661
    },
    {
      "epoch": 0.8414522058823529,
      "grad_norm": 1.2140789031982422,
      "learning_rate": 7.996595744680852e-06,
      "loss": 0.1185,
      "step": 3662
    },
    {
      "epoch": 0.8416819852941176,
      "grad_norm": 1.6750801801681519,
      "learning_rate": 7.995744680851064e-06,
      "loss": 0.1,
      "step": 3663
    },
    {
      "epoch": 0.8419117647058824,
      "grad_norm": 1.1457136869430542,
      "learning_rate": 7.994893617021277e-06,
      "loss": 0.0921,
      "step": 3664
    },
    {
      "epoch": 0.8421415441176471,
      "grad_norm": 1.8929054737091064,
      "learning_rate": 7.99404255319149e-06,
      "loss": 0.0949,
      "step": 3665
    },
    {
      "epoch": 0.8423713235294118,
      "grad_norm": 0.94414883852005,
      "learning_rate": 7.993191489361702e-06,
      "loss": 0.0802,
      "step": 3666
    },
    {
      "epoch": 0.8426011029411765,
      "grad_norm": 1.193027138710022,
      "learning_rate": 7.992340425531916e-06,
      "loss": 0.0917,
      "step": 3667
    },
    {
      "epoch": 0.8428308823529411,
      "grad_norm": 1.0519227981567383,
      "learning_rate": 7.991489361702128e-06,
      "loss": 0.1328,
      "step": 3668
    },
    {
      "epoch": 0.8430606617647058,
      "grad_norm": 1.0219671726226807,
      "learning_rate": 7.990638297872341e-06,
      "loss": 0.0921,
      "step": 3669
    },
    {
      "epoch": 0.8432904411764706,
      "grad_norm": 1.373088002204895,
      "learning_rate": 7.989787234042554e-06,
      "loss": 0.0727,
      "step": 3670
    },
    {
      "epoch": 0.8435202205882353,
      "grad_norm": 1.1415029764175415,
      "learning_rate": 7.988936170212766e-06,
      "loss": 0.1243,
      "step": 3671
    },
    {
      "epoch": 0.84375,
      "grad_norm": 1.5711711645126343,
      "learning_rate": 7.988085106382979e-06,
      "loss": 0.163,
      "step": 3672
    },
    {
      "epoch": 0.8439797794117647,
      "grad_norm": 1.0480246543884277,
      "learning_rate": 7.987234042553192e-06,
      "loss": 0.088,
      "step": 3673
    },
    {
      "epoch": 0.8442095588235294,
      "grad_norm": 1.6703627109527588,
      "learning_rate": 7.986382978723405e-06,
      "loss": 0.1304,
      "step": 3674
    },
    {
      "epoch": 0.8444393382352942,
      "grad_norm": 1.3043129444122314,
      "learning_rate": 7.985531914893617e-06,
      "loss": 0.0907,
      "step": 3675
    },
    {
      "epoch": 0.8446691176470589,
      "grad_norm": 1.412795066833496,
      "learning_rate": 7.98468085106383e-06,
      "loss": 0.1516,
      "step": 3676
    },
    {
      "epoch": 0.8448988970588235,
      "grad_norm": 1.286553978919983,
      "learning_rate": 7.983829787234043e-06,
      "loss": 0.1314,
      "step": 3677
    },
    {
      "epoch": 0.8451286764705882,
      "grad_norm": 1.7129316329956055,
      "learning_rate": 7.982978723404256e-06,
      "loss": 0.1491,
      "step": 3678
    },
    {
      "epoch": 0.8453584558823529,
      "grad_norm": 0.9304341077804565,
      "learning_rate": 7.98212765957447e-06,
      "loss": 0.1169,
      "step": 3679
    },
    {
      "epoch": 0.8455882352941176,
      "grad_norm": 0.8861200213432312,
      "learning_rate": 7.981276595744681e-06,
      "loss": 0.0677,
      "step": 3680
    },
    {
      "epoch": 0.8458180147058824,
      "grad_norm": 1.4110451936721802,
      "learning_rate": 7.980425531914894e-06,
      "loss": 0.1099,
      "step": 3681
    },
    {
      "epoch": 0.8460477941176471,
      "grad_norm": 1.406727910041809,
      "learning_rate": 7.979574468085107e-06,
      "loss": 0.0982,
      "step": 3682
    },
    {
      "epoch": 0.8462775735294118,
      "grad_norm": 1.2252228260040283,
      "learning_rate": 7.97872340425532e-06,
      "loss": 0.0876,
      "step": 3683
    },
    {
      "epoch": 0.8465073529411765,
      "grad_norm": 1.0040048360824585,
      "learning_rate": 7.977872340425532e-06,
      "loss": 0.086,
      "step": 3684
    },
    {
      "epoch": 0.8467371323529411,
      "grad_norm": 1.383265495300293,
      "learning_rate": 7.977021276595745e-06,
      "loss": 0.1205,
      "step": 3685
    },
    {
      "epoch": 0.8469669117647058,
      "grad_norm": 1.8708875179290771,
      "learning_rate": 7.976170212765958e-06,
      "loss": 0.1302,
      "step": 3686
    },
    {
      "epoch": 0.8471966911764706,
      "grad_norm": 1.439177393913269,
      "learning_rate": 7.97531914893617e-06,
      "loss": 0.0829,
      "step": 3687
    },
    {
      "epoch": 0.8474264705882353,
      "grad_norm": 1.7260940074920654,
      "learning_rate": 7.974468085106385e-06,
      "loss": 0.1322,
      "step": 3688
    },
    {
      "epoch": 0.84765625,
      "grad_norm": 1.843227744102478,
      "learning_rate": 7.973617021276596e-06,
      "loss": 0.1198,
      "step": 3689
    },
    {
      "epoch": 0.8478860294117647,
      "grad_norm": 2.1476850509643555,
      "learning_rate": 7.97276595744681e-06,
      "loss": 0.1167,
      "step": 3690
    },
    {
      "epoch": 0.8481158088235294,
      "grad_norm": 2.148111581802368,
      "learning_rate": 7.971914893617022e-06,
      "loss": 0.1021,
      "step": 3691
    },
    {
      "epoch": 0.8483455882352942,
      "grad_norm": 1.7148208618164062,
      "learning_rate": 7.971063829787234e-06,
      "loss": 0.1544,
      "step": 3692
    },
    {
      "epoch": 0.8485753676470589,
      "grad_norm": 1.8103432655334473,
      "learning_rate": 7.970212765957449e-06,
      "loss": 0.101,
      "step": 3693
    },
    {
      "epoch": 0.8488051470588235,
      "grad_norm": 1.7335290908813477,
      "learning_rate": 7.96936170212766e-06,
      "loss": 0.1088,
      "step": 3694
    },
    {
      "epoch": 0.8490349264705882,
      "grad_norm": 2.232574224472046,
      "learning_rate": 7.968510638297873e-06,
      "loss": 0.1327,
      "step": 3695
    },
    {
      "epoch": 0.8492647058823529,
      "grad_norm": 1.468230128288269,
      "learning_rate": 7.967659574468087e-06,
      "loss": 0.0901,
      "step": 3696
    },
    {
      "epoch": 0.8494944852941176,
      "grad_norm": 1.8214607238769531,
      "learning_rate": 7.966808510638298e-06,
      "loss": 0.1074,
      "step": 3697
    },
    {
      "epoch": 0.8497242647058824,
      "grad_norm": 1.4821369647979736,
      "learning_rate": 7.965957446808511e-06,
      "loss": 0.1184,
      "step": 3698
    },
    {
      "epoch": 0.8499540441176471,
      "grad_norm": 1.4074501991271973,
      "learning_rate": 7.965106382978724e-06,
      "loss": 0.0963,
      "step": 3699
    },
    {
      "epoch": 0.8501838235294118,
      "grad_norm": 1.5200388431549072,
      "learning_rate": 7.964255319148938e-06,
      "loss": 0.1576,
      "step": 3700
    },
    {
      "epoch": 0.8504136029411765,
      "grad_norm": 1.4317808151245117,
      "learning_rate": 7.963404255319149e-06,
      "loss": 0.107,
      "step": 3701
    },
    {
      "epoch": 0.8506433823529411,
      "grad_norm": 1.2190797328948975,
      "learning_rate": 7.962553191489362e-06,
      "loss": 0.1318,
      "step": 3702
    },
    {
      "epoch": 0.8508731617647058,
      "grad_norm": 1.0621272325515747,
      "learning_rate": 7.961702127659575e-06,
      "loss": 0.0792,
      "step": 3703
    },
    {
      "epoch": 0.8511029411764706,
      "grad_norm": 1.2158128023147583,
      "learning_rate": 7.960851063829787e-06,
      "loss": 0.1161,
      "step": 3704
    },
    {
      "epoch": 0.8513327205882353,
      "grad_norm": 1.3514862060546875,
      "learning_rate": 7.960000000000002e-06,
      "loss": 0.133,
      "step": 3705
    },
    {
      "epoch": 0.8515625,
      "grad_norm": 1.3913367986679077,
      "learning_rate": 7.959148936170213e-06,
      "loss": 0.1094,
      "step": 3706
    },
    {
      "epoch": 0.8517922794117647,
      "grad_norm": 1.2233247756958008,
      "learning_rate": 7.958297872340426e-06,
      "loss": 0.0748,
      "step": 3707
    },
    {
      "epoch": 0.8520220588235294,
      "grad_norm": 1.4701695442199707,
      "learning_rate": 7.95744680851064e-06,
      "loss": 0.1227,
      "step": 3708
    },
    {
      "epoch": 0.8522518382352942,
      "grad_norm": 1.5266690254211426,
      "learning_rate": 7.956595744680851e-06,
      "loss": 0.1048,
      "step": 3709
    },
    {
      "epoch": 0.8524816176470589,
      "grad_norm": 1.365240454673767,
      "learning_rate": 7.955744680851064e-06,
      "loss": 0.1478,
      "step": 3710
    },
    {
      "epoch": 0.8527113970588235,
      "grad_norm": 1.1048543453216553,
      "learning_rate": 7.954893617021277e-06,
      "loss": 0.0909,
      "step": 3711
    },
    {
      "epoch": 0.8529411764705882,
      "grad_norm": 1.1418629884719849,
      "learning_rate": 7.95404255319149e-06,
      "loss": 0.0997,
      "step": 3712
    },
    {
      "epoch": 0.8531709558823529,
      "grad_norm": 1.5103111267089844,
      "learning_rate": 7.953191489361702e-06,
      "loss": 0.1355,
      "step": 3713
    },
    {
      "epoch": 0.8534007352941176,
      "grad_norm": 0.9942075610160828,
      "learning_rate": 7.952340425531915e-06,
      "loss": 0.1145,
      "step": 3714
    },
    {
      "epoch": 0.8536305147058824,
      "grad_norm": 1.2894856929779053,
      "learning_rate": 7.951489361702128e-06,
      "loss": 0.1055,
      "step": 3715
    },
    {
      "epoch": 0.8538602941176471,
      "grad_norm": 1.387861728668213,
      "learning_rate": 7.95063829787234e-06,
      "loss": 0.1098,
      "step": 3716
    },
    {
      "epoch": 0.8540900735294118,
      "grad_norm": 1.2465180158615112,
      "learning_rate": 7.949787234042555e-06,
      "loss": 0.0989,
      "step": 3717
    },
    {
      "epoch": 0.8543198529411765,
      "grad_norm": 1.32610285282135,
      "learning_rate": 7.948936170212766e-06,
      "loss": 0.112,
      "step": 3718
    },
    {
      "epoch": 0.8545496323529411,
      "grad_norm": 1.033056378364563,
      "learning_rate": 7.94808510638298e-06,
      "loss": 0.0723,
      "step": 3719
    },
    {
      "epoch": 0.8547794117647058,
      "grad_norm": 1.1716774702072144,
      "learning_rate": 7.947234042553192e-06,
      "loss": 0.0996,
      "step": 3720
    },
    {
      "epoch": 0.8550091911764706,
      "grad_norm": 1.1781491041183472,
      "learning_rate": 7.946382978723404e-06,
      "loss": 0.1039,
      "step": 3721
    },
    {
      "epoch": 0.8552389705882353,
      "grad_norm": 1.0705373287200928,
      "learning_rate": 7.945531914893617e-06,
      "loss": 0.1061,
      "step": 3722
    },
    {
      "epoch": 0.85546875,
      "grad_norm": 1.2057459354400635,
      "learning_rate": 7.94468085106383e-06,
      "loss": 0.1109,
      "step": 3723
    },
    {
      "epoch": 0.8556985294117647,
      "grad_norm": 2.1034257411956787,
      "learning_rate": 7.943829787234043e-06,
      "loss": 0.1162,
      "step": 3724
    },
    {
      "epoch": 0.8559283088235294,
      "grad_norm": 1.2640126943588257,
      "learning_rate": 7.942978723404255e-06,
      "loss": 0.0873,
      "step": 3725
    },
    {
      "epoch": 0.8561580882352942,
      "grad_norm": 1.2975908517837524,
      "learning_rate": 7.942127659574468e-06,
      "loss": 0.1141,
      "step": 3726
    },
    {
      "epoch": 0.8563878676470589,
      "grad_norm": 1.3943212032318115,
      "learning_rate": 7.941276595744681e-06,
      "loss": 0.1044,
      "step": 3727
    },
    {
      "epoch": 0.8566176470588235,
      "grad_norm": 0.8837966918945312,
      "learning_rate": 7.940425531914894e-06,
      "loss": 0.0728,
      "step": 3728
    },
    {
      "epoch": 0.8568474264705882,
      "grad_norm": 0.8839218616485596,
      "learning_rate": 7.939574468085108e-06,
      "loss": 0.0917,
      "step": 3729
    },
    {
      "epoch": 0.8570772058823529,
      "grad_norm": 1.1297627687454224,
      "learning_rate": 7.938723404255319e-06,
      "loss": 0.1186,
      "step": 3730
    },
    {
      "epoch": 0.8573069852941176,
      "grad_norm": 1.1813836097717285,
      "learning_rate": 7.937872340425532e-06,
      "loss": 0.0844,
      "step": 3731
    },
    {
      "epoch": 0.8575367647058824,
      "grad_norm": 1.562182068824768,
      "learning_rate": 7.937021276595745e-06,
      "loss": 0.1063,
      "step": 3732
    },
    {
      "epoch": 0.8577665441176471,
      "grad_norm": 0.928342878818512,
      "learning_rate": 7.936170212765959e-06,
      "loss": 0.0701,
      "step": 3733
    },
    {
      "epoch": 0.8579963235294118,
      "grad_norm": 1.2009007930755615,
      "learning_rate": 7.935319148936172e-06,
      "loss": 0.0932,
      "step": 3734
    },
    {
      "epoch": 0.8582261029411765,
      "grad_norm": 1.0088878870010376,
      "learning_rate": 7.934468085106383e-06,
      "loss": 0.0995,
      "step": 3735
    },
    {
      "epoch": 0.8584558823529411,
      "grad_norm": 1.3225992918014526,
      "learning_rate": 7.933617021276596e-06,
      "loss": 0.113,
      "step": 3736
    },
    {
      "epoch": 0.8586856617647058,
      "grad_norm": 1.213100552558899,
      "learning_rate": 7.93276595744681e-06,
      "loss": 0.1325,
      "step": 3737
    },
    {
      "epoch": 0.8589154411764706,
      "grad_norm": 0.9726177453994751,
      "learning_rate": 7.931914893617023e-06,
      "loss": 0.0696,
      "step": 3738
    },
    {
      "epoch": 0.8591452205882353,
      "grad_norm": 1.1929850578308105,
      "learning_rate": 7.931063829787234e-06,
      "loss": 0.1176,
      "step": 3739
    },
    {
      "epoch": 0.859375,
      "grad_norm": 1.0513100624084473,
      "learning_rate": 7.930212765957447e-06,
      "loss": 0.0683,
      "step": 3740
    },
    {
      "epoch": 0.8596047794117647,
      "grad_norm": 1.0321167707443237,
      "learning_rate": 7.92936170212766e-06,
      "loss": 0.0996,
      "step": 3741
    },
    {
      "epoch": 0.8598345588235294,
      "grad_norm": 1.4147671461105347,
      "learning_rate": 7.928510638297872e-06,
      "loss": 0.109,
      "step": 3742
    },
    {
      "epoch": 0.8600643382352942,
      "grad_norm": 1.5752496719360352,
      "learning_rate": 7.927659574468087e-06,
      "loss": 0.1108,
      "step": 3743
    },
    {
      "epoch": 0.8602941176470589,
      "grad_norm": 0.9499591588973999,
      "learning_rate": 7.926808510638298e-06,
      "loss": 0.0705,
      "step": 3744
    },
    {
      "epoch": 0.8605238970588235,
      "grad_norm": 1.0776196718215942,
      "learning_rate": 7.925957446808512e-06,
      "loss": 0.0856,
      "step": 3745
    },
    {
      "epoch": 0.8607536764705882,
      "grad_norm": 1.264715313911438,
      "learning_rate": 7.925106382978725e-06,
      "loss": 0.1167,
      "step": 3746
    },
    {
      "epoch": 0.8609834558823529,
      "grad_norm": 1.1450278759002686,
      "learning_rate": 7.924255319148936e-06,
      "loss": 0.0972,
      "step": 3747
    },
    {
      "epoch": 0.8612132352941176,
      "grad_norm": 1.2374982833862305,
      "learning_rate": 7.92340425531915e-06,
      "loss": 0.0924,
      "step": 3748
    },
    {
      "epoch": 0.8614430147058824,
      "grad_norm": 1.071361780166626,
      "learning_rate": 7.922553191489363e-06,
      "loss": 0.0803,
      "step": 3749
    },
    {
      "epoch": 0.8616727941176471,
      "grad_norm": 1.4334217309951782,
      "learning_rate": 7.921702127659576e-06,
      "loss": 0.0946,
      "step": 3750
    },
    {
      "epoch": 0.8619025735294118,
      "grad_norm": 1.1127920150756836,
      "learning_rate": 7.920851063829787e-06,
      "loss": 0.0908,
      "step": 3751
    },
    {
      "epoch": 0.8621323529411765,
      "grad_norm": 1.1245626211166382,
      "learning_rate": 7.92e-06,
      "loss": 0.1073,
      "step": 3752
    },
    {
      "epoch": 0.8623621323529411,
      "grad_norm": 0.9880803227424622,
      "learning_rate": 7.919148936170214e-06,
      "loss": 0.068,
      "step": 3753
    },
    {
      "epoch": 0.8625919117647058,
      "grad_norm": 1.3146024942398071,
      "learning_rate": 7.918297872340425e-06,
      "loss": 0.1096,
      "step": 3754
    },
    {
      "epoch": 0.8628216911764706,
      "grad_norm": 1.1203709840774536,
      "learning_rate": 7.91744680851064e-06,
      "loss": 0.1355,
      "step": 3755
    },
    {
      "epoch": 0.8630514705882353,
      "grad_norm": 1.1771886348724365,
      "learning_rate": 7.916595744680851e-06,
      "loss": 0.1051,
      "step": 3756
    },
    {
      "epoch": 0.86328125,
      "grad_norm": 1.7484525442123413,
      "learning_rate": 7.915744680851065e-06,
      "loss": 0.114,
      "step": 3757
    },
    {
      "epoch": 0.8635110294117647,
      "grad_norm": 1.6373331546783447,
      "learning_rate": 7.914893617021278e-06,
      "loss": 0.0948,
      "step": 3758
    },
    {
      "epoch": 0.8637408088235294,
      "grad_norm": 1.0786609649658203,
      "learning_rate": 7.91404255319149e-06,
      "loss": 0.0823,
      "step": 3759
    },
    {
      "epoch": 0.8639705882352942,
      "grad_norm": 1.3219902515411377,
      "learning_rate": 7.913191489361702e-06,
      "loss": 0.0938,
      "step": 3760
    },
    {
      "epoch": 0.8642003676470589,
      "grad_norm": 1.48084557056427,
      "learning_rate": 7.912340425531916e-06,
      "loss": 0.0666,
      "step": 3761
    },
    {
      "epoch": 0.8644301470588235,
      "grad_norm": 1.199895977973938,
      "learning_rate": 7.911489361702129e-06,
      "loss": 0.0922,
      "step": 3762
    },
    {
      "epoch": 0.8646599264705882,
      "grad_norm": 1.4009076356887817,
      "learning_rate": 7.91063829787234e-06,
      "loss": 0.1121,
      "step": 3763
    },
    {
      "epoch": 0.8648897058823529,
      "grad_norm": 1.7467403411865234,
      "learning_rate": 7.909787234042553e-06,
      "loss": 0.1152,
      "step": 3764
    },
    {
      "epoch": 0.8651194852941176,
      "grad_norm": 1.2802224159240723,
      "learning_rate": 7.908936170212767e-06,
      "loss": 0.0998,
      "step": 3765
    },
    {
      "epoch": 0.8653492647058824,
      "grad_norm": 1.3706499338150024,
      "learning_rate": 7.90808510638298e-06,
      "loss": 0.2039,
      "step": 3766
    },
    {
      "epoch": 0.8655790441176471,
      "grad_norm": 1.4890973567962646,
      "learning_rate": 7.907234042553193e-06,
      "loss": 0.0777,
      "step": 3767
    },
    {
      "epoch": 0.8658088235294118,
      "grad_norm": 1.141196608543396,
      "learning_rate": 7.906382978723404e-06,
      "loss": 0.0883,
      "step": 3768
    },
    {
      "epoch": 0.8660386029411765,
      "grad_norm": 1.3317475318908691,
      "learning_rate": 7.905531914893618e-06,
      "loss": 0.1291,
      "step": 3769
    },
    {
      "epoch": 0.8662683823529411,
      "grad_norm": 1.2798538208007812,
      "learning_rate": 7.90468085106383e-06,
      "loss": 0.0887,
      "step": 3770
    },
    {
      "epoch": 0.8664981617647058,
      "grad_norm": 1.231320858001709,
      "learning_rate": 7.903829787234044e-06,
      "loss": 0.1094,
      "step": 3771
    },
    {
      "epoch": 0.8667279411764706,
      "grad_norm": 1.2220150232315063,
      "learning_rate": 7.902978723404255e-06,
      "loss": 0.1021,
      "step": 3772
    },
    {
      "epoch": 0.8669577205882353,
      "grad_norm": 1.4572935104370117,
      "learning_rate": 7.902127659574469e-06,
      "loss": 0.1333,
      "step": 3773
    },
    {
      "epoch": 0.8671875,
      "grad_norm": 1.050234079360962,
      "learning_rate": 7.901276595744682e-06,
      "loss": 0.083,
      "step": 3774
    },
    {
      "epoch": 0.8674172794117647,
      "grad_norm": 1.2680590152740479,
      "learning_rate": 7.900425531914895e-06,
      "loss": 0.0886,
      "step": 3775
    },
    {
      "epoch": 0.8676470588235294,
      "grad_norm": 1.6556577682495117,
      "learning_rate": 7.899574468085108e-06,
      "loss": 0.1325,
      "step": 3776
    },
    {
      "epoch": 0.8678768382352942,
      "grad_norm": 1.8837471008300781,
      "learning_rate": 7.89872340425532e-06,
      "loss": 0.1132,
      "step": 3777
    },
    {
      "epoch": 0.8681066176470589,
      "grad_norm": 1.4568111896514893,
      "learning_rate": 7.897872340425533e-06,
      "loss": 0.1294,
      "step": 3778
    },
    {
      "epoch": 0.8683363970588235,
      "grad_norm": 1.262708067893982,
      "learning_rate": 7.897021276595746e-06,
      "loss": 0.1182,
      "step": 3779
    },
    {
      "epoch": 0.8685661764705882,
      "grad_norm": 1.482387661933899,
      "learning_rate": 7.896170212765957e-06,
      "loss": 0.1125,
      "step": 3780
    },
    {
      "epoch": 0.8687959558823529,
      "grad_norm": 1.388114333152771,
      "learning_rate": 7.895319148936172e-06,
      "loss": 0.1075,
      "step": 3781
    },
    {
      "epoch": 0.8690257352941176,
      "grad_norm": 1.172369360923767,
      "learning_rate": 7.894468085106384e-06,
      "loss": 0.0751,
      "step": 3782
    },
    {
      "epoch": 0.8692555147058824,
      "grad_norm": 1.277361512184143,
      "learning_rate": 7.893617021276597e-06,
      "loss": 0.1309,
      "step": 3783
    },
    {
      "epoch": 0.8694852941176471,
      "grad_norm": 1.4641733169555664,
      "learning_rate": 7.89276595744681e-06,
      "loss": 0.1393,
      "step": 3784
    },
    {
      "epoch": 0.8697150735294118,
      "grad_norm": 1.153656005859375,
      "learning_rate": 7.891914893617021e-06,
      "loss": 0.083,
      "step": 3785
    },
    {
      "epoch": 0.8699448529411765,
      "grad_norm": 1.1771115064620972,
      "learning_rate": 7.891063829787235e-06,
      "loss": 0.0997,
      "step": 3786
    },
    {
      "epoch": 0.8701746323529411,
      "grad_norm": 0.9259268045425415,
      "learning_rate": 7.890212765957448e-06,
      "loss": 0.0847,
      "step": 3787
    },
    {
      "epoch": 0.8704044117647058,
      "grad_norm": 1.59372079372406,
      "learning_rate": 7.889361702127661e-06,
      "loss": 0.1287,
      "step": 3788
    },
    {
      "epoch": 0.8706341911764706,
      "grad_norm": 1.5818232297897339,
      "learning_rate": 7.888510638297872e-06,
      "loss": 0.1017,
      "step": 3789
    },
    {
      "epoch": 0.8708639705882353,
      "grad_norm": 1.4031733274459839,
      "learning_rate": 7.887659574468086e-06,
      "loss": 0.1318,
      "step": 3790
    },
    {
      "epoch": 0.87109375,
      "grad_norm": 1.220389723777771,
      "learning_rate": 7.886808510638299e-06,
      "loss": 0.0849,
      "step": 3791
    },
    {
      "epoch": 0.8713235294117647,
      "grad_norm": 1.364949345588684,
      "learning_rate": 7.88595744680851e-06,
      "loss": 0.1127,
      "step": 3792
    },
    {
      "epoch": 0.8715533088235294,
      "grad_norm": 1.103508472442627,
      "learning_rate": 7.885106382978725e-06,
      "loss": 0.0894,
      "step": 3793
    },
    {
      "epoch": 0.8717830882352942,
      "grad_norm": 0.9713694453239441,
      "learning_rate": 7.884255319148937e-06,
      "loss": 0.0849,
      "step": 3794
    },
    {
      "epoch": 0.8720128676470589,
      "grad_norm": 1.169689416885376,
      "learning_rate": 7.88340425531915e-06,
      "loss": 0.0714,
      "step": 3795
    },
    {
      "epoch": 0.8722426470588235,
      "grad_norm": 1.3613708019256592,
      "learning_rate": 7.882553191489363e-06,
      "loss": 0.1053,
      "step": 3796
    },
    {
      "epoch": 0.8724724264705882,
      "grad_norm": 0.987594723701477,
      "learning_rate": 7.881702127659574e-06,
      "loss": 0.0907,
      "step": 3797
    },
    {
      "epoch": 0.8727022058823529,
      "grad_norm": 1.5602985620498657,
      "learning_rate": 7.880851063829788e-06,
      "loss": 0.1068,
      "step": 3798
    },
    {
      "epoch": 0.8729319852941176,
      "grad_norm": 1.350966453552246,
      "learning_rate": 7.88e-06,
      "loss": 0.1288,
      "step": 3799
    },
    {
      "epoch": 0.8731617647058824,
      "grad_norm": 1.026430606842041,
      "learning_rate": 7.879148936170214e-06,
      "loss": 0.0767,
      "step": 3800
    },
    {
      "epoch": 0.8733915441176471,
      "grad_norm": 1.239440679550171,
      "learning_rate": 7.878297872340425e-06,
      "loss": 0.1305,
      "step": 3801
    },
    {
      "epoch": 0.8736213235294118,
      "grad_norm": 1.1474772691726685,
      "learning_rate": 7.877446808510639e-06,
      "loss": 0.0931,
      "step": 3802
    },
    {
      "epoch": 0.8738511029411765,
      "grad_norm": 1.2954914569854736,
      "learning_rate": 7.876595744680852e-06,
      "loss": 0.1097,
      "step": 3803
    },
    {
      "epoch": 0.8740808823529411,
      "grad_norm": 1.1787017583847046,
      "learning_rate": 7.875744680851063e-06,
      "loss": 0.1098,
      "step": 3804
    },
    {
      "epoch": 0.8743106617647058,
      "grad_norm": 0.9151043891906738,
      "learning_rate": 7.874893617021278e-06,
      "loss": 0.0757,
      "step": 3805
    },
    {
      "epoch": 0.8745404411764706,
      "grad_norm": 1.0537647008895874,
      "learning_rate": 7.87404255319149e-06,
      "loss": 0.1325,
      "step": 3806
    },
    {
      "epoch": 0.8747702205882353,
      "grad_norm": 1.2595840692520142,
      "learning_rate": 7.873191489361703e-06,
      "loss": 0.1166,
      "step": 3807
    },
    {
      "epoch": 0.875,
      "grad_norm": 1.4558181762695312,
      "learning_rate": 7.872340425531916e-06,
      "loss": 0.1073,
      "step": 3808
    },
    {
      "epoch": 0.8752297794117647,
      "grad_norm": 1.0995601415634155,
      "learning_rate": 7.871489361702127e-06,
      "loss": 0.0842,
      "step": 3809
    },
    {
      "epoch": 0.8754595588235294,
      "grad_norm": 0.9020724296569824,
      "learning_rate": 7.87063829787234e-06,
      "loss": 0.0642,
      "step": 3810
    },
    {
      "epoch": 0.8756893382352942,
      "grad_norm": 1.2861183881759644,
      "learning_rate": 7.869787234042554e-06,
      "loss": 0.1216,
      "step": 3811
    },
    {
      "epoch": 0.8759191176470589,
      "grad_norm": 1.1579252481460571,
      "learning_rate": 7.868936170212767e-06,
      "loss": 0.0804,
      "step": 3812
    },
    {
      "epoch": 0.8761488970588235,
      "grad_norm": 1.1885297298431396,
      "learning_rate": 7.868085106382978e-06,
      "loss": 0.1159,
      "step": 3813
    },
    {
      "epoch": 0.8763786764705882,
      "grad_norm": 1.2336901426315308,
      "learning_rate": 7.867234042553192e-06,
      "loss": 0.0924,
      "step": 3814
    },
    {
      "epoch": 0.8766084558823529,
      "grad_norm": 1.0211538076400757,
      "learning_rate": 7.866382978723405e-06,
      "loss": 0.1035,
      "step": 3815
    },
    {
      "epoch": 0.8768382352941176,
      "grad_norm": 1.4562019109725952,
      "learning_rate": 7.865531914893618e-06,
      "loss": 0.0872,
      "step": 3816
    },
    {
      "epoch": 0.8770680147058824,
      "grad_norm": 1.1965221166610718,
      "learning_rate": 7.864680851063831e-06,
      "loss": 0.1116,
      "step": 3817
    },
    {
      "epoch": 0.8772977941176471,
      "grad_norm": 1.1429959535598755,
      "learning_rate": 7.863829787234043e-06,
      "loss": 0.0972,
      "step": 3818
    },
    {
      "epoch": 0.8775275735294118,
      "grad_norm": 1.015224814414978,
      "learning_rate": 7.862978723404256e-06,
      "loss": 0.0954,
      "step": 3819
    },
    {
      "epoch": 0.8777573529411765,
      "grad_norm": 1.1864598989486694,
      "learning_rate": 7.862127659574469e-06,
      "loss": 0.1217,
      "step": 3820
    },
    {
      "epoch": 0.8779871323529411,
      "grad_norm": 1.0922222137451172,
      "learning_rate": 7.861276595744682e-06,
      "loss": 0.1191,
      "step": 3821
    },
    {
      "epoch": 0.8782169117647058,
      "grad_norm": 1.1490083932876587,
      "learning_rate": 7.860425531914895e-06,
      "loss": 0.0728,
      "step": 3822
    },
    {
      "epoch": 0.8784466911764706,
      "grad_norm": 1.0741064548492432,
      "learning_rate": 7.859574468085107e-06,
      "loss": 0.0994,
      "step": 3823
    },
    {
      "epoch": 0.8786764705882353,
      "grad_norm": 1.2107594013214111,
      "learning_rate": 7.85872340425532e-06,
      "loss": 0.096,
      "step": 3824
    },
    {
      "epoch": 0.87890625,
      "grad_norm": 1.383540391921997,
      "learning_rate": 7.857872340425533e-06,
      "loss": 0.1191,
      "step": 3825
    },
    {
      "epoch": 0.8791360294117647,
      "grad_norm": 1.1828744411468506,
      "learning_rate": 7.857021276595746e-06,
      "loss": 0.1105,
      "step": 3826
    },
    {
      "epoch": 0.8793658088235294,
      "grad_norm": 1.8006341457366943,
      "learning_rate": 7.856170212765958e-06,
      "loss": 0.1348,
      "step": 3827
    },
    {
      "epoch": 0.8795955882352942,
      "grad_norm": 1.3826628923416138,
      "learning_rate": 7.855319148936171e-06,
      "loss": 0.0782,
      "step": 3828
    },
    {
      "epoch": 0.8798253676470589,
      "grad_norm": 0.8564568161964417,
      "learning_rate": 7.854468085106384e-06,
      "loss": 0.0678,
      "step": 3829
    },
    {
      "epoch": 0.8800551470588235,
      "grad_norm": 1.244054913520813,
      "learning_rate": 7.853617021276596e-06,
      "loss": 0.0899,
      "step": 3830
    },
    {
      "epoch": 0.8802849264705882,
      "grad_norm": 1.3694103956222534,
      "learning_rate": 7.85276595744681e-06,
      "loss": 0.1189,
      "step": 3831
    },
    {
      "epoch": 0.8805147058823529,
      "grad_norm": 1.150749683380127,
      "learning_rate": 7.851914893617022e-06,
      "loss": 0.1287,
      "step": 3832
    },
    {
      "epoch": 0.8807444852941176,
      "grad_norm": 1.496118426322937,
      "learning_rate": 7.851063829787235e-06,
      "loss": 0.125,
      "step": 3833
    },
    {
      "epoch": 0.8809742647058824,
      "grad_norm": 0.8577582240104675,
      "learning_rate": 7.850212765957448e-06,
      "loss": 0.0848,
      "step": 3834
    },
    {
      "epoch": 0.8812040441176471,
      "grad_norm": 1.132707118988037,
      "learning_rate": 7.84936170212766e-06,
      "loss": 0.0941,
      "step": 3835
    },
    {
      "epoch": 0.8814338235294118,
      "grad_norm": 1.2140361070632935,
      "learning_rate": 7.848510638297873e-06,
      "loss": 0.0892,
      "step": 3836
    },
    {
      "epoch": 0.8816636029411765,
      "grad_norm": 1.4432179927825928,
      "learning_rate": 7.847659574468086e-06,
      "loss": 0.118,
      "step": 3837
    },
    {
      "epoch": 0.8818933823529411,
      "grad_norm": 1.306902289390564,
      "learning_rate": 7.8468085106383e-06,
      "loss": 0.1076,
      "step": 3838
    },
    {
      "epoch": 0.8821231617647058,
      "grad_norm": 1.051784634590149,
      "learning_rate": 7.84595744680851e-06,
      "loss": 0.085,
      "step": 3839
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 1.2307548522949219,
      "learning_rate": 7.845106382978724e-06,
      "loss": 0.1312,
      "step": 3840
    },
    {
      "epoch": 0.8825827205882353,
      "grad_norm": 1.3215546607971191,
      "learning_rate": 7.844255319148937e-06,
      "loss": 0.1433,
      "step": 3841
    },
    {
      "epoch": 0.8828125,
      "grad_norm": 1.1293312311172485,
      "learning_rate": 7.843404255319148e-06,
      "loss": 0.1108,
      "step": 3842
    },
    {
      "epoch": 0.8830422794117647,
      "grad_norm": 1.2674520015716553,
      "learning_rate": 7.842553191489363e-06,
      "loss": 0.1202,
      "step": 3843
    },
    {
      "epoch": 0.8832720588235294,
      "grad_norm": 1.0806314945220947,
      "learning_rate": 7.841702127659575e-06,
      "loss": 0.0959,
      "step": 3844
    },
    {
      "epoch": 0.8835018382352942,
      "grad_norm": 1.2100591659545898,
      "learning_rate": 7.840851063829788e-06,
      "loss": 0.1307,
      "step": 3845
    },
    {
      "epoch": 0.8837316176470589,
      "grad_norm": 1.0593675374984741,
      "learning_rate": 7.840000000000001e-06,
      "loss": 0.0964,
      "step": 3846
    },
    {
      "epoch": 0.8839613970588235,
      "grad_norm": 1.0710715055465698,
      "learning_rate": 7.839148936170213e-06,
      "loss": 0.0887,
      "step": 3847
    },
    {
      "epoch": 0.8841911764705882,
      "grad_norm": 0.9851884841918945,
      "learning_rate": 7.838297872340426e-06,
      "loss": 0.0942,
      "step": 3848
    },
    {
      "epoch": 0.8844209558823529,
      "grad_norm": 1.035575032234192,
      "learning_rate": 7.837446808510639e-06,
      "loss": 0.1032,
      "step": 3849
    },
    {
      "epoch": 0.8846507352941176,
      "grad_norm": 1.2691965103149414,
      "learning_rate": 7.836595744680852e-06,
      "loss": 0.088,
      "step": 3850
    },
    {
      "epoch": 0.8848805147058824,
      "grad_norm": 0.9449652433395386,
      "learning_rate": 7.835744680851064e-06,
      "loss": 0.0674,
      "step": 3851
    },
    {
      "epoch": 0.8851102941176471,
      "grad_norm": 1.033249020576477,
      "learning_rate": 7.834893617021277e-06,
      "loss": 0.0918,
      "step": 3852
    },
    {
      "epoch": 0.8853400735294118,
      "grad_norm": 0.9118177890777588,
      "learning_rate": 7.83404255319149e-06,
      "loss": 0.0962,
      "step": 3853
    },
    {
      "epoch": 0.8855698529411765,
      "grad_norm": 1.1613707542419434,
      "learning_rate": 7.833191489361701e-06,
      "loss": 0.1071,
      "step": 3854
    },
    {
      "epoch": 0.8857996323529411,
      "grad_norm": 1.7591835260391235,
      "learning_rate": 7.832340425531916e-06,
      "loss": 0.1312,
      "step": 3855
    },
    {
      "epoch": 0.8860294117647058,
      "grad_norm": 1.2849149703979492,
      "learning_rate": 7.831489361702128e-06,
      "loss": 0.0874,
      "step": 3856
    },
    {
      "epoch": 0.8862591911764706,
      "grad_norm": 1.4977666139602661,
      "learning_rate": 7.830638297872341e-06,
      "loss": 0.1343,
      "step": 3857
    },
    {
      "epoch": 0.8864889705882353,
      "grad_norm": 1.0904170274734497,
      "learning_rate": 7.829787234042554e-06,
      "loss": 0.0755,
      "step": 3858
    },
    {
      "epoch": 0.88671875,
      "grad_norm": 1.3927026987075806,
      "learning_rate": 7.828936170212766e-06,
      "loss": 0.108,
      "step": 3859
    },
    {
      "epoch": 0.8869485294117647,
      "grad_norm": 1.4655382633209229,
      "learning_rate": 7.82808510638298e-06,
      "loss": 0.1132,
      "step": 3860
    },
    {
      "epoch": 0.8871783088235294,
      "grad_norm": 1.5040661096572876,
      "learning_rate": 7.827234042553192e-06,
      "loss": 0.1069,
      "step": 3861
    },
    {
      "epoch": 0.8874080882352942,
      "grad_norm": 0.9640001058578491,
      "learning_rate": 7.826382978723405e-06,
      "loss": 0.0729,
      "step": 3862
    },
    {
      "epoch": 0.8876378676470589,
      "grad_norm": 1.0480670928955078,
      "learning_rate": 7.825531914893618e-06,
      "loss": 0.0832,
      "step": 3863
    },
    {
      "epoch": 0.8878676470588235,
      "grad_norm": 1.7044914960861206,
      "learning_rate": 7.82468085106383e-06,
      "loss": 0.1149,
      "step": 3864
    },
    {
      "epoch": 0.8880974264705882,
      "grad_norm": 1.5728152990341187,
      "learning_rate": 7.823829787234043e-06,
      "loss": 0.1354,
      "step": 3865
    },
    {
      "epoch": 0.8883272058823529,
      "grad_norm": 1.1067147254943848,
      "learning_rate": 7.822978723404256e-06,
      "loss": 0.0871,
      "step": 3866
    },
    {
      "epoch": 0.8885569852941176,
      "grad_norm": 1.2827988862991333,
      "learning_rate": 7.82212765957447e-06,
      "loss": 0.0787,
      "step": 3867
    },
    {
      "epoch": 0.8887867647058824,
      "grad_norm": 1.0372345447540283,
      "learning_rate": 7.82127659574468e-06,
      "loss": 0.0683,
      "step": 3868
    },
    {
      "epoch": 0.8890165441176471,
      "grad_norm": 0.9062525629997253,
      "learning_rate": 7.820425531914894e-06,
      "loss": 0.0653,
      "step": 3869
    },
    {
      "epoch": 0.8892463235294118,
      "grad_norm": 1.5455422401428223,
      "learning_rate": 7.819574468085107e-06,
      "loss": 0.1484,
      "step": 3870
    },
    {
      "epoch": 0.8894761029411765,
      "grad_norm": 1.2220616340637207,
      "learning_rate": 7.81872340425532e-06,
      "loss": 0.0956,
      "step": 3871
    },
    {
      "epoch": 0.8897058823529411,
      "grad_norm": 1.7627286911010742,
      "learning_rate": 7.817872340425533e-06,
      "loss": 0.1175,
      "step": 3872
    },
    {
      "epoch": 0.8899356617647058,
      "grad_norm": 1.1739670038223267,
      "learning_rate": 7.817021276595745e-06,
      "loss": 0.0974,
      "step": 3873
    },
    {
      "epoch": 0.8901654411764706,
      "grad_norm": 1.4392884969711304,
      "learning_rate": 7.816170212765958e-06,
      "loss": 0.109,
      "step": 3874
    },
    {
      "epoch": 0.8903952205882353,
      "grad_norm": 1.1230140924453735,
      "learning_rate": 7.815319148936171e-06,
      "loss": 0.09,
      "step": 3875
    },
    {
      "epoch": 0.890625,
      "grad_norm": 0.788337230682373,
      "learning_rate": 7.814468085106384e-06,
      "loss": 0.0782,
      "step": 3876
    },
    {
      "epoch": 0.8908547794117647,
      "grad_norm": 1.5851945877075195,
      "learning_rate": 7.813617021276596e-06,
      "loss": 0.1293,
      "step": 3877
    },
    {
      "epoch": 0.8910845588235294,
      "grad_norm": 1.607012152671814,
      "learning_rate": 7.812765957446809e-06,
      "loss": 0.1373,
      "step": 3878
    },
    {
      "epoch": 0.8913143382352942,
      "grad_norm": 1.2361737489700317,
      "learning_rate": 7.811914893617022e-06,
      "loss": 0.1041,
      "step": 3879
    },
    {
      "epoch": 0.8915441176470589,
      "grad_norm": 1.3623327016830444,
      "learning_rate": 7.811063829787234e-06,
      "loss": 0.0971,
      "step": 3880
    },
    {
      "epoch": 0.8917738970588235,
      "grad_norm": 1.7733908891677856,
      "learning_rate": 7.810212765957449e-06,
      "loss": 0.1085,
      "step": 3881
    },
    {
      "epoch": 0.8920036764705882,
      "grad_norm": 1.5954664945602417,
      "learning_rate": 7.80936170212766e-06,
      "loss": 0.1051,
      "step": 3882
    },
    {
      "epoch": 0.8922334558823529,
      "grad_norm": 1.1635639667510986,
      "learning_rate": 7.808510638297873e-06,
      "loss": 0.0909,
      "step": 3883
    },
    {
      "epoch": 0.8924632352941176,
      "grad_norm": 1.23557710647583,
      "learning_rate": 7.807659574468086e-06,
      "loss": 0.096,
      "step": 3884
    },
    {
      "epoch": 0.8926930147058824,
      "grad_norm": 1.3139010667800903,
      "learning_rate": 7.806808510638298e-06,
      "loss": 0.0972,
      "step": 3885
    },
    {
      "epoch": 0.8929227941176471,
      "grad_norm": 1.2757642269134521,
      "learning_rate": 7.805957446808511e-06,
      "loss": 0.0895,
      "step": 3886
    },
    {
      "epoch": 0.8931525735294118,
      "grad_norm": 1.2885982990264893,
      "learning_rate": 7.805106382978724e-06,
      "loss": 0.1224,
      "step": 3887
    },
    {
      "epoch": 0.8933823529411765,
      "grad_norm": 1.6505200862884521,
      "learning_rate": 7.804255319148937e-06,
      "loss": 0.1398,
      "step": 3888
    },
    {
      "epoch": 0.8936121323529411,
      "grad_norm": 1.222780704498291,
      "learning_rate": 7.803404255319149e-06,
      "loss": 0.1047,
      "step": 3889
    },
    {
      "epoch": 0.8938419117647058,
      "grad_norm": 1.4756771326065063,
      "learning_rate": 7.802553191489362e-06,
      "loss": 0.1215,
      "step": 3890
    },
    {
      "epoch": 0.8940716911764706,
      "grad_norm": 1.57341468334198,
      "learning_rate": 7.801702127659575e-06,
      "loss": 0.1162,
      "step": 3891
    },
    {
      "epoch": 0.8943014705882353,
      "grad_norm": 1.0913764238357544,
      "learning_rate": 7.800851063829787e-06,
      "loss": 0.1047,
      "step": 3892
    },
    {
      "epoch": 0.89453125,
      "grad_norm": 1.2021164894104004,
      "learning_rate": 7.800000000000002e-06,
      "loss": 0.059,
      "step": 3893
    },
    {
      "epoch": 0.8947610294117647,
      "grad_norm": 1.102340817451477,
      "learning_rate": 7.799148936170213e-06,
      "loss": 0.0774,
      "step": 3894
    },
    {
      "epoch": 0.8949908088235294,
      "grad_norm": 1.6386699676513672,
      "learning_rate": 7.798297872340426e-06,
      "loss": 0.1023,
      "step": 3895
    },
    {
      "epoch": 0.8952205882352942,
      "grad_norm": 1.0894688367843628,
      "learning_rate": 7.79744680851064e-06,
      "loss": 0.0907,
      "step": 3896
    },
    {
      "epoch": 0.8954503676470589,
      "grad_norm": 1.5849518775939941,
      "learning_rate": 7.796595744680851e-06,
      "loss": 0.0909,
      "step": 3897
    },
    {
      "epoch": 0.8956801470588235,
      "grad_norm": 1.40291166305542,
      "learning_rate": 7.795744680851064e-06,
      "loss": 0.0803,
      "step": 3898
    },
    {
      "epoch": 0.8959099264705882,
      "grad_norm": 1.485599398612976,
      "learning_rate": 7.794893617021277e-06,
      "loss": 0.1347,
      "step": 3899
    },
    {
      "epoch": 0.8961397058823529,
      "grad_norm": 1.4355156421661377,
      "learning_rate": 7.79404255319149e-06,
      "loss": 0.1024,
      "step": 3900
    },
    {
      "epoch": 0.8963694852941176,
      "grad_norm": 1.1861659288406372,
      "learning_rate": 7.793191489361702e-06,
      "loss": 0.1015,
      "step": 3901
    },
    {
      "epoch": 0.8965992647058824,
      "grad_norm": 1.0463312864303589,
      "learning_rate": 7.792340425531915e-06,
      "loss": 0.1278,
      "step": 3902
    },
    {
      "epoch": 0.8968290441176471,
      "grad_norm": 1.2292274236679077,
      "learning_rate": 7.791489361702128e-06,
      "loss": 0.0785,
      "step": 3903
    },
    {
      "epoch": 0.8970588235294118,
      "grad_norm": 1.3755271434783936,
      "learning_rate": 7.790638297872341e-06,
      "loss": 0.122,
      "step": 3904
    },
    {
      "epoch": 0.8972886029411765,
      "grad_norm": 1.0412284135818481,
      "learning_rate": 7.789787234042555e-06,
      "loss": 0.0765,
      "step": 3905
    },
    {
      "epoch": 0.8975183823529411,
      "grad_norm": 1.2922917604446411,
      "learning_rate": 7.788936170212766e-06,
      "loss": 0.1076,
      "step": 3906
    },
    {
      "epoch": 0.8977481617647058,
      "grad_norm": 1.066635251045227,
      "learning_rate": 7.78808510638298e-06,
      "loss": 0.0818,
      "step": 3907
    },
    {
      "epoch": 0.8979779411764706,
      "grad_norm": 1.5996496677398682,
      "learning_rate": 7.787234042553192e-06,
      "loss": 0.1265,
      "step": 3908
    },
    {
      "epoch": 0.8982077205882353,
      "grad_norm": 1.2919223308563232,
      "learning_rate": 7.786382978723404e-06,
      "loss": 0.1197,
      "step": 3909
    },
    {
      "epoch": 0.8984375,
      "grad_norm": 1.0409713983535767,
      "learning_rate": 7.785531914893619e-06,
      "loss": 0.0886,
      "step": 3910
    },
    {
      "epoch": 0.8986672794117647,
      "grad_norm": 1.1799037456512451,
      "learning_rate": 7.78468085106383e-06,
      "loss": 0.1122,
      "step": 3911
    },
    {
      "epoch": 0.8988970588235294,
      "grad_norm": 1.318245768547058,
      "learning_rate": 7.783829787234043e-06,
      "loss": 0.123,
      "step": 3912
    },
    {
      "epoch": 0.8991268382352942,
      "grad_norm": 1.175644874572754,
      "learning_rate": 7.782978723404256e-06,
      "loss": 0.0965,
      "step": 3913
    },
    {
      "epoch": 0.8993566176470589,
      "grad_norm": 1.2836860418319702,
      "learning_rate": 7.782127659574468e-06,
      "loss": 0.1026,
      "step": 3914
    },
    {
      "epoch": 0.8995863970588235,
      "grad_norm": 1.1396267414093018,
      "learning_rate": 7.781276595744681e-06,
      "loss": 0.0832,
      "step": 3915
    },
    {
      "epoch": 0.8998161764705882,
      "grad_norm": 1.1082607507705688,
      "learning_rate": 7.780425531914894e-06,
      "loss": 0.1193,
      "step": 3916
    },
    {
      "epoch": 0.9000459558823529,
      "grad_norm": 1.0744831562042236,
      "learning_rate": 7.779574468085107e-06,
      "loss": 0.1176,
      "step": 3917
    },
    {
      "epoch": 0.9002757352941176,
      "grad_norm": 1.1411429643630981,
      "learning_rate": 7.778723404255319e-06,
      "loss": 0.091,
      "step": 3918
    },
    {
      "epoch": 0.9005055147058824,
      "grad_norm": 1.2731319665908813,
      "learning_rate": 7.777872340425532e-06,
      "loss": 0.1005,
      "step": 3919
    },
    {
      "epoch": 0.9007352941176471,
      "grad_norm": 1.1130656003952026,
      "learning_rate": 7.777021276595745e-06,
      "loss": 0.0986,
      "step": 3920
    },
    {
      "epoch": 0.9009650735294118,
      "grad_norm": 1.1220409870147705,
      "learning_rate": 7.776170212765958e-06,
      "loss": 0.093,
      "step": 3921
    },
    {
      "epoch": 0.9011948529411765,
      "grad_norm": 1.2894787788391113,
      "learning_rate": 7.775319148936172e-06,
      "loss": 0.1006,
      "step": 3922
    },
    {
      "epoch": 0.9014246323529411,
      "grad_norm": 1.08781099319458,
      "learning_rate": 7.774468085106383e-06,
      "loss": 0.0968,
      "step": 3923
    },
    {
      "epoch": 0.9016544117647058,
      "grad_norm": 1.4091929197311401,
      "learning_rate": 7.773617021276596e-06,
      "loss": 0.1134,
      "step": 3924
    },
    {
      "epoch": 0.9018841911764706,
      "grad_norm": 1.3496431112289429,
      "learning_rate": 7.77276595744681e-06,
      "loss": 0.099,
      "step": 3925
    },
    {
      "epoch": 0.9021139705882353,
      "grad_norm": 1.7257239818572998,
      "learning_rate": 7.771914893617023e-06,
      "loss": 0.1152,
      "step": 3926
    },
    {
      "epoch": 0.90234375,
      "grad_norm": 1.326922059059143,
      "learning_rate": 7.771063829787234e-06,
      "loss": 0.0957,
      "step": 3927
    },
    {
      "epoch": 0.9025735294117647,
      "grad_norm": 1.2165353298187256,
      "learning_rate": 7.770212765957447e-06,
      "loss": 0.1127,
      "step": 3928
    },
    {
      "epoch": 0.9028033088235294,
      "grad_norm": 1.085119366645813,
      "learning_rate": 7.76936170212766e-06,
      "loss": 0.1012,
      "step": 3929
    },
    {
      "epoch": 0.9030330882352942,
      "grad_norm": 1.3059130907058716,
      "learning_rate": 7.768510638297872e-06,
      "loss": 0.1529,
      "step": 3930
    },
    {
      "epoch": 0.9032628676470589,
      "grad_norm": 1.0337469577789307,
      "learning_rate": 7.767659574468087e-06,
      "loss": 0.1149,
      "step": 3931
    },
    {
      "epoch": 0.9034926470588235,
      "grad_norm": 1.5332244634628296,
      "learning_rate": 7.766808510638298e-06,
      "loss": 0.1042,
      "step": 3932
    },
    {
      "epoch": 0.9037224264705882,
      "grad_norm": 1.024935007095337,
      "learning_rate": 7.765957446808511e-06,
      "loss": 0.0612,
      "step": 3933
    },
    {
      "epoch": 0.9039522058823529,
      "grad_norm": 0.956927478313446,
      "learning_rate": 7.765106382978725e-06,
      "loss": 0.0856,
      "step": 3934
    },
    {
      "epoch": 0.9041819852941176,
      "grad_norm": 1.5745974779129028,
      "learning_rate": 7.764255319148936e-06,
      "loss": 0.1378,
      "step": 3935
    },
    {
      "epoch": 0.9044117647058824,
      "grad_norm": 1.2313423156738281,
      "learning_rate": 7.76340425531915e-06,
      "loss": 0.1211,
      "step": 3936
    },
    {
      "epoch": 0.9046415441176471,
      "grad_norm": 1.486023187637329,
      "learning_rate": 7.762553191489362e-06,
      "loss": 0.1071,
      "step": 3937
    },
    {
      "epoch": 0.9048713235294118,
      "grad_norm": 1.084181547164917,
      "learning_rate": 7.761702127659576e-06,
      "loss": 0.0847,
      "step": 3938
    },
    {
      "epoch": 0.9051011029411765,
      "grad_norm": 1.4684903621673584,
      "learning_rate": 7.760851063829787e-06,
      "loss": 0.1314,
      "step": 3939
    },
    {
      "epoch": 0.9053308823529411,
      "grad_norm": 1.102582573890686,
      "learning_rate": 7.76e-06,
      "loss": 0.084,
      "step": 3940
    },
    {
      "epoch": 0.9055606617647058,
      "grad_norm": 1.5604509115219116,
      "learning_rate": 7.759148936170213e-06,
      "loss": 0.1168,
      "step": 3941
    },
    {
      "epoch": 0.9057904411764706,
      "grad_norm": 1.2623225450515747,
      "learning_rate": 7.758297872340425e-06,
      "loss": 0.1078,
      "step": 3942
    },
    {
      "epoch": 0.9060202205882353,
      "grad_norm": 1.1537503004074097,
      "learning_rate": 7.75744680851064e-06,
      "loss": 0.1033,
      "step": 3943
    },
    {
      "epoch": 0.90625,
      "grad_norm": 1.3069772720336914,
      "learning_rate": 7.756595744680851e-06,
      "loss": 0.0965,
      "step": 3944
    },
    {
      "epoch": 0.9064797794117647,
      "grad_norm": 1.1675816774368286,
      "learning_rate": 7.755744680851064e-06,
      "loss": 0.1104,
      "step": 3945
    },
    {
      "epoch": 0.9067095588235294,
      "grad_norm": 1.0686583518981934,
      "learning_rate": 7.754893617021278e-06,
      "loss": 0.0885,
      "step": 3946
    },
    {
      "epoch": 0.9069393382352942,
      "grad_norm": 1.1944291591644287,
      "learning_rate": 7.754042553191489e-06,
      "loss": 0.1136,
      "step": 3947
    },
    {
      "epoch": 0.9071691176470589,
      "grad_norm": 1.1666234731674194,
      "learning_rate": 7.753191489361704e-06,
      "loss": 0.1036,
      "step": 3948
    },
    {
      "epoch": 0.9073988970588235,
      "grad_norm": 1.120747447013855,
      "learning_rate": 7.752340425531915e-06,
      "loss": 0.1095,
      "step": 3949
    },
    {
      "epoch": 0.9076286764705882,
      "grad_norm": 1.2747231721878052,
      "learning_rate": 7.751489361702129e-06,
      "loss": 0.1012,
      "step": 3950
    },
    {
      "epoch": 0.9078584558823529,
      "grad_norm": 1.221685767173767,
      "learning_rate": 7.750638297872342e-06,
      "loss": 0.1012,
      "step": 3951
    },
    {
      "epoch": 0.9080882352941176,
      "grad_norm": 1.2432819604873657,
      "learning_rate": 7.749787234042553e-06,
      "loss": 0.0849,
      "step": 3952
    },
    {
      "epoch": 0.9083180147058824,
      "grad_norm": 0.9119266867637634,
      "learning_rate": 7.748936170212766e-06,
      "loss": 0.0903,
      "step": 3953
    },
    {
      "epoch": 0.9085477941176471,
      "grad_norm": 1.2848718166351318,
      "learning_rate": 7.74808510638298e-06,
      "loss": 0.1154,
      "step": 3954
    },
    {
      "epoch": 0.9087775735294118,
      "grad_norm": 1.4033929109573364,
      "learning_rate": 7.747234042553193e-06,
      "loss": 0.1007,
      "step": 3955
    },
    {
      "epoch": 0.9090073529411765,
      "grad_norm": 1.6783310174942017,
      "learning_rate": 7.746382978723404e-06,
      "loss": 0.1057,
      "step": 3956
    },
    {
      "epoch": 0.9092371323529411,
      "grad_norm": 1.2521380186080933,
      "learning_rate": 7.745531914893617e-06,
      "loss": 0.1232,
      "step": 3957
    },
    {
      "epoch": 0.9094669117647058,
      "grad_norm": 1.4098292589187622,
      "learning_rate": 7.74468085106383e-06,
      "loss": 0.157,
      "step": 3958
    },
    {
      "epoch": 0.9096966911764706,
      "grad_norm": 1.3188565969467163,
      "learning_rate": 7.743829787234044e-06,
      "loss": 0.1121,
      "step": 3959
    },
    {
      "epoch": 0.9099264705882353,
      "grad_norm": 0.9735924005508423,
      "learning_rate": 7.742978723404257e-06,
      "loss": 0.0744,
      "step": 3960
    },
    {
      "epoch": 0.91015625,
      "grad_norm": 1.4178085327148438,
      "learning_rate": 7.742127659574468e-06,
      "loss": 0.1225,
      "step": 3961
    },
    {
      "epoch": 0.9103860294117647,
      "grad_norm": 1.3243170976638794,
      "learning_rate": 7.741276595744682e-06,
      "loss": 0.1037,
      "step": 3962
    },
    {
      "epoch": 0.9106158088235294,
      "grad_norm": 1.3610057830810547,
      "learning_rate": 7.740425531914895e-06,
      "loss": 0.1253,
      "step": 3963
    },
    {
      "epoch": 0.9108455882352942,
      "grad_norm": 1.19515860080719,
      "learning_rate": 7.739574468085108e-06,
      "loss": 0.114,
      "step": 3964
    },
    {
      "epoch": 0.9110753676470589,
      "grad_norm": 1.1279240846633911,
      "learning_rate": 7.73872340425532e-06,
      "loss": 0.0859,
      "step": 3965
    },
    {
      "epoch": 0.9113051470588235,
      "grad_norm": 1.080315113067627,
      "learning_rate": 7.737872340425533e-06,
      "loss": 0.1036,
      "step": 3966
    },
    {
      "epoch": 0.9115349264705882,
      "grad_norm": 1.1176328659057617,
      "learning_rate": 7.737021276595746e-06,
      "loss": 0.0905,
      "step": 3967
    },
    {
      "epoch": 0.9117647058823529,
      "grad_norm": 1.223781943321228,
      "learning_rate": 7.736170212765957e-06,
      "loss": 0.1268,
      "step": 3968
    },
    {
      "epoch": 0.9119944852941176,
      "grad_norm": 1.0848013162612915,
      "learning_rate": 7.735319148936172e-06,
      "loss": 0.0728,
      "step": 3969
    },
    {
      "epoch": 0.9122242647058824,
      "grad_norm": 1.1479482650756836,
      "learning_rate": 7.734468085106384e-06,
      "loss": 0.0649,
      "step": 3970
    },
    {
      "epoch": 0.9124540441176471,
      "grad_norm": 1.51676344871521,
      "learning_rate": 7.733617021276597e-06,
      "loss": 0.123,
      "step": 3971
    },
    {
      "epoch": 0.9126838235294118,
      "grad_norm": 1.1516146659851074,
      "learning_rate": 7.73276595744681e-06,
      "loss": 0.0942,
      "step": 3972
    },
    {
      "epoch": 0.9129136029411765,
      "grad_norm": 1.3248084783554077,
      "learning_rate": 7.731914893617021e-06,
      "loss": 0.1028,
      "step": 3973
    },
    {
      "epoch": 0.9131433823529411,
      "grad_norm": 1.4221657514572144,
      "learning_rate": 7.731063829787234e-06,
      "loss": 0.0856,
      "step": 3974
    },
    {
      "epoch": 0.9133731617647058,
      "grad_norm": 1.3800212144851685,
      "learning_rate": 7.730212765957448e-06,
      "loss": 0.1134,
      "step": 3975
    },
    {
      "epoch": 0.9136029411764706,
      "grad_norm": 1.065590500831604,
      "learning_rate": 7.72936170212766e-06,
      "loss": 0.0834,
      "step": 3976
    },
    {
      "epoch": 0.9138327205882353,
      "grad_norm": 1.0373140573501587,
      "learning_rate": 7.728510638297872e-06,
      "loss": 0.095,
      "step": 3977
    },
    {
      "epoch": 0.9140625,
      "grad_norm": 1.1047056913375854,
      "learning_rate": 7.727659574468085e-06,
      "loss": 0.1075,
      "step": 3978
    },
    {
      "epoch": 0.9142922794117647,
      "grad_norm": 1.3827557563781738,
      "learning_rate": 7.726808510638299e-06,
      "loss": 0.1223,
      "step": 3979
    },
    {
      "epoch": 0.9145220588235294,
      "grad_norm": 1.2880229949951172,
      "learning_rate": 7.72595744680851e-06,
      "loss": 0.1107,
      "step": 3980
    },
    {
      "epoch": 0.9147518382352942,
      "grad_norm": 1.126097559928894,
      "learning_rate": 7.725106382978725e-06,
      "loss": 0.0877,
      "step": 3981
    },
    {
      "epoch": 0.9149816176470589,
      "grad_norm": 1.6624493598937988,
      "learning_rate": 7.724255319148936e-06,
      "loss": 0.0925,
      "step": 3982
    },
    {
      "epoch": 0.9152113970588235,
      "grad_norm": 1.064064621925354,
      "learning_rate": 7.72340425531915e-06,
      "loss": 0.1043,
      "step": 3983
    },
    {
      "epoch": 0.9154411764705882,
      "grad_norm": 1.2917910814285278,
      "learning_rate": 7.722553191489363e-06,
      "loss": 0.0593,
      "step": 3984
    },
    {
      "epoch": 0.9156709558823529,
      "grad_norm": 1.2992610931396484,
      "learning_rate": 7.721702127659574e-06,
      "loss": 0.1188,
      "step": 3985
    },
    {
      "epoch": 0.9159007352941176,
      "grad_norm": 1.957507610321045,
      "learning_rate": 7.720851063829787e-06,
      "loss": 0.1694,
      "step": 3986
    },
    {
      "epoch": 0.9161305147058824,
      "grad_norm": 1.6823979616165161,
      "learning_rate": 7.72e-06,
      "loss": 0.1297,
      "step": 3987
    },
    {
      "epoch": 0.9163602941176471,
      "grad_norm": 1.5186424255371094,
      "learning_rate": 7.719148936170214e-06,
      "loss": 0.1272,
      "step": 3988
    },
    {
      "epoch": 0.9165900735294118,
      "grad_norm": 1.2958275079727173,
      "learning_rate": 7.718297872340427e-06,
      "loss": 0.1311,
      "step": 3989
    },
    {
      "epoch": 0.9168198529411765,
      "grad_norm": 1.112270474433899,
      "learning_rate": 7.717446808510638e-06,
      "loss": 0.0872,
      "step": 3990
    },
    {
      "epoch": 0.9170496323529411,
      "grad_norm": 1.129687786102295,
      "learning_rate": 7.716595744680852e-06,
      "loss": 0.0866,
      "step": 3991
    },
    {
      "epoch": 0.9172794117647058,
      "grad_norm": 1.2083783149719238,
      "learning_rate": 7.715744680851065e-06,
      "loss": 0.0886,
      "step": 3992
    },
    {
      "epoch": 0.9175091911764706,
      "grad_norm": 1.117061734199524,
      "learning_rate": 7.714893617021278e-06,
      "loss": 0.1071,
      "step": 3993
    },
    {
      "epoch": 0.9177389705882353,
      "grad_norm": 0.9689897298812866,
      "learning_rate": 7.71404255319149e-06,
      "loss": 0.0966,
      "step": 3994
    },
    {
      "epoch": 0.91796875,
      "grad_norm": 0.8755228519439697,
      "learning_rate": 7.713191489361703e-06,
      "loss": 0.0713,
      "step": 3995
    },
    {
      "epoch": 0.9181985294117647,
      "grad_norm": 1.6724865436553955,
      "learning_rate": 7.712340425531916e-06,
      "loss": 0.0932,
      "step": 3996
    },
    {
      "epoch": 0.9184283088235294,
      "grad_norm": 1.5258325338363647,
      "learning_rate": 7.711489361702127e-06,
      "loss": 0.1011,
      "step": 3997
    },
    {
      "epoch": 0.9186580882352942,
      "grad_norm": 0.8556190729141235,
      "learning_rate": 7.710638297872342e-06,
      "loss": 0.077,
      "step": 3998
    },
    {
      "epoch": 0.9188878676470589,
      "grad_norm": 2.037044048309326,
      "learning_rate": 7.709787234042554e-06,
      "loss": 0.0987,
      "step": 3999
    },
    {
      "epoch": 0.9191176470588235,
      "grad_norm": 1.1512781381607056,
      "learning_rate": 7.708936170212767e-06,
      "loss": 0.0678,
      "step": 4000
    },
    {
      "epoch": 0.9191176470588235,
      "eval_loss": 0.10370684415102005,
      "eval_runtime": 1964.6192,
      "eval_samples_per_second": 4.533,
      "eval_steps_per_second": 2.267,
      "step": 4000
    },
    {
      "epoch": 0.9193474264705882,
      "grad_norm": 1.2168160676956177,
      "learning_rate": 7.70808510638298e-06,
      "loss": 0.1117,
      "step": 4001
    },
    {
      "epoch": 0.9195772058823529,
      "grad_norm": 1.0850775241851807,
      "learning_rate": 7.707234042553191e-06,
      "loss": 0.0861,
      "step": 4002
    },
    {
      "epoch": 0.9198069852941176,
      "grad_norm": 1.2062363624572754,
      "learning_rate": 7.706382978723405e-06,
      "loss": 0.0979,
      "step": 4003
    },
    {
      "epoch": 0.9200367647058824,
      "grad_norm": 1.327895998954773,
      "learning_rate": 7.705531914893618e-06,
      "loss": 0.1019,
      "step": 4004
    },
    {
      "epoch": 0.9202665441176471,
      "grad_norm": 1.3185709714889526,
      "learning_rate": 7.704680851063831e-06,
      "loss": 0.0937,
      "step": 4005
    },
    {
      "epoch": 0.9204963235294118,
      "grad_norm": 1.0672643184661865,
      "learning_rate": 7.703829787234042e-06,
      "loss": 0.0774,
      "step": 4006
    },
    {
      "epoch": 0.9207261029411765,
      "grad_norm": 1.5306719541549683,
      "learning_rate": 7.702978723404256e-06,
      "loss": 0.1695,
      "step": 4007
    },
    {
      "epoch": 0.9209558823529411,
      "grad_norm": 1.3467069864273071,
      "learning_rate": 7.702127659574469e-06,
      "loss": 0.0869,
      "step": 4008
    },
    {
      "epoch": 0.9211856617647058,
      "grad_norm": 1.6217769384384155,
      "learning_rate": 7.701276595744682e-06,
      "loss": 0.098,
      "step": 4009
    },
    {
      "epoch": 0.9214154411764706,
      "grad_norm": 1.5419673919677734,
      "learning_rate": 7.700425531914895e-06,
      "loss": 0.15,
      "step": 4010
    },
    {
      "epoch": 0.9216452205882353,
      "grad_norm": 1.1645228862762451,
      "learning_rate": 7.699574468085107e-06,
      "loss": 0.1018,
      "step": 4011
    },
    {
      "epoch": 0.921875,
      "grad_norm": 1.624868631362915,
      "learning_rate": 7.69872340425532e-06,
      "loss": 0.1225,
      "step": 4012
    },
    {
      "epoch": 0.9221047794117647,
      "grad_norm": 1.2106480598449707,
      "learning_rate": 7.697872340425533e-06,
      "loss": 0.0944,
      "step": 4013
    },
    {
      "epoch": 0.9223345588235294,
      "grad_norm": 1.1057729721069336,
      "learning_rate": 7.697021276595746e-06,
      "loss": 0.0917,
      "step": 4014
    },
    {
      "epoch": 0.9225643382352942,
      "grad_norm": 1.0133774280548096,
      "learning_rate": 7.696170212765958e-06,
      "loss": 0.0869,
      "step": 4015
    },
    {
      "epoch": 0.9227941176470589,
      "grad_norm": 1.0257750749588013,
      "learning_rate": 7.69531914893617e-06,
      "loss": 0.0982,
      "step": 4016
    },
    {
      "epoch": 0.9230238970588235,
      "grad_norm": 1.5149257183074951,
      "learning_rate": 7.694468085106384e-06,
      "loss": 0.1083,
      "step": 4017
    },
    {
      "epoch": 0.9232536764705882,
      "grad_norm": 1.9663013219833374,
      "learning_rate": 7.693617021276595e-06,
      "loss": 0.0876,
      "step": 4018
    },
    {
      "epoch": 0.9234834558823529,
      "grad_norm": 1.5092568397521973,
      "learning_rate": 7.69276595744681e-06,
      "loss": 0.1077,
      "step": 4019
    },
    {
      "epoch": 0.9237132352941176,
      "grad_norm": 1.4565060138702393,
      "learning_rate": 7.691914893617022e-06,
      "loss": 0.1383,
      "step": 4020
    },
    {
      "epoch": 0.9239430147058824,
      "grad_norm": 1.1800646781921387,
      "learning_rate": 7.691063829787235e-06,
      "loss": 0.0896,
      "step": 4021
    },
    {
      "epoch": 0.9241727941176471,
      "grad_norm": 1.3538740873336792,
      "learning_rate": 7.690212765957448e-06,
      "loss": 0.1067,
      "step": 4022
    },
    {
      "epoch": 0.9244025735294118,
      "grad_norm": 1.1670953035354614,
      "learning_rate": 7.68936170212766e-06,
      "loss": 0.1062,
      "step": 4023
    },
    {
      "epoch": 0.9246323529411765,
      "grad_norm": 1.339041829109192,
      "learning_rate": 7.688510638297873e-06,
      "loss": 0.1118,
      "step": 4024
    },
    {
      "epoch": 0.9248621323529411,
      "grad_norm": 1.6654016971588135,
      "learning_rate": 7.687659574468086e-06,
      "loss": 0.1134,
      "step": 4025
    },
    {
      "epoch": 0.9250919117647058,
      "grad_norm": 1.3238378763198853,
      "learning_rate": 7.686808510638299e-06,
      "loss": 0.1003,
      "step": 4026
    },
    {
      "epoch": 0.9253216911764706,
      "grad_norm": 1.4830467700958252,
      "learning_rate": 7.68595744680851e-06,
      "loss": 0.1038,
      "step": 4027
    },
    {
      "epoch": 0.9255514705882353,
      "grad_norm": 1.2307237386703491,
      "learning_rate": 7.685106382978724e-06,
      "loss": 0.0999,
      "step": 4028
    },
    {
      "epoch": 0.92578125,
      "grad_norm": 0.9255964159965515,
      "learning_rate": 7.684255319148937e-06,
      "loss": 0.072,
      "step": 4029
    },
    {
      "epoch": 0.9260110294117647,
      "grad_norm": 1.5240485668182373,
      "learning_rate": 7.683404255319148e-06,
      "loss": 0.1049,
      "step": 4030
    },
    {
      "epoch": 0.9262408088235294,
      "grad_norm": 1.4454118013381958,
      "learning_rate": 7.682553191489363e-06,
      "loss": 0.0985,
      "step": 4031
    },
    {
      "epoch": 0.9264705882352942,
      "grad_norm": 1.0147355794906616,
      "learning_rate": 7.681702127659575e-06,
      "loss": 0.0857,
      "step": 4032
    },
    {
      "epoch": 0.9267003676470589,
      "grad_norm": 1.7344799041748047,
      "learning_rate": 7.680851063829788e-06,
      "loss": 0.1247,
      "step": 4033
    },
    {
      "epoch": 0.9269301470588235,
      "grad_norm": 1.174200177192688,
      "learning_rate": 7.680000000000001e-06,
      "loss": 0.0983,
      "step": 4034
    },
    {
      "epoch": 0.9271599264705882,
      "grad_norm": 1.0895785093307495,
      "learning_rate": 7.679148936170212e-06,
      "loss": 0.09,
      "step": 4035
    },
    {
      "epoch": 0.9273897058823529,
      "grad_norm": 1.15842866897583,
      "learning_rate": 7.678297872340427e-06,
      "loss": 0.0988,
      "step": 4036
    },
    {
      "epoch": 0.9276194852941176,
      "grad_norm": 1.1554127931594849,
      "learning_rate": 7.677446808510639e-06,
      "loss": 0.1236,
      "step": 4037
    },
    {
      "epoch": 0.9278492647058824,
      "grad_norm": 1.059815764427185,
      "learning_rate": 7.676595744680852e-06,
      "loss": 0.1104,
      "step": 4038
    },
    {
      "epoch": 0.9280790441176471,
      "grad_norm": 1.2180122137069702,
      "learning_rate": 7.675744680851065e-06,
      "loss": 0.0858,
      "step": 4039
    },
    {
      "epoch": 0.9283088235294118,
      "grad_norm": 1.2146942615509033,
      "learning_rate": 7.674893617021277e-06,
      "loss": 0.0863,
      "step": 4040
    },
    {
      "epoch": 0.9285386029411765,
      "grad_norm": 1.2077640295028687,
      "learning_rate": 7.67404255319149e-06,
      "loss": 0.1279,
      "step": 4041
    },
    {
      "epoch": 0.9287683823529411,
      "grad_norm": 1.4363727569580078,
      "learning_rate": 7.673191489361703e-06,
      "loss": 0.1159,
      "step": 4042
    },
    {
      "epoch": 0.9289981617647058,
      "grad_norm": 1.1352442502975464,
      "learning_rate": 7.672340425531916e-06,
      "loss": 0.1167,
      "step": 4043
    },
    {
      "epoch": 0.9292279411764706,
      "grad_norm": 1.1612699031829834,
      "learning_rate": 7.671489361702128e-06,
      "loss": 0.0798,
      "step": 4044
    },
    {
      "epoch": 0.9294577205882353,
      "grad_norm": 1.127279281616211,
      "learning_rate": 7.67063829787234e-06,
      "loss": 0.0987,
      "step": 4045
    },
    {
      "epoch": 0.9296875,
      "grad_norm": 1.060018539428711,
      "learning_rate": 7.669787234042554e-06,
      "loss": 0.1011,
      "step": 4046
    },
    {
      "epoch": 0.9299172794117647,
      "grad_norm": 1.0874696969985962,
      "learning_rate": 7.668936170212765e-06,
      "loss": 0.1157,
      "step": 4047
    },
    {
      "epoch": 0.9301470588235294,
      "grad_norm": 0.9696088433265686,
      "learning_rate": 7.66808510638298e-06,
      "loss": 0.0832,
      "step": 4048
    },
    {
      "epoch": 0.9303768382352942,
      "grad_norm": 1.9834531545639038,
      "learning_rate": 7.667234042553192e-06,
      "loss": 0.1622,
      "step": 4049
    },
    {
      "epoch": 0.9306066176470589,
      "grad_norm": 1.285679817199707,
      "learning_rate": 7.666382978723405e-06,
      "loss": 0.0989,
      "step": 4050
    },
    {
      "epoch": 0.9308363970588235,
      "grad_norm": 1.1510138511657715,
      "learning_rate": 7.665531914893618e-06,
      "loss": 0.0844,
      "step": 4051
    },
    {
      "epoch": 0.9310661764705882,
      "grad_norm": 1.1803017854690552,
      "learning_rate": 7.66468085106383e-06,
      "loss": 0.0803,
      "step": 4052
    },
    {
      "epoch": 0.9312959558823529,
      "grad_norm": 1.1719311475753784,
      "learning_rate": 7.663829787234043e-06,
      "loss": 0.1224,
      "step": 4053
    },
    {
      "epoch": 0.9315257352941176,
      "grad_norm": 1.1229407787322998,
      "learning_rate": 7.662978723404256e-06,
      "loss": 0.0984,
      "step": 4054
    },
    {
      "epoch": 0.9317555147058824,
      "grad_norm": 1.2041562795639038,
      "learning_rate": 7.662127659574469e-06,
      "loss": 0.1183,
      "step": 4055
    },
    {
      "epoch": 0.9319852941176471,
      "grad_norm": 1.2581884860992432,
      "learning_rate": 7.66127659574468e-06,
      "loss": 0.1164,
      "step": 4056
    },
    {
      "epoch": 0.9322150735294118,
      "grad_norm": 1.1454700231552124,
      "learning_rate": 7.660425531914894e-06,
      "loss": 0.0873,
      "step": 4057
    },
    {
      "epoch": 0.9324448529411765,
      "grad_norm": 1.4385182857513428,
      "learning_rate": 7.659574468085107e-06,
      "loss": 0.1309,
      "step": 4058
    },
    {
      "epoch": 0.9326746323529411,
      "grad_norm": 1.0106905698776245,
      "learning_rate": 7.65872340425532e-06,
      "loss": 0.0798,
      "step": 4059
    },
    {
      "epoch": 0.9329044117647058,
      "grad_norm": 1.7516531944274902,
      "learning_rate": 7.657872340425533e-06,
      "loss": 0.1899,
      "step": 4060
    },
    {
      "epoch": 0.9331341911764706,
      "grad_norm": 0.8861928582191467,
      "learning_rate": 7.657021276595745e-06,
      "loss": 0.0528,
      "step": 4061
    },
    {
      "epoch": 0.9333639705882353,
      "grad_norm": 1.8906457424163818,
      "learning_rate": 7.656170212765958e-06,
      "loss": 0.0896,
      "step": 4062
    },
    {
      "epoch": 0.93359375,
      "grad_norm": 1.1520594358444214,
      "learning_rate": 7.655319148936171e-06,
      "loss": 0.1007,
      "step": 4063
    },
    {
      "epoch": 0.9338235294117647,
      "grad_norm": 1.336392879486084,
      "learning_rate": 7.654468085106384e-06,
      "loss": 0.0862,
      "step": 4064
    },
    {
      "epoch": 0.9340533088235294,
      "grad_norm": 1.1026252508163452,
      "learning_rate": 7.653617021276596e-06,
      "loss": 0.1116,
      "step": 4065
    },
    {
      "epoch": 0.9342830882352942,
      "grad_norm": 1.3324466943740845,
      "learning_rate": 7.652765957446809e-06,
      "loss": 0.1229,
      "step": 4066
    },
    {
      "epoch": 0.9345128676470589,
      "grad_norm": 1.3463990688323975,
      "learning_rate": 7.651914893617022e-06,
      "loss": 0.0861,
      "step": 4067
    },
    {
      "epoch": 0.9347426470588235,
      "grad_norm": 1.4098623991012573,
      "learning_rate": 7.651063829787234e-06,
      "loss": 0.1106,
      "step": 4068
    },
    {
      "epoch": 0.9349724264705882,
      "grad_norm": 1.0974174737930298,
      "learning_rate": 7.650212765957448e-06,
      "loss": 0.1017,
      "step": 4069
    },
    {
      "epoch": 0.9352022058823529,
      "grad_norm": 1.4139195680618286,
      "learning_rate": 7.64936170212766e-06,
      "loss": 0.122,
      "step": 4070
    },
    {
      "epoch": 0.9354319852941176,
      "grad_norm": 1.1301398277282715,
      "learning_rate": 7.648510638297873e-06,
      "loss": 0.0801,
      "step": 4071
    },
    {
      "epoch": 0.9356617647058824,
      "grad_norm": 1.055558681488037,
      "learning_rate": 7.647659574468086e-06,
      "loss": 0.0969,
      "step": 4072
    },
    {
      "epoch": 0.9358915441176471,
      "grad_norm": 1.3178147077560425,
      "learning_rate": 7.646808510638298e-06,
      "loss": 0.0985,
      "step": 4073
    },
    {
      "epoch": 0.9361213235294118,
      "grad_norm": 1.2237873077392578,
      "learning_rate": 7.645957446808513e-06,
      "loss": 0.1003,
      "step": 4074
    },
    {
      "epoch": 0.9363511029411765,
      "grad_norm": 1.408030390739441,
      "learning_rate": 7.645106382978724e-06,
      "loss": 0.1128,
      "step": 4075
    },
    {
      "epoch": 0.9365808823529411,
      "grad_norm": 1.2703431844711304,
      "learning_rate": 7.644255319148937e-06,
      "loss": 0.1094,
      "step": 4076
    },
    {
      "epoch": 0.9368106617647058,
      "grad_norm": 1.3237117528915405,
      "learning_rate": 7.64340425531915e-06,
      "loss": 0.1241,
      "step": 4077
    },
    {
      "epoch": 0.9370404411764706,
      "grad_norm": 1.0504958629608154,
      "learning_rate": 7.642553191489362e-06,
      "loss": 0.1322,
      "step": 4078
    },
    {
      "epoch": 0.9372702205882353,
      "grad_norm": 0.9855268001556396,
      "learning_rate": 7.641702127659575e-06,
      "loss": 0.0967,
      "step": 4079
    },
    {
      "epoch": 0.9375,
      "grad_norm": 1.9039021730422974,
      "learning_rate": 7.640851063829788e-06,
      "loss": 0.1469,
      "step": 4080
    },
    {
      "epoch": 0.9377297794117647,
      "grad_norm": 1.3106881380081177,
      "learning_rate": 7.640000000000001e-06,
      "loss": 0.1132,
      "step": 4081
    },
    {
      "epoch": 0.9379595588235294,
      "grad_norm": 1.1511197090148926,
      "learning_rate": 7.639148936170213e-06,
      "loss": 0.0986,
      "step": 4082
    },
    {
      "epoch": 0.9381893382352942,
      "grad_norm": 1.1965570449829102,
      "learning_rate": 7.638297872340426e-06,
      "loss": 0.1018,
      "step": 4083
    },
    {
      "epoch": 0.9384191176470589,
      "grad_norm": 1.4366657733917236,
      "learning_rate": 7.63744680851064e-06,
      "loss": 0.1394,
      "step": 4084
    },
    {
      "epoch": 0.9386488970588235,
      "grad_norm": 1.1054966449737549,
      "learning_rate": 7.63659574468085e-06,
      "loss": 0.0912,
      "step": 4085
    },
    {
      "epoch": 0.9388786764705882,
      "grad_norm": 1.2795078754425049,
      "learning_rate": 7.635744680851066e-06,
      "loss": 0.098,
      "step": 4086
    },
    {
      "epoch": 0.9391084558823529,
      "grad_norm": 1.0380288362503052,
      "learning_rate": 7.634893617021277e-06,
      "loss": 0.0787,
      "step": 4087
    },
    {
      "epoch": 0.9393382352941176,
      "grad_norm": 1.3320432901382446,
      "learning_rate": 7.63404255319149e-06,
      "loss": 0.1491,
      "step": 4088
    },
    {
      "epoch": 0.9395680147058824,
      "grad_norm": 1.0011906623840332,
      "learning_rate": 7.633191489361703e-06,
      "loss": 0.0801,
      "step": 4089
    },
    {
      "epoch": 0.9397977941176471,
      "grad_norm": 1.0265189409255981,
      "learning_rate": 7.632340425531915e-06,
      "loss": 0.0763,
      "step": 4090
    },
    {
      "epoch": 0.9400275735294118,
      "grad_norm": 1.5825732946395874,
      "learning_rate": 7.631489361702128e-06,
      "loss": 0.1073,
      "step": 4091
    },
    {
      "epoch": 0.9402573529411765,
      "grad_norm": 1.3388845920562744,
      "learning_rate": 7.630638297872341e-06,
      "loss": 0.1368,
      "step": 4092
    },
    {
      "epoch": 0.9404871323529411,
      "grad_norm": 1.4305858612060547,
      "learning_rate": 7.629787234042554e-06,
      "loss": 0.1064,
      "step": 4093
    },
    {
      "epoch": 0.9407169117647058,
      "grad_norm": 1.4449065923690796,
      "learning_rate": 7.628936170212766e-06,
      "loss": 0.0846,
      "step": 4094
    },
    {
      "epoch": 0.9409466911764706,
      "grad_norm": 1.1492711305618286,
      "learning_rate": 7.62808510638298e-06,
      "loss": 0.1063,
      "step": 4095
    },
    {
      "epoch": 0.9411764705882353,
      "grad_norm": 1.2577269077301025,
      "learning_rate": 7.627234042553192e-06,
      "loss": 0.0979,
      "step": 4096
    },
    {
      "epoch": 0.94140625,
      "grad_norm": 1.4134777784347534,
      "learning_rate": 7.6263829787234045e-06,
      "loss": 0.0846,
      "step": 4097
    },
    {
      "epoch": 0.9416360294117647,
      "grad_norm": 1.2493582963943481,
      "learning_rate": 7.625531914893618e-06,
      "loss": 0.1113,
      "step": 4098
    },
    {
      "epoch": 0.9418658088235294,
      "grad_norm": 1.1881414651870728,
      "learning_rate": 7.62468085106383e-06,
      "loss": 0.0903,
      "step": 4099
    },
    {
      "epoch": 0.9420955882352942,
      "grad_norm": 1.6496353149414062,
      "learning_rate": 7.623829787234043e-06,
      "loss": 0.1108,
      "step": 4100
    },
    {
      "epoch": 0.9423253676470589,
      "grad_norm": 1.537723422050476,
      "learning_rate": 7.622978723404256e-06,
      "loss": 0.1303,
      "step": 4101
    },
    {
      "epoch": 0.9425551470588235,
      "grad_norm": 2.1333160400390625,
      "learning_rate": 7.622127659574469e-06,
      "loss": 0.1414,
      "step": 4102
    },
    {
      "epoch": 0.9427849264705882,
      "grad_norm": 1.285516381263733,
      "learning_rate": 7.621276595744681e-06,
      "loss": 0.1059,
      "step": 4103
    },
    {
      "epoch": 0.9430147058823529,
      "grad_norm": 1.6979072093963623,
      "learning_rate": 7.620425531914894e-06,
      "loss": 0.1302,
      "step": 4104
    },
    {
      "epoch": 0.9432444852941176,
      "grad_norm": 1.0554304122924805,
      "learning_rate": 7.619574468085107e-06,
      "loss": 0.1056,
      "step": 4105
    },
    {
      "epoch": 0.9434742647058824,
      "grad_norm": 1.4058873653411865,
      "learning_rate": 7.61872340425532e-06,
      "loss": 0.0854,
      "step": 4106
    },
    {
      "epoch": 0.9437040441176471,
      "grad_norm": 1.1915936470031738,
      "learning_rate": 7.617872340425533e-06,
      "loss": 0.0825,
      "step": 4107
    },
    {
      "epoch": 0.9439338235294118,
      "grad_norm": 1.2559053897857666,
      "learning_rate": 7.617021276595745e-06,
      "loss": 0.0825,
      "step": 4108
    },
    {
      "epoch": 0.9441636029411765,
      "grad_norm": 1.363041639328003,
      "learning_rate": 7.6161702127659575e-06,
      "loss": 0.0696,
      "step": 4109
    },
    {
      "epoch": 0.9443933823529411,
      "grad_norm": 1.0462833642959595,
      "learning_rate": 7.6153191489361715e-06,
      "loss": 0.0791,
      "step": 4110
    },
    {
      "epoch": 0.9446231617647058,
      "grad_norm": 1.3867017030715942,
      "learning_rate": 7.614468085106384e-06,
      "loss": 0.0764,
      "step": 4111
    },
    {
      "epoch": 0.9448529411764706,
      "grad_norm": 1.5948967933654785,
      "learning_rate": 7.613617021276596e-06,
      "loss": 0.1255,
      "step": 4112
    },
    {
      "epoch": 0.9450827205882353,
      "grad_norm": 1.0112553834915161,
      "learning_rate": 7.612765957446809e-06,
      "loss": 0.09,
      "step": 4113
    },
    {
      "epoch": 0.9453125,
      "grad_norm": 1.4201825857162476,
      "learning_rate": 7.611914893617022e-06,
      "loss": 0.1177,
      "step": 4114
    },
    {
      "epoch": 0.9455422794117647,
      "grad_norm": 1.6461225748062134,
      "learning_rate": 7.611063829787234e-06,
      "loss": 0.139,
      "step": 4115
    },
    {
      "epoch": 0.9457720588235294,
      "grad_norm": 1.0287823677062988,
      "learning_rate": 7.610212765957448e-06,
      "loss": 0.0679,
      "step": 4116
    },
    {
      "epoch": 0.9460018382352942,
      "grad_norm": 1.7245527505874634,
      "learning_rate": 7.60936170212766e-06,
      "loss": 0.1094,
      "step": 4117
    },
    {
      "epoch": 0.9462316176470589,
      "grad_norm": 1.1364988088607788,
      "learning_rate": 7.6085106382978735e-06,
      "loss": 0.1042,
      "step": 4118
    },
    {
      "epoch": 0.9464613970588235,
      "grad_norm": 1.098548412322998,
      "learning_rate": 7.607659574468086e-06,
      "loss": 0.0727,
      "step": 4119
    },
    {
      "epoch": 0.9466911764705882,
      "grad_norm": 1.366722822189331,
      "learning_rate": 7.606808510638298e-06,
      "loss": 0.0863,
      "step": 4120
    },
    {
      "epoch": 0.9469209558823529,
      "grad_norm": 1.1780904531478882,
      "learning_rate": 7.605957446808512e-06,
      "loss": 0.1026,
      "step": 4121
    },
    {
      "epoch": 0.9471507352941176,
      "grad_norm": 1.181145429611206,
      "learning_rate": 7.6051063829787244e-06,
      "loss": 0.095,
      "step": 4122
    },
    {
      "epoch": 0.9473805147058824,
      "grad_norm": 1.2016403675079346,
      "learning_rate": 7.604255319148937e-06,
      "loss": 0.1002,
      "step": 4123
    },
    {
      "epoch": 0.9476102941176471,
      "grad_norm": 1.4041577577590942,
      "learning_rate": 7.60340425531915e-06,
      "loss": 0.0833,
      "step": 4124
    },
    {
      "epoch": 0.9478400735294118,
      "grad_norm": 1.3724852800369263,
      "learning_rate": 7.602553191489362e-06,
      "loss": 0.121,
      "step": 4125
    },
    {
      "epoch": 0.9480698529411765,
      "grad_norm": 1.3111329078674316,
      "learning_rate": 7.601702127659575e-06,
      "loss": 0.1135,
      "step": 4126
    },
    {
      "epoch": 0.9482996323529411,
      "grad_norm": 1.3762428760528564,
      "learning_rate": 7.600851063829789e-06,
      "loss": 0.1011,
      "step": 4127
    },
    {
      "epoch": 0.9485294117647058,
      "grad_norm": 1.0627470016479492,
      "learning_rate": 7.600000000000001e-06,
      "loss": 0.0854,
      "step": 4128
    },
    {
      "epoch": 0.9487591911764706,
      "grad_norm": 1.2101109027862549,
      "learning_rate": 7.599148936170213e-06,
      "loss": 0.092,
      "step": 4129
    },
    {
      "epoch": 0.9489889705882353,
      "grad_norm": 1.1406047344207764,
      "learning_rate": 7.598297872340426e-06,
      "loss": 0.0951,
      "step": 4130
    },
    {
      "epoch": 0.94921875,
      "grad_norm": 1.087123155593872,
      "learning_rate": 7.597446808510639e-06,
      "loss": 0.0494,
      "step": 4131
    },
    {
      "epoch": 0.9494485294117647,
      "grad_norm": 1.014739990234375,
      "learning_rate": 7.596595744680851e-06,
      "loss": 0.0867,
      "step": 4132
    },
    {
      "epoch": 0.9496783088235294,
      "grad_norm": 1.77139151096344,
      "learning_rate": 7.595744680851065e-06,
      "loss": 0.1253,
      "step": 4133
    },
    {
      "epoch": 0.9499080882352942,
      "grad_norm": 1.0565041303634644,
      "learning_rate": 7.594893617021277e-06,
      "loss": 0.0959,
      "step": 4134
    },
    {
      "epoch": 0.9501378676470589,
      "grad_norm": 1.1706359386444092,
      "learning_rate": 7.59404255319149e-06,
      "loss": 0.0691,
      "step": 4135
    },
    {
      "epoch": 0.9503676470588235,
      "grad_norm": 1.295428991317749,
      "learning_rate": 7.593191489361703e-06,
      "loss": 0.1035,
      "step": 4136
    },
    {
      "epoch": 0.9505974264705882,
      "grad_norm": 1.423825979232788,
      "learning_rate": 7.592340425531915e-06,
      "loss": 0.102,
      "step": 4137
    },
    {
      "epoch": 0.9508272058823529,
      "grad_norm": 1.2405844926834106,
      "learning_rate": 7.5914893617021276e-06,
      "loss": 0.1145,
      "step": 4138
    },
    {
      "epoch": 0.9510569852941176,
      "grad_norm": 1.4426467418670654,
      "learning_rate": 7.5906382978723416e-06,
      "loss": 0.1098,
      "step": 4139
    },
    {
      "epoch": 0.9512867647058824,
      "grad_norm": 1.464752197265625,
      "learning_rate": 7.589787234042554e-06,
      "loss": 0.1127,
      "step": 4140
    },
    {
      "epoch": 0.9515165441176471,
      "grad_norm": 0.9791284203529358,
      "learning_rate": 7.588936170212766e-06,
      "loss": 0.068,
      "step": 4141
    },
    {
      "epoch": 0.9517463235294118,
      "grad_norm": 1.9055622816085815,
      "learning_rate": 7.588085106382979e-06,
      "loss": 0.1364,
      "step": 4142
    },
    {
      "epoch": 0.9519761029411765,
      "grad_norm": 1.5259690284729004,
      "learning_rate": 7.587234042553192e-06,
      "loss": 0.1329,
      "step": 4143
    },
    {
      "epoch": 0.9522058823529411,
      "grad_norm": 1.2768031358718872,
      "learning_rate": 7.586382978723405e-06,
      "loss": 0.1174,
      "step": 4144
    },
    {
      "epoch": 0.9524356617647058,
      "grad_norm": 1.0382672548294067,
      "learning_rate": 7.585531914893618e-06,
      "loss": 0.1028,
      "step": 4145
    },
    {
      "epoch": 0.9526654411764706,
      "grad_norm": 1.4776129722595215,
      "learning_rate": 7.58468085106383e-06,
      "loss": 0.1089,
      "step": 4146
    },
    {
      "epoch": 0.9528952205882353,
      "grad_norm": 1.0673010349273682,
      "learning_rate": 7.583829787234043e-06,
      "loss": 0.0731,
      "step": 4147
    },
    {
      "epoch": 0.953125,
      "grad_norm": 1.0460741519927979,
      "learning_rate": 7.582978723404256e-06,
      "loss": 0.0826,
      "step": 4148
    },
    {
      "epoch": 0.9533547794117647,
      "grad_norm": 1.028088927268982,
      "learning_rate": 7.582127659574468e-06,
      "loss": 0.104,
      "step": 4149
    },
    {
      "epoch": 0.9535845588235294,
      "grad_norm": 1.845752239227295,
      "learning_rate": 7.581276595744681e-06,
      "loss": 0.1029,
      "step": 4150
    },
    {
      "epoch": 0.9538143382352942,
      "grad_norm": 1.5236541032791138,
      "learning_rate": 7.5804255319148945e-06,
      "loss": 0.1083,
      "step": 4151
    },
    {
      "epoch": 0.9540441176470589,
      "grad_norm": 1.009938359260559,
      "learning_rate": 7.579574468085107e-06,
      "loss": 0.0793,
      "step": 4152
    },
    {
      "epoch": 0.9542738970588235,
      "grad_norm": 1.177505373954773,
      "learning_rate": 7.578723404255319e-06,
      "loss": 0.1016,
      "step": 4153
    },
    {
      "epoch": 0.9545036764705882,
      "grad_norm": 0.9409394264221191,
      "learning_rate": 7.577872340425532e-06,
      "loss": 0.0867,
      "step": 4154
    },
    {
      "epoch": 0.9547334558823529,
      "grad_norm": 1.8750396966934204,
      "learning_rate": 7.5770212765957455e-06,
      "loss": 0.1194,
      "step": 4155
    },
    {
      "epoch": 0.9549632352941176,
      "grad_norm": 1.4228606224060059,
      "learning_rate": 7.576170212765958e-06,
      "loss": 0.1046,
      "step": 4156
    },
    {
      "epoch": 0.9551930147058824,
      "grad_norm": 1.1557422876358032,
      "learning_rate": 7.575319148936171e-06,
      "loss": 0.0892,
      "step": 4157
    },
    {
      "epoch": 0.9554227941176471,
      "grad_norm": 1.2773430347442627,
      "learning_rate": 7.574468085106383e-06,
      "loss": 0.1185,
      "step": 4158
    },
    {
      "epoch": 0.9556525735294118,
      "grad_norm": 1.2083650827407837,
      "learning_rate": 7.573617021276596e-06,
      "loss": 0.1151,
      "step": 4159
    },
    {
      "epoch": 0.9558823529411765,
      "grad_norm": 1.389163851737976,
      "learning_rate": 7.57276595744681e-06,
      "loss": 0.1128,
      "step": 4160
    },
    {
      "epoch": 0.9561121323529411,
      "grad_norm": 1.3417035341262817,
      "learning_rate": 7.571914893617022e-06,
      "loss": 0.1137,
      "step": 4161
    },
    {
      "epoch": 0.9563419117647058,
      "grad_norm": 1.1134097576141357,
      "learning_rate": 7.571063829787235e-06,
      "loss": 0.0816,
      "step": 4162
    },
    {
      "epoch": 0.9565716911764706,
      "grad_norm": 1.2079859972000122,
      "learning_rate": 7.5702127659574475e-06,
      "loss": 0.1033,
      "step": 4163
    },
    {
      "epoch": 0.9568014705882353,
      "grad_norm": 1.7472342252731323,
      "learning_rate": 7.56936170212766e-06,
      "loss": 0.1,
      "step": 4164
    },
    {
      "epoch": 0.95703125,
      "grad_norm": 1.142410397529602,
      "learning_rate": 7.568510638297874e-06,
      "loss": 0.1063,
      "step": 4165
    },
    {
      "epoch": 0.9572610294117647,
      "grad_norm": 1.219874382019043,
      "learning_rate": 7.567659574468086e-06,
      "loss": 0.1047,
      "step": 4166
    },
    {
      "epoch": 0.9574908088235294,
      "grad_norm": 0.9592651724815369,
      "learning_rate": 7.5668085106382985e-06,
      "loss": 0.0788,
      "step": 4167
    },
    {
      "epoch": 0.9577205882352942,
      "grad_norm": 0.8685034513473511,
      "learning_rate": 7.565957446808512e-06,
      "loss": 0.1129,
      "step": 4168
    },
    {
      "epoch": 0.9579503676470589,
      "grad_norm": 1.0830544233322144,
      "learning_rate": 7.565106382978724e-06,
      "loss": 0.0952,
      "step": 4169
    },
    {
      "epoch": 0.9581801470588235,
      "grad_norm": 1.149048924446106,
      "learning_rate": 7.564255319148936e-06,
      "loss": 0.1194,
      "step": 4170
    },
    {
      "epoch": 0.9584099264705882,
      "grad_norm": 1.0934199094772339,
      "learning_rate": 7.56340425531915e-06,
      "loss": 0.1014,
      "step": 4171
    },
    {
      "epoch": 0.9586397058823529,
      "grad_norm": 1.0563637018203735,
      "learning_rate": 7.562553191489363e-06,
      "loss": 0.0939,
      "step": 4172
    },
    {
      "epoch": 0.9588694852941176,
      "grad_norm": 1.4705482721328735,
      "learning_rate": 7.561702127659575e-06,
      "loss": 0.1453,
      "step": 4173
    },
    {
      "epoch": 0.9590992647058824,
      "grad_norm": 1.0814456939697266,
      "learning_rate": 7.560851063829788e-06,
      "loss": 0.1053,
      "step": 4174
    },
    {
      "epoch": 0.9593290441176471,
      "grad_norm": 1.2166534662246704,
      "learning_rate": 7.5600000000000005e-06,
      "loss": 0.0947,
      "step": 4175
    },
    {
      "epoch": 0.9595588235294118,
      "grad_norm": 1.2493860721588135,
      "learning_rate": 7.559148936170213e-06,
      "loss": 0.0923,
      "step": 4176
    },
    {
      "epoch": 0.9597886029411765,
      "grad_norm": 1.341681718826294,
      "learning_rate": 7.558297872340427e-06,
      "loss": 0.1139,
      "step": 4177
    },
    {
      "epoch": 0.9600183823529411,
      "grad_norm": 1.081628441810608,
      "learning_rate": 7.557446808510639e-06,
      "loss": 0.1046,
      "step": 4178
    },
    {
      "epoch": 0.9602481617647058,
      "grad_norm": 0.9947285056114197,
      "learning_rate": 7.5565957446808515e-06,
      "loss": 0.0791,
      "step": 4179
    },
    {
      "epoch": 0.9604779411764706,
      "grad_norm": 0.9382660984992981,
      "learning_rate": 7.555744680851065e-06,
      "loss": 0.077,
      "step": 4180
    },
    {
      "epoch": 0.9607077205882353,
      "grad_norm": 0.9927186369895935,
      "learning_rate": 7.554893617021277e-06,
      "loss": 0.0788,
      "step": 4181
    },
    {
      "epoch": 0.9609375,
      "grad_norm": 1.394717812538147,
      "learning_rate": 7.554042553191489e-06,
      "loss": 0.1188,
      "step": 4182
    },
    {
      "epoch": 0.9611672794117647,
      "grad_norm": 0.8942049145698547,
      "learning_rate": 7.553191489361703e-06,
      "loss": 0.0989,
      "step": 4183
    },
    {
      "epoch": 0.9613970588235294,
      "grad_norm": 1.1031016111373901,
      "learning_rate": 7.552340425531916e-06,
      "loss": 0.0757,
      "step": 4184
    },
    {
      "epoch": 0.9616268382352942,
      "grad_norm": 1.702350378036499,
      "learning_rate": 7.551489361702128e-06,
      "loss": 0.1564,
      "step": 4185
    },
    {
      "epoch": 0.9618566176470589,
      "grad_norm": 1.149850845336914,
      "learning_rate": 7.550638297872341e-06,
      "loss": 0.1023,
      "step": 4186
    },
    {
      "epoch": 0.9620863970588235,
      "grad_norm": 1.0300073623657227,
      "learning_rate": 7.5497872340425534e-06,
      "loss": 0.0939,
      "step": 4187
    },
    {
      "epoch": 0.9623161764705882,
      "grad_norm": 1.426215648651123,
      "learning_rate": 7.548936170212766e-06,
      "loss": 0.077,
      "step": 4188
    },
    {
      "epoch": 0.9625459558823529,
      "grad_norm": 0.7617654204368591,
      "learning_rate": 7.54808510638298e-06,
      "loss": 0.0705,
      "step": 4189
    },
    {
      "epoch": 0.9627757352941176,
      "grad_norm": 1.2382339239120483,
      "learning_rate": 7.547234042553192e-06,
      "loss": 0.0907,
      "step": 4190
    },
    {
      "epoch": 0.9630055147058824,
      "grad_norm": 1.0617434978485107,
      "learning_rate": 7.546382978723404e-06,
      "loss": 0.0722,
      "step": 4191
    },
    {
      "epoch": 0.9632352941176471,
      "grad_norm": 1.1503998041152954,
      "learning_rate": 7.545531914893618e-06,
      "loss": 0.089,
      "step": 4192
    },
    {
      "epoch": 0.9634650735294118,
      "grad_norm": 1.4239919185638428,
      "learning_rate": 7.54468085106383e-06,
      "loss": 0.1032,
      "step": 4193
    },
    {
      "epoch": 0.9636948529411765,
      "grad_norm": 1.1675996780395508,
      "learning_rate": 7.543829787234043e-06,
      "loss": 0.1151,
      "step": 4194
    },
    {
      "epoch": 0.9639246323529411,
      "grad_norm": 1.5945273637771606,
      "learning_rate": 7.542978723404256e-06,
      "loss": 0.1205,
      "step": 4195
    },
    {
      "epoch": 0.9641544117647058,
      "grad_norm": 1.4951378107070923,
      "learning_rate": 7.5421276595744686e-06,
      "loss": 0.107,
      "step": 4196
    },
    {
      "epoch": 0.9643841911764706,
      "grad_norm": 1.251268982887268,
      "learning_rate": 7.541276595744681e-06,
      "loss": 0.1012,
      "step": 4197
    },
    {
      "epoch": 0.9646139705882353,
      "grad_norm": 1.7211254835128784,
      "learning_rate": 7.540425531914894e-06,
      "loss": 0.135,
      "step": 4198
    },
    {
      "epoch": 0.96484375,
      "grad_norm": 1.0428564548492432,
      "learning_rate": 7.539574468085107e-06,
      "loss": 0.102,
      "step": 4199
    },
    {
      "epoch": 0.9650735294117647,
      "grad_norm": 1.110470175743103,
      "learning_rate": 7.5387234042553196e-06,
      "loss": 0.0907,
      "step": 4200
    },
    {
      "epoch": 0.9653033088235294,
      "grad_norm": 1.1118375062942505,
      "learning_rate": 7.537872340425533e-06,
      "loss": 0.084,
      "step": 4201
    },
    {
      "epoch": 0.9655330882352942,
      "grad_norm": 1.473045825958252,
      "learning_rate": 7.537021276595745e-06,
      "loss": 0.1176,
      "step": 4202
    },
    {
      "epoch": 0.9657628676470589,
      "grad_norm": 1.4112205505371094,
      "learning_rate": 7.536170212765958e-06,
      "loss": 0.1321,
      "step": 4203
    },
    {
      "epoch": 0.9659926470588235,
      "grad_norm": 1.2140291929244995,
      "learning_rate": 7.535319148936171e-06,
      "loss": 0.102,
      "step": 4204
    },
    {
      "epoch": 0.9662224264705882,
      "grad_norm": 1.0636783838272095,
      "learning_rate": 7.534468085106384e-06,
      "loss": 0.1057,
      "step": 4205
    },
    {
      "epoch": 0.9664522058823529,
      "grad_norm": 1.1011494398117065,
      "learning_rate": 7.533617021276597e-06,
      "loss": 0.0811,
      "step": 4206
    },
    {
      "epoch": 0.9666819852941176,
      "grad_norm": 1.0449285507202148,
      "learning_rate": 7.532765957446809e-06,
      "loss": 0.0885,
      "step": 4207
    },
    {
      "epoch": 0.9669117647058824,
      "grad_norm": 1.4305397272109985,
      "learning_rate": 7.5319148936170215e-06,
      "loss": 0.0787,
      "step": 4208
    },
    {
      "epoch": 0.9671415441176471,
      "grad_norm": 1.1988016366958618,
      "learning_rate": 7.5310638297872356e-06,
      "loss": 0.0696,
      "step": 4209
    },
    {
      "epoch": 0.9673713235294118,
      "grad_norm": 1.2354782819747925,
      "learning_rate": 7.530212765957448e-06,
      "loss": 0.1009,
      "step": 4210
    },
    {
      "epoch": 0.9676011029411765,
      "grad_norm": 1.0597901344299316,
      "learning_rate": 7.52936170212766e-06,
      "loss": 0.0797,
      "step": 4211
    },
    {
      "epoch": 0.9678308823529411,
      "grad_norm": 1.086582064628601,
      "learning_rate": 7.528510638297873e-06,
      "loss": 0.1077,
      "step": 4212
    },
    {
      "epoch": 0.9680606617647058,
      "grad_norm": 1.4260159730911255,
      "learning_rate": 7.527659574468086e-06,
      "loss": 0.1261,
      "step": 4213
    },
    {
      "epoch": 0.9682904411764706,
      "grad_norm": 1.8973238468170166,
      "learning_rate": 7.526808510638298e-06,
      "loss": 0.1355,
      "step": 4214
    },
    {
      "epoch": 0.9685202205882353,
      "grad_norm": 1.2337541580200195,
      "learning_rate": 7.525957446808512e-06,
      "loss": 0.0857,
      "step": 4215
    },
    {
      "epoch": 0.96875,
      "grad_norm": 1.7206602096557617,
      "learning_rate": 7.525106382978724e-06,
      "loss": 0.076,
      "step": 4216
    },
    {
      "epoch": 0.9689797794117647,
      "grad_norm": 1.9115166664123535,
      "learning_rate": 7.524255319148937e-06,
      "loss": 0.0969,
      "step": 4217
    },
    {
      "epoch": 0.9692095588235294,
      "grad_norm": 1.135796308517456,
      "learning_rate": 7.52340425531915e-06,
      "loss": 0.0844,
      "step": 4218
    },
    {
      "epoch": 0.9694393382352942,
      "grad_norm": 1.2036458253860474,
      "learning_rate": 7.522553191489362e-06,
      "loss": 0.1153,
      "step": 4219
    },
    {
      "epoch": 0.9696691176470589,
      "grad_norm": 1.4165810346603394,
      "learning_rate": 7.5217021276595745e-06,
      "loss": 0.1108,
      "step": 4220
    },
    {
      "epoch": 0.9698988970588235,
      "grad_norm": 1.3008754253387451,
      "learning_rate": 7.5208510638297885e-06,
      "loss": 0.1142,
      "step": 4221
    },
    {
      "epoch": 0.9701286764705882,
      "grad_norm": 0.8740533590316772,
      "learning_rate": 7.520000000000001e-06,
      "loss": 0.061,
      "step": 4222
    },
    {
      "epoch": 0.9703584558823529,
      "grad_norm": 1.487960934638977,
      "learning_rate": 7.519148936170213e-06,
      "loss": 0.1178,
      "step": 4223
    },
    {
      "epoch": 0.9705882352941176,
      "grad_norm": 1.4012264013290405,
      "learning_rate": 7.518297872340426e-06,
      "loss": 0.08,
      "step": 4224
    },
    {
      "epoch": 0.9708180147058824,
      "grad_norm": 1.0845915079116821,
      "learning_rate": 7.517446808510639e-06,
      "loss": 0.0717,
      "step": 4225
    },
    {
      "epoch": 0.9710477941176471,
      "grad_norm": 1.3629869222640991,
      "learning_rate": 7.516595744680851e-06,
      "loss": 0.1122,
      "step": 4226
    },
    {
      "epoch": 0.9712775735294118,
      "grad_norm": 1.0512301921844482,
      "learning_rate": 7.515744680851065e-06,
      "loss": 0.0868,
      "step": 4227
    },
    {
      "epoch": 0.9715073529411765,
      "grad_norm": 1.1189796924591064,
      "learning_rate": 7.514893617021277e-06,
      "loss": 0.0855,
      "step": 4228
    },
    {
      "epoch": 0.9717371323529411,
      "grad_norm": 1.56486177444458,
      "learning_rate": 7.51404255319149e-06,
      "loss": 0.121,
      "step": 4229
    },
    {
      "epoch": 0.9719669117647058,
      "grad_norm": 1.6549772024154663,
      "learning_rate": 7.513191489361703e-06,
      "loss": 0.1175,
      "step": 4230
    },
    {
      "epoch": 0.9721966911764706,
      "grad_norm": 1.4793336391448975,
      "learning_rate": 7.512340425531915e-06,
      "loss": 0.1139,
      "step": 4231
    },
    {
      "epoch": 0.9724264705882353,
      "grad_norm": 1.5327609777450562,
      "learning_rate": 7.5114893617021275e-06,
      "loss": 0.1424,
      "step": 4232
    },
    {
      "epoch": 0.97265625,
      "grad_norm": 1.120924472808838,
      "learning_rate": 7.5106382978723415e-06,
      "loss": 0.127,
      "step": 4233
    },
    {
      "epoch": 0.9728860294117647,
      "grad_norm": 1.1114178895950317,
      "learning_rate": 7.509787234042554e-06,
      "loss": 0.0976,
      "step": 4234
    },
    {
      "epoch": 0.9731158088235294,
      "grad_norm": 1.2236409187316895,
      "learning_rate": 7.508936170212766e-06,
      "loss": 0.0982,
      "step": 4235
    },
    {
      "epoch": 0.9733455882352942,
      "grad_norm": 1.061834692955017,
      "learning_rate": 7.508085106382979e-06,
      "loss": 0.0707,
      "step": 4236
    },
    {
      "epoch": 0.9735753676470589,
      "grad_norm": 1.0284618139266968,
      "learning_rate": 7.507234042553192e-06,
      "loss": 0.0805,
      "step": 4237
    },
    {
      "epoch": 0.9738051470588235,
      "grad_norm": 1.1688189506530762,
      "learning_rate": 7.506382978723405e-06,
      "loss": 0.118,
      "step": 4238
    },
    {
      "epoch": 0.9740349264705882,
      "grad_norm": 0.9912676215171814,
      "learning_rate": 7.505531914893618e-06,
      "loss": 0.0998,
      "step": 4239
    },
    {
      "epoch": 0.9742647058823529,
      "grad_norm": 1.2086058855056763,
      "learning_rate": 7.50468085106383e-06,
      "loss": 0.0817,
      "step": 4240
    },
    {
      "epoch": 0.9744944852941176,
      "grad_norm": 1.3495843410491943,
      "learning_rate": 7.503829787234043e-06,
      "loss": 0.1014,
      "step": 4241
    },
    {
      "epoch": 0.9747242647058824,
      "grad_norm": 1.1885699033737183,
      "learning_rate": 7.502978723404256e-06,
      "loss": 0.1033,
      "step": 4242
    },
    {
      "epoch": 0.9749540441176471,
      "grad_norm": 1.3218475580215454,
      "learning_rate": 7.502127659574469e-06,
      "loss": 0.1169,
      "step": 4243
    },
    {
      "epoch": 0.9751838235294118,
      "grad_norm": 1.0445914268493652,
      "learning_rate": 7.501276595744681e-06,
      "loss": 0.0698,
      "step": 4244
    },
    {
      "epoch": 0.9754136029411765,
      "grad_norm": 1.3979984521865845,
      "learning_rate": 7.5004255319148945e-06,
      "loss": 0.0752,
      "step": 4245
    },
    {
      "epoch": 0.9756433823529411,
      "grad_norm": 0.9502307176589966,
      "learning_rate": 7.499574468085107e-06,
      "loss": 0.0833,
      "step": 4246
    },
    {
      "epoch": 0.9758731617647058,
      "grad_norm": 1.089142084121704,
      "learning_rate": 7.49872340425532e-06,
      "loss": 0.0966,
      "step": 4247
    },
    {
      "epoch": 0.9761029411764706,
      "grad_norm": 1.0092086791992188,
      "learning_rate": 7.497872340425532e-06,
      "loss": 0.0825,
      "step": 4248
    },
    {
      "epoch": 0.9763327205882353,
      "grad_norm": 1.418516993522644,
      "learning_rate": 7.4970212765957454e-06,
      "loss": 0.063,
      "step": 4249
    },
    {
      "epoch": 0.9765625,
      "grad_norm": 4.121852397918701,
      "learning_rate": 7.496170212765959e-06,
      "loss": 0.1287,
      "step": 4250
    },
    {
      "epoch": 0.9767922794117647,
      "grad_norm": 1.3354370594024658,
      "learning_rate": 7.495319148936171e-06,
      "loss": 0.0846,
      "step": 4251
    },
    {
      "epoch": 0.9770220588235294,
      "grad_norm": 0.8232400417327881,
      "learning_rate": 7.494468085106383e-06,
      "loss": 0.087,
      "step": 4252
    },
    {
      "epoch": 0.9772518382352942,
      "grad_norm": 1.369368076324463,
      "learning_rate": 7.4936170212765964e-06,
      "loss": 0.086,
      "step": 4253
    },
    {
      "epoch": 0.9774816176470589,
      "grad_norm": 0.8742602467536926,
      "learning_rate": 7.49276595744681e-06,
      "loss": 0.0649,
      "step": 4254
    },
    {
      "epoch": 0.9777113970588235,
      "grad_norm": 1.1827476024627686,
      "learning_rate": 7.491914893617022e-06,
      "loss": 0.1018,
      "step": 4255
    },
    {
      "epoch": 0.9779411764705882,
      "grad_norm": 1.545814037322998,
      "learning_rate": 7.491063829787235e-06,
      "loss": 0.1328,
      "step": 4256
    },
    {
      "epoch": 0.9781709558823529,
      "grad_norm": 1.2123805284500122,
      "learning_rate": 7.490212765957447e-06,
      "loss": 0.1065,
      "step": 4257
    },
    {
      "epoch": 0.9784007352941176,
      "grad_norm": 1.413154125213623,
      "learning_rate": 7.48936170212766e-06,
      "loss": 0.1686,
      "step": 4258
    },
    {
      "epoch": 0.9786305147058824,
      "grad_norm": 1.1068625450134277,
      "learning_rate": 7.488510638297874e-06,
      "loss": 0.1114,
      "step": 4259
    },
    {
      "epoch": 0.9788602941176471,
      "grad_norm": 1.6635363101959229,
      "learning_rate": 7.487659574468086e-06,
      "loss": 0.1166,
      "step": 4260
    },
    {
      "epoch": 0.9790900735294118,
      "grad_norm": 1.101272702217102,
      "learning_rate": 7.486808510638298e-06,
      "loss": 0.0849,
      "step": 4261
    },
    {
      "epoch": 0.9793198529411765,
      "grad_norm": 1.0905630588531494,
      "learning_rate": 7.4859574468085116e-06,
      "loss": 0.0898,
      "step": 4262
    },
    {
      "epoch": 0.9795496323529411,
      "grad_norm": 1.057581901550293,
      "learning_rate": 7.485106382978724e-06,
      "loss": 0.0792,
      "step": 4263
    },
    {
      "epoch": 0.9797794117647058,
      "grad_norm": 1.267546534538269,
      "learning_rate": 7.484255319148936e-06,
      "loss": 0.0925,
      "step": 4264
    },
    {
      "epoch": 0.9800091911764706,
      "grad_norm": 1.2108557224273682,
      "learning_rate": 7.48340425531915e-06,
      "loss": 0.0738,
      "step": 4265
    },
    {
      "epoch": 0.9802389705882353,
      "grad_norm": 1.5247882604599,
      "learning_rate": 7.4825531914893626e-06,
      "loss": 0.0843,
      "step": 4266
    },
    {
      "epoch": 0.98046875,
      "grad_norm": 0.9812960028648376,
      "learning_rate": 7.481702127659575e-06,
      "loss": 0.0854,
      "step": 4267
    },
    {
      "epoch": 0.9806985294117647,
      "grad_norm": 1.009085774421692,
      "learning_rate": 7.480851063829788e-06,
      "loss": 0.0943,
      "step": 4268
    },
    {
      "epoch": 0.9809283088235294,
      "grad_norm": 1.5397192239761353,
      "learning_rate": 7.48e-06,
      "loss": 0.1164,
      "step": 4269
    },
    {
      "epoch": 0.9811580882352942,
      "grad_norm": 1.155052900314331,
      "learning_rate": 7.479148936170213e-06,
      "loss": 0.1021,
      "step": 4270
    },
    {
      "epoch": 0.9813878676470589,
      "grad_norm": 1.2093771696090698,
      "learning_rate": 7.478297872340427e-06,
      "loss": 0.0755,
      "step": 4271
    },
    {
      "epoch": 0.9816176470588235,
      "grad_norm": 2.0353453159332275,
      "learning_rate": 7.477446808510639e-06,
      "loss": 0.095,
      "step": 4272
    },
    {
      "epoch": 0.9818474264705882,
      "grad_norm": 1.111619234085083,
      "learning_rate": 7.476595744680851e-06,
      "loss": 0.0893,
      "step": 4273
    },
    {
      "epoch": 0.9820772058823529,
      "grad_norm": 1.149674415588379,
      "learning_rate": 7.4757446808510645e-06,
      "loss": 0.0867,
      "step": 4274
    },
    {
      "epoch": 0.9823069852941176,
      "grad_norm": 1.4015647172927856,
      "learning_rate": 7.474893617021277e-06,
      "loss": 0.0892,
      "step": 4275
    },
    {
      "epoch": 0.9825367647058824,
      "grad_norm": 1.2957746982574463,
      "learning_rate": 7.474042553191489e-06,
      "loss": 0.088,
      "step": 4276
    },
    {
      "epoch": 0.9827665441176471,
      "grad_norm": 1.2354336977005005,
      "learning_rate": 7.473191489361703e-06,
      "loss": 0.0878,
      "step": 4277
    },
    {
      "epoch": 0.9829963235294118,
      "grad_norm": 1.0893000364303589,
      "learning_rate": 7.4723404255319155e-06,
      "loss": 0.1093,
      "step": 4278
    },
    {
      "epoch": 0.9832261029411765,
      "grad_norm": 2.1803762912750244,
      "learning_rate": 7.471489361702128e-06,
      "loss": 0.1228,
      "step": 4279
    },
    {
      "epoch": 0.9834558823529411,
      "grad_norm": 0.9613826870918274,
      "learning_rate": 7.470638297872341e-06,
      "loss": 0.0811,
      "step": 4280
    },
    {
      "epoch": 0.9836856617647058,
      "grad_norm": 1.0253238677978516,
      "learning_rate": 7.469787234042553e-06,
      "loss": 0.1133,
      "step": 4281
    },
    {
      "epoch": 0.9839154411764706,
      "grad_norm": 1.4629979133605957,
      "learning_rate": 7.468936170212766e-06,
      "loss": 0.1061,
      "step": 4282
    },
    {
      "epoch": 0.9841452205882353,
      "grad_norm": 1.356368064880371,
      "learning_rate": 7.46808510638298e-06,
      "loss": 0.1141,
      "step": 4283
    },
    {
      "epoch": 0.984375,
      "grad_norm": 1.403167963027954,
      "learning_rate": 7.467234042553192e-06,
      "loss": 0.1119,
      "step": 4284
    },
    {
      "epoch": 0.9846047794117647,
      "grad_norm": 1.3198094367980957,
      "learning_rate": 7.466382978723404e-06,
      "loss": 0.0908,
      "step": 4285
    },
    {
      "epoch": 0.9848345588235294,
      "grad_norm": 1.1620410680770874,
      "learning_rate": 7.4655319148936175e-06,
      "loss": 0.0984,
      "step": 4286
    },
    {
      "epoch": 0.9850643382352942,
      "grad_norm": 1.231902837753296,
      "learning_rate": 7.46468085106383e-06,
      "loss": 0.0636,
      "step": 4287
    },
    {
      "epoch": 0.9852941176470589,
      "grad_norm": 1.2131074666976929,
      "learning_rate": 7.463829787234043e-06,
      "loss": 0.0737,
      "step": 4288
    },
    {
      "epoch": 0.9855238970588235,
      "grad_norm": 1.0751944780349731,
      "learning_rate": 7.462978723404256e-06,
      "loss": 0.1044,
      "step": 4289
    },
    {
      "epoch": 0.9857536764705882,
      "grad_norm": 1.216130256652832,
      "learning_rate": 7.4621276595744685e-06,
      "loss": 0.1,
      "step": 4290
    },
    {
      "epoch": 0.9859834558823529,
      "grad_norm": 1.0958662033081055,
      "learning_rate": 7.461276595744682e-06,
      "loss": 0.0734,
      "step": 4291
    },
    {
      "epoch": 0.9862132352941176,
      "grad_norm": 1.5531216859817505,
      "learning_rate": 7.460425531914894e-06,
      "loss": 0.1159,
      "step": 4292
    },
    {
      "epoch": 0.9864430147058824,
      "grad_norm": 1.0305519104003906,
      "learning_rate": 7.459574468085107e-06,
      "loss": 0.0984,
      "step": 4293
    },
    {
      "epoch": 0.9866727941176471,
      "grad_norm": 1.082438588142395,
      "learning_rate": 7.45872340425532e-06,
      "loss": 0.0788,
      "step": 4294
    },
    {
      "epoch": 0.9869025735294118,
      "grad_norm": 1.2432717084884644,
      "learning_rate": 7.457872340425533e-06,
      "loss": 0.0799,
      "step": 4295
    },
    {
      "epoch": 0.9871323529411765,
      "grad_norm": 1.1006280183792114,
      "learning_rate": 7.457021276595745e-06,
      "loss": 0.0961,
      "step": 4296
    },
    {
      "epoch": 0.9873621323529411,
      "grad_norm": 1.3357189893722534,
      "learning_rate": 7.456170212765958e-06,
      "loss": 0.1005,
      "step": 4297
    },
    {
      "epoch": 0.9875919117647058,
      "grad_norm": 2.0153377056121826,
      "learning_rate": 7.455319148936171e-06,
      "loss": 0.1163,
      "step": 4298
    },
    {
      "epoch": 0.9878216911764706,
      "grad_norm": 1.0986038446426392,
      "learning_rate": 7.454468085106384e-06,
      "loss": 0.0852,
      "step": 4299
    },
    {
      "epoch": 0.9880514705882353,
      "grad_norm": 1.1686681509017944,
      "learning_rate": 7.453617021276597e-06,
      "loss": 0.0934,
      "step": 4300
    },
    {
      "epoch": 0.98828125,
      "grad_norm": 1.1329234838485718,
      "learning_rate": 7.452765957446809e-06,
      "loss": 0.1027,
      "step": 4301
    },
    {
      "epoch": 0.9885110294117647,
      "grad_norm": 1.009007215499878,
      "learning_rate": 7.4519148936170215e-06,
      "loss": 0.0689,
      "step": 4302
    },
    {
      "epoch": 0.9887408088235294,
      "grad_norm": 0.995300829410553,
      "learning_rate": 7.4510638297872355e-06,
      "loss": 0.0684,
      "step": 4303
    },
    {
      "epoch": 0.9889705882352942,
      "grad_norm": 1.418062448501587,
      "learning_rate": 7.450212765957448e-06,
      "loss": 0.1027,
      "step": 4304
    },
    {
      "epoch": 0.9892003676470589,
      "grad_norm": 1.0478148460388184,
      "learning_rate": 7.44936170212766e-06,
      "loss": 0.0893,
      "step": 4305
    },
    {
      "epoch": 0.9894301470588235,
      "grad_norm": 1.4785377979278564,
      "learning_rate": 7.448510638297873e-06,
      "loss": 0.1147,
      "step": 4306
    },
    {
      "epoch": 0.9896599264705882,
      "grad_norm": 1.1713930368423462,
      "learning_rate": 7.447659574468086e-06,
      "loss": 0.0875,
      "step": 4307
    },
    {
      "epoch": 0.9898897058823529,
      "grad_norm": 1.3191397190093994,
      "learning_rate": 7.446808510638298e-06,
      "loss": 0.1183,
      "step": 4308
    },
    {
      "epoch": 0.9901194852941176,
      "grad_norm": 1.1597813367843628,
      "learning_rate": 7.445957446808512e-06,
      "loss": 0.0933,
      "step": 4309
    },
    {
      "epoch": 0.9903492647058824,
      "grad_norm": 1.538479208946228,
      "learning_rate": 7.445106382978724e-06,
      "loss": 0.1206,
      "step": 4310
    },
    {
      "epoch": 0.9905790441176471,
      "grad_norm": 1.0533955097198486,
      "learning_rate": 7.444255319148937e-06,
      "loss": 0.0768,
      "step": 4311
    },
    {
      "epoch": 0.9908088235294118,
      "grad_norm": 1.3274877071380615,
      "learning_rate": 7.44340425531915e-06,
      "loss": 0.1372,
      "step": 4312
    },
    {
      "epoch": 0.9910386029411765,
      "grad_norm": 1.7722656726837158,
      "learning_rate": 7.442553191489362e-06,
      "loss": 0.137,
      "step": 4313
    },
    {
      "epoch": 0.9912683823529411,
      "grad_norm": 1.0880810022354126,
      "learning_rate": 7.441702127659574e-06,
      "loss": 0.0957,
      "step": 4314
    },
    {
      "epoch": 0.9914981617647058,
      "grad_norm": 1.25722336769104,
      "learning_rate": 7.4408510638297884e-06,
      "loss": 0.087,
      "step": 4315
    },
    {
      "epoch": 0.9917279411764706,
      "grad_norm": 1.3730263710021973,
      "learning_rate": 7.440000000000001e-06,
      "loss": 0.1044,
      "step": 4316
    },
    {
      "epoch": 0.9919577205882353,
      "grad_norm": 1.3845831155776978,
      "learning_rate": 7.439148936170213e-06,
      "loss": 0.1078,
      "step": 4317
    },
    {
      "epoch": 0.9921875,
      "grad_norm": 0.9353447556495667,
      "learning_rate": 7.438297872340426e-06,
      "loss": 0.092,
      "step": 4318
    },
    {
      "epoch": 0.9924172794117647,
      "grad_norm": 1.480962872505188,
      "learning_rate": 7.437446808510639e-06,
      "loss": 0.0922,
      "step": 4319
    },
    {
      "epoch": 0.9926470588235294,
      "grad_norm": 1.3116768598556519,
      "learning_rate": 7.436595744680851e-06,
      "loss": 0.0727,
      "step": 4320
    },
    {
      "epoch": 0.9928768382352942,
      "grad_norm": 1.7343450784683228,
      "learning_rate": 7.435744680851065e-06,
      "loss": 0.1159,
      "step": 4321
    },
    {
      "epoch": 0.9931066176470589,
      "grad_norm": 1.3115475177764893,
      "learning_rate": 7.434893617021277e-06,
      "loss": 0.0889,
      "step": 4322
    },
    {
      "epoch": 0.9933363970588235,
      "grad_norm": 1.0012069940567017,
      "learning_rate": 7.4340425531914896e-06,
      "loss": 0.0681,
      "step": 4323
    },
    {
      "epoch": 0.9935661764705882,
      "grad_norm": 1.2198116779327393,
      "learning_rate": 7.433191489361703e-06,
      "loss": 0.0899,
      "step": 4324
    },
    {
      "epoch": 0.9937959558823529,
      "grad_norm": 1.0082825422286987,
      "learning_rate": 7.432340425531915e-06,
      "loss": 0.0683,
      "step": 4325
    },
    {
      "epoch": 0.9940257352941176,
      "grad_norm": 1.2733780145645142,
      "learning_rate": 7.431489361702127e-06,
      "loss": 0.0976,
      "step": 4326
    },
    {
      "epoch": 0.9942555147058824,
      "grad_norm": 1.2373005151748657,
      "learning_rate": 7.430638297872341e-06,
      "loss": 0.1009,
      "step": 4327
    },
    {
      "epoch": 0.9944852941176471,
      "grad_norm": 1.2349604368209839,
      "learning_rate": 7.429787234042554e-06,
      "loss": 0.0791,
      "step": 4328
    },
    {
      "epoch": 0.9947150735294118,
      "grad_norm": 1.4173996448516846,
      "learning_rate": 7.428936170212766e-06,
      "loss": 0.1089,
      "step": 4329
    },
    {
      "epoch": 0.9949448529411765,
      "grad_norm": 1.5632749795913696,
      "learning_rate": 7.428085106382979e-06,
      "loss": 0.0816,
      "step": 4330
    },
    {
      "epoch": 0.9951746323529411,
      "grad_norm": 1.6487421989440918,
      "learning_rate": 7.4272340425531915e-06,
      "loss": 0.1204,
      "step": 4331
    },
    {
      "epoch": 0.9954044117647058,
      "grad_norm": 1.4333997964859009,
      "learning_rate": 7.4263829787234056e-06,
      "loss": 0.1222,
      "step": 4332
    },
    {
      "epoch": 0.9956341911764706,
      "grad_norm": 1.7740156650543213,
      "learning_rate": 7.425531914893618e-06,
      "loss": 0.153,
      "step": 4333
    },
    {
      "epoch": 0.9958639705882353,
      "grad_norm": 1.2899458408355713,
      "learning_rate": 7.42468085106383e-06,
      "loss": 0.1031,
      "step": 4334
    },
    {
      "epoch": 0.99609375,
      "grad_norm": 1.260710597038269,
      "learning_rate": 7.423829787234043e-06,
      "loss": 0.0885,
      "step": 4335
    },
    {
      "epoch": 0.9963235294117647,
      "grad_norm": 1.4268641471862793,
      "learning_rate": 7.422978723404256e-06,
      "loss": 0.0921,
      "step": 4336
    },
    {
      "epoch": 0.9965533088235294,
      "grad_norm": 1.2326840162277222,
      "learning_rate": 7.422127659574469e-06,
      "loss": 0.0891,
      "step": 4337
    },
    {
      "epoch": 0.9967830882352942,
      "grad_norm": 1.5574311017990112,
      "learning_rate": 7.421276595744682e-06,
      "loss": 0.124,
      "step": 4338
    },
    {
      "epoch": 0.9970128676470589,
      "grad_norm": 1.53948974609375,
      "learning_rate": 7.420425531914894e-06,
      "loss": 0.063,
      "step": 4339
    },
    {
      "epoch": 0.9972426470588235,
      "grad_norm": 1.527661681175232,
      "learning_rate": 7.419574468085107e-06,
      "loss": 0.1256,
      "step": 4340
    },
    {
      "epoch": 0.9974724264705882,
      "grad_norm": 1.081978678703308,
      "learning_rate": 7.41872340425532e-06,
      "loss": 0.0852,
      "step": 4341
    },
    {
      "epoch": 0.9977022058823529,
      "grad_norm": 1.344355821609497,
      "learning_rate": 7.417872340425533e-06,
      "loss": 0.1131,
      "step": 4342
    },
    {
      "epoch": 0.9979319852941176,
      "grad_norm": 1.3404490947723389,
      "learning_rate": 7.417021276595745e-06,
      "loss": 0.1444,
      "step": 4343
    },
    {
      "epoch": 0.9981617647058824,
      "grad_norm": 1.1196024417877197,
      "learning_rate": 7.4161702127659585e-06,
      "loss": 0.0841,
      "step": 4344
    },
    {
      "epoch": 0.9983915441176471,
      "grad_norm": 1.2785718441009521,
      "learning_rate": 7.415319148936171e-06,
      "loss": 0.1046,
      "step": 4345
    },
    {
      "epoch": 0.9986213235294118,
      "grad_norm": 1.0187432765960693,
      "learning_rate": 7.414468085106383e-06,
      "loss": 0.0652,
      "step": 4346
    },
    {
      "epoch": 0.9988511029411765,
      "grad_norm": 1.3838753700256348,
      "learning_rate": 7.413617021276596e-06,
      "loss": 0.0805,
      "step": 4347
    },
    {
      "epoch": 0.9990808823529411,
      "grad_norm": 1.217548131942749,
      "learning_rate": 7.4127659574468095e-06,
      "loss": 0.0751,
      "step": 4348
    },
    {
      "epoch": 0.9993106617647058,
      "grad_norm": 1.3637182712554932,
      "learning_rate": 7.411914893617022e-06,
      "loss": 0.0985,
      "step": 4349
    },
    {
      "epoch": 0.9995404411764706,
      "grad_norm": 1.5740652084350586,
      "learning_rate": 7.411063829787235e-06,
      "loss": 0.1127,
      "step": 4350
    },
    {
      "epoch": 0.9997702205882353,
      "grad_norm": 1.219043493270874,
      "learning_rate": 7.410212765957447e-06,
      "loss": 0.0764,
      "step": 4351
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.5625779628753662,
      "learning_rate": 7.40936170212766e-06,
      "loss": 0.1484,
      "step": 4352
    },
    {
      "epoch": 1.0002297794117647,
      "grad_norm": 1.0369380712509155,
      "learning_rate": 7.408510638297874e-06,
      "loss": 0.0514,
      "step": 4353
    },
    {
      "epoch": 1.0004595588235294,
      "grad_norm": 0.8731341361999512,
      "learning_rate": 7.407659574468086e-06,
      "loss": 0.0777,
      "step": 4354
    },
    {
      "epoch": 1.0006893382352942,
      "grad_norm": 1.1523183584213257,
      "learning_rate": 7.406808510638298e-06,
      "loss": 0.1072,
      "step": 4355
    },
    {
      "epoch": 1.0009191176470589,
      "grad_norm": 1.143589973449707,
      "learning_rate": 7.4059574468085115e-06,
      "loss": 0.0835,
      "step": 4356
    },
    {
      "epoch": 1.0011488970588236,
      "grad_norm": 1.2768222093582153,
      "learning_rate": 7.405106382978724e-06,
      "loss": 0.0892,
      "step": 4357
    },
    {
      "epoch": 1.0013786764705883,
      "grad_norm": 0.974677324295044,
      "learning_rate": 7.404255319148936e-06,
      "loss": 0.1035,
      "step": 4358
    },
    {
      "epoch": 1.001608455882353,
      "grad_norm": 1.216166377067566,
      "learning_rate": 7.40340425531915e-06,
      "loss": 0.0927,
      "step": 4359
    },
    {
      "epoch": 1.0018382352941178,
      "grad_norm": 1.562656044960022,
      "learning_rate": 7.4025531914893625e-06,
      "loss": 0.0724,
      "step": 4360
    },
    {
      "epoch": 1.0020680147058822,
      "grad_norm": 1.2073163986206055,
      "learning_rate": 7.401702127659575e-06,
      "loss": 0.1208,
      "step": 4361
    },
    {
      "epoch": 1.002297794117647,
      "grad_norm": 1.3003075122833252,
      "learning_rate": 7.400851063829788e-06,
      "loss": 0.1352,
      "step": 4362
    },
    {
      "epoch": 1.0025275735294117,
      "grad_norm": 1.1137741804122925,
      "learning_rate": 7.4e-06,
      "loss": 0.1263,
      "step": 4363
    },
    {
      "epoch": 1.0027573529411764,
      "grad_norm": 1.0882320404052734,
      "learning_rate": 7.399148936170213e-06,
      "loss": 0.0424,
      "step": 4364
    },
    {
      "epoch": 1.0029871323529411,
      "grad_norm": 1.6418458223342896,
      "learning_rate": 7.398297872340427e-06,
      "loss": 0.1169,
      "step": 4365
    },
    {
      "epoch": 1.0032169117647058,
      "grad_norm": 1.1817941665649414,
      "learning_rate": 7.397446808510639e-06,
      "loss": 0.0816,
      "step": 4366
    },
    {
      "epoch": 1.0034466911764706,
      "grad_norm": 1.3545477390289307,
      "learning_rate": 7.396595744680851e-06,
      "loss": 0.1288,
      "step": 4367
    },
    {
      "epoch": 1.0036764705882353,
      "grad_norm": 1.274557113647461,
      "learning_rate": 7.3957446808510645e-06,
      "loss": 0.0922,
      "step": 4368
    },
    {
      "epoch": 1.00390625,
      "grad_norm": 0.8961981534957886,
      "learning_rate": 7.394893617021277e-06,
      "loss": 0.0752,
      "step": 4369
    },
    {
      "epoch": 1.0041360294117647,
      "grad_norm": 0.888412356376648,
      "learning_rate": 7.394042553191489e-06,
      "loss": 0.0738,
      "step": 4370
    },
    {
      "epoch": 1.0043658088235294,
      "grad_norm": 1.2499510049819946,
      "learning_rate": 7.393191489361703e-06,
      "loss": 0.0917,
      "step": 4371
    },
    {
      "epoch": 1.0045955882352942,
      "grad_norm": 1.3963074684143066,
      "learning_rate": 7.3923404255319154e-06,
      "loss": 0.1022,
      "step": 4372
    },
    {
      "epoch": 1.0048253676470589,
      "grad_norm": 1.4037683010101318,
      "learning_rate": 7.391489361702128e-06,
      "loss": 0.1133,
      "step": 4373
    },
    {
      "epoch": 1.0050551470588236,
      "grad_norm": 1.0598087310791016,
      "learning_rate": 7.390638297872341e-06,
      "loss": 0.0732,
      "step": 4374
    },
    {
      "epoch": 1.0052849264705883,
      "grad_norm": 1.1419703960418701,
      "learning_rate": 7.389787234042553e-06,
      "loss": 0.0756,
      "step": 4375
    },
    {
      "epoch": 1.005514705882353,
      "grad_norm": 1.5687873363494873,
      "learning_rate": 7.388936170212767e-06,
      "loss": 0.1335,
      "step": 4376
    },
    {
      "epoch": 1.0057444852941178,
      "grad_norm": 1.423485517501831,
      "learning_rate": 7.38808510638298e-06,
      "loss": 0.1161,
      "step": 4377
    },
    {
      "epoch": 1.0059742647058822,
      "grad_norm": 1.1145521402359009,
      "learning_rate": 7.387234042553192e-06,
      "loss": 0.1084,
      "step": 4378
    },
    {
      "epoch": 1.006204044117647,
      "grad_norm": 1.2185879945755005,
      "learning_rate": 7.386382978723405e-06,
      "loss": 0.1008,
      "step": 4379
    },
    {
      "epoch": 1.0064338235294117,
      "grad_norm": 1.026854157447815,
      "learning_rate": 7.3855319148936174e-06,
      "loss": 0.0996,
      "step": 4380
    },
    {
      "epoch": 1.0066636029411764,
      "grad_norm": 1.4576646089553833,
      "learning_rate": 7.38468085106383e-06,
      "loss": 0.0749,
      "step": 4381
    },
    {
      "epoch": 1.0068933823529411,
      "grad_norm": 0.9323444962501526,
      "learning_rate": 7.383829787234044e-06,
      "loss": 0.0612,
      "step": 4382
    },
    {
      "epoch": 1.0071231617647058,
      "grad_norm": 1.1863784790039062,
      "learning_rate": 7.382978723404256e-06,
      "loss": 0.0591,
      "step": 4383
    },
    {
      "epoch": 1.0073529411764706,
      "grad_norm": 1.4049865007400513,
      "learning_rate": 7.382127659574468e-06,
      "loss": 0.095,
      "step": 4384
    },
    {
      "epoch": 1.0075827205882353,
      "grad_norm": 1.063254952430725,
      "learning_rate": 7.381276595744682e-06,
      "loss": 0.0969,
      "step": 4385
    },
    {
      "epoch": 1.0078125,
      "grad_norm": 1.1960036754608154,
      "learning_rate": 7.380425531914894e-06,
      "loss": 0.0896,
      "step": 4386
    },
    {
      "epoch": 1.0080422794117647,
      "grad_norm": 1.403314471244812,
      "learning_rate": 7.379574468085107e-06,
      "loss": 0.1588,
      "step": 4387
    },
    {
      "epoch": 1.0082720588235294,
      "grad_norm": 1.3661513328552246,
      "learning_rate": 7.37872340425532e-06,
      "loss": 0.1061,
      "step": 4388
    },
    {
      "epoch": 1.0085018382352942,
      "grad_norm": 1.0155673027038574,
      "learning_rate": 7.3778723404255326e-06,
      "loss": 0.0816,
      "step": 4389
    },
    {
      "epoch": 1.0087316176470589,
      "grad_norm": 1.7556990385055542,
      "learning_rate": 7.377021276595745e-06,
      "loss": 0.1094,
      "step": 4390
    },
    {
      "epoch": 1.0089613970588236,
      "grad_norm": 1.1994959115982056,
      "learning_rate": 7.376170212765958e-06,
      "loss": 0.0674,
      "step": 4391
    },
    {
      "epoch": 1.0091911764705883,
      "grad_norm": 1.1715188026428223,
      "learning_rate": 7.375319148936171e-06,
      "loss": 0.0825,
      "step": 4392
    },
    {
      "epoch": 1.009420955882353,
      "grad_norm": 1.0413936376571655,
      "learning_rate": 7.3744680851063836e-06,
      "loss": 0.0873,
      "step": 4393
    },
    {
      "epoch": 1.0096507352941178,
      "grad_norm": 1.1108986139297485,
      "learning_rate": 7.373617021276597e-06,
      "loss": 0.0713,
      "step": 4394
    },
    {
      "epoch": 1.0098805147058822,
      "grad_norm": 1.536998987197876,
      "learning_rate": 7.372765957446809e-06,
      "loss": 0.1394,
      "step": 4395
    },
    {
      "epoch": 1.010110294117647,
      "grad_norm": 0.9401904344558716,
      "learning_rate": 7.371914893617021e-06,
      "loss": 0.0687,
      "step": 4396
    },
    {
      "epoch": 1.0103400735294117,
      "grad_norm": 1.282470703125,
      "learning_rate": 7.371063829787235e-06,
      "loss": 0.0814,
      "step": 4397
    },
    {
      "epoch": 1.0105698529411764,
      "grad_norm": 1.039276123046875,
      "learning_rate": 7.370212765957448e-06,
      "loss": 0.103,
      "step": 4398
    },
    {
      "epoch": 1.0107996323529411,
      "grad_norm": 1.3492896556854248,
      "learning_rate": 7.36936170212766e-06,
      "loss": 0.0899,
      "step": 4399
    },
    {
      "epoch": 1.0110294117647058,
      "grad_norm": 1.3485159873962402,
      "learning_rate": 7.368510638297873e-06,
      "loss": 0.0856,
      "step": 4400
    },
    {
      "epoch": 1.0112591911764706,
      "grad_norm": 1.089804768562317,
      "learning_rate": 7.3676595744680855e-06,
      "loss": 0.0817,
      "step": 4401
    },
    {
      "epoch": 1.0114889705882353,
      "grad_norm": 1.0561308860778809,
      "learning_rate": 7.366808510638298e-06,
      "loss": 0.069,
      "step": 4402
    },
    {
      "epoch": 1.01171875,
      "grad_norm": 1.4673913717269897,
      "learning_rate": 7.365957446808512e-06,
      "loss": 0.1264,
      "step": 4403
    },
    {
      "epoch": 1.0119485294117647,
      "grad_norm": 1.528039813041687,
      "learning_rate": 7.365106382978724e-06,
      "loss": 0.1215,
      "step": 4404
    },
    {
      "epoch": 1.0121783088235294,
      "grad_norm": 1.4332484006881714,
      "learning_rate": 7.3642553191489365e-06,
      "loss": 0.103,
      "step": 4405
    },
    {
      "epoch": 1.0124080882352942,
      "grad_norm": 1.0375962257385254,
      "learning_rate": 7.36340425531915e-06,
      "loss": 0.0894,
      "step": 4406
    },
    {
      "epoch": 1.0126378676470589,
      "grad_norm": 0.9690311551094055,
      "learning_rate": 7.362553191489362e-06,
      "loss": 0.0524,
      "step": 4407
    },
    {
      "epoch": 1.0128676470588236,
      "grad_norm": 1.0288344621658325,
      "learning_rate": 7.361702127659574e-06,
      "loss": 0.0942,
      "step": 4408
    },
    {
      "epoch": 1.0130974264705883,
      "grad_norm": 1.4058959484100342,
      "learning_rate": 7.360851063829788e-06,
      "loss": 0.0908,
      "step": 4409
    },
    {
      "epoch": 1.013327205882353,
      "grad_norm": 1.4521726369857788,
      "learning_rate": 7.360000000000001e-06,
      "loss": 0.1117,
      "step": 4410
    },
    {
      "epoch": 1.0135569852941178,
      "grad_norm": 1.4066542387008667,
      "learning_rate": 7.359148936170213e-06,
      "loss": 0.0969,
      "step": 4411
    },
    {
      "epoch": 1.0137867647058822,
      "grad_norm": 1.286372423171997,
      "learning_rate": 7.358297872340426e-06,
      "loss": 0.0847,
      "step": 4412
    },
    {
      "epoch": 1.014016544117647,
      "grad_norm": 1.782025933265686,
      "learning_rate": 7.3574468085106385e-06,
      "loss": 0.128,
      "step": 4413
    },
    {
      "epoch": 1.0142463235294117,
      "grad_norm": 1.1029129028320312,
      "learning_rate": 7.356595744680851e-06,
      "loss": 0.0847,
      "step": 4414
    },
    {
      "epoch": 1.0144761029411764,
      "grad_norm": 1.5082875490188599,
      "learning_rate": 7.355744680851065e-06,
      "loss": 0.1143,
      "step": 4415
    },
    {
      "epoch": 1.0147058823529411,
      "grad_norm": 1.2815468311309814,
      "learning_rate": 7.354893617021277e-06,
      "loss": 0.0916,
      "step": 4416
    },
    {
      "epoch": 1.0149356617647058,
      "grad_norm": 1.273869514465332,
      "learning_rate": 7.3540425531914895e-06,
      "loss": 0.0994,
      "step": 4417
    },
    {
      "epoch": 1.0151654411764706,
      "grad_norm": 1.4903373718261719,
      "learning_rate": 7.353191489361703e-06,
      "loss": 0.1022,
      "step": 4418
    },
    {
      "epoch": 1.0153952205882353,
      "grad_norm": 1.720247745513916,
      "learning_rate": 7.352340425531915e-06,
      "loss": 0.106,
      "step": 4419
    },
    {
      "epoch": 1.015625,
      "grad_norm": 1.1249135732650757,
      "learning_rate": 7.351489361702129e-06,
      "loss": 0.058,
      "step": 4420
    },
    {
      "epoch": 1.0158547794117647,
      "grad_norm": 1.2764242887496948,
      "learning_rate": 7.350638297872341e-06,
      "loss": 0.0793,
      "step": 4421
    },
    {
      "epoch": 1.0160845588235294,
      "grad_norm": 1.6702747344970703,
      "learning_rate": 7.349787234042554e-06,
      "loss": 0.1177,
      "step": 4422
    },
    {
      "epoch": 1.0163143382352942,
      "grad_norm": 1.265678882598877,
      "learning_rate": 7.348936170212767e-06,
      "loss": 0.0915,
      "step": 4423
    },
    {
      "epoch": 1.0165441176470589,
      "grad_norm": 1.1252610683441162,
      "learning_rate": 7.348085106382979e-06,
      "loss": 0.066,
      "step": 4424
    },
    {
      "epoch": 1.0167738970588236,
      "grad_norm": 0.9528323411941528,
      "learning_rate": 7.3472340425531915e-06,
      "loss": 0.1215,
      "step": 4425
    },
    {
      "epoch": 1.0170036764705883,
      "grad_norm": 1.732104778289795,
      "learning_rate": 7.3463829787234055e-06,
      "loss": 0.1419,
      "step": 4426
    },
    {
      "epoch": 1.017233455882353,
      "grad_norm": 1.2324037551879883,
      "learning_rate": 7.345531914893618e-06,
      "loss": 0.0922,
      "step": 4427
    },
    {
      "epoch": 1.0174632352941178,
      "grad_norm": 1.4695457220077515,
      "learning_rate": 7.34468085106383e-06,
      "loss": 0.1449,
      "step": 4428
    },
    {
      "epoch": 1.0176930147058822,
      "grad_norm": 1.1364283561706543,
      "learning_rate": 7.343829787234043e-06,
      "loss": 0.0762,
      "step": 4429
    },
    {
      "epoch": 1.017922794117647,
      "grad_norm": 1.649636149406433,
      "learning_rate": 7.342978723404256e-06,
      "loss": 0.1129,
      "step": 4430
    },
    {
      "epoch": 1.0181525735294117,
      "grad_norm": 1.216396450996399,
      "learning_rate": 7.342127659574469e-06,
      "loss": 0.0879,
      "step": 4431
    },
    {
      "epoch": 1.0183823529411764,
      "grad_norm": 1.1256861686706543,
      "learning_rate": 7.341276595744682e-06,
      "loss": 0.0802,
      "step": 4432
    },
    {
      "epoch": 1.0186121323529411,
      "grad_norm": 0.9495668411254883,
      "learning_rate": 7.340425531914894e-06,
      "loss": 0.084,
      "step": 4433
    },
    {
      "epoch": 1.0188419117647058,
      "grad_norm": 1.2668330669403076,
      "learning_rate": 7.339574468085107e-06,
      "loss": 0.0928,
      "step": 4434
    },
    {
      "epoch": 1.0190716911764706,
      "grad_norm": 0.9294477701187134,
      "learning_rate": 7.33872340425532e-06,
      "loss": 0.0745,
      "step": 4435
    },
    {
      "epoch": 1.0193014705882353,
      "grad_norm": 1.0863878726959229,
      "learning_rate": 7.337872340425533e-06,
      "loss": 0.0915,
      "step": 4436
    },
    {
      "epoch": 1.01953125,
      "grad_norm": 1.5305169820785522,
      "learning_rate": 7.337021276595745e-06,
      "loss": 0.1142,
      "step": 4437
    },
    {
      "epoch": 1.0197610294117647,
      "grad_norm": 1.201801061630249,
      "learning_rate": 7.3361702127659584e-06,
      "loss": 0.0955,
      "step": 4438
    },
    {
      "epoch": 1.0199908088235294,
      "grad_norm": 1.015689730644226,
      "learning_rate": 7.335319148936171e-06,
      "loss": 0.0759,
      "step": 4439
    },
    {
      "epoch": 1.0202205882352942,
      "grad_norm": 1.1754183769226074,
      "learning_rate": 7.334468085106383e-06,
      "loss": 0.077,
      "step": 4440
    },
    {
      "epoch": 1.0204503676470589,
      "grad_norm": 1.3388482332229614,
      "learning_rate": 7.333617021276597e-06,
      "loss": 0.1045,
      "step": 4441
    },
    {
      "epoch": 1.0206801470588236,
      "grad_norm": 1.141548991203308,
      "learning_rate": 7.3327659574468094e-06,
      "loss": 0.0632,
      "step": 4442
    },
    {
      "epoch": 1.0209099264705883,
      "grad_norm": 1.308149814605713,
      "learning_rate": 7.331914893617022e-06,
      "loss": 0.105,
      "step": 4443
    },
    {
      "epoch": 1.021139705882353,
      "grad_norm": 1.036139726638794,
      "learning_rate": 7.331063829787235e-06,
      "loss": 0.0654,
      "step": 4444
    },
    {
      "epoch": 1.0213694852941178,
      "grad_norm": 1.046921730041504,
      "learning_rate": 7.330212765957447e-06,
      "loss": 0.0895,
      "step": 4445
    },
    {
      "epoch": 1.0215992647058822,
      "grad_norm": 1.07706618309021,
      "learning_rate": 7.32936170212766e-06,
      "loss": 0.0734,
      "step": 4446
    },
    {
      "epoch": 1.021829044117647,
      "grad_norm": 1.3243812322616577,
      "learning_rate": 7.328510638297874e-06,
      "loss": 0.1217,
      "step": 4447
    },
    {
      "epoch": 1.0220588235294117,
      "grad_norm": 1.511742115020752,
      "learning_rate": 7.327659574468086e-06,
      "loss": 0.073,
      "step": 4448
    },
    {
      "epoch": 1.0222886029411764,
      "grad_norm": 1.6255699396133423,
      "learning_rate": 7.326808510638298e-06,
      "loss": 0.1094,
      "step": 4449
    },
    {
      "epoch": 1.0225183823529411,
      "grad_norm": 1.0232380628585815,
      "learning_rate": 7.325957446808511e-06,
      "loss": 0.0657,
      "step": 4450
    },
    {
      "epoch": 1.0227481617647058,
      "grad_norm": 1.4833433628082275,
      "learning_rate": 7.325106382978724e-06,
      "loss": 0.0762,
      "step": 4451
    },
    {
      "epoch": 1.0229779411764706,
      "grad_norm": 1.1490172147750854,
      "learning_rate": 7.324255319148936e-06,
      "loss": 0.1068,
      "step": 4452
    },
    {
      "epoch": 1.0232077205882353,
      "grad_norm": 1.0597532987594604,
      "learning_rate": 7.32340425531915e-06,
      "loss": 0.078,
      "step": 4453
    },
    {
      "epoch": 1.0234375,
      "grad_norm": 1.2818669080734253,
      "learning_rate": 7.322553191489362e-06,
      "loss": 0.0991,
      "step": 4454
    },
    {
      "epoch": 1.0236672794117647,
      "grad_norm": 1.1718086004257202,
      "learning_rate": 7.321702127659575e-06,
      "loss": 0.0854,
      "step": 4455
    },
    {
      "epoch": 1.0238970588235294,
      "grad_norm": 1.028173565864563,
      "learning_rate": 7.320851063829788e-06,
      "loss": 0.0994,
      "step": 4456
    },
    {
      "epoch": 1.0241268382352942,
      "grad_norm": 1.720560073852539,
      "learning_rate": 7.32e-06,
      "loss": 0.1444,
      "step": 4457
    },
    {
      "epoch": 1.0243566176470589,
      "grad_norm": 2.1874704360961914,
      "learning_rate": 7.3191489361702125e-06,
      "loss": 0.1354,
      "step": 4458
    },
    {
      "epoch": 1.0245863970588236,
      "grad_norm": 1.3039708137512207,
      "learning_rate": 7.3182978723404266e-06,
      "loss": 0.1229,
      "step": 4459
    },
    {
      "epoch": 1.0248161764705883,
      "grad_norm": 1.1966826915740967,
      "learning_rate": 7.317446808510639e-06,
      "loss": 0.0819,
      "step": 4460
    },
    {
      "epoch": 1.025045955882353,
      "grad_norm": 1.1967039108276367,
      "learning_rate": 7.316595744680852e-06,
      "loss": 0.1107,
      "step": 4461
    },
    {
      "epoch": 1.0252757352941178,
      "grad_norm": 1.617891550064087,
      "learning_rate": 7.315744680851064e-06,
      "loss": 0.1132,
      "step": 4462
    },
    {
      "epoch": 1.0255055147058822,
      "grad_norm": 1.119956612586975,
      "learning_rate": 7.314893617021277e-06,
      "loss": 0.1096,
      "step": 4463
    },
    {
      "epoch": 1.025735294117647,
      "grad_norm": 1.4844541549682617,
      "learning_rate": 7.314042553191491e-06,
      "loss": 0.0989,
      "step": 4464
    },
    {
      "epoch": 1.0259650735294117,
      "grad_norm": 1.2168489694595337,
      "learning_rate": 7.313191489361703e-06,
      "loss": 0.082,
      "step": 4465
    },
    {
      "epoch": 1.0261948529411764,
      "grad_norm": 1.4824260473251343,
      "learning_rate": 7.312340425531915e-06,
      "loss": 0.1032,
      "step": 4466
    },
    {
      "epoch": 1.0264246323529411,
      "grad_norm": 1.252854585647583,
      "learning_rate": 7.3114893617021285e-06,
      "loss": 0.0929,
      "step": 4467
    },
    {
      "epoch": 1.0266544117647058,
      "grad_norm": 1.2183514833450317,
      "learning_rate": 7.310638297872341e-06,
      "loss": 0.1029,
      "step": 4468
    },
    {
      "epoch": 1.0268841911764706,
      "grad_norm": 1.435778021812439,
      "learning_rate": 7.309787234042553e-06,
      "loss": 0.1049,
      "step": 4469
    },
    {
      "epoch": 1.0271139705882353,
      "grad_norm": 1.181883454322815,
      "learning_rate": 7.308936170212767e-06,
      "loss": 0.0775,
      "step": 4470
    },
    {
      "epoch": 1.02734375,
      "grad_norm": 2.598670482635498,
      "learning_rate": 7.3080851063829795e-06,
      "loss": 0.1162,
      "step": 4471
    },
    {
      "epoch": 1.0275735294117647,
      "grad_norm": 0.9330475926399231,
      "learning_rate": 7.307234042553192e-06,
      "loss": 0.0791,
      "step": 4472
    },
    {
      "epoch": 1.0278033088235294,
      "grad_norm": 1.6605281829833984,
      "learning_rate": 7.306382978723405e-06,
      "loss": 0.0915,
      "step": 4473
    },
    {
      "epoch": 1.0280330882352942,
      "grad_norm": 1.6887118816375732,
      "learning_rate": 7.305531914893617e-06,
      "loss": 0.1635,
      "step": 4474
    },
    {
      "epoch": 1.0282628676470589,
      "grad_norm": 1.0692392587661743,
      "learning_rate": 7.30468085106383e-06,
      "loss": 0.0881,
      "step": 4475
    },
    {
      "epoch": 1.0284926470588236,
      "grad_norm": 1.1065526008605957,
      "learning_rate": 7.303829787234044e-06,
      "loss": 0.1094,
      "step": 4476
    },
    {
      "epoch": 1.0287224264705883,
      "grad_norm": 1.1799768209457397,
      "learning_rate": 7.302978723404256e-06,
      "loss": 0.095,
      "step": 4477
    },
    {
      "epoch": 1.028952205882353,
      "grad_norm": 1.6844133138656616,
      "learning_rate": 7.302127659574468e-06,
      "loss": 0.1435,
      "step": 4478
    },
    {
      "epoch": 1.0291819852941178,
      "grad_norm": 0.9995255470275879,
      "learning_rate": 7.3012765957446815e-06,
      "loss": 0.0719,
      "step": 4479
    },
    {
      "epoch": 1.0294117647058822,
      "grad_norm": 1.1966304779052734,
      "learning_rate": 7.300425531914894e-06,
      "loss": 0.0906,
      "step": 4480
    },
    {
      "epoch": 1.029641544117647,
      "grad_norm": 2.2579689025878906,
      "learning_rate": 7.299574468085107e-06,
      "loss": 0.0868,
      "step": 4481
    },
    {
      "epoch": 1.0298713235294117,
      "grad_norm": 1.4117062091827393,
      "learning_rate": 7.29872340425532e-06,
      "loss": 0.0765,
      "step": 4482
    },
    {
      "epoch": 1.0301011029411764,
      "grad_norm": 1.1442474126815796,
      "learning_rate": 7.2978723404255325e-06,
      "loss": 0.0793,
      "step": 4483
    },
    {
      "epoch": 1.0303308823529411,
      "grad_norm": 1.2282241582870483,
      "learning_rate": 7.297021276595745e-06,
      "loss": 0.0824,
      "step": 4484
    },
    {
      "epoch": 1.0305606617647058,
      "grad_norm": 1.1385046243667603,
      "learning_rate": 7.296170212765958e-06,
      "loss": 0.073,
      "step": 4485
    },
    {
      "epoch": 1.0307904411764706,
      "grad_norm": 0.969639003276825,
      "learning_rate": 7.295319148936171e-06,
      "loss": 0.0559,
      "step": 4486
    },
    {
      "epoch": 1.0310202205882353,
      "grad_norm": 0.8657026886940002,
      "learning_rate": 7.2944680851063835e-06,
      "loss": 0.0692,
      "step": 4487
    },
    {
      "epoch": 1.03125,
      "grad_norm": 1.6109960079193115,
      "learning_rate": 7.293617021276597e-06,
      "loss": 0.0842,
      "step": 4488
    },
    {
      "epoch": 1.0314797794117647,
      "grad_norm": 1.3851735591888428,
      "learning_rate": 7.292765957446809e-06,
      "loss": 0.0831,
      "step": 4489
    },
    {
      "epoch": 1.0317095588235294,
      "grad_norm": 0.9760485887527466,
      "learning_rate": 7.291914893617021e-06,
      "loss": 0.0753,
      "step": 4490
    },
    {
      "epoch": 1.0319393382352942,
      "grad_norm": 1.576014518737793,
      "learning_rate": 7.291063829787235e-06,
      "loss": 0.1143,
      "step": 4491
    },
    {
      "epoch": 1.0321691176470589,
      "grad_norm": 1.2069356441497803,
      "learning_rate": 7.290212765957448e-06,
      "loss": 0.0764,
      "step": 4492
    },
    {
      "epoch": 1.0323988970588236,
      "grad_norm": 0.9865815043449402,
      "learning_rate": 7.28936170212766e-06,
      "loss": 0.0705,
      "step": 4493
    },
    {
      "epoch": 1.0326286764705883,
      "grad_norm": 0.8952644467353821,
      "learning_rate": 7.288510638297873e-06,
      "loss": 0.0787,
      "step": 4494
    },
    {
      "epoch": 1.032858455882353,
      "grad_norm": 1.0829977989196777,
      "learning_rate": 7.2876595744680855e-06,
      "loss": 0.0553,
      "step": 4495
    },
    {
      "epoch": 1.0330882352941178,
      "grad_norm": 1.043591022491455,
      "learning_rate": 7.286808510638298e-06,
      "loss": 0.0814,
      "step": 4496
    },
    {
      "epoch": 1.0333180147058822,
      "grad_norm": 0.9624454379081726,
      "learning_rate": 7.285957446808512e-06,
      "loss": 0.0782,
      "step": 4497
    },
    {
      "epoch": 1.033547794117647,
      "grad_norm": 1.2407835721969604,
      "learning_rate": 7.285106382978724e-06,
      "loss": 0.0855,
      "step": 4498
    },
    {
      "epoch": 1.0337775735294117,
      "grad_norm": 0.9723525047302246,
      "learning_rate": 7.2842553191489364e-06,
      "loss": 0.1046,
      "step": 4499
    },
    {
      "epoch": 1.0340073529411764,
      "grad_norm": 0.9129446148872375,
      "learning_rate": 7.28340425531915e-06,
      "loss": 0.0696,
      "step": 4500
    },
    {
      "epoch": 1.0340073529411764,
      "eval_loss": 0.09843694418668747,
      "eval_runtime": 1966.0715,
      "eval_samples_per_second": 4.53,
      "eval_steps_per_second": 2.265,
      "step": 4500
    },
    {
      "epoch": 1.0342371323529411,
      "grad_norm": 1.1300585269927979,
      "learning_rate": 7.282553191489362e-06,
      "loss": 0.0915,
      "step": 4501
    },
    {
      "epoch": 1.0344669117647058,
      "grad_norm": 2.0255463123321533,
      "learning_rate": 7.281702127659574e-06,
      "loss": 0.1202,
      "step": 4502
    },
    {
      "epoch": 1.0346966911764706,
      "grad_norm": 1.2087712287902832,
      "learning_rate": 7.280851063829788e-06,
      "loss": 0.062,
      "step": 4503
    },
    {
      "epoch": 1.0349264705882353,
      "grad_norm": 0.9921870231628418,
      "learning_rate": 7.280000000000001e-06,
      "loss": 0.071,
      "step": 4504
    },
    {
      "epoch": 1.03515625,
      "grad_norm": 1.1016626358032227,
      "learning_rate": 7.279148936170214e-06,
      "loss": 0.1117,
      "step": 4505
    },
    {
      "epoch": 1.0353860294117647,
      "grad_norm": 1.2457305192947388,
      "learning_rate": 7.278297872340426e-06,
      "loss": 0.0927,
      "step": 4506
    },
    {
      "epoch": 1.0356158088235294,
      "grad_norm": 1.5596134662628174,
      "learning_rate": 7.277446808510638e-06,
      "loss": 0.1172,
      "step": 4507
    },
    {
      "epoch": 1.0358455882352942,
      "grad_norm": 1.3554315567016602,
      "learning_rate": 7.2765957446808524e-06,
      "loss": 0.0692,
      "step": 4508
    },
    {
      "epoch": 1.0360753676470589,
      "grad_norm": 1.568153977394104,
      "learning_rate": 7.275744680851065e-06,
      "loss": 0.1078,
      "step": 4509
    },
    {
      "epoch": 1.0363051470588236,
      "grad_norm": 1.1546255350112915,
      "learning_rate": 7.274893617021277e-06,
      "loss": 0.0783,
      "step": 4510
    },
    {
      "epoch": 1.0365349264705883,
      "grad_norm": 1.881700038909912,
      "learning_rate": 7.27404255319149e-06,
      "loss": 0.1112,
      "step": 4511
    },
    {
      "epoch": 1.036764705882353,
      "grad_norm": 1.8824409246444702,
      "learning_rate": 7.273191489361703e-06,
      "loss": 0.1311,
      "step": 4512
    },
    {
      "epoch": 1.0369944852941178,
      "grad_norm": 1.485177993774414,
      "learning_rate": 7.272340425531915e-06,
      "loss": 0.1374,
      "step": 4513
    },
    {
      "epoch": 1.0372242647058822,
      "grad_norm": 1.5556608438491821,
      "learning_rate": 7.271489361702129e-06,
      "loss": 0.1242,
      "step": 4514
    },
    {
      "epoch": 1.037454044117647,
      "grad_norm": 1.4320722818374634,
      "learning_rate": 7.270638297872341e-06,
      "loss": 0.0812,
      "step": 4515
    },
    {
      "epoch": 1.0376838235294117,
      "grad_norm": 1.0393991470336914,
      "learning_rate": 7.2697872340425536e-06,
      "loss": 0.0518,
      "step": 4516
    },
    {
      "epoch": 1.0379136029411764,
      "grad_norm": 1.6473019123077393,
      "learning_rate": 7.268936170212767e-06,
      "loss": 0.1031,
      "step": 4517
    },
    {
      "epoch": 1.0381433823529411,
      "grad_norm": 1.3854141235351562,
      "learning_rate": 7.268085106382979e-06,
      "loss": 0.0614,
      "step": 4518
    },
    {
      "epoch": 1.0383731617647058,
      "grad_norm": 1.5607616901397705,
      "learning_rate": 7.267234042553191e-06,
      "loss": 0.1035,
      "step": 4519
    },
    {
      "epoch": 1.0386029411764706,
      "grad_norm": 1.4088200330734253,
      "learning_rate": 7.266382978723405e-06,
      "loss": 0.091,
      "step": 4520
    },
    {
      "epoch": 1.0388327205882353,
      "grad_norm": 1.475752353668213,
      "learning_rate": 7.265531914893618e-06,
      "loss": 0.0768,
      "step": 4521
    },
    {
      "epoch": 1.0390625,
      "grad_norm": 1.643019676208496,
      "learning_rate": 7.26468085106383e-06,
      "loss": 0.12,
      "step": 4522
    },
    {
      "epoch": 1.0392922794117647,
      "grad_norm": 1.3832001686096191,
      "learning_rate": 7.263829787234043e-06,
      "loss": 0.0831,
      "step": 4523
    },
    {
      "epoch": 1.0395220588235294,
      "grad_norm": 1.2049241065979004,
      "learning_rate": 7.2629787234042555e-06,
      "loss": 0.0781,
      "step": 4524
    },
    {
      "epoch": 1.0397518382352942,
      "grad_norm": 1.0068122148513794,
      "learning_rate": 7.262127659574469e-06,
      "loss": 0.078,
      "step": 4525
    },
    {
      "epoch": 1.0399816176470589,
      "grad_norm": 1.128390908241272,
      "learning_rate": 7.261276595744682e-06,
      "loss": 0.099,
      "step": 4526
    },
    {
      "epoch": 1.0402113970588236,
      "grad_norm": 1.4835511445999146,
      "learning_rate": 7.260425531914894e-06,
      "loss": 0.1121,
      "step": 4527
    },
    {
      "epoch": 1.0404411764705883,
      "grad_norm": 1.2435059547424316,
      "learning_rate": 7.2595744680851065e-06,
      "loss": 0.0767,
      "step": 4528
    },
    {
      "epoch": 1.040670955882353,
      "grad_norm": 1.0462307929992676,
      "learning_rate": 7.25872340425532e-06,
      "loss": 0.0832,
      "step": 4529
    },
    {
      "epoch": 1.0409007352941178,
      "grad_norm": 1.1722056865692139,
      "learning_rate": 7.257872340425533e-06,
      "loss": 0.088,
      "step": 4530
    },
    {
      "epoch": 1.0411305147058822,
      "grad_norm": 1.0853807926177979,
      "learning_rate": 7.257021276595745e-06,
      "loss": 0.0862,
      "step": 4531
    },
    {
      "epoch": 1.041360294117647,
      "grad_norm": 1.237265944480896,
      "learning_rate": 7.256170212765958e-06,
      "loss": 0.1099,
      "step": 4532
    },
    {
      "epoch": 1.0415900735294117,
      "grad_norm": 1.0173838138580322,
      "learning_rate": 7.255319148936171e-06,
      "loss": 0.1089,
      "step": 4533
    },
    {
      "epoch": 1.0418198529411764,
      "grad_norm": 1.436232566833496,
      "learning_rate": 7.254468085106383e-06,
      "loss": 0.1166,
      "step": 4534
    },
    {
      "epoch": 1.0420496323529411,
      "grad_norm": 1.1044455766677856,
      "learning_rate": 7.253617021276597e-06,
      "loss": 0.1011,
      "step": 4535
    },
    {
      "epoch": 1.0422794117647058,
      "grad_norm": 0.9391202926635742,
      "learning_rate": 7.252765957446809e-06,
      "loss": 0.0888,
      "step": 4536
    },
    {
      "epoch": 1.0425091911764706,
      "grad_norm": 1.2254621982574463,
      "learning_rate": 7.251914893617022e-06,
      "loss": 0.1261,
      "step": 4537
    },
    {
      "epoch": 1.0427389705882353,
      "grad_norm": 1.134405255317688,
      "learning_rate": 7.251063829787235e-06,
      "loss": 0.09,
      "step": 4538
    },
    {
      "epoch": 1.04296875,
      "grad_norm": 0.978125274181366,
      "learning_rate": 7.250212765957447e-06,
      "loss": 0.0716,
      "step": 4539
    },
    {
      "epoch": 1.0431985294117647,
      "grad_norm": 1.083986520767212,
      "learning_rate": 7.2493617021276595e-06,
      "loss": 0.0759,
      "step": 4540
    },
    {
      "epoch": 1.0434283088235294,
      "grad_norm": 1.2684046030044556,
      "learning_rate": 7.2485106382978735e-06,
      "loss": 0.0857,
      "step": 4541
    },
    {
      "epoch": 1.0436580882352942,
      "grad_norm": 1.4152101278305054,
      "learning_rate": 7.247659574468086e-06,
      "loss": 0.1118,
      "step": 4542
    },
    {
      "epoch": 1.0438878676470589,
      "grad_norm": 1.17569899559021,
      "learning_rate": 7.246808510638298e-06,
      "loss": 0.0718,
      "step": 4543
    },
    {
      "epoch": 1.0441176470588236,
      "grad_norm": 1.2505409717559814,
      "learning_rate": 7.245957446808511e-06,
      "loss": 0.1299,
      "step": 4544
    },
    {
      "epoch": 1.0443474264705883,
      "grad_norm": 1.426072359085083,
      "learning_rate": 7.245106382978724e-06,
      "loss": 0.0835,
      "step": 4545
    },
    {
      "epoch": 1.044577205882353,
      "grad_norm": 1.5535969734191895,
      "learning_rate": 7.244255319148938e-06,
      "loss": 0.1026,
      "step": 4546
    },
    {
      "epoch": 1.0448069852941178,
      "grad_norm": 0.8818151950836182,
      "learning_rate": 7.24340425531915e-06,
      "loss": 0.0584,
      "step": 4547
    },
    {
      "epoch": 1.0450367647058822,
      "grad_norm": 1.1938799619674683,
      "learning_rate": 7.242553191489362e-06,
      "loss": 0.0797,
      "step": 4548
    },
    {
      "epoch": 1.045266544117647,
      "grad_norm": 1.0822768211364746,
      "learning_rate": 7.2417021276595755e-06,
      "loss": 0.0878,
      "step": 4549
    },
    {
      "epoch": 1.0454963235294117,
      "grad_norm": 1.3485785722732544,
      "learning_rate": 7.240851063829788e-06,
      "loss": 0.1074,
      "step": 4550
    },
    {
      "epoch": 1.0457261029411764,
      "grad_norm": 1.2591125965118408,
      "learning_rate": 7.24e-06,
      "loss": 0.0966,
      "step": 4551
    },
    {
      "epoch": 1.0459558823529411,
      "grad_norm": 1.5086010694503784,
      "learning_rate": 7.239148936170214e-06,
      "loss": 0.0911,
      "step": 4552
    },
    {
      "epoch": 1.0461856617647058,
      "grad_norm": 1.2061357498168945,
      "learning_rate": 7.2382978723404265e-06,
      "loss": 0.0747,
      "step": 4553
    },
    {
      "epoch": 1.0464154411764706,
      "grad_norm": 1.096605658531189,
      "learning_rate": 7.237446808510639e-06,
      "loss": 0.0856,
      "step": 4554
    },
    {
      "epoch": 1.0466452205882353,
      "grad_norm": 1.0719226598739624,
      "learning_rate": 7.236595744680852e-06,
      "loss": 0.1234,
      "step": 4555
    },
    {
      "epoch": 1.046875,
      "grad_norm": 1.1766047477722168,
      "learning_rate": 7.235744680851064e-06,
      "loss": 0.0803,
      "step": 4556
    },
    {
      "epoch": 1.0471047794117647,
      "grad_norm": 1.0962941646575928,
      "learning_rate": 7.234893617021277e-06,
      "loss": 0.0795,
      "step": 4557
    },
    {
      "epoch": 1.0473345588235294,
      "grad_norm": 1.131624460220337,
      "learning_rate": 7.234042553191491e-06,
      "loss": 0.1093,
      "step": 4558
    },
    {
      "epoch": 1.0475643382352942,
      "grad_norm": 1.0426620244979858,
      "learning_rate": 7.233191489361703e-06,
      "loss": 0.0887,
      "step": 4559
    },
    {
      "epoch": 1.0477941176470589,
      "grad_norm": 1.0718744993209839,
      "learning_rate": 7.232340425531915e-06,
      "loss": 0.0811,
      "step": 4560
    },
    {
      "epoch": 1.0480238970588236,
      "grad_norm": 1.0739463567733765,
      "learning_rate": 7.2314893617021285e-06,
      "loss": 0.101,
      "step": 4561
    },
    {
      "epoch": 1.0482536764705883,
      "grad_norm": 1.3983912467956543,
      "learning_rate": 7.230638297872341e-06,
      "loss": 0.0934,
      "step": 4562
    },
    {
      "epoch": 1.048483455882353,
      "grad_norm": 1.6220556497573853,
      "learning_rate": 7.229787234042553e-06,
      "loss": 0.0746,
      "step": 4563
    },
    {
      "epoch": 1.0487132352941178,
      "grad_norm": 1.147019624710083,
      "learning_rate": 7.228936170212767e-06,
      "loss": 0.0791,
      "step": 4564
    },
    {
      "epoch": 1.0489430147058822,
      "grad_norm": 1.3188972473144531,
      "learning_rate": 7.2280851063829794e-06,
      "loss": 0.0591,
      "step": 4565
    },
    {
      "epoch": 1.049172794117647,
      "grad_norm": 1.0312455892562866,
      "learning_rate": 7.227234042553192e-06,
      "loss": 0.0875,
      "step": 4566
    },
    {
      "epoch": 1.0494025735294117,
      "grad_norm": 1.1818166971206665,
      "learning_rate": 7.226382978723405e-06,
      "loss": 0.0742,
      "step": 4567
    },
    {
      "epoch": 1.0496323529411764,
      "grad_norm": 1.3287357091903687,
      "learning_rate": 7.225531914893617e-06,
      "loss": 0.1067,
      "step": 4568
    },
    {
      "epoch": 1.0498621323529411,
      "grad_norm": 1.3565881252288818,
      "learning_rate": 7.22468085106383e-06,
      "loss": 0.1213,
      "step": 4569
    },
    {
      "epoch": 1.0500919117647058,
      "grad_norm": 1.4651111364364624,
      "learning_rate": 7.223829787234044e-06,
      "loss": 0.0969,
      "step": 4570
    },
    {
      "epoch": 1.0503216911764706,
      "grad_norm": 0.9425145983695984,
      "learning_rate": 7.222978723404256e-06,
      "loss": 0.0642,
      "step": 4571
    },
    {
      "epoch": 1.0505514705882353,
      "grad_norm": 0.9349968433380127,
      "learning_rate": 7.222127659574468e-06,
      "loss": 0.097,
      "step": 4572
    },
    {
      "epoch": 1.05078125,
      "grad_norm": 0.9259957075119019,
      "learning_rate": 7.221276595744681e-06,
      "loss": 0.0821,
      "step": 4573
    },
    {
      "epoch": 1.0510110294117647,
      "grad_norm": 1.1435414552688599,
      "learning_rate": 7.220425531914894e-06,
      "loss": 0.0762,
      "step": 4574
    },
    {
      "epoch": 1.0512408088235294,
      "grad_norm": 1.1183453798294067,
      "learning_rate": 7.219574468085107e-06,
      "loss": 0.0773,
      "step": 4575
    },
    {
      "epoch": 1.0514705882352942,
      "grad_norm": 1.7717267274856567,
      "learning_rate": 7.21872340425532e-06,
      "loss": 0.0992,
      "step": 4576
    },
    {
      "epoch": 1.0517003676470589,
      "grad_norm": 1.0695538520812988,
      "learning_rate": 7.217872340425532e-06,
      "loss": 0.0917,
      "step": 4577
    },
    {
      "epoch": 1.0519301470588236,
      "grad_norm": 1.6091933250427246,
      "learning_rate": 7.217021276595745e-06,
      "loss": 0.1373,
      "step": 4578
    },
    {
      "epoch": 1.0521599264705883,
      "grad_norm": 1.1744487285614014,
      "learning_rate": 7.216170212765958e-06,
      "loss": 0.0954,
      "step": 4579
    },
    {
      "epoch": 1.052389705882353,
      "grad_norm": 1.2861013412475586,
      "learning_rate": 7.215319148936171e-06,
      "loss": 0.0793,
      "step": 4580
    },
    {
      "epoch": 1.0526194852941178,
      "grad_norm": 1.305649995803833,
      "learning_rate": 7.214468085106383e-06,
      "loss": 0.127,
      "step": 4581
    },
    {
      "epoch": 1.0528492647058822,
      "grad_norm": 1.084946632385254,
      "learning_rate": 7.2136170212765966e-06,
      "loss": 0.0635,
      "step": 4582
    },
    {
      "epoch": 1.053079044117647,
      "grad_norm": 1.310002088546753,
      "learning_rate": 7.212765957446809e-06,
      "loss": 0.0967,
      "step": 4583
    },
    {
      "epoch": 1.0533088235294117,
      "grad_norm": 1.1732585430145264,
      "learning_rate": 7.211914893617021e-06,
      "loss": 0.0884,
      "step": 4584
    },
    {
      "epoch": 1.0535386029411764,
      "grad_norm": 1.2907699346542358,
      "learning_rate": 7.211063829787235e-06,
      "loss": 0.0749,
      "step": 4585
    },
    {
      "epoch": 1.0537683823529411,
      "grad_norm": 0.9490957856178284,
      "learning_rate": 7.2102127659574476e-06,
      "loss": 0.0688,
      "step": 4586
    },
    {
      "epoch": 1.0539981617647058,
      "grad_norm": 1.473517656326294,
      "learning_rate": 7.20936170212766e-06,
      "loss": 0.1501,
      "step": 4587
    },
    {
      "epoch": 1.0542279411764706,
      "grad_norm": 1.5119237899780273,
      "learning_rate": 7.208510638297873e-06,
      "loss": 0.1341,
      "step": 4588
    },
    {
      "epoch": 1.0544577205882353,
      "grad_norm": 1.7667150497436523,
      "learning_rate": 7.207659574468085e-06,
      "loss": 0.1166,
      "step": 4589
    },
    {
      "epoch": 1.0546875,
      "grad_norm": 1.7214282751083374,
      "learning_rate": 7.206808510638299e-06,
      "loss": 0.1338,
      "step": 4590
    },
    {
      "epoch": 1.0549172794117647,
      "grad_norm": 2.0488014221191406,
      "learning_rate": 7.205957446808512e-06,
      "loss": 0.1062,
      "step": 4591
    },
    {
      "epoch": 1.0551470588235294,
      "grad_norm": 1.9313151836395264,
      "learning_rate": 7.205106382978724e-06,
      "loss": 0.0886,
      "step": 4592
    },
    {
      "epoch": 1.0553768382352942,
      "grad_norm": 1.289035439491272,
      "learning_rate": 7.204255319148937e-06,
      "loss": 0.0948,
      "step": 4593
    },
    {
      "epoch": 1.0556066176470589,
      "grad_norm": 1.2879760265350342,
      "learning_rate": 7.2034042553191495e-06,
      "loss": 0.1291,
      "step": 4594
    },
    {
      "epoch": 1.0558363970588236,
      "grad_norm": 1.2450542449951172,
      "learning_rate": 7.202553191489362e-06,
      "loss": 0.0883,
      "step": 4595
    },
    {
      "epoch": 1.0560661764705883,
      "grad_norm": 1.1428660154342651,
      "learning_rate": 7.201702127659576e-06,
      "loss": 0.0758,
      "step": 4596
    },
    {
      "epoch": 1.056295955882353,
      "grad_norm": 1.2613826990127563,
      "learning_rate": 7.200851063829788e-06,
      "loss": 0.0744,
      "step": 4597
    },
    {
      "epoch": 1.0565257352941178,
      "grad_norm": 1.737882375717163,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 0.1081,
      "step": 4598
    },
    {
      "epoch": 1.0567555147058822,
      "grad_norm": 1.5151385068893433,
      "learning_rate": 7.199148936170214e-06,
      "loss": 0.0879,
      "step": 4599
    },
    {
      "epoch": 1.056985294117647,
      "grad_norm": 1.5020791292190552,
      "learning_rate": 7.198297872340426e-06,
      "loss": 0.1143,
      "step": 4600
    },
    {
      "epoch": 1.0572150735294117,
      "grad_norm": 1.3864864110946655,
      "learning_rate": 7.197446808510638e-06,
      "loss": 0.0843,
      "step": 4601
    },
    {
      "epoch": 1.0574448529411764,
      "grad_norm": 1.288793683052063,
      "learning_rate": 7.196595744680852e-06,
      "loss": 0.0907,
      "step": 4602
    },
    {
      "epoch": 1.0576746323529411,
      "grad_norm": 1.3736764192581177,
      "learning_rate": 7.195744680851065e-06,
      "loss": 0.1,
      "step": 4603
    },
    {
      "epoch": 1.0579044117647058,
      "grad_norm": 1.25470769405365,
      "learning_rate": 7.194893617021277e-06,
      "loss": 0.1109,
      "step": 4604
    },
    {
      "epoch": 1.0581341911764706,
      "grad_norm": 0.9458820819854736,
      "learning_rate": 7.19404255319149e-06,
      "loss": 0.0614,
      "step": 4605
    },
    {
      "epoch": 1.0583639705882353,
      "grad_norm": 1.833787441253662,
      "learning_rate": 7.1931914893617025e-06,
      "loss": 0.101,
      "step": 4606
    },
    {
      "epoch": 1.05859375,
      "grad_norm": 1.305293083190918,
      "learning_rate": 7.192340425531915e-06,
      "loss": 0.1011,
      "step": 4607
    },
    {
      "epoch": 1.0588235294117647,
      "grad_norm": 0.9143835306167603,
      "learning_rate": 7.191489361702129e-06,
      "loss": 0.0615,
      "step": 4608
    },
    {
      "epoch": 1.0590533088235294,
      "grad_norm": 1.1698386669158936,
      "learning_rate": 7.190638297872341e-06,
      "loss": 0.0685,
      "step": 4609
    },
    {
      "epoch": 1.0592830882352942,
      "grad_norm": 0.7478107810020447,
      "learning_rate": 7.1897872340425535e-06,
      "loss": 0.0687,
      "step": 4610
    },
    {
      "epoch": 1.0595128676470589,
      "grad_norm": 1.5700609683990479,
      "learning_rate": 7.188936170212767e-06,
      "loss": 0.1029,
      "step": 4611
    },
    {
      "epoch": 1.0597426470588236,
      "grad_norm": 1.3311755657196045,
      "learning_rate": 7.188085106382979e-06,
      "loss": 0.0856,
      "step": 4612
    },
    {
      "epoch": 1.0599724264705883,
      "grad_norm": 1.6329435110092163,
      "learning_rate": 7.187234042553191e-06,
      "loss": 0.1163,
      "step": 4613
    },
    {
      "epoch": 1.060202205882353,
      "grad_norm": 1.1019988059997559,
      "learning_rate": 7.186382978723405e-06,
      "loss": 0.0683,
      "step": 4614
    },
    {
      "epoch": 1.0604319852941178,
      "grad_norm": 1.0272953510284424,
      "learning_rate": 7.185531914893618e-06,
      "loss": 0.057,
      "step": 4615
    },
    {
      "epoch": 1.0606617647058822,
      "grad_norm": 1.1874500513076782,
      "learning_rate": 7.18468085106383e-06,
      "loss": 0.0854,
      "step": 4616
    },
    {
      "epoch": 1.060891544117647,
      "grad_norm": 1.1076157093048096,
      "learning_rate": 7.183829787234043e-06,
      "loss": 0.0677,
      "step": 4617
    },
    {
      "epoch": 1.0611213235294117,
      "grad_norm": 0.9526940584182739,
      "learning_rate": 7.1829787234042555e-06,
      "loss": 0.0706,
      "step": 4618
    },
    {
      "epoch": 1.0613511029411764,
      "grad_norm": 1.1880682706832886,
      "learning_rate": 7.182127659574469e-06,
      "loss": 0.0824,
      "step": 4619
    },
    {
      "epoch": 1.0615808823529411,
      "grad_norm": 1.412821650505066,
      "learning_rate": 7.181276595744682e-06,
      "loss": 0.1127,
      "step": 4620
    },
    {
      "epoch": 1.0618106617647058,
      "grad_norm": 1.2862658500671387,
      "learning_rate": 7.180425531914894e-06,
      "loss": 0.105,
      "step": 4621
    },
    {
      "epoch": 1.0620404411764706,
      "grad_norm": 1.1338977813720703,
      "learning_rate": 7.1795744680851065e-06,
      "loss": 0.0762,
      "step": 4622
    },
    {
      "epoch": 1.0622702205882353,
      "grad_norm": 0.989434540271759,
      "learning_rate": 7.17872340425532e-06,
      "loss": 0.0796,
      "step": 4623
    },
    {
      "epoch": 1.0625,
      "grad_norm": 1.0736600160598755,
      "learning_rate": 7.177872340425533e-06,
      "loss": 0.0823,
      "step": 4624
    },
    {
      "epoch": 1.0627297794117647,
      "grad_norm": 1.0170223712921143,
      "learning_rate": 7.177021276595745e-06,
      "loss": 0.0713,
      "step": 4625
    },
    {
      "epoch": 1.0629595588235294,
      "grad_norm": 1.4810477495193481,
      "learning_rate": 7.176170212765958e-06,
      "loss": 0.1344,
      "step": 4626
    },
    {
      "epoch": 1.0631893382352942,
      "grad_norm": 1.5323684215545654,
      "learning_rate": 7.175319148936171e-06,
      "loss": 0.0811,
      "step": 4627
    },
    {
      "epoch": 1.0634191176470589,
      "grad_norm": 1.21956467628479,
      "learning_rate": 7.174468085106383e-06,
      "loss": 0.0979,
      "step": 4628
    },
    {
      "epoch": 1.0636488970588236,
      "grad_norm": 1.249980092048645,
      "learning_rate": 7.173617021276597e-06,
      "loss": 0.0887,
      "step": 4629
    },
    {
      "epoch": 1.0638786764705883,
      "grad_norm": 1.4178117513656616,
      "learning_rate": 7.172765957446809e-06,
      "loss": 0.1067,
      "step": 4630
    },
    {
      "epoch": 1.064108455882353,
      "grad_norm": 1.0310934782028198,
      "learning_rate": 7.171914893617022e-06,
      "loss": 0.1012,
      "step": 4631
    },
    {
      "epoch": 1.0643382352941178,
      "grad_norm": 1.1382017135620117,
      "learning_rate": 7.171063829787235e-06,
      "loss": 0.0746,
      "step": 4632
    },
    {
      "epoch": 1.0645680147058822,
      "grad_norm": 1.3215246200561523,
      "learning_rate": 7.170212765957447e-06,
      "loss": 0.0795,
      "step": 4633
    },
    {
      "epoch": 1.064797794117647,
      "grad_norm": 0.7633955478668213,
      "learning_rate": 7.169361702127661e-06,
      "loss": 0.0558,
      "step": 4634
    },
    {
      "epoch": 1.0650275735294117,
      "grad_norm": 1.386781930923462,
      "learning_rate": 7.1685106382978734e-06,
      "loss": 0.0891,
      "step": 4635
    },
    {
      "epoch": 1.0652573529411764,
      "grad_norm": 1.2453421354293823,
      "learning_rate": 7.167659574468086e-06,
      "loss": 0.0759,
      "step": 4636
    },
    {
      "epoch": 1.0654871323529411,
      "grad_norm": 1.037460446357727,
      "learning_rate": 7.166808510638299e-06,
      "loss": 0.0771,
      "step": 4637
    },
    {
      "epoch": 1.0657169117647058,
      "grad_norm": 1.2505854368209839,
      "learning_rate": 7.165957446808511e-06,
      "loss": 0.0809,
      "step": 4638
    },
    {
      "epoch": 1.0659466911764706,
      "grad_norm": 1.4818307161331177,
      "learning_rate": 7.1651063829787236e-06,
      "loss": 0.0877,
      "step": 4639
    },
    {
      "epoch": 1.0661764705882353,
      "grad_norm": 1.0769908428192139,
      "learning_rate": 7.164255319148938e-06,
      "loss": 0.0689,
      "step": 4640
    },
    {
      "epoch": 1.06640625,
      "grad_norm": 1.1068410873413086,
      "learning_rate": 7.16340425531915e-06,
      "loss": 0.0766,
      "step": 4641
    },
    {
      "epoch": 1.0666360294117647,
      "grad_norm": 1.1235333681106567,
      "learning_rate": 7.162553191489362e-06,
      "loss": 0.1011,
      "step": 4642
    },
    {
      "epoch": 1.0668658088235294,
      "grad_norm": 1.6352161169052124,
      "learning_rate": 7.161702127659575e-06,
      "loss": 0.1073,
      "step": 4643
    },
    {
      "epoch": 1.0670955882352942,
      "grad_norm": 1.5683990716934204,
      "learning_rate": 7.160851063829788e-06,
      "loss": 0.129,
      "step": 4644
    },
    {
      "epoch": 1.0673253676470589,
      "grad_norm": 1.0462279319763184,
      "learning_rate": 7.16e-06,
      "loss": 0.0796,
      "step": 4645
    },
    {
      "epoch": 1.0675551470588236,
      "grad_norm": 1.3450819253921509,
      "learning_rate": 7.159148936170214e-06,
      "loss": 0.0813,
      "step": 4646
    },
    {
      "epoch": 1.0677849264705883,
      "grad_norm": 1.1456347703933716,
      "learning_rate": 7.158297872340426e-06,
      "loss": 0.1012,
      "step": 4647
    },
    {
      "epoch": 1.068014705882353,
      "grad_norm": 1.0183770656585693,
      "learning_rate": 7.157446808510639e-06,
      "loss": 0.08,
      "step": 4648
    },
    {
      "epoch": 1.0682444852941178,
      "grad_norm": 1.4282208681106567,
      "learning_rate": 7.156595744680852e-06,
      "loss": 0.0642,
      "step": 4649
    },
    {
      "epoch": 1.0684742647058822,
      "grad_norm": 1.199965238571167,
      "learning_rate": 7.155744680851064e-06,
      "loss": 0.0919,
      "step": 4650
    },
    {
      "epoch": 1.068704044117647,
      "grad_norm": 1.3637197017669678,
      "learning_rate": 7.1548936170212765e-06,
      "loss": 0.1137,
      "step": 4651
    },
    {
      "epoch": 1.0689338235294117,
      "grad_norm": 1.4796860218048096,
      "learning_rate": 7.1540425531914906e-06,
      "loss": 0.085,
      "step": 4652
    },
    {
      "epoch": 1.0691636029411764,
      "grad_norm": 1.0622689723968506,
      "learning_rate": 7.153191489361703e-06,
      "loss": 0.0807,
      "step": 4653
    },
    {
      "epoch": 1.0693933823529411,
      "grad_norm": 1.2227751016616821,
      "learning_rate": 7.152340425531915e-06,
      "loss": 0.0773,
      "step": 4654
    },
    {
      "epoch": 1.0696231617647058,
      "grad_norm": 1.1699371337890625,
      "learning_rate": 7.151489361702128e-06,
      "loss": 0.0747,
      "step": 4655
    },
    {
      "epoch": 1.0698529411764706,
      "grad_norm": 1.3952518701553345,
      "learning_rate": 7.150638297872341e-06,
      "loss": 0.078,
      "step": 4656
    },
    {
      "epoch": 1.0700827205882353,
      "grad_norm": 1.1467368602752686,
      "learning_rate": 7.149787234042553e-06,
      "loss": 0.0594,
      "step": 4657
    },
    {
      "epoch": 1.0703125,
      "grad_norm": 1.5163776874542236,
      "learning_rate": 7.148936170212767e-06,
      "loss": 0.1495,
      "step": 4658
    },
    {
      "epoch": 1.0705422794117647,
      "grad_norm": 1.3805902004241943,
      "learning_rate": 7.148085106382979e-06,
      "loss": 0.1099,
      "step": 4659
    },
    {
      "epoch": 1.0707720588235294,
      "grad_norm": 1.1795079708099365,
      "learning_rate": 7.147234042553192e-06,
      "loss": 0.0833,
      "step": 4660
    },
    {
      "epoch": 1.0710018382352942,
      "grad_norm": 1.0948549509048462,
      "learning_rate": 7.146382978723405e-06,
      "loss": 0.0789,
      "step": 4661
    },
    {
      "epoch": 1.0712316176470589,
      "grad_norm": 1.228935718536377,
      "learning_rate": 7.145531914893617e-06,
      "loss": 0.0869,
      "step": 4662
    },
    {
      "epoch": 1.0714613970588236,
      "grad_norm": 1.2731868028640747,
      "learning_rate": 7.1446808510638295e-06,
      "loss": 0.0763,
      "step": 4663
    },
    {
      "epoch": 1.0716911764705883,
      "grad_norm": 1.3372708559036255,
      "learning_rate": 7.1438297872340435e-06,
      "loss": 0.0902,
      "step": 4664
    },
    {
      "epoch": 1.071920955882353,
      "grad_norm": 1.5819778442382812,
      "learning_rate": 7.142978723404256e-06,
      "loss": 0.1243,
      "step": 4665
    },
    {
      "epoch": 1.0721507352941178,
      "grad_norm": 1.2883825302124023,
      "learning_rate": 7.142127659574468e-06,
      "loss": 0.1128,
      "step": 4666
    },
    {
      "epoch": 1.0723805147058822,
      "grad_norm": 1.177300214767456,
      "learning_rate": 7.141276595744681e-06,
      "loss": 0.0645,
      "step": 4667
    },
    {
      "epoch": 1.072610294117647,
      "grad_norm": 1.7866472005844116,
      "learning_rate": 7.140425531914894e-06,
      "loss": 0.1294,
      "step": 4668
    },
    {
      "epoch": 1.0728400735294117,
      "grad_norm": 1.3590545654296875,
      "learning_rate": 7.139574468085107e-06,
      "loss": 0.1362,
      "step": 4669
    },
    {
      "epoch": 1.0730698529411764,
      "grad_norm": 0.8184170722961426,
      "learning_rate": 7.13872340425532e-06,
      "loss": 0.0571,
      "step": 4670
    },
    {
      "epoch": 1.0732996323529411,
      "grad_norm": 1.1887034177780151,
      "learning_rate": 7.137872340425532e-06,
      "loss": 0.0904,
      "step": 4671
    },
    {
      "epoch": 1.0735294117647058,
      "grad_norm": 1.110612154006958,
      "learning_rate": 7.137021276595745e-06,
      "loss": 0.1404,
      "step": 4672
    },
    {
      "epoch": 1.0737591911764706,
      "grad_norm": 1.5601047277450562,
      "learning_rate": 7.136170212765958e-06,
      "loss": 0.0851,
      "step": 4673
    },
    {
      "epoch": 1.0739889705882353,
      "grad_norm": 1.427152395248413,
      "learning_rate": 7.135319148936171e-06,
      "loss": 0.0908,
      "step": 4674
    },
    {
      "epoch": 1.07421875,
      "grad_norm": 1.0474010705947876,
      "learning_rate": 7.134468085106384e-06,
      "loss": 0.0667,
      "step": 4675
    },
    {
      "epoch": 1.0744485294117647,
      "grad_norm": 1.1926096677780151,
      "learning_rate": 7.1336170212765965e-06,
      "loss": 0.0951,
      "step": 4676
    },
    {
      "epoch": 1.0746783088235294,
      "grad_norm": 1.9859977960586548,
      "learning_rate": 7.132765957446809e-06,
      "loss": 0.0807,
      "step": 4677
    },
    {
      "epoch": 1.0749080882352942,
      "grad_norm": 1.4362270832061768,
      "learning_rate": 7.131914893617022e-06,
      "loss": 0.098,
      "step": 4678
    },
    {
      "epoch": 1.0751378676470589,
      "grad_norm": 1.2303593158721924,
      "learning_rate": 7.131063829787235e-06,
      "loss": 0.0709,
      "step": 4679
    },
    {
      "epoch": 1.0753676470588236,
      "grad_norm": 0.931346595287323,
      "learning_rate": 7.1302127659574475e-06,
      "loss": 0.0746,
      "step": 4680
    },
    {
      "epoch": 1.0755974264705883,
      "grad_norm": 1.136610984802246,
      "learning_rate": 7.129361702127661e-06,
      "loss": 0.1074,
      "step": 4681
    },
    {
      "epoch": 1.075827205882353,
      "grad_norm": 0.9852631688117981,
      "learning_rate": 7.128510638297873e-06,
      "loss": 0.0945,
      "step": 4682
    },
    {
      "epoch": 1.0760569852941178,
      "grad_norm": 1.4710414409637451,
      "learning_rate": 7.127659574468085e-06,
      "loss": 0.0963,
      "step": 4683
    },
    {
      "epoch": 1.0762867647058822,
      "grad_norm": 1.253583550453186,
      "learning_rate": 7.126808510638299e-06,
      "loss": 0.0907,
      "step": 4684
    },
    {
      "epoch": 1.076516544117647,
      "grad_norm": 0.8363790512084961,
      "learning_rate": 7.125957446808512e-06,
      "loss": 0.0634,
      "step": 4685
    },
    {
      "epoch": 1.0767463235294117,
      "grad_norm": 1.1931737661361694,
      "learning_rate": 7.125106382978724e-06,
      "loss": 0.084,
      "step": 4686
    },
    {
      "epoch": 1.0769761029411764,
      "grad_norm": 1.3662140369415283,
      "learning_rate": 7.124255319148937e-06,
      "loss": 0.107,
      "step": 4687
    },
    {
      "epoch": 1.0772058823529411,
      "grad_norm": 1.1277873516082764,
      "learning_rate": 7.1234042553191495e-06,
      "loss": 0.0982,
      "step": 4688
    },
    {
      "epoch": 1.0774356617647058,
      "grad_norm": 1.3022502660751343,
      "learning_rate": 7.122553191489362e-06,
      "loss": 0.1062,
      "step": 4689
    },
    {
      "epoch": 1.0776654411764706,
      "grad_norm": 0.8317500352859497,
      "learning_rate": 7.121702127659576e-06,
      "loss": 0.0733,
      "step": 4690
    },
    {
      "epoch": 1.0778952205882353,
      "grad_norm": 1.095044493675232,
      "learning_rate": 7.120851063829788e-06,
      "loss": 0.0812,
      "step": 4691
    },
    {
      "epoch": 1.078125,
      "grad_norm": 1.3671857118606567,
      "learning_rate": 7.1200000000000004e-06,
      "loss": 0.1158,
      "step": 4692
    },
    {
      "epoch": 1.0783547794117647,
      "grad_norm": 0.9741443991661072,
      "learning_rate": 7.119148936170214e-06,
      "loss": 0.087,
      "step": 4693
    },
    {
      "epoch": 1.0785845588235294,
      "grad_norm": 1.651319146156311,
      "learning_rate": 7.118297872340426e-06,
      "loss": 0.1237,
      "step": 4694
    },
    {
      "epoch": 1.0788143382352942,
      "grad_norm": 1.3602542877197266,
      "learning_rate": 7.117446808510638e-06,
      "loss": 0.0776,
      "step": 4695
    },
    {
      "epoch": 1.0790441176470589,
      "grad_norm": 1.0163626670837402,
      "learning_rate": 7.116595744680852e-06,
      "loss": 0.0756,
      "step": 4696
    },
    {
      "epoch": 1.0792738970588236,
      "grad_norm": 1.2315866947174072,
      "learning_rate": 7.115744680851065e-06,
      "loss": 0.0853,
      "step": 4697
    },
    {
      "epoch": 1.0795036764705883,
      "grad_norm": 1.0058718919754028,
      "learning_rate": 7.114893617021277e-06,
      "loss": 0.0826,
      "step": 4698
    },
    {
      "epoch": 1.079733455882353,
      "grad_norm": 1.1116061210632324,
      "learning_rate": 7.11404255319149e-06,
      "loss": 0.0767,
      "step": 4699
    },
    {
      "epoch": 1.0799632352941178,
      "grad_norm": 1.1575987339019775,
      "learning_rate": 7.113191489361702e-06,
      "loss": 0.1122,
      "step": 4700
    },
    {
      "epoch": 1.0801930147058822,
      "grad_norm": 1.1039741039276123,
      "learning_rate": 7.112340425531915e-06,
      "loss": 0.0647,
      "step": 4701
    },
    {
      "epoch": 1.080422794117647,
      "grad_norm": 1.6787184476852417,
      "learning_rate": 7.111489361702129e-06,
      "loss": 0.083,
      "step": 4702
    },
    {
      "epoch": 1.0806525735294117,
      "grad_norm": 0.8468523621559143,
      "learning_rate": 7.110638297872341e-06,
      "loss": 0.0632,
      "step": 4703
    },
    {
      "epoch": 1.0808823529411764,
      "grad_norm": 1.2345203161239624,
      "learning_rate": 7.109787234042553e-06,
      "loss": 0.0979,
      "step": 4704
    },
    {
      "epoch": 1.0811121323529411,
      "grad_norm": 1.44428288936615,
      "learning_rate": 7.1089361702127666e-06,
      "loss": 0.103,
      "step": 4705
    },
    {
      "epoch": 1.0813419117647058,
      "grad_norm": 1.0499387979507446,
      "learning_rate": 7.108085106382979e-06,
      "loss": 0.0666,
      "step": 4706
    },
    {
      "epoch": 1.0815716911764706,
      "grad_norm": 1.60313081741333,
      "learning_rate": 7.107234042553191e-06,
      "loss": 0.1254,
      "step": 4707
    },
    {
      "epoch": 1.0818014705882353,
      "grad_norm": Infinity,
      "learning_rate": 7.106382978723405e-06,
      "loss": 0.06,
      "step": 4708
    },
    {
      "epoch": 1.08203125,
      "grad_norm": 1.1869863271713257,
      "learning_rate": 7.106382978723405e-06,
      "loss": 0.0993,
      "step": 4709
    },
    {
      "epoch": 1.0822610294117647,
      "grad_norm": 1.7449629306793213,
      "learning_rate": 7.1055319148936176e-06,
      "loss": 0.1072,
      "step": 4710
    },
    {
      "epoch": 1.0824908088235294,
      "grad_norm": 1.2299679517745972,
      "learning_rate": 7.10468085106383e-06,
      "loss": 0.0735,
      "step": 4711
    },
    {
      "epoch": 1.0827205882352942,
      "grad_norm": 0.909804105758667,
      "learning_rate": 7.103829787234043e-06,
      "loss": 0.0591,
      "step": 4712
    },
    {
      "epoch": 1.0829503676470589,
      "grad_norm": 1.0513904094696045,
      "learning_rate": 7.102978723404255e-06,
      "loss": 0.0775,
      "step": 4713
    },
    {
      "epoch": 1.0831801470588236,
      "grad_norm": 1.1155016422271729,
      "learning_rate": 7.1021276595744686e-06,
      "loss": 0.0939,
      "step": 4714
    },
    {
      "epoch": 1.0834099264705883,
      "grad_norm": 1.0355790853500366,
      "learning_rate": 7.101276595744682e-06,
      "loss": 0.0761,
      "step": 4715
    },
    {
      "epoch": 1.083639705882353,
      "grad_norm": 1.3648054599761963,
      "learning_rate": 7.100425531914894e-06,
      "loss": 0.0991,
      "step": 4716
    },
    {
      "epoch": 1.0838694852941178,
      "grad_norm": 1.2560114860534668,
      "learning_rate": 7.099574468085106e-06,
      "loss": 0.1082,
      "step": 4717
    },
    {
      "epoch": 1.0840992647058822,
      "grad_norm": 1.220396876335144,
      "learning_rate": 7.0987234042553195e-06,
      "loss": 0.0773,
      "step": 4718
    },
    {
      "epoch": 1.084329044117647,
      "grad_norm": 1.2820546627044678,
      "learning_rate": 7.097872340425533e-06,
      "loss": 0.1358,
      "step": 4719
    },
    {
      "epoch": 1.0845588235294117,
      "grad_norm": 1.2411696910858154,
      "learning_rate": 7.097021276595746e-06,
      "loss": 0.0825,
      "step": 4720
    },
    {
      "epoch": 1.0847886029411764,
      "grad_norm": 1.1012994050979614,
      "learning_rate": 7.096170212765958e-06,
      "loss": 0.0749,
      "step": 4721
    },
    {
      "epoch": 1.0850183823529411,
      "grad_norm": 1.1639065742492676,
      "learning_rate": 7.0953191489361705e-06,
      "loss": 0.0826,
      "step": 4722
    },
    {
      "epoch": 1.0852481617647058,
      "grad_norm": 1.6105815172195435,
      "learning_rate": 7.094468085106384e-06,
      "loss": 0.1178,
      "step": 4723
    },
    {
      "epoch": 1.0854779411764706,
      "grad_norm": 2.6861464977264404,
      "learning_rate": 7.093617021276597e-06,
      "loss": 0.1338,
      "step": 4724
    },
    {
      "epoch": 1.0857077205882353,
      "grad_norm": 1.1580199003219604,
      "learning_rate": 7.092765957446809e-06,
      "loss": 0.0673,
      "step": 4725
    },
    {
      "epoch": 1.0859375,
      "grad_norm": 1.342394471168518,
      "learning_rate": 7.091914893617022e-06,
      "loss": 0.076,
      "step": 4726
    },
    {
      "epoch": 1.0861672794117647,
      "grad_norm": 1.5005624294281006,
      "learning_rate": 7.091063829787235e-06,
      "loss": 0.0743,
      "step": 4727
    },
    {
      "epoch": 1.0863970588235294,
      "grad_norm": 1.0290805101394653,
      "learning_rate": 7.090212765957447e-06,
      "loss": 0.0699,
      "step": 4728
    },
    {
      "epoch": 1.0866268382352942,
      "grad_norm": 1.578454613685608,
      "learning_rate": 7.089361702127661e-06,
      "loss": 0.1025,
      "step": 4729
    },
    {
      "epoch": 1.0868566176470589,
      "grad_norm": 1.0086243152618408,
      "learning_rate": 7.088510638297873e-06,
      "loss": 0.0843,
      "step": 4730
    },
    {
      "epoch": 1.0870863970588236,
      "grad_norm": 1.054093837738037,
      "learning_rate": 7.087659574468086e-06,
      "loss": 0.075,
      "step": 4731
    },
    {
      "epoch": 1.0873161764705883,
      "grad_norm": 1.3405911922454834,
      "learning_rate": 7.086808510638299e-06,
      "loss": 0.0945,
      "step": 4732
    },
    {
      "epoch": 1.087545955882353,
      "grad_norm": 1.0358794927597046,
      "learning_rate": 7.085957446808511e-06,
      "loss": 0.0888,
      "step": 4733
    },
    {
      "epoch": 1.0877757352941178,
      "grad_norm": 1.3695130348205566,
      "learning_rate": 7.0851063829787235e-06,
      "loss": 0.1036,
      "step": 4734
    },
    {
      "epoch": 1.0880055147058822,
      "grad_norm": 1.0447970628738403,
      "learning_rate": 7.0842553191489375e-06,
      "loss": 0.0876,
      "step": 4735
    },
    {
      "epoch": 1.088235294117647,
      "grad_norm": 1.2031595706939697,
      "learning_rate": 7.08340425531915e-06,
      "loss": 0.1044,
      "step": 4736
    },
    {
      "epoch": 1.0884650735294117,
      "grad_norm": 1.2280747890472412,
      "learning_rate": 7.082553191489362e-06,
      "loss": 0.1098,
      "step": 4737
    },
    {
      "epoch": 1.0886948529411764,
      "grad_norm": 1.2394124269485474,
      "learning_rate": 7.081702127659575e-06,
      "loss": 0.0848,
      "step": 4738
    },
    {
      "epoch": 1.0889246323529411,
      "grad_norm": 1.0939364433288574,
      "learning_rate": 7.080851063829788e-06,
      "loss": 0.0817,
      "step": 4739
    },
    {
      "epoch": 1.0891544117647058,
      "grad_norm": 1.1874767541885376,
      "learning_rate": 7.08e-06,
      "loss": 0.0676,
      "step": 4740
    },
    {
      "epoch": 1.0893841911764706,
      "grad_norm": 1.5015393495559692,
      "learning_rate": 7.079148936170214e-06,
      "loss": 0.1181,
      "step": 4741
    },
    {
      "epoch": 1.0896139705882353,
      "grad_norm": 0.9984325766563416,
      "learning_rate": 7.078297872340426e-06,
      "loss": 0.0771,
      "step": 4742
    },
    {
      "epoch": 1.08984375,
      "grad_norm": 1.2113579511642456,
      "learning_rate": 7.077446808510639e-06,
      "loss": 0.0959,
      "step": 4743
    },
    {
      "epoch": 1.0900735294117647,
      "grad_norm": 1.0171175003051758,
      "learning_rate": 7.076595744680852e-06,
      "loss": 0.0767,
      "step": 4744
    },
    {
      "epoch": 1.0903033088235294,
      "grad_norm": 1.0802966356277466,
      "learning_rate": 7.075744680851064e-06,
      "loss": 0.0857,
      "step": 4745
    },
    {
      "epoch": 1.0905330882352942,
      "grad_norm": 1.327027678489685,
      "learning_rate": 7.0748936170212765e-06,
      "loss": 0.0921,
      "step": 4746
    },
    {
      "epoch": 1.0907628676470589,
      "grad_norm": 1.6874046325683594,
      "learning_rate": 7.0740425531914905e-06,
      "loss": 0.139,
      "step": 4747
    },
    {
      "epoch": 1.0909926470588236,
      "grad_norm": 1.0328621864318848,
      "learning_rate": 7.073191489361703e-06,
      "loss": 0.0611,
      "step": 4748
    },
    {
      "epoch": 1.0912224264705883,
      "grad_norm": 1.2851970195770264,
      "learning_rate": 7.072340425531915e-06,
      "loss": 0.0961,
      "step": 4749
    },
    {
      "epoch": 1.091452205882353,
      "grad_norm": 1.1160824298858643,
      "learning_rate": 7.071489361702128e-06,
      "loss": 0.093,
      "step": 4750
    },
    {
      "epoch": 1.0916819852941178,
      "grad_norm": 0.9385296702384949,
      "learning_rate": 7.070638297872341e-06,
      "loss": 0.0574,
      "step": 4751
    },
    {
      "epoch": 1.0919117647058822,
      "grad_norm": 1.3503988981246948,
      "learning_rate": 7.069787234042553e-06,
      "loss": 0.0967,
      "step": 4752
    },
    {
      "epoch": 1.092141544117647,
      "grad_norm": 0.8466586470603943,
      "learning_rate": 7.068936170212767e-06,
      "loss": 0.0726,
      "step": 4753
    },
    {
      "epoch": 1.0923713235294117,
      "grad_norm": 1.1498126983642578,
      "learning_rate": 7.068085106382979e-06,
      "loss": 0.1111,
      "step": 4754
    },
    {
      "epoch": 1.0926011029411764,
      "grad_norm": 1.1076905727386475,
      "learning_rate": 7.067234042553192e-06,
      "loss": 0.0923,
      "step": 4755
    },
    {
      "epoch": 1.0928308823529411,
      "grad_norm": 1.0557425022125244,
      "learning_rate": 7.066382978723405e-06,
      "loss": 0.0812,
      "step": 4756
    },
    {
      "epoch": 1.0930606617647058,
      "grad_norm": 1.1541434526443481,
      "learning_rate": 7.065531914893617e-06,
      "loss": 0.085,
      "step": 4757
    },
    {
      "epoch": 1.0932904411764706,
      "grad_norm": 1.3227754831314087,
      "learning_rate": 7.064680851063829e-06,
      "loss": 0.1004,
      "step": 4758
    },
    {
      "epoch": 1.0935202205882353,
      "grad_norm": 1.281232237815857,
      "learning_rate": 7.0638297872340434e-06,
      "loss": 0.0924,
      "step": 4759
    },
    {
      "epoch": 1.09375,
      "grad_norm": 1.0176563262939453,
      "learning_rate": 7.062978723404256e-06,
      "loss": 0.0863,
      "step": 4760
    },
    {
      "epoch": 1.0939797794117647,
      "grad_norm": 1.2674576044082642,
      "learning_rate": 7.062127659574468e-06,
      "loss": 0.0964,
      "step": 4761
    },
    {
      "epoch": 1.0942095588235294,
      "grad_norm": 1.4211583137512207,
      "learning_rate": 7.061276595744681e-06,
      "loss": 0.0861,
      "step": 4762
    },
    {
      "epoch": 1.0944393382352942,
      "grad_norm": 1.268742561340332,
      "learning_rate": 7.060425531914894e-06,
      "loss": 0.0895,
      "step": 4763
    },
    {
      "epoch": 1.0946691176470589,
      "grad_norm": 1.0878971815109253,
      "learning_rate": 7.059574468085108e-06,
      "loss": 0.0918,
      "step": 4764
    },
    {
      "epoch": 1.0948988970588236,
      "grad_norm": 1.2768052816390991,
      "learning_rate": 7.05872340425532e-06,
      "loss": 0.0846,
      "step": 4765
    },
    {
      "epoch": 1.0951286764705883,
      "grad_norm": 1.1814337968826294,
      "learning_rate": 7.057872340425532e-06,
      "loss": 0.0659,
      "step": 4766
    },
    {
      "epoch": 1.095358455882353,
      "grad_norm": 1.202180027961731,
      "learning_rate": 7.057021276595745e-06,
      "loss": 0.1366,
      "step": 4767
    },
    {
      "epoch": 1.0955882352941178,
      "grad_norm": 1.048187255859375,
      "learning_rate": 7.056170212765958e-06,
      "loss": 0.0989,
      "step": 4768
    },
    {
      "epoch": 1.0958180147058822,
      "grad_norm": 1.556482195854187,
      "learning_rate": 7.055319148936171e-06,
      "loss": 0.0843,
      "step": 4769
    },
    {
      "epoch": 1.096047794117647,
      "grad_norm": 1.2516613006591797,
      "learning_rate": 7.054468085106384e-06,
      "loss": 0.1003,
      "step": 4770
    },
    {
      "epoch": 1.0962775735294117,
      "grad_norm": 1.4809777736663818,
      "learning_rate": 7.053617021276596e-06,
      "loss": 0.0831,
      "step": 4771
    },
    {
      "epoch": 1.0965073529411764,
      "grad_norm": 1.3861795663833618,
      "learning_rate": 7.052765957446809e-06,
      "loss": 0.0697,
      "step": 4772
    },
    {
      "epoch": 1.0967371323529411,
      "grad_norm": 1.5367399454116821,
      "learning_rate": 7.051914893617022e-06,
      "loss": 0.1197,
      "step": 4773
    },
    {
      "epoch": 1.0969669117647058,
      "grad_norm": 0.9096472859382629,
      "learning_rate": 7.051063829787235e-06,
      "loss": 0.0664,
      "step": 4774
    },
    {
      "epoch": 1.0971966911764706,
      "grad_norm": 1.533170461654663,
      "learning_rate": 7.050212765957447e-06,
      "loss": 0.1215,
      "step": 4775
    },
    {
      "epoch": 1.0974264705882353,
      "grad_norm": 1.3708418607711792,
      "learning_rate": 7.0493617021276606e-06,
      "loss": 0.1299,
      "step": 4776
    },
    {
      "epoch": 1.09765625,
      "grad_norm": 1.0685077905654907,
      "learning_rate": 7.048510638297873e-06,
      "loss": 0.0895,
      "step": 4777
    },
    {
      "epoch": 1.0978860294117647,
      "grad_norm": 0.933318555355072,
      "learning_rate": 7.047659574468085e-06,
      "loss": 0.0794,
      "step": 4778
    },
    {
      "epoch": 1.0981158088235294,
      "grad_norm": 1.7836371660232544,
      "learning_rate": 7.046808510638299e-06,
      "loss": 0.1156,
      "step": 4779
    },
    {
      "epoch": 1.0983455882352942,
      "grad_norm": 0.8809065222740173,
      "learning_rate": 7.0459574468085116e-06,
      "loss": 0.0632,
      "step": 4780
    },
    {
      "epoch": 1.0985753676470589,
      "grad_norm": 1.9906258583068848,
      "learning_rate": 7.045106382978724e-06,
      "loss": 0.1102,
      "step": 4781
    },
    {
      "epoch": 1.0988051470588236,
      "grad_norm": 1.0948582887649536,
      "learning_rate": 7.044255319148937e-06,
      "loss": 0.0559,
      "step": 4782
    },
    {
      "epoch": 1.0990349264705883,
      "grad_norm": 1.33076810836792,
      "learning_rate": 7.043404255319149e-06,
      "loss": 0.0795,
      "step": 4783
    },
    {
      "epoch": 1.099264705882353,
      "grad_norm": 1.3383439779281616,
      "learning_rate": 7.042553191489362e-06,
      "loss": 0.1032,
      "step": 4784
    },
    {
      "epoch": 1.0994944852941178,
      "grad_norm": 1.1375433206558228,
      "learning_rate": 7.041702127659576e-06,
      "loss": 0.0672,
      "step": 4785
    },
    {
      "epoch": 1.0997242647058822,
      "grad_norm": 1.1490830183029175,
      "learning_rate": 7.040851063829788e-06,
      "loss": 0.0981,
      "step": 4786
    },
    {
      "epoch": 1.099954044117647,
      "grad_norm": 1.1403429508209229,
      "learning_rate": 7.04e-06,
      "loss": 0.0799,
      "step": 4787
    },
    {
      "epoch": 1.1001838235294117,
      "grad_norm": 1.1395864486694336,
      "learning_rate": 7.0391489361702135e-06,
      "loss": 0.0886,
      "step": 4788
    },
    {
      "epoch": 1.1004136029411764,
      "grad_norm": 1.2147250175476074,
      "learning_rate": 7.038297872340426e-06,
      "loss": 0.0893,
      "step": 4789
    },
    {
      "epoch": 1.1006433823529411,
      "grad_norm": 1.1137068271636963,
      "learning_rate": 7.037446808510638e-06,
      "loss": 0.0971,
      "step": 4790
    },
    {
      "epoch": 1.1008731617647058,
      "grad_norm": 1.206599235534668,
      "learning_rate": 7.036595744680852e-06,
      "loss": 0.0966,
      "step": 4791
    },
    {
      "epoch": 1.1011029411764706,
      "grad_norm": 1.107901930809021,
      "learning_rate": 7.0357446808510645e-06,
      "loss": 0.0696,
      "step": 4792
    },
    {
      "epoch": 1.1013327205882353,
      "grad_norm": 1.344459891319275,
      "learning_rate": 7.034893617021277e-06,
      "loss": 0.1277,
      "step": 4793
    },
    {
      "epoch": 1.1015625,
      "grad_norm": 0.9765112996101379,
      "learning_rate": 7.03404255319149e-06,
      "loss": 0.0857,
      "step": 4794
    },
    {
      "epoch": 1.1017922794117647,
      "grad_norm": 1.2839449644088745,
      "learning_rate": 7.033191489361702e-06,
      "loss": 0.1172,
      "step": 4795
    },
    {
      "epoch": 1.1020220588235294,
      "grad_norm": 1.194445013999939,
      "learning_rate": 7.032340425531915e-06,
      "loss": 0.0653,
      "step": 4796
    },
    {
      "epoch": 1.1022518382352942,
      "grad_norm": 1.4223262071609497,
      "learning_rate": 7.031489361702129e-06,
      "loss": 0.1207,
      "step": 4797
    },
    {
      "epoch": 1.1024816176470589,
      "grad_norm": 1.358362078666687,
      "learning_rate": 7.030638297872341e-06,
      "loss": 0.1017,
      "step": 4798
    },
    {
      "epoch": 1.1027113970588236,
      "grad_norm": 1.9163280725479126,
      "learning_rate": 7.029787234042553e-06,
      "loss": 0.1565,
      "step": 4799
    },
    {
      "epoch": 1.1029411764705883,
      "grad_norm": 1.3031713962554932,
      "learning_rate": 7.0289361702127665e-06,
      "loss": 0.1222,
      "step": 4800
    },
    {
      "epoch": 1.103170955882353,
      "grad_norm": 1.1880887746810913,
      "learning_rate": 7.028085106382979e-06,
      "loss": 0.1092,
      "step": 4801
    },
    {
      "epoch": 1.1034007352941178,
      "grad_norm": 1.3051549196243286,
      "learning_rate": 7.027234042553191e-06,
      "loss": 0.1201,
      "step": 4802
    },
    {
      "epoch": 1.1036305147058822,
      "grad_norm": 1.0901001691818237,
      "learning_rate": 7.026382978723405e-06,
      "loss": 0.0609,
      "step": 4803
    },
    {
      "epoch": 1.103860294117647,
      "grad_norm": 1.2081031799316406,
      "learning_rate": 7.0255319148936175e-06,
      "loss": 0.0778,
      "step": 4804
    },
    {
      "epoch": 1.1040900735294117,
      "grad_norm": 1.2059571743011475,
      "learning_rate": 7.024680851063831e-06,
      "loss": 0.0854,
      "step": 4805
    },
    {
      "epoch": 1.1043198529411764,
      "grad_norm": 1.4459627866744995,
      "learning_rate": 7.023829787234043e-06,
      "loss": 0.1214,
      "step": 4806
    },
    {
      "epoch": 1.1045496323529411,
      "grad_norm": 3.4650778770446777,
      "learning_rate": 7.022978723404255e-06,
      "loss": 0.1009,
      "step": 4807
    },
    {
      "epoch": 1.1047794117647058,
      "grad_norm": 1.2033376693725586,
      "learning_rate": 7.022127659574469e-06,
      "loss": 0.0999,
      "step": 4808
    },
    {
      "epoch": 1.1050091911764706,
      "grad_norm": 1.1642568111419678,
      "learning_rate": 7.021276595744682e-06,
      "loss": 0.0952,
      "step": 4809
    },
    {
      "epoch": 1.1052389705882353,
      "grad_norm": 0.8890546560287476,
      "learning_rate": 7.020425531914894e-06,
      "loss": 0.0674,
      "step": 4810
    },
    {
      "epoch": 1.10546875,
      "grad_norm": 1.3186066150665283,
      "learning_rate": 7.019574468085107e-06,
      "loss": 0.0787,
      "step": 4811
    },
    {
      "epoch": 1.1056985294117647,
      "grad_norm": 2.156036376953125,
      "learning_rate": 7.0187234042553195e-06,
      "loss": 0.0651,
      "step": 4812
    },
    {
      "epoch": 1.1059283088235294,
      "grad_norm": 0.9505342245101929,
      "learning_rate": 7.017872340425533e-06,
      "loss": 0.079,
      "step": 4813
    },
    {
      "epoch": 1.1061580882352942,
      "grad_norm": 1.4869089126586914,
      "learning_rate": 7.017021276595746e-06,
      "loss": 0.1261,
      "step": 4814
    },
    {
      "epoch": 1.1063878676470589,
      "grad_norm": 0.9079915285110474,
      "learning_rate": 7.016170212765958e-06,
      "loss": 0.0807,
      "step": 4815
    },
    {
      "epoch": 1.1066176470588236,
      "grad_norm": 1.227536678314209,
      "learning_rate": 7.0153191489361704e-06,
      "loss": 0.0798,
      "step": 4816
    },
    {
      "epoch": 1.1068474264705883,
      "grad_norm": 1.3519622087478638,
      "learning_rate": 7.014468085106384e-06,
      "loss": 0.0963,
      "step": 4817
    },
    {
      "epoch": 1.107077205882353,
      "grad_norm": 1.00924813747406,
      "learning_rate": 7.013617021276597e-06,
      "loss": 0.0858,
      "step": 4818
    },
    {
      "epoch": 1.1073069852941178,
      "grad_norm": 1.370352864265442,
      "learning_rate": 7.012765957446809e-06,
      "loss": 0.1243,
      "step": 4819
    },
    {
      "epoch": 1.1075367647058822,
      "grad_norm": 1.25360107421875,
      "learning_rate": 7.011914893617022e-06,
      "loss": 0.0919,
      "step": 4820
    },
    {
      "epoch": 1.107766544117647,
      "grad_norm": 1.2816522121429443,
      "learning_rate": 7.011063829787235e-06,
      "loss": 0.1059,
      "step": 4821
    },
    {
      "epoch": 1.1079963235294117,
      "grad_norm": 1.5199850797653198,
      "learning_rate": 7.010212765957447e-06,
      "loss": 0.0976,
      "step": 4822
    },
    {
      "epoch": 1.1082261029411764,
      "grad_norm": 1.2490084171295166,
      "learning_rate": 7.009361702127661e-06,
      "loss": 0.0841,
      "step": 4823
    },
    {
      "epoch": 1.1084558823529411,
      "grad_norm": 1.4006227254867554,
      "learning_rate": 7.008510638297873e-06,
      "loss": 0.1087,
      "step": 4824
    },
    {
      "epoch": 1.1086856617647058,
      "grad_norm": 1.1853255033493042,
      "learning_rate": 7.007659574468086e-06,
      "loss": 0.0846,
      "step": 4825
    },
    {
      "epoch": 1.1089154411764706,
      "grad_norm": 0.9448432326316833,
      "learning_rate": 7.006808510638299e-06,
      "loss": 0.0734,
      "step": 4826
    },
    {
      "epoch": 1.1091452205882353,
      "grad_norm": 1.1650995016098022,
      "learning_rate": 7.005957446808511e-06,
      "loss": 0.0697,
      "step": 4827
    },
    {
      "epoch": 1.109375,
      "grad_norm": 1.3154550790786743,
      "learning_rate": 7.005106382978723e-06,
      "loss": 0.0735,
      "step": 4828
    },
    {
      "epoch": 1.1096047794117647,
      "grad_norm": 1.1056323051452637,
      "learning_rate": 7.0042553191489374e-06,
      "loss": 0.0843,
      "step": 4829
    },
    {
      "epoch": 1.1098345588235294,
      "grad_norm": 1.3668749332427979,
      "learning_rate": 7.00340425531915e-06,
      "loss": 0.096,
      "step": 4830
    },
    {
      "epoch": 1.1100643382352942,
      "grad_norm": 1.3142118453979492,
      "learning_rate": 7.002553191489362e-06,
      "loss": 0.0864,
      "step": 4831
    },
    {
      "epoch": 1.1102941176470589,
      "grad_norm": 1.4804275035858154,
      "learning_rate": 7.001702127659575e-06,
      "loss": 0.0821,
      "step": 4832
    },
    {
      "epoch": 1.1105238970588236,
      "grad_norm": 1.4242987632751465,
      "learning_rate": 7.0008510638297876e-06,
      "loss": 0.0747,
      "step": 4833
    },
    {
      "epoch": 1.1107536764705883,
      "grad_norm": 1.1294382810592651,
      "learning_rate": 7e-06,
      "loss": 0.1143,
      "step": 4834
    },
    {
      "epoch": 1.110983455882353,
      "grad_norm": 1.1573600769042969,
      "learning_rate": 6.999148936170214e-06,
      "loss": 0.0915,
      "step": 4835
    },
    {
      "epoch": 1.1112132352941178,
      "grad_norm": 1.7027608156204224,
      "learning_rate": 6.998297872340426e-06,
      "loss": 0.1389,
      "step": 4836
    },
    {
      "epoch": 1.1114430147058822,
      "grad_norm": 1.2935034036636353,
      "learning_rate": 6.9974468085106386e-06,
      "loss": 0.0807,
      "step": 4837
    },
    {
      "epoch": 1.111672794117647,
      "grad_norm": 1.2429689168930054,
      "learning_rate": 6.996595744680852e-06,
      "loss": 0.0808,
      "step": 4838
    },
    {
      "epoch": 1.1119025735294117,
      "grad_norm": 1.3690680265426636,
      "learning_rate": 6.995744680851064e-06,
      "loss": 0.0871,
      "step": 4839
    },
    {
      "epoch": 1.1121323529411764,
      "grad_norm": 1.4721808433532715,
      "learning_rate": 6.994893617021276e-06,
      "loss": 0.1488,
      "step": 4840
    },
    {
      "epoch": 1.1123621323529411,
      "grad_norm": 1.0970938205718994,
      "learning_rate": 6.99404255319149e-06,
      "loss": 0.1054,
      "step": 4841
    },
    {
      "epoch": 1.1125919117647058,
      "grad_norm": 1.1549757719039917,
      "learning_rate": 6.993191489361703e-06,
      "loss": 0.0788,
      "step": 4842
    },
    {
      "epoch": 1.1128216911764706,
      "grad_norm": 1.977980613708496,
      "learning_rate": 6.992340425531915e-06,
      "loss": 0.1113,
      "step": 4843
    },
    {
      "epoch": 1.1130514705882353,
      "grad_norm": 1.617126226425171,
      "learning_rate": 6.991489361702128e-06,
      "loss": 0.1159,
      "step": 4844
    },
    {
      "epoch": 1.11328125,
      "grad_norm": 0.91219562292099,
      "learning_rate": 6.9906382978723405e-06,
      "loss": 0.0762,
      "step": 4845
    },
    {
      "epoch": 1.1135110294117647,
      "grad_norm": 1.1592363119125366,
      "learning_rate": 6.989787234042553e-06,
      "loss": 0.0689,
      "step": 4846
    },
    {
      "epoch": 1.1137408088235294,
      "grad_norm": 1.5274412631988525,
      "learning_rate": 6.988936170212767e-06,
      "loss": 0.0908,
      "step": 4847
    },
    {
      "epoch": 1.1139705882352942,
      "grad_norm": 1.0080231428146362,
      "learning_rate": 6.988085106382979e-06,
      "loss": 0.0688,
      "step": 4848
    },
    {
      "epoch": 1.1142003676470589,
      "grad_norm": 1.2414436340332031,
      "learning_rate": 6.987234042553192e-06,
      "loss": 0.0813,
      "step": 4849
    },
    {
      "epoch": 1.1144301470588236,
      "grad_norm": 1.2185275554656982,
      "learning_rate": 6.986382978723405e-06,
      "loss": 0.0857,
      "step": 4850
    },
    {
      "epoch": 1.1146599264705883,
      "grad_norm": 1.2088079452514648,
      "learning_rate": 6.985531914893617e-06,
      "loss": 0.1086,
      "step": 4851
    },
    {
      "epoch": 1.114889705882353,
      "grad_norm": 1.5818434953689575,
      "learning_rate": 6.984680851063831e-06,
      "loss": 0.1187,
      "step": 4852
    },
    {
      "epoch": 1.1151194852941178,
      "grad_norm": 1.3997231721878052,
      "learning_rate": 6.983829787234043e-06,
      "loss": 0.1141,
      "step": 4853
    },
    {
      "epoch": 1.1153492647058822,
      "grad_norm": 1.0638574361801147,
      "learning_rate": 6.982978723404256e-06,
      "loss": 0.0722,
      "step": 4854
    },
    {
      "epoch": 1.115579044117647,
      "grad_norm": 1.2670010328292847,
      "learning_rate": 6.982127659574469e-06,
      "loss": 0.0895,
      "step": 4855
    },
    {
      "epoch": 1.1158088235294117,
      "grad_norm": 1.4890084266662598,
      "learning_rate": 6.981276595744681e-06,
      "loss": 0.0711,
      "step": 4856
    },
    {
      "epoch": 1.1160386029411764,
      "grad_norm": 1.2061527967453003,
      "learning_rate": 6.9804255319148935e-06,
      "loss": 0.1109,
      "step": 4857
    },
    {
      "epoch": 1.1162683823529411,
      "grad_norm": 1.053314447402954,
      "learning_rate": 6.9795744680851075e-06,
      "loss": 0.0707,
      "step": 4858
    },
    {
      "epoch": 1.1164981617647058,
      "grad_norm": 1.2996549606323242,
      "learning_rate": 6.97872340425532e-06,
      "loss": 0.0766,
      "step": 4859
    },
    {
      "epoch": 1.1167279411764706,
      "grad_norm": 1.0999263525009155,
      "learning_rate": 6.977872340425532e-06,
      "loss": 0.0904,
      "step": 4860
    },
    {
      "epoch": 1.1169577205882353,
      "grad_norm": 0.997768223285675,
      "learning_rate": 6.977021276595745e-06,
      "loss": 0.0655,
      "step": 4861
    },
    {
      "epoch": 1.1171875,
      "grad_norm": 1.6926040649414062,
      "learning_rate": 6.976170212765958e-06,
      "loss": 0.1106,
      "step": 4862
    },
    {
      "epoch": 1.1174172794117647,
      "grad_norm": 1.039583444595337,
      "learning_rate": 6.975319148936171e-06,
      "loss": 0.0894,
      "step": 4863
    },
    {
      "epoch": 1.1176470588235294,
      "grad_norm": 1.881086826324463,
      "learning_rate": 6.974468085106384e-06,
      "loss": 0.0971,
      "step": 4864
    },
    {
      "epoch": 1.1178768382352942,
      "grad_norm": 1.214017391204834,
      "learning_rate": 6.973617021276596e-06,
      "loss": 0.0883,
      "step": 4865
    },
    {
      "epoch": 1.1181066176470589,
      "grad_norm": 1.6241230964660645,
      "learning_rate": 6.972765957446809e-06,
      "loss": 0.0887,
      "step": 4866
    },
    {
      "epoch": 1.1183363970588236,
      "grad_norm": 1.0046272277832031,
      "learning_rate": 6.971914893617022e-06,
      "loss": 0.0975,
      "step": 4867
    },
    {
      "epoch": 1.1185661764705883,
      "grad_norm": 1.5039976835250854,
      "learning_rate": 6.971063829787235e-06,
      "loss": 0.1202,
      "step": 4868
    },
    {
      "epoch": 1.118795955882353,
      "grad_norm": 1.2955232858657837,
      "learning_rate": 6.970212765957447e-06,
      "loss": 0.107,
      "step": 4869
    },
    {
      "epoch": 1.1190257352941178,
      "grad_norm": 1.2781150341033936,
      "learning_rate": 6.9693617021276605e-06,
      "loss": 0.0838,
      "step": 4870
    },
    {
      "epoch": 1.1192555147058822,
      "grad_norm": 1.572288990020752,
      "learning_rate": 6.968510638297873e-06,
      "loss": 0.105,
      "step": 4871
    },
    {
      "epoch": 1.119485294117647,
      "grad_norm": 1.0842782258987427,
      "learning_rate": 6.967659574468085e-06,
      "loss": 0.0834,
      "step": 4872
    },
    {
      "epoch": 1.1197150735294117,
      "grad_norm": 1.1086041927337646,
      "learning_rate": 6.966808510638299e-06,
      "loss": 0.0882,
      "step": 4873
    },
    {
      "epoch": 1.1199448529411764,
      "grad_norm": 1.136887550354004,
      "learning_rate": 6.9659574468085115e-06,
      "loss": 0.0818,
      "step": 4874
    },
    {
      "epoch": 1.1201746323529411,
      "grad_norm": 2.183265209197998,
      "learning_rate": 6.965106382978724e-06,
      "loss": 0.1471,
      "step": 4875
    },
    {
      "epoch": 1.1204044117647058,
      "grad_norm": 1.084073543548584,
      "learning_rate": 6.964255319148937e-06,
      "loss": 0.0844,
      "step": 4876
    },
    {
      "epoch": 1.1206341911764706,
      "grad_norm": 1.483391284942627,
      "learning_rate": 6.963404255319149e-06,
      "loss": 0.1008,
      "step": 4877
    },
    {
      "epoch": 1.1208639705882353,
      "grad_norm": 1.5693682432174683,
      "learning_rate": 6.962553191489362e-06,
      "loss": 0.0916,
      "step": 4878
    },
    {
      "epoch": 1.12109375,
      "grad_norm": 1.2153420448303223,
      "learning_rate": 6.961702127659576e-06,
      "loss": 0.0892,
      "step": 4879
    },
    {
      "epoch": 1.1213235294117647,
      "grad_norm": 1.2821900844573975,
      "learning_rate": 6.960851063829788e-06,
      "loss": 0.0854,
      "step": 4880
    },
    {
      "epoch": 1.1215533088235294,
      "grad_norm": 1.6726571321487427,
      "learning_rate": 6.96e-06,
      "loss": 0.0924,
      "step": 4881
    },
    {
      "epoch": 1.1217830882352942,
      "grad_norm": 2.4519169330596924,
      "learning_rate": 6.9591489361702134e-06,
      "loss": 0.104,
      "step": 4882
    },
    {
      "epoch": 1.1220128676470589,
      "grad_norm": 1.1911721229553223,
      "learning_rate": 6.958297872340426e-06,
      "loss": 0.0717,
      "step": 4883
    },
    {
      "epoch": 1.1222426470588236,
      "grad_norm": 1.2622461318969727,
      "learning_rate": 6.957446808510638e-06,
      "loss": 0.1058,
      "step": 4884
    },
    {
      "epoch": 1.1224724264705883,
      "grad_norm": 1.0096259117126465,
      "learning_rate": 6.956595744680852e-06,
      "loss": 0.0565,
      "step": 4885
    },
    {
      "epoch": 1.122702205882353,
      "grad_norm": 1.0667738914489746,
      "learning_rate": 6.9557446808510644e-06,
      "loss": 0.0806,
      "step": 4886
    },
    {
      "epoch": 1.1229319852941178,
      "grad_norm": 1.4232192039489746,
      "learning_rate": 6.954893617021277e-06,
      "loss": 0.0864,
      "step": 4887
    },
    {
      "epoch": 1.1231617647058822,
      "grad_norm": 1.1743332147598267,
      "learning_rate": 6.95404255319149e-06,
      "loss": 0.0898,
      "step": 4888
    },
    {
      "epoch": 1.123391544117647,
      "grad_norm": 1.0561896562576294,
      "learning_rate": 6.953191489361702e-06,
      "loss": 0.0812,
      "step": 4889
    },
    {
      "epoch": 1.1236213235294117,
      "grad_norm": 1.0213197469711304,
      "learning_rate": 6.952340425531916e-06,
      "loss": 0.0861,
      "step": 4890
    },
    {
      "epoch": 1.1238511029411764,
      "grad_norm": 1.0007447004318237,
      "learning_rate": 6.951489361702129e-06,
      "loss": 0.0602,
      "step": 4891
    },
    {
      "epoch": 1.1240808823529411,
      "grad_norm": 1.0424624681472778,
      "learning_rate": 6.950638297872341e-06,
      "loss": 0.0827,
      "step": 4892
    },
    {
      "epoch": 1.1243106617647058,
      "grad_norm": 1.587568998336792,
      "learning_rate": 6.949787234042554e-06,
      "loss": 0.1085,
      "step": 4893
    },
    {
      "epoch": 1.1245404411764706,
      "grad_norm": 1.4476245641708374,
      "learning_rate": 6.948936170212766e-06,
      "loss": 0.1005,
      "step": 4894
    },
    {
      "epoch": 1.1247702205882353,
      "grad_norm": 1.015976071357727,
      "learning_rate": 6.948085106382979e-06,
      "loss": 0.0699,
      "step": 4895
    },
    {
      "epoch": 1.125,
      "grad_norm": 1.201743483543396,
      "learning_rate": 6.947234042553193e-06,
      "loss": 0.0916,
      "step": 4896
    },
    {
      "epoch": 1.1252297794117647,
      "grad_norm": 1.2144644260406494,
      "learning_rate": 6.946382978723405e-06,
      "loss": 0.0945,
      "step": 4897
    },
    {
      "epoch": 1.1254595588235294,
      "grad_norm": 1.458655595779419,
      "learning_rate": 6.945531914893617e-06,
      "loss": 0.1019,
      "step": 4898
    },
    {
      "epoch": 1.1256893382352942,
      "grad_norm": 1.0762578248977661,
      "learning_rate": 6.9446808510638306e-06,
      "loss": 0.0527,
      "step": 4899
    },
    {
      "epoch": 1.1259191176470589,
      "grad_norm": 1.163709044456482,
      "learning_rate": 6.943829787234043e-06,
      "loss": 0.0615,
      "step": 4900
    },
    {
      "epoch": 1.1261488970588236,
      "grad_norm": 1.4674298763275146,
      "learning_rate": 6.942978723404255e-06,
      "loss": 0.1264,
      "step": 4901
    },
    {
      "epoch": 1.1263786764705883,
      "grad_norm": 1.3558294773101807,
      "learning_rate": 6.942127659574469e-06,
      "loss": 0.082,
      "step": 4902
    },
    {
      "epoch": 1.126608455882353,
      "grad_norm": 1.4201220273971558,
      "learning_rate": 6.9412765957446816e-06,
      "loss": 0.0999,
      "step": 4903
    },
    {
      "epoch": 1.1268382352941178,
      "grad_norm": 1.327394723892212,
      "learning_rate": 6.940425531914894e-06,
      "loss": 0.1065,
      "step": 4904
    },
    {
      "epoch": 1.1270680147058822,
      "grad_norm": 1.2583121061325073,
      "learning_rate": 6.939574468085107e-06,
      "loss": 0.1191,
      "step": 4905
    },
    {
      "epoch": 1.127297794117647,
      "grad_norm": 0.918595552444458,
      "learning_rate": 6.938723404255319e-06,
      "loss": 0.07,
      "step": 4906
    },
    {
      "epoch": 1.1275275735294117,
      "grad_norm": 1.6361063718795776,
      "learning_rate": 6.9378723404255325e-06,
      "loss": 0.1319,
      "step": 4907
    },
    {
      "epoch": 1.1277573529411764,
      "grad_norm": 1.5570276975631714,
      "learning_rate": 6.937021276595746e-06,
      "loss": 0.0969,
      "step": 4908
    },
    {
      "epoch": 1.1279871323529411,
      "grad_norm": 1.1898735761642456,
      "learning_rate": 6.936170212765958e-06,
      "loss": 0.1234,
      "step": 4909
    },
    {
      "epoch": 1.1282169117647058,
      "grad_norm": 0.7440105080604553,
      "learning_rate": 6.93531914893617e-06,
      "loss": 0.0713,
      "step": 4910
    },
    {
      "epoch": 1.1284466911764706,
      "grad_norm": 1.4276419878005981,
      "learning_rate": 6.9344680851063835e-06,
      "loss": 0.1088,
      "step": 4911
    },
    {
      "epoch": 1.1286764705882353,
      "grad_norm": 1.11869478225708,
      "learning_rate": 6.933617021276597e-06,
      "loss": 0.0714,
      "step": 4912
    },
    {
      "epoch": 1.12890625,
      "grad_norm": 0.92313152551651,
      "learning_rate": 6.932765957446809e-06,
      "loss": 0.0756,
      "step": 4913
    },
    {
      "epoch": 1.1291360294117647,
      "grad_norm": 1.2382588386535645,
      "learning_rate": 6.931914893617022e-06,
      "loss": 0.0892,
      "step": 4914
    },
    {
      "epoch": 1.1293658088235294,
      "grad_norm": 1.2926790714263916,
      "learning_rate": 6.9310638297872345e-06,
      "loss": 0.0931,
      "step": 4915
    },
    {
      "epoch": 1.1295955882352942,
      "grad_norm": 1.3195804357528687,
      "learning_rate": 6.930212765957447e-06,
      "loss": 0.1078,
      "step": 4916
    },
    {
      "epoch": 1.1298253676470589,
      "grad_norm": 1.3038312196731567,
      "learning_rate": 6.929361702127661e-06,
      "loss": 0.0863,
      "step": 4917
    },
    {
      "epoch": 1.1300551470588236,
      "grad_norm": 1.3291476964950562,
      "learning_rate": 6.928510638297873e-06,
      "loss": 0.1119,
      "step": 4918
    },
    {
      "epoch": 1.1302849264705883,
      "grad_norm": 0.8832883238792419,
      "learning_rate": 6.9276595744680855e-06,
      "loss": 0.0834,
      "step": 4919
    },
    {
      "epoch": 1.130514705882353,
      "grad_norm": 1.4794734716415405,
      "learning_rate": 6.926808510638299e-06,
      "loss": 0.0657,
      "step": 4920
    },
    {
      "epoch": 1.1307444852941178,
      "grad_norm": 1.187949299812317,
      "learning_rate": 6.925957446808511e-06,
      "loss": 0.0814,
      "step": 4921
    },
    {
      "epoch": 1.1309742647058822,
      "grad_norm": 1.1686344146728516,
      "learning_rate": 6.925106382978723e-06,
      "loss": 0.0918,
      "step": 4922
    },
    {
      "epoch": 1.131204044117647,
      "grad_norm": 1.1286176443099976,
      "learning_rate": 6.924255319148937e-06,
      "loss": 0.0867,
      "step": 4923
    },
    {
      "epoch": 1.1314338235294117,
      "grad_norm": 1.1046019792556763,
      "learning_rate": 6.92340425531915e-06,
      "loss": 0.0735,
      "step": 4924
    },
    {
      "epoch": 1.1316636029411764,
      "grad_norm": 1.2401942014694214,
      "learning_rate": 6.922553191489362e-06,
      "loss": 0.1053,
      "step": 4925
    },
    {
      "epoch": 1.1318933823529411,
      "grad_norm": 1.1151459217071533,
      "learning_rate": 6.921702127659575e-06,
      "loss": 0.1049,
      "step": 4926
    },
    {
      "epoch": 1.1321231617647058,
      "grad_norm": 1.166759967803955,
      "learning_rate": 6.9208510638297875e-06,
      "loss": 0.0748,
      "step": 4927
    },
    {
      "epoch": 1.1323529411764706,
      "grad_norm": 1.1718339920043945,
      "learning_rate": 6.92e-06,
      "loss": 0.0775,
      "step": 4928
    },
    {
      "epoch": 1.1325827205882353,
      "grad_norm": 1.4938058853149414,
      "learning_rate": 6.919148936170214e-06,
      "loss": 0.0958,
      "step": 4929
    },
    {
      "epoch": 1.1328125,
      "grad_norm": 1.3707014322280884,
      "learning_rate": 6.918297872340426e-06,
      "loss": 0.1135,
      "step": 4930
    },
    {
      "epoch": 1.1330422794117647,
      "grad_norm": 1.1093560457229614,
      "learning_rate": 6.9174468085106385e-06,
      "loss": 0.0935,
      "step": 4931
    },
    {
      "epoch": 1.1332720588235294,
      "grad_norm": 1.724004864692688,
      "learning_rate": 6.916595744680852e-06,
      "loss": 0.0904,
      "step": 4932
    },
    {
      "epoch": 1.1335018382352942,
      "grad_norm": 1.5981520414352417,
      "learning_rate": 6.915744680851064e-06,
      "loss": 0.1064,
      "step": 4933
    },
    {
      "epoch": 1.1337316176470589,
      "grad_norm": 1.1248008012771606,
      "learning_rate": 6.914893617021278e-06,
      "loss": 0.0751,
      "step": 4934
    },
    {
      "epoch": 1.1339613970588236,
      "grad_norm": 1.0460882186889648,
      "learning_rate": 6.91404255319149e-06,
      "loss": 0.0848,
      "step": 4935
    },
    {
      "epoch": 1.1341911764705883,
      "grad_norm": 0.9759219884872437,
      "learning_rate": 6.913191489361703e-06,
      "loss": 0.0946,
      "step": 4936
    },
    {
      "epoch": 1.134420955882353,
      "grad_norm": 0.9074438810348511,
      "learning_rate": 6.912340425531916e-06,
      "loss": 0.0778,
      "step": 4937
    },
    {
      "epoch": 1.1346507352941178,
      "grad_norm": 0.9311067461967468,
      "learning_rate": 6.911489361702128e-06,
      "loss": 0.0641,
      "step": 4938
    },
    {
      "epoch": 1.1348805147058822,
      "grad_norm": 0.6986486315727234,
      "learning_rate": 6.9106382978723405e-06,
      "loss": 0.052,
      "step": 4939
    },
    {
      "epoch": 1.135110294117647,
      "grad_norm": 1.7389345169067383,
      "learning_rate": 6.9097872340425545e-06,
      "loss": 0.1075,
      "step": 4940
    },
    {
      "epoch": 1.1353400735294117,
      "grad_norm": 1.1183615922927856,
      "learning_rate": 6.908936170212767e-06,
      "loss": 0.066,
      "step": 4941
    },
    {
      "epoch": 1.1355698529411764,
      "grad_norm": 1.548190712928772,
      "learning_rate": 6.908085106382979e-06,
      "loss": 0.0992,
      "step": 4942
    },
    {
      "epoch": 1.1357996323529411,
      "grad_norm": 1.0730485916137695,
      "learning_rate": 6.907234042553192e-06,
      "loss": 0.0731,
      "step": 4943
    },
    {
      "epoch": 1.1360294117647058,
      "grad_norm": 1.436505675315857,
      "learning_rate": 6.906382978723405e-06,
      "loss": 0.101,
      "step": 4944
    },
    {
      "epoch": 1.1362591911764706,
      "grad_norm": 1.2915798425674438,
      "learning_rate": 6.905531914893617e-06,
      "loss": 0.097,
      "step": 4945
    },
    {
      "epoch": 1.1364889705882353,
      "grad_norm": 1.5358352661132812,
      "learning_rate": 6.904680851063831e-06,
      "loss": 0.0804,
      "step": 4946
    },
    {
      "epoch": 1.13671875,
      "grad_norm": 1.1796795129776,
      "learning_rate": 6.903829787234043e-06,
      "loss": 0.0676,
      "step": 4947
    },
    {
      "epoch": 1.1369485294117647,
      "grad_norm": 0.9671447277069092,
      "learning_rate": 6.902978723404256e-06,
      "loss": 0.0658,
      "step": 4948
    },
    {
      "epoch": 1.1371783088235294,
      "grad_norm": 1.3643293380737305,
      "learning_rate": 6.902127659574469e-06,
      "loss": 0.1037,
      "step": 4949
    },
    {
      "epoch": 1.1374080882352942,
      "grad_norm": 1.2599282264709473,
      "learning_rate": 6.901276595744681e-06,
      "loss": 0.1022,
      "step": 4950
    },
    {
      "epoch": 1.1376378676470589,
      "grad_norm": 1.272796869277954,
      "learning_rate": 6.900425531914893e-06,
      "loss": 0.0871,
      "step": 4951
    },
    {
      "epoch": 1.1378676470588236,
      "grad_norm": 1.2197431325912476,
      "learning_rate": 6.8995744680851074e-06,
      "loss": 0.0784,
      "step": 4952
    },
    {
      "epoch": 1.1380974264705883,
      "grad_norm": 1.0942461490631104,
      "learning_rate": 6.89872340425532e-06,
      "loss": 0.0805,
      "step": 4953
    },
    {
      "epoch": 1.138327205882353,
      "grad_norm": 1.1277040243148804,
      "learning_rate": 6.897872340425532e-06,
      "loss": 0.0873,
      "step": 4954
    },
    {
      "epoch": 1.1385569852941178,
      "grad_norm": 1.4841622114181519,
      "learning_rate": 6.897021276595745e-06,
      "loss": 0.1096,
      "step": 4955
    },
    {
      "epoch": 1.1387867647058822,
      "grad_norm": 1.4062669277191162,
      "learning_rate": 6.896170212765958e-06,
      "loss": 0.0897,
      "step": 4956
    },
    {
      "epoch": 1.139016544117647,
      "grad_norm": 1.2278062105178833,
      "learning_rate": 6.895319148936171e-06,
      "loss": 0.0913,
      "step": 4957
    },
    {
      "epoch": 1.1392463235294117,
      "grad_norm": 1.3606903553009033,
      "learning_rate": 6.894468085106384e-06,
      "loss": 0.0955,
      "step": 4958
    },
    {
      "epoch": 1.1394761029411764,
      "grad_norm": 1.4174740314483643,
      "learning_rate": 6.893617021276596e-06,
      "loss": 0.0821,
      "step": 4959
    },
    {
      "epoch": 1.1397058823529411,
      "grad_norm": 1.5282390117645264,
      "learning_rate": 6.8927659574468086e-06,
      "loss": 0.127,
      "step": 4960
    },
    {
      "epoch": 1.1399356617647058,
      "grad_norm": 1.0387170314788818,
      "learning_rate": 6.891914893617022e-06,
      "loss": 0.0731,
      "step": 4961
    },
    {
      "epoch": 1.1401654411764706,
      "grad_norm": 1.4823291301727295,
      "learning_rate": 6.891063829787235e-06,
      "loss": 0.112,
      "step": 4962
    },
    {
      "epoch": 1.1403952205882353,
      "grad_norm": 1.769417405128479,
      "learning_rate": 6.890212765957447e-06,
      "loss": 0.1464,
      "step": 4963
    },
    {
      "epoch": 1.140625,
      "grad_norm": 1.493619680404663,
      "learning_rate": 6.88936170212766e-06,
      "loss": 0.1064,
      "step": 4964
    },
    {
      "epoch": 1.1408547794117647,
      "grad_norm": 1.3575769662857056,
      "learning_rate": 6.888510638297873e-06,
      "loss": 0.1058,
      "step": 4965
    },
    {
      "epoch": 1.1410845588235294,
      "grad_norm": 1.9063483476638794,
      "learning_rate": 6.887659574468085e-06,
      "loss": 0.1184,
      "step": 4966
    },
    {
      "epoch": 1.1413143382352942,
      "grad_norm": 1.6105877161026,
      "learning_rate": 6.886808510638299e-06,
      "loss": 0.0938,
      "step": 4967
    },
    {
      "epoch": 1.1415441176470589,
      "grad_norm": 1.820173740386963,
      "learning_rate": 6.885957446808511e-06,
      "loss": 0.1229,
      "step": 4968
    },
    {
      "epoch": 1.1417738970588236,
      "grad_norm": 1.4485605955123901,
      "learning_rate": 6.885106382978724e-06,
      "loss": 0.1206,
      "step": 4969
    },
    {
      "epoch": 1.1420036764705883,
      "grad_norm": 1.6440318822860718,
      "learning_rate": 6.884255319148937e-06,
      "loss": 0.1173,
      "step": 4970
    },
    {
      "epoch": 1.142233455882353,
      "grad_norm": 1.0550456047058105,
      "learning_rate": 6.883404255319149e-06,
      "loss": 0.0873,
      "step": 4971
    },
    {
      "epoch": 1.1424632352941178,
      "grad_norm": 1.084322214126587,
      "learning_rate": 6.8825531914893615e-06,
      "loss": 0.0835,
      "step": 4972
    },
    {
      "epoch": 1.1426930147058822,
      "grad_norm": 1.6542539596557617,
      "learning_rate": 6.8817021276595755e-06,
      "loss": 0.087,
      "step": 4973
    },
    {
      "epoch": 1.142922794117647,
      "grad_norm": 1.4048594236373901,
      "learning_rate": 6.880851063829788e-06,
      "loss": 0.0826,
      "step": 4974
    },
    {
      "epoch": 1.1431525735294117,
      "grad_norm": 1.119840145111084,
      "learning_rate": 6.88e-06,
      "loss": 0.1034,
      "step": 4975
    },
    {
      "epoch": 1.1433823529411764,
      "grad_norm": 0.9899765849113464,
      "learning_rate": 6.879148936170213e-06,
      "loss": 0.0739,
      "step": 4976
    },
    {
      "epoch": 1.1436121323529411,
      "grad_norm": 1.3493001461029053,
      "learning_rate": 6.878297872340426e-06,
      "loss": 0.0978,
      "step": 4977
    },
    {
      "epoch": 1.1438419117647058,
      "grad_norm": 1.0090880393981934,
      "learning_rate": 6.87744680851064e-06,
      "loss": 0.07,
      "step": 4978
    },
    {
      "epoch": 1.1440716911764706,
      "grad_norm": 0.8366619348526001,
      "learning_rate": 6.876595744680852e-06,
      "loss": 0.0732,
      "step": 4979
    },
    {
      "epoch": 1.1443014705882353,
      "grad_norm": 1.158296823501587,
      "learning_rate": 6.875744680851064e-06,
      "loss": 0.0794,
      "step": 4980
    },
    {
      "epoch": 1.14453125,
      "grad_norm": 1.1228983402252197,
      "learning_rate": 6.8748936170212775e-06,
      "loss": 0.0908,
      "step": 4981
    },
    {
      "epoch": 1.1447610294117647,
      "grad_norm": 1.160923957824707,
      "learning_rate": 6.87404255319149e-06,
      "loss": 0.0802,
      "step": 4982
    },
    {
      "epoch": 1.1449908088235294,
      "grad_norm": 1.2362914085388184,
      "learning_rate": 6.873191489361702e-06,
      "loss": 0.0905,
      "step": 4983
    },
    {
      "epoch": 1.1452205882352942,
      "grad_norm": 1.1577452421188354,
      "learning_rate": 6.872340425531916e-06,
      "loss": 0.1004,
      "step": 4984
    },
    {
      "epoch": 1.1454503676470589,
      "grad_norm": 1.525831699371338,
      "learning_rate": 6.8714893617021285e-06,
      "loss": 0.1219,
      "step": 4985
    },
    {
      "epoch": 1.1456801470588236,
      "grad_norm": 1.0359293222427368,
      "learning_rate": 6.870638297872341e-06,
      "loss": 0.082,
      "step": 4986
    },
    {
      "epoch": 1.1459099264705883,
      "grad_norm": 1.2168498039245605,
      "learning_rate": 6.869787234042554e-06,
      "loss": 0.0911,
      "step": 4987
    },
    {
      "epoch": 1.146139705882353,
      "grad_norm": 1.4191349744796753,
      "learning_rate": 6.868936170212766e-06,
      "loss": 0.1042,
      "step": 4988
    },
    {
      "epoch": 1.1463694852941178,
      "grad_norm": 1.5735608339309692,
      "learning_rate": 6.868085106382979e-06,
      "loss": 0.1286,
      "step": 4989
    },
    {
      "epoch": 1.1465992647058822,
      "grad_norm": 1.0727330446243286,
      "learning_rate": 6.867234042553193e-06,
      "loss": 0.0858,
      "step": 4990
    },
    {
      "epoch": 1.146829044117647,
      "grad_norm": 1.3526370525360107,
      "learning_rate": 6.866382978723405e-06,
      "loss": 0.073,
      "step": 4991
    },
    {
      "epoch": 1.1470588235294117,
      "grad_norm": 1.041335105895996,
      "learning_rate": 6.865531914893617e-06,
      "loss": 0.0907,
      "step": 4992
    },
    {
      "epoch": 1.1472886029411764,
      "grad_norm": 1.2470557689666748,
      "learning_rate": 6.8646808510638305e-06,
      "loss": 0.0818,
      "step": 4993
    },
    {
      "epoch": 1.1475183823529411,
      "grad_norm": 1.4398024082183838,
      "learning_rate": 6.863829787234043e-06,
      "loss": 0.0927,
      "step": 4994
    },
    {
      "epoch": 1.1477481617647058,
      "grad_norm": 1.2540552616119385,
      "learning_rate": 6.862978723404255e-06,
      "loss": 0.0947,
      "step": 4995
    },
    {
      "epoch": 1.1479779411764706,
      "grad_norm": 0.8111453056335449,
      "learning_rate": 6.862127659574469e-06,
      "loss": 0.0631,
      "step": 4996
    },
    {
      "epoch": 1.1482077205882353,
      "grad_norm": 0.8733208179473877,
      "learning_rate": 6.8612765957446815e-06,
      "loss": 0.0593,
      "step": 4997
    },
    {
      "epoch": 1.1484375,
      "grad_norm": 1.103171467781067,
      "learning_rate": 6.860425531914894e-06,
      "loss": 0.076,
      "step": 4998
    },
    {
      "epoch": 1.1486672794117647,
      "grad_norm": 1.0524508953094482,
      "learning_rate": 6.859574468085107e-06,
      "loss": 0.0558,
      "step": 4999
    },
    {
      "epoch": 1.1488970588235294,
      "grad_norm": 1.5740495920181274,
      "learning_rate": 6.858723404255319e-06,
      "loss": 0.1083,
      "step": 5000
    },
    {
      "epoch": 1.1488970588235294,
      "eval_loss": 0.09407763183116913,
      "eval_runtime": 1966.0599,
      "eval_samples_per_second": 4.53,
      "eval_steps_per_second": 2.265,
      "step": 5000
    },
    {
      "epoch": 1.1491268382352942,
      "grad_norm": 1.5756590366363525,
      "learning_rate": 6.8578723404255325e-06,
      "loss": 0.1503,
      "step": 5001
    },
    {
      "epoch": 1.1493566176470589,
      "grad_norm": 1.1566082239151,
      "learning_rate": 6.857021276595746e-06,
      "loss": 0.0935,
      "step": 5002
    },
    {
      "epoch": 1.1495863970588236,
      "grad_norm": 1.2682687044143677,
      "learning_rate": 6.856170212765958e-06,
      "loss": 0.0679,
      "step": 5003
    },
    {
      "epoch": 1.1498161764705883,
      "grad_norm": 1.1872758865356445,
      "learning_rate": 6.85531914893617e-06,
      "loss": 0.0776,
      "step": 5004
    },
    {
      "epoch": 1.150045955882353,
      "grad_norm": 1.457696795463562,
      "learning_rate": 6.8544680851063835e-06,
      "loss": 0.0998,
      "step": 5005
    },
    {
      "epoch": 1.1502757352941178,
      "grad_norm": 1.0449912548065186,
      "learning_rate": 6.853617021276597e-06,
      "loss": 0.0923,
      "step": 5006
    },
    {
      "epoch": 1.1505055147058822,
      "grad_norm": 1.0719001293182373,
      "learning_rate": 6.852765957446809e-06,
      "loss": 0.0772,
      "step": 5007
    },
    {
      "epoch": 1.150735294117647,
      "grad_norm": 1.1762256622314453,
      "learning_rate": 6.851914893617022e-06,
      "loss": 0.0748,
      "step": 5008
    },
    {
      "epoch": 1.1509650735294117,
      "grad_norm": 1.5840792655944824,
      "learning_rate": 6.8510638297872344e-06,
      "loss": 0.1044,
      "step": 5009
    },
    {
      "epoch": 1.1511948529411764,
      "grad_norm": 1.3583890199661255,
      "learning_rate": 6.850212765957447e-06,
      "loss": 0.1084,
      "step": 5010
    },
    {
      "epoch": 1.1514246323529411,
      "grad_norm": 0.8035010099411011,
      "learning_rate": 6.849361702127661e-06,
      "loss": 0.0523,
      "step": 5011
    },
    {
      "epoch": 1.1516544117647058,
      "grad_norm": 1.1993930339813232,
      "learning_rate": 6.848510638297873e-06,
      "loss": 0.0843,
      "step": 5012
    },
    {
      "epoch": 1.1518841911764706,
      "grad_norm": 0.7915053963661194,
      "learning_rate": 6.8476595744680854e-06,
      "loss": 0.0561,
      "step": 5013
    },
    {
      "epoch": 1.1521139705882353,
      "grad_norm": 1.3897486925125122,
      "learning_rate": 6.846808510638299e-06,
      "loss": 0.1007,
      "step": 5014
    },
    {
      "epoch": 1.15234375,
      "grad_norm": 1.2072992324829102,
      "learning_rate": 6.845957446808511e-06,
      "loss": 0.0622,
      "step": 5015
    },
    {
      "epoch": 1.1525735294117647,
      "grad_norm": 1.2299721240997314,
      "learning_rate": 6.845106382978723e-06,
      "loss": 0.097,
      "step": 5016
    },
    {
      "epoch": 1.1528033088235294,
      "grad_norm": 1.3620716333389282,
      "learning_rate": 6.844255319148937e-06,
      "loss": 0.0941,
      "step": 5017
    },
    {
      "epoch": 1.1530330882352942,
      "grad_norm": 1.2841389179229736,
      "learning_rate": 6.84340425531915e-06,
      "loss": 0.0831,
      "step": 5018
    },
    {
      "epoch": 1.1532628676470589,
      "grad_norm": 1.4051820039749146,
      "learning_rate": 6.842553191489363e-06,
      "loss": 0.1145,
      "step": 5019
    },
    {
      "epoch": 1.1534926470588236,
      "grad_norm": 1.186706781387329,
      "learning_rate": 6.841702127659575e-06,
      "loss": 0.0789,
      "step": 5020
    },
    {
      "epoch": 1.1537224264705883,
      "grad_norm": 1.0086913108825684,
      "learning_rate": 6.840851063829787e-06,
      "loss": 0.0764,
      "step": 5021
    },
    {
      "epoch": 1.153952205882353,
      "grad_norm": 0.9616343379020691,
      "learning_rate": 6.8400000000000014e-06,
      "loss": 0.0823,
      "step": 5022
    },
    {
      "epoch": 1.1541819852941178,
      "grad_norm": 1.0835657119750977,
      "learning_rate": 6.839148936170214e-06,
      "loss": 0.0802,
      "step": 5023
    },
    {
      "epoch": 1.1544117647058822,
      "grad_norm": 1.2163002490997314,
      "learning_rate": 6.838297872340426e-06,
      "loss": 0.0846,
      "step": 5024
    },
    {
      "epoch": 1.154641544117647,
      "grad_norm": 0.7477150559425354,
      "learning_rate": 6.837446808510639e-06,
      "loss": 0.0586,
      "step": 5025
    },
    {
      "epoch": 1.1548713235294117,
      "grad_norm": 1.7190576791763306,
      "learning_rate": 6.8365957446808516e-06,
      "loss": 0.1088,
      "step": 5026
    },
    {
      "epoch": 1.1551011029411764,
      "grad_norm": 1.6462798118591309,
      "learning_rate": 6.835744680851064e-06,
      "loss": 0.0907,
      "step": 5027
    },
    {
      "epoch": 1.1553308823529411,
      "grad_norm": 1.5765407085418701,
      "learning_rate": 6.834893617021278e-06,
      "loss": 0.0993,
      "step": 5028
    },
    {
      "epoch": 1.1555606617647058,
      "grad_norm": 1.6200717687606812,
      "learning_rate": 6.83404255319149e-06,
      "loss": 0.0848,
      "step": 5029
    },
    {
      "epoch": 1.1557904411764706,
      "grad_norm": 0.9896571040153503,
      "learning_rate": 6.8331914893617026e-06,
      "loss": 0.0556,
      "step": 5030
    },
    {
      "epoch": 1.1560202205882353,
      "grad_norm": 0.9658522009849548,
      "learning_rate": 6.832340425531916e-06,
      "loss": 0.0683,
      "step": 5031
    },
    {
      "epoch": 1.15625,
      "grad_norm": 1.3010938167572021,
      "learning_rate": 6.831489361702128e-06,
      "loss": 0.0713,
      "step": 5032
    },
    {
      "epoch": 1.1564797794117647,
      "grad_norm": 1.2606390714645386,
      "learning_rate": 6.83063829787234e-06,
      "loss": 0.1109,
      "step": 5033
    },
    {
      "epoch": 1.1567095588235294,
      "grad_norm": 1.2528434991836548,
      "learning_rate": 6.829787234042554e-06,
      "loss": 0.0686,
      "step": 5034
    },
    {
      "epoch": 1.1569393382352942,
      "grad_norm": 1.3338229656219482,
      "learning_rate": 6.828936170212767e-06,
      "loss": 0.0822,
      "step": 5035
    },
    {
      "epoch": 1.1571691176470589,
      "grad_norm": 0.9091542959213257,
      "learning_rate": 6.828085106382979e-06,
      "loss": 0.075,
      "step": 5036
    },
    {
      "epoch": 1.1573988970588236,
      "grad_norm": 1.6546837091445923,
      "learning_rate": 6.827234042553192e-06,
      "loss": 0.1039,
      "step": 5037
    },
    {
      "epoch": 1.1576286764705883,
      "grad_norm": 1.1542750597000122,
      "learning_rate": 6.8263829787234045e-06,
      "loss": 0.0699,
      "step": 5038
    },
    {
      "epoch": 1.157858455882353,
      "grad_norm": 0.8684214949607849,
      "learning_rate": 6.825531914893617e-06,
      "loss": 0.0678,
      "step": 5039
    },
    {
      "epoch": 1.1580882352941178,
      "grad_norm": 1.8588027954101562,
      "learning_rate": 6.824680851063831e-06,
      "loss": 0.0781,
      "step": 5040
    },
    {
      "epoch": 1.1583180147058822,
      "grad_norm": 1.1919071674346924,
      "learning_rate": 6.823829787234043e-06,
      "loss": 0.0846,
      "step": 5041
    },
    {
      "epoch": 1.158547794117647,
      "grad_norm": 1.298392415046692,
      "learning_rate": 6.8229787234042555e-06,
      "loss": 0.0982,
      "step": 5042
    },
    {
      "epoch": 1.1587775735294117,
      "grad_norm": 1.280202031135559,
      "learning_rate": 6.822127659574469e-06,
      "loss": 0.1251,
      "step": 5043
    },
    {
      "epoch": 1.1590073529411764,
      "grad_norm": 1.0027652978897095,
      "learning_rate": 6.821276595744681e-06,
      "loss": 0.0756,
      "step": 5044
    },
    {
      "epoch": 1.1592371323529411,
      "grad_norm": 1.52494215965271,
      "learning_rate": 6.820425531914893e-06,
      "loss": 0.0828,
      "step": 5045
    },
    {
      "epoch": 1.1594669117647058,
      "grad_norm": 1.0896670818328857,
      "learning_rate": 6.819574468085107e-06,
      "loss": 0.0767,
      "step": 5046
    },
    {
      "epoch": 1.1596966911764706,
      "grad_norm": 1.243262767791748,
      "learning_rate": 6.81872340425532e-06,
      "loss": 0.09,
      "step": 5047
    },
    {
      "epoch": 1.1599264705882353,
      "grad_norm": 1.2020891904830933,
      "learning_rate": 6.817872340425532e-06,
      "loss": 0.0771,
      "step": 5048
    },
    {
      "epoch": 1.16015625,
      "grad_norm": 1.3662726879119873,
      "learning_rate": 6.817021276595745e-06,
      "loss": 0.1309,
      "step": 5049
    },
    {
      "epoch": 1.1603860294117647,
      "grad_norm": 1.277604341506958,
      "learning_rate": 6.8161702127659575e-06,
      "loss": 0.1059,
      "step": 5050
    },
    {
      "epoch": 1.1606158088235294,
      "grad_norm": 1.6721160411834717,
      "learning_rate": 6.815319148936171e-06,
      "loss": 0.0988,
      "step": 5051
    },
    {
      "epoch": 1.1608455882352942,
      "grad_norm": 1.1238163709640503,
      "learning_rate": 6.814468085106384e-06,
      "loss": 0.0776,
      "step": 5052
    },
    {
      "epoch": 1.1610753676470589,
      "grad_norm": 1.706587791442871,
      "learning_rate": 6.813617021276596e-06,
      "loss": 0.1223,
      "step": 5053
    },
    {
      "epoch": 1.1613051470588236,
      "grad_norm": 0.9224934577941895,
      "learning_rate": 6.8127659574468085e-06,
      "loss": 0.0625,
      "step": 5054
    },
    {
      "epoch": 1.1615349264705883,
      "grad_norm": 1.3215289115905762,
      "learning_rate": 6.811914893617022e-06,
      "loss": 0.0858,
      "step": 5055
    },
    {
      "epoch": 1.161764705882353,
      "grad_norm": 1.1390767097473145,
      "learning_rate": 6.811063829787235e-06,
      "loss": 0.0835,
      "step": 5056
    },
    {
      "epoch": 1.1619944852941178,
      "grad_norm": 1.2004637718200684,
      "learning_rate": 6.810212765957447e-06,
      "loss": 0.0676,
      "step": 5057
    },
    {
      "epoch": 1.1622242647058822,
      "grad_norm": 1.3175806999206543,
      "learning_rate": 6.80936170212766e-06,
      "loss": 0.0752,
      "step": 5058
    },
    {
      "epoch": 1.162454044117647,
      "grad_norm": 1.299228549003601,
      "learning_rate": 6.808510638297873e-06,
      "loss": 0.1134,
      "step": 5059
    },
    {
      "epoch": 1.1626838235294117,
      "grad_norm": 1.0330878496170044,
      "learning_rate": 6.807659574468085e-06,
      "loss": 0.0715,
      "step": 5060
    },
    {
      "epoch": 1.1629136029411764,
      "grad_norm": 1.0109620094299316,
      "learning_rate": 6.806808510638299e-06,
      "loss": 0.0787,
      "step": 5061
    },
    {
      "epoch": 1.1631433823529411,
      "grad_norm": 1.496324062347412,
      "learning_rate": 6.805957446808511e-06,
      "loss": 0.1187,
      "step": 5062
    },
    {
      "epoch": 1.1633731617647058,
      "grad_norm": 1.502798318862915,
      "learning_rate": 6.8051063829787245e-06,
      "loss": 0.1121,
      "step": 5063
    },
    {
      "epoch": 1.1636029411764706,
      "grad_norm": 1.3874138593673706,
      "learning_rate": 6.804255319148937e-06,
      "loss": 0.0982,
      "step": 5064
    },
    {
      "epoch": 1.1638327205882353,
      "grad_norm": 1.4171886444091797,
      "learning_rate": 6.803404255319149e-06,
      "loss": 0.0736,
      "step": 5065
    },
    {
      "epoch": 1.1640625,
      "grad_norm": 1.7965648174285889,
      "learning_rate": 6.802553191489363e-06,
      "loss": 0.1051,
      "step": 5066
    },
    {
      "epoch": 1.1642922794117647,
      "grad_norm": 1.0672732591629028,
      "learning_rate": 6.8017021276595755e-06,
      "loss": 0.0594,
      "step": 5067
    },
    {
      "epoch": 1.1645220588235294,
      "grad_norm": 1.6338366270065308,
      "learning_rate": 6.800851063829788e-06,
      "loss": 0.099,
      "step": 5068
    },
    {
      "epoch": 1.1647518382352942,
      "grad_norm": 1.5549882650375366,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.1006,
      "step": 5069
    },
    {
      "epoch": 1.1649816176470589,
      "grad_norm": 1.1077251434326172,
      "learning_rate": 6.799148936170213e-06,
      "loss": 0.1175,
      "step": 5070
    },
    {
      "epoch": 1.1652113970588236,
      "grad_norm": 1.0871978998184204,
      "learning_rate": 6.798297872340426e-06,
      "loss": 0.091,
      "step": 5071
    },
    {
      "epoch": 1.1654411764705883,
      "grad_norm": 1.4547829627990723,
      "learning_rate": 6.79744680851064e-06,
      "loss": 0.1041,
      "step": 5072
    },
    {
      "epoch": 1.165670955882353,
      "grad_norm": 0.9441272020339966,
      "learning_rate": 6.796595744680852e-06,
      "loss": 0.0699,
      "step": 5073
    },
    {
      "epoch": 1.1659007352941178,
      "grad_norm": 1.2414056062698364,
      "learning_rate": 6.795744680851064e-06,
      "loss": 0.0952,
      "step": 5074
    },
    {
      "epoch": 1.1661305147058822,
      "grad_norm": 1.4719722270965576,
      "learning_rate": 6.7948936170212774e-06,
      "loss": 0.1379,
      "step": 5075
    },
    {
      "epoch": 1.166360294117647,
      "grad_norm": 1.1334022283554077,
      "learning_rate": 6.79404255319149e-06,
      "loss": 0.083,
      "step": 5076
    },
    {
      "epoch": 1.1665900735294117,
      "grad_norm": 1.4752706289291382,
      "learning_rate": 6.793191489361702e-06,
      "loss": 0.1103,
      "step": 5077
    },
    {
      "epoch": 1.1668198529411764,
      "grad_norm": 1.1227412223815918,
      "learning_rate": 6.792340425531916e-06,
      "loss": 0.1084,
      "step": 5078
    },
    {
      "epoch": 1.1670496323529411,
      "grad_norm": 1.0511094331741333,
      "learning_rate": 6.7914893617021284e-06,
      "loss": 0.0697,
      "step": 5079
    },
    {
      "epoch": 1.1672794117647058,
      "grad_norm": 1.338937759399414,
      "learning_rate": 6.790638297872341e-06,
      "loss": 0.1203,
      "step": 5080
    },
    {
      "epoch": 1.1675091911764706,
      "grad_norm": 1.1690056324005127,
      "learning_rate": 6.789787234042554e-06,
      "loss": 0.0865,
      "step": 5081
    },
    {
      "epoch": 1.1677389705882353,
      "grad_norm": 1.422419786453247,
      "learning_rate": 6.788936170212766e-06,
      "loss": 0.0849,
      "step": 5082
    },
    {
      "epoch": 1.16796875,
      "grad_norm": 0.9662404656410217,
      "learning_rate": 6.7880851063829786e-06,
      "loss": 0.0901,
      "step": 5083
    },
    {
      "epoch": 1.1681985294117647,
      "grad_norm": 1.3021880388259888,
      "learning_rate": 6.787234042553193e-06,
      "loss": 0.0825,
      "step": 5084
    },
    {
      "epoch": 1.1684283088235294,
      "grad_norm": 1.2222446203231812,
      "learning_rate": 6.786382978723405e-06,
      "loss": 0.061,
      "step": 5085
    },
    {
      "epoch": 1.1686580882352942,
      "grad_norm": 0.9453117251396179,
      "learning_rate": 6.785531914893617e-06,
      "loss": 0.1007,
      "step": 5086
    },
    {
      "epoch": 1.1688878676470589,
      "grad_norm": 1.0932790040969849,
      "learning_rate": 6.78468085106383e-06,
      "loss": 0.0743,
      "step": 5087
    },
    {
      "epoch": 1.1691176470588236,
      "grad_norm": 1.0982935428619385,
      "learning_rate": 6.783829787234043e-06,
      "loss": 0.0739,
      "step": 5088
    },
    {
      "epoch": 1.1693474264705883,
      "grad_norm": 1.0658468008041382,
      "learning_rate": 6.782978723404255e-06,
      "loss": 0.0935,
      "step": 5089
    },
    {
      "epoch": 1.169577205882353,
      "grad_norm": 1.5918813943862915,
      "learning_rate": 6.782127659574469e-06,
      "loss": 0.121,
      "step": 5090
    },
    {
      "epoch": 1.1698069852941178,
      "grad_norm": 1.349938988685608,
      "learning_rate": 6.781276595744681e-06,
      "loss": 0.1177,
      "step": 5091
    },
    {
      "epoch": 1.1700367647058822,
      "grad_norm": 1.115189790725708,
      "learning_rate": 6.780425531914894e-06,
      "loss": 0.089,
      "step": 5092
    },
    {
      "epoch": 1.170266544117647,
      "grad_norm": 1.3749674558639526,
      "learning_rate": 6.779574468085107e-06,
      "loss": 0.1047,
      "step": 5093
    },
    {
      "epoch": 1.1704963235294117,
      "grad_norm": 1.1844931840896606,
      "learning_rate": 6.778723404255319e-06,
      "loss": 0.0818,
      "step": 5094
    },
    {
      "epoch": 1.1707261029411764,
      "grad_norm": 1.7193833589553833,
      "learning_rate": 6.777872340425532e-06,
      "loss": 0.1308,
      "step": 5095
    },
    {
      "epoch": 1.1709558823529411,
      "grad_norm": 1.1736171245574951,
      "learning_rate": 6.7770212765957456e-06,
      "loss": 0.0858,
      "step": 5096
    },
    {
      "epoch": 1.1711856617647058,
      "grad_norm": 1.2485628128051758,
      "learning_rate": 6.776170212765958e-06,
      "loss": 0.0735,
      "step": 5097
    },
    {
      "epoch": 1.1714154411764706,
      "grad_norm": 1.3975286483764648,
      "learning_rate": 6.77531914893617e-06,
      "loss": 0.0904,
      "step": 5098
    },
    {
      "epoch": 1.1716452205882353,
      "grad_norm": 1.585147500038147,
      "learning_rate": 6.774468085106383e-06,
      "loss": 0.1042,
      "step": 5099
    },
    {
      "epoch": 1.171875,
      "grad_norm": 2.163605213165283,
      "learning_rate": 6.7736170212765965e-06,
      "loss": 0.0775,
      "step": 5100
    },
    {
      "epoch": 1.1721047794117647,
      "grad_norm": 1.3949776887893677,
      "learning_rate": 6.772765957446809e-06,
      "loss": 0.0945,
      "step": 5101
    },
    {
      "epoch": 1.1723345588235294,
      "grad_norm": 1.0211595296859741,
      "learning_rate": 6.771914893617022e-06,
      "loss": 0.0899,
      "step": 5102
    },
    {
      "epoch": 1.1725643382352942,
      "grad_norm": 1.3711785078048706,
      "learning_rate": 6.771063829787234e-06,
      "loss": 0.1162,
      "step": 5103
    },
    {
      "epoch": 1.1727941176470589,
      "grad_norm": 1.7521352767944336,
      "learning_rate": 6.770212765957447e-06,
      "loss": 0.0979,
      "step": 5104
    },
    {
      "epoch": 1.1730238970588236,
      "grad_norm": 1.1003166437149048,
      "learning_rate": 6.769361702127661e-06,
      "loss": 0.0728,
      "step": 5105
    },
    {
      "epoch": 1.1732536764705883,
      "grad_norm": 1.282023310661316,
      "learning_rate": 6.768510638297873e-06,
      "loss": 0.0904,
      "step": 5106
    },
    {
      "epoch": 1.173483455882353,
      "grad_norm": 1.0506500005722046,
      "learning_rate": 6.767659574468086e-06,
      "loss": 0.0935,
      "step": 5107
    },
    {
      "epoch": 1.1737132352941178,
      "grad_norm": 0.9585041999816895,
      "learning_rate": 6.7668085106382985e-06,
      "loss": 0.1104,
      "step": 5108
    },
    {
      "epoch": 1.1739430147058822,
      "grad_norm": 1.2835726737976074,
      "learning_rate": 6.765957446808511e-06,
      "loss": 0.0782,
      "step": 5109
    },
    {
      "epoch": 1.174172794117647,
      "grad_norm": 1.1256043910980225,
      "learning_rate": 6.765106382978725e-06,
      "loss": 0.1142,
      "step": 5110
    },
    {
      "epoch": 1.1744025735294117,
      "grad_norm": 1.213232398033142,
      "learning_rate": 6.764255319148937e-06,
      "loss": 0.0875,
      "step": 5111
    },
    {
      "epoch": 1.1746323529411764,
      "grad_norm": 1.318852424621582,
      "learning_rate": 6.7634042553191495e-06,
      "loss": 0.0743,
      "step": 5112
    },
    {
      "epoch": 1.1748621323529411,
      "grad_norm": 1.037724494934082,
      "learning_rate": 6.762553191489363e-06,
      "loss": 0.0769,
      "step": 5113
    },
    {
      "epoch": 1.1750919117647058,
      "grad_norm": 1.2374111413955688,
      "learning_rate": 6.761702127659575e-06,
      "loss": 0.0971,
      "step": 5114
    },
    {
      "epoch": 1.1753216911764706,
      "grad_norm": 1.176811933517456,
      "learning_rate": 6.760851063829787e-06,
      "loss": 0.0907,
      "step": 5115
    },
    {
      "epoch": 1.1755514705882353,
      "grad_norm": 1.2852414846420288,
      "learning_rate": 6.760000000000001e-06,
      "loss": 0.0835,
      "step": 5116
    },
    {
      "epoch": 1.17578125,
      "grad_norm": 1.1730144023895264,
      "learning_rate": 6.759148936170214e-06,
      "loss": 0.0673,
      "step": 5117
    },
    {
      "epoch": 1.1760110294117647,
      "grad_norm": 1.5572028160095215,
      "learning_rate": 6.758297872340426e-06,
      "loss": 0.121,
      "step": 5118
    },
    {
      "epoch": 1.1762408088235294,
      "grad_norm": 1.1070160865783691,
      "learning_rate": 6.757446808510639e-06,
      "loss": 0.0799,
      "step": 5119
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 1.3056260347366333,
      "learning_rate": 6.7565957446808515e-06,
      "loss": 0.1322,
      "step": 5120
    },
    {
      "epoch": 1.1767003676470589,
      "grad_norm": 1.410765528678894,
      "learning_rate": 6.755744680851064e-06,
      "loss": 0.1222,
      "step": 5121
    },
    {
      "epoch": 1.1769301470588236,
      "grad_norm": 1.1614625453948975,
      "learning_rate": 6.754893617021278e-06,
      "loss": 0.1013,
      "step": 5122
    },
    {
      "epoch": 1.1771599264705883,
      "grad_norm": 0.9988560676574707,
      "learning_rate": 6.75404255319149e-06,
      "loss": 0.0793,
      "step": 5123
    },
    {
      "epoch": 1.177389705882353,
      "grad_norm": 1.0056090354919434,
      "learning_rate": 6.7531914893617025e-06,
      "loss": 0.0886,
      "step": 5124
    },
    {
      "epoch": 1.1776194852941178,
      "grad_norm": 1.4830541610717773,
      "learning_rate": 6.752340425531916e-06,
      "loss": 0.1185,
      "step": 5125
    },
    {
      "epoch": 1.1778492647058822,
      "grad_norm": 0.9958857893943787,
      "learning_rate": 6.751489361702128e-06,
      "loss": 0.0685,
      "step": 5126
    },
    {
      "epoch": 1.178079044117647,
      "grad_norm": 1.496917724609375,
      "learning_rate": 6.75063829787234e-06,
      "loss": 0.0839,
      "step": 5127
    },
    {
      "epoch": 1.1783088235294117,
      "grad_norm": 1.0531604290008545,
      "learning_rate": 6.749787234042554e-06,
      "loss": 0.0819,
      "step": 5128
    },
    {
      "epoch": 1.1785386029411764,
      "grad_norm": 1.0574349164962769,
      "learning_rate": 6.748936170212767e-06,
      "loss": 0.0806,
      "step": 5129
    },
    {
      "epoch": 1.1787683823529411,
      "grad_norm": 1.4416218996047974,
      "learning_rate": 6.748085106382979e-06,
      "loss": 0.0859,
      "step": 5130
    },
    {
      "epoch": 1.1789981617647058,
      "grad_norm": 1.1296494007110596,
      "learning_rate": 6.747234042553192e-06,
      "loss": 0.0787,
      "step": 5131
    },
    {
      "epoch": 1.1792279411764706,
      "grad_norm": 1.1651936769485474,
      "learning_rate": 6.7463829787234045e-06,
      "loss": 0.0704,
      "step": 5132
    },
    {
      "epoch": 1.1794577205882353,
      "grad_norm": 1.3004331588745117,
      "learning_rate": 6.745531914893617e-06,
      "loss": 0.0769,
      "step": 5133
    },
    {
      "epoch": 1.1796875,
      "grad_norm": 1.2856611013412476,
      "learning_rate": 6.744680851063831e-06,
      "loss": 0.1093,
      "step": 5134
    },
    {
      "epoch": 1.1799172794117647,
      "grad_norm": 1.0692129135131836,
      "learning_rate": 6.743829787234043e-06,
      "loss": 0.0739,
      "step": 5135
    },
    {
      "epoch": 1.1801470588235294,
      "grad_norm": 1.800068736076355,
      "learning_rate": 6.7429787234042554e-06,
      "loss": 0.1186,
      "step": 5136
    },
    {
      "epoch": 1.1803768382352942,
      "grad_norm": 1.3216612339019775,
      "learning_rate": 6.742127659574469e-06,
      "loss": 0.0996,
      "step": 5137
    },
    {
      "epoch": 1.1806066176470589,
      "grad_norm": 1.541067123413086,
      "learning_rate": 6.741276595744681e-06,
      "loss": 0.08,
      "step": 5138
    },
    {
      "epoch": 1.1808363970588236,
      "grad_norm": 1.2359145879745483,
      "learning_rate": 6.740425531914894e-06,
      "loss": 0.0804,
      "step": 5139
    },
    {
      "epoch": 1.1810661764705883,
      "grad_norm": 1.0180132389068604,
      "learning_rate": 6.739574468085107e-06,
      "loss": 0.1043,
      "step": 5140
    },
    {
      "epoch": 1.181295955882353,
      "grad_norm": 1.4237726926803589,
      "learning_rate": 6.73872340425532e-06,
      "loss": 0.0632,
      "step": 5141
    },
    {
      "epoch": 1.1815257352941178,
      "grad_norm": 1.6113849878311157,
      "learning_rate": 6.737872340425532e-06,
      "loss": 0.098,
      "step": 5142
    },
    {
      "epoch": 1.1817555147058822,
      "grad_norm": 1.3417468070983887,
      "learning_rate": 6.737021276595745e-06,
      "loss": 0.0892,
      "step": 5143
    },
    {
      "epoch": 1.181985294117647,
      "grad_norm": 1.1843892335891724,
      "learning_rate": 6.736170212765957e-06,
      "loss": 0.0988,
      "step": 5144
    },
    {
      "epoch": 1.1822150735294117,
      "grad_norm": 1.3131457567214966,
      "learning_rate": 6.735319148936171e-06,
      "loss": 0.1175,
      "step": 5145
    },
    {
      "epoch": 1.1824448529411764,
      "grad_norm": 0.9761945009231567,
      "learning_rate": 6.734468085106384e-06,
      "loss": 0.0645,
      "step": 5146
    },
    {
      "epoch": 1.1826746323529411,
      "grad_norm": 1.6195508241653442,
      "learning_rate": 6.733617021276596e-06,
      "loss": 0.0963,
      "step": 5147
    },
    {
      "epoch": 1.1829044117647058,
      "grad_norm": 1.025765299797058,
      "learning_rate": 6.732765957446809e-06,
      "loss": 0.0862,
      "step": 5148
    },
    {
      "epoch": 1.1831341911764706,
      "grad_norm": 1.3484383821487427,
      "learning_rate": 6.7319148936170216e-06,
      "loss": 0.0806,
      "step": 5149
    },
    {
      "epoch": 1.1833639705882353,
      "grad_norm": 0.9764078855514526,
      "learning_rate": 6.731063829787235e-06,
      "loss": 0.0678,
      "step": 5150
    },
    {
      "epoch": 1.18359375,
      "grad_norm": 1.5601425170898438,
      "learning_rate": 6.730212765957448e-06,
      "loss": 0.103,
      "step": 5151
    },
    {
      "epoch": 1.1838235294117647,
      "grad_norm": 1.0971232652664185,
      "learning_rate": 6.72936170212766e-06,
      "loss": 0.0581,
      "step": 5152
    },
    {
      "epoch": 1.1840533088235294,
      "grad_norm": 1.1081268787384033,
      "learning_rate": 6.7285106382978726e-06,
      "loss": 0.1051,
      "step": 5153
    },
    {
      "epoch": 1.1842830882352942,
      "grad_norm": 1.2112456560134888,
      "learning_rate": 6.727659574468086e-06,
      "loss": 0.0755,
      "step": 5154
    },
    {
      "epoch": 1.1845128676470589,
      "grad_norm": 1.2323887348175049,
      "learning_rate": 6.726808510638299e-06,
      "loss": 0.0737,
      "step": 5155
    },
    {
      "epoch": 1.1847426470588236,
      "grad_norm": 1.288195252418518,
      "learning_rate": 6.725957446808511e-06,
      "loss": 0.0515,
      "step": 5156
    },
    {
      "epoch": 1.1849724264705883,
      "grad_norm": 1.0201842784881592,
      "learning_rate": 6.725106382978724e-06,
      "loss": 0.0827,
      "step": 5157
    },
    {
      "epoch": 1.185202205882353,
      "grad_norm": 1.0987417697906494,
      "learning_rate": 6.724255319148937e-06,
      "loss": 0.1051,
      "step": 5158
    },
    {
      "epoch": 1.1854319852941178,
      "grad_norm": 1.0605911016464233,
      "learning_rate": 6.723404255319149e-06,
      "loss": 0.075,
      "step": 5159
    },
    {
      "epoch": 1.1856617647058822,
      "grad_norm": 1.1052346229553223,
      "learning_rate": 6.722553191489363e-06,
      "loss": 0.0852,
      "step": 5160
    },
    {
      "epoch": 1.185891544117647,
      "grad_norm": 1.2440235614776611,
      "learning_rate": 6.721702127659575e-06,
      "loss": 0.0686,
      "step": 5161
    },
    {
      "epoch": 1.1861213235294117,
      "grad_norm": 1.1373772621154785,
      "learning_rate": 6.720851063829788e-06,
      "loss": 0.098,
      "step": 5162
    },
    {
      "epoch": 1.1863511029411764,
      "grad_norm": 1.2394880056381226,
      "learning_rate": 6.720000000000001e-06,
      "loss": 0.0832,
      "step": 5163
    },
    {
      "epoch": 1.1865808823529411,
      "grad_norm": 1.1127841472625732,
      "learning_rate": 6.719148936170213e-06,
      "loss": 0.1099,
      "step": 5164
    },
    {
      "epoch": 1.1868106617647058,
      "grad_norm": 0.9217703938484192,
      "learning_rate": 6.7182978723404255e-06,
      "loss": 0.0683,
      "step": 5165
    },
    {
      "epoch": 1.1870404411764706,
      "grad_norm": 1.1655151844024658,
      "learning_rate": 6.7174468085106395e-06,
      "loss": 0.0788,
      "step": 5166
    },
    {
      "epoch": 1.1872702205882353,
      "grad_norm": 1.5837210416793823,
      "learning_rate": 6.716595744680852e-06,
      "loss": 0.1064,
      "step": 5167
    },
    {
      "epoch": 1.1875,
      "grad_norm": 1.2724965810775757,
      "learning_rate": 6.715744680851064e-06,
      "loss": 0.1111,
      "step": 5168
    },
    {
      "epoch": 1.1877297794117647,
      "grad_norm": 0.9686424136161804,
      "learning_rate": 6.714893617021277e-06,
      "loss": 0.0733,
      "step": 5169
    },
    {
      "epoch": 1.1879595588235294,
      "grad_norm": 2.0433757305145264,
      "learning_rate": 6.71404255319149e-06,
      "loss": 0.1201,
      "step": 5170
    },
    {
      "epoch": 1.1881893382352942,
      "grad_norm": 1.5710211992263794,
      "learning_rate": 6.713191489361702e-06,
      "loss": 0.0849,
      "step": 5171
    },
    {
      "epoch": 1.1884191176470589,
      "grad_norm": 1.4925274848937988,
      "learning_rate": 6.712340425531916e-06,
      "loss": 0.1026,
      "step": 5172
    },
    {
      "epoch": 1.1886488970588236,
      "grad_norm": 1.41446053981781,
      "learning_rate": 6.711489361702128e-06,
      "loss": 0.0917,
      "step": 5173
    },
    {
      "epoch": 1.1888786764705883,
      "grad_norm": 1.2033511400222778,
      "learning_rate": 6.710638297872341e-06,
      "loss": 0.0788,
      "step": 5174
    },
    {
      "epoch": 1.189108455882353,
      "grad_norm": 1.1009628772735596,
      "learning_rate": 6.709787234042554e-06,
      "loss": 0.0685,
      "step": 5175
    },
    {
      "epoch": 1.1893382352941178,
      "grad_norm": 1.8424698114395142,
      "learning_rate": 6.708936170212766e-06,
      "loss": 0.1254,
      "step": 5176
    },
    {
      "epoch": 1.1895680147058822,
      "grad_norm": 0.9367951154708862,
      "learning_rate": 6.7080851063829785e-06,
      "loss": 0.0675,
      "step": 5177
    },
    {
      "epoch": 1.189797794117647,
      "grad_norm": 1.139665961265564,
      "learning_rate": 6.7072340425531925e-06,
      "loss": 0.0875,
      "step": 5178
    },
    {
      "epoch": 1.1900275735294117,
      "grad_norm": 1.2401716709136963,
      "learning_rate": 6.706382978723405e-06,
      "loss": 0.0614,
      "step": 5179
    },
    {
      "epoch": 1.1902573529411764,
      "grad_norm": 1.4186303615570068,
      "learning_rate": 6.705531914893617e-06,
      "loss": 0.1014,
      "step": 5180
    },
    {
      "epoch": 1.1904871323529411,
      "grad_norm": 1.2130039930343628,
      "learning_rate": 6.70468085106383e-06,
      "loss": 0.0896,
      "step": 5181
    },
    {
      "epoch": 1.1907169117647058,
      "grad_norm": 1.2280093431472778,
      "learning_rate": 6.703829787234043e-06,
      "loss": 0.0788,
      "step": 5182
    },
    {
      "epoch": 1.1909466911764706,
      "grad_norm": 1.310857892036438,
      "learning_rate": 6.702978723404255e-06,
      "loss": 0.1088,
      "step": 5183
    },
    {
      "epoch": 1.1911764705882353,
      "grad_norm": 1.1873966455459595,
      "learning_rate": 6.702127659574469e-06,
      "loss": 0.0862,
      "step": 5184
    },
    {
      "epoch": 1.19140625,
      "grad_norm": 1.796370029449463,
      "learning_rate": 6.701276595744681e-06,
      "loss": 0.1112,
      "step": 5185
    },
    {
      "epoch": 1.1916360294117647,
      "grad_norm": 1.5352402925491333,
      "learning_rate": 6.700425531914894e-06,
      "loss": 0.1225,
      "step": 5186
    },
    {
      "epoch": 1.1918658088235294,
      "grad_norm": 1.01521635055542,
      "learning_rate": 6.699574468085107e-06,
      "loss": 0.0813,
      "step": 5187
    },
    {
      "epoch": 1.1920955882352942,
      "grad_norm": 1.202770471572876,
      "learning_rate": 6.698723404255319e-06,
      "loss": 0.1076,
      "step": 5188
    },
    {
      "epoch": 1.1923253676470589,
      "grad_norm": 1.3916407823562622,
      "learning_rate": 6.697872340425532e-06,
      "loss": 0.1152,
      "step": 5189
    },
    {
      "epoch": 1.1925551470588236,
      "grad_norm": 1.5401859283447266,
      "learning_rate": 6.6970212765957455e-06,
      "loss": 0.1122,
      "step": 5190
    },
    {
      "epoch": 1.1927849264705883,
      "grad_norm": 0.9757969379425049,
      "learning_rate": 6.696170212765958e-06,
      "loss": 0.0704,
      "step": 5191
    },
    {
      "epoch": 1.193014705882353,
      "grad_norm": 1.1009442806243896,
      "learning_rate": 6.695319148936171e-06,
      "loss": 0.0639,
      "step": 5192
    },
    {
      "epoch": 1.1932444852941178,
      "grad_norm": 1.1628961563110352,
      "learning_rate": 6.694468085106383e-06,
      "loss": 0.0932,
      "step": 5193
    },
    {
      "epoch": 1.1934742647058822,
      "grad_norm": 1.4855451583862305,
      "learning_rate": 6.6936170212765965e-06,
      "loss": 0.0977,
      "step": 5194
    },
    {
      "epoch": 1.193704044117647,
      "grad_norm": 1.1924735307693481,
      "learning_rate": 6.69276595744681e-06,
      "loss": 0.0894,
      "step": 5195
    },
    {
      "epoch": 1.1939338235294117,
      "grad_norm": 0.9546253681182861,
      "learning_rate": 6.691914893617022e-06,
      "loss": 0.0582,
      "step": 5196
    },
    {
      "epoch": 1.1941636029411764,
      "grad_norm": 1.3881977796554565,
      "learning_rate": 6.691063829787234e-06,
      "loss": 0.0804,
      "step": 5197
    },
    {
      "epoch": 1.1943933823529411,
      "grad_norm": 1.1444368362426758,
      "learning_rate": 6.6902127659574475e-06,
      "loss": 0.0785,
      "step": 5198
    },
    {
      "epoch": 1.1946231617647058,
      "grad_norm": 1.1061201095581055,
      "learning_rate": 6.689361702127661e-06,
      "loss": 0.0762,
      "step": 5199
    },
    {
      "epoch": 1.1948529411764706,
      "grad_norm": 1.6948740482330322,
      "learning_rate": 6.688510638297873e-06,
      "loss": 0.0715,
      "step": 5200
    },
    {
      "epoch": 1.1950827205882353,
      "grad_norm": 1.154451608657837,
      "learning_rate": 6.687659574468086e-06,
      "loss": 0.0893,
      "step": 5201
    },
    {
      "epoch": 1.1953125,
      "grad_norm": 1.2348687648773193,
      "learning_rate": 6.6868085106382984e-06,
      "loss": 0.0719,
      "step": 5202
    },
    {
      "epoch": 1.1955422794117647,
      "grad_norm": 1.3702398538589478,
      "learning_rate": 6.685957446808511e-06,
      "loss": 0.0958,
      "step": 5203
    },
    {
      "epoch": 1.1957720588235294,
      "grad_norm": 1.4295313358306885,
      "learning_rate": 6.685106382978725e-06,
      "loss": 0.0978,
      "step": 5204
    },
    {
      "epoch": 1.1960018382352942,
      "grad_norm": 1.3122200965881348,
      "learning_rate": 6.684255319148937e-06,
      "loss": 0.076,
      "step": 5205
    },
    {
      "epoch": 1.1962316176470589,
      "grad_norm": 1.2484861612319946,
      "learning_rate": 6.6834042553191494e-06,
      "loss": 0.0945,
      "step": 5206
    },
    {
      "epoch": 1.1964613970588236,
      "grad_norm": 1.2005780935287476,
      "learning_rate": 6.682553191489363e-06,
      "loss": 0.0828,
      "step": 5207
    },
    {
      "epoch": 1.1966911764705883,
      "grad_norm": 0.9795623421669006,
      "learning_rate": 6.681702127659575e-06,
      "loss": 0.0537,
      "step": 5208
    },
    {
      "epoch": 1.196920955882353,
      "grad_norm": 0.9275387525558472,
      "learning_rate": 6.680851063829787e-06,
      "loss": 0.0716,
      "step": 5209
    },
    {
      "epoch": 1.1971507352941178,
      "grad_norm": 1.681848168373108,
      "learning_rate": 6.680000000000001e-06,
      "loss": 0.0993,
      "step": 5210
    },
    {
      "epoch": 1.1973805147058822,
      "grad_norm": 1.218809723854065,
      "learning_rate": 6.679148936170214e-06,
      "loss": 0.0772,
      "step": 5211
    },
    {
      "epoch": 1.197610294117647,
      "grad_norm": 1.0789567232131958,
      "learning_rate": 6.678297872340426e-06,
      "loss": 0.0867,
      "step": 5212
    },
    {
      "epoch": 1.1978400735294117,
      "grad_norm": 0.9255690574645996,
      "learning_rate": 6.677446808510639e-06,
      "loss": 0.076,
      "step": 5213
    },
    {
      "epoch": 1.1980698529411764,
      "grad_norm": 1.1162060499191284,
      "learning_rate": 6.676595744680851e-06,
      "loss": 0.0749,
      "step": 5214
    },
    {
      "epoch": 1.1982996323529411,
      "grad_norm": 1.5966671705245972,
      "learning_rate": 6.675744680851064e-06,
      "loss": 0.069,
      "step": 5215
    },
    {
      "epoch": 1.1985294117647058,
      "grad_norm": 1.3693212270736694,
      "learning_rate": 6.674893617021278e-06,
      "loss": 0.068,
      "step": 5216
    },
    {
      "epoch": 1.1987591911764706,
      "grad_norm": 1.0635672807693481,
      "learning_rate": 6.67404255319149e-06,
      "loss": 0.0752,
      "step": 5217
    },
    {
      "epoch": 1.1989889705882353,
      "grad_norm": 0.9345402121543884,
      "learning_rate": 6.673191489361702e-06,
      "loss": 0.0768,
      "step": 5218
    },
    {
      "epoch": 1.19921875,
      "grad_norm": 1.9530872106552124,
      "learning_rate": 6.6723404255319156e-06,
      "loss": 0.1029,
      "step": 5219
    },
    {
      "epoch": 1.1994485294117647,
      "grad_norm": 0.8494628071784973,
      "learning_rate": 6.671489361702128e-06,
      "loss": 0.0595,
      "step": 5220
    },
    {
      "epoch": 1.1996783088235294,
      "grad_norm": 1.3317533731460571,
      "learning_rate": 6.67063829787234e-06,
      "loss": 0.0781,
      "step": 5221
    },
    {
      "epoch": 1.1999080882352942,
      "grad_norm": 0.9712746143341064,
      "learning_rate": 6.669787234042554e-06,
      "loss": 0.0707,
      "step": 5222
    },
    {
      "epoch": 1.2001378676470589,
      "grad_norm": 1.0067448616027832,
      "learning_rate": 6.6689361702127666e-06,
      "loss": 0.0684,
      "step": 5223
    },
    {
      "epoch": 1.2003676470588236,
      "grad_norm": 1.372711181640625,
      "learning_rate": 6.668085106382979e-06,
      "loss": 0.1147,
      "step": 5224
    },
    {
      "epoch": 1.2005974264705883,
      "grad_norm": 1.520589828491211,
      "learning_rate": 6.667234042553192e-06,
      "loss": 0.0907,
      "step": 5225
    },
    {
      "epoch": 1.200827205882353,
      "grad_norm": 1.502014398574829,
      "learning_rate": 6.666382978723404e-06,
      "loss": 0.071,
      "step": 5226
    },
    {
      "epoch": 1.2010569852941178,
      "grad_norm": 1.1974363327026367,
      "learning_rate": 6.665531914893617e-06,
      "loss": 0.1042,
      "step": 5227
    },
    {
      "epoch": 1.2012867647058822,
      "grad_norm": 1.10776686668396,
      "learning_rate": 6.664680851063831e-06,
      "loss": 0.0669,
      "step": 5228
    },
    {
      "epoch": 1.201516544117647,
      "grad_norm": 1.3927327394485474,
      "learning_rate": 6.663829787234043e-06,
      "loss": 0.0928,
      "step": 5229
    },
    {
      "epoch": 1.2017463235294117,
      "grad_norm": 1.0161628723144531,
      "learning_rate": 6.662978723404255e-06,
      "loss": 0.0694,
      "step": 5230
    },
    {
      "epoch": 1.2019761029411764,
      "grad_norm": 1.346479892730713,
      "learning_rate": 6.6621276595744685e-06,
      "loss": 0.0762,
      "step": 5231
    },
    {
      "epoch": 1.2022058823529411,
      "grad_norm": 1.3431332111358643,
      "learning_rate": 6.661276595744681e-06,
      "loss": 0.0954,
      "step": 5232
    },
    {
      "epoch": 1.2024356617647058,
      "grad_norm": 1.4290213584899902,
      "learning_rate": 6.660425531914895e-06,
      "loss": 0.1087,
      "step": 5233
    },
    {
      "epoch": 1.2026654411764706,
      "grad_norm": 1.3198509216308594,
      "learning_rate": 6.659574468085107e-06,
      "loss": 0.0825,
      "step": 5234
    },
    {
      "epoch": 1.2028952205882353,
      "grad_norm": 0.8454654216766357,
      "learning_rate": 6.6587234042553195e-06,
      "loss": 0.064,
      "step": 5235
    },
    {
      "epoch": 1.203125,
      "grad_norm": 1.3158838748931885,
      "learning_rate": 6.657872340425533e-06,
      "loss": 0.1022,
      "step": 5236
    },
    {
      "epoch": 1.2033547794117647,
      "grad_norm": 1.7719820737838745,
      "learning_rate": 6.657021276595745e-06,
      "loss": 0.1107,
      "step": 5237
    },
    {
      "epoch": 1.2035845588235294,
      "grad_norm": 1.1532845497131348,
      "learning_rate": 6.656170212765958e-06,
      "loss": 0.0673,
      "step": 5238
    },
    {
      "epoch": 1.2038143382352942,
      "grad_norm": 1.3199563026428223,
      "learning_rate": 6.655319148936171e-06,
      "loss": 0.088,
      "step": 5239
    },
    {
      "epoch": 1.2040441176470589,
      "grad_norm": 1.535022497177124,
      "learning_rate": 6.654468085106384e-06,
      "loss": 0.089,
      "step": 5240
    },
    {
      "epoch": 1.2042738970588236,
      "grad_norm": 1.2206013202667236,
      "learning_rate": 6.653617021276596e-06,
      "loss": 0.0763,
      "step": 5241
    },
    {
      "epoch": 1.2045036764705883,
      "grad_norm": 1.173932433128357,
      "learning_rate": 6.652765957446809e-06,
      "loss": 0.081,
      "step": 5242
    },
    {
      "epoch": 1.204733455882353,
      "grad_norm": 1.232378363609314,
      "learning_rate": 6.6519148936170215e-06,
      "loss": 0.0906,
      "step": 5243
    },
    {
      "epoch": 1.2049632352941178,
      "grad_norm": 1.1920218467712402,
      "learning_rate": 6.651063829787235e-06,
      "loss": 0.0773,
      "step": 5244
    },
    {
      "epoch": 1.2051930147058822,
      "grad_norm": 1.337302565574646,
      "learning_rate": 6.650212765957448e-06,
      "loss": 0.1099,
      "step": 5245
    },
    {
      "epoch": 1.205422794117647,
      "grad_norm": 1.1241142749786377,
      "learning_rate": 6.64936170212766e-06,
      "loss": 0.0773,
      "step": 5246
    },
    {
      "epoch": 1.2056525735294117,
      "grad_norm": 1.3522311449050903,
      "learning_rate": 6.6485106382978725e-06,
      "loss": 0.098,
      "step": 5247
    },
    {
      "epoch": 1.2058823529411764,
      "grad_norm": 1.3333418369293213,
      "learning_rate": 6.647659574468086e-06,
      "loss": 0.144,
      "step": 5248
    },
    {
      "epoch": 1.2061121323529411,
      "grad_norm": 1.2715351581573486,
      "learning_rate": 6.646808510638299e-06,
      "loss": 0.0968,
      "step": 5249
    },
    {
      "epoch": 1.2063419117647058,
      "grad_norm": 1.0638939142227173,
      "learning_rate": 6.645957446808511e-06,
      "loss": 0.095,
      "step": 5250
    },
    {
      "epoch": 1.2065716911764706,
      "grad_norm": 1.161638855934143,
      "learning_rate": 6.645106382978724e-06,
      "loss": 0.0745,
      "step": 5251
    },
    {
      "epoch": 1.2068014705882353,
      "grad_norm": 1.4709752798080444,
      "learning_rate": 6.644255319148937e-06,
      "loss": 0.093,
      "step": 5252
    },
    {
      "epoch": 1.20703125,
      "grad_norm": 1.431555986404419,
      "learning_rate": 6.643404255319149e-06,
      "loss": 0.112,
      "step": 5253
    },
    {
      "epoch": 1.2072610294117647,
      "grad_norm": 1.4559416770935059,
      "learning_rate": 6.642553191489363e-06,
      "loss": 0.119,
      "step": 5254
    },
    {
      "epoch": 1.2074908088235294,
      "grad_norm": 1.291932225227356,
      "learning_rate": 6.641702127659575e-06,
      "loss": 0.0814,
      "step": 5255
    },
    {
      "epoch": 1.2077205882352942,
      "grad_norm": 1.1289937496185303,
      "learning_rate": 6.640851063829788e-06,
      "loss": 0.0692,
      "step": 5256
    },
    {
      "epoch": 1.2079503676470589,
      "grad_norm": 1.3630926609039307,
      "learning_rate": 6.640000000000001e-06,
      "loss": 0.0673,
      "step": 5257
    },
    {
      "epoch": 1.2081801470588236,
      "grad_norm": 1.1191550493240356,
      "learning_rate": 6.639148936170213e-06,
      "loss": 0.0801,
      "step": 5258
    },
    {
      "epoch": 1.2084099264705883,
      "grad_norm": 0.8907957077026367,
      "learning_rate": 6.6382978723404254e-06,
      "loss": 0.0632,
      "step": 5259
    },
    {
      "epoch": 1.208639705882353,
      "grad_norm": 1.39385187625885,
      "learning_rate": 6.6374468085106395e-06,
      "loss": 0.0795,
      "step": 5260
    },
    {
      "epoch": 1.2088694852941178,
      "grad_norm": 1.0657784938812256,
      "learning_rate": 6.636595744680852e-06,
      "loss": 0.0609,
      "step": 5261
    },
    {
      "epoch": 1.2090992647058822,
      "grad_norm": 1.3372912406921387,
      "learning_rate": 6.635744680851064e-06,
      "loss": 0.0803,
      "step": 5262
    },
    {
      "epoch": 1.209329044117647,
      "grad_norm": 1.7731668949127197,
      "learning_rate": 6.634893617021277e-06,
      "loss": 0.1087,
      "step": 5263
    },
    {
      "epoch": 1.2095588235294117,
      "grad_norm": 1.3569130897521973,
      "learning_rate": 6.63404255319149e-06,
      "loss": 0.0884,
      "step": 5264
    },
    {
      "epoch": 1.2097886029411764,
      "grad_norm": 0.837885856628418,
      "learning_rate": 6.633191489361702e-06,
      "loss": 0.0501,
      "step": 5265
    },
    {
      "epoch": 1.2100183823529411,
      "grad_norm": 0.8276305198669434,
      "learning_rate": 6.632340425531916e-06,
      "loss": 0.0634,
      "step": 5266
    },
    {
      "epoch": 1.2102481617647058,
      "grad_norm": 1.9909590482711792,
      "learning_rate": 6.631489361702128e-06,
      "loss": 0.0785,
      "step": 5267
    },
    {
      "epoch": 1.2104779411764706,
      "grad_norm": 1.0918675661087036,
      "learning_rate": 6.630638297872341e-06,
      "loss": 0.0848,
      "step": 5268
    },
    {
      "epoch": 1.2107077205882353,
      "grad_norm": 1.399153470993042,
      "learning_rate": 6.629787234042554e-06,
      "loss": 0.0904,
      "step": 5269
    },
    {
      "epoch": 1.2109375,
      "grad_norm": 1.0375962257385254,
      "learning_rate": 6.628936170212766e-06,
      "loss": 0.0748,
      "step": 5270
    },
    {
      "epoch": 1.2111672794117647,
      "grad_norm": 1.158474087715149,
      "learning_rate": 6.628085106382978e-06,
      "loss": 0.0793,
      "step": 5271
    },
    {
      "epoch": 1.2113970588235294,
      "grad_norm": 1.3678605556488037,
      "learning_rate": 6.6272340425531924e-06,
      "loss": 0.0889,
      "step": 5272
    },
    {
      "epoch": 1.2116268382352942,
      "grad_norm": 1.224944829940796,
      "learning_rate": 6.626382978723405e-06,
      "loss": 0.0852,
      "step": 5273
    },
    {
      "epoch": 1.2118566176470589,
      "grad_norm": 1.4890376329421997,
      "learning_rate": 6.625531914893617e-06,
      "loss": 0.0896,
      "step": 5274
    },
    {
      "epoch": 1.2120863970588236,
      "grad_norm": 1.521666169166565,
      "learning_rate": 6.62468085106383e-06,
      "loss": 0.0647,
      "step": 5275
    },
    {
      "epoch": 1.2123161764705883,
      "grad_norm": 1.3065142631530762,
      "learning_rate": 6.6238297872340426e-06,
      "loss": 0.0976,
      "step": 5276
    },
    {
      "epoch": 1.212545955882353,
      "grad_norm": 1.24610435962677,
      "learning_rate": 6.622978723404257e-06,
      "loss": 0.0928,
      "step": 5277
    },
    {
      "epoch": 1.2127757352941178,
      "grad_norm": 1.8597230911254883,
      "learning_rate": 6.622127659574469e-06,
      "loss": 0.1356,
      "step": 5278
    },
    {
      "epoch": 1.2130055147058822,
      "grad_norm": 1.0522528886795044,
      "learning_rate": 6.621276595744681e-06,
      "loss": 0.0793,
      "step": 5279
    },
    {
      "epoch": 1.213235294117647,
      "grad_norm": 1.2873287200927734,
      "learning_rate": 6.620425531914894e-06,
      "loss": 0.0991,
      "step": 5280
    },
    {
      "epoch": 1.2134650735294117,
      "grad_norm": 1.1163884401321411,
      "learning_rate": 6.619574468085107e-06,
      "loss": 0.0683,
      "step": 5281
    },
    {
      "epoch": 1.2136948529411764,
      "grad_norm": 1.1695338487625122,
      "learning_rate": 6.618723404255319e-06,
      "loss": 0.1008,
      "step": 5282
    },
    {
      "epoch": 1.2139246323529411,
      "grad_norm": 1.5951851606369019,
      "learning_rate": 6.617872340425533e-06,
      "loss": 0.0941,
      "step": 5283
    },
    {
      "epoch": 1.2141544117647058,
      "grad_norm": 1.2152825593948364,
      "learning_rate": 6.617021276595745e-06,
      "loss": 0.0879,
      "step": 5284
    },
    {
      "epoch": 1.2143841911764706,
      "grad_norm": 0.9598584175109863,
      "learning_rate": 6.616170212765958e-06,
      "loss": 0.0844,
      "step": 5285
    },
    {
      "epoch": 1.2146139705882353,
      "grad_norm": 1.0405794382095337,
      "learning_rate": 6.615319148936171e-06,
      "loss": 0.0767,
      "step": 5286
    },
    {
      "epoch": 1.21484375,
      "grad_norm": 1.1523728370666504,
      "learning_rate": 6.614468085106383e-06,
      "loss": 0.0892,
      "step": 5287
    },
    {
      "epoch": 1.2150735294117647,
      "grad_norm": 1.3421214818954468,
      "learning_rate": 6.613617021276596e-06,
      "loss": 0.081,
      "step": 5288
    },
    {
      "epoch": 1.2153033088235294,
      "grad_norm": 1.4182013273239136,
      "learning_rate": 6.6127659574468096e-06,
      "loss": 0.1255,
      "step": 5289
    },
    {
      "epoch": 1.2155330882352942,
      "grad_norm": 1.07662832736969,
      "learning_rate": 6.611914893617022e-06,
      "loss": 0.0495,
      "step": 5290
    },
    {
      "epoch": 1.2157628676470589,
      "grad_norm": 1.0729413032531738,
      "learning_rate": 6.611063829787234e-06,
      "loss": 0.0736,
      "step": 5291
    },
    {
      "epoch": 1.2159926470588236,
      "grad_norm": 1.1232131719589233,
      "learning_rate": 6.610212765957447e-06,
      "loss": 0.0725,
      "step": 5292
    },
    {
      "epoch": 1.2162224264705883,
      "grad_norm": 1.0608901977539062,
      "learning_rate": 6.6093617021276605e-06,
      "loss": 0.0603,
      "step": 5293
    },
    {
      "epoch": 1.216452205882353,
      "grad_norm": 1.0716232061386108,
      "learning_rate": 6.608510638297873e-06,
      "loss": 0.0839,
      "step": 5294
    },
    {
      "epoch": 1.2166819852941178,
      "grad_norm": 1.465262770652771,
      "learning_rate": 6.607659574468086e-06,
      "loss": 0.0968,
      "step": 5295
    },
    {
      "epoch": 1.2169117647058822,
      "grad_norm": 1.136073350906372,
      "learning_rate": 6.606808510638298e-06,
      "loss": 0.0884,
      "step": 5296
    },
    {
      "epoch": 1.217141544117647,
      "grad_norm": 1.5192781686782837,
      "learning_rate": 6.605957446808511e-06,
      "loss": 0.1332,
      "step": 5297
    },
    {
      "epoch": 1.2173713235294117,
      "grad_norm": 1.498536229133606,
      "learning_rate": 6.605106382978725e-06,
      "loss": 0.1179,
      "step": 5298
    },
    {
      "epoch": 1.2176011029411764,
      "grad_norm": 1.340316653251648,
      "learning_rate": 6.604255319148937e-06,
      "loss": 0.0883,
      "step": 5299
    },
    {
      "epoch": 1.2178308823529411,
      "grad_norm": 1.1128346920013428,
      "learning_rate": 6.603404255319149e-06,
      "loss": 0.0884,
      "step": 5300
    },
    {
      "epoch": 1.2180606617647058,
      "grad_norm": 1.1567723751068115,
      "learning_rate": 6.6025531914893625e-06,
      "loss": 0.0829,
      "step": 5301
    },
    {
      "epoch": 1.2182904411764706,
      "grad_norm": 1.933868646621704,
      "learning_rate": 6.601702127659575e-06,
      "loss": 0.0783,
      "step": 5302
    },
    {
      "epoch": 1.2185202205882353,
      "grad_norm": 1.3496034145355225,
      "learning_rate": 6.600851063829787e-06,
      "loss": 0.0672,
      "step": 5303
    },
    {
      "epoch": 1.21875,
      "grad_norm": 1.116144061088562,
      "learning_rate": 6.600000000000001e-06,
      "loss": 0.0851,
      "step": 5304
    },
    {
      "epoch": 1.2189797794117647,
      "grad_norm": 1.2823556661605835,
      "learning_rate": 6.5991489361702135e-06,
      "loss": 0.0634,
      "step": 5305
    },
    {
      "epoch": 1.2192095588235294,
      "grad_norm": 1.1550182104110718,
      "learning_rate": 6.598297872340426e-06,
      "loss": 0.0838,
      "step": 5306
    },
    {
      "epoch": 1.2194393382352942,
      "grad_norm": 0.931761622428894,
      "learning_rate": 6.597446808510639e-06,
      "loss": 0.0597,
      "step": 5307
    },
    {
      "epoch": 1.2196691176470589,
      "grad_norm": 1.4070154428482056,
      "learning_rate": 6.596595744680851e-06,
      "loss": 0.0854,
      "step": 5308
    },
    {
      "epoch": 1.2198988970588236,
      "grad_norm": 0.9730921387672424,
      "learning_rate": 6.595744680851064e-06,
      "loss": 0.0586,
      "step": 5309
    },
    {
      "epoch": 1.2201286764705883,
      "grad_norm": 1.0260415077209473,
      "learning_rate": 6.594893617021278e-06,
      "loss": 0.0714,
      "step": 5310
    },
    {
      "epoch": 1.220358455882353,
      "grad_norm": 0.8709933757781982,
      "learning_rate": 6.59404255319149e-06,
      "loss": 0.0771,
      "step": 5311
    },
    {
      "epoch": 1.2205882352941178,
      "grad_norm": 1.332763671875,
      "learning_rate": 6.593191489361702e-06,
      "loss": 0.1058,
      "step": 5312
    },
    {
      "epoch": 1.2208180147058822,
      "grad_norm": 1.4353978633880615,
      "learning_rate": 6.5923404255319155e-06,
      "loss": 0.1,
      "step": 5313
    },
    {
      "epoch": 1.221047794117647,
      "grad_norm": 0.9050174355506897,
      "learning_rate": 6.591489361702128e-06,
      "loss": 0.0798,
      "step": 5314
    },
    {
      "epoch": 1.2212775735294117,
      "grad_norm": 1.0912245512008667,
      "learning_rate": 6.59063829787234e-06,
      "loss": 0.0749,
      "step": 5315
    },
    {
      "epoch": 1.2215073529411764,
      "grad_norm": 1.314819574356079,
      "learning_rate": 6.589787234042554e-06,
      "loss": 0.0927,
      "step": 5316
    },
    {
      "epoch": 1.2217371323529411,
      "grad_norm": 1.102494478225708,
      "learning_rate": 6.5889361702127665e-06,
      "loss": 0.0935,
      "step": 5317
    },
    {
      "epoch": 1.2219669117647058,
      "grad_norm": 0.9930506944656372,
      "learning_rate": 6.588085106382979e-06,
      "loss": 0.077,
      "step": 5318
    },
    {
      "epoch": 1.2221966911764706,
      "grad_norm": 0.9501539468765259,
      "learning_rate": 6.587234042553192e-06,
      "loss": 0.069,
      "step": 5319
    },
    {
      "epoch": 1.2224264705882353,
      "grad_norm": 1.0841573476791382,
      "learning_rate": 6.586382978723404e-06,
      "loss": 0.0627,
      "step": 5320
    },
    {
      "epoch": 1.22265625,
      "grad_norm": 1.008107304573059,
      "learning_rate": 6.585531914893618e-06,
      "loss": 0.0797,
      "step": 5321
    },
    {
      "epoch": 1.2228860294117647,
      "grad_norm": 1.1433091163635254,
      "learning_rate": 6.584680851063831e-06,
      "loss": 0.0749,
      "step": 5322
    },
    {
      "epoch": 1.2231158088235294,
      "grad_norm": 1.1263965368270874,
      "learning_rate": 6.583829787234043e-06,
      "loss": 0.0567,
      "step": 5323
    },
    {
      "epoch": 1.2233455882352942,
      "grad_norm": 1.3809185028076172,
      "learning_rate": 6.582978723404256e-06,
      "loss": 0.0897,
      "step": 5324
    },
    {
      "epoch": 1.2235753676470589,
      "grad_norm": 1.1511677503585815,
      "learning_rate": 6.5821276595744684e-06,
      "loss": 0.0773,
      "step": 5325
    },
    {
      "epoch": 1.2238051470588236,
      "grad_norm": 1.668549656867981,
      "learning_rate": 6.581276595744681e-06,
      "loss": 0.1423,
      "step": 5326
    },
    {
      "epoch": 1.2240349264705883,
      "grad_norm": 1.14443039894104,
      "learning_rate": 6.580425531914895e-06,
      "loss": 0.0997,
      "step": 5327
    },
    {
      "epoch": 1.224264705882353,
      "grad_norm": 1.0735970735549927,
      "learning_rate": 6.579574468085107e-06,
      "loss": 0.0697,
      "step": 5328
    },
    {
      "epoch": 1.2244944852941178,
      "grad_norm": 1.0606831312179565,
      "learning_rate": 6.5787234042553194e-06,
      "loss": 0.0703,
      "step": 5329
    },
    {
      "epoch": 1.2247242647058822,
      "grad_norm": 0.9243188500404358,
      "learning_rate": 6.577872340425533e-06,
      "loss": 0.0585,
      "step": 5330
    },
    {
      "epoch": 1.224954044117647,
      "grad_norm": 1.3472388982772827,
      "learning_rate": 6.577021276595745e-06,
      "loss": 0.0785,
      "step": 5331
    },
    {
      "epoch": 1.2251838235294117,
      "grad_norm": 1.6544580459594727,
      "learning_rate": 6.576170212765958e-06,
      "loss": 0.0915,
      "step": 5332
    },
    {
      "epoch": 1.2254136029411764,
      "grad_norm": 1.4546791315078735,
      "learning_rate": 6.575319148936171e-06,
      "loss": 0.0951,
      "step": 5333
    },
    {
      "epoch": 1.2256433823529411,
      "grad_norm": 1.0476576089859009,
      "learning_rate": 6.574468085106384e-06,
      "loss": 0.0747,
      "step": 5334
    },
    {
      "epoch": 1.2258731617647058,
      "grad_norm": 1.1566861867904663,
      "learning_rate": 6.573617021276596e-06,
      "loss": 0.0752,
      "step": 5335
    },
    {
      "epoch": 1.2261029411764706,
      "grad_norm": 1.118630290031433,
      "learning_rate": 6.572765957446809e-06,
      "loss": 0.0807,
      "step": 5336
    },
    {
      "epoch": 1.2263327205882353,
      "grad_norm": 1.2521061897277832,
      "learning_rate": 6.571914893617022e-06,
      "loss": 0.105,
      "step": 5337
    },
    {
      "epoch": 1.2265625,
      "grad_norm": 1.1905014514923096,
      "learning_rate": 6.571063829787235e-06,
      "loss": 0.0941,
      "step": 5338
    },
    {
      "epoch": 1.2267922794117647,
      "grad_norm": 1.4863163232803345,
      "learning_rate": 6.570212765957448e-06,
      "loss": 0.0912,
      "step": 5339
    },
    {
      "epoch": 1.2270220588235294,
      "grad_norm": 1.2555700540542603,
      "learning_rate": 6.56936170212766e-06,
      "loss": 0.1086,
      "step": 5340
    },
    {
      "epoch": 1.2272518382352942,
      "grad_norm": 1.6929738521575928,
      "learning_rate": 6.568510638297872e-06,
      "loss": 0.0982,
      "step": 5341
    },
    {
      "epoch": 1.2274816176470589,
      "grad_norm": 1.1327069997787476,
      "learning_rate": 6.567659574468086e-06,
      "loss": 0.0779,
      "step": 5342
    },
    {
      "epoch": 1.2277113970588236,
      "grad_norm": 1.0520095825195312,
      "learning_rate": 6.566808510638299e-06,
      "loss": 0.0724,
      "step": 5343
    },
    {
      "epoch": 1.2279411764705883,
      "grad_norm": 1.2295770645141602,
      "learning_rate": 6.565957446808511e-06,
      "loss": 0.0748,
      "step": 5344
    },
    {
      "epoch": 1.228170955882353,
      "grad_norm": 1.1677024364471436,
      "learning_rate": 6.565106382978724e-06,
      "loss": 0.0653,
      "step": 5345
    },
    {
      "epoch": 1.2284007352941178,
      "grad_norm": 1.8045414686203003,
      "learning_rate": 6.5642553191489366e-06,
      "loss": 0.1255,
      "step": 5346
    },
    {
      "epoch": 1.2286305147058822,
      "grad_norm": 0.9427140951156616,
      "learning_rate": 6.563404255319149e-06,
      "loss": 0.0681,
      "step": 5347
    },
    {
      "epoch": 1.228860294117647,
      "grad_norm": 1.4676053524017334,
      "learning_rate": 6.562553191489363e-06,
      "loss": 0.1021,
      "step": 5348
    },
    {
      "epoch": 1.2290900735294117,
      "grad_norm": 1.1435344219207764,
      "learning_rate": 6.561702127659575e-06,
      "loss": 0.0835,
      "step": 5349
    },
    {
      "epoch": 1.2293198529411764,
      "grad_norm": 1.2042180299758911,
      "learning_rate": 6.5608510638297875e-06,
      "loss": 0.0747,
      "step": 5350
    },
    {
      "epoch": 1.2295496323529411,
      "grad_norm": 1.3546808958053589,
      "learning_rate": 6.560000000000001e-06,
      "loss": 0.1266,
      "step": 5351
    },
    {
      "epoch": 1.2297794117647058,
      "grad_norm": 1.5029308795928955,
      "learning_rate": 6.559148936170213e-06,
      "loss": 0.0642,
      "step": 5352
    },
    {
      "epoch": 1.2300091911764706,
      "grad_norm": 1.3712565898895264,
      "learning_rate": 6.558297872340425e-06,
      "loss": 0.1072,
      "step": 5353
    },
    {
      "epoch": 1.2302389705882353,
      "grad_norm": 1.7181187868118286,
      "learning_rate": 6.557446808510639e-06,
      "loss": 0.0803,
      "step": 5354
    },
    {
      "epoch": 1.23046875,
      "grad_norm": 1.385624885559082,
      "learning_rate": 6.556595744680852e-06,
      "loss": 0.1054,
      "step": 5355
    },
    {
      "epoch": 1.2306985294117647,
      "grad_norm": 1.7307770252227783,
      "learning_rate": 6.555744680851064e-06,
      "loss": 0.1554,
      "step": 5356
    },
    {
      "epoch": 1.2309283088235294,
      "grad_norm": 1.1919814348220825,
      "learning_rate": 6.554893617021277e-06,
      "loss": 0.0933,
      "step": 5357
    },
    {
      "epoch": 1.2311580882352942,
      "grad_norm": 1.0677787065505981,
      "learning_rate": 6.5540425531914895e-06,
      "loss": 0.0744,
      "step": 5358
    },
    {
      "epoch": 1.2313878676470589,
      "grad_norm": 1.399529218673706,
      "learning_rate": 6.553191489361702e-06,
      "loss": 0.0966,
      "step": 5359
    },
    {
      "epoch": 1.2316176470588236,
      "grad_norm": 1.202650547027588,
      "learning_rate": 6.552340425531916e-06,
      "loss": 0.0723,
      "step": 5360
    },
    {
      "epoch": 1.2318474264705883,
      "grad_norm": 1.1870410442352295,
      "learning_rate": 6.551489361702128e-06,
      "loss": 0.0841,
      "step": 5361
    },
    {
      "epoch": 1.232077205882353,
      "grad_norm": 1.5305591821670532,
      "learning_rate": 6.550638297872341e-06,
      "loss": 0.0864,
      "step": 5362
    },
    {
      "epoch": 1.2323069852941178,
      "grad_norm": 1.0721548795700073,
      "learning_rate": 6.549787234042554e-06,
      "loss": 0.0758,
      "step": 5363
    },
    {
      "epoch": 1.2325367647058822,
      "grad_norm": 1.4227912425994873,
      "learning_rate": 6.548936170212766e-06,
      "loss": 0.0807,
      "step": 5364
    },
    {
      "epoch": 1.232766544117647,
      "grad_norm": 1.4045206308364868,
      "learning_rate": 6.54808510638298e-06,
      "loss": 0.1054,
      "step": 5365
    },
    {
      "epoch": 1.2329963235294117,
      "grad_norm": 1.0333811044692993,
      "learning_rate": 6.547234042553192e-06,
      "loss": 0.0903,
      "step": 5366
    },
    {
      "epoch": 1.2332261029411764,
      "grad_norm": 1.2707197666168213,
      "learning_rate": 6.546382978723405e-06,
      "loss": 0.089,
      "step": 5367
    },
    {
      "epoch": 1.2334558823529411,
      "grad_norm": 1.0194451808929443,
      "learning_rate": 6.545531914893618e-06,
      "loss": 0.0694,
      "step": 5368
    },
    {
      "epoch": 1.2336856617647058,
      "grad_norm": 1.2984405755996704,
      "learning_rate": 6.54468085106383e-06,
      "loss": 0.104,
      "step": 5369
    },
    {
      "epoch": 1.2339154411764706,
      "grad_norm": 1.2465479373931885,
      "learning_rate": 6.5438297872340425e-06,
      "loss": 0.0822,
      "step": 5370
    },
    {
      "epoch": 1.2341452205882353,
      "grad_norm": 1.2278450727462769,
      "learning_rate": 6.5429787234042565e-06,
      "loss": 0.119,
      "step": 5371
    },
    {
      "epoch": 1.234375,
      "grad_norm": 1.0652782917022705,
      "learning_rate": 6.542127659574469e-06,
      "loss": 0.1,
      "step": 5372
    },
    {
      "epoch": 1.2346047794117647,
      "grad_norm": 1.4559266567230225,
      "learning_rate": 6.541276595744681e-06,
      "loss": 0.1065,
      "step": 5373
    },
    {
      "epoch": 1.2348345588235294,
      "grad_norm": 1.0305595397949219,
      "learning_rate": 6.540425531914894e-06,
      "loss": 0.0905,
      "step": 5374
    },
    {
      "epoch": 1.2350643382352942,
      "grad_norm": 1.3215932846069336,
      "learning_rate": 6.539574468085107e-06,
      "loss": 0.1096,
      "step": 5375
    },
    {
      "epoch": 1.2352941176470589,
      "grad_norm": 1.2953734397888184,
      "learning_rate": 6.538723404255319e-06,
      "loss": 0.0782,
      "step": 5376
    },
    {
      "epoch": 1.2355238970588236,
      "grad_norm": 1.107782244682312,
      "learning_rate": 6.537872340425533e-06,
      "loss": 0.1001,
      "step": 5377
    },
    {
      "epoch": 1.2357536764705883,
      "grad_norm": 1.0263550281524658,
      "learning_rate": 6.537021276595745e-06,
      "loss": 0.0719,
      "step": 5378
    },
    {
      "epoch": 1.235983455882353,
      "grad_norm": 1.3377548456192017,
      "learning_rate": 6.536170212765958e-06,
      "loss": 0.098,
      "step": 5379
    },
    {
      "epoch": 1.2362132352941178,
      "grad_norm": 1.2152420282363892,
      "learning_rate": 6.535319148936171e-06,
      "loss": 0.0707,
      "step": 5380
    },
    {
      "epoch": 1.2364430147058822,
      "grad_norm": 1.1083089113235474,
      "learning_rate": 6.534468085106383e-06,
      "loss": 0.0546,
      "step": 5381
    },
    {
      "epoch": 1.236672794117647,
      "grad_norm": 1.028734803199768,
      "learning_rate": 6.533617021276596e-06,
      "loss": 0.0667,
      "step": 5382
    },
    {
      "epoch": 1.2369025735294117,
      "grad_norm": 1.3499234914779663,
      "learning_rate": 6.5327659574468095e-06,
      "loss": 0.1142,
      "step": 5383
    },
    {
      "epoch": 1.2371323529411764,
      "grad_norm": 1.2347732782363892,
      "learning_rate": 6.531914893617022e-06,
      "loss": 0.0895,
      "step": 5384
    },
    {
      "epoch": 1.2373621323529411,
      "grad_norm": 1.0986303091049194,
      "learning_rate": 6.531063829787234e-06,
      "loss": 0.0824,
      "step": 5385
    },
    {
      "epoch": 1.2375919117647058,
      "grad_norm": 1.0203996896743774,
      "learning_rate": 6.530212765957447e-06,
      "loss": 0.0733,
      "step": 5386
    },
    {
      "epoch": 1.2378216911764706,
      "grad_norm": 1.4856687784194946,
      "learning_rate": 6.5293617021276605e-06,
      "loss": 0.102,
      "step": 5387
    },
    {
      "epoch": 1.2380514705882353,
      "grad_norm": 1.2471851110458374,
      "learning_rate": 6.528510638297873e-06,
      "loss": 0.0656,
      "step": 5388
    },
    {
      "epoch": 1.23828125,
      "grad_norm": 1.3158875703811646,
      "learning_rate": 6.527659574468086e-06,
      "loss": 0.0676,
      "step": 5389
    },
    {
      "epoch": 1.2385110294117647,
      "grad_norm": 1.2852123975753784,
      "learning_rate": 6.526808510638298e-06,
      "loss": 0.07,
      "step": 5390
    },
    {
      "epoch": 1.2387408088235294,
      "grad_norm": 1.0299866199493408,
      "learning_rate": 6.525957446808511e-06,
      "loss": 0.0775,
      "step": 5391
    },
    {
      "epoch": 1.2389705882352942,
      "grad_norm": 1.0745820999145508,
      "learning_rate": 6.525106382978725e-06,
      "loss": 0.065,
      "step": 5392
    },
    {
      "epoch": 1.2392003676470589,
      "grad_norm": 1.3209335803985596,
      "learning_rate": 6.524255319148937e-06,
      "loss": 0.0738,
      "step": 5393
    },
    {
      "epoch": 1.2394301470588236,
      "grad_norm": 1.3390089273452759,
      "learning_rate": 6.523404255319149e-06,
      "loss": 0.0823,
      "step": 5394
    },
    {
      "epoch": 1.2396599264705883,
      "grad_norm": 1.0881537199020386,
      "learning_rate": 6.5225531914893624e-06,
      "loss": 0.0788,
      "step": 5395
    },
    {
      "epoch": 1.239889705882353,
      "grad_norm": 1.6815613508224487,
      "learning_rate": 6.521702127659575e-06,
      "loss": 0.0928,
      "step": 5396
    },
    {
      "epoch": 1.2401194852941178,
      "grad_norm": 1.1702314615249634,
      "learning_rate": 6.520851063829787e-06,
      "loss": 0.0852,
      "step": 5397
    },
    {
      "epoch": 1.2403492647058822,
      "grad_norm": 1.9636036157608032,
      "learning_rate": 6.520000000000001e-06,
      "loss": 0.079,
      "step": 5398
    },
    {
      "epoch": 1.240579044117647,
      "grad_norm": 0.9136340618133545,
      "learning_rate": 6.5191489361702134e-06,
      "loss": 0.064,
      "step": 5399
    },
    {
      "epoch": 1.2408088235294117,
      "grad_norm": 1.120736837387085,
      "learning_rate": 6.518297872340426e-06,
      "loss": 0.0886,
      "step": 5400
    },
    {
      "epoch": 1.2410386029411764,
      "grad_norm": 1.0566396713256836,
      "learning_rate": 6.517446808510639e-06,
      "loss": 0.0729,
      "step": 5401
    },
    {
      "epoch": 1.2412683823529411,
      "grad_norm": 1.3390027284622192,
      "learning_rate": 6.516595744680851e-06,
      "loss": 0.1076,
      "step": 5402
    },
    {
      "epoch": 1.2414981617647058,
      "grad_norm": 1.043947696685791,
      "learning_rate": 6.5157446808510636e-06,
      "loss": 0.0654,
      "step": 5403
    },
    {
      "epoch": 1.2417279411764706,
      "grad_norm": 1.0932775735855103,
      "learning_rate": 6.514893617021278e-06,
      "loss": 0.0953,
      "step": 5404
    },
    {
      "epoch": 1.2419577205882353,
      "grad_norm": 1.3519026041030884,
      "learning_rate": 6.51404255319149e-06,
      "loss": 0.0664,
      "step": 5405
    },
    {
      "epoch": 1.2421875,
      "grad_norm": 0.9754849076271057,
      "learning_rate": 6.513191489361703e-06,
      "loss": 0.0835,
      "step": 5406
    },
    {
      "epoch": 1.2424172794117647,
      "grad_norm": 1.502320408821106,
      "learning_rate": 6.512340425531915e-06,
      "loss": 0.0996,
      "step": 5407
    },
    {
      "epoch": 1.2426470588235294,
      "grad_norm": 1.6187846660614014,
      "learning_rate": 6.511489361702128e-06,
      "loss": 0.1374,
      "step": 5408
    },
    {
      "epoch": 1.2428768382352942,
      "grad_norm": 1.2716946601867676,
      "learning_rate": 6.510638297872342e-06,
      "loss": 0.0656,
      "step": 5409
    },
    {
      "epoch": 1.2431066176470589,
      "grad_norm": 1.232189655303955,
      "learning_rate": 6.509787234042554e-06,
      "loss": 0.1055,
      "step": 5410
    },
    {
      "epoch": 1.2433363970588236,
      "grad_norm": 1.639888048171997,
      "learning_rate": 6.508936170212766e-06,
      "loss": 0.1061,
      "step": 5411
    },
    {
      "epoch": 1.2435661764705883,
      "grad_norm": 1.282589316368103,
      "learning_rate": 6.5080851063829796e-06,
      "loss": 0.1038,
      "step": 5412
    },
    {
      "epoch": 1.243795955882353,
      "grad_norm": 1.4913500547409058,
      "learning_rate": 6.507234042553192e-06,
      "loss": 0.1075,
      "step": 5413
    },
    {
      "epoch": 1.2440257352941178,
      "grad_norm": 1.2189346551895142,
      "learning_rate": 6.506382978723404e-06,
      "loss": 0.1053,
      "step": 5414
    },
    {
      "epoch": 1.2442555147058822,
      "grad_norm": 1.579756736755371,
      "learning_rate": 6.505531914893618e-06,
      "loss": 0.1031,
      "step": 5415
    },
    {
      "epoch": 1.244485294117647,
      "grad_norm": 1.1552798748016357,
      "learning_rate": 6.5046808510638305e-06,
      "loss": 0.1358,
      "step": 5416
    },
    {
      "epoch": 1.2447150735294117,
      "grad_norm": 1.5289604663848877,
      "learning_rate": 6.503829787234043e-06,
      "loss": 0.1302,
      "step": 5417
    },
    {
      "epoch": 1.2449448529411764,
      "grad_norm": 1.3150198459625244,
      "learning_rate": 6.502978723404256e-06,
      "loss": 0.078,
      "step": 5418
    },
    {
      "epoch": 1.2451746323529411,
      "grad_norm": 1.0191946029663086,
      "learning_rate": 6.502127659574468e-06,
      "loss": 0.0699,
      "step": 5419
    },
    {
      "epoch": 1.2454044117647058,
      "grad_norm": 1.4171149730682373,
      "learning_rate": 6.501276595744681e-06,
      "loss": 0.0839,
      "step": 5420
    },
    {
      "epoch": 1.2456341911764706,
      "grad_norm": 1.5197103023529053,
      "learning_rate": 6.500425531914895e-06,
      "loss": 0.0892,
      "step": 5421
    },
    {
      "epoch": 1.2458639705882353,
      "grad_norm": 1.3600876331329346,
      "learning_rate": 6.499574468085107e-06,
      "loss": 0.0885,
      "step": 5422
    },
    {
      "epoch": 1.24609375,
      "grad_norm": 1.0628900527954102,
      "learning_rate": 6.498723404255319e-06,
      "loss": 0.0872,
      "step": 5423
    },
    {
      "epoch": 1.2463235294117647,
      "grad_norm": 0.9900379180908203,
      "learning_rate": 6.4978723404255325e-06,
      "loss": 0.0798,
      "step": 5424
    },
    {
      "epoch": 1.2465533088235294,
      "grad_norm": 0.9420143961906433,
      "learning_rate": 6.497021276595745e-06,
      "loss": 0.074,
      "step": 5425
    },
    {
      "epoch": 1.2467830882352942,
      "grad_norm": 1.1524990797042847,
      "learning_rate": 6.496170212765958e-06,
      "loss": 0.0846,
      "step": 5426
    },
    {
      "epoch": 1.2470128676470589,
      "grad_norm": 1.0501126050949097,
      "learning_rate": 6.495319148936171e-06,
      "loss": 0.0755,
      "step": 5427
    },
    {
      "epoch": 1.2472426470588236,
      "grad_norm": 1.2206908464431763,
      "learning_rate": 6.4944680851063835e-06,
      "loss": 0.0948,
      "step": 5428
    },
    {
      "epoch": 1.2474724264705883,
      "grad_norm": 1.332603931427002,
      "learning_rate": 6.493617021276596e-06,
      "loss": 0.0854,
      "step": 5429
    },
    {
      "epoch": 1.247702205882353,
      "grad_norm": 1.2057669162750244,
      "learning_rate": 6.492765957446809e-06,
      "loss": 0.1209,
      "step": 5430
    },
    {
      "epoch": 1.2479319852941178,
      "grad_norm": 1.4593477249145508,
      "learning_rate": 6.491914893617022e-06,
      "loss": 0.0666,
      "step": 5431
    },
    {
      "epoch": 1.2481617647058822,
      "grad_norm": 0.9142034649848938,
      "learning_rate": 6.4910638297872345e-06,
      "loss": 0.0617,
      "step": 5432
    },
    {
      "epoch": 1.248391544117647,
      "grad_norm": 1.343846082687378,
      "learning_rate": 6.490212765957448e-06,
      "loss": 0.0877,
      "step": 5433
    },
    {
      "epoch": 1.2486213235294117,
      "grad_norm": 1.476820707321167,
      "learning_rate": 6.48936170212766e-06,
      "loss": 0.0999,
      "step": 5434
    },
    {
      "epoch": 1.2488511029411764,
      "grad_norm": 1.1932079792022705,
      "learning_rate": 6.488510638297872e-06,
      "loss": 0.0788,
      "step": 5435
    },
    {
      "epoch": 1.2490808823529411,
      "grad_norm": 0.893606424331665,
      "learning_rate": 6.487659574468086e-06,
      "loss": 0.0542,
      "step": 5436
    },
    {
      "epoch": 1.2493106617647058,
      "grad_norm": 0.9062147736549377,
      "learning_rate": 6.486808510638299e-06,
      "loss": 0.067,
      "step": 5437
    },
    {
      "epoch": 1.2495404411764706,
      "grad_norm": 0.8576361536979675,
      "learning_rate": 6.485957446808511e-06,
      "loss": 0.0743,
      "step": 5438
    },
    {
      "epoch": 1.2497702205882353,
      "grad_norm": 1.0894200801849365,
      "learning_rate": 6.485106382978724e-06,
      "loss": 0.0763,
      "step": 5439
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.1137135028839111,
      "learning_rate": 6.4842553191489365e-06,
      "loss": 0.0666,
      "step": 5440
    },
    {
      "epoch": 1.2502297794117647,
      "grad_norm": 1.084660291671753,
      "learning_rate": 6.483404255319149e-06,
      "loss": 0.0791,
      "step": 5441
    },
    {
      "epoch": 1.2504595588235294,
      "grad_norm": 1.2287482023239136,
      "learning_rate": 6.482553191489363e-06,
      "loss": 0.1228,
      "step": 5442
    },
    {
      "epoch": 1.2506893382352942,
      "grad_norm": 0.9346674680709839,
      "learning_rate": 6.481702127659575e-06,
      "loss": 0.0547,
      "step": 5443
    },
    {
      "epoch": 1.2509191176470589,
      "grad_norm": 1.1723649501800537,
      "learning_rate": 6.4808510638297875e-06,
      "loss": 0.1135,
      "step": 5444
    },
    {
      "epoch": 1.2511488970588236,
      "grad_norm": 1.4594776630401611,
      "learning_rate": 6.480000000000001e-06,
      "loss": 0.0663,
      "step": 5445
    },
    {
      "epoch": 1.2513786764705883,
      "grad_norm": 1.587985634803772,
      "learning_rate": 6.479148936170213e-06,
      "loss": 0.094,
      "step": 5446
    },
    {
      "epoch": 1.2516084558823528,
      "grad_norm": 1.2340725660324097,
      "learning_rate": 6.478297872340425e-06,
      "loss": 0.079,
      "step": 5447
    },
    {
      "epoch": 1.2518382352941178,
      "grad_norm": 1.2050122022628784,
      "learning_rate": 6.477446808510639e-06,
      "loss": 0.0776,
      "step": 5448
    },
    {
      "epoch": 1.2520680147058822,
      "grad_norm": 1.0353949069976807,
      "learning_rate": 6.476595744680852e-06,
      "loss": 0.0701,
      "step": 5449
    },
    {
      "epoch": 1.2522977941176472,
      "grad_norm": 1.4340269565582275,
      "learning_rate": 6.475744680851065e-06,
      "loss": 0.1152,
      "step": 5450
    },
    {
      "epoch": 1.2525275735294117,
      "grad_norm": 1.7114287614822388,
      "learning_rate": 6.474893617021277e-06,
      "loss": 0.0808,
      "step": 5451
    },
    {
      "epoch": 1.2527573529411764,
      "grad_norm": 1.4404513835906982,
      "learning_rate": 6.4740425531914894e-06,
      "loss": 0.1104,
      "step": 5452
    },
    {
      "epoch": 1.2529871323529411,
      "grad_norm": 1.5624486207962036,
      "learning_rate": 6.4731914893617035e-06,
      "loss": 0.1006,
      "step": 5453
    },
    {
      "epoch": 1.2532169117647058,
      "grad_norm": 1.1218290328979492,
      "learning_rate": 6.472340425531916e-06,
      "loss": 0.062,
      "step": 5454
    },
    {
      "epoch": 1.2534466911764706,
      "grad_norm": 1.1833128929138184,
      "learning_rate": 6.471489361702128e-06,
      "loss": 0.0804,
      "step": 5455
    },
    {
      "epoch": 1.2536764705882353,
      "grad_norm": 1.1298094987869263,
      "learning_rate": 6.470638297872341e-06,
      "loss": 0.0766,
      "step": 5456
    },
    {
      "epoch": 1.25390625,
      "grad_norm": 1.2493107318878174,
      "learning_rate": 6.469787234042554e-06,
      "loss": 0.085,
      "step": 5457
    },
    {
      "epoch": 1.2541360294117647,
      "grad_norm": 1.1335124969482422,
      "learning_rate": 6.468936170212766e-06,
      "loss": 0.0764,
      "step": 5458
    },
    {
      "epoch": 1.2543658088235294,
      "grad_norm": 1.0805878639221191,
      "learning_rate": 6.46808510638298e-06,
      "loss": 0.0905,
      "step": 5459
    },
    {
      "epoch": 1.2545955882352942,
      "grad_norm": 1.1020066738128662,
      "learning_rate": 6.467234042553192e-06,
      "loss": 0.0807,
      "step": 5460
    },
    {
      "epoch": 1.2548253676470589,
      "grad_norm": 1.3067225217819214,
      "learning_rate": 6.466382978723405e-06,
      "loss": 0.0806,
      "step": 5461
    },
    {
      "epoch": 1.2550551470588236,
      "grad_norm": 1.5876986980438232,
      "learning_rate": 6.465531914893618e-06,
      "loss": 0.1135,
      "step": 5462
    },
    {
      "epoch": 1.2552849264705883,
      "grad_norm": 1.1267991065979004,
      "learning_rate": 6.46468085106383e-06,
      "loss": 0.0642,
      "step": 5463
    },
    {
      "epoch": 1.2555147058823528,
      "grad_norm": 1.3728904724121094,
      "learning_rate": 6.463829787234042e-06,
      "loss": 0.0917,
      "step": 5464
    },
    {
      "epoch": 1.2557444852941178,
      "grad_norm": 1.0117416381835938,
      "learning_rate": 6.4629787234042564e-06,
      "loss": 0.0709,
      "step": 5465
    },
    {
      "epoch": 1.2559742647058822,
      "grad_norm": 1.191938042640686,
      "learning_rate": 6.462127659574469e-06,
      "loss": 0.0705,
      "step": 5466
    },
    {
      "epoch": 1.2562040441176472,
      "grad_norm": 1.2268109321594238,
      "learning_rate": 6.461276595744681e-06,
      "loss": 0.0708,
      "step": 5467
    },
    {
      "epoch": 1.2564338235294117,
      "grad_norm": 1.899037480354309,
      "learning_rate": 6.460425531914894e-06,
      "loss": 0.11,
      "step": 5468
    },
    {
      "epoch": 1.2566636029411764,
      "grad_norm": 1.2663227319717407,
      "learning_rate": 6.4595744680851066e-06,
      "loss": 0.0876,
      "step": 5469
    },
    {
      "epoch": 1.2568933823529411,
      "grad_norm": 1.2853901386260986,
      "learning_rate": 6.458723404255319e-06,
      "loss": 0.0843,
      "step": 5470
    },
    {
      "epoch": 1.2571231617647058,
      "grad_norm": 1.252504587173462,
      "learning_rate": 6.457872340425533e-06,
      "loss": 0.0745,
      "step": 5471
    },
    {
      "epoch": 1.2573529411764706,
      "grad_norm": 1.2003676891326904,
      "learning_rate": 6.457021276595745e-06,
      "loss": 0.0889,
      "step": 5472
    },
    {
      "epoch": 1.2575827205882353,
      "grad_norm": 1.3752048015594482,
      "learning_rate": 6.4561702127659576e-06,
      "loss": 0.0959,
      "step": 5473
    },
    {
      "epoch": 1.2578125,
      "grad_norm": 1.707180142402649,
      "learning_rate": 6.455319148936171e-06,
      "loss": 0.1062,
      "step": 5474
    },
    {
      "epoch": 1.2580422794117647,
      "grad_norm": 1.0478955507278442,
      "learning_rate": 6.454468085106383e-06,
      "loss": 0.0607,
      "step": 5475
    },
    {
      "epoch": 1.2582720588235294,
      "grad_norm": 1.1246532201766968,
      "learning_rate": 6.453617021276596e-06,
      "loss": 0.0719,
      "step": 5476
    },
    {
      "epoch": 1.2585018382352942,
      "grad_norm": 0.8770367503166199,
      "learning_rate": 6.452765957446809e-06,
      "loss": 0.0741,
      "step": 5477
    },
    {
      "epoch": 1.2587316176470589,
      "grad_norm": 1.2005000114440918,
      "learning_rate": 6.451914893617022e-06,
      "loss": 0.0597,
      "step": 5478
    },
    {
      "epoch": 1.2589613970588236,
      "grad_norm": 1.211693286895752,
      "learning_rate": 6.451063829787234e-06,
      "loss": 0.077,
      "step": 5479
    },
    {
      "epoch": 1.2591911764705883,
      "grad_norm": 1.22501540184021,
      "learning_rate": 6.450212765957447e-06,
      "loss": 0.0713,
      "step": 5480
    },
    {
      "epoch": 1.2594209558823528,
      "grad_norm": 1.318446397781372,
      "learning_rate": 6.44936170212766e-06,
      "loss": 0.0852,
      "step": 5481
    },
    {
      "epoch": 1.2596507352941178,
      "grad_norm": 1.1808762550354004,
      "learning_rate": 6.448510638297873e-06,
      "loss": 0.0819,
      "step": 5482
    },
    {
      "epoch": 1.2598805147058822,
      "grad_norm": 1.1235021352767944,
      "learning_rate": 6.447659574468086e-06,
      "loss": 0.0583,
      "step": 5483
    },
    {
      "epoch": 1.2601102941176472,
      "grad_norm": 1.236016035079956,
      "learning_rate": 6.446808510638298e-06,
      "loss": 0.0741,
      "step": 5484
    },
    {
      "epoch": 1.2603400735294117,
      "grad_norm": 1.2929022312164307,
      "learning_rate": 6.4459574468085105e-06,
      "loss": 0.0952,
      "step": 5485
    },
    {
      "epoch": 1.2605698529411764,
      "grad_norm": 1.2042584419250488,
      "learning_rate": 6.4451063829787245e-06,
      "loss": 0.0889,
      "step": 5486
    },
    {
      "epoch": 1.2607996323529411,
      "grad_norm": 1.3486422300338745,
      "learning_rate": 6.444255319148937e-06,
      "loss": 0.0783,
      "step": 5487
    },
    {
      "epoch": 1.2610294117647058,
      "grad_norm": 1.119490385055542,
      "learning_rate": 6.443404255319149e-06,
      "loss": 0.0662,
      "step": 5488
    },
    {
      "epoch": 1.2612591911764706,
      "grad_norm": 1.5997660160064697,
      "learning_rate": 6.442553191489362e-06,
      "loss": 0.0955,
      "step": 5489
    },
    {
      "epoch": 1.2614889705882353,
      "grad_norm": 1.1633981466293335,
      "learning_rate": 6.441702127659575e-06,
      "loss": 0.1123,
      "step": 5490
    },
    {
      "epoch": 1.26171875,
      "grad_norm": 1.3144447803497314,
      "learning_rate": 6.440851063829789e-06,
      "loss": 0.0625,
      "step": 5491
    },
    {
      "epoch": 1.2619485294117647,
      "grad_norm": 1.25630521774292,
      "learning_rate": 6.440000000000001e-06,
      "loss": 0.065,
      "step": 5492
    },
    {
      "epoch": 1.2621783088235294,
      "grad_norm": 1.2704764604568481,
      "learning_rate": 6.439148936170213e-06,
      "loss": 0.083,
      "step": 5493
    },
    {
      "epoch": 1.2624080882352942,
      "grad_norm": 1.3444077968597412,
      "learning_rate": 6.4382978723404265e-06,
      "loss": 0.0998,
      "step": 5494
    },
    {
      "epoch": 1.2626378676470589,
      "grad_norm": 1.3789114952087402,
      "learning_rate": 6.437446808510639e-06,
      "loss": 0.0949,
      "step": 5495
    },
    {
      "epoch": 1.2628676470588236,
      "grad_norm": 1.3454184532165527,
      "learning_rate": 6.436595744680851e-06,
      "loss": 0.0883,
      "step": 5496
    },
    {
      "epoch": 1.2630974264705883,
      "grad_norm": 1.295462727546692,
      "learning_rate": 6.435744680851065e-06,
      "loss": 0.124,
      "step": 5497
    },
    {
      "epoch": 1.2633272058823528,
      "grad_norm": 1.0063213109970093,
      "learning_rate": 6.4348936170212775e-06,
      "loss": 0.0998,
      "step": 5498
    },
    {
      "epoch": 1.2635569852941178,
      "grad_norm": 1.7096518278121948,
      "learning_rate": 6.43404255319149e-06,
      "loss": 0.1314,
      "step": 5499
    },
    {
      "epoch": 1.2637867647058822,
      "grad_norm": 1.1194080114364624,
      "learning_rate": 6.433191489361703e-06,
      "loss": 0.0934,
      "step": 5500
    },
    {
      "epoch": 1.2637867647058822,
      "eval_loss": 0.09030837565660477,
      "eval_runtime": 1968.9813,
      "eval_samples_per_second": 4.523,
      "eval_steps_per_second": 2.262,
      "step": 5500
    },
    {
      "epoch": 1.2640165441176472,
      "grad_norm": 1.1890679597854614,
      "learning_rate": 6.432340425531915e-06,
      "loss": 0.0963,
      "step": 5501
    },
    {
      "epoch": 1.2642463235294117,
      "grad_norm": 1.2451424598693848,
      "learning_rate": 6.431489361702128e-06,
      "loss": 0.061,
      "step": 5502
    },
    {
      "epoch": 1.2644761029411764,
      "grad_norm": 1.290480375289917,
      "learning_rate": 6.430638297872342e-06,
      "loss": 0.0849,
      "step": 5503
    },
    {
      "epoch": 1.2647058823529411,
      "grad_norm": 1.3101558685302734,
      "learning_rate": 6.429787234042554e-06,
      "loss": 0.0878,
      "step": 5504
    },
    {
      "epoch": 1.2649356617647058,
      "grad_norm": 1.3080135583877563,
      "learning_rate": 6.428936170212766e-06,
      "loss": 0.0829,
      "step": 5505
    },
    {
      "epoch": 1.2651654411764706,
      "grad_norm": 1.0269736051559448,
      "learning_rate": 6.4280851063829795e-06,
      "loss": 0.0603,
      "step": 5506
    },
    {
      "epoch": 1.2653952205882353,
      "grad_norm": 1.1887915134429932,
      "learning_rate": 6.427234042553192e-06,
      "loss": 0.0907,
      "step": 5507
    },
    {
      "epoch": 1.265625,
      "grad_norm": 1.5808167457580566,
      "learning_rate": 6.426382978723404e-06,
      "loss": 0.0777,
      "step": 5508
    },
    {
      "epoch": 1.2658547794117647,
      "grad_norm": 0.9452865719795227,
      "learning_rate": 6.425531914893618e-06,
      "loss": 0.0574,
      "step": 5509
    },
    {
      "epoch": 1.2660845588235294,
      "grad_norm": 1.2362775802612305,
      "learning_rate": 6.4246808510638305e-06,
      "loss": 0.0753,
      "step": 5510
    },
    {
      "epoch": 1.2663143382352942,
      "grad_norm": 1.5568947792053223,
      "learning_rate": 6.423829787234043e-06,
      "loss": 0.1186,
      "step": 5511
    },
    {
      "epoch": 1.2665441176470589,
      "grad_norm": 1.102571964263916,
      "learning_rate": 6.422978723404256e-06,
      "loss": 0.0738,
      "step": 5512
    },
    {
      "epoch": 1.2667738970588236,
      "grad_norm": 1.2211582660675049,
      "learning_rate": 6.422127659574468e-06,
      "loss": 0.0994,
      "step": 5513
    },
    {
      "epoch": 1.2670036764705883,
      "grad_norm": 1.183423399925232,
      "learning_rate": 6.421276595744681e-06,
      "loss": 0.0613,
      "step": 5514
    },
    {
      "epoch": 1.2672334558823528,
      "grad_norm": 1.5165698528289795,
      "learning_rate": 6.420425531914895e-06,
      "loss": 0.1024,
      "step": 5515
    },
    {
      "epoch": 1.2674632352941178,
      "grad_norm": 1.204164981842041,
      "learning_rate": 6.419574468085107e-06,
      "loss": 0.0801,
      "step": 5516
    },
    {
      "epoch": 1.2676930147058822,
      "grad_norm": 1.418377161026001,
      "learning_rate": 6.418723404255319e-06,
      "loss": 0.1052,
      "step": 5517
    },
    {
      "epoch": 1.2679227941176472,
      "grad_norm": 1.4294809103012085,
      "learning_rate": 6.4178723404255324e-06,
      "loss": 0.0835,
      "step": 5518
    },
    {
      "epoch": 1.2681525735294117,
      "grad_norm": 1.1984907388687134,
      "learning_rate": 6.417021276595745e-06,
      "loss": 0.1208,
      "step": 5519
    },
    {
      "epoch": 1.2683823529411764,
      "grad_norm": 1.2291016578674316,
      "learning_rate": 6.416170212765958e-06,
      "loss": 0.0514,
      "step": 5520
    },
    {
      "epoch": 1.2686121323529411,
      "grad_norm": 1.3673092126846313,
      "learning_rate": 6.415319148936171e-06,
      "loss": 0.0886,
      "step": 5521
    },
    {
      "epoch": 1.2688419117647058,
      "grad_norm": 1.070840835571289,
      "learning_rate": 6.4144680851063834e-06,
      "loss": 0.0548,
      "step": 5522
    },
    {
      "epoch": 1.2690716911764706,
      "grad_norm": 1.4538257122039795,
      "learning_rate": 6.413617021276596e-06,
      "loss": 0.0849,
      "step": 5523
    },
    {
      "epoch": 1.2693014705882353,
      "grad_norm": 1.013269305229187,
      "learning_rate": 6.412765957446809e-06,
      "loss": 0.0816,
      "step": 5524
    },
    {
      "epoch": 1.26953125,
      "grad_norm": 0.9333670735359192,
      "learning_rate": 6.411914893617022e-06,
      "loss": 0.0655,
      "step": 5525
    },
    {
      "epoch": 1.2697610294117647,
      "grad_norm": 1.0144929885864258,
      "learning_rate": 6.411063829787234e-06,
      "loss": 0.0718,
      "step": 5526
    },
    {
      "epoch": 1.2699908088235294,
      "grad_norm": 1.1052671670913696,
      "learning_rate": 6.410212765957448e-06,
      "loss": 0.0795,
      "step": 5527
    },
    {
      "epoch": 1.2702205882352942,
      "grad_norm": 1.3454337120056152,
      "learning_rate": 6.40936170212766e-06,
      "loss": 0.0883,
      "step": 5528
    },
    {
      "epoch": 1.2704503676470589,
      "grad_norm": 1.1256357431411743,
      "learning_rate": 6.408510638297872e-06,
      "loss": 0.0819,
      "step": 5529
    },
    {
      "epoch": 1.2706801470588236,
      "grad_norm": 1.2461763620376587,
      "learning_rate": 6.407659574468086e-06,
      "loss": 0.088,
      "step": 5530
    },
    {
      "epoch": 1.2709099264705883,
      "grad_norm": 1.0963718891143799,
      "learning_rate": 6.406808510638299e-06,
      "loss": 0.093,
      "step": 5531
    },
    {
      "epoch": 1.2711397058823528,
      "grad_norm": 0.9459642171859741,
      "learning_rate": 6.405957446808511e-06,
      "loss": 0.0642,
      "step": 5532
    },
    {
      "epoch": 1.2713694852941178,
      "grad_norm": 1.1725715398788452,
      "learning_rate": 6.405106382978724e-06,
      "loss": 0.0643,
      "step": 5533
    },
    {
      "epoch": 1.2715992647058822,
      "grad_norm": 1.2951629161834717,
      "learning_rate": 6.404255319148936e-06,
      "loss": 0.0947,
      "step": 5534
    },
    {
      "epoch": 1.2718290441176472,
      "grad_norm": 1.490479588508606,
      "learning_rate": 6.40340425531915e-06,
      "loss": 0.0958,
      "step": 5535
    },
    {
      "epoch": 1.2720588235294117,
      "grad_norm": 1.0959903001785278,
      "learning_rate": 6.402553191489363e-06,
      "loss": 0.0711,
      "step": 5536
    },
    {
      "epoch": 1.2722886029411764,
      "grad_norm": 1.2918719053268433,
      "learning_rate": 6.401702127659575e-06,
      "loss": 0.0749,
      "step": 5537
    },
    {
      "epoch": 1.2725183823529411,
      "grad_norm": 1.0431056022644043,
      "learning_rate": 6.400851063829788e-06,
      "loss": 0.0874,
      "step": 5538
    },
    {
      "epoch": 1.2727481617647058,
      "grad_norm": 0.8276352882385254,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.0564,
      "step": 5539
    },
    {
      "epoch": 1.2729779411764706,
      "grad_norm": 1.488080620765686,
      "learning_rate": 6.399148936170213e-06,
      "loss": 0.1093,
      "step": 5540
    },
    {
      "epoch": 1.2732077205882353,
      "grad_norm": 1.3177133798599243,
      "learning_rate": 6.398297872340427e-06,
      "loss": 0.067,
      "step": 5541
    },
    {
      "epoch": 1.2734375,
      "grad_norm": 1.1941769123077393,
      "learning_rate": 6.397446808510639e-06,
      "loss": 0.067,
      "step": 5542
    },
    {
      "epoch": 1.2736672794117647,
      "grad_norm": 1.3961418867111206,
      "learning_rate": 6.3965957446808515e-06,
      "loss": 0.1117,
      "step": 5543
    },
    {
      "epoch": 1.2738970588235294,
      "grad_norm": 1.1283663511276245,
      "learning_rate": 6.395744680851065e-06,
      "loss": 0.0691,
      "step": 5544
    },
    {
      "epoch": 1.2741268382352942,
      "grad_norm": 1.5485177040100098,
      "learning_rate": 6.394893617021277e-06,
      "loss": 0.0997,
      "step": 5545
    },
    {
      "epoch": 1.2743566176470589,
      "grad_norm": 1.4369556903839111,
      "learning_rate": 6.394042553191489e-06,
      "loss": 0.1007,
      "step": 5546
    },
    {
      "epoch": 1.2745863970588236,
      "grad_norm": 1.2755217552185059,
      "learning_rate": 6.393191489361703e-06,
      "loss": 0.0781,
      "step": 5547
    },
    {
      "epoch": 1.2748161764705883,
      "grad_norm": 1.1381596326828003,
      "learning_rate": 6.392340425531916e-06,
      "loss": 0.1007,
      "step": 5548
    },
    {
      "epoch": 1.2750459558823528,
      "grad_norm": 1.0043426752090454,
      "learning_rate": 6.391489361702128e-06,
      "loss": 0.0742,
      "step": 5549
    },
    {
      "epoch": 1.2752757352941178,
      "grad_norm": 1.0582683086395264,
      "learning_rate": 6.390638297872341e-06,
      "loss": 0.0673,
      "step": 5550
    },
    {
      "epoch": 1.2755055147058822,
      "grad_norm": 1.3154231309890747,
      "learning_rate": 6.3897872340425535e-06,
      "loss": 0.0711,
      "step": 5551
    },
    {
      "epoch": 1.2757352941176472,
      "grad_norm": 1.2520573139190674,
      "learning_rate": 6.388936170212766e-06,
      "loss": 0.0706,
      "step": 5552
    },
    {
      "epoch": 1.2759650735294117,
      "grad_norm": 1.2867661714553833,
      "learning_rate": 6.38808510638298e-06,
      "loss": 0.0886,
      "step": 5553
    },
    {
      "epoch": 1.2761948529411764,
      "grad_norm": 0.9721273183822632,
      "learning_rate": 6.387234042553192e-06,
      "loss": 0.0763,
      "step": 5554
    },
    {
      "epoch": 1.2764246323529411,
      "grad_norm": 0.9076160192489624,
      "learning_rate": 6.3863829787234045e-06,
      "loss": 0.0639,
      "step": 5555
    },
    {
      "epoch": 1.2766544117647058,
      "grad_norm": 1.485206127166748,
      "learning_rate": 6.385531914893618e-06,
      "loss": 0.078,
      "step": 5556
    },
    {
      "epoch": 1.2768841911764706,
      "grad_norm": 0.9355060458183289,
      "learning_rate": 6.38468085106383e-06,
      "loss": 0.0703,
      "step": 5557
    },
    {
      "epoch": 1.2771139705882353,
      "grad_norm": 1.2808139324188232,
      "learning_rate": 6.383829787234042e-06,
      "loss": 0.1043,
      "step": 5558
    },
    {
      "epoch": 1.27734375,
      "grad_norm": 1.212754726409912,
      "learning_rate": 6.382978723404256e-06,
      "loss": 0.0803,
      "step": 5559
    },
    {
      "epoch": 1.2775735294117647,
      "grad_norm": 0.8322826027870178,
      "learning_rate": 6.382127659574469e-06,
      "loss": 0.0562,
      "step": 5560
    },
    {
      "epoch": 1.2778033088235294,
      "grad_norm": 1.4574968814849854,
      "learning_rate": 6.381276595744681e-06,
      "loss": 0.0824,
      "step": 5561
    },
    {
      "epoch": 1.2780330882352942,
      "grad_norm": 1.2078934907913208,
      "learning_rate": 6.380425531914894e-06,
      "loss": 0.1236,
      "step": 5562
    },
    {
      "epoch": 1.2782628676470589,
      "grad_norm": 1.0314942598342896,
      "learning_rate": 6.3795744680851065e-06,
      "loss": 0.0603,
      "step": 5563
    },
    {
      "epoch": 1.2784926470588236,
      "grad_norm": 0.9324180483818054,
      "learning_rate": 6.378723404255319e-06,
      "loss": 0.0836,
      "step": 5564
    },
    {
      "epoch": 1.2787224264705883,
      "grad_norm": 1.359548807144165,
      "learning_rate": 6.377872340425533e-06,
      "loss": 0.0958,
      "step": 5565
    },
    {
      "epoch": 1.2789522058823528,
      "grad_norm": 1.3049571514129639,
      "learning_rate": 6.377021276595745e-06,
      "loss": 0.069,
      "step": 5566
    },
    {
      "epoch": 1.2791819852941178,
      "grad_norm": 1.377092719078064,
      "learning_rate": 6.3761702127659575e-06,
      "loss": 0.0773,
      "step": 5567
    },
    {
      "epoch": 1.2794117647058822,
      "grad_norm": 0.8114187121391296,
      "learning_rate": 6.375319148936171e-06,
      "loss": 0.059,
      "step": 5568
    },
    {
      "epoch": 1.2796415441176472,
      "grad_norm": 1.2563570737838745,
      "learning_rate": 6.374468085106383e-06,
      "loss": 0.079,
      "step": 5569
    },
    {
      "epoch": 1.2798713235294117,
      "grad_norm": 1.4244657754898071,
      "learning_rate": 6.373617021276596e-06,
      "loss": 0.1089,
      "step": 5570
    },
    {
      "epoch": 1.2801011029411764,
      "grad_norm": 1.1343356370925903,
      "learning_rate": 6.372765957446809e-06,
      "loss": 0.0969,
      "step": 5571
    },
    {
      "epoch": 1.2803308823529411,
      "grad_norm": 1.083164930343628,
      "learning_rate": 6.371914893617022e-06,
      "loss": 0.0793,
      "step": 5572
    },
    {
      "epoch": 1.2805606617647058,
      "grad_norm": 0.9507973194122314,
      "learning_rate": 6.371063829787234e-06,
      "loss": 0.0891,
      "step": 5573
    },
    {
      "epoch": 1.2807904411764706,
      "grad_norm": 1.3516640663146973,
      "learning_rate": 6.370212765957447e-06,
      "loss": 0.0973,
      "step": 5574
    },
    {
      "epoch": 1.2810202205882353,
      "grad_norm": 1.146768569946289,
      "learning_rate": 6.36936170212766e-06,
      "loss": 0.0857,
      "step": 5575
    },
    {
      "epoch": 1.28125,
      "grad_norm": 0.7665818333625793,
      "learning_rate": 6.3685106382978735e-06,
      "loss": 0.0443,
      "step": 5576
    },
    {
      "epoch": 1.2814797794117647,
      "grad_norm": 1.3114787340164185,
      "learning_rate": 6.367659574468086e-06,
      "loss": 0.0852,
      "step": 5577
    },
    {
      "epoch": 1.2817095588235294,
      "grad_norm": 0.9743916988372803,
      "learning_rate": 6.366808510638298e-06,
      "loss": 0.0602,
      "step": 5578
    },
    {
      "epoch": 1.2819393382352942,
      "grad_norm": 1.7765716314315796,
      "learning_rate": 6.365957446808511e-06,
      "loss": 0.1025,
      "step": 5579
    },
    {
      "epoch": 1.2821691176470589,
      "grad_norm": 1.3463531732559204,
      "learning_rate": 6.3651063829787245e-06,
      "loss": 0.0797,
      "step": 5580
    },
    {
      "epoch": 1.2823988970588236,
      "grad_norm": 1.3122528791427612,
      "learning_rate": 6.364255319148937e-06,
      "loss": 0.0822,
      "step": 5581
    },
    {
      "epoch": 1.2826286764705883,
      "grad_norm": 0.8940346240997314,
      "learning_rate": 6.36340425531915e-06,
      "loss": 0.0602,
      "step": 5582
    },
    {
      "epoch": 1.2828584558823528,
      "grad_norm": 1.365069031715393,
      "learning_rate": 6.362553191489362e-06,
      "loss": 0.0657,
      "step": 5583
    },
    {
      "epoch": 1.2830882352941178,
      "grad_norm": 1.1180754899978638,
      "learning_rate": 6.361702127659575e-06,
      "loss": 0.1078,
      "step": 5584
    },
    {
      "epoch": 1.2833180147058822,
      "grad_norm": 1.265436053276062,
      "learning_rate": 6.360851063829789e-06,
      "loss": 0.0647,
      "step": 5585
    },
    {
      "epoch": 1.2835477941176472,
      "grad_norm": 0.9307669997215271,
      "learning_rate": 6.360000000000001e-06,
      "loss": 0.0531,
      "step": 5586
    },
    {
      "epoch": 1.2837775735294117,
      "grad_norm": 1.3406403064727783,
      "learning_rate": 6.359148936170213e-06,
      "loss": 0.0604,
      "step": 5587
    },
    {
      "epoch": 1.2840073529411764,
      "grad_norm": 0.9899201393127441,
      "learning_rate": 6.3582978723404264e-06,
      "loss": 0.056,
      "step": 5588
    },
    {
      "epoch": 1.2842371323529411,
      "grad_norm": 1.427170753479004,
      "learning_rate": 6.357446808510639e-06,
      "loss": 0.0714,
      "step": 5589
    },
    {
      "epoch": 1.2844669117647058,
      "grad_norm": 1.1932120323181152,
      "learning_rate": 6.356595744680851e-06,
      "loss": 0.0664,
      "step": 5590
    },
    {
      "epoch": 1.2846966911764706,
      "grad_norm": 0.9346729516983032,
      "learning_rate": 6.355744680851065e-06,
      "loss": 0.0866,
      "step": 5591
    },
    {
      "epoch": 1.2849264705882353,
      "grad_norm": 1.0690946578979492,
      "learning_rate": 6.354893617021277e-06,
      "loss": 0.0595,
      "step": 5592
    },
    {
      "epoch": 1.28515625,
      "grad_norm": 1.4982069730758667,
      "learning_rate": 6.35404255319149e-06,
      "loss": 0.1065,
      "step": 5593
    },
    {
      "epoch": 1.2853860294117647,
      "grad_norm": 1.4602738618850708,
      "learning_rate": 6.353191489361703e-06,
      "loss": 0.0905,
      "step": 5594
    },
    {
      "epoch": 1.2856158088235294,
      "grad_norm": 1.2150328159332275,
      "learning_rate": 6.352340425531915e-06,
      "loss": 0.0961,
      "step": 5595
    },
    {
      "epoch": 1.2858455882352942,
      "grad_norm": 1.1473537683486938,
      "learning_rate": 6.3514893617021276e-06,
      "loss": 0.0839,
      "step": 5596
    },
    {
      "epoch": 1.2860753676470589,
      "grad_norm": 1.4189536571502686,
      "learning_rate": 6.350638297872342e-06,
      "loss": 0.0849,
      "step": 5597
    },
    {
      "epoch": 1.2863051470588236,
      "grad_norm": 0.9862802624702454,
      "learning_rate": 6.349787234042554e-06,
      "loss": 0.0685,
      "step": 5598
    },
    {
      "epoch": 1.2865349264705883,
      "grad_norm": 0.9039315581321716,
      "learning_rate": 6.348936170212766e-06,
      "loss": 0.0658,
      "step": 5599
    },
    {
      "epoch": 1.2867647058823528,
      "grad_norm": 1.4414668083190918,
      "learning_rate": 6.348085106382979e-06,
      "loss": 0.0843,
      "step": 5600
    },
    {
      "epoch": 1.2869944852941178,
      "grad_norm": 1.6490715742111206,
      "learning_rate": 6.347234042553192e-06,
      "loss": 0.0854,
      "step": 5601
    },
    {
      "epoch": 1.2872242647058822,
      "grad_norm": 1.399873971939087,
      "learning_rate": 6.346382978723404e-06,
      "loss": 0.096,
      "step": 5602
    },
    {
      "epoch": 1.2874540441176472,
      "grad_norm": 1.376085877418518,
      "learning_rate": 6.345531914893618e-06,
      "loss": 0.0908,
      "step": 5603
    },
    {
      "epoch": 1.2876838235294117,
      "grad_norm": 1.0269302129745483,
      "learning_rate": 6.34468085106383e-06,
      "loss": 0.0723,
      "step": 5604
    },
    {
      "epoch": 1.2879136029411764,
      "grad_norm": 1.1668214797973633,
      "learning_rate": 6.343829787234043e-06,
      "loss": 0.0629,
      "step": 5605
    },
    {
      "epoch": 1.2881433823529411,
      "grad_norm": 1.170928716659546,
      "learning_rate": 6.342978723404256e-06,
      "loss": 0.0882,
      "step": 5606
    },
    {
      "epoch": 1.2883731617647058,
      "grad_norm": 1.0531210899353027,
      "learning_rate": 6.342127659574468e-06,
      "loss": 0.0655,
      "step": 5607
    },
    {
      "epoch": 1.2886029411764706,
      "grad_norm": 1.1078256368637085,
      "learning_rate": 6.3412765957446805e-06,
      "loss": 0.0647,
      "step": 5608
    },
    {
      "epoch": 1.2888327205882353,
      "grad_norm": 1.7064327001571655,
      "learning_rate": 6.3404255319148945e-06,
      "loss": 0.0843,
      "step": 5609
    },
    {
      "epoch": 1.2890625,
      "grad_norm": 1.3121330738067627,
      "learning_rate": 6.339574468085107e-06,
      "loss": 0.0855,
      "step": 5610
    },
    {
      "epoch": 1.2892922794117647,
      "grad_norm": 1.2790831327438354,
      "learning_rate": 6.338723404255319e-06,
      "loss": 0.1074,
      "step": 5611
    },
    {
      "epoch": 1.2895220588235294,
      "grad_norm": 1.481587529182434,
      "learning_rate": 6.337872340425532e-06,
      "loss": 0.1078,
      "step": 5612
    },
    {
      "epoch": 1.2897518382352942,
      "grad_norm": 1.2315882444381714,
      "learning_rate": 6.337021276595745e-06,
      "loss": 0.0977,
      "step": 5613
    },
    {
      "epoch": 1.2899816176470589,
      "grad_norm": 1.3357285261154175,
      "learning_rate": 6.336170212765958e-06,
      "loss": 0.0955,
      "step": 5614
    },
    {
      "epoch": 1.2902113970588236,
      "grad_norm": 1.5785062313079834,
      "learning_rate": 6.335319148936171e-06,
      "loss": 0.1,
      "step": 5615
    },
    {
      "epoch": 1.2904411764705883,
      "grad_norm": 1.588673710823059,
      "learning_rate": 6.334468085106383e-06,
      "loss": 0.1282,
      "step": 5616
    },
    {
      "epoch": 1.2906709558823528,
      "grad_norm": 1.1273692846298218,
      "learning_rate": 6.333617021276596e-06,
      "loss": 0.0761,
      "step": 5617
    },
    {
      "epoch": 1.2909007352941178,
      "grad_norm": 1.1930314302444458,
      "learning_rate": 6.332765957446809e-06,
      "loss": 0.1091,
      "step": 5618
    },
    {
      "epoch": 1.2911305147058822,
      "grad_norm": 1.1999233961105347,
      "learning_rate": 6.331914893617022e-06,
      "loss": 0.0862,
      "step": 5619
    },
    {
      "epoch": 1.2913602941176472,
      "grad_norm": 1.3495209217071533,
      "learning_rate": 6.331063829787235e-06,
      "loss": 0.1256,
      "step": 5620
    },
    {
      "epoch": 1.2915900735294117,
      "grad_norm": 1.3192541599273682,
      "learning_rate": 6.3302127659574475e-06,
      "loss": 0.0882,
      "step": 5621
    },
    {
      "epoch": 1.2918198529411764,
      "grad_norm": 1.292122721672058,
      "learning_rate": 6.32936170212766e-06,
      "loss": 0.0758,
      "step": 5622
    },
    {
      "epoch": 1.2920496323529411,
      "grad_norm": 1.0816723108291626,
      "learning_rate": 6.328510638297873e-06,
      "loss": 0.07,
      "step": 5623
    },
    {
      "epoch": 1.2922794117647058,
      "grad_norm": 1.227024793624878,
      "learning_rate": 6.327659574468086e-06,
      "loss": 0.1005,
      "step": 5624
    },
    {
      "epoch": 1.2925091911764706,
      "grad_norm": 1.2579333782196045,
      "learning_rate": 6.3268085106382985e-06,
      "loss": 0.0955,
      "step": 5625
    },
    {
      "epoch": 1.2927389705882353,
      "grad_norm": 1.4520305395126343,
      "learning_rate": 6.325957446808512e-06,
      "loss": 0.0979,
      "step": 5626
    },
    {
      "epoch": 1.29296875,
      "grad_norm": 1.0967625379562378,
      "learning_rate": 6.325106382978724e-06,
      "loss": 0.0934,
      "step": 5627
    },
    {
      "epoch": 1.2931985294117647,
      "grad_norm": 1.4209489822387695,
      "learning_rate": 6.324255319148936e-06,
      "loss": 0.0971,
      "step": 5628
    },
    {
      "epoch": 1.2934283088235294,
      "grad_norm": 1.5617517232894897,
      "learning_rate": 6.32340425531915e-06,
      "loss": 0.0911,
      "step": 5629
    },
    {
      "epoch": 1.2936580882352942,
      "grad_norm": 1.2168179750442505,
      "learning_rate": 6.322553191489363e-06,
      "loss": 0.0706,
      "step": 5630
    },
    {
      "epoch": 1.2938878676470589,
      "grad_norm": 1.2311815023422241,
      "learning_rate": 6.321702127659575e-06,
      "loss": 0.0985,
      "step": 5631
    },
    {
      "epoch": 1.2941176470588236,
      "grad_norm": 1.0384151935577393,
      "learning_rate": 6.320851063829788e-06,
      "loss": 0.0925,
      "step": 5632
    },
    {
      "epoch": 1.2943474264705883,
      "grad_norm": 0.9753928184509277,
      "learning_rate": 6.3200000000000005e-06,
      "loss": 0.0834,
      "step": 5633
    },
    {
      "epoch": 1.2945772058823528,
      "grad_norm": 1.2421212196350098,
      "learning_rate": 6.319148936170213e-06,
      "loss": 0.0804,
      "step": 5634
    },
    {
      "epoch": 1.2948069852941178,
      "grad_norm": 1.5510714054107666,
      "learning_rate": 6.318297872340427e-06,
      "loss": 0.0949,
      "step": 5635
    },
    {
      "epoch": 1.2950367647058822,
      "grad_norm": 1.1559373140335083,
      "learning_rate": 6.317446808510639e-06,
      "loss": 0.0889,
      "step": 5636
    },
    {
      "epoch": 1.2952665441176472,
      "grad_norm": 1.1928647756576538,
      "learning_rate": 6.3165957446808515e-06,
      "loss": 0.0887,
      "step": 5637
    },
    {
      "epoch": 1.2954963235294117,
      "grad_norm": 1.2108614444732666,
      "learning_rate": 6.315744680851065e-06,
      "loss": 0.1136,
      "step": 5638
    },
    {
      "epoch": 1.2957261029411764,
      "grad_norm": 1.900902271270752,
      "learning_rate": 6.314893617021277e-06,
      "loss": 0.1063,
      "step": 5639
    },
    {
      "epoch": 1.2959558823529411,
      "grad_norm": 1.3416749238967896,
      "learning_rate": 6.314042553191489e-06,
      "loss": 0.0788,
      "step": 5640
    },
    {
      "epoch": 1.2961856617647058,
      "grad_norm": 1.3400661945343018,
      "learning_rate": 6.313191489361703e-06,
      "loss": 0.1165,
      "step": 5641
    },
    {
      "epoch": 1.2964154411764706,
      "grad_norm": 1.050875186920166,
      "learning_rate": 6.312340425531916e-06,
      "loss": 0.0497,
      "step": 5642
    },
    {
      "epoch": 1.2966452205882353,
      "grad_norm": 1.101362943649292,
      "learning_rate": 6.311489361702128e-06,
      "loss": 0.0729,
      "step": 5643
    },
    {
      "epoch": 1.296875,
      "grad_norm": 1.2265533208847046,
      "learning_rate": 6.310638297872341e-06,
      "loss": 0.0824,
      "step": 5644
    },
    {
      "epoch": 1.2971047794117647,
      "grad_norm": 1.2997337579727173,
      "learning_rate": 6.3097872340425534e-06,
      "loss": 0.1041,
      "step": 5645
    },
    {
      "epoch": 1.2973345588235294,
      "grad_norm": 0.847159743309021,
      "learning_rate": 6.308936170212766e-06,
      "loss": 0.0684,
      "step": 5646
    },
    {
      "epoch": 1.2975643382352942,
      "grad_norm": 1.120910406112671,
      "learning_rate": 6.30808510638298e-06,
      "loss": 0.0759,
      "step": 5647
    },
    {
      "epoch": 1.2977941176470589,
      "grad_norm": 1.3866883516311646,
      "learning_rate": 6.307234042553192e-06,
      "loss": 0.0915,
      "step": 5648
    },
    {
      "epoch": 1.2980238970588236,
      "grad_norm": 1.0929075479507446,
      "learning_rate": 6.3063829787234044e-06,
      "loss": 0.0981,
      "step": 5649
    },
    {
      "epoch": 1.2982536764705883,
      "grad_norm": 0.8931006193161011,
      "learning_rate": 6.305531914893618e-06,
      "loss": 0.0594,
      "step": 5650
    },
    {
      "epoch": 1.2984834558823528,
      "grad_norm": 1.2328187227249146,
      "learning_rate": 6.30468085106383e-06,
      "loss": 0.0592,
      "step": 5651
    },
    {
      "epoch": 1.2987132352941178,
      "grad_norm": 1.280470371246338,
      "learning_rate": 6.303829787234042e-06,
      "loss": 0.1103,
      "step": 5652
    },
    {
      "epoch": 1.2989430147058822,
      "grad_norm": 1.1934508085250854,
      "learning_rate": 6.302978723404256e-06,
      "loss": 0.0763,
      "step": 5653
    },
    {
      "epoch": 1.2991727941176472,
      "grad_norm": 1.093197226524353,
      "learning_rate": 6.302127659574469e-06,
      "loss": 0.0778,
      "step": 5654
    },
    {
      "epoch": 1.2994025735294117,
      "grad_norm": 1.074796199798584,
      "learning_rate": 6.301276595744681e-06,
      "loss": 0.0618,
      "step": 5655
    },
    {
      "epoch": 1.2996323529411764,
      "grad_norm": 1.5250778198242188,
      "learning_rate": 6.300425531914894e-06,
      "loss": 0.0769,
      "step": 5656
    },
    {
      "epoch": 1.2998621323529411,
      "grad_norm": 0.8789377212524414,
      "learning_rate": 6.299574468085106e-06,
      "loss": 0.07,
      "step": 5657
    },
    {
      "epoch": 1.3000919117647058,
      "grad_norm": 1.0602142810821533,
      "learning_rate": 6.298723404255319e-06,
      "loss": 0.0843,
      "step": 5658
    },
    {
      "epoch": 1.3003216911764706,
      "grad_norm": 1.324904441833496,
      "learning_rate": 6.297872340425533e-06,
      "loss": 0.0885,
      "step": 5659
    },
    {
      "epoch": 1.3005514705882353,
      "grad_norm": 1.7418426275253296,
      "learning_rate": 6.297021276595745e-06,
      "loss": 0.0878,
      "step": 5660
    },
    {
      "epoch": 1.30078125,
      "grad_norm": 1.0047394037246704,
      "learning_rate": 6.296170212765957e-06,
      "loss": 0.0734,
      "step": 5661
    },
    {
      "epoch": 1.3010110294117647,
      "grad_norm": 1.8504900932312012,
      "learning_rate": 6.2953191489361706e-06,
      "loss": 0.0748,
      "step": 5662
    },
    {
      "epoch": 1.3012408088235294,
      "grad_norm": 1.413133144378662,
      "learning_rate": 6.294468085106383e-06,
      "loss": 0.1221,
      "step": 5663
    },
    {
      "epoch": 1.3014705882352942,
      "grad_norm": 1.3585106134414673,
      "learning_rate": 6.293617021276597e-06,
      "loss": 0.1053,
      "step": 5664
    },
    {
      "epoch": 1.3017003676470589,
      "grad_norm": 1.608816385269165,
      "learning_rate": 6.292765957446809e-06,
      "loss": 0.1034,
      "step": 5665
    },
    {
      "epoch": 1.3019301470588236,
      "grad_norm": 1.1105060577392578,
      "learning_rate": 6.2919148936170216e-06,
      "loss": 0.0736,
      "step": 5666
    },
    {
      "epoch": 1.3021599264705883,
      "grad_norm": 1.1410434246063232,
      "learning_rate": 6.291063829787235e-06,
      "loss": 0.0909,
      "step": 5667
    },
    {
      "epoch": 1.3023897058823528,
      "grad_norm": 1.0199896097183228,
      "learning_rate": 6.290212765957447e-06,
      "loss": 0.1033,
      "step": 5668
    },
    {
      "epoch": 1.3026194852941178,
      "grad_norm": 1.0919849872589111,
      "learning_rate": 6.28936170212766e-06,
      "loss": 0.059,
      "step": 5669
    },
    {
      "epoch": 1.3028492647058822,
      "grad_norm": 1.0522955656051636,
      "learning_rate": 6.288510638297873e-06,
      "loss": 0.0756,
      "step": 5670
    },
    {
      "epoch": 1.3030790441176472,
      "grad_norm": 1.2481133937835693,
      "learning_rate": 6.287659574468086e-06,
      "loss": 0.0792,
      "step": 5671
    },
    {
      "epoch": 1.3033088235294117,
      "grad_norm": 0.9639232158660889,
      "learning_rate": 6.286808510638298e-06,
      "loss": 0.063,
      "step": 5672
    },
    {
      "epoch": 1.3035386029411764,
      "grad_norm": 1.1492376327514648,
      "learning_rate": 6.285957446808511e-06,
      "loss": 0.0846,
      "step": 5673
    },
    {
      "epoch": 1.3037683823529411,
      "grad_norm": 1.3986502885818481,
      "learning_rate": 6.285106382978724e-06,
      "loss": 0.1074,
      "step": 5674
    },
    {
      "epoch": 1.3039981617647058,
      "grad_norm": 1.3511583805084229,
      "learning_rate": 6.284255319148937e-06,
      "loss": 0.102,
      "step": 5675
    },
    {
      "epoch": 1.3042279411764706,
      "grad_norm": 1.212782382965088,
      "learning_rate": 6.28340425531915e-06,
      "loss": 0.0894,
      "step": 5676
    },
    {
      "epoch": 1.3044577205882353,
      "grad_norm": 1.4803723096847534,
      "learning_rate": 6.282553191489362e-06,
      "loss": 0.0924,
      "step": 5677
    },
    {
      "epoch": 1.3046875,
      "grad_norm": 0.9308485388755798,
      "learning_rate": 6.2817021276595745e-06,
      "loss": 0.0642,
      "step": 5678
    },
    {
      "epoch": 1.3049172794117647,
      "grad_norm": 0.9906401634216309,
      "learning_rate": 6.2808510638297885e-06,
      "loss": 0.0776,
      "step": 5679
    },
    {
      "epoch": 1.3051470588235294,
      "grad_norm": 1.2947596311569214,
      "learning_rate": 6.280000000000001e-06,
      "loss": 0.098,
      "step": 5680
    },
    {
      "epoch": 1.3053768382352942,
      "grad_norm": 1.3579847812652588,
      "learning_rate": 6.279148936170213e-06,
      "loss": 0.1161,
      "step": 5681
    },
    {
      "epoch": 1.3056066176470589,
      "grad_norm": 1.0919843912124634,
      "learning_rate": 6.278297872340426e-06,
      "loss": 0.0863,
      "step": 5682
    },
    {
      "epoch": 1.3058363970588236,
      "grad_norm": 1.3690931797027588,
      "learning_rate": 6.277446808510639e-06,
      "loss": 0.1027,
      "step": 5683
    },
    {
      "epoch": 1.3060661764705883,
      "grad_norm": 1.5709609985351562,
      "learning_rate": 6.276595744680851e-06,
      "loss": 0.0918,
      "step": 5684
    },
    {
      "epoch": 1.3062959558823528,
      "grad_norm": 1.5566768646240234,
      "learning_rate": 6.275744680851065e-06,
      "loss": 0.1124,
      "step": 5685
    },
    {
      "epoch": 1.3065257352941178,
      "grad_norm": 1.1415228843688965,
      "learning_rate": 6.274893617021277e-06,
      "loss": 0.0939,
      "step": 5686
    },
    {
      "epoch": 1.3067555147058822,
      "grad_norm": 1.328980803489685,
      "learning_rate": 6.27404255319149e-06,
      "loss": 0.0864,
      "step": 5687
    },
    {
      "epoch": 1.3069852941176472,
      "grad_norm": 1.1517255306243896,
      "learning_rate": 6.273191489361703e-06,
      "loss": 0.097,
      "step": 5688
    },
    {
      "epoch": 1.3072150735294117,
      "grad_norm": 1.4588520526885986,
      "learning_rate": 6.272340425531915e-06,
      "loss": 0.1048,
      "step": 5689
    },
    {
      "epoch": 1.3074448529411764,
      "grad_norm": 1.3658357858657837,
      "learning_rate": 6.2714893617021275e-06,
      "loss": 0.1121,
      "step": 5690
    },
    {
      "epoch": 1.3076746323529411,
      "grad_norm": 1.1424399614334106,
      "learning_rate": 6.2706382978723415e-06,
      "loss": 0.0764,
      "step": 5691
    },
    {
      "epoch": 1.3079044117647058,
      "grad_norm": 0.8923741579055786,
      "learning_rate": 6.269787234042554e-06,
      "loss": 0.0847,
      "step": 5692
    },
    {
      "epoch": 1.3081341911764706,
      "grad_norm": 1.2493027448654175,
      "learning_rate": 6.268936170212766e-06,
      "loss": 0.0813,
      "step": 5693
    },
    {
      "epoch": 1.3083639705882353,
      "grad_norm": 0.9634100794792175,
      "learning_rate": 6.268085106382979e-06,
      "loss": 0.0871,
      "step": 5694
    },
    {
      "epoch": 1.30859375,
      "grad_norm": 0.973296582698822,
      "learning_rate": 6.267234042553192e-06,
      "loss": 0.0971,
      "step": 5695
    },
    {
      "epoch": 1.3088235294117647,
      "grad_norm": 1.144523024559021,
      "learning_rate": 6.266382978723404e-06,
      "loss": 0.068,
      "step": 5696
    },
    {
      "epoch": 1.3090533088235294,
      "grad_norm": 1.3619260787963867,
      "learning_rate": 6.265531914893618e-06,
      "loss": 0.0895,
      "step": 5697
    },
    {
      "epoch": 1.3092830882352942,
      "grad_norm": 1.2423772811889648,
      "learning_rate": 6.26468085106383e-06,
      "loss": 0.0874,
      "step": 5698
    },
    {
      "epoch": 1.3095128676470589,
      "grad_norm": 1.4502464532852173,
      "learning_rate": 6.263829787234043e-06,
      "loss": 0.1065,
      "step": 5699
    },
    {
      "epoch": 1.3097426470588236,
      "grad_norm": 1.1117476224899292,
      "learning_rate": 6.262978723404256e-06,
      "loss": 0.0584,
      "step": 5700
    },
    {
      "epoch": 1.3099724264705883,
      "grad_norm": 1.097270131111145,
      "learning_rate": 6.262127659574468e-06,
      "loss": 0.0811,
      "step": 5701
    },
    {
      "epoch": 1.3102022058823528,
      "grad_norm": 1.0966589450836182,
      "learning_rate": 6.2612765957446804e-06,
      "loss": 0.1064,
      "step": 5702
    },
    {
      "epoch": 1.3104319852941178,
      "grad_norm": 1.4038547277450562,
      "learning_rate": 6.2604255319148945e-06,
      "loss": 0.0817,
      "step": 5703
    },
    {
      "epoch": 1.3106617647058822,
      "grad_norm": 1.6091488599777222,
      "learning_rate": 6.259574468085107e-06,
      "loss": 0.078,
      "step": 5704
    },
    {
      "epoch": 1.3108915441176472,
      "grad_norm": 1.3579881191253662,
      "learning_rate": 6.25872340425532e-06,
      "loss": 0.0925,
      "step": 5705
    },
    {
      "epoch": 1.3111213235294117,
      "grad_norm": 1.205561876296997,
      "learning_rate": 6.257872340425532e-06,
      "loss": 0.0791,
      "step": 5706
    },
    {
      "epoch": 1.3113511029411764,
      "grad_norm": 0.9256584644317627,
      "learning_rate": 6.257021276595745e-06,
      "loss": 0.079,
      "step": 5707
    },
    {
      "epoch": 1.3115808823529411,
      "grad_norm": 0.8797559142112732,
      "learning_rate": 6.256170212765959e-06,
      "loss": 0.0709,
      "step": 5708
    },
    {
      "epoch": 1.3118106617647058,
      "grad_norm": 1.9927940368652344,
      "learning_rate": 6.255319148936171e-06,
      "loss": 0.1201,
      "step": 5709
    },
    {
      "epoch": 1.3120404411764706,
      "grad_norm": 1.4945623874664307,
      "learning_rate": 6.254468085106383e-06,
      "loss": 0.1081,
      "step": 5710
    },
    {
      "epoch": 1.3122702205882353,
      "grad_norm": 1.1739424467086792,
      "learning_rate": 6.2536170212765964e-06,
      "loss": 0.0902,
      "step": 5711
    },
    {
      "epoch": 1.3125,
      "grad_norm": 1.2424404621124268,
      "learning_rate": 6.252765957446809e-06,
      "loss": 0.1063,
      "step": 5712
    },
    {
      "epoch": 1.3127297794117647,
      "grad_norm": 0.6917641758918762,
      "learning_rate": 6.251914893617022e-06,
      "loss": 0.0455,
      "step": 5713
    },
    {
      "epoch": 1.3129595588235294,
      "grad_norm": 1.5327478647232056,
      "learning_rate": 6.251063829787235e-06,
      "loss": 0.0996,
      "step": 5714
    },
    {
      "epoch": 1.3131893382352942,
      "grad_norm": 1.002355933189392,
      "learning_rate": 6.2502127659574474e-06,
      "loss": 0.0574,
      "step": 5715
    },
    {
      "epoch": 1.3134191176470589,
      "grad_norm": 1.2692712545394897,
      "learning_rate": 6.24936170212766e-06,
      "loss": 0.0829,
      "step": 5716
    },
    {
      "epoch": 1.3136488970588236,
      "grad_norm": 1.5636520385742188,
      "learning_rate": 6.248510638297873e-06,
      "loss": 0.0933,
      "step": 5717
    },
    {
      "epoch": 1.3138786764705883,
      "grad_norm": 1.0657713413238525,
      "learning_rate": 6.247659574468086e-06,
      "loss": 0.0771,
      "step": 5718
    },
    {
      "epoch": 1.3141084558823528,
      "grad_norm": 1.52117121219635,
      "learning_rate": 6.246808510638298e-06,
      "loss": 0.108,
      "step": 5719
    },
    {
      "epoch": 1.3143382352941178,
      "grad_norm": 1.4687845706939697,
      "learning_rate": 6.245957446808512e-06,
      "loss": 0.1039,
      "step": 5720
    },
    {
      "epoch": 1.3145680147058822,
      "grad_norm": 1.6998813152313232,
      "learning_rate": 6.245106382978724e-06,
      "loss": 0.1117,
      "step": 5721
    },
    {
      "epoch": 1.3147977941176472,
      "grad_norm": 0.8404524922370911,
      "learning_rate": 6.244255319148936e-06,
      "loss": 0.0633,
      "step": 5722
    },
    {
      "epoch": 1.3150275735294117,
      "grad_norm": 1.6571626663208008,
      "learning_rate": 6.24340425531915e-06,
      "loss": 0.121,
      "step": 5723
    },
    {
      "epoch": 1.3152573529411764,
      "grad_norm": 1.326641321182251,
      "learning_rate": 6.242553191489363e-06,
      "loss": 0.0931,
      "step": 5724
    },
    {
      "epoch": 1.3154871323529411,
      "grad_norm": 0.8973501920700073,
      "learning_rate": 6.241702127659575e-06,
      "loss": 0.0674,
      "step": 5725
    },
    {
      "epoch": 1.3157169117647058,
      "grad_norm": 1.0111740827560425,
      "learning_rate": 6.240851063829788e-06,
      "loss": 0.0691,
      "step": 5726
    },
    {
      "epoch": 1.3159466911764706,
      "grad_norm": 1.1159383058547974,
      "learning_rate": 6.24e-06,
      "loss": 0.0738,
      "step": 5727
    },
    {
      "epoch": 1.3161764705882353,
      "grad_norm": 0.9229665994644165,
      "learning_rate": 6.239148936170213e-06,
      "loss": 0.0682,
      "step": 5728
    },
    {
      "epoch": 1.31640625,
      "grad_norm": 1.2003211975097656,
      "learning_rate": 6.238297872340427e-06,
      "loss": 0.0956,
      "step": 5729
    },
    {
      "epoch": 1.3166360294117647,
      "grad_norm": 1.5049210786819458,
      "learning_rate": 6.237446808510639e-06,
      "loss": 0.0793,
      "step": 5730
    },
    {
      "epoch": 1.3168658088235294,
      "grad_norm": 1.3550431728363037,
      "learning_rate": 6.236595744680851e-06,
      "loss": 0.1012,
      "step": 5731
    },
    {
      "epoch": 1.3170955882352942,
      "grad_norm": 1.2907812595367432,
      "learning_rate": 6.2357446808510646e-06,
      "loss": 0.0664,
      "step": 5732
    },
    {
      "epoch": 1.3173253676470589,
      "grad_norm": 1.0756407976150513,
      "learning_rate": 6.234893617021277e-06,
      "loss": 0.0736,
      "step": 5733
    },
    {
      "epoch": 1.3175551470588236,
      "grad_norm": 1.1535452604293823,
      "learning_rate": 6.234042553191489e-06,
      "loss": 0.0893,
      "step": 5734
    },
    {
      "epoch": 1.3177849264705883,
      "grad_norm": 1.2719168663024902,
      "learning_rate": 6.233191489361703e-06,
      "loss": 0.0844,
      "step": 5735
    },
    {
      "epoch": 1.3180147058823528,
      "grad_norm": 1.257207989692688,
      "learning_rate": 6.2323404255319155e-06,
      "loss": 0.0752,
      "step": 5736
    },
    {
      "epoch": 1.3182444852941178,
      "grad_norm": 1.5457367897033691,
      "learning_rate": 6.231489361702128e-06,
      "loss": 0.126,
      "step": 5737
    },
    {
      "epoch": 1.3184742647058822,
      "grad_norm": 1.4412726163864136,
      "learning_rate": 6.230638297872341e-06,
      "loss": 0.1121,
      "step": 5738
    },
    {
      "epoch": 1.3187040441176472,
      "grad_norm": 1.2963368892669678,
      "learning_rate": 6.229787234042553e-06,
      "loss": 0.0939,
      "step": 5739
    },
    {
      "epoch": 1.3189338235294117,
      "grad_norm": 1.1128129959106445,
      "learning_rate": 6.228936170212766e-06,
      "loss": 0.0617,
      "step": 5740
    },
    {
      "epoch": 1.3191636029411764,
      "grad_norm": 1.008833408355713,
      "learning_rate": 6.22808510638298e-06,
      "loss": 0.069,
      "step": 5741
    },
    {
      "epoch": 1.3193933823529411,
      "grad_norm": 1.3664239645004272,
      "learning_rate": 6.227234042553192e-06,
      "loss": 0.0912,
      "step": 5742
    },
    {
      "epoch": 1.3196231617647058,
      "grad_norm": 1.2440943717956543,
      "learning_rate": 6.226382978723404e-06,
      "loss": 0.1074,
      "step": 5743
    },
    {
      "epoch": 1.3198529411764706,
      "grad_norm": 1.5623788833618164,
      "learning_rate": 6.2255319148936175e-06,
      "loss": 0.0894,
      "step": 5744
    },
    {
      "epoch": 1.3200827205882353,
      "grad_norm": 1.552432656288147,
      "learning_rate": 6.22468085106383e-06,
      "loss": 0.093,
      "step": 5745
    },
    {
      "epoch": 1.3203125,
      "grad_norm": 0.9725590944290161,
      "learning_rate": 6.223829787234042e-06,
      "loss": 0.0647,
      "step": 5746
    },
    {
      "epoch": 1.3205422794117647,
      "grad_norm": 1.3155606985092163,
      "learning_rate": 6.222978723404256e-06,
      "loss": 0.0858,
      "step": 5747
    },
    {
      "epoch": 1.3207720588235294,
      "grad_norm": 1.6934638023376465,
      "learning_rate": 6.2221276595744685e-06,
      "loss": 0.1011,
      "step": 5748
    },
    {
      "epoch": 1.3210018382352942,
      "grad_norm": 1.2178497314453125,
      "learning_rate": 6.221276595744682e-06,
      "loss": 0.0806,
      "step": 5749
    },
    {
      "epoch": 1.3212316176470589,
      "grad_norm": 1.2139254808425903,
      "learning_rate": 6.220425531914894e-06,
      "loss": 0.0567,
      "step": 5750
    },
    {
      "epoch": 1.3214613970588236,
      "grad_norm": 1.2253530025482178,
      "learning_rate": 6.219574468085106e-06,
      "loss": 0.0584,
      "step": 5751
    },
    {
      "epoch": 1.3216911764705883,
      "grad_norm": 1.3851064443588257,
      "learning_rate": 6.21872340425532e-06,
      "loss": 0.0796,
      "step": 5752
    },
    {
      "epoch": 1.3219209558823528,
      "grad_norm": 2.011697292327881,
      "learning_rate": 6.217872340425533e-06,
      "loss": 0.0838,
      "step": 5753
    },
    {
      "epoch": 1.3221507352941178,
      "grad_norm": 1.1282591819763184,
      "learning_rate": 6.217021276595745e-06,
      "loss": 0.0725,
      "step": 5754
    },
    {
      "epoch": 1.3223805147058822,
      "grad_norm": 1.2934489250183105,
      "learning_rate": 6.216170212765958e-06,
      "loss": 0.0691,
      "step": 5755
    },
    {
      "epoch": 1.3226102941176472,
      "grad_norm": 0.9991784691810608,
      "learning_rate": 6.2153191489361705e-06,
      "loss": 0.0673,
      "step": 5756
    },
    {
      "epoch": 1.3228400735294117,
      "grad_norm": 1.5553629398345947,
      "learning_rate": 6.214468085106383e-06,
      "loss": 0.0749,
      "step": 5757
    },
    {
      "epoch": 1.3230698529411764,
      "grad_norm": 1.3583664894104004,
      "learning_rate": 6.213617021276597e-06,
      "loss": 0.0963,
      "step": 5758
    },
    {
      "epoch": 1.3232996323529411,
      "grad_norm": 1.3312376737594604,
      "learning_rate": 6.212765957446809e-06,
      "loss": 0.0749,
      "step": 5759
    },
    {
      "epoch": 1.3235294117647058,
      "grad_norm": 1.4464341402053833,
      "learning_rate": 6.2119148936170215e-06,
      "loss": 0.0939,
      "step": 5760
    },
    {
      "epoch": 1.3237591911764706,
      "grad_norm": 1.1265934705734253,
      "learning_rate": 6.211063829787235e-06,
      "loss": 0.0717,
      "step": 5761
    },
    {
      "epoch": 1.3239889705882353,
      "grad_norm": 1.1589850187301636,
      "learning_rate": 6.210212765957447e-06,
      "loss": 0.0724,
      "step": 5762
    },
    {
      "epoch": 1.32421875,
      "grad_norm": 1.3506436347961426,
      "learning_rate": 6.20936170212766e-06,
      "loss": 0.1077,
      "step": 5763
    },
    {
      "epoch": 1.3244485294117647,
      "grad_norm": 1.268660068511963,
      "learning_rate": 6.208510638297873e-06,
      "loss": 0.0814,
      "step": 5764
    },
    {
      "epoch": 1.3246783088235294,
      "grad_norm": 0.972318172454834,
      "learning_rate": 6.207659574468086e-06,
      "loss": 0.0627,
      "step": 5765
    },
    {
      "epoch": 1.3249080882352942,
      "grad_norm": 0.8274900317192078,
      "learning_rate": 6.206808510638298e-06,
      "loss": 0.0579,
      "step": 5766
    },
    {
      "epoch": 1.3251378676470589,
      "grad_norm": 1.1299545764923096,
      "learning_rate": 6.205957446808511e-06,
      "loss": 0.0882,
      "step": 5767
    },
    {
      "epoch": 1.3253676470588236,
      "grad_norm": 1.3221718072891235,
      "learning_rate": 6.205106382978724e-06,
      "loss": 0.0853,
      "step": 5768
    },
    {
      "epoch": 1.3255974264705883,
      "grad_norm": 1.2517876625061035,
      "learning_rate": 6.204255319148937e-06,
      "loss": 0.1156,
      "step": 5769
    },
    {
      "epoch": 1.3258272058823528,
      "grad_norm": 1.2050827741622925,
      "learning_rate": 6.20340425531915e-06,
      "loss": 0.0935,
      "step": 5770
    },
    {
      "epoch": 1.3260569852941178,
      "grad_norm": 0.948390007019043,
      "learning_rate": 6.202553191489362e-06,
      "loss": 0.0709,
      "step": 5771
    },
    {
      "epoch": 1.3262867647058822,
      "grad_norm": 1.3926985263824463,
      "learning_rate": 6.2017021276595744e-06,
      "loss": 0.0674,
      "step": 5772
    },
    {
      "epoch": 1.3265165441176472,
      "grad_norm": 1.3891880512237549,
      "learning_rate": 6.2008510638297885e-06,
      "loss": 0.1107,
      "step": 5773
    },
    {
      "epoch": 1.3267463235294117,
      "grad_norm": 1.3308360576629639,
      "learning_rate": 6.200000000000001e-06,
      "loss": 0.0743,
      "step": 5774
    },
    {
      "epoch": 1.3269761029411764,
      "grad_norm": 1.1856359243392944,
      "learning_rate": 6.199148936170213e-06,
      "loss": 0.0714,
      "step": 5775
    },
    {
      "epoch": 1.3272058823529411,
      "grad_norm": 1.6043834686279297,
      "learning_rate": 6.198297872340426e-06,
      "loss": 0.0897,
      "step": 5776
    },
    {
      "epoch": 1.3274356617647058,
      "grad_norm": 0.8279929757118225,
      "learning_rate": 6.197446808510639e-06,
      "loss": 0.0483,
      "step": 5777
    },
    {
      "epoch": 1.3276654411764706,
      "grad_norm": 1.1265307664871216,
      "learning_rate": 6.196595744680851e-06,
      "loss": 0.0724,
      "step": 5778
    },
    {
      "epoch": 1.3278952205882353,
      "grad_norm": 1.1784303188323975,
      "learning_rate": 6.195744680851065e-06,
      "loss": 0.1077,
      "step": 5779
    },
    {
      "epoch": 1.328125,
      "grad_norm": 1.3484805822372437,
      "learning_rate": 6.194893617021277e-06,
      "loss": 0.0907,
      "step": 5780
    },
    {
      "epoch": 1.3283547794117647,
      "grad_norm": 1.2567358016967773,
      "learning_rate": 6.19404255319149e-06,
      "loss": 0.0854,
      "step": 5781
    },
    {
      "epoch": 1.3285845588235294,
      "grad_norm": 1.523568034172058,
      "learning_rate": 6.193191489361703e-06,
      "loss": 0.0825,
      "step": 5782
    },
    {
      "epoch": 1.3288143382352942,
      "grad_norm": 1.3015222549438477,
      "learning_rate": 6.192340425531915e-06,
      "loss": 0.103,
      "step": 5783
    },
    {
      "epoch": 1.3290441176470589,
      "grad_norm": 1.3563807010650635,
      "learning_rate": 6.191489361702127e-06,
      "loss": 0.0909,
      "step": 5784
    },
    {
      "epoch": 1.3292738970588236,
      "grad_norm": 1.1426023244857788,
      "learning_rate": 6.190638297872341e-06,
      "loss": 0.0562,
      "step": 5785
    },
    {
      "epoch": 1.3295036764705883,
      "grad_norm": 1.665533423423767,
      "learning_rate": 6.189787234042554e-06,
      "loss": 0.0579,
      "step": 5786
    },
    {
      "epoch": 1.3297334558823528,
      "grad_norm": 1.022079586982727,
      "learning_rate": 6.188936170212766e-06,
      "loss": 0.0855,
      "step": 5787
    },
    {
      "epoch": 1.3299632352941178,
      "grad_norm": 1.8155533075332642,
      "learning_rate": 6.188085106382979e-06,
      "loss": 0.0663,
      "step": 5788
    },
    {
      "epoch": 1.3301930147058822,
      "grad_norm": 1.2928310632705688,
      "learning_rate": 6.1872340425531916e-06,
      "loss": 0.0981,
      "step": 5789
    },
    {
      "epoch": 1.3304227941176472,
      "grad_norm": 1.2573357820510864,
      "learning_rate": 6.186382978723404e-06,
      "loss": 0.0632,
      "step": 5790
    },
    {
      "epoch": 1.3306525735294117,
      "grad_norm": 1.2200002670288086,
      "learning_rate": 6.185531914893618e-06,
      "loss": 0.1061,
      "step": 5791
    },
    {
      "epoch": 1.3308823529411764,
      "grad_norm": 0.724267303943634,
      "learning_rate": 6.18468085106383e-06,
      "loss": 0.043,
      "step": 5792
    },
    {
      "epoch": 1.3311121323529411,
      "grad_norm": 1.6858545541763306,
      "learning_rate": 6.183829787234043e-06,
      "loss": 0.1095,
      "step": 5793
    },
    {
      "epoch": 1.3313419117647058,
      "grad_norm": 1.0432401895523071,
      "learning_rate": 6.182978723404256e-06,
      "loss": 0.0658,
      "step": 5794
    },
    {
      "epoch": 1.3315716911764706,
      "grad_norm": 1.576742172241211,
      "learning_rate": 6.182127659574468e-06,
      "loss": 0.0841,
      "step": 5795
    },
    {
      "epoch": 1.3318014705882353,
      "grad_norm": 1.389847993850708,
      "learning_rate": 6.181276595744682e-06,
      "loss": 0.12,
      "step": 5796
    },
    {
      "epoch": 1.33203125,
      "grad_norm": 1.470678448677063,
      "learning_rate": 6.180425531914894e-06,
      "loss": 0.1026,
      "step": 5797
    },
    {
      "epoch": 1.3322610294117647,
      "grad_norm": 1.653777003288269,
      "learning_rate": 6.179574468085107e-06,
      "loss": 0.1365,
      "step": 5798
    },
    {
      "epoch": 1.3324908088235294,
      "grad_norm": 1.7133969068527222,
      "learning_rate": 6.17872340425532e-06,
      "loss": 0.0919,
      "step": 5799
    },
    {
      "epoch": 1.3327205882352942,
      "grad_norm": 1.2728315591812134,
      "learning_rate": 6.177872340425532e-06,
      "loss": 0.063,
      "step": 5800
    },
    {
      "epoch": 1.3329503676470589,
      "grad_norm": 1.091221809387207,
      "learning_rate": 6.1770212765957445e-06,
      "loss": 0.0747,
      "step": 5801
    },
    {
      "epoch": 1.3331801470588236,
      "grad_norm": 1.2293869256973267,
      "learning_rate": 6.1761702127659585e-06,
      "loss": 0.0867,
      "step": 5802
    },
    {
      "epoch": 1.3334099264705883,
      "grad_norm": 1.1193630695343018,
      "learning_rate": 6.175319148936171e-06,
      "loss": 0.0671,
      "step": 5803
    },
    {
      "epoch": 1.3336397058823528,
      "grad_norm": 0.8181337118148804,
      "learning_rate": 6.174468085106383e-06,
      "loss": 0.0646,
      "step": 5804
    },
    {
      "epoch": 1.3338694852941178,
      "grad_norm": 0.8157647848129272,
      "learning_rate": 6.173617021276596e-06,
      "loss": 0.0613,
      "step": 5805
    },
    {
      "epoch": 1.3340992647058822,
      "grad_norm": 1.1504199504852295,
      "learning_rate": 6.172765957446809e-06,
      "loss": 0.0601,
      "step": 5806
    },
    {
      "epoch": 1.3343290441176472,
      "grad_norm": 1.284398078918457,
      "learning_rate": 6.171914893617022e-06,
      "loss": 0.0739,
      "step": 5807
    },
    {
      "epoch": 1.3345588235294117,
      "grad_norm": 1.156150460243225,
      "learning_rate": 6.171063829787235e-06,
      "loss": 0.0612,
      "step": 5808
    },
    {
      "epoch": 1.3347886029411764,
      "grad_norm": 1.3842545747756958,
      "learning_rate": 6.170212765957447e-06,
      "loss": 0.0995,
      "step": 5809
    },
    {
      "epoch": 1.3350183823529411,
      "grad_norm": 1.2491461038589478,
      "learning_rate": 6.16936170212766e-06,
      "loss": 0.1145,
      "step": 5810
    },
    {
      "epoch": 1.3352481617647058,
      "grad_norm": 1.787597894668579,
      "learning_rate": 6.168510638297873e-06,
      "loss": 0.0785,
      "step": 5811
    },
    {
      "epoch": 1.3354779411764706,
      "grad_norm": 1.439398169517517,
      "learning_rate": 6.167659574468086e-06,
      "loss": 0.11,
      "step": 5812
    },
    {
      "epoch": 1.3357077205882353,
      "grad_norm": 1.4403046369552612,
      "learning_rate": 6.166808510638298e-06,
      "loss": 0.0877,
      "step": 5813
    },
    {
      "epoch": 1.3359375,
      "grad_norm": 1.2472237348556519,
      "learning_rate": 6.1659574468085115e-06,
      "loss": 0.0929,
      "step": 5814
    },
    {
      "epoch": 1.3361672794117647,
      "grad_norm": 0.9932979941368103,
      "learning_rate": 6.165106382978724e-06,
      "loss": 0.0672,
      "step": 5815
    },
    {
      "epoch": 1.3363970588235294,
      "grad_norm": 1.6730504035949707,
      "learning_rate": 6.164255319148936e-06,
      "loss": 0.094,
      "step": 5816
    },
    {
      "epoch": 1.3366268382352942,
      "grad_norm": 1.2006598711013794,
      "learning_rate": 6.16340425531915e-06,
      "loss": 0.0856,
      "step": 5817
    },
    {
      "epoch": 1.3368566176470589,
      "grad_norm": 1.1399717330932617,
      "learning_rate": 6.1625531914893625e-06,
      "loss": 0.0566,
      "step": 5818
    },
    {
      "epoch": 1.3370863970588236,
      "grad_norm": 1.5407402515411377,
      "learning_rate": 6.161702127659575e-06,
      "loss": 0.0979,
      "step": 5819
    },
    {
      "epoch": 1.3373161764705883,
      "grad_norm": 1.2962398529052734,
      "learning_rate": 6.160851063829788e-06,
      "loss": 0.0714,
      "step": 5820
    },
    {
      "epoch": 1.3375459558823528,
      "grad_norm": 1.2904256582260132,
      "learning_rate": 6.16e-06,
      "loss": 0.0839,
      "step": 5821
    },
    {
      "epoch": 1.3377757352941178,
      "grad_norm": 1.8935376405715942,
      "learning_rate": 6.159148936170213e-06,
      "loss": 0.1187,
      "step": 5822
    },
    {
      "epoch": 1.3380055147058822,
      "grad_norm": 1.2793067693710327,
      "learning_rate": 6.158297872340427e-06,
      "loss": 0.0675,
      "step": 5823
    },
    {
      "epoch": 1.3382352941176472,
      "grad_norm": 1.007304072380066,
      "learning_rate": 6.157446808510639e-06,
      "loss": 0.0567,
      "step": 5824
    },
    {
      "epoch": 1.3384650735294117,
      "grad_norm": 1.103718638420105,
      "learning_rate": 6.156595744680851e-06,
      "loss": 0.0871,
      "step": 5825
    },
    {
      "epoch": 1.3386948529411764,
      "grad_norm": 0.9266554713249207,
      "learning_rate": 6.1557446808510645e-06,
      "loss": 0.0642,
      "step": 5826
    },
    {
      "epoch": 1.3389246323529411,
      "grad_norm": 1.1305259466171265,
      "learning_rate": 6.154893617021277e-06,
      "loss": 0.0899,
      "step": 5827
    },
    {
      "epoch": 1.3391544117647058,
      "grad_norm": 1.0830551385879517,
      "learning_rate": 6.154042553191489e-06,
      "loss": 0.0756,
      "step": 5828
    },
    {
      "epoch": 1.3393841911764706,
      "grad_norm": 1.2124637365341187,
      "learning_rate": 6.153191489361703e-06,
      "loss": 0.0929,
      "step": 5829
    },
    {
      "epoch": 1.3396139705882353,
      "grad_norm": 1.1664228439331055,
      "learning_rate": 6.1523404255319155e-06,
      "loss": 0.0739,
      "step": 5830
    },
    {
      "epoch": 1.33984375,
      "grad_norm": 1.516929268836975,
      "learning_rate": 6.151489361702128e-06,
      "loss": 0.075,
      "step": 5831
    },
    {
      "epoch": 1.3400735294117647,
      "grad_norm": 1.8324847221374512,
      "learning_rate": 6.150638297872341e-06,
      "loss": 0.0863,
      "step": 5832
    },
    {
      "epoch": 1.3403033088235294,
      "grad_norm": 0.9016739726066589,
      "learning_rate": 6.149787234042553e-06,
      "loss": 0.0639,
      "step": 5833
    },
    {
      "epoch": 1.3405330882352942,
      "grad_norm": 0.9490984678268433,
      "learning_rate": 6.148936170212767e-06,
      "loss": 0.06,
      "step": 5834
    },
    {
      "epoch": 1.3407628676470589,
      "grad_norm": 0.9505459666252136,
      "learning_rate": 6.14808510638298e-06,
      "loss": 0.0612,
      "step": 5835
    },
    {
      "epoch": 1.3409926470588236,
      "grad_norm": 0.929850161075592,
      "learning_rate": 6.147234042553192e-06,
      "loss": 0.0577,
      "step": 5836
    },
    {
      "epoch": 1.3412224264705883,
      "grad_norm": 1.2793240547180176,
      "learning_rate": 6.146382978723405e-06,
      "loss": 0.0793,
      "step": 5837
    },
    {
      "epoch": 1.3414522058823528,
      "grad_norm": 1.3811177015304565,
      "learning_rate": 6.1455319148936174e-06,
      "loss": 0.104,
      "step": 5838
    },
    {
      "epoch": 1.3416819852941178,
      "grad_norm": 1.2556926012039185,
      "learning_rate": 6.14468085106383e-06,
      "loss": 0.0883,
      "step": 5839
    },
    {
      "epoch": 1.3419117647058822,
      "grad_norm": 1.4152767658233643,
      "learning_rate": 6.143829787234044e-06,
      "loss": 0.0755,
      "step": 5840
    },
    {
      "epoch": 1.3421415441176472,
      "grad_norm": 1.680855393409729,
      "learning_rate": 6.142978723404256e-06,
      "loss": 0.1378,
      "step": 5841
    },
    {
      "epoch": 1.3423713235294117,
      "grad_norm": 1.1416687965393066,
      "learning_rate": 6.1421276595744684e-06,
      "loss": 0.0659,
      "step": 5842
    },
    {
      "epoch": 1.3426011029411764,
      "grad_norm": 1.1945909261703491,
      "learning_rate": 6.141276595744682e-06,
      "loss": 0.0772,
      "step": 5843
    },
    {
      "epoch": 1.3428308823529411,
      "grad_norm": 1.412039875984192,
      "learning_rate": 6.140425531914894e-06,
      "loss": 0.0721,
      "step": 5844
    },
    {
      "epoch": 1.3430606617647058,
      "grad_norm": 1.1962192058563232,
      "learning_rate": 6.139574468085106e-06,
      "loss": 0.0661,
      "step": 5845
    },
    {
      "epoch": 1.3432904411764706,
      "grad_norm": 1.137542963027954,
      "learning_rate": 6.13872340425532e-06,
      "loss": 0.0918,
      "step": 5846
    },
    {
      "epoch": 1.3435202205882353,
      "grad_norm": 1.334598183631897,
      "learning_rate": 6.137872340425533e-06,
      "loss": 0.0687,
      "step": 5847
    },
    {
      "epoch": 1.34375,
      "grad_norm": 1.5136462450027466,
      "learning_rate": 6.137021276595745e-06,
      "loss": 0.0926,
      "step": 5848
    },
    {
      "epoch": 1.3439797794117647,
      "grad_norm": 1.6204009056091309,
      "learning_rate": 6.136170212765958e-06,
      "loss": 0.0904,
      "step": 5849
    },
    {
      "epoch": 1.3442095588235294,
      "grad_norm": 2.0646605491638184,
      "learning_rate": 6.13531914893617e-06,
      "loss": 0.0986,
      "step": 5850
    },
    {
      "epoch": 1.3444393382352942,
      "grad_norm": 1.2106399536132812,
      "learning_rate": 6.134468085106383e-06,
      "loss": 0.0698,
      "step": 5851
    },
    {
      "epoch": 1.3446691176470589,
      "grad_norm": 0.9464951753616333,
      "learning_rate": 6.133617021276597e-06,
      "loss": 0.0748,
      "step": 5852
    },
    {
      "epoch": 1.3448988970588236,
      "grad_norm": 1.0105087757110596,
      "learning_rate": 6.132765957446809e-06,
      "loss": 0.0953,
      "step": 5853
    },
    {
      "epoch": 1.3451286764705883,
      "grad_norm": 1.3776389360427856,
      "learning_rate": 6.131914893617021e-06,
      "loss": 0.1263,
      "step": 5854
    },
    {
      "epoch": 1.3453584558823528,
      "grad_norm": 1.1593199968338013,
      "learning_rate": 6.1310638297872346e-06,
      "loss": 0.0956,
      "step": 5855
    },
    {
      "epoch": 1.3455882352941178,
      "grad_norm": 0.9330688714981079,
      "learning_rate": 6.130212765957447e-06,
      "loss": 0.0783,
      "step": 5856
    },
    {
      "epoch": 1.3458180147058822,
      "grad_norm": 1.4577710628509521,
      "learning_rate": 6.12936170212766e-06,
      "loss": 0.0878,
      "step": 5857
    },
    {
      "epoch": 1.3460477941176472,
      "grad_norm": 1.4445202350616455,
      "learning_rate": 6.128510638297873e-06,
      "loss": 0.0865,
      "step": 5858
    },
    {
      "epoch": 1.3462775735294117,
      "grad_norm": 1.2662174701690674,
      "learning_rate": 6.1276595744680855e-06,
      "loss": 0.0504,
      "step": 5859
    },
    {
      "epoch": 1.3465073529411764,
      "grad_norm": 0.9562090039253235,
      "learning_rate": 6.126808510638298e-06,
      "loss": 0.0447,
      "step": 5860
    },
    {
      "epoch": 1.3467371323529411,
      "grad_norm": 0.8955985903739929,
      "learning_rate": 6.125957446808511e-06,
      "loss": 0.0564,
      "step": 5861
    },
    {
      "epoch": 1.3469669117647058,
      "grad_norm": 1.094175934791565,
      "learning_rate": 6.125106382978724e-06,
      "loss": 0.0824,
      "step": 5862
    },
    {
      "epoch": 1.3471966911764706,
      "grad_norm": 1.3337303400039673,
      "learning_rate": 6.1242553191489365e-06,
      "loss": 0.0972,
      "step": 5863
    },
    {
      "epoch": 1.3474264705882353,
      "grad_norm": 0.898229718208313,
      "learning_rate": 6.12340425531915e-06,
      "loss": 0.0664,
      "step": 5864
    },
    {
      "epoch": 1.34765625,
      "grad_norm": 1.0155682563781738,
      "learning_rate": 6.122553191489362e-06,
      "loss": 0.0693,
      "step": 5865
    },
    {
      "epoch": 1.3478860294117647,
      "grad_norm": 1.1362016201019287,
      "learning_rate": 6.121702127659574e-06,
      "loss": 0.0967,
      "step": 5866
    },
    {
      "epoch": 1.3481158088235294,
      "grad_norm": 1.763723373413086,
      "learning_rate": 6.120851063829788e-06,
      "loss": 0.1096,
      "step": 5867
    },
    {
      "epoch": 1.3483455882352942,
      "grad_norm": 1.4539378881454468,
      "learning_rate": 6.120000000000001e-06,
      "loss": 0.084,
      "step": 5868
    },
    {
      "epoch": 1.3485753676470589,
      "grad_norm": 1.2859859466552734,
      "learning_rate": 6.119148936170213e-06,
      "loss": 0.0925,
      "step": 5869
    },
    {
      "epoch": 1.3488051470588236,
      "grad_norm": 1.2003031969070435,
      "learning_rate": 6.118297872340426e-06,
      "loss": 0.0667,
      "step": 5870
    },
    {
      "epoch": 1.3490349264705883,
      "grad_norm": 1.0804049968719482,
      "learning_rate": 6.1174468085106385e-06,
      "loss": 0.0822,
      "step": 5871
    },
    {
      "epoch": 1.3492647058823528,
      "grad_norm": 1.0577889680862427,
      "learning_rate": 6.116595744680851e-06,
      "loss": 0.066,
      "step": 5872
    },
    {
      "epoch": 1.3494944852941178,
      "grad_norm": 1.27190101146698,
      "learning_rate": 6.115744680851065e-06,
      "loss": 0.0848,
      "step": 5873
    },
    {
      "epoch": 1.3497242647058822,
      "grad_norm": 1.0538698434829712,
      "learning_rate": 6.114893617021277e-06,
      "loss": 0.1054,
      "step": 5874
    },
    {
      "epoch": 1.3499540441176472,
      "grad_norm": 1.6118922233581543,
      "learning_rate": 6.1140425531914895e-06,
      "loss": 0.0844,
      "step": 5875
    },
    {
      "epoch": 1.3501838235294117,
      "grad_norm": 1.5331536531448364,
      "learning_rate": 6.113191489361703e-06,
      "loss": 0.1068,
      "step": 5876
    },
    {
      "epoch": 1.3504136029411764,
      "grad_norm": 0.9985169172286987,
      "learning_rate": 6.112340425531915e-06,
      "loss": 0.0848,
      "step": 5877
    },
    {
      "epoch": 1.3506433823529411,
      "grad_norm": 1.5927385091781616,
      "learning_rate": 6.111489361702129e-06,
      "loss": 0.0929,
      "step": 5878
    },
    {
      "epoch": 1.3508731617647058,
      "grad_norm": 1.7553377151489258,
      "learning_rate": 6.110638297872341e-06,
      "loss": 0.1214,
      "step": 5879
    },
    {
      "epoch": 1.3511029411764706,
      "grad_norm": 1.2341347932815552,
      "learning_rate": 6.109787234042554e-06,
      "loss": 0.0789,
      "step": 5880
    },
    {
      "epoch": 1.3513327205882353,
      "grad_norm": 1.1729953289031982,
      "learning_rate": 6.108936170212767e-06,
      "loss": 0.0847,
      "step": 5881
    },
    {
      "epoch": 1.3515625,
      "grad_norm": 1.0818185806274414,
      "learning_rate": 6.108085106382979e-06,
      "loss": 0.0834,
      "step": 5882
    },
    {
      "epoch": 1.3517922794117647,
      "grad_norm": 1.4727245569229126,
      "learning_rate": 6.1072340425531915e-06,
      "loss": 0.0825,
      "step": 5883
    },
    {
      "epoch": 1.3520220588235294,
      "grad_norm": 1.286437749862671,
      "learning_rate": 6.1063829787234055e-06,
      "loss": 0.0735,
      "step": 5884
    },
    {
      "epoch": 1.3522518382352942,
      "grad_norm": 1.0247588157653809,
      "learning_rate": 6.105531914893618e-06,
      "loss": 0.0561,
      "step": 5885
    },
    {
      "epoch": 1.3524816176470589,
      "grad_norm": 0.9822189211845398,
      "learning_rate": 6.10468085106383e-06,
      "loss": 0.0835,
      "step": 5886
    },
    {
      "epoch": 1.3527113970588236,
      "grad_norm": 1.716890573501587,
      "learning_rate": 6.103829787234043e-06,
      "loss": 0.0885,
      "step": 5887
    },
    {
      "epoch": 1.3529411764705883,
      "grad_norm": 1.5986462831497192,
      "learning_rate": 6.102978723404256e-06,
      "loss": 0.1041,
      "step": 5888
    },
    {
      "epoch": 1.3531709558823528,
      "grad_norm": 1.2515029907226562,
      "learning_rate": 6.102127659574468e-06,
      "loss": 0.0703,
      "step": 5889
    },
    {
      "epoch": 1.3534007352941178,
      "grad_norm": 0.8517219424247742,
      "learning_rate": 6.101276595744682e-06,
      "loss": 0.0593,
      "step": 5890
    },
    {
      "epoch": 1.3536305147058822,
      "grad_norm": 1.1552948951721191,
      "learning_rate": 6.100425531914894e-06,
      "loss": 0.0815,
      "step": 5891
    },
    {
      "epoch": 1.3538602941176472,
      "grad_norm": 1.6321227550506592,
      "learning_rate": 6.099574468085107e-06,
      "loss": 0.0832,
      "step": 5892
    },
    {
      "epoch": 1.3540900735294117,
      "grad_norm": 0.8418894410133362,
      "learning_rate": 6.09872340425532e-06,
      "loss": 0.0461,
      "step": 5893
    },
    {
      "epoch": 1.3543198529411764,
      "grad_norm": 1.1367241144180298,
      "learning_rate": 6.097872340425532e-06,
      "loss": 0.0614,
      "step": 5894
    },
    {
      "epoch": 1.3545496323529411,
      "grad_norm": 1.568265676498413,
      "learning_rate": 6.0970212765957444e-06,
      "loss": 0.1026,
      "step": 5895
    },
    {
      "epoch": 1.3547794117647058,
      "grad_norm": 1.303218960762024,
      "learning_rate": 6.0961702127659585e-06,
      "loss": 0.1014,
      "step": 5896
    },
    {
      "epoch": 1.3550091911764706,
      "grad_norm": 1.275026798248291,
      "learning_rate": 6.095319148936171e-06,
      "loss": 0.0887,
      "step": 5897
    },
    {
      "epoch": 1.3552389705882353,
      "grad_norm": 1.4669798612594604,
      "learning_rate": 6.094468085106383e-06,
      "loss": 0.102,
      "step": 5898
    },
    {
      "epoch": 1.35546875,
      "grad_norm": 1.7034610509872437,
      "learning_rate": 6.093617021276596e-06,
      "loss": 0.0945,
      "step": 5899
    },
    {
      "epoch": 1.3556985294117647,
      "grad_norm": 0.9581014513969421,
      "learning_rate": 6.092765957446809e-06,
      "loss": 0.0536,
      "step": 5900
    },
    {
      "epoch": 1.3559283088235294,
      "grad_norm": 1.241605520248413,
      "learning_rate": 6.091914893617022e-06,
      "loss": 0.0969,
      "step": 5901
    },
    {
      "epoch": 1.3561580882352942,
      "grad_norm": 1.2886661291122437,
      "learning_rate": 6.091063829787235e-06,
      "loss": 0.0937,
      "step": 5902
    },
    {
      "epoch": 1.3563878676470589,
      "grad_norm": 1.104318618774414,
      "learning_rate": 6.090212765957447e-06,
      "loss": 0.0657,
      "step": 5903
    },
    {
      "epoch": 1.3566176470588236,
      "grad_norm": 1.301740288734436,
      "learning_rate": 6.08936170212766e-06,
      "loss": 0.0743,
      "step": 5904
    },
    {
      "epoch": 1.3568474264705883,
      "grad_norm": 1.3697786331176758,
      "learning_rate": 6.088510638297873e-06,
      "loss": 0.1169,
      "step": 5905
    },
    {
      "epoch": 1.3570772058823528,
      "grad_norm": 1.1777442693710327,
      "learning_rate": 6.087659574468086e-06,
      "loss": 0.0693,
      "step": 5906
    },
    {
      "epoch": 1.3573069852941178,
      "grad_norm": 1.075534701347351,
      "learning_rate": 6.086808510638298e-06,
      "loss": 0.0738,
      "step": 5907
    },
    {
      "epoch": 1.3575367647058822,
      "grad_norm": 1.0123660564422607,
      "learning_rate": 6.0859574468085114e-06,
      "loss": 0.0774,
      "step": 5908
    },
    {
      "epoch": 1.3577665441176472,
      "grad_norm": 0.8561269044876099,
      "learning_rate": 6.085106382978724e-06,
      "loss": 0.0536,
      "step": 5909
    },
    {
      "epoch": 1.3579963235294117,
      "grad_norm": 1.4603087902069092,
      "learning_rate": 6.084255319148936e-06,
      "loss": 0.1212,
      "step": 5910
    },
    {
      "epoch": 1.3582261029411764,
      "grad_norm": 1.2236857414245605,
      "learning_rate": 6.08340425531915e-06,
      "loss": 0.0721,
      "step": 5911
    },
    {
      "epoch": 1.3584558823529411,
      "grad_norm": 1.4059592485427856,
      "learning_rate": 6.082553191489362e-06,
      "loss": 0.0724,
      "step": 5912
    },
    {
      "epoch": 1.3586856617647058,
      "grad_norm": 1.0964195728302002,
      "learning_rate": 6.081702127659575e-06,
      "loss": 0.0702,
      "step": 5913
    },
    {
      "epoch": 1.3589154411764706,
      "grad_norm": 1.3343250751495361,
      "learning_rate": 6.080851063829788e-06,
      "loss": 0.0694,
      "step": 5914
    },
    {
      "epoch": 1.3591452205882353,
      "grad_norm": 1.1956156492233276,
      "learning_rate": 6.08e-06,
      "loss": 0.1042,
      "step": 5915
    },
    {
      "epoch": 1.359375,
      "grad_norm": 1.7069005966186523,
      "learning_rate": 6.0791489361702126e-06,
      "loss": 0.1265,
      "step": 5916
    },
    {
      "epoch": 1.3596047794117647,
      "grad_norm": 1.4527561664581299,
      "learning_rate": 6.0782978723404266e-06,
      "loss": 0.0786,
      "step": 5917
    },
    {
      "epoch": 1.3598345588235294,
      "grad_norm": 1.036720633506775,
      "learning_rate": 6.077446808510639e-06,
      "loss": 0.0659,
      "step": 5918
    },
    {
      "epoch": 1.3600643382352942,
      "grad_norm": 1.1429613828659058,
      "learning_rate": 6.076595744680852e-06,
      "loss": 0.075,
      "step": 5919
    },
    {
      "epoch": 1.3602941176470589,
      "grad_norm": 1.1047855615615845,
      "learning_rate": 6.075744680851064e-06,
      "loss": 0.0675,
      "step": 5920
    },
    {
      "epoch": 1.3605238970588236,
      "grad_norm": 1.3257699012756348,
      "learning_rate": 6.074893617021277e-06,
      "loss": 0.0819,
      "step": 5921
    },
    {
      "epoch": 1.3607536764705883,
      "grad_norm": 1.3088040351867676,
      "learning_rate": 6.074042553191491e-06,
      "loss": 0.0766,
      "step": 5922
    },
    {
      "epoch": 1.3609834558823528,
      "grad_norm": 1.033414602279663,
      "learning_rate": 6.073191489361703e-06,
      "loss": 0.0829,
      "step": 5923
    },
    {
      "epoch": 1.3612132352941178,
      "grad_norm": 1.445578694343567,
      "learning_rate": 6.072340425531915e-06,
      "loss": 0.0853,
      "step": 5924
    },
    {
      "epoch": 1.3614430147058822,
      "grad_norm": 0.9407103657722473,
      "learning_rate": 6.0714893617021286e-06,
      "loss": 0.1036,
      "step": 5925
    },
    {
      "epoch": 1.3616727941176472,
      "grad_norm": 1.1000686883926392,
      "learning_rate": 6.070638297872341e-06,
      "loss": 0.0832,
      "step": 5926
    },
    {
      "epoch": 1.3619025735294117,
      "grad_norm": 1.2083793878555298,
      "learning_rate": 6.069787234042553e-06,
      "loss": 0.1191,
      "step": 5927
    },
    {
      "epoch": 1.3621323529411764,
      "grad_norm": 1.4529756307601929,
      "learning_rate": 6.068936170212767e-06,
      "loss": 0.0955,
      "step": 5928
    },
    {
      "epoch": 1.3623621323529411,
      "grad_norm": 1.0388635396957397,
      "learning_rate": 6.0680851063829795e-06,
      "loss": 0.0792,
      "step": 5929
    },
    {
      "epoch": 1.3625919117647058,
      "grad_norm": 1.2566500902175903,
      "learning_rate": 6.067234042553192e-06,
      "loss": 0.095,
      "step": 5930
    },
    {
      "epoch": 1.3628216911764706,
      "grad_norm": 1.3219410181045532,
      "learning_rate": 6.066382978723405e-06,
      "loss": 0.0749,
      "step": 5931
    },
    {
      "epoch": 1.3630514705882353,
      "grad_norm": 1.21226167678833,
      "learning_rate": 6.065531914893617e-06,
      "loss": 0.0693,
      "step": 5932
    },
    {
      "epoch": 1.36328125,
      "grad_norm": 1.1717643737792969,
      "learning_rate": 6.06468085106383e-06,
      "loss": 0.096,
      "step": 5933
    },
    {
      "epoch": 1.3635110294117647,
      "grad_norm": 1.3655177354812622,
      "learning_rate": 6.063829787234044e-06,
      "loss": 0.1052,
      "step": 5934
    },
    {
      "epoch": 1.3637408088235294,
      "grad_norm": 1.1838427782058716,
      "learning_rate": 6.062978723404256e-06,
      "loss": 0.1124,
      "step": 5935
    },
    {
      "epoch": 1.3639705882352942,
      "grad_norm": 1.281123399734497,
      "learning_rate": 6.062127659574468e-06,
      "loss": 0.1005,
      "step": 5936
    },
    {
      "epoch": 1.3642003676470589,
      "grad_norm": 1.184942603111267,
      "learning_rate": 6.0612765957446815e-06,
      "loss": 0.0897,
      "step": 5937
    },
    {
      "epoch": 1.3644301470588236,
      "grad_norm": 1.3037229776382446,
      "learning_rate": 6.060425531914894e-06,
      "loss": 0.1149,
      "step": 5938
    },
    {
      "epoch": 1.3646599264705883,
      "grad_norm": 1.1945396661758423,
      "learning_rate": 6.059574468085106e-06,
      "loss": 0.0836,
      "step": 5939
    },
    {
      "epoch": 1.3648897058823528,
      "grad_norm": 1.052334189414978,
      "learning_rate": 6.05872340425532e-06,
      "loss": 0.0762,
      "step": 5940
    },
    {
      "epoch": 1.3651194852941178,
      "grad_norm": 1.003274917602539,
      "learning_rate": 6.0578723404255325e-06,
      "loss": 0.0728,
      "step": 5941
    },
    {
      "epoch": 1.3653492647058822,
      "grad_norm": 1.3675708770751953,
      "learning_rate": 6.057021276595745e-06,
      "loss": 0.1137,
      "step": 5942
    },
    {
      "epoch": 1.3655790441176472,
      "grad_norm": 1.448754072189331,
      "learning_rate": 6.056170212765958e-06,
      "loss": 0.084,
      "step": 5943
    },
    {
      "epoch": 1.3658088235294117,
      "grad_norm": 1.2550039291381836,
      "learning_rate": 6.05531914893617e-06,
      "loss": 0.0708,
      "step": 5944
    },
    {
      "epoch": 1.3660386029411764,
      "grad_norm": 0.9676978588104248,
      "learning_rate": 6.054468085106383e-06,
      "loss": 0.0845,
      "step": 5945
    },
    {
      "epoch": 1.3662683823529411,
      "grad_norm": 0.8521969318389893,
      "learning_rate": 6.053617021276597e-06,
      "loss": 0.0745,
      "step": 5946
    },
    {
      "epoch": 1.3664981617647058,
      "grad_norm": 1.1200319528579712,
      "learning_rate": 6.052765957446809e-06,
      "loss": 0.0519,
      "step": 5947
    },
    {
      "epoch": 1.3667279411764706,
      "grad_norm": 1.2938504219055176,
      "learning_rate": 6.051914893617021e-06,
      "loss": 0.1174,
      "step": 5948
    },
    {
      "epoch": 1.3669577205882353,
      "grad_norm": 1.2163722515106201,
      "learning_rate": 6.0510638297872345e-06,
      "loss": 0.0681,
      "step": 5949
    },
    {
      "epoch": 1.3671875,
      "grad_norm": 1.0367285013198853,
      "learning_rate": 6.050212765957447e-06,
      "loss": 0.0572,
      "step": 5950
    },
    {
      "epoch": 1.3674172794117647,
      "grad_norm": 1.22233247756958,
      "learning_rate": 6.04936170212766e-06,
      "loss": 0.0752,
      "step": 5951
    },
    {
      "epoch": 1.3676470588235294,
      "grad_norm": 1.2085062265396118,
      "learning_rate": 6.048510638297873e-06,
      "loss": 0.0591,
      "step": 5952
    },
    {
      "epoch": 1.3678768382352942,
      "grad_norm": 1.110461711883545,
      "learning_rate": 6.0476595744680855e-06,
      "loss": 0.0615,
      "step": 5953
    },
    {
      "epoch": 1.3681066176470589,
      "grad_norm": 1.3032464981079102,
      "learning_rate": 6.046808510638298e-06,
      "loss": 0.0735,
      "step": 5954
    },
    {
      "epoch": 1.3683363970588236,
      "grad_norm": 1.4252631664276123,
      "learning_rate": 6.045957446808511e-06,
      "loss": 0.0849,
      "step": 5955
    },
    {
      "epoch": 1.3685661764705883,
      "grad_norm": 1.504171371459961,
      "learning_rate": 6.045106382978724e-06,
      "loss": 0.1054,
      "step": 5956
    },
    {
      "epoch": 1.3687959558823528,
      "grad_norm": 1.0640846490859985,
      "learning_rate": 6.0442553191489365e-06,
      "loss": 0.0605,
      "step": 5957
    },
    {
      "epoch": 1.3690257352941178,
      "grad_norm": 0.9898648858070374,
      "learning_rate": 6.04340425531915e-06,
      "loss": 0.0565,
      "step": 5958
    },
    {
      "epoch": 1.3692555147058822,
      "grad_norm": 1.8327380418777466,
      "learning_rate": 6.042553191489362e-06,
      "loss": 0.0694,
      "step": 5959
    },
    {
      "epoch": 1.3694852941176472,
      "grad_norm": 1.0631651878356934,
      "learning_rate": 6.041702127659574e-06,
      "loss": 0.0929,
      "step": 5960
    },
    {
      "epoch": 1.3697150735294117,
      "grad_norm": 0.7878411412239075,
      "learning_rate": 6.040851063829788e-06,
      "loss": 0.0512,
      "step": 5961
    },
    {
      "epoch": 1.3699448529411764,
      "grad_norm": 1.519071102142334,
      "learning_rate": 6.040000000000001e-06,
      "loss": 0.1235,
      "step": 5962
    },
    {
      "epoch": 1.3701746323529411,
      "grad_norm": 1.1003799438476562,
      "learning_rate": 6.039148936170214e-06,
      "loss": 0.087,
      "step": 5963
    },
    {
      "epoch": 1.3704044117647058,
      "grad_norm": 1.0270601511001587,
      "learning_rate": 6.038297872340426e-06,
      "loss": 0.0771,
      "step": 5964
    },
    {
      "epoch": 1.3706341911764706,
      "grad_norm": 0.9060319066047668,
      "learning_rate": 6.0374468085106384e-06,
      "loss": 0.0419,
      "step": 5965
    },
    {
      "epoch": 1.3708639705882353,
      "grad_norm": 1.19663405418396,
      "learning_rate": 6.0365957446808525e-06,
      "loss": 0.1085,
      "step": 5966
    },
    {
      "epoch": 1.37109375,
      "grad_norm": 1.43990957736969,
      "learning_rate": 6.035744680851065e-06,
      "loss": 0.0869,
      "step": 5967
    },
    {
      "epoch": 1.3713235294117647,
      "grad_norm": 1.083432674407959,
      "learning_rate": 6.034893617021277e-06,
      "loss": 0.0788,
      "step": 5968
    },
    {
      "epoch": 1.3715533088235294,
      "grad_norm": 1.3520097732543945,
      "learning_rate": 6.03404255319149e-06,
      "loss": 0.0734,
      "step": 5969
    },
    {
      "epoch": 1.3717830882352942,
      "grad_norm": 1.1694546937942505,
      "learning_rate": 6.033191489361703e-06,
      "loss": 0.0715,
      "step": 5970
    },
    {
      "epoch": 1.3720128676470589,
      "grad_norm": 1.1633532047271729,
      "learning_rate": 6.032340425531915e-06,
      "loss": 0.0713,
      "step": 5971
    },
    {
      "epoch": 1.3722426470588236,
      "grad_norm": 1.5318074226379395,
      "learning_rate": 6.031489361702129e-06,
      "loss": 0.0939,
      "step": 5972
    },
    {
      "epoch": 1.3724724264705883,
      "grad_norm": 0.9549121856689453,
      "learning_rate": 6.030638297872341e-06,
      "loss": 0.0747,
      "step": 5973
    },
    {
      "epoch": 1.3727022058823528,
      "grad_norm": 1.1853303909301758,
      "learning_rate": 6.029787234042554e-06,
      "loss": 0.0934,
      "step": 5974
    },
    {
      "epoch": 1.3729319852941178,
      "grad_norm": 1.2398728132247925,
      "learning_rate": 6.028936170212767e-06,
      "loss": 0.0873,
      "step": 5975
    },
    {
      "epoch": 1.3731617647058822,
      "grad_norm": 1.0564097166061401,
      "learning_rate": 6.028085106382979e-06,
      "loss": 0.0692,
      "step": 5976
    },
    {
      "epoch": 1.3733915441176472,
      "grad_norm": 2.9255542755126953,
      "learning_rate": 6.027234042553191e-06,
      "loss": 0.0648,
      "step": 5977
    },
    {
      "epoch": 1.3736213235294117,
      "grad_norm": 1.2497271299362183,
      "learning_rate": 6.026382978723405e-06,
      "loss": 0.0979,
      "step": 5978
    },
    {
      "epoch": 1.3738511029411764,
      "grad_norm": 1.2504544258117676,
      "learning_rate": 6.025531914893618e-06,
      "loss": 0.0825,
      "step": 5979
    },
    {
      "epoch": 1.3740808823529411,
      "grad_norm": 0.9406085014343262,
      "learning_rate": 6.02468085106383e-06,
      "loss": 0.0783,
      "step": 5980
    },
    {
      "epoch": 1.3743106617647058,
      "grad_norm": 0.9112772941589355,
      "learning_rate": 6.023829787234043e-06,
      "loss": 0.0617,
      "step": 5981
    },
    {
      "epoch": 1.3745404411764706,
      "grad_norm": 1.2702823877334595,
      "learning_rate": 6.0229787234042556e-06,
      "loss": 0.0596,
      "step": 5982
    },
    {
      "epoch": 1.3747702205882353,
      "grad_norm": 1.0673158168792725,
      "learning_rate": 6.022127659574468e-06,
      "loss": 0.0743,
      "step": 5983
    },
    {
      "epoch": 1.375,
      "grad_norm": 1.1768125295639038,
      "learning_rate": 6.021276595744682e-06,
      "loss": 0.092,
      "step": 5984
    },
    {
      "epoch": 1.3752297794117647,
      "grad_norm": 1.311535120010376,
      "learning_rate": 6.020425531914894e-06,
      "loss": 0.0969,
      "step": 5985
    },
    {
      "epoch": 1.3754595588235294,
      "grad_norm": 1.660009503364563,
      "learning_rate": 6.0195744680851065e-06,
      "loss": 0.093,
      "step": 5986
    },
    {
      "epoch": 1.3756893382352942,
      "grad_norm": 1.3122575283050537,
      "learning_rate": 6.01872340425532e-06,
      "loss": 0.0654,
      "step": 5987
    },
    {
      "epoch": 1.3759191176470589,
      "grad_norm": 1.3097617626190186,
      "learning_rate": 6.017872340425532e-06,
      "loss": 0.0889,
      "step": 5988
    },
    {
      "epoch": 1.3761488970588236,
      "grad_norm": 1.4421249628067017,
      "learning_rate": 6.017021276595744e-06,
      "loss": 0.0871,
      "step": 5989
    },
    {
      "epoch": 1.3763786764705883,
      "grad_norm": 1.2221697568893433,
      "learning_rate": 6.016170212765958e-06,
      "loss": 0.0674,
      "step": 5990
    },
    {
      "epoch": 1.3766084558823528,
      "grad_norm": 1.5552853345870972,
      "learning_rate": 6.015319148936171e-06,
      "loss": 0.126,
      "step": 5991
    },
    {
      "epoch": 1.3768382352941178,
      "grad_norm": 1.4072569608688354,
      "learning_rate": 6.014468085106383e-06,
      "loss": 0.0994,
      "step": 5992
    },
    {
      "epoch": 1.3770680147058822,
      "grad_norm": 1.0033010244369507,
      "learning_rate": 6.013617021276596e-06,
      "loss": 0.06,
      "step": 5993
    },
    {
      "epoch": 1.3772977941176472,
      "grad_norm": 1.6824052333831787,
      "learning_rate": 6.0127659574468085e-06,
      "loss": 0.0876,
      "step": 5994
    },
    {
      "epoch": 1.3775275735294117,
      "grad_norm": 1.3120672702789307,
      "learning_rate": 6.011914893617022e-06,
      "loss": 0.0771,
      "step": 5995
    },
    {
      "epoch": 1.3777573529411764,
      "grad_norm": 0.9782910943031311,
      "learning_rate": 6.011063829787235e-06,
      "loss": 0.068,
      "step": 5996
    },
    {
      "epoch": 1.3779871323529411,
      "grad_norm": 1.464971899986267,
      "learning_rate": 6.010212765957447e-06,
      "loss": 0.0885,
      "step": 5997
    },
    {
      "epoch": 1.3782169117647058,
      "grad_norm": 1.2192200422286987,
      "learning_rate": 6.0093617021276595e-06,
      "loss": 0.0887,
      "step": 5998
    },
    {
      "epoch": 1.3784466911764706,
      "grad_norm": 1.391596794128418,
      "learning_rate": 6.008510638297873e-06,
      "loss": 0.0784,
      "step": 5999
    },
    {
      "epoch": 1.3786764705882353,
      "grad_norm": 1.2287867069244385,
      "learning_rate": 6.007659574468086e-06,
      "loss": 0.0978,
      "step": 6000
    },
    {
      "epoch": 1.3786764705882353,
      "eval_loss": 0.08776329457759857,
      "eval_runtime": 1966.1228,
      "eval_samples_per_second": 4.53,
      "eval_steps_per_second": 2.265,
      "step": 6000
    },
    {
      "epoch": 1.37890625,
      "grad_norm": 1.4801194667816162,
      "learning_rate": 6.006808510638298e-06,
      "loss": 0.0929,
      "step": 6001
    },
    {
      "epoch": 1.3791360294117647,
      "grad_norm": 1.0008535385131836,
      "learning_rate": 6.005957446808511e-06,
      "loss": 0.063,
      "step": 6002
    },
    {
      "epoch": 1.3793658088235294,
      "grad_norm": 1.159027099609375,
      "learning_rate": 6.005106382978724e-06,
      "loss": 0.0805,
      "step": 6003
    },
    {
      "epoch": 1.3795955882352942,
      "grad_norm": 1.2717338800430298,
      "learning_rate": 6.004255319148936e-06,
      "loss": 0.1031,
      "step": 6004
    },
    {
      "epoch": 1.3798253676470589,
      "grad_norm": 1.0020407438278198,
      "learning_rate": 6.00340425531915e-06,
      "loss": 0.0789,
      "step": 6005
    },
    {
      "epoch": 1.3800551470588236,
      "grad_norm": 0.9273179769515991,
      "learning_rate": 6.002553191489362e-06,
      "loss": 0.0578,
      "step": 6006
    },
    {
      "epoch": 1.3802849264705883,
      "grad_norm": 1.2905772924423218,
      "learning_rate": 6.0017021276595755e-06,
      "loss": 0.0963,
      "step": 6007
    },
    {
      "epoch": 1.3805147058823528,
      "grad_norm": 1.0182464122772217,
      "learning_rate": 6.000851063829788e-06,
      "loss": 0.0874,
      "step": 6008
    },
    {
      "epoch": 1.3807444852941178,
      "grad_norm": 1.0290642976760864,
      "learning_rate": 6e-06,
      "loss": 0.09,
      "step": 6009
    },
    {
      "epoch": 1.3809742647058822,
      "grad_norm": 1.047532320022583,
      "learning_rate": 5.999148936170214e-06,
      "loss": 0.0695,
      "step": 6010
    },
    {
      "epoch": 1.3812040441176472,
      "grad_norm": 1.495263695716858,
      "learning_rate": 5.9982978723404265e-06,
      "loss": 0.1195,
      "step": 6011
    },
    {
      "epoch": 1.3814338235294117,
      "grad_norm": 1.2189584970474243,
      "learning_rate": 5.997446808510639e-06,
      "loss": 0.0735,
      "step": 6012
    },
    {
      "epoch": 1.3816636029411764,
      "grad_norm": 1.1943228244781494,
      "learning_rate": 5.996595744680852e-06,
      "loss": 0.0807,
      "step": 6013
    },
    {
      "epoch": 1.3818933823529411,
      "grad_norm": 1.2015795707702637,
      "learning_rate": 5.995744680851064e-06,
      "loss": 0.0736,
      "step": 6014
    },
    {
      "epoch": 1.3821231617647058,
      "grad_norm": 1.118043065071106,
      "learning_rate": 5.994893617021277e-06,
      "loss": 0.0655,
      "step": 6015
    },
    {
      "epoch": 1.3823529411764706,
      "grad_norm": 1.4096027612686157,
      "learning_rate": 5.994042553191491e-06,
      "loss": 0.1008,
      "step": 6016
    },
    {
      "epoch": 1.3825827205882353,
      "grad_norm": 1.3652420043945312,
      "learning_rate": 5.993191489361703e-06,
      "loss": 0.0672,
      "step": 6017
    },
    {
      "epoch": 1.3828125,
      "grad_norm": 1.463780403137207,
      "learning_rate": 5.992340425531915e-06,
      "loss": 0.1375,
      "step": 6018
    },
    {
      "epoch": 1.3830422794117647,
      "grad_norm": 1.4684247970581055,
      "learning_rate": 5.9914893617021285e-06,
      "loss": 0.0891,
      "step": 6019
    },
    {
      "epoch": 1.3832720588235294,
      "grad_norm": 1.0096254348754883,
      "learning_rate": 5.990638297872341e-06,
      "loss": 0.0827,
      "step": 6020
    },
    {
      "epoch": 1.3835018382352942,
      "grad_norm": 1.5091880559921265,
      "learning_rate": 5.989787234042553e-06,
      "loss": 0.0995,
      "step": 6021
    },
    {
      "epoch": 1.3837316176470589,
      "grad_norm": 0.8819076418876648,
      "learning_rate": 5.988936170212767e-06,
      "loss": 0.0633,
      "step": 6022
    },
    {
      "epoch": 1.3839613970588236,
      "grad_norm": 1.0200004577636719,
      "learning_rate": 5.9880851063829795e-06,
      "loss": 0.0891,
      "step": 6023
    },
    {
      "epoch": 1.3841911764705883,
      "grad_norm": 1.3166030645370483,
      "learning_rate": 5.987234042553192e-06,
      "loss": 0.1134,
      "step": 6024
    },
    {
      "epoch": 1.3844209558823528,
      "grad_norm": 1.4243090152740479,
      "learning_rate": 5.986382978723405e-06,
      "loss": 0.1067,
      "step": 6025
    },
    {
      "epoch": 1.3846507352941178,
      "grad_norm": 0.9632263779640198,
      "learning_rate": 5.985531914893617e-06,
      "loss": 0.0756,
      "step": 6026
    },
    {
      "epoch": 1.3848805147058822,
      "grad_norm": 1.2416093349456787,
      "learning_rate": 5.98468085106383e-06,
      "loss": 0.0559,
      "step": 6027
    },
    {
      "epoch": 1.3851102941176472,
      "grad_norm": 1.2539311647415161,
      "learning_rate": 5.983829787234044e-06,
      "loss": 0.0879,
      "step": 6028
    },
    {
      "epoch": 1.3853400735294117,
      "grad_norm": 1.4010735750198364,
      "learning_rate": 5.982978723404256e-06,
      "loss": 0.0739,
      "step": 6029
    },
    {
      "epoch": 1.3855698529411764,
      "grad_norm": 1.082714319229126,
      "learning_rate": 5.982127659574468e-06,
      "loss": 0.0943,
      "step": 6030
    },
    {
      "epoch": 1.3857996323529411,
      "grad_norm": 0.9174247980117798,
      "learning_rate": 5.9812765957446814e-06,
      "loss": 0.0525,
      "step": 6031
    },
    {
      "epoch": 1.3860294117647058,
      "grad_norm": 1.2068393230438232,
      "learning_rate": 5.980425531914894e-06,
      "loss": 0.0829,
      "step": 6032
    },
    {
      "epoch": 1.3862591911764706,
      "grad_norm": 0.9477477669715881,
      "learning_rate": 5.979574468085106e-06,
      "loss": 0.0788,
      "step": 6033
    },
    {
      "epoch": 1.3864889705882353,
      "grad_norm": 1.2760971784591675,
      "learning_rate": 5.97872340425532e-06,
      "loss": 0.0806,
      "step": 6034
    },
    {
      "epoch": 1.38671875,
      "grad_norm": 1.6014151573181152,
      "learning_rate": 5.977872340425532e-06,
      "loss": 0.0717,
      "step": 6035
    },
    {
      "epoch": 1.3869485294117647,
      "grad_norm": 1.2786238193511963,
      "learning_rate": 5.977021276595745e-06,
      "loss": 0.0802,
      "step": 6036
    },
    {
      "epoch": 1.3871783088235294,
      "grad_norm": 0.9081166982650757,
      "learning_rate": 5.976170212765958e-06,
      "loss": 0.0664,
      "step": 6037
    },
    {
      "epoch": 1.3874080882352942,
      "grad_norm": 1.5483460426330566,
      "learning_rate": 5.97531914893617e-06,
      "loss": 0.1079,
      "step": 6038
    },
    {
      "epoch": 1.3876378676470589,
      "grad_norm": 1.2764742374420166,
      "learning_rate": 5.9744680851063826e-06,
      "loss": 0.07,
      "step": 6039
    },
    {
      "epoch": 1.3878676470588236,
      "grad_norm": 1.549773931503296,
      "learning_rate": 5.973617021276597e-06,
      "loss": 0.0879,
      "step": 6040
    },
    {
      "epoch": 1.3880974264705883,
      "grad_norm": 1.0390297174453735,
      "learning_rate": 5.972765957446809e-06,
      "loss": 0.0705,
      "step": 6041
    },
    {
      "epoch": 1.3883272058823528,
      "grad_norm": 1.433236002922058,
      "learning_rate": 5.971914893617021e-06,
      "loss": 0.0996,
      "step": 6042
    },
    {
      "epoch": 1.3885569852941178,
      "grad_norm": 1.0827070474624634,
      "learning_rate": 5.971063829787234e-06,
      "loss": 0.0729,
      "step": 6043
    },
    {
      "epoch": 1.3887867647058822,
      "grad_norm": 1.2219716310501099,
      "learning_rate": 5.970212765957447e-06,
      "loss": 0.1156,
      "step": 6044
    },
    {
      "epoch": 1.3890165441176472,
      "grad_norm": 1.3055323362350464,
      "learning_rate": 5.96936170212766e-06,
      "loss": 0.0597,
      "step": 6045
    },
    {
      "epoch": 1.3892463235294117,
      "grad_norm": 1.1085736751556396,
      "learning_rate": 5.968510638297873e-06,
      "loss": 0.0905,
      "step": 6046
    },
    {
      "epoch": 1.3894761029411764,
      "grad_norm": 1.1366556882858276,
      "learning_rate": 5.967659574468085e-06,
      "loss": 0.07,
      "step": 6047
    },
    {
      "epoch": 1.3897058823529411,
      "grad_norm": 1.704357624053955,
      "learning_rate": 5.9668085106382986e-06,
      "loss": 0.0698,
      "step": 6048
    },
    {
      "epoch": 1.3899356617647058,
      "grad_norm": 1.0462156534194946,
      "learning_rate": 5.965957446808511e-06,
      "loss": 0.083,
      "step": 6049
    },
    {
      "epoch": 1.3901654411764706,
      "grad_norm": 1.1901452541351318,
      "learning_rate": 5.965106382978724e-06,
      "loss": 0.0691,
      "step": 6050
    },
    {
      "epoch": 1.3903952205882353,
      "grad_norm": 1.5200549364089966,
      "learning_rate": 5.964255319148937e-06,
      "loss": 0.0739,
      "step": 6051
    },
    {
      "epoch": 1.390625,
      "grad_norm": 0.96270751953125,
      "learning_rate": 5.9634042553191495e-06,
      "loss": 0.0357,
      "step": 6052
    },
    {
      "epoch": 1.3908547794117647,
      "grad_norm": 1.2006343603134155,
      "learning_rate": 5.962553191489362e-06,
      "loss": 0.0761,
      "step": 6053
    },
    {
      "epoch": 1.3910845588235294,
      "grad_norm": 1.1588072776794434,
      "learning_rate": 5.961702127659575e-06,
      "loss": 0.061,
      "step": 6054
    },
    {
      "epoch": 1.3913143382352942,
      "grad_norm": 1.5572803020477295,
      "learning_rate": 5.960851063829788e-06,
      "loss": 0.0798,
      "step": 6055
    },
    {
      "epoch": 1.3915441176470589,
      "grad_norm": 1.1217328310012817,
      "learning_rate": 5.9600000000000005e-06,
      "loss": 0.0805,
      "step": 6056
    },
    {
      "epoch": 1.3917738970588236,
      "grad_norm": 1.1743704080581665,
      "learning_rate": 5.959148936170214e-06,
      "loss": 0.0658,
      "step": 6057
    },
    {
      "epoch": 1.3920036764705883,
      "grad_norm": 1.2900409698486328,
      "learning_rate": 5.958297872340426e-06,
      "loss": 0.0768,
      "step": 6058
    },
    {
      "epoch": 1.3922334558823528,
      "grad_norm": 1.2374073266983032,
      "learning_rate": 5.957446808510638e-06,
      "loss": 0.0773,
      "step": 6059
    },
    {
      "epoch": 1.3924632352941178,
      "grad_norm": 1.1059260368347168,
      "learning_rate": 5.956595744680852e-06,
      "loss": 0.0624,
      "step": 6060
    },
    {
      "epoch": 1.3926930147058822,
      "grad_norm": 1.5650068521499634,
      "learning_rate": 5.955744680851065e-06,
      "loss": 0.1157,
      "step": 6061
    },
    {
      "epoch": 1.3929227941176472,
      "grad_norm": 1.153624176979065,
      "learning_rate": 5.954893617021277e-06,
      "loss": 0.0819,
      "step": 6062
    },
    {
      "epoch": 1.3931525735294117,
      "grad_norm": 1.1069085597991943,
      "learning_rate": 5.95404255319149e-06,
      "loss": 0.0639,
      "step": 6063
    },
    {
      "epoch": 1.3933823529411764,
      "grad_norm": 1.2299387454986572,
      "learning_rate": 5.9531914893617025e-06,
      "loss": 0.0776,
      "step": 6064
    },
    {
      "epoch": 1.3936121323529411,
      "grad_norm": 1.3134868144989014,
      "learning_rate": 5.952340425531915e-06,
      "loss": 0.0619,
      "step": 6065
    },
    {
      "epoch": 1.3938419117647058,
      "grad_norm": 1.7909437417984009,
      "learning_rate": 5.951489361702129e-06,
      "loss": 0.1297,
      "step": 6066
    },
    {
      "epoch": 1.3940716911764706,
      "grad_norm": 1.3254210948944092,
      "learning_rate": 5.950638297872341e-06,
      "loss": 0.0809,
      "step": 6067
    },
    {
      "epoch": 1.3943014705882353,
      "grad_norm": 0.8446853756904602,
      "learning_rate": 5.9497872340425535e-06,
      "loss": 0.0782,
      "step": 6068
    },
    {
      "epoch": 1.39453125,
      "grad_norm": 1.2509490251541138,
      "learning_rate": 5.948936170212767e-06,
      "loss": 0.0886,
      "step": 6069
    },
    {
      "epoch": 1.3947610294117647,
      "grad_norm": 0.9362255930900574,
      "learning_rate": 5.948085106382979e-06,
      "loss": 0.0391,
      "step": 6070
    },
    {
      "epoch": 1.3949908088235294,
      "grad_norm": 1.529229760169983,
      "learning_rate": 5.947234042553191e-06,
      "loss": 0.0882,
      "step": 6071
    },
    {
      "epoch": 1.3952205882352942,
      "grad_norm": 1.2056745290756226,
      "learning_rate": 5.946382978723405e-06,
      "loss": 0.086,
      "step": 6072
    },
    {
      "epoch": 1.3954503676470589,
      "grad_norm": 1.0733128786087036,
      "learning_rate": 5.945531914893618e-06,
      "loss": 0.0751,
      "step": 6073
    },
    {
      "epoch": 1.3956801470588236,
      "grad_norm": 1.5762089490890503,
      "learning_rate": 5.94468085106383e-06,
      "loss": 0.1375,
      "step": 6074
    },
    {
      "epoch": 1.3959099264705883,
      "grad_norm": 0.9953545331954956,
      "learning_rate": 5.943829787234043e-06,
      "loss": 0.0597,
      "step": 6075
    },
    {
      "epoch": 1.3961397058823528,
      "grad_norm": 1.2686856985092163,
      "learning_rate": 5.9429787234042555e-06,
      "loss": 0.0922,
      "step": 6076
    },
    {
      "epoch": 1.3963694852941178,
      "grad_norm": 0.9946507215499878,
      "learning_rate": 5.942127659574468e-06,
      "loss": 0.0714,
      "step": 6077
    },
    {
      "epoch": 1.3965992647058822,
      "grad_norm": 1.2125555276870728,
      "learning_rate": 5.941276595744682e-06,
      "loss": 0.0759,
      "step": 6078
    },
    {
      "epoch": 1.3968290441176472,
      "grad_norm": 1.2667471170425415,
      "learning_rate": 5.940425531914894e-06,
      "loss": 0.0788,
      "step": 6079
    },
    {
      "epoch": 1.3970588235294117,
      "grad_norm": 1.3890111446380615,
      "learning_rate": 5.9395744680851065e-06,
      "loss": 0.0647,
      "step": 6080
    },
    {
      "epoch": 1.3972886029411764,
      "grad_norm": 1.3247785568237305,
      "learning_rate": 5.93872340425532e-06,
      "loss": 0.0693,
      "step": 6081
    },
    {
      "epoch": 1.3975183823529411,
      "grad_norm": 1.0705339908599854,
      "learning_rate": 5.937872340425532e-06,
      "loss": 0.0597,
      "step": 6082
    },
    {
      "epoch": 1.3977481617647058,
      "grad_norm": 1.5807628631591797,
      "learning_rate": 5.937021276595744e-06,
      "loss": 0.0866,
      "step": 6083
    },
    {
      "epoch": 1.3979779411764706,
      "grad_norm": 1.2313734292984009,
      "learning_rate": 5.936170212765958e-06,
      "loss": 0.0799,
      "step": 6084
    },
    {
      "epoch": 1.3982077205882353,
      "grad_norm": 1.633609652519226,
      "learning_rate": 5.935319148936171e-06,
      "loss": 0.1148,
      "step": 6085
    },
    {
      "epoch": 1.3984375,
      "grad_norm": 1.055600643157959,
      "learning_rate": 5.934468085106383e-06,
      "loss": 0.0707,
      "step": 6086
    },
    {
      "epoch": 1.3986672794117647,
      "grad_norm": 1.0000605583190918,
      "learning_rate": 5.933617021276596e-06,
      "loss": 0.0684,
      "step": 6087
    },
    {
      "epoch": 1.3988970588235294,
      "grad_norm": 1.1388953924179077,
      "learning_rate": 5.9327659574468084e-06,
      "loss": 0.0916,
      "step": 6088
    },
    {
      "epoch": 1.3991268382352942,
      "grad_norm": 1.3058712482452393,
      "learning_rate": 5.931914893617022e-06,
      "loss": 0.0792,
      "step": 6089
    },
    {
      "epoch": 1.3993566176470589,
      "grad_norm": 1.6071243286132812,
      "learning_rate": 5.931063829787235e-06,
      "loss": 0.1347,
      "step": 6090
    },
    {
      "epoch": 1.3995863970588236,
      "grad_norm": 1.1069296598434448,
      "learning_rate": 5.930212765957447e-06,
      "loss": 0.0626,
      "step": 6091
    },
    {
      "epoch": 1.3998161764705883,
      "grad_norm": 1.2426339387893677,
      "learning_rate": 5.92936170212766e-06,
      "loss": 0.0895,
      "step": 6092
    },
    {
      "epoch": 1.4000459558823528,
      "grad_norm": 1.1944835186004639,
      "learning_rate": 5.928510638297873e-06,
      "loss": 0.0858,
      "step": 6093
    },
    {
      "epoch": 1.4002757352941178,
      "grad_norm": 1.0951489210128784,
      "learning_rate": 5.927659574468086e-06,
      "loss": 0.0768,
      "step": 6094
    },
    {
      "epoch": 1.4005055147058822,
      "grad_norm": 0.926216721534729,
      "learning_rate": 5.926808510638299e-06,
      "loss": 0.096,
      "step": 6095
    },
    {
      "epoch": 1.4007352941176472,
      "grad_norm": 1.0126608610153198,
      "learning_rate": 5.925957446808511e-06,
      "loss": 0.0773,
      "step": 6096
    },
    {
      "epoch": 1.4009650735294117,
      "grad_norm": 0.9876892566680908,
      "learning_rate": 5.925106382978724e-06,
      "loss": 0.0646,
      "step": 6097
    },
    {
      "epoch": 1.4011948529411764,
      "grad_norm": 1.3645089864730835,
      "learning_rate": 5.924255319148937e-06,
      "loss": 0.0958,
      "step": 6098
    },
    {
      "epoch": 1.4014246323529411,
      "grad_norm": 0.9523301720619202,
      "learning_rate": 5.92340425531915e-06,
      "loss": 0.062,
      "step": 6099
    },
    {
      "epoch": 1.4016544117647058,
      "grad_norm": 1.4150965213775635,
      "learning_rate": 5.922553191489362e-06,
      "loss": 0.0651,
      "step": 6100
    },
    {
      "epoch": 1.4018841911764706,
      "grad_norm": 1.5229265689849854,
      "learning_rate": 5.9217021276595754e-06,
      "loss": 0.0975,
      "step": 6101
    },
    {
      "epoch": 1.4021139705882353,
      "grad_norm": 1.3454018831253052,
      "learning_rate": 5.920851063829788e-06,
      "loss": 0.0774,
      "step": 6102
    },
    {
      "epoch": 1.40234375,
      "grad_norm": 1.2142378091812134,
      "learning_rate": 5.92e-06,
      "loss": 0.1056,
      "step": 6103
    },
    {
      "epoch": 1.4025735294117647,
      "grad_norm": 1.4116426706314087,
      "learning_rate": 5.919148936170214e-06,
      "loss": 0.1121,
      "step": 6104
    },
    {
      "epoch": 1.4028033088235294,
      "grad_norm": 1.2091203927993774,
      "learning_rate": 5.918297872340426e-06,
      "loss": 0.0821,
      "step": 6105
    },
    {
      "epoch": 1.4030330882352942,
      "grad_norm": 1.3958687782287598,
      "learning_rate": 5.917446808510639e-06,
      "loss": 0.0997,
      "step": 6106
    },
    {
      "epoch": 1.4032628676470589,
      "grad_norm": 1.0790812969207764,
      "learning_rate": 5.916595744680852e-06,
      "loss": 0.0661,
      "step": 6107
    },
    {
      "epoch": 1.4034926470588236,
      "grad_norm": 1.0021145343780518,
      "learning_rate": 5.915744680851064e-06,
      "loss": 0.0731,
      "step": 6108
    },
    {
      "epoch": 1.4037224264705883,
      "grad_norm": 1.2787164449691772,
      "learning_rate": 5.9148936170212766e-06,
      "loss": 0.0944,
      "step": 6109
    },
    {
      "epoch": 1.4039522058823528,
      "grad_norm": 1.1778372526168823,
      "learning_rate": 5.9140425531914906e-06,
      "loss": 0.0986,
      "step": 6110
    },
    {
      "epoch": 1.4041819852941178,
      "grad_norm": 1.1241930723190308,
      "learning_rate": 5.913191489361703e-06,
      "loss": 0.0805,
      "step": 6111
    },
    {
      "epoch": 1.4044117647058822,
      "grad_norm": 0.9145668148994446,
      "learning_rate": 5.912340425531915e-06,
      "loss": 0.0636,
      "step": 6112
    },
    {
      "epoch": 1.4046415441176472,
      "grad_norm": 1.4972025156021118,
      "learning_rate": 5.911489361702128e-06,
      "loss": 0.0971,
      "step": 6113
    },
    {
      "epoch": 1.4048713235294117,
      "grad_norm": 1.1136558055877686,
      "learning_rate": 5.910638297872341e-06,
      "loss": 0.086,
      "step": 6114
    },
    {
      "epoch": 1.4051011029411764,
      "grad_norm": 1.263968825340271,
      "learning_rate": 5.909787234042553e-06,
      "loss": 0.0918,
      "step": 6115
    },
    {
      "epoch": 1.4053308823529411,
      "grad_norm": 1.484976887702942,
      "learning_rate": 5.908936170212767e-06,
      "loss": 0.079,
      "step": 6116
    },
    {
      "epoch": 1.4055606617647058,
      "grad_norm": 1.2147122621536255,
      "learning_rate": 5.908085106382979e-06,
      "loss": 0.0776,
      "step": 6117
    },
    {
      "epoch": 1.4057904411764706,
      "grad_norm": 1.1755508184432983,
      "learning_rate": 5.907234042553192e-06,
      "loss": 0.0835,
      "step": 6118
    },
    {
      "epoch": 1.4060202205882353,
      "grad_norm": 1.2678605318069458,
      "learning_rate": 5.906382978723405e-06,
      "loss": 0.0749,
      "step": 6119
    },
    {
      "epoch": 1.40625,
      "grad_norm": 1.0555598735809326,
      "learning_rate": 5.905531914893617e-06,
      "loss": 0.0819,
      "step": 6120
    },
    {
      "epoch": 1.4064797794117647,
      "grad_norm": 1.1107723712921143,
      "learning_rate": 5.9046808510638295e-06,
      "loss": 0.0726,
      "step": 6121
    },
    {
      "epoch": 1.4067095588235294,
      "grad_norm": 1.3728021383285522,
      "learning_rate": 5.9038297872340435e-06,
      "loss": 0.0738,
      "step": 6122
    },
    {
      "epoch": 1.4069393382352942,
      "grad_norm": 1.5328937768936157,
      "learning_rate": 5.902978723404256e-06,
      "loss": 0.1002,
      "step": 6123
    },
    {
      "epoch": 1.4071691176470589,
      "grad_norm": 1.3360291719436646,
      "learning_rate": 5.902127659574468e-06,
      "loss": 0.0756,
      "step": 6124
    },
    {
      "epoch": 1.4073988970588236,
      "grad_norm": 1.0684305429458618,
      "learning_rate": 5.901276595744681e-06,
      "loss": 0.0685,
      "step": 6125
    },
    {
      "epoch": 1.4076286764705883,
      "grad_norm": 1.5991487503051758,
      "learning_rate": 5.900425531914894e-06,
      "loss": 0.113,
      "step": 6126
    },
    {
      "epoch": 1.4078584558823528,
      "grad_norm": 1.5178707838058472,
      "learning_rate": 5.899574468085106e-06,
      "loss": 0.1291,
      "step": 6127
    },
    {
      "epoch": 1.4080882352941178,
      "grad_norm": 1.040444254875183,
      "learning_rate": 5.89872340425532e-06,
      "loss": 0.0705,
      "step": 6128
    },
    {
      "epoch": 1.4083180147058822,
      "grad_norm": 1.303663730621338,
      "learning_rate": 5.897872340425532e-06,
      "loss": 0.0767,
      "step": 6129
    },
    {
      "epoch": 1.4085477941176472,
      "grad_norm": 1.077976942062378,
      "learning_rate": 5.897021276595745e-06,
      "loss": 0.0701,
      "step": 6130
    },
    {
      "epoch": 1.4087775735294117,
      "grad_norm": 1.088322639465332,
      "learning_rate": 5.896170212765958e-06,
      "loss": 0.0871,
      "step": 6131
    },
    {
      "epoch": 1.4090073529411764,
      "grad_norm": 1.1383205652236938,
      "learning_rate": 5.89531914893617e-06,
      "loss": 0.0861,
      "step": 6132
    },
    {
      "epoch": 1.4092371323529411,
      "grad_norm": 1.1400575637817383,
      "learning_rate": 5.894468085106383e-06,
      "loss": 0.1125,
      "step": 6133
    },
    {
      "epoch": 1.4094669117647058,
      "grad_norm": 1.2258405685424805,
      "learning_rate": 5.8936170212765965e-06,
      "loss": 0.0988,
      "step": 6134
    },
    {
      "epoch": 1.4096966911764706,
      "grad_norm": 1.4203625917434692,
      "learning_rate": 5.892765957446809e-06,
      "loss": 0.095,
      "step": 6135
    },
    {
      "epoch": 1.4099264705882353,
      "grad_norm": 1.2511327266693115,
      "learning_rate": 5.891914893617022e-06,
      "loss": 0.0785,
      "step": 6136
    },
    {
      "epoch": 1.41015625,
      "grad_norm": 1.309775710105896,
      "learning_rate": 5.891063829787234e-06,
      "loss": 0.0997,
      "step": 6137
    },
    {
      "epoch": 1.4103860294117647,
      "grad_norm": 1.1861464977264404,
      "learning_rate": 5.890212765957447e-06,
      "loss": 0.0763,
      "step": 6138
    },
    {
      "epoch": 1.4106158088235294,
      "grad_norm": 1.1562420129776,
      "learning_rate": 5.889361702127661e-06,
      "loss": 0.0841,
      "step": 6139
    },
    {
      "epoch": 1.4108455882352942,
      "grad_norm": 1.043995976448059,
      "learning_rate": 5.888510638297873e-06,
      "loss": 0.0789,
      "step": 6140
    },
    {
      "epoch": 1.4110753676470589,
      "grad_norm": 1.077606201171875,
      "learning_rate": 5.887659574468085e-06,
      "loss": 0.0929,
      "step": 6141
    },
    {
      "epoch": 1.4113051470588236,
      "grad_norm": 0.958001971244812,
      "learning_rate": 5.8868085106382985e-06,
      "loss": 0.0742,
      "step": 6142
    },
    {
      "epoch": 1.4115349264705883,
      "grad_norm": 1.2248693704605103,
      "learning_rate": 5.885957446808511e-06,
      "loss": 0.0974,
      "step": 6143
    },
    {
      "epoch": 1.4117647058823528,
      "grad_norm": 1.176592469215393,
      "learning_rate": 5.885106382978724e-06,
      "loss": 0.0797,
      "step": 6144
    },
    {
      "epoch": 1.4119944852941178,
      "grad_norm": 1.0695794820785522,
      "learning_rate": 5.884255319148937e-06,
      "loss": 0.0797,
      "step": 6145
    },
    {
      "epoch": 1.4122242647058822,
      "grad_norm": 1.5524775981903076,
      "learning_rate": 5.8834042553191495e-06,
      "loss": 0.1099,
      "step": 6146
    },
    {
      "epoch": 1.4124540441176472,
      "grad_norm": 1.1198941469192505,
      "learning_rate": 5.882553191489362e-06,
      "loss": 0.0647,
      "step": 6147
    },
    {
      "epoch": 1.4126838235294117,
      "grad_norm": 0.9776079058647156,
      "learning_rate": 5.881702127659575e-06,
      "loss": 0.0755,
      "step": 6148
    },
    {
      "epoch": 1.4129136029411764,
      "grad_norm": 1.3062595129013062,
      "learning_rate": 5.880851063829788e-06,
      "loss": 0.1288,
      "step": 6149
    },
    {
      "epoch": 1.4131433823529411,
      "grad_norm": 1.0748631954193115,
      "learning_rate": 5.8800000000000005e-06,
      "loss": 0.0916,
      "step": 6150
    },
    {
      "epoch": 1.4133731617647058,
      "grad_norm": 1.2832764387130737,
      "learning_rate": 5.879148936170214e-06,
      "loss": 0.0787,
      "step": 6151
    },
    {
      "epoch": 1.4136029411764706,
      "grad_norm": 1.1626367568969727,
      "learning_rate": 5.878297872340426e-06,
      "loss": 0.0916,
      "step": 6152
    },
    {
      "epoch": 1.4138327205882353,
      "grad_norm": 1.0928304195404053,
      "learning_rate": 5.877446808510638e-06,
      "loss": 0.0653,
      "step": 6153
    },
    {
      "epoch": 1.4140625,
      "grad_norm": 1.2307006120681763,
      "learning_rate": 5.876595744680852e-06,
      "loss": 0.0787,
      "step": 6154
    },
    {
      "epoch": 1.4142922794117647,
      "grad_norm": 1.1427321434020996,
      "learning_rate": 5.875744680851065e-06,
      "loss": 0.0697,
      "step": 6155
    },
    {
      "epoch": 1.4145220588235294,
      "grad_norm": 1.2085635662078857,
      "learning_rate": 5.874893617021277e-06,
      "loss": 0.0755,
      "step": 6156
    },
    {
      "epoch": 1.4147518382352942,
      "grad_norm": 1.7239482402801514,
      "learning_rate": 5.87404255319149e-06,
      "loss": 0.0729,
      "step": 6157
    },
    {
      "epoch": 1.4149816176470589,
      "grad_norm": 1.0030337572097778,
      "learning_rate": 5.8731914893617024e-06,
      "loss": 0.0648,
      "step": 6158
    },
    {
      "epoch": 1.4152113970588236,
      "grad_norm": 1.5584207773208618,
      "learning_rate": 5.872340425531915e-06,
      "loss": 0.0899,
      "step": 6159
    },
    {
      "epoch": 1.4154411764705883,
      "grad_norm": 1.8312023878097534,
      "learning_rate": 5.871489361702129e-06,
      "loss": 0.0725,
      "step": 6160
    },
    {
      "epoch": 1.4156709558823528,
      "grad_norm": 1.4014480113983154,
      "learning_rate": 5.870638297872341e-06,
      "loss": 0.089,
      "step": 6161
    },
    {
      "epoch": 1.4159007352941178,
      "grad_norm": 0.8447867035865784,
      "learning_rate": 5.869787234042553e-06,
      "loss": 0.0623,
      "step": 6162
    },
    {
      "epoch": 1.4161305147058822,
      "grad_norm": 1.4792369604110718,
      "learning_rate": 5.868936170212767e-06,
      "loss": 0.0974,
      "step": 6163
    },
    {
      "epoch": 1.4163602941176472,
      "grad_norm": 1.1647306680679321,
      "learning_rate": 5.868085106382979e-06,
      "loss": 0.0963,
      "step": 6164
    },
    {
      "epoch": 1.4165900735294117,
      "grad_norm": 1.8617926836013794,
      "learning_rate": 5.867234042553191e-06,
      "loss": 0.1167,
      "step": 6165
    },
    {
      "epoch": 1.4168198529411764,
      "grad_norm": 1.4326305389404297,
      "learning_rate": 5.866382978723405e-06,
      "loss": 0.1089,
      "step": 6166
    },
    {
      "epoch": 1.4170496323529411,
      "grad_norm": 1.2050752639770508,
      "learning_rate": 5.865531914893618e-06,
      "loss": 0.0849,
      "step": 6167
    },
    {
      "epoch": 1.4172794117647058,
      "grad_norm": 1.0768663883209229,
      "learning_rate": 5.86468085106383e-06,
      "loss": 0.0568,
      "step": 6168
    },
    {
      "epoch": 1.4175091911764706,
      "grad_norm": 1.1971105337142944,
      "learning_rate": 5.863829787234043e-06,
      "loss": 0.078,
      "step": 6169
    },
    {
      "epoch": 1.4177389705882353,
      "grad_norm": 1.0336291790008545,
      "learning_rate": 5.862978723404255e-06,
      "loss": 0.0673,
      "step": 6170
    },
    {
      "epoch": 1.41796875,
      "grad_norm": 0.8189191222190857,
      "learning_rate": 5.862127659574468e-06,
      "loss": 0.0608,
      "step": 6171
    },
    {
      "epoch": 1.4181985294117647,
      "grad_norm": 1.040623664855957,
      "learning_rate": 5.861276595744682e-06,
      "loss": 0.087,
      "step": 6172
    },
    {
      "epoch": 1.4184283088235294,
      "grad_norm": 1.2292187213897705,
      "learning_rate": 5.860425531914894e-06,
      "loss": 0.0698,
      "step": 6173
    },
    {
      "epoch": 1.4186580882352942,
      "grad_norm": 1.3792777061462402,
      "learning_rate": 5.859574468085106e-06,
      "loss": 0.068,
      "step": 6174
    },
    {
      "epoch": 1.4188878676470589,
      "grad_norm": 1.0055922269821167,
      "learning_rate": 5.8587234042553196e-06,
      "loss": 0.0709,
      "step": 6175
    },
    {
      "epoch": 1.4191176470588236,
      "grad_norm": 1.7575149536132812,
      "learning_rate": 5.857872340425532e-06,
      "loss": 0.12,
      "step": 6176
    },
    {
      "epoch": 1.4193474264705883,
      "grad_norm": 1.0830482244491577,
      "learning_rate": 5.857021276595746e-06,
      "loss": 0.0766,
      "step": 6177
    },
    {
      "epoch": 1.4195772058823528,
      "grad_norm": 0.9657806158065796,
      "learning_rate": 5.856170212765958e-06,
      "loss": 0.0608,
      "step": 6178
    },
    {
      "epoch": 1.4198069852941178,
      "grad_norm": 1.2573939561843872,
      "learning_rate": 5.8553191489361705e-06,
      "loss": 0.0996,
      "step": 6179
    },
    {
      "epoch": 1.4200367647058822,
      "grad_norm": 1.316748023033142,
      "learning_rate": 5.854468085106384e-06,
      "loss": 0.0759,
      "step": 6180
    },
    {
      "epoch": 1.4202665441176472,
      "grad_norm": 1.337853193283081,
      "learning_rate": 5.853617021276596e-06,
      "loss": 0.0829,
      "step": 6181
    },
    {
      "epoch": 1.4204963235294117,
      "grad_norm": 1.2798866033554077,
      "learning_rate": 5.852765957446808e-06,
      "loss": 0.0843,
      "step": 6182
    },
    {
      "epoch": 1.4207261029411764,
      "grad_norm": 1.4430168867111206,
      "learning_rate": 5.851914893617022e-06,
      "loss": 0.112,
      "step": 6183
    },
    {
      "epoch": 1.4209558823529411,
      "grad_norm": 1.5370690822601318,
      "learning_rate": 5.851063829787235e-06,
      "loss": 0.0998,
      "step": 6184
    },
    {
      "epoch": 1.4211856617647058,
      "grad_norm": 1.7493913173675537,
      "learning_rate": 5.850212765957447e-06,
      "loss": 0.1147,
      "step": 6185
    },
    {
      "epoch": 1.4214154411764706,
      "grad_norm": 0.8418881893157959,
      "learning_rate": 5.84936170212766e-06,
      "loss": 0.0631,
      "step": 6186
    },
    {
      "epoch": 1.4216452205882353,
      "grad_norm": 1.0388103723526,
      "learning_rate": 5.8485106382978725e-06,
      "loss": 0.0571,
      "step": 6187
    },
    {
      "epoch": 1.421875,
      "grad_norm": 1.1111794710159302,
      "learning_rate": 5.847659574468086e-06,
      "loss": 0.0985,
      "step": 6188
    },
    {
      "epoch": 1.4221047794117647,
      "grad_norm": 1.912069320678711,
      "learning_rate": 5.846808510638299e-06,
      "loss": 0.0682,
      "step": 6189
    },
    {
      "epoch": 1.4223345588235294,
      "grad_norm": 1.4182701110839844,
      "learning_rate": 5.845957446808511e-06,
      "loss": 0.0729,
      "step": 6190
    },
    {
      "epoch": 1.4225643382352942,
      "grad_norm": 1.0241848230361938,
      "learning_rate": 5.8451063829787235e-06,
      "loss": 0.0728,
      "step": 6191
    },
    {
      "epoch": 1.4227941176470589,
      "grad_norm": 1.162070631980896,
      "learning_rate": 5.844255319148937e-06,
      "loss": 0.0924,
      "step": 6192
    },
    {
      "epoch": 1.4230238970588236,
      "grad_norm": 1.2663837671279907,
      "learning_rate": 5.84340425531915e-06,
      "loss": 0.0729,
      "step": 6193
    },
    {
      "epoch": 1.4232536764705883,
      "grad_norm": 0.9374645948410034,
      "learning_rate": 5.842553191489362e-06,
      "loss": 0.0607,
      "step": 6194
    },
    {
      "epoch": 1.4234834558823528,
      "grad_norm": 1.5380101203918457,
      "learning_rate": 5.841702127659575e-06,
      "loss": 0.0892,
      "step": 6195
    },
    {
      "epoch": 1.4237132352941178,
      "grad_norm": 1.7274532318115234,
      "learning_rate": 5.840851063829788e-06,
      "loss": 0.1464,
      "step": 6196
    },
    {
      "epoch": 1.4239430147058822,
      "grad_norm": 1.0044922828674316,
      "learning_rate": 5.84e-06,
      "loss": 0.0968,
      "step": 6197
    },
    {
      "epoch": 1.4241727941176472,
      "grad_norm": 1.15092134475708,
      "learning_rate": 5.839148936170214e-06,
      "loss": 0.0752,
      "step": 6198
    },
    {
      "epoch": 1.4244025735294117,
      "grad_norm": 1.2711278200149536,
      "learning_rate": 5.838297872340426e-06,
      "loss": 0.0792,
      "step": 6199
    },
    {
      "epoch": 1.4246323529411764,
      "grad_norm": 1.1766108274459839,
      "learning_rate": 5.837446808510639e-06,
      "loss": 0.0813,
      "step": 6200
    },
    {
      "epoch": 1.4248621323529411,
      "grad_norm": 1.1112236976623535,
      "learning_rate": 5.836595744680852e-06,
      "loss": 0.0786,
      "step": 6201
    },
    {
      "epoch": 1.4250919117647058,
      "grad_norm": 1.2067333459854126,
      "learning_rate": 5.835744680851064e-06,
      "loss": 0.0937,
      "step": 6202
    },
    {
      "epoch": 1.4253216911764706,
      "grad_norm": 1.9121897220611572,
      "learning_rate": 5.8348936170212765e-06,
      "loss": 0.1034,
      "step": 6203
    },
    {
      "epoch": 1.4255514705882353,
      "grad_norm": 1.1909085512161255,
      "learning_rate": 5.8340425531914905e-06,
      "loss": 0.0848,
      "step": 6204
    },
    {
      "epoch": 1.42578125,
      "grad_norm": 1.391584038734436,
      "learning_rate": 5.833191489361703e-06,
      "loss": 0.0908,
      "step": 6205
    },
    {
      "epoch": 1.4260110294117647,
      "grad_norm": 1.1118006706237793,
      "learning_rate": 5.832340425531915e-06,
      "loss": 0.0768,
      "step": 6206
    },
    {
      "epoch": 1.4262408088235294,
      "grad_norm": 1.218886375427246,
      "learning_rate": 5.831489361702128e-06,
      "loss": 0.0866,
      "step": 6207
    },
    {
      "epoch": 1.4264705882352942,
      "grad_norm": 0.804938018321991,
      "learning_rate": 5.830638297872341e-06,
      "loss": 0.0441,
      "step": 6208
    },
    {
      "epoch": 1.4267003676470589,
      "grad_norm": 1.2794312238693237,
      "learning_rate": 5.829787234042553e-06,
      "loss": 0.0714,
      "step": 6209
    },
    {
      "epoch": 1.4269301470588236,
      "grad_norm": 1.0948200225830078,
      "learning_rate": 5.828936170212767e-06,
      "loss": 0.0437,
      "step": 6210
    },
    {
      "epoch": 1.4271599264705883,
      "grad_norm": 1.1209057569503784,
      "learning_rate": 5.828085106382979e-06,
      "loss": 0.0941,
      "step": 6211
    },
    {
      "epoch": 1.4273897058823528,
      "grad_norm": 1.0596730709075928,
      "learning_rate": 5.827234042553192e-06,
      "loss": 0.0455,
      "step": 6212
    },
    {
      "epoch": 1.4276194852941178,
      "grad_norm": 1.0841318368911743,
      "learning_rate": 5.826382978723405e-06,
      "loss": 0.0778,
      "step": 6213
    },
    {
      "epoch": 1.4278492647058822,
      "grad_norm": 1.2350994348526,
      "learning_rate": 5.825531914893617e-06,
      "loss": 0.0822,
      "step": 6214
    },
    {
      "epoch": 1.4280790441176472,
      "grad_norm": 1.1506043672561646,
      "learning_rate": 5.8246808510638294e-06,
      "loss": 0.066,
      "step": 6215
    },
    {
      "epoch": 1.4283088235294117,
      "grad_norm": 1.0072163343429565,
      "learning_rate": 5.8238297872340435e-06,
      "loss": 0.0619,
      "step": 6216
    },
    {
      "epoch": 1.4285386029411764,
      "grad_norm": 1.3163214921951294,
      "learning_rate": 5.822978723404256e-06,
      "loss": 0.0968,
      "step": 6217
    },
    {
      "epoch": 1.4287683823529411,
      "grad_norm": 1.2679790258407593,
      "learning_rate": 5.822127659574468e-06,
      "loss": 0.0695,
      "step": 6218
    },
    {
      "epoch": 1.4289981617647058,
      "grad_norm": 1.582258701324463,
      "learning_rate": 5.821276595744681e-06,
      "loss": 0.1117,
      "step": 6219
    },
    {
      "epoch": 1.4292279411764706,
      "grad_norm": 1.6023937463760376,
      "learning_rate": 5.820425531914894e-06,
      "loss": 0.0871,
      "step": 6220
    },
    {
      "epoch": 1.4294577205882353,
      "grad_norm": 1.4468436241149902,
      "learning_rate": 5.819574468085108e-06,
      "loss": 0.0566,
      "step": 6221
    },
    {
      "epoch": 1.4296875,
      "grad_norm": 1.235427975654602,
      "learning_rate": 5.81872340425532e-06,
      "loss": 0.0852,
      "step": 6222
    },
    {
      "epoch": 1.4299172794117647,
      "grad_norm": 1.1443862915039062,
      "learning_rate": 5.817872340425532e-06,
      "loss": 0.0749,
      "step": 6223
    },
    {
      "epoch": 1.4301470588235294,
      "grad_norm": 1.3932148218154907,
      "learning_rate": 5.8170212765957454e-06,
      "loss": 0.0813,
      "step": 6224
    },
    {
      "epoch": 1.4303768382352942,
      "grad_norm": 1.5290416479110718,
      "learning_rate": 5.816170212765958e-06,
      "loss": 0.1102,
      "step": 6225
    },
    {
      "epoch": 1.4306066176470589,
      "grad_norm": 0.9495382308959961,
      "learning_rate": 5.81531914893617e-06,
      "loss": 0.0914,
      "step": 6226
    },
    {
      "epoch": 1.4308363970588236,
      "grad_norm": 1.5962467193603516,
      "learning_rate": 5.814468085106384e-06,
      "loss": 0.1205,
      "step": 6227
    },
    {
      "epoch": 1.4310661764705883,
      "grad_norm": 1.5814114809036255,
      "learning_rate": 5.813617021276596e-06,
      "loss": 0.1245,
      "step": 6228
    },
    {
      "epoch": 1.4312959558823528,
      "grad_norm": 1.0044766664505005,
      "learning_rate": 5.812765957446809e-06,
      "loss": 0.0672,
      "step": 6229
    },
    {
      "epoch": 1.4315257352941178,
      "grad_norm": 1.1478173732757568,
      "learning_rate": 5.811914893617022e-06,
      "loss": 0.0491,
      "step": 6230
    },
    {
      "epoch": 1.4317555147058822,
      "grad_norm": 1.233924150466919,
      "learning_rate": 5.811063829787234e-06,
      "loss": 0.0708,
      "step": 6231
    },
    {
      "epoch": 1.4319852941176472,
      "grad_norm": 1.71941339969635,
      "learning_rate": 5.810212765957447e-06,
      "loss": 0.0929,
      "step": 6232
    },
    {
      "epoch": 1.4322150735294117,
      "grad_norm": 1.2565362453460693,
      "learning_rate": 5.809361702127661e-06,
      "loss": 0.0762,
      "step": 6233
    },
    {
      "epoch": 1.4324448529411764,
      "grad_norm": 1.2273706197738647,
      "learning_rate": 5.808510638297873e-06,
      "loss": 0.0815,
      "step": 6234
    },
    {
      "epoch": 1.4326746323529411,
      "grad_norm": 2.6262223720550537,
      "learning_rate": 5.807659574468085e-06,
      "loss": 0.0895,
      "step": 6235
    },
    {
      "epoch": 1.4329044117647058,
      "grad_norm": 3.134855270385742,
      "learning_rate": 5.806808510638298e-06,
      "loss": 0.1101,
      "step": 6236
    },
    {
      "epoch": 1.4331341911764706,
      "grad_norm": 1.3662391901016235,
      "learning_rate": 5.8059574468085116e-06,
      "loss": 0.0949,
      "step": 6237
    },
    {
      "epoch": 1.4333639705882353,
      "grad_norm": 1.2822643518447876,
      "learning_rate": 5.805106382978724e-06,
      "loss": 0.1082,
      "step": 6238
    },
    {
      "epoch": 1.43359375,
      "grad_norm": 1.5229344367980957,
      "learning_rate": 5.804255319148937e-06,
      "loss": 0.1398,
      "step": 6239
    },
    {
      "epoch": 1.4338235294117647,
      "grad_norm": 2.5427894592285156,
      "learning_rate": 5.803404255319149e-06,
      "loss": 0.1129,
      "step": 6240
    },
    {
      "epoch": 1.4340533088235294,
      "grad_norm": 1.266231894493103,
      "learning_rate": 5.802553191489362e-06,
      "loss": 0.0644,
      "step": 6241
    },
    {
      "epoch": 1.4342830882352942,
      "grad_norm": 1.1685552597045898,
      "learning_rate": 5.801702127659575e-06,
      "loss": 0.0879,
      "step": 6242
    },
    {
      "epoch": 1.4345128676470589,
      "grad_norm": 1.3794732093811035,
      "learning_rate": 5.800851063829788e-06,
      "loss": 0.1132,
      "step": 6243
    },
    {
      "epoch": 1.4347426470588236,
      "grad_norm": 1.7421314716339111,
      "learning_rate": 5.8e-06,
      "loss": 0.0961,
      "step": 6244
    },
    {
      "epoch": 1.4349724264705883,
      "grad_norm": 1.536887764930725,
      "learning_rate": 5.7991489361702135e-06,
      "loss": 0.0842,
      "step": 6245
    },
    {
      "epoch": 1.4352022058823528,
      "grad_norm": 1.5236283540725708,
      "learning_rate": 5.798297872340426e-06,
      "loss": 0.0907,
      "step": 6246
    },
    {
      "epoch": 1.4354319852941178,
      "grad_norm": 1.3010368347167969,
      "learning_rate": 5.797446808510638e-06,
      "loss": 0.0747,
      "step": 6247
    },
    {
      "epoch": 1.4356617647058822,
      "grad_norm": 1.1370015144348145,
      "learning_rate": 5.796595744680852e-06,
      "loss": 0.0814,
      "step": 6248
    },
    {
      "epoch": 1.4358915441176472,
      "grad_norm": 1.5311590433120728,
      "learning_rate": 5.7957446808510645e-06,
      "loss": 0.0878,
      "step": 6249
    },
    {
      "epoch": 1.4361213235294117,
      "grad_norm": 1.0216844081878662,
      "learning_rate": 5.794893617021277e-06,
      "loss": 0.0614,
      "step": 6250
    },
    {
      "epoch": 1.4363511029411764,
      "grad_norm": 0.9253491759300232,
      "learning_rate": 5.79404255319149e-06,
      "loss": 0.0866,
      "step": 6251
    },
    {
      "epoch": 1.4365808823529411,
      "grad_norm": 1.041021466255188,
      "learning_rate": 5.793191489361702e-06,
      "loss": 0.0749,
      "step": 6252
    },
    {
      "epoch": 1.4368106617647058,
      "grad_norm": 1.1847426891326904,
      "learning_rate": 5.792340425531915e-06,
      "loss": 0.0607,
      "step": 6253
    },
    {
      "epoch": 1.4370404411764706,
      "grad_norm": 1.1971666812896729,
      "learning_rate": 5.791489361702129e-06,
      "loss": 0.0934,
      "step": 6254
    },
    {
      "epoch": 1.4372702205882353,
      "grad_norm": 1.0517634153366089,
      "learning_rate": 5.790638297872341e-06,
      "loss": 0.0912,
      "step": 6255
    },
    {
      "epoch": 1.4375,
      "grad_norm": 1.3402223587036133,
      "learning_rate": 5.789787234042553e-06,
      "loss": 0.0867,
      "step": 6256
    },
    {
      "epoch": 1.4377297794117647,
      "grad_norm": 1.6861610412597656,
      "learning_rate": 5.7889361702127665e-06,
      "loss": 0.0879,
      "step": 6257
    },
    {
      "epoch": 1.4379595588235294,
      "grad_norm": 1.1138525009155273,
      "learning_rate": 5.788085106382979e-06,
      "loss": 0.086,
      "step": 6258
    },
    {
      "epoch": 1.4381893382352942,
      "grad_norm": 1.2000807523727417,
      "learning_rate": 5.787234042553191e-06,
      "loss": 0.0842,
      "step": 6259
    },
    {
      "epoch": 1.4384191176470589,
      "grad_norm": 1.096685528755188,
      "learning_rate": 5.786382978723405e-06,
      "loss": 0.068,
      "step": 6260
    },
    {
      "epoch": 1.4386488970588236,
      "grad_norm": 1.0094527006149292,
      "learning_rate": 5.7855319148936175e-06,
      "loss": 0.071,
      "step": 6261
    },
    {
      "epoch": 1.4388786764705883,
      "grad_norm": 1.0932241678237915,
      "learning_rate": 5.78468085106383e-06,
      "loss": 0.0585,
      "step": 6262
    },
    {
      "epoch": 1.4391084558823528,
      "grad_norm": 1.0316860675811768,
      "learning_rate": 5.783829787234043e-06,
      "loss": 0.0866,
      "step": 6263
    },
    {
      "epoch": 1.4393382352941178,
      "grad_norm": 0.9365955591201782,
      "learning_rate": 5.782978723404255e-06,
      "loss": 0.0715,
      "step": 6264
    },
    {
      "epoch": 1.4395680147058822,
      "grad_norm": 1.2102700471878052,
      "learning_rate": 5.782127659574469e-06,
      "loss": 0.0912,
      "step": 6265
    },
    {
      "epoch": 1.4397977941176472,
      "grad_norm": 1.3771722316741943,
      "learning_rate": 5.781276595744682e-06,
      "loss": 0.1006,
      "step": 6266
    },
    {
      "epoch": 1.4400275735294117,
      "grad_norm": 1.5492783784866333,
      "learning_rate": 5.780425531914894e-06,
      "loss": 0.0741,
      "step": 6267
    },
    {
      "epoch": 1.4402573529411764,
      "grad_norm": 1.0973334312438965,
      "learning_rate": 5.779574468085107e-06,
      "loss": 0.0592,
      "step": 6268
    },
    {
      "epoch": 1.4404871323529411,
      "grad_norm": 1.6991381645202637,
      "learning_rate": 5.7787234042553195e-06,
      "loss": 0.0938,
      "step": 6269
    },
    {
      "epoch": 1.4407169117647058,
      "grad_norm": 1.152885913848877,
      "learning_rate": 5.777872340425532e-06,
      "loss": 0.0741,
      "step": 6270
    },
    {
      "epoch": 1.4409466911764706,
      "grad_norm": 1.068644642829895,
      "learning_rate": 5.777021276595746e-06,
      "loss": 0.0865,
      "step": 6271
    },
    {
      "epoch": 1.4411764705882353,
      "grad_norm": 1.4165377616882324,
      "learning_rate": 5.776170212765958e-06,
      "loss": 0.062,
      "step": 6272
    },
    {
      "epoch": 1.44140625,
      "grad_norm": 1.2125097513198853,
      "learning_rate": 5.7753191489361705e-06,
      "loss": 0.0877,
      "step": 6273
    },
    {
      "epoch": 1.4416360294117647,
      "grad_norm": 1.1863573789596558,
      "learning_rate": 5.774468085106384e-06,
      "loss": 0.1066,
      "step": 6274
    },
    {
      "epoch": 1.4418658088235294,
      "grad_norm": 1.2170108556747437,
      "learning_rate": 5.773617021276596e-06,
      "loss": 0.0751,
      "step": 6275
    },
    {
      "epoch": 1.4420955882352942,
      "grad_norm": 1.1998186111450195,
      "learning_rate": 5.772765957446808e-06,
      "loss": 0.0834,
      "step": 6276
    },
    {
      "epoch": 1.4423253676470589,
      "grad_norm": 1.065877914428711,
      "learning_rate": 5.771914893617022e-06,
      "loss": 0.0625,
      "step": 6277
    },
    {
      "epoch": 1.4425551470588236,
      "grad_norm": 1.4095866680145264,
      "learning_rate": 5.771063829787235e-06,
      "loss": 0.0852,
      "step": 6278
    },
    {
      "epoch": 1.4427849264705883,
      "grad_norm": 1.156001329421997,
      "learning_rate": 5.770212765957447e-06,
      "loss": 0.0806,
      "step": 6279
    },
    {
      "epoch": 1.4430147058823528,
      "grad_norm": 1.301741361618042,
      "learning_rate": 5.76936170212766e-06,
      "loss": 0.0771,
      "step": 6280
    },
    {
      "epoch": 1.4432444852941178,
      "grad_norm": 1.1421064138412476,
      "learning_rate": 5.7685106382978724e-06,
      "loss": 0.071,
      "step": 6281
    },
    {
      "epoch": 1.4434742647058822,
      "grad_norm": 1.2153706550598145,
      "learning_rate": 5.767659574468086e-06,
      "loss": 0.0919,
      "step": 6282
    },
    {
      "epoch": 1.4437040441176472,
      "grad_norm": 1.4606367349624634,
      "learning_rate": 5.766808510638299e-06,
      "loss": 0.083,
      "step": 6283
    },
    {
      "epoch": 1.4439338235294117,
      "grad_norm": 1.1540366411209106,
      "learning_rate": 5.765957446808511e-06,
      "loss": 0.0755,
      "step": 6284
    },
    {
      "epoch": 1.4441636029411764,
      "grad_norm": 1.1707607507705688,
      "learning_rate": 5.7651063829787234e-06,
      "loss": 0.0601,
      "step": 6285
    },
    {
      "epoch": 1.4443933823529411,
      "grad_norm": 1.0502127408981323,
      "learning_rate": 5.764255319148937e-06,
      "loss": 0.0938,
      "step": 6286
    },
    {
      "epoch": 1.4446231617647058,
      "grad_norm": 1.1002707481384277,
      "learning_rate": 5.76340425531915e-06,
      "loss": 0.0632,
      "step": 6287
    },
    {
      "epoch": 1.4448529411764706,
      "grad_norm": 1.1640450954437256,
      "learning_rate": 5.762553191489362e-06,
      "loss": 0.0738,
      "step": 6288
    },
    {
      "epoch": 1.4450827205882353,
      "grad_norm": 1.1692674160003662,
      "learning_rate": 5.761702127659575e-06,
      "loss": 0.0989,
      "step": 6289
    },
    {
      "epoch": 1.4453125,
      "grad_norm": 1.0817121267318726,
      "learning_rate": 5.760851063829788e-06,
      "loss": 0.0446,
      "step": 6290
    },
    {
      "epoch": 1.4455422794117647,
      "grad_norm": 1.2854907512664795,
      "learning_rate": 5.76e-06,
      "loss": 0.0786,
      "step": 6291
    },
    {
      "epoch": 1.4457720588235294,
      "grad_norm": 1.1936495304107666,
      "learning_rate": 5.759148936170214e-06,
      "loss": 0.0691,
      "step": 6292
    },
    {
      "epoch": 1.4460018382352942,
      "grad_norm": 0.8081409335136414,
      "learning_rate": 5.758297872340426e-06,
      "loss": 0.0653,
      "step": 6293
    },
    {
      "epoch": 1.4462316176470589,
      "grad_norm": 1.6657967567443848,
      "learning_rate": 5.7574468085106386e-06,
      "loss": 0.084,
      "step": 6294
    },
    {
      "epoch": 1.4464613970588236,
      "grad_norm": 1.0464626550674438,
      "learning_rate": 5.756595744680852e-06,
      "loss": 0.057,
      "step": 6295
    },
    {
      "epoch": 1.4466911764705883,
      "grad_norm": 1.3377928733825684,
      "learning_rate": 5.755744680851064e-06,
      "loss": 0.1033,
      "step": 6296
    },
    {
      "epoch": 1.4469209558823528,
      "grad_norm": 1.5116595029830933,
      "learning_rate": 5.754893617021276e-06,
      "loss": 0.0966,
      "step": 6297
    },
    {
      "epoch": 1.4471507352941178,
      "grad_norm": 1.183835506439209,
      "learning_rate": 5.75404255319149e-06,
      "loss": 0.0691,
      "step": 6298
    },
    {
      "epoch": 1.4473805147058822,
      "grad_norm": 1.3889354467391968,
      "learning_rate": 5.753191489361703e-06,
      "loss": 0.0819,
      "step": 6299
    },
    {
      "epoch": 1.4476102941176472,
      "grad_norm": 2.090268611907959,
      "learning_rate": 5.752340425531915e-06,
      "loss": 0.0963,
      "step": 6300
    },
    {
      "epoch": 1.4478400735294117,
      "grad_norm": 1.3468433618545532,
      "learning_rate": 5.751489361702128e-06,
      "loss": 0.0775,
      "step": 6301
    },
    {
      "epoch": 1.4480698529411764,
      "grad_norm": 1.4270009994506836,
      "learning_rate": 5.7506382978723406e-06,
      "loss": 0.0765,
      "step": 6302
    },
    {
      "epoch": 1.4482996323529411,
      "grad_norm": 1.198808193206787,
      "learning_rate": 5.749787234042553e-06,
      "loss": 0.0834,
      "step": 6303
    },
    {
      "epoch": 1.4485294117647058,
      "grad_norm": 1.1647260189056396,
      "learning_rate": 5.748936170212767e-06,
      "loss": 0.049,
      "step": 6304
    },
    {
      "epoch": 1.4487591911764706,
      "grad_norm": 1.027688980102539,
      "learning_rate": 5.748085106382979e-06,
      "loss": 0.0438,
      "step": 6305
    },
    {
      "epoch": 1.4489889705882353,
      "grad_norm": 1.2751532793045044,
      "learning_rate": 5.747234042553192e-06,
      "loss": 0.1036,
      "step": 6306
    },
    {
      "epoch": 1.44921875,
      "grad_norm": 1.1261354684829712,
      "learning_rate": 5.746382978723405e-06,
      "loss": 0.0935,
      "step": 6307
    },
    {
      "epoch": 1.4494485294117647,
      "grad_norm": 1.580847144126892,
      "learning_rate": 5.745531914893617e-06,
      "loss": 0.095,
      "step": 6308
    },
    {
      "epoch": 1.4496783088235294,
      "grad_norm": 0.9949666261672974,
      "learning_rate": 5.744680851063831e-06,
      "loss": 0.0598,
      "step": 6309
    },
    {
      "epoch": 1.4499080882352942,
      "grad_norm": 1.0946601629257202,
      "learning_rate": 5.743829787234043e-06,
      "loss": 0.0562,
      "step": 6310
    },
    {
      "epoch": 1.4501378676470589,
      "grad_norm": 1.3101009130477905,
      "learning_rate": 5.742978723404256e-06,
      "loss": 0.1283,
      "step": 6311
    },
    {
      "epoch": 1.4503676470588236,
      "grad_norm": 1.0228941440582275,
      "learning_rate": 5.742127659574469e-06,
      "loss": 0.0792,
      "step": 6312
    },
    {
      "epoch": 1.4505974264705883,
      "grad_norm": 1.0773613452911377,
      "learning_rate": 5.741276595744681e-06,
      "loss": 0.0636,
      "step": 6313
    },
    {
      "epoch": 1.4508272058823528,
      "grad_norm": 1.4083470106124878,
      "learning_rate": 5.7404255319148935e-06,
      "loss": 0.0813,
      "step": 6314
    },
    {
      "epoch": 1.4510569852941178,
      "grad_norm": 1.1146042346954346,
      "learning_rate": 5.7395744680851075e-06,
      "loss": 0.0649,
      "step": 6315
    },
    {
      "epoch": 1.4512867647058822,
      "grad_norm": 1.2286392450332642,
      "learning_rate": 5.73872340425532e-06,
      "loss": 0.0788,
      "step": 6316
    },
    {
      "epoch": 1.4515165441176472,
      "grad_norm": 1.3119101524353027,
      "learning_rate": 5.737872340425532e-06,
      "loss": 0.102,
      "step": 6317
    },
    {
      "epoch": 1.4517463235294117,
      "grad_norm": 0.9966394305229187,
      "learning_rate": 5.737021276595745e-06,
      "loss": 0.0598,
      "step": 6318
    },
    {
      "epoch": 1.4519761029411764,
      "grad_norm": 1.5047682523727417,
      "learning_rate": 5.736170212765958e-06,
      "loss": 0.1231,
      "step": 6319
    },
    {
      "epoch": 1.4522058823529411,
      "grad_norm": 1.2275758981704712,
      "learning_rate": 5.73531914893617e-06,
      "loss": 0.0885,
      "step": 6320
    },
    {
      "epoch": 1.4524356617647058,
      "grad_norm": 1.1844886541366577,
      "learning_rate": 5.734468085106384e-06,
      "loss": 0.0616,
      "step": 6321
    },
    {
      "epoch": 1.4526654411764706,
      "grad_norm": 1.164759635925293,
      "learning_rate": 5.733617021276596e-06,
      "loss": 0.0824,
      "step": 6322
    },
    {
      "epoch": 1.4528952205882353,
      "grad_norm": 1.0257731676101685,
      "learning_rate": 5.732765957446809e-06,
      "loss": 0.0786,
      "step": 6323
    },
    {
      "epoch": 1.453125,
      "grad_norm": 1.6444758176803589,
      "learning_rate": 5.731914893617022e-06,
      "loss": 0.1158,
      "step": 6324
    },
    {
      "epoch": 1.4533547794117647,
      "grad_norm": 1.577481985092163,
      "learning_rate": 5.731063829787234e-06,
      "loss": 0.0806,
      "step": 6325
    },
    {
      "epoch": 1.4535845588235294,
      "grad_norm": 1.412409782409668,
      "learning_rate": 5.730212765957447e-06,
      "loss": 0.1435,
      "step": 6326
    },
    {
      "epoch": 1.4538143382352942,
      "grad_norm": 1.6632192134857178,
      "learning_rate": 5.7293617021276605e-06,
      "loss": 0.0824,
      "step": 6327
    },
    {
      "epoch": 1.4540441176470589,
      "grad_norm": 1.2801107168197632,
      "learning_rate": 5.728510638297873e-06,
      "loss": 0.082,
      "step": 6328
    },
    {
      "epoch": 1.4542738970588236,
      "grad_norm": 1.1049296855926514,
      "learning_rate": 5.727659574468085e-06,
      "loss": 0.0591,
      "step": 6329
    },
    {
      "epoch": 1.4545036764705883,
      "grad_norm": 1.4135782718658447,
      "learning_rate": 5.726808510638298e-06,
      "loss": 0.0855,
      "step": 6330
    },
    {
      "epoch": 1.4547334558823528,
      "grad_norm": 1.4656474590301514,
      "learning_rate": 5.7259574468085115e-06,
      "loss": 0.1201,
      "step": 6331
    },
    {
      "epoch": 1.4549632352941178,
      "grad_norm": 1.3375805616378784,
      "learning_rate": 5.725106382978724e-06,
      "loss": 0.0994,
      "step": 6332
    },
    {
      "epoch": 1.4551930147058822,
      "grad_norm": 0.9460203051567078,
      "learning_rate": 5.724255319148937e-06,
      "loss": 0.0735,
      "step": 6333
    },
    {
      "epoch": 1.4554227941176472,
      "grad_norm": 1.3133740425109863,
      "learning_rate": 5.723404255319149e-06,
      "loss": 0.0933,
      "step": 6334
    },
    {
      "epoch": 1.4556525735294117,
      "grad_norm": 1.2734447717666626,
      "learning_rate": 5.722553191489362e-06,
      "loss": 0.0673,
      "step": 6335
    },
    {
      "epoch": 1.4558823529411764,
      "grad_norm": 1.2879899740219116,
      "learning_rate": 5.721702127659576e-06,
      "loss": 0.1059,
      "step": 6336
    },
    {
      "epoch": 1.4561121323529411,
      "grad_norm": 1.1322506666183472,
      "learning_rate": 5.720851063829788e-06,
      "loss": 0.0979,
      "step": 6337
    },
    {
      "epoch": 1.4563419117647058,
      "grad_norm": 1.230475902557373,
      "learning_rate": 5.72e-06,
      "loss": 0.1144,
      "step": 6338
    },
    {
      "epoch": 1.4565716911764706,
      "grad_norm": 0.8944916129112244,
      "learning_rate": 5.7191489361702135e-06,
      "loss": 0.0462,
      "step": 6339
    },
    {
      "epoch": 1.4568014705882353,
      "grad_norm": 1.323481798171997,
      "learning_rate": 5.718297872340426e-06,
      "loss": 0.0566,
      "step": 6340
    },
    {
      "epoch": 1.45703125,
      "grad_norm": 1.3524523973464966,
      "learning_rate": 5.717446808510638e-06,
      "loss": 0.0774,
      "step": 6341
    },
    {
      "epoch": 1.4572610294117647,
      "grad_norm": 1.2464743852615356,
      "learning_rate": 5.716595744680852e-06,
      "loss": 0.0692,
      "step": 6342
    },
    {
      "epoch": 1.4574908088235294,
      "grad_norm": 1.3784139156341553,
      "learning_rate": 5.7157446808510645e-06,
      "loss": 0.0423,
      "step": 6343
    },
    {
      "epoch": 1.4577205882352942,
      "grad_norm": 1.4254318475723267,
      "learning_rate": 5.714893617021277e-06,
      "loss": 0.0769,
      "step": 6344
    },
    {
      "epoch": 1.4579503676470589,
      "grad_norm": 1.0490506887435913,
      "learning_rate": 5.71404255319149e-06,
      "loss": 0.0844,
      "step": 6345
    },
    {
      "epoch": 1.4581801470588236,
      "grad_norm": 1.3851704597473145,
      "learning_rate": 5.713191489361702e-06,
      "loss": 0.0923,
      "step": 6346
    },
    {
      "epoch": 1.4584099264705883,
      "grad_norm": 1.0312297344207764,
      "learning_rate": 5.712340425531915e-06,
      "loss": 0.0701,
      "step": 6347
    },
    {
      "epoch": 1.4586397058823528,
      "grad_norm": 1.1994776725769043,
      "learning_rate": 5.711489361702129e-06,
      "loss": 0.0615,
      "step": 6348
    },
    {
      "epoch": 1.4588694852941178,
      "grad_norm": 1.5268248319625854,
      "learning_rate": 5.710638297872341e-06,
      "loss": 0.1334,
      "step": 6349
    },
    {
      "epoch": 1.4590992647058822,
      "grad_norm": 1.5945775508880615,
      "learning_rate": 5.709787234042554e-06,
      "loss": 0.1256,
      "step": 6350
    },
    {
      "epoch": 1.4593290441176472,
      "grad_norm": 1.0012916326522827,
      "learning_rate": 5.7089361702127664e-06,
      "loss": 0.0768,
      "step": 6351
    },
    {
      "epoch": 1.4595588235294117,
      "grad_norm": 1.028185486793518,
      "learning_rate": 5.708085106382979e-06,
      "loss": 0.0733,
      "step": 6352
    },
    {
      "epoch": 1.4597886029411764,
      "grad_norm": 0.9499445557594299,
      "learning_rate": 5.707234042553193e-06,
      "loss": 0.0773,
      "step": 6353
    },
    {
      "epoch": 1.4600183823529411,
      "grad_norm": 1.5170867443084717,
      "learning_rate": 5.706382978723405e-06,
      "loss": 0.085,
      "step": 6354
    },
    {
      "epoch": 1.4602481617647058,
      "grad_norm": 1.3035215139389038,
      "learning_rate": 5.705531914893617e-06,
      "loss": 0.0742,
      "step": 6355
    },
    {
      "epoch": 1.4604779411764706,
      "grad_norm": 0.94645094871521,
      "learning_rate": 5.704680851063831e-06,
      "loss": 0.0806,
      "step": 6356
    },
    {
      "epoch": 1.4607077205882353,
      "grad_norm": 1.2364439964294434,
      "learning_rate": 5.703829787234043e-06,
      "loss": 0.0902,
      "step": 6357
    },
    {
      "epoch": 1.4609375,
      "grad_norm": 1.1429812908172607,
      "learning_rate": 5.702978723404255e-06,
      "loss": 0.0692,
      "step": 6358
    },
    {
      "epoch": 1.4611672794117647,
      "grad_norm": 0.9012046456336975,
      "learning_rate": 5.702127659574469e-06,
      "loss": 0.0715,
      "step": 6359
    },
    {
      "epoch": 1.4613970588235294,
      "grad_norm": 1.4150543212890625,
      "learning_rate": 5.7012765957446816e-06,
      "loss": 0.1214,
      "step": 6360
    },
    {
      "epoch": 1.4616268382352942,
      "grad_norm": 1.2477843761444092,
      "learning_rate": 5.700425531914894e-06,
      "loss": 0.0878,
      "step": 6361
    },
    {
      "epoch": 1.4618566176470589,
      "grad_norm": 1.1492750644683838,
      "learning_rate": 5.699574468085107e-06,
      "loss": 0.0491,
      "step": 6362
    },
    {
      "epoch": 1.4620863970588236,
      "grad_norm": 1.852169394493103,
      "learning_rate": 5.698723404255319e-06,
      "loss": 0.1049,
      "step": 6363
    },
    {
      "epoch": 1.4623161764705883,
      "grad_norm": 1.2562083005905151,
      "learning_rate": 5.697872340425532e-06,
      "loss": 0.1024,
      "step": 6364
    },
    {
      "epoch": 1.4625459558823528,
      "grad_norm": 1.1475658416748047,
      "learning_rate": 5.697021276595746e-06,
      "loss": 0.078,
      "step": 6365
    },
    {
      "epoch": 1.4627757352941178,
      "grad_norm": 2.078260660171509,
      "learning_rate": 5.696170212765958e-06,
      "loss": 0.1159,
      "step": 6366
    },
    {
      "epoch": 1.4630055147058822,
      "grad_norm": 1.5409438610076904,
      "learning_rate": 5.69531914893617e-06,
      "loss": 0.0579,
      "step": 6367
    },
    {
      "epoch": 1.4632352941176472,
      "grad_norm": 0.9381766319274902,
      "learning_rate": 5.6944680851063836e-06,
      "loss": 0.0331,
      "step": 6368
    },
    {
      "epoch": 1.4634650735294117,
      "grad_norm": 1.5815047025680542,
      "learning_rate": 5.693617021276596e-06,
      "loss": 0.0757,
      "step": 6369
    },
    {
      "epoch": 1.4636948529411764,
      "grad_norm": 1.2981129884719849,
      "learning_rate": 5.692765957446808e-06,
      "loss": 0.0694,
      "step": 6370
    },
    {
      "epoch": 1.4639246323529411,
      "grad_norm": 1.2335559129714966,
      "learning_rate": 5.691914893617022e-06,
      "loss": 0.0762,
      "step": 6371
    },
    {
      "epoch": 1.4641544117647058,
      "grad_norm": 1.208277940750122,
      "learning_rate": 5.6910638297872345e-06,
      "loss": 0.074,
      "step": 6372
    },
    {
      "epoch": 1.4643841911764706,
      "grad_norm": 1.3238708972930908,
      "learning_rate": 5.690212765957447e-06,
      "loss": 0.0763,
      "step": 6373
    },
    {
      "epoch": 1.4646139705882353,
      "grad_norm": 1.1777185201644897,
      "learning_rate": 5.68936170212766e-06,
      "loss": 0.0792,
      "step": 6374
    },
    {
      "epoch": 1.46484375,
      "grad_norm": 1.3476570844650269,
      "learning_rate": 5.688510638297872e-06,
      "loss": 0.0922,
      "step": 6375
    },
    {
      "epoch": 1.4650735294117647,
      "grad_norm": 1.3977292776107788,
      "learning_rate": 5.6876595744680855e-06,
      "loss": 0.0793,
      "step": 6376
    },
    {
      "epoch": 1.4653033088235294,
      "grad_norm": 1.1479078531265259,
      "learning_rate": 5.686808510638299e-06,
      "loss": 0.0711,
      "step": 6377
    },
    {
      "epoch": 1.4655330882352942,
      "grad_norm": 1.349312663078308,
      "learning_rate": 5.685957446808511e-06,
      "loss": 0.0934,
      "step": 6378
    },
    {
      "epoch": 1.4657628676470589,
      "grad_norm": 1.6256943941116333,
      "learning_rate": 5.685106382978723e-06,
      "loss": 0.0869,
      "step": 6379
    },
    {
      "epoch": 1.4659926470588236,
      "grad_norm": 1.5536437034606934,
      "learning_rate": 5.6842553191489365e-06,
      "loss": 0.0962,
      "step": 6380
    },
    {
      "epoch": 1.4662224264705883,
      "grad_norm": 1.2565480470657349,
      "learning_rate": 5.68340425531915e-06,
      "loss": 0.0877,
      "step": 6381
    },
    {
      "epoch": 1.4664522058823528,
      "grad_norm": 1.1211563348770142,
      "learning_rate": 5.682553191489362e-06,
      "loss": 0.0824,
      "step": 6382
    },
    {
      "epoch": 1.4666819852941178,
      "grad_norm": 1.57789146900177,
      "learning_rate": 5.681702127659575e-06,
      "loss": 0.0854,
      "step": 6383
    },
    {
      "epoch": 1.4669117647058822,
      "grad_norm": 1.2210168838500977,
      "learning_rate": 5.6808510638297875e-06,
      "loss": 0.0567,
      "step": 6384
    },
    {
      "epoch": 1.4671415441176472,
      "grad_norm": 1.3500423431396484,
      "learning_rate": 5.68e-06,
      "loss": 0.1019,
      "step": 6385
    },
    {
      "epoch": 1.4673713235294117,
      "grad_norm": 1.5726851224899292,
      "learning_rate": 5.679148936170214e-06,
      "loss": 0.0921,
      "step": 6386
    },
    {
      "epoch": 1.4676011029411764,
      "grad_norm": 1.214637279510498,
      "learning_rate": 5.678297872340426e-06,
      "loss": 0.0937,
      "step": 6387
    },
    {
      "epoch": 1.4678308823529411,
      "grad_norm": 1.797702670097351,
      "learning_rate": 5.6774468085106385e-06,
      "loss": 0.1163,
      "step": 6388
    },
    {
      "epoch": 1.4680606617647058,
      "grad_norm": 1.1504449844360352,
      "learning_rate": 5.676595744680852e-06,
      "loss": 0.0753,
      "step": 6389
    },
    {
      "epoch": 1.4682904411764706,
      "grad_norm": 1.2282291650772095,
      "learning_rate": 5.675744680851064e-06,
      "loss": 0.0612,
      "step": 6390
    },
    {
      "epoch": 1.4685202205882353,
      "grad_norm": 1.023032307624817,
      "learning_rate": 5.674893617021278e-06,
      "loss": 0.0567,
      "step": 6391
    },
    {
      "epoch": 1.46875,
      "grad_norm": 0.967043399810791,
      "learning_rate": 5.67404255319149e-06,
      "loss": 0.0712,
      "step": 6392
    },
    {
      "epoch": 1.4689797794117647,
      "grad_norm": 1.3781312704086304,
      "learning_rate": 5.673191489361703e-06,
      "loss": 0.0989,
      "step": 6393
    },
    {
      "epoch": 1.4692095588235294,
      "grad_norm": 1.554383635520935,
      "learning_rate": 5.672340425531916e-06,
      "loss": 0.0933,
      "step": 6394
    },
    {
      "epoch": 1.4694393382352942,
      "grad_norm": 1.2389898300170898,
      "learning_rate": 5.671489361702128e-06,
      "loss": 0.0768,
      "step": 6395
    },
    {
      "epoch": 1.4696691176470589,
      "grad_norm": 1.387231469154358,
      "learning_rate": 5.6706382978723405e-06,
      "loss": 0.0665,
      "step": 6396
    },
    {
      "epoch": 1.4698988970588236,
      "grad_norm": 1.1940369606018066,
      "learning_rate": 5.6697872340425545e-06,
      "loss": 0.0749,
      "step": 6397
    },
    {
      "epoch": 1.4701286764705883,
      "grad_norm": 1.2295020818710327,
      "learning_rate": 5.668936170212767e-06,
      "loss": 0.0863,
      "step": 6398
    },
    {
      "epoch": 1.4703584558823528,
      "grad_norm": 1.5165146589279175,
      "learning_rate": 5.668085106382979e-06,
      "loss": 0.0686,
      "step": 6399
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 1.077538013458252,
      "learning_rate": 5.667234042553192e-06,
      "loss": 0.0581,
      "step": 6400
    },
    {
      "epoch": 1.4708180147058822,
      "grad_norm": 1.4982726573944092,
      "learning_rate": 5.666382978723405e-06,
      "loss": 0.0963,
      "step": 6401
    },
    {
      "epoch": 1.4710477941176472,
      "grad_norm": 1.1151652336120605,
      "learning_rate": 5.665531914893617e-06,
      "loss": 0.0522,
      "step": 6402
    },
    {
      "epoch": 1.4712775735294117,
      "grad_norm": 1.2390646934509277,
      "learning_rate": 5.664680851063831e-06,
      "loss": 0.0811,
      "step": 6403
    },
    {
      "epoch": 1.4715073529411764,
      "grad_norm": 0.9837794303894043,
      "learning_rate": 5.663829787234043e-06,
      "loss": 0.0761,
      "step": 6404
    },
    {
      "epoch": 1.4717371323529411,
      "grad_norm": 1.1996831893920898,
      "learning_rate": 5.662978723404256e-06,
      "loss": 0.0748,
      "step": 6405
    },
    {
      "epoch": 1.4719669117647058,
      "grad_norm": 1.2603496313095093,
      "learning_rate": 5.662127659574469e-06,
      "loss": 0.1066,
      "step": 6406
    },
    {
      "epoch": 1.4721966911764706,
      "grad_norm": 1.3351906538009644,
      "learning_rate": 5.661276595744681e-06,
      "loss": 0.0843,
      "step": 6407
    },
    {
      "epoch": 1.4724264705882353,
      "grad_norm": 1.3314234018325806,
      "learning_rate": 5.6604255319148934e-06,
      "loss": 0.0928,
      "step": 6408
    },
    {
      "epoch": 1.47265625,
      "grad_norm": 1.0521069765090942,
      "learning_rate": 5.6595744680851075e-06,
      "loss": 0.0853,
      "step": 6409
    },
    {
      "epoch": 1.4728860294117647,
      "grad_norm": 1.377286672592163,
      "learning_rate": 5.65872340425532e-06,
      "loss": 0.1041,
      "step": 6410
    },
    {
      "epoch": 1.4731158088235294,
      "grad_norm": 1.3273557424545288,
      "learning_rate": 5.657872340425532e-06,
      "loss": 0.0615,
      "step": 6411
    },
    {
      "epoch": 1.4733455882352942,
      "grad_norm": 1.1854794025421143,
      "learning_rate": 5.657021276595745e-06,
      "loss": 0.0717,
      "step": 6412
    },
    {
      "epoch": 1.4735753676470589,
      "grad_norm": 1.3950179815292358,
      "learning_rate": 5.656170212765958e-06,
      "loss": 0.0835,
      "step": 6413
    },
    {
      "epoch": 1.4738051470588236,
      "grad_norm": 1.3607927560806274,
      "learning_rate": 5.65531914893617e-06,
      "loss": 0.1015,
      "step": 6414
    },
    {
      "epoch": 1.4740349264705883,
      "grad_norm": 1.1884485483169556,
      "learning_rate": 5.654468085106384e-06,
      "loss": 0.0926,
      "step": 6415
    },
    {
      "epoch": 1.4742647058823528,
      "grad_norm": 0.9733509421348572,
      "learning_rate": 5.653617021276596e-06,
      "loss": 0.0459,
      "step": 6416
    },
    {
      "epoch": 1.4744944852941178,
      "grad_norm": 1.100218415260315,
      "learning_rate": 5.652765957446809e-06,
      "loss": 0.0846,
      "step": 6417
    },
    {
      "epoch": 1.4747242647058822,
      "grad_norm": 1.1978055238723755,
      "learning_rate": 5.651914893617022e-06,
      "loss": 0.0647,
      "step": 6418
    },
    {
      "epoch": 1.4749540441176472,
      "grad_norm": 1.1982102394104004,
      "learning_rate": 5.651063829787234e-06,
      "loss": 0.0612,
      "step": 6419
    },
    {
      "epoch": 1.4751838235294117,
      "grad_norm": 1.4371659755706787,
      "learning_rate": 5.650212765957447e-06,
      "loss": 0.0979,
      "step": 6420
    },
    {
      "epoch": 1.4754136029411764,
      "grad_norm": 1.6618473529815674,
      "learning_rate": 5.64936170212766e-06,
      "loss": 0.1206,
      "step": 6421
    },
    {
      "epoch": 1.4756433823529411,
      "grad_norm": 1.0112082958221436,
      "learning_rate": 5.648510638297873e-06,
      "loss": 0.0738,
      "step": 6422
    },
    {
      "epoch": 1.4758731617647058,
      "grad_norm": 1.0884023904800415,
      "learning_rate": 5.647659574468085e-06,
      "loss": 0.0647,
      "step": 6423
    },
    {
      "epoch": 1.4761029411764706,
      "grad_norm": 1.0760018825531006,
      "learning_rate": 5.646808510638298e-06,
      "loss": 0.0804,
      "step": 6424
    },
    {
      "epoch": 1.4763327205882353,
      "grad_norm": 1.2735092639923096,
      "learning_rate": 5.645957446808511e-06,
      "loss": 0.0546,
      "step": 6425
    },
    {
      "epoch": 1.4765625,
      "grad_norm": 1.404678225517273,
      "learning_rate": 5.645106382978724e-06,
      "loss": 0.1099,
      "step": 6426
    },
    {
      "epoch": 1.4767922794117647,
      "grad_norm": 1.3327313661575317,
      "learning_rate": 5.644255319148937e-06,
      "loss": 0.0559,
      "step": 6427
    },
    {
      "epoch": 1.4770220588235294,
      "grad_norm": 1.0903822183609009,
      "learning_rate": 5.643404255319149e-06,
      "loss": 0.0829,
      "step": 6428
    },
    {
      "epoch": 1.4772518382352942,
      "grad_norm": 0.9690878391265869,
      "learning_rate": 5.6425531914893615e-06,
      "loss": 0.0507,
      "step": 6429
    },
    {
      "epoch": 1.4774816176470589,
      "grad_norm": 1.2180702686309814,
      "learning_rate": 5.6417021276595756e-06,
      "loss": 0.0758,
      "step": 6430
    },
    {
      "epoch": 1.4777113970588236,
      "grad_norm": 1.2301324605941772,
      "learning_rate": 5.640851063829788e-06,
      "loss": 0.0948,
      "step": 6431
    },
    {
      "epoch": 1.4779411764705883,
      "grad_norm": 1.2943381071090698,
      "learning_rate": 5.64e-06,
      "loss": 0.0823,
      "step": 6432
    },
    {
      "epoch": 1.4781709558823528,
      "grad_norm": 1.5140842199325562,
      "learning_rate": 5.639148936170213e-06,
      "loss": 0.0966,
      "step": 6433
    },
    {
      "epoch": 1.4784007352941178,
      "grad_norm": 2.8772671222686768,
      "learning_rate": 5.638297872340426e-06,
      "loss": 0.0973,
      "step": 6434
    },
    {
      "epoch": 1.4786305147058822,
      "grad_norm": 1.1037254333496094,
      "learning_rate": 5.63744680851064e-06,
      "loss": 0.0678,
      "step": 6435
    },
    {
      "epoch": 1.4788602941176472,
      "grad_norm": 1.0502718687057495,
      "learning_rate": 5.636595744680852e-06,
      "loss": 0.0768,
      "step": 6436
    },
    {
      "epoch": 1.4790900735294117,
      "grad_norm": 1.3204706907272339,
      "learning_rate": 5.635744680851064e-06,
      "loss": 0.0848,
      "step": 6437
    },
    {
      "epoch": 1.4793198529411764,
      "grad_norm": 1.2465702295303345,
      "learning_rate": 5.6348936170212775e-06,
      "loss": 0.0672,
      "step": 6438
    },
    {
      "epoch": 1.4795496323529411,
      "grad_norm": 1.4333302974700928,
      "learning_rate": 5.63404255319149e-06,
      "loss": 0.1076,
      "step": 6439
    },
    {
      "epoch": 1.4797794117647058,
      "grad_norm": 1.4305977821350098,
      "learning_rate": 5.633191489361702e-06,
      "loss": 0.071,
      "step": 6440
    },
    {
      "epoch": 1.4800091911764706,
      "grad_norm": 1.3793249130249023,
      "learning_rate": 5.632340425531916e-06,
      "loss": 0.0776,
      "step": 6441
    },
    {
      "epoch": 1.4802389705882353,
      "grad_norm": 1.8155577182769775,
      "learning_rate": 5.6314893617021285e-06,
      "loss": 0.1023,
      "step": 6442
    },
    {
      "epoch": 1.48046875,
      "grad_norm": 0.9367926120758057,
      "learning_rate": 5.630638297872341e-06,
      "loss": 0.0704,
      "step": 6443
    },
    {
      "epoch": 1.4806985294117647,
      "grad_norm": 1.5737810134887695,
      "learning_rate": 5.629787234042554e-06,
      "loss": 0.0972,
      "step": 6444
    },
    {
      "epoch": 1.4809283088235294,
      "grad_norm": 1.2805726528167725,
      "learning_rate": 5.628936170212766e-06,
      "loss": 0.0719,
      "step": 6445
    },
    {
      "epoch": 1.4811580882352942,
      "grad_norm": 1.043591856956482,
      "learning_rate": 5.628085106382979e-06,
      "loss": 0.067,
      "step": 6446
    },
    {
      "epoch": 1.4813878676470589,
      "grad_norm": 1.0236129760742188,
      "learning_rate": 5.627234042553193e-06,
      "loss": 0.0809,
      "step": 6447
    },
    {
      "epoch": 1.4816176470588236,
      "grad_norm": 1.6859451532363892,
      "learning_rate": 5.626382978723405e-06,
      "loss": 0.0623,
      "step": 6448
    },
    {
      "epoch": 1.4818474264705883,
      "grad_norm": 1.5625277757644653,
      "learning_rate": 5.625531914893617e-06,
      "loss": 0.0825,
      "step": 6449
    },
    {
      "epoch": 1.4820772058823528,
      "grad_norm": 1.150428056716919,
      "learning_rate": 5.6246808510638305e-06,
      "loss": 0.0538,
      "step": 6450
    },
    {
      "epoch": 1.4823069852941178,
      "grad_norm": 1.7656760215759277,
      "learning_rate": 5.623829787234043e-06,
      "loss": 0.079,
      "step": 6451
    },
    {
      "epoch": 1.4825367647058822,
      "grad_norm": 1.6655206680297852,
      "learning_rate": 5.622978723404255e-06,
      "loss": 0.1046,
      "step": 6452
    },
    {
      "epoch": 1.4827665441176472,
      "grad_norm": 1.701249361038208,
      "learning_rate": 5.622127659574469e-06,
      "loss": 0.1084,
      "step": 6453
    },
    {
      "epoch": 1.4829963235294117,
      "grad_norm": 1.1409685611724854,
      "learning_rate": 5.6212765957446815e-06,
      "loss": 0.0814,
      "step": 6454
    },
    {
      "epoch": 1.4832261029411764,
      "grad_norm": 1.5247358083724976,
      "learning_rate": 5.620425531914894e-06,
      "loss": 0.0583,
      "step": 6455
    },
    {
      "epoch": 1.4834558823529411,
      "grad_norm": 1.1712965965270996,
      "learning_rate": 5.619574468085107e-06,
      "loss": 0.0778,
      "step": 6456
    },
    {
      "epoch": 1.4836856617647058,
      "grad_norm": 1.4196150302886963,
      "learning_rate": 5.618723404255319e-06,
      "loss": 0.1097,
      "step": 6457
    },
    {
      "epoch": 1.4839154411764706,
      "grad_norm": 1.1067622900009155,
      "learning_rate": 5.617872340425532e-06,
      "loss": 0.0634,
      "step": 6458
    },
    {
      "epoch": 1.4841452205882353,
      "grad_norm": 1.2113615274429321,
      "learning_rate": 5.617021276595746e-06,
      "loss": 0.1009,
      "step": 6459
    },
    {
      "epoch": 1.484375,
      "grad_norm": 0.9533315896987915,
      "learning_rate": 5.616170212765958e-06,
      "loss": 0.0648,
      "step": 6460
    },
    {
      "epoch": 1.4846047794117647,
      "grad_norm": 1.3014445304870605,
      "learning_rate": 5.61531914893617e-06,
      "loss": 0.1188,
      "step": 6461
    },
    {
      "epoch": 1.4848345588235294,
      "grad_norm": 1.645561695098877,
      "learning_rate": 5.6144680851063835e-06,
      "loss": 0.08,
      "step": 6462
    },
    {
      "epoch": 1.4850643382352942,
      "grad_norm": 1.1606038808822632,
      "learning_rate": 5.613617021276596e-06,
      "loss": 0.0798,
      "step": 6463
    },
    {
      "epoch": 1.4852941176470589,
      "grad_norm": 1.379187822341919,
      "learning_rate": 5.612765957446808e-06,
      "loss": 0.0879,
      "step": 6464
    },
    {
      "epoch": 1.4855238970588236,
      "grad_norm": 0.8765433430671692,
      "learning_rate": 5.611914893617022e-06,
      "loss": 0.0659,
      "step": 6465
    },
    {
      "epoch": 1.4857536764705883,
      "grad_norm": 1.136173129081726,
      "learning_rate": 5.6110638297872345e-06,
      "loss": 0.0909,
      "step": 6466
    },
    {
      "epoch": 1.4859834558823528,
      "grad_norm": 1.3336855173110962,
      "learning_rate": 5.610212765957447e-06,
      "loss": 0.0995,
      "step": 6467
    },
    {
      "epoch": 1.4862132352941178,
      "grad_norm": 1.7641053199768066,
      "learning_rate": 5.60936170212766e-06,
      "loss": 0.102,
      "step": 6468
    },
    {
      "epoch": 1.4864430147058822,
      "grad_norm": 1.1679754257202148,
      "learning_rate": 5.608510638297872e-06,
      "loss": 0.0608,
      "step": 6469
    },
    {
      "epoch": 1.4866727941176472,
      "grad_norm": 1.4682626724243164,
      "learning_rate": 5.6076595744680854e-06,
      "loss": 0.0766,
      "step": 6470
    },
    {
      "epoch": 1.4869025735294117,
      "grad_norm": 0.8496382832527161,
      "learning_rate": 5.606808510638299e-06,
      "loss": 0.0643,
      "step": 6471
    },
    {
      "epoch": 1.4871323529411764,
      "grad_norm": 1.0063966512680054,
      "learning_rate": 5.605957446808511e-06,
      "loss": 0.0736,
      "step": 6472
    },
    {
      "epoch": 1.4873621323529411,
      "grad_norm": 0.9103250503540039,
      "learning_rate": 5.605106382978723e-06,
      "loss": 0.0726,
      "step": 6473
    },
    {
      "epoch": 1.4875919117647058,
      "grad_norm": 1.5534507036209106,
      "learning_rate": 5.6042553191489364e-06,
      "loss": 0.0888,
      "step": 6474
    },
    {
      "epoch": 1.4878216911764706,
      "grad_norm": 0.9422711133956909,
      "learning_rate": 5.60340425531915e-06,
      "loss": 0.0502,
      "step": 6475
    },
    {
      "epoch": 1.4880514705882353,
      "grad_norm": 1.437659740447998,
      "learning_rate": 5.602553191489362e-06,
      "loss": 0.0946,
      "step": 6476
    },
    {
      "epoch": 1.48828125,
      "grad_norm": 1.1465259790420532,
      "learning_rate": 5.601702127659575e-06,
      "loss": 0.0823,
      "step": 6477
    },
    {
      "epoch": 1.4885110294117647,
      "grad_norm": 1.440402865409851,
      "learning_rate": 5.600851063829787e-06,
      "loss": 0.1064,
      "step": 6478
    },
    {
      "epoch": 1.4887408088235294,
      "grad_norm": 1.2071527242660522,
      "learning_rate": 5.600000000000001e-06,
      "loss": 0.0758,
      "step": 6479
    },
    {
      "epoch": 1.4889705882352942,
      "grad_norm": 1.432267189025879,
      "learning_rate": 5.599148936170214e-06,
      "loss": 0.0788,
      "step": 6480
    },
    {
      "epoch": 1.4892003676470589,
      "grad_norm": 1.7128615379333496,
      "learning_rate": 5.598297872340426e-06,
      "loss": 0.0788,
      "step": 6481
    },
    {
      "epoch": 1.4894301470588236,
      "grad_norm": 1.7646679878234863,
      "learning_rate": 5.597446808510639e-06,
      "loss": 0.0975,
      "step": 6482
    },
    {
      "epoch": 1.4896599264705883,
      "grad_norm": 1.1207549571990967,
      "learning_rate": 5.596595744680852e-06,
      "loss": 0.0508,
      "step": 6483
    },
    {
      "epoch": 1.4898897058823528,
      "grad_norm": 1.5151399374008179,
      "learning_rate": 5.595744680851064e-06,
      "loss": 0.134,
      "step": 6484
    },
    {
      "epoch": 1.4901194852941178,
      "grad_norm": 1.0524848699569702,
      "learning_rate": 5.594893617021278e-06,
      "loss": 0.0676,
      "step": 6485
    },
    {
      "epoch": 1.4903492647058822,
      "grad_norm": 1.197543740272522,
      "learning_rate": 5.59404255319149e-06,
      "loss": 0.0715,
      "step": 6486
    },
    {
      "epoch": 1.4905790441176472,
      "grad_norm": 1.3879990577697754,
      "learning_rate": 5.5931914893617026e-06,
      "loss": 0.065,
      "step": 6487
    },
    {
      "epoch": 1.4908088235294117,
      "grad_norm": 1.4363845586776733,
      "learning_rate": 5.592340425531916e-06,
      "loss": 0.0821,
      "step": 6488
    },
    {
      "epoch": 1.4910386029411764,
      "grad_norm": 1.0759021043777466,
      "learning_rate": 5.591489361702128e-06,
      "loss": 0.0708,
      "step": 6489
    },
    {
      "epoch": 1.4912683823529411,
      "grad_norm": 1.170707106590271,
      "learning_rate": 5.59063829787234e-06,
      "loss": 0.073,
      "step": 6490
    },
    {
      "epoch": 1.4914981617647058,
      "grad_norm": 1.1578779220581055,
      "learning_rate": 5.589787234042554e-06,
      "loss": 0.0674,
      "step": 6491
    },
    {
      "epoch": 1.4917279411764706,
      "grad_norm": 1.3314532041549683,
      "learning_rate": 5.588936170212767e-06,
      "loss": 0.1189,
      "step": 6492
    },
    {
      "epoch": 1.4919577205882353,
      "grad_norm": 1.3017023801803589,
      "learning_rate": 5.588085106382979e-06,
      "loss": 0.11,
      "step": 6493
    },
    {
      "epoch": 1.4921875,
      "grad_norm": 1.435705542564392,
      "learning_rate": 5.587234042553192e-06,
      "loss": 0.104,
      "step": 6494
    },
    {
      "epoch": 1.4924172794117647,
      "grad_norm": 1.2109222412109375,
      "learning_rate": 5.5863829787234045e-06,
      "loss": 0.0905,
      "step": 6495
    },
    {
      "epoch": 1.4926470588235294,
      "grad_norm": 1.365768313407898,
      "learning_rate": 5.585531914893617e-06,
      "loss": 0.0842,
      "step": 6496
    },
    {
      "epoch": 1.4928768382352942,
      "grad_norm": 1.5314537286758423,
      "learning_rate": 5.584680851063831e-06,
      "loss": 0.0806,
      "step": 6497
    },
    {
      "epoch": 1.4931066176470589,
      "grad_norm": 1.3476742506027222,
      "learning_rate": 5.583829787234043e-06,
      "loss": 0.0752,
      "step": 6498
    },
    {
      "epoch": 1.4933363970588236,
      "grad_norm": 1.0665559768676758,
      "learning_rate": 5.5829787234042555e-06,
      "loss": 0.0705,
      "step": 6499
    },
    {
      "epoch": 1.4935661764705883,
      "grad_norm": 1.3833366632461548,
      "learning_rate": 5.582127659574469e-06,
      "loss": 0.0911,
      "step": 6500
    },
    {
      "epoch": 1.4935661764705883,
      "eval_loss": 0.08454028517007828,
      "eval_runtime": 1963.7937,
      "eval_samples_per_second": 4.535,
      "eval_steps_per_second": 2.268,
      "step": 6500
    },
    {
      "epoch": 1.4937959558823528,
      "grad_norm": 0.9778311252593994,
      "learning_rate": 5.581276595744681e-06,
      "loss": 0.0654,
      "step": 6501
    },
    {
      "epoch": 1.4940257352941178,
      "grad_norm": 1.5731197595596313,
      "learning_rate": 5.580425531914893e-06,
      "loss": 0.0764,
      "step": 6502
    },
    {
      "epoch": 1.4942555147058822,
      "grad_norm": 1.125435709953308,
      "learning_rate": 5.579574468085107e-06,
      "loss": 0.089,
      "step": 6503
    },
    {
      "epoch": 1.4944852941176472,
      "grad_norm": 1.4685168266296387,
      "learning_rate": 5.57872340425532e-06,
      "loss": 0.1029,
      "step": 6504
    },
    {
      "epoch": 1.4947150735294117,
      "grad_norm": 1.1617215871810913,
      "learning_rate": 5.577872340425532e-06,
      "loss": 0.0671,
      "step": 6505
    },
    {
      "epoch": 1.4949448529411764,
      "grad_norm": 1.4922969341278076,
      "learning_rate": 5.577021276595745e-06,
      "loss": 0.0962,
      "step": 6506
    },
    {
      "epoch": 1.4951746323529411,
      "grad_norm": 1.312772274017334,
      "learning_rate": 5.5761702127659575e-06,
      "loss": 0.0638,
      "step": 6507
    },
    {
      "epoch": 1.4954044117647058,
      "grad_norm": 1.1236854791641235,
      "learning_rate": 5.57531914893617e-06,
      "loss": 0.0879,
      "step": 6508
    },
    {
      "epoch": 1.4956341911764706,
      "grad_norm": 1.3418936729431152,
      "learning_rate": 5.574468085106384e-06,
      "loss": 0.0777,
      "step": 6509
    },
    {
      "epoch": 1.4958639705882353,
      "grad_norm": 1.3633744716644287,
      "learning_rate": 5.573617021276596e-06,
      "loss": 0.0855,
      "step": 6510
    },
    {
      "epoch": 1.49609375,
      "grad_norm": 1.2175288200378418,
      "learning_rate": 5.5727659574468085e-06,
      "loss": 0.0771,
      "step": 6511
    },
    {
      "epoch": 1.4963235294117647,
      "grad_norm": 1.105061650276184,
      "learning_rate": 5.571914893617022e-06,
      "loss": 0.0784,
      "step": 6512
    },
    {
      "epoch": 1.4965533088235294,
      "grad_norm": 1.329357385635376,
      "learning_rate": 5.571063829787234e-06,
      "loss": 0.0837,
      "step": 6513
    },
    {
      "epoch": 1.4967830882352942,
      "grad_norm": 1.3339605331420898,
      "learning_rate": 5.570212765957447e-06,
      "loss": 0.0791,
      "step": 6514
    },
    {
      "epoch": 1.4970128676470589,
      "grad_norm": 1.4004453420639038,
      "learning_rate": 5.56936170212766e-06,
      "loss": 0.0748,
      "step": 6515
    },
    {
      "epoch": 1.4972426470588236,
      "grad_norm": 0.9581636190414429,
      "learning_rate": 5.568510638297873e-06,
      "loss": 0.0579,
      "step": 6516
    },
    {
      "epoch": 1.4974724264705883,
      "grad_norm": 1.460604190826416,
      "learning_rate": 5.567659574468085e-06,
      "loss": 0.1024,
      "step": 6517
    },
    {
      "epoch": 1.4977022058823528,
      "grad_norm": 1.3883435726165771,
      "learning_rate": 5.566808510638298e-06,
      "loss": 0.074,
      "step": 6518
    },
    {
      "epoch": 1.4979319852941178,
      "grad_norm": 1.2907912731170654,
      "learning_rate": 5.565957446808511e-06,
      "loss": 0.0843,
      "step": 6519
    },
    {
      "epoch": 1.4981617647058822,
      "grad_norm": 1.2363145351409912,
      "learning_rate": 5.5651063829787245e-06,
      "loss": 0.0688,
      "step": 6520
    },
    {
      "epoch": 1.4983915441176472,
      "grad_norm": 1.3138574361801147,
      "learning_rate": 5.564255319148937e-06,
      "loss": 0.0918,
      "step": 6521
    },
    {
      "epoch": 1.4986213235294117,
      "grad_norm": 1.2063709497451782,
      "learning_rate": 5.563404255319149e-06,
      "loss": 0.0737,
      "step": 6522
    },
    {
      "epoch": 1.4988511029411764,
      "grad_norm": 0.88443922996521,
      "learning_rate": 5.562553191489362e-06,
      "loss": 0.0615,
      "step": 6523
    },
    {
      "epoch": 1.4990808823529411,
      "grad_norm": 1.598944067955017,
      "learning_rate": 5.5617021276595755e-06,
      "loss": 0.1168,
      "step": 6524
    },
    {
      "epoch": 1.4993106617647058,
      "grad_norm": 1.166503667831421,
      "learning_rate": 5.560851063829788e-06,
      "loss": 0.0712,
      "step": 6525
    },
    {
      "epoch": 1.4995404411764706,
      "grad_norm": 1.2243956327438354,
      "learning_rate": 5.560000000000001e-06,
      "loss": 0.0949,
      "step": 6526
    },
    {
      "epoch": 1.4997702205882353,
      "grad_norm": 1.2277345657348633,
      "learning_rate": 5.559148936170213e-06,
      "loss": 0.0557,
      "step": 6527
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.6842527389526367,
      "learning_rate": 5.558297872340426e-06,
      "loss": 0.067,
      "step": 6528
    },
    {
      "epoch": 1.5002297794117647,
      "grad_norm": 1.338994026184082,
      "learning_rate": 5.55744680851064e-06,
      "loss": 0.1413,
      "step": 6529
    },
    {
      "epoch": 1.5004595588235294,
      "grad_norm": 1.3834915161132812,
      "learning_rate": 5.556595744680852e-06,
      "loss": 0.082,
      "step": 6530
    },
    {
      "epoch": 1.5006893382352942,
      "grad_norm": 1.1708784103393555,
      "learning_rate": 5.555744680851064e-06,
      "loss": 0.0897,
      "step": 6531
    },
    {
      "epoch": 1.5009191176470589,
      "grad_norm": 1.1989505290985107,
      "learning_rate": 5.5548936170212775e-06,
      "loss": 0.0849,
      "step": 6532
    },
    {
      "epoch": 1.5011488970588234,
      "grad_norm": 1.1661943197250366,
      "learning_rate": 5.55404255319149e-06,
      "loss": 0.0831,
      "step": 6533
    },
    {
      "epoch": 1.5013786764705883,
      "grad_norm": 0.7941313982009888,
      "learning_rate": 5.553191489361702e-06,
      "loss": 0.0389,
      "step": 6534
    },
    {
      "epoch": 1.5016084558823528,
      "grad_norm": 1.348467230796814,
      "learning_rate": 5.552340425531916e-06,
      "loss": 0.1042,
      "step": 6535
    },
    {
      "epoch": 1.5018382352941178,
      "grad_norm": 1.2357923984527588,
      "learning_rate": 5.5514893617021284e-06,
      "loss": 0.0875,
      "step": 6536
    },
    {
      "epoch": 1.5020680147058822,
      "grad_norm": 0.779340386390686,
      "learning_rate": 5.550638297872341e-06,
      "loss": 0.0662,
      "step": 6537
    },
    {
      "epoch": 1.5022977941176472,
      "grad_norm": 1.348504662513733,
      "learning_rate": 5.549787234042554e-06,
      "loss": 0.0788,
      "step": 6538
    },
    {
      "epoch": 1.5025275735294117,
      "grad_norm": 1.4082021713256836,
      "learning_rate": 5.548936170212766e-06,
      "loss": 0.1026,
      "step": 6539
    },
    {
      "epoch": 1.5027573529411766,
      "grad_norm": 1.0868277549743652,
      "learning_rate": 5.548085106382979e-06,
      "loss": 0.0621,
      "step": 6540
    },
    {
      "epoch": 1.5029871323529411,
      "grad_norm": 1.496273159980774,
      "learning_rate": 5.547234042553193e-06,
      "loss": 0.1376,
      "step": 6541
    },
    {
      "epoch": 1.5032169117647058,
      "grad_norm": 1.2156689167022705,
      "learning_rate": 5.546382978723405e-06,
      "loss": 0.0904,
      "step": 6542
    },
    {
      "epoch": 1.5034466911764706,
      "grad_norm": 1.1819547414779663,
      "learning_rate": 5.545531914893617e-06,
      "loss": 0.0831,
      "step": 6543
    },
    {
      "epoch": 1.5036764705882353,
      "grad_norm": 1.4481964111328125,
      "learning_rate": 5.5446808510638304e-06,
      "loss": 0.0744,
      "step": 6544
    },
    {
      "epoch": 1.50390625,
      "grad_norm": 1.0029934644699097,
      "learning_rate": 5.543829787234043e-06,
      "loss": 0.075,
      "step": 6545
    },
    {
      "epoch": 1.5041360294117647,
      "grad_norm": 0.8737738132476807,
      "learning_rate": 5.542978723404255e-06,
      "loss": 0.0391,
      "step": 6546
    },
    {
      "epoch": 1.5043658088235294,
      "grad_norm": 1.2656201124191284,
      "learning_rate": 5.542127659574469e-06,
      "loss": 0.0614,
      "step": 6547
    },
    {
      "epoch": 1.5045955882352942,
      "grad_norm": 1.163732647895813,
      "learning_rate": 5.541276595744681e-06,
      "loss": 0.08,
      "step": 6548
    },
    {
      "epoch": 1.5048253676470589,
      "grad_norm": 1.2358840703964233,
      "learning_rate": 5.540425531914894e-06,
      "loss": 0.0669,
      "step": 6549
    },
    {
      "epoch": 1.5050551470588234,
      "grad_norm": 1.1814240217208862,
      "learning_rate": 5.539574468085107e-06,
      "loss": 0.0694,
      "step": 6550
    },
    {
      "epoch": 1.5052849264705883,
      "grad_norm": 1.2096669673919678,
      "learning_rate": 5.538723404255319e-06,
      "loss": 0.0866,
      "step": 6551
    },
    {
      "epoch": 1.5055147058823528,
      "grad_norm": 1.298323154449463,
      "learning_rate": 5.5378723404255316e-06,
      "loss": 0.078,
      "step": 6552
    },
    {
      "epoch": 1.5057444852941178,
      "grad_norm": 1.278473138809204,
      "learning_rate": 5.5370212765957456e-06,
      "loss": 0.0932,
      "step": 6553
    },
    {
      "epoch": 1.5059742647058822,
      "grad_norm": 1.0892889499664307,
      "learning_rate": 5.536170212765958e-06,
      "loss": 0.082,
      "step": 6554
    },
    {
      "epoch": 1.5062040441176472,
      "grad_norm": 1.4339481592178345,
      "learning_rate": 5.53531914893617e-06,
      "loss": 0.0987,
      "step": 6555
    },
    {
      "epoch": 1.5064338235294117,
      "grad_norm": 0.9107087254524231,
      "learning_rate": 5.534468085106383e-06,
      "loss": 0.064,
      "step": 6556
    },
    {
      "epoch": 1.5066636029411766,
      "grad_norm": 1.4217931032180786,
      "learning_rate": 5.533617021276596e-06,
      "loss": 0.0589,
      "step": 6557
    },
    {
      "epoch": 1.5068933823529411,
      "grad_norm": 1.338614583015442,
      "learning_rate": 5.532765957446808e-06,
      "loss": 0.082,
      "step": 6558
    },
    {
      "epoch": 1.5071231617647058,
      "grad_norm": 1.2268931865692139,
      "learning_rate": 5.531914893617022e-06,
      "loss": 0.0909,
      "step": 6559
    },
    {
      "epoch": 1.5073529411764706,
      "grad_norm": 1.3815830945968628,
      "learning_rate": 5.531063829787234e-06,
      "loss": 0.0576,
      "step": 6560
    },
    {
      "epoch": 1.5075827205882353,
      "grad_norm": 1.1325064897537231,
      "learning_rate": 5.530212765957447e-06,
      "loss": 0.0703,
      "step": 6561
    },
    {
      "epoch": 1.5078125,
      "grad_norm": 1.279879093170166,
      "learning_rate": 5.52936170212766e-06,
      "loss": 0.0723,
      "step": 6562
    },
    {
      "epoch": 1.5080422794117647,
      "grad_norm": 1.1068925857543945,
      "learning_rate": 5.528510638297872e-06,
      "loss": 0.079,
      "step": 6563
    },
    {
      "epoch": 1.5082720588235294,
      "grad_norm": 1.1584888696670532,
      "learning_rate": 5.527659574468086e-06,
      "loss": 0.0792,
      "step": 6564
    },
    {
      "epoch": 1.5085018382352942,
      "grad_norm": 1.0507291555404663,
      "learning_rate": 5.5268085106382985e-06,
      "loss": 0.0729,
      "step": 6565
    },
    {
      "epoch": 1.5087316176470589,
      "grad_norm": 1.124785304069519,
      "learning_rate": 5.525957446808511e-06,
      "loss": 0.0656,
      "step": 6566
    },
    {
      "epoch": 1.5089613970588234,
      "grad_norm": 1.039441466331482,
      "learning_rate": 5.525106382978724e-06,
      "loss": 0.0645,
      "step": 6567
    },
    {
      "epoch": 1.5091911764705883,
      "grad_norm": 1.351935625076294,
      "learning_rate": 5.524255319148936e-06,
      "loss": 0.084,
      "step": 6568
    },
    {
      "epoch": 1.5094209558823528,
      "grad_norm": 1.0020685195922852,
      "learning_rate": 5.5234042553191495e-06,
      "loss": 0.0708,
      "step": 6569
    },
    {
      "epoch": 1.5096507352941178,
      "grad_norm": 1.0826363563537598,
      "learning_rate": 5.522553191489363e-06,
      "loss": 0.0584,
      "step": 6570
    },
    {
      "epoch": 1.5098805147058822,
      "grad_norm": 1.1149221658706665,
      "learning_rate": 5.521702127659575e-06,
      "loss": 0.0733,
      "step": 6571
    },
    {
      "epoch": 1.5101102941176472,
      "grad_norm": 1.1154769659042358,
      "learning_rate": 5.520851063829787e-06,
      "loss": 0.0622,
      "step": 6572
    },
    {
      "epoch": 1.5103400735294117,
      "grad_norm": 1.4596328735351562,
      "learning_rate": 5.5200000000000005e-06,
      "loss": 0.0953,
      "step": 6573
    },
    {
      "epoch": 1.5105698529411766,
      "grad_norm": 1.2024047374725342,
      "learning_rate": 5.519148936170214e-06,
      "loss": 0.1061,
      "step": 6574
    },
    {
      "epoch": 1.5107996323529411,
      "grad_norm": 1.0473183393478394,
      "learning_rate": 5.518297872340426e-06,
      "loss": 0.0805,
      "step": 6575
    },
    {
      "epoch": 1.5110294117647058,
      "grad_norm": 2.0665173530578613,
      "learning_rate": 5.517446808510639e-06,
      "loss": 0.1139,
      "step": 6576
    },
    {
      "epoch": 1.5112591911764706,
      "grad_norm": 1.837326169013977,
      "learning_rate": 5.5165957446808515e-06,
      "loss": 0.0865,
      "step": 6577
    },
    {
      "epoch": 1.5114889705882353,
      "grad_norm": 1.0849215984344482,
      "learning_rate": 5.515744680851064e-06,
      "loss": 0.0795,
      "step": 6578
    },
    {
      "epoch": 1.51171875,
      "grad_norm": 1.0548723936080933,
      "learning_rate": 5.514893617021278e-06,
      "loss": 0.0567,
      "step": 6579
    },
    {
      "epoch": 1.5119485294117647,
      "grad_norm": 2.01446533203125,
      "learning_rate": 5.51404255319149e-06,
      "loss": 0.1267,
      "step": 6580
    },
    {
      "epoch": 1.5121783088235294,
      "grad_norm": 1.384660243988037,
      "learning_rate": 5.5131914893617025e-06,
      "loss": 0.0927,
      "step": 6581
    },
    {
      "epoch": 1.5124080882352942,
      "grad_norm": 1.789541482925415,
      "learning_rate": 5.512340425531916e-06,
      "loss": 0.1276,
      "step": 6582
    },
    {
      "epoch": 1.5126378676470589,
      "grad_norm": 1.066121220588684,
      "learning_rate": 5.511489361702128e-06,
      "loss": 0.0561,
      "step": 6583
    },
    {
      "epoch": 1.5128676470588234,
      "grad_norm": 1.1581006050109863,
      "learning_rate": 5.51063829787234e-06,
      "loss": 0.0716,
      "step": 6584
    },
    {
      "epoch": 1.5130974264705883,
      "grad_norm": 2.044590950012207,
      "learning_rate": 5.509787234042554e-06,
      "loss": 0.1125,
      "step": 6585
    },
    {
      "epoch": 1.5133272058823528,
      "grad_norm": 1.7451084852218628,
      "learning_rate": 5.508936170212767e-06,
      "loss": 0.0753,
      "step": 6586
    },
    {
      "epoch": 1.5135569852941178,
      "grad_norm": 0.8644193410873413,
      "learning_rate": 5.508085106382979e-06,
      "loss": 0.0732,
      "step": 6587
    },
    {
      "epoch": 1.5137867647058822,
      "grad_norm": 0.8793730139732361,
      "learning_rate": 5.507234042553192e-06,
      "loss": 0.0584,
      "step": 6588
    },
    {
      "epoch": 1.5140165441176472,
      "grad_norm": 1.2376629114151,
      "learning_rate": 5.5063829787234045e-06,
      "loss": 0.0875,
      "step": 6589
    },
    {
      "epoch": 1.5142463235294117,
      "grad_norm": 1.200042486190796,
      "learning_rate": 5.505531914893617e-06,
      "loss": 0.0822,
      "step": 6590
    },
    {
      "epoch": 1.5144761029411766,
      "grad_norm": 1.0057284832000732,
      "learning_rate": 5.504680851063831e-06,
      "loss": 0.0521,
      "step": 6591
    },
    {
      "epoch": 1.5147058823529411,
      "grad_norm": 0.9020146131515503,
      "learning_rate": 5.503829787234043e-06,
      "loss": 0.0474,
      "step": 6592
    },
    {
      "epoch": 1.5149356617647058,
      "grad_norm": 1.1441328525543213,
      "learning_rate": 5.5029787234042555e-06,
      "loss": 0.1,
      "step": 6593
    },
    {
      "epoch": 1.5151654411764706,
      "grad_norm": 1.2610293626785278,
      "learning_rate": 5.502127659574469e-06,
      "loss": 0.1077,
      "step": 6594
    },
    {
      "epoch": 1.5153952205882353,
      "grad_norm": 1.1082007884979248,
      "learning_rate": 5.501276595744681e-06,
      "loss": 0.0728,
      "step": 6595
    },
    {
      "epoch": 1.515625,
      "grad_norm": 0.8805254697799683,
      "learning_rate": 5.500425531914893e-06,
      "loss": 0.0665,
      "step": 6596
    },
    {
      "epoch": 1.5158547794117647,
      "grad_norm": 1.5011496543884277,
      "learning_rate": 5.499574468085107e-06,
      "loss": 0.0929,
      "step": 6597
    },
    {
      "epoch": 1.5160845588235294,
      "grad_norm": 1.5780850648880005,
      "learning_rate": 5.49872340425532e-06,
      "loss": 0.0959,
      "step": 6598
    },
    {
      "epoch": 1.5163143382352942,
      "grad_norm": 1.163886308670044,
      "learning_rate": 5.497872340425532e-06,
      "loss": 0.0924,
      "step": 6599
    },
    {
      "epoch": 1.5165441176470589,
      "grad_norm": 1.359614610671997,
      "learning_rate": 5.497021276595745e-06,
      "loss": 0.1186,
      "step": 6600
    },
    {
      "epoch": 1.5167738970588234,
      "grad_norm": 1.0526326894760132,
      "learning_rate": 5.4961702127659574e-06,
      "loss": 0.0794,
      "step": 6601
    },
    {
      "epoch": 1.5170036764705883,
      "grad_norm": 0.8453187942504883,
      "learning_rate": 5.49531914893617e-06,
      "loss": 0.0382,
      "step": 6602
    },
    {
      "epoch": 1.5172334558823528,
      "grad_norm": 1.3172162771224976,
      "learning_rate": 5.494468085106384e-06,
      "loss": 0.0867,
      "step": 6603
    },
    {
      "epoch": 1.5174632352941178,
      "grad_norm": 1.5125186443328857,
      "learning_rate": 5.493617021276596e-06,
      "loss": 0.0704,
      "step": 6604
    },
    {
      "epoch": 1.5176930147058822,
      "grad_norm": 1.3270952701568604,
      "learning_rate": 5.492765957446808e-06,
      "loss": 0.1064,
      "step": 6605
    },
    {
      "epoch": 1.5179227941176472,
      "grad_norm": 1.3148245811462402,
      "learning_rate": 5.491914893617022e-06,
      "loss": 0.107,
      "step": 6606
    },
    {
      "epoch": 1.5181525735294117,
      "grad_norm": 1.497077226638794,
      "learning_rate": 5.491063829787234e-06,
      "loss": 0.1005,
      "step": 6607
    },
    {
      "epoch": 1.5183823529411766,
      "grad_norm": 0.8904431462287903,
      "learning_rate": 5.490212765957448e-06,
      "loss": 0.0675,
      "step": 6608
    },
    {
      "epoch": 1.5186121323529411,
      "grad_norm": 0.9351263046264648,
      "learning_rate": 5.48936170212766e-06,
      "loss": 0.0589,
      "step": 6609
    },
    {
      "epoch": 1.5188419117647058,
      "grad_norm": 1.0853005647659302,
      "learning_rate": 5.488510638297873e-06,
      "loss": 0.0668,
      "step": 6610
    },
    {
      "epoch": 1.5190716911764706,
      "grad_norm": 1.437754511833191,
      "learning_rate": 5.487659574468086e-06,
      "loss": 0.1066,
      "step": 6611
    },
    {
      "epoch": 1.5193014705882353,
      "grad_norm": 1.501945972442627,
      "learning_rate": 5.486808510638298e-06,
      "loss": 0.0876,
      "step": 6612
    },
    {
      "epoch": 1.51953125,
      "grad_norm": 1.030962347984314,
      "learning_rate": 5.485957446808511e-06,
      "loss": 0.0735,
      "step": 6613
    },
    {
      "epoch": 1.5197610294117647,
      "grad_norm": 1.2958647012710571,
      "learning_rate": 5.485106382978724e-06,
      "loss": 0.1003,
      "step": 6614
    },
    {
      "epoch": 1.5199908088235294,
      "grad_norm": 1.3007330894470215,
      "learning_rate": 5.484255319148937e-06,
      "loss": 0.0911,
      "step": 6615
    },
    {
      "epoch": 1.5202205882352942,
      "grad_norm": 1.268137812614441,
      "learning_rate": 5.483404255319149e-06,
      "loss": 0.0604,
      "step": 6616
    },
    {
      "epoch": 1.5204503676470589,
      "grad_norm": 1.0033626556396484,
      "learning_rate": 5.482553191489362e-06,
      "loss": 0.067,
      "step": 6617
    },
    {
      "epoch": 1.5206801470588234,
      "grad_norm": 0.8375017642974854,
      "learning_rate": 5.481702127659575e-06,
      "loss": 0.0635,
      "step": 6618
    },
    {
      "epoch": 1.5209099264705883,
      "grad_norm": 1.3023970127105713,
      "learning_rate": 5.480851063829788e-06,
      "loss": 0.0605,
      "step": 6619
    },
    {
      "epoch": 1.5211397058823528,
      "grad_norm": 1.795099139213562,
      "learning_rate": 5.480000000000001e-06,
      "loss": 0.1248,
      "step": 6620
    },
    {
      "epoch": 1.5213694852941178,
      "grad_norm": 1.3366793394088745,
      "learning_rate": 5.479148936170213e-06,
      "loss": 0.0897,
      "step": 6621
    },
    {
      "epoch": 1.5215992647058822,
      "grad_norm": 0.7412847280502319,
      "learning_rate": 5.4782978723404255e-06,
      "loss": 0.0502,
      "step": 6622
    },
    {
      "epoch": 1.5218290441176472,
      "grad_norm": 1.3379652500152588,
      "learning_rate": 5.4774468085106396e-06,
      "loss": 0.1237,
      "step": 6623
    },
    {
      "epoch": 1.5220588235294117,
      "grad_norm": 1.0445395708084106,
      "learning_rate": 5.476595744680852e-06,
      "loss": 0.0625,
      "step": 6624
    },
    {
      "epoch": 1.5222886029411766,
      "grad_norm": 1.1544673442840576,
      "learning_rate": 5.475744680851064e-06,
      "loss": 0.0793,
      "step": 6625
    },
    {
      "epoch": 1.5225183823529411,
      "grad_norm": 1.0861941576004028,
      "learning_rate": 5.474893617021277e-06,
      "loss": 0.1087,
      "step": 6626
    },
    {
      "epoch": 1.5227481617647058,
      "grad_norm": 1.2569653987884521,
      "learning_rate": 5.47404255319149e-06,
      "loss": 0.0765,
      "step": 6627
    },
    {
      "epoch": 1.5229779411764706,
      "grad_norm": 1.5352518558502197,
      "learning_rate": 5.473191489361702e-06,
      "loss": 0.0939,
      "step": 6628
    },
    {
      "epoch": 1.5232077205882353,
      "grad_norm": 1.2241626977920532,
      "learning_rate": 5.472340425531916e-06,
      "loss": 0.0833,
      "step": 6629
    },
    {
      "epoch": 1.5234375,
      "grad_norm": 1.588310718536377,
      "learning_rate": 5.471489361702128e-06,
      "loss": 0.1192,
      "step": 6630
    },
    {
      "epoch": 1.5236672794117647,
      "grad_norm": 1.183298110961914,
      "learning_rate": 5.470638297872341e-06,
      "loss": 0.0898,
      "step": 6631
    },
    {
      "epoch": 1.5238970588235294,
      "grad_norm": 1.538367509841919,
      "learning_rate": 5.469787234042554e-06,
      "loss": 0.0922,
      "step": 6632
    },
    {
      "epoch": 1.5241268382352942,
      "grad_norm": 1.3049194812774658,
      "learning_rate": 5.468936170212766e-06,
      "loss": 0.0878,
      "step": 6633
    },
    {
      "epoch": 1.5243566176470589,
      "grad_norm": 1.3608458042144775,
      "learning_rate": 5.4680851063829785e-06,
      "loss": 0.0909,
      "step": 6634
    },
    {
      "epoch": 1.5245863970588234,
      "grad_norm": 1.0275181531906128,
      "learning_rate": 5.4672340425531925e-06,
      "loss": 0.0626,
      "step": 6635
    },
    {
      "epoch": 1.5248161764705883,
      "grad_norm": 1.6968728303909302,
      "learning_rate": 5.466382978723405e-06,
      "loss": 0.0774,
      "step": 6636
    },
    {
      "epoch": 1.5250459558823528,
      "grad_norm": 1.4265660047531128,
      "learning_rate": 5.465531914893617e-06,
      "loss": 0.1101,
      "step": 6637
    },
    {
      "epoch": 1.5252757352941178,
      "grad_norm": 1.2671253681182861,
      "learning_rate": 5.46468085106383e-06,
      "loss": 0.0755,
      "step": 6638
    },
    {
      "epoch": 1.5255055147058822,
      "grad_norm": 1.0022319555282593,
      "learning_rate": 5.463829787234043e-06,
      "loss": 0.0752,
      "step": 6639
    },
    {
      "epoch": 1.5257352941176472,
      "grad_norm": 1.432164192199707,
      "learning_rate": 5.462978723404255e-06,
      "loss": 0.0944,
      "step": 6640
    },
    {
      "epoch": 1.5259650735294117,
      "grad_norm": 1.1633306741714478,
      "learning_rate": 5.462127659574469e-06,
      "loss": 0.0766,
      "step": 6641
    },
    {
      "epoch": 1.5261948529411766,
      "grad_norm": 1.0758744478225708,
      "learning_rate": 5.461276595744681e-06,
      "loss": 0.0718,
      "step": 6642
    },
    {
      "epoch": 1.5264246323529411,
      "grad_norm": 0.9332988858222961,
      "learning_rate": 5.460425531914894e-06,
      "loss": 0.0654,
      "step": 6643
    },
    {
      "epoch": 1.5266544117647058,
      "grad_norm": 1.2488439083099365,
      "learning_rate": 5.459574468085107e-06,
      "loss": 0.0815,
      "step": 6644
    },
    {
      "epoch": 1.5268841911764706,
      "grad_norm": 1.0221779346466064,
      "learning_rate": 5.458723404255319e-06,
      "loss": 0.0908,
      "step": 6645
    },
    {
      "epoch": 1.5271139705882353,
      "grad_norm": 1.4101536273956299,
      "learning_rate": 5.4578723404255315e-06,
      "loss": 0.0872,
      "step": 6646
    },
    {
      "epoch": 1.52734375,
      "grad_norm": 1.6958154439926147,
      "learning_rate": 5.4570212765957455e-06,
      "loss": 0.109,
      "step": 6647
    },
    {
      "epoch": 1.5275735294117647,
      "grad_norm": 1.470823049545288,
      "learning_rate": 5.456170212765958e-06,
      "loss": 0.1004,
      "step": 6648
    },
    {
      "epoch": 1.5278033088235294,
      "grad_norm": 1.2796465158462524,
      "learning_rate": 5.455319148936171e-06,
      "loss": 0.0791,
      "step": 6649
    },
    {
      "epoch": 1.5280330882352942,
      "grad_norm": 1.1301931142807007,
      "learning_rate": 5.454468085106383e-06,
      "loss": 0.0614,
      "step": 6650
    },
    {
      "epoch": 1.5282628676470589,
      "grad_norm": 1.0081617832183838,
      "learning_rate": 5.453617021276596e-06,
      "loss": 0.0667,
      "step": 6651
    },
    {
      "epoch": 1.5284926470588234,
      "grad_norm": 1.3852211236953735,
      "learning_rate": 5.45276595744681e-06,
      "loss": 0.0811,
      "step": 6652
    },
    {
      "epoch": 1.5287224264705883,
      "grad_norm": 1.1735024452209473,
      "learning_rate": 5.451914893617022e-06,
      "loss": 0.092,
      "step": 6653
    },
    {
      "epoch": 1.5289522058823528,
      "grad_norm": 0.8897980451583862,
      "learning_rate": 5.451063829787234e-06,
      "loss": 0.0698,
      "step": 6654
    },
    {
      "epoch": 1.5291819852941178,
      "grad_norm": 1.8349355459213257,
      "learning_rate": 5.4502127659574475e-06,
      "loss": 0.1422,
      "step": 6655
    },
    {
      "epoch": 1.5294117647058822,
      "grad_norm": 1.2247674465179443,
      "learning_rate": 5.44936170212766e-06,
      "loss": 0.0974,
      "step": 6656
    },
    {
      "epoch": 1.5296415441176472,
      "grad_norm": 1.0681970119476318,
      "learning_rate": 5.448510638297872e-06,
      "loss": 0.0667,
      "step": 6657
    },
    {
      "epoch": 1.5298713235294117,
      "grad_norm": 0.9607242345809937,
      "learning_rate": 5.447659574468086e-06,
      "loss": 0.0549,
      "step": 6658
    },
    {
      "epoch": 1.5301011029411766,
      "grad_norm": 1.1701000928878784,
      "learning_rate": 5.4468085106382985e-06,
      "loss": 0.0732,
      "step": 6659
    },
    {
      "epoch": 1.5303308823529411,
      "grad_norm": 1.4291832447052002,
      "learning_rate": 5.445957446808511e-06,
      "loss": 0.0947,
      "step": 6660
    },
    {
      "epoch": 1.5305606617647058,
      "grad_norm": 1.1700578927993774,
      "learning_rate": 5.445106382978724e-06,
      "loss": 0.0616,
      "step": 6661
    },
    {
      "epoch": 1.5307904411764706,
      "grad_norm": 1.1138273477554321,
      "learning_rate": 5.444255319148936e-06,
      "loss": 0.0834,
      "step": 6662
    },
    {
      "epoch": 1.5310202205882353,
      "grad_norm": 1.642183780670166,
      "learning_rate": 5.4434042553191494e-06,
      "loss": 0.1138,
      "step": 6663
    },
    {
      "epoch": 1.53125,
      "grad_norm": 0.9525337219238281,
      "learning_rate": 5.442553191489363e-06,
      "loss": 0.0565,
      "step": 6664
    },
    {
      "epoch": 1.5314797794117647,
      "grad_norm": 1.1806573867797852,
      "learning_rate": 5.441702127659575e-06,
      "loss": 0.0858,
      "step": 6665
    },
    {
      "epoch": 1.5317095588235294,
      "grad_norm": 1.1481980085372925,
      "learning_rate": 5.440851063829787e-06,
      "loss": 0.0858,
      "step": 6666
    },
    {
      "epoch": 1.5319393382352942,
      "grad_norm": 1.2791908979415894,
      "learning_rate": 5.4400000000000004e-06,
      "loss": 0.0533,
      "step": 6667
    },
    {
      "epoch": 1.5321691176470589,
      "grad_norm": 1.1833178997039795,
      "learning_rate": 5.439148936170214e-06,
      "loss": 0.0858,
      "step": 6668
    },
    {
      "epoch": 1.5323988970588234,
      "grad_norm": 1.220191478729248,
      "learning_rate": 5.438297872340426e-06,
      "loss": 0.1072,
      "step": 6669
    },
    {
      "epoch": 1.5326286764705883,
      "grad_norm": 1.428010106086731,
      "learning_rate": 5.437446808510639e-06,
      "loss": 0.0849,
      "step": 6670
    },
    {
      "epoch": 1.5328584558823528,
      "grad_norm": 0.9915823936462402,
      "learning_rate": 5.436595744680851e-06,
      "loss": 0.0551,
      "step": 6671
    },
    {
      "epoch": 1.5330882352941178,
      "grad_norm": 0.9015980958938599,
      "learning_rate": 5.435744680851064e-06,
      "loss": 0.0649,
      "step": 6672
    },
    {
      "epoch": 1.5333180147058822,
      "grad_norm": 1.2158801555633545,
      "learning_rate": 5.434893617021278e-06,
      "loss": 0.0782,
      "step": 6673
    },
    {
      "epoch": 1.5335477941176472,
      "grad_norm": 1.0122382640838623,
      "learning_rate": 5.43404255319149e-06,
      "loss": 0.0709,
      "step": 6674
    },
    {
      "epoch": 1.5337775735294117,
      "grad_norm": 1.264917254447937,
      "learning_rate": 5.433191489361702e-06,
      "loss": 0.0631,
      "step": 6675
    },
    {
      "epoch": 1.5340073529411766,
      "grad_norm": 1.3748234510421753,
      "learning_rate": 5.432340425531916e-06,
      "loss": 0.0645,
      "step": 6676
    },
    {
      "epoch": 1.5342371323529411,
      "grad_norm": 1.2817860841751099,
      "learning_rate": 5.431489361702128e-06,
      "loss": 0.069,
      "step": 6677
    },
    {
      "epoch": 1.5344669117647058,
      "grad_norm": 1.1400679349899292,
      "learning_rate": 5.43063829787234e-06,
      "loss": 0.0806,
      "step": 6678
    },
    {
      "epoch": 1.5346966911764706,
      "grad_norm": 1.370300531387329,
      "learning_rate": 5.429787234042554e-06,
      "loss": 0.0696,
      "step": 6679
    },
    {
      "epoch": 1.5349264705882353,
      "grad_norm": 1.2558337450027466,
      "learning_rate": 5.4289361702127666e-06,
      "loss": 0.0661,
      "step": 6680
    },
    {
      "epoch": 1.53515625,
      "grad_norm": 1.128949522972107,
      "learning_rate": 5.428085106382979e-06,
      "loss": 0.0791,
      "step": 6681
    },
    {
      "epoch": 1.5353860294117647,
      "grad_norm": 1.6818220615386963,
      "learning_rate": 5.427234042553192e-06,
      "loss": 0.0972,
      "step": 6682
    },
    {
      "epoch": 1.5356158088235294,
      "grad_norm": 1.1986446380615234,
      "learning_rate": 5.426382978723404e-06,
      "loss": 0.0661,
      "step": 6683
    },
    {
      "epoch": 1.5358455882352942,
      "grad_norm": 1.2206698656082153,
      "learning_rate": 5.425531914893617e-06,
      "loss": 0.0804,
      "step": 6684
    },
    {
      "epoch": 1.5360753676470589,
      "grad_norm": 1.2405457496643066,
      "learning_rate": 5.424680851063831e-06,
      "loss": 0.0679,
      "step": 6685
    },
    {
      "epoch": 1.5363051470588234,
      "grad_norm": 1.114831566810608,
      "learning_rate": 5.423829787234043e-06,
      "loss": 0.062,
      "step": 6686
    },
    {
      "epoch": 1.5365349264705883,
      "grad_norm": 0.9655945897102356,
      "learning_rate": 5.422978723404255e-06,
      "loss": 0.0575,
      "step": 6687
    },
    {
      "epoch": 1.5367647058823528,
      "grad_norm": 1.2104694843292236,
      "learning_rate": 5.4221276595744685e-06,
      "loss": 0.0811,
      "step": 6688
    },
    {
      "epoch": 1.5369944852941178,
      "grad_norm": 1.6507996320724487,
      "learning_rate": 5.421276595744681e-06,
      "loss": 0.0962,
      "step": 6689
    },
    {
      "epoch": 1.5372242647058822,
      "grad_norm": 1.3911749124526978,
      "learning_rate": 5.420425531914893e-06,
      "loss": 0.0639,
      "step": 6690
    },
    {
      "epoch": 1.5374540441176472,
      "grad_norm": 1.1183090209960938,
      "learning_rate": 5.419574468085107e-06,
      "loss": 0.0607,
      "step": 6691
    },
    {
      "epoch": 1.5376838235294117,
      "grad_norm": 1.5851926803588867,
      "learning_rate": 5.4187234042553195e-06,
      "loss": 0.068,
      "step": 6692
    },
    {
      "epoch": 1.5379136029411766,
      "grad_norm": 0.9564418792724609,
      "learning_rate": 5.417872340425533e-06,
      "loss": 0.0709,
      "step": 6693
    },
    {
      "epoch": 1.5381433823529411,
      "grad_norm": 1.5535513162612915,
      "learning_rate": 5.417021276595745e-06,
      "loss": 0.0861,
      "step": 6694
    },
    {
      "epoch": 1.5383731617647058,
      "grad_norm": 1.3526161909103394,
      "learning_rate": 5.416170212765957e-06,
      "loss": 0.1042,
      "step": 6695
    },
    {
      "epoch": 1.5386029411764706,
      "grad_norm": 1.1650876998901367,
      "learning_rate": 5.415319148936171e-06,
      "loss": 0.0581,
      "step": 6696
    },
    {
      "epoch": 1.5388327205882353,
      "grad_norm": 1.3167449235916138,
      "learning_rate": 5.414468085106384e-06,
      "loss": 0.0957,
      "step": 6697
    },
    {
      "epoch": 1.5390625,
      "grad_norm": 0.8885215520858765,
      "learning_rate": 5.413617021276596e-06,
      "loss": 0.0537,
      "step": 6698
    },
    {
      "epoch": 1.5392922794117647,
      "grad_norm": 0.8130286931991577,
      "learning_rate": 5.412765957446809e-06,
      "loss": 0.0531,
      "step": 6699
    },
    {
      "epoch": 1.5395220588235294,
      "grad_norm": 0.9473978281021118,
      "learning_rate": 5.4119148936170215e-06,
      "loss": 0.0629,
      "step": 6700
    },
    {
      "epoch": 1.5397518382352942,
      "grad_norm": 1.5174704790115356,
      "learning_rate": 5.411063829787234e-06,
      "loss": 0.0807,
      "step": 6701
    },
    {
      "epoch": 1.5399816176470589,
      "grad_norm": 1.3536686897277832,
      "learning_rate": 5.410212765957448e-06,
      "loss": 0.0799,
      "step": 6702
    },
    {
      "epoch": 1.5402113970588234,
      "grad_norm": 1.1246410608291626,
      "learning_rate": 5.40936170212766e-06,
      "loss": 0.1021,
      "step": 6703
    },
    {
      "epoch": 1.5404411764705883,
      "grad_norm": 1.1879117488861084,
      "learning_rate": 5.4085106382978725e-06,
      "loss": 0.0706,
      "step": 6704
    },
    {
      "epoch": 1.5406709558823528,
      "grad_norm": 1.2565678358078003,
      "learning_rate": 5.407659574468086e-06,
      "loss": 0.0853,
      "step": 6705
    },
    {
      "epoch": 1.5409007352941178,
      "grad_norm": 1.4827626943588257,
      "learning_rate": 5.406808510638298e-06,
      "loss": 0.097,
      "step": 6706
    },
    {
      "epoch": 1.5411305147058822,
      "grad_norm": 1.1455267667770386,
      "learning_rate": 5.405957446808511e-06,
      "loss": 0.073,
      "step": 6707
    },
    {
      "epoch": 1.5413602941176472,
      "grad_norm": 1.0279797315597534,
      "learning_rate": 5.405106382978724e-06,
      "loss": 0.0509,
      "step": 6708
    },
    {
      "epoch": 1.5415900735294117,
      "grad_norm": 0.9837712049484253,
      "learning_rate": 5.404255319148937e-06,
      "loss": 0.038,
      "step": 6709
    },
    {
      "epoch": 1.5418198529411766,
      "grad_norm": 1.2834926843643188,
      "learning_rate": 5.403404255319149e-06,
      "loss": 0.0923,
      "step": 6710
    },
    {
      "epoch": 1.5420496323529411,
      "grad_norm": 1.5522325038909912,
      "learning_rate": 5.402553191489362e-06,
      "loss": 0.0861,
      "step": 6711
    },
    {
      "epoch": 1.5422794117647058,
      "grad_norm": 1.0868252515792847,
      "learning_rate": 5.401702127659575e-06,
      "loss": 0.0571,
      "step": 6712
    },
    {
      "epoch": 1.5425091911764706,
      "grad_norm": 1.0907894372940063,
      "learning_rate": 5.400851063829788e-06,
      "loss": 0.0673,
      "step": 6713
    },
    {
      "epoch": 1.5427389705882353,
      "grad_norm": 0.8485369086265564,
      "learning_rate": 5.400000000000001e-06,
      "loss": 0.0599,
      "step": 6714
    },
    {
      "epoch": 1.54296875,
      "grad_norm": 1.2349646091461182,
      "learning_rate": 5.399148936170213e-06,
      "loss": 0.063,
      "step": 6715
    },
    {
      "epoch": 1.5431985294117647,
      "grad_norm": 1.219267725944519,
      "learning_rate": 5.3982978723404255e-06,
      "loss": 0.0842,
      "step": 6716
    },
    {
      "epoch": 1.5434283088235294,
      "grad_norm": 1.2254523038864136,
      "learning_rate": 5.3974468085106395e-06,
      "loss": 0.0742,
      "step": 6717
    },
    {
      "epoch": 1.5436580882352942,
      "grad_norm": 1.1672382354736328,
      "learning_rate": 5.396595744680852e-06,
      "loss": 0.0698,
      "step": 6718
    },
    {
      "epoch": 1.5438878676470589,
      "grad_norm": 1.3551195859909058,
      "learning_rate": 5.395744680851064e-06,
      "loss": 0.079,
      "step": 6719
    },
    {
      "epoch": 1.5441176470588234,
      "grad_norm": 1.5262596607208252,
      "learning_rate": 5.394893617021277e-06,
      "loss": 0.0967,
      "step": 6720
    },
    {
      "epoch": 1.5443474264705883,
      "grad_norm": 0.9448018074035645,
      "learning_rate": 5.39404255319149e-06,
      "loss": 0.0699,
      "step": 6721
    },
    {
      "epoch": 1.5445772058823528,
      "grad_norm": 0.7220509052276611,
      "learning_rate": 5.393191489361702e-06,
      "loss": 0.045,
      "step": 6722
    },
    {
      "epoch": 1.5448069852941178,
      "grad_norm": 0.8055864572525024,
      "learning_rate": 5.392340425531916e-06,
      "loss": 0.0511,
      "step": 6723
    },
    {
      "epoch": 1.5450367647058822,
      "grad_norm": 1.4609001874923706,
      "learning_rate": 5.391489361702128e-06,
      "loss": 0.1047,
      "step": 6724
    },
    {
      "epoch": 1.5452665441176472,
      "grad_norm": 1.4197419881820679,
      "learning_rate": 5.390638297872341e-06,
      "loss": 0.0671,
      "step": 6725
    },
    {
      "epoch": 1.5454963235294117,
      "grad_norm": 1.4595261812210083,
      "learning_rate": 5.389787234042554e-06,
      "loss": 0.0653,
      "step": 6726
    },
    {
      "epoch": 1.5457261029411766,
      "grad_norm": 1.4912112951278687,
      "learning_rate": 5.388936170212766e-06,
      "loss": 0.0823,
      "step": 6727
    },
    {
      "epoch": 1.5459558823529411,
      "grad_norm": 1.3858940601348877,
      "learning_rate": 5.3880851063829784e-06,
      "loss": 0.0967,
      "step": 6728
    },
    {
      "epoch": 1.5461856617647058,
      "grad_norm": 1.4672908782958984,
      "learning_rate": 5.3872340425531924e-06,
      "loss": 0.075,
      "step": 6729
    },
    {
      "epoch": 1.5464154411764706,
      "grad_norm": 1.6452388763427734,
      "learning_rate": 5.386382978723405e-06,
      "loss": 0.0817,
      "step": 6730
    },
    {
      "epoch": 1.5466452205882353,
      "grad_norm": 1.10445237159729,
      "learning_rate": 5.385531914893617e-06,
      "loss": 0.0888,
      "step": 6731
    },
    {
      "epoch": 1.546875,
      "grad_norm": 1.2557930946350098,
      "learning_rate": 5.38468085106383e-06,
      "loss": 0.0881,
      "step": 6732
    },
    {
      "epoch": 1.5471047794117647,
      "grad_norm": 1.4097416400909424,
      "learning_rate": 5.383829787234043e-06,
      "loss": 0.0781,
      "step": 6733
    },
    {
      "epoch": 1.5473345588235294,
      "grad_norm": 0.9143164753913879,
      "learning_rate": 5.382978723404257e-06,
      "loss": 0.0738,
      "step": 6734
    },
    {
      "epoch": 1.5475643382352942,
      "grad_norm": 1.0586142539978027,
      "learning_rate": 5.382127659574469e-06,
      "loss": 0.0629,
      "step": 6735
    },
    {
      "epoch": 1.5477941176470589,
      "grad_norm": 1.1474711894989014,
      "learning_rate": 5.381276595744681e-06,
      "loss": 0.0714,
      "step": 6736
    },
    {
      "epoch": 1.5480238970588234,
      "grad_norm": 1.2175118923187256,
      "learning_rate": 5.380425531914894e-06,
      "loss": 0.1008,
      "step": 6737
    },
    {
      "epoch": 1.5482536764705883,
      "grad_norm": 1.190667986869812,
      "learning_rate": 5.379574468085107e-06,
      "loss": 0.0587,
      "step": 6738
    },
    {
      "epoch": 1.5484834558823528,
      "grad_norm": 1.3964797258377075,
      "learning_rate": 5.378723404255319e-06,
      "loss": 0.0682,
      "step": 6739
    },
    {
      "epoch": 1.5487132352941178,
      "grad_norm": 1.341927170753479,
      "learning_rate": 5.377872340425533e-06,
      "loss": 0.0846,
      "step": 6740
    },
    {
      "epoch": 1.5489430147058822,
      "grad_norm": 1.3273117542266846,
      "learning_rate": 5.377021276595745e-06,
      "loss": 0.076,
      "step": 6741
    },
    {
      "epoch": 1.5491727941176472,
      "grad_norm": 1.1836470365524292,
      "learning_rate": 5.376170212765958e-06,
      "loss": 0.093,
      "step": 6742
    },
    {
      "epoch": 1.5494025735294117,
      "grad_norm": 1.3486559391021729,
      "learning_rate": 5.375319148936171e-06,
      "loss": 0.0797,
      "step": 6743
    },
    {
      "epoch": 1.5496323529411766,
      "grad_norm": 1.5738545656204224,
      "learning_rate": 5.374468085106383e-06,
      "loss": 0.1135,
      "step": 6744
    },
    {
      "epoch": 1.5498621323529411,
      "grad_norm": 0.8869001865386963,
      "learning_rate": 5.3736170212765956e-06,
      "loss": 0.062,
      "step": 6745
    },
    {
      "epoch": 1.5500919117647058,
      "grad_norm": 1.1138197183609009,
      "learning_rate": 5.3727659574468096e-06,
      "loss": 0.0898,
      "step": 6746
    },
    {
      "epoch": 1.5503216911764706,
      "grad_norm": 1.1968936920166016,
      "learning_rate": 5.371914893617022e-06,
      "loss": 0.0688,
      "step": 6747
    },
    {
      "epoch": 1.5505514705882353,
      "grad_norm": 1.0924383401870728,
      "learning_rate": 5.371063829787234e-06,
      "loss": 0.0637,
      "step": 6748
    },
    {
      "epoch": 1.55078125,
      "grad_norm": 1.1172457933425903,
      "learning_rate": 5.370212765957447e-06,
      "loss": 0.0703,
      "step": 6749
    },
    {
      "epoch": 1.5510110294117647,
      "grad_norm": 1.0612984895706177,
      "learning_rate": 5.36936170212766e-06,
      "loss": 0.0945,
      "step": 6750
    },
    {
      "epoch": 1.5512408088235294,
      "grad_norm": 1.0738874673843384,
      "learning_rate": 5.368510638297872e-06,
      "loss": 0.0549,
      "step": 6751
    },
    {
      "epoch": 1.5514705882352942,
      "grad_norm": 1.2630388736724854,
      "learning_rate": 5.367659574468086e-06,
      "loss": 0.1219,
      "step": 6752
    },
    {
      "epoch": 1.5517003676470589,
      "grad_norm": 1.2596747875213623,
      "learning_rate": 5.366808510638298e-06,
      "loss": 0.0891,
      "step": 6753
    },
    {
      "epoch": 1.5519301470588234,
      "grad_norm": 1.3631885051727295,
      "learning_rate": 5.365957446808511e-06,
      "loss": 0.08,
      "step": 6754
    },
    {
      "epoch": 1.5521599264705883,
      "grad_norm": 1.4411338567733765,
      "learning_rate": 5.365106382978724e-06,
      "loss": 0.0781,
      "step": 6755
    },
    {
      "epoch": 1.5523897058823528,
      "grad_norm": 1.784457802772522,
      "learning_rate": 5.364255319148936e-06,
      "loss": 0.0727,
      "step": 6756
    },
    {
      "epoch": 1.5526194852941178,
      "grad_norm": 1.0632601976394653,
      "learning_rate": 5.363404255319149e-06,
      "loss": 0.0737,
      "step": 6757
    },
    {
      "epoch": 1.5528492647058822,
      "grad_norm": 1.4128578901290894,
      "learning_rate": 5.3625531914893625e-06,
      "loss": 0.1035,
      "step": 6758
    },
    {
      "epoch": 1.5530790441176472,
      "grad_norm": 1.1054928302764893,
      "learning_rate": 5.361702127659575e-06,
      "loss": 0.071,
      "step": 6759
    },
    {
      "epoch": 1.5533088235294117,
      "grad_norm": 1.0722730159759521,
      "learning_rate": 5.360851063829787e-06,
      "loss": 0.0597,
      "step": 6760
    },
    {
      "epoch": 1.5535386029411766,
      "grad_norm": 1.0250667333602905,
      "learning_rate": 5.36e-06,
      "loss": 0.0442,
      "step": 6761
    },
    {
      "epoch": 1.5537683823529411,
      "grad_norm": 1.2149404287338257,
      "learning_rate": 5.3591489361702135e-06,
      "loss": 0.0849,
      "step": 6762
    },
    {
      "epoch": 1.5539981617647058,
      "grad_norm": 1.261459231376648,
      "learning_rate": 5.358297872340426e-06,
      "loss": 0.0758,
      "step": 6763
    },
    {
      "epoch": 1.5542279411764706,
      "grad_norm": 1.1311683654785156,
      "learning_rate": 5.357446808510639e-06,
      "loss": 0.0874,
      "step": 6764
    },
    {
      "epoch": 1.5544577205882353,
      "grad_norm": 1.6355782747268677,
      "learning_rate": 5.356595744680851e-06,
      "loss": 0.0774,
      "step": 6765
    },
    {
      "epoch": 1.5546875,
      "grad_norm": 1.448614478111267,
      "learning_rate": 5.355744680851064e-06,
      "loss": 0.0947,
      "step": 6766
    },
    {
      "epoch": 1.5549172794117647,
      "grad_norm": 1.3373132944107056,
      "learning_rate": 5.354893617021278e-06,
      "loss": 0.0636,
      "step": 6767
    },
    {
      "epoch": 1.5551470588235294,
      "grad_norm": 1.372230887413025,
      "learning_rate": 5.35404255319149e-06,
      "loss": 0.111,
      "step": 6768
    },
    {
      "epoch": 1.5553768382352942,
      "grad_norm": 1.1730824708938599,
      "learning_rate": 5.353191489361702e-06,
      "loss": 0.0744,
      "step": 6769
    },
    {
      "epoch": 1.5556066176470589,
      "grad_norm": 1.222715973854065,
      "learning_rate": 5.3523404255319155e-06,
      "loss": 0.076,
      "step": 6770
    },
    {
      "epoch": 1.5558363970588234,
      "grad_norm": 1.928114652633667,
      "learning_rate": 5.351489361702128e-06,
      "loss": 0.1139,
      "step": 6771
    },
    {
      "epoch": 1.5560661764705883,
      "grad_norm": 1.359811782836914,
      "learning_rate": 5.35063829787234e-06,
      "loss": 0.0665,
      "step": 6772
    },
    {
      "epoch": 1.5562959558823528,
      "grad_norm": 1.654786229133606,
      "learning_rate": 5.349787234042554e-06,
      "loss": 0.1324,
      "step": 6773
    },
    {
      "epoch": 1.5565257352941178,
      "grad_norm": 1.5671513080596924,
      "learning_rate": 5.3489361702127665e-06,
      "loss": 0.1172,
      "step": 6774
    },
    {
      "epoch": 1.5567555147058822,
      "grad_norm": 1.0691381692886353,
      "learning_rate": 5.348085106382979e-06,
      "loss": 0.1086,
      "step": 6775
    },
    {
      "epoch": 1.5569852941176472,
      "grad_norm": 1.6173006296157837,
      "learning_rate": 5.347234042553192e-06,
      "loss": 0.104,
      "step": 6776
    },
    {
      "epoch": 1.5572150735294117,
      "grad_norm": 1.4621940851211548,
      "learning_rate": 5.346382978723404e-06,
      "loss": 0.0768,
      "step": 6777
    },
    {
      "epoch": 1.5574448529411766,
      "grad_norm": 0.9525260329246521,
      "learning_rate": 5.345531914893618e-06,
      "loss": 0.07,
      "step": 6778
    },
    {
      "epoch": 1.5576746323529411,
      "grad_norm": 1.0779211521148682,
      "learning_rate": 5.344680851063831e-06,
      "loss": 0.0598,
      "step": 6779
    },
    {
      "epoch": 1.5579044117647058,
      "grad_norm": 1.1464482545852661,
      "learning_rate": 5.343829787234043e-06,
      "loss": 0.0751,
      "step": 6780
    },
    {
      "epoch": 1.5581341911764706,
      "grad_norm": 1.634171485900879,
      "learning_rate": 5.342978723404256e-06,
      "loss": 0.0983,
      "step": 6781
    },
    {
      "epoch": 1.5583639705882353,
      "grad_norm": 1.1444990634918213,
      "learning_rate": 5.3421276595744685e-06,
      "loss": 0.0888,
      "step": 6782
    },
    {
      "epoch": 1.55859375,
      "grad_norm": 0.9277492761611938,
      "learning_rate": 5.341276595744681e-06,
      "loss": 0.062,
      "step": 6783
    },
    {
      "epoch": 1.5588235294117647,
      "grad_norm": 1.2668256759643555,
      "learning_rate": 5.340425531914895e-06,
      "loss": 0.0913,
      "step": 6784
    },
    {
      "epoch": 1.5590533088235294,
      "grad_norm": 0.9390228986740112,
      "learning_rate": 5.339574468085107e-06,
      "loss": 0.078,
      "step": 6785
    },
    {
      "epoch": 1.5592830882352942,
      "grad_norm": 0.9140582084655762,
      "learning_rate": 5.3387234042553195e-06,
      "loss": 0.0752,
      "step": 6786
    },
    {
      "epoch": 1.5595128676470589,
      "grad_norm": 0.913395881652832,
      "learning_rate": 5.337872340425533e-06,
      "loss": 0.0699,
      "step": 6787
    },
    {
      "epoch": 1.5597426470588234,
      "grad_norm": 1.02388334274292,
      "learning_rate": 5.337021276595745e-06,
      "loss": 0.0664,
      "step": 6788
    },
    {
      "epoch": 1.5599724264705883,
      "grad_norm": 1.5194790363311768,
      "learning_rate": 5.336170212765957e-06,
      "loss": 0.1143,
      "step": 6789
    },
    {
      "epoch": 1.5602022058823528,
      "grad_norm": 0.9458715319633484,
      "learning_rate": 5.335319148936171e-06,
      "loss": 0.0764,
      "step": 6790
    },
    {
      "epoch": 1.5604319852941178,
      "grad_norm": 1.3285996913909912,
      "learning_rate": 5.334468085106384e-06,
      "loss": 0.0929,
      "step": 6791
    },
    {
      "epoch": 1.5606617647058822,
      "grad_norm": 0.9013117551803589,
      "learning_rate": 5.333617021276596e-06,
      "loss": 0.0643,
      "step": 6792
    },
    {
      "epoch": 1.5608915441176472,
      "grad_norm": 1.280365228652954,
      "learning_rate": 5.332765957446809e-06,
      "loss": 0.0737,
      "step": 6793
    },
    {
      "epoch": 1.5611213235294117,
      "grad_norm": 1.3156083822250366,
      "learning_rate": 5.3319148936170214e-06,
      "loss": 0.0807,
      "step": 6794
    },
    {
      "epoch": 1.5613511029411766,
      "grad_norm": 1.133786916732788,
      "learning_rate": 5.331063829787234e-06,
      "loss": 0.0566,
      "step": 6795
    },
    {
      "epoch": 1.5615808823529411,
      "grad_norm": 1.0848495960235596,
      "learning_rate": 5.330212765957448e-06,
      "loss": 0.0425,
      "step": 6796
    },
    {
      "epoch": 1.5618106617647058,
      "grad_norm": 1.2086747884750366,
      "learning_rate": 5.32936170212766e-06,
      "loss": 0.0639,
      "step": 6797
    },
    {
      "epoch": 1.5620404411764706,
      "grad_norm": 1.0316424369812012,
      "learning_rate": 5.328510638297872e-06,
      "loss": 0.0663,
      "step": 6798
    },
    {
      "epoch": 1.5622702205882353,
      "grad_norm": 1.1921172142028809,
      "learning_rate": 5.327659574468086e-06,
      "loss": 0.0738,
      "step": 6799
    },
    {
      "epoch": 1.5625,
      "grad_norm": 1.0299650430679321,
      "learning_rate": 5.326808510638298e-06,
      "loss": 0.0694,
      "step": 6800
    },
    {
      "epoch": 1.5627297794117647,
      "grad_norm": 1.3202356100082397,
      "learning_rate": 5.325957446808511e-06,
      "loss": 0.0781,
      "step": 6801
    },
    {
      "epoch": 1.5629595588235294,
      "grad_norm": 1.603760004043579,
      "learning_rate": 5.325106382978724e-06,
      "loss": 0.0739,
      "step": 6802
    },
    {
      "epoch": 1.5631893382352942,
      "grad_norm": 1.3726558685302734,
      "learning_rate": 5.3242553191489366e-06,
      "loss": 0.0598,
      "step": 6803
    },
    {
      "epoch": 1.5634191176470589,
      "grad_norm": 1.495234489440918,
      "learning_rate": 5.323404255319149e-06,
      "loss": 0.0951,
      "step": 6804
    },
    {
      "epoch": 1.5636488970588234,
      "grad_norm": 1.1435166597366333,
      "learning_rate": 5.322553191489362e-06,
      "loss": 0.0751,
      "step": 6805
    },
    {
      "epoch": 1.5638786764705883,
      "grad_norm": 1.13405179977417,
      "learning_rate": 5.321702127659575e-06,
      "loss": 0.0808,
      "step": 6806
    },
    {
      "epoch": 1.5641084558823528,
      "grad_norm": 1.7028276920318604,
      "learning_rate": 5.3208510638297876e-06,
      "loss": 0.1055,
      "step": 6807
    },
    {
      "epoch": 1.5643382352941178,
      "grad_norm": 1.3895421028137207,
      "learning_rate": 5.320000000000001e-06,
      "loss": 0.0919,
      "step": 6808
    },
    {
      "epoch": 1.5645680147058822,
      "grad_norm": 1.3598175048828125,
      "learning_rate": 5.319148936170213e-06,
      "loss": 0.0959,
      "step": 6809
    },
    {
      "epoch": 1.5647977941176472,
      "grad_norm": 1.0614160299301147,
      "learning_rate": 5.318297872340425e-06,
      "loss": 0.0652,
      "step": 6810
    },
    {
      "epoch": 1.5650275735294117,
      "grad_norm": 1.5453119277954102,
      "learning_rate": 5.317446808510639e-06,
      "loss": 0.0759,
      "step": 6811
    },
    {
      "epoch": 1.5652573529411766,
      "grad_norm": 1.0971932411193848,
      "learning_rate": 5.316595744680852e-06,
      "loss": 0.0683,
      "step": 6812
    },
    {
      "epoch": 1.5654871323529411,
      "grad_norm": 1.2800832986831665,
      "learning_rate": 5.315744680851064e-06,
      "loss": 0.0826,
      "step": 6813
    },
    {
      "epoch": 1.5657169117647058,
      "grad_norm": 1.2703559398651123,
      "learning_rate": 5.314893617021277e-06,
      "loss": 0.0755,
      "step": 6814
    },
    {
      "epoch": 1.5659466911764706,
      "grad_norm": 0.9285929799079895,
      "learning_rate": 5.3140425531914895e-06,
      "loss": 0.0511,
      "step": 6815
    },
    {
      "epoch": 1.5661764705882353,
      "grad_norm": 1.1939812898635864,
      "learning_rate": 5.313191489361702e-06,
      "loss": 0.0858,
      "step": 6816
    },
    {
      "epoch": 1.56640625,
      "grad_norm": 1.8641334772109985,
      "learning_rate": 5.312340425531916e-06,
      "loss": 0.1121,
      "step": 6817
    },
    {
      "epoch": 1.5666360294117647,
      "grad_norm": 1.470780372619629,
      "learning_rate": 5.311489361702128e-06,
      "loss": 0.0846,
      "step": 6818
    },
    {
      "epoch": 1.5668658088235294,
      "grad_norm": 1.3404775857925415,
      "learning_rate": 5.3106382978723405e-06,
      "loss": 0.0906,
      "step": 6819
    },
    {
      "epoch": 1.5670955882352942,
      "grad_norm": 1.1016509532928467,
      "learning_rate": 5.309787234042554e-06,
      "loss": 0.0698,
      "step": 6820
    },
    {
      "epoch": 1.5673253676470589,
      "grad_norm": 1.4661283493041992,
      "learning_rate": 5.308936170212766e-06,
      "loss": 0.0943,
      "step": 6821
    },
    {
      "epoch": 1.5675551470588234,
      "grad_norm": 1.3856303691864014,
      "learning_rate": 5.30808510638298e-06,
      "loss": 0.0577,
      "step": 6822
    },
    {
      "epoch": 1.5677849264705883,
      "grad_norm": 0.9835889935493469,
      "learning_rate": 5.307234042553192e-06,
      "loss": 0.0793,
      "step": 6823
    },
    {
      "epoch": 1.5680147058823528,
      "grad_norm": 0.9371462464332581,
      "learning_rate": 5.306382978723405e-06,
      "loss": 0.0767,
      "step": 6824
    },
    {
      "epoch": 1.5682444852941178,
      "grad_norm": 1.2486977577209473,
      "learning_rate": 5.305531914893618e-06,
      "loss": 0.0887,
      "step": 6825
    },
    {
      "epoch": 1.5684742647058822,
      "grad_norm": 1.064937949180603,
      "learning_rate": 5.30468085106383e-06,
      "loss": 0.0682,
      "step": 6826
    },
    {
      "epoch": 1.5687040441176472,
      "grad_norm": 1.165587306022644,
      "learning_rate": 5.3038297872340425e-06,
      "loss": 0.0905,
      "step": 6827
    },
    {
      "epoch": 1.5689338235294117,
      "grad_norm": 1.421044111251831,
      "learning_rate": 5.3029787234042565e-06,
      "loss": 0.0733,
      "step": 6828
    },
    {
      "epoch": 1.5691636029411766,
      "grad_norm": 1.1062395572662354,
      "learning_rate": 5.302127659574469e-06,
      "loss": 0.0672,
      "step": 6829
    },
    {
      "epoch": 1.5693933823529411,
      "grad_norm": 1.5448600053787231,
      "learning_rate": 5.301276595744681e-06,
      "loss": 0.0969,
      "step": 6830
    },
    {
      "epoch": 1.5696231617647058,
      "grad_norm": 1.1489392518997192,
      "learning_rate": 5.300425531914894e-06,
      "loss": 0.0516,
      "step": 6831
    },
    {
      "epoch": 1.5698529411764706,
      "grad_norm": 0.919113278388977,
      "learning_rate": 5.299574468085107e-06,
      "loss": 0.0623,
      "step": 6832
    },
    {
      "epoch": 1.5700827205882353,
      "grad_norm": 2.0287792682647705,
      "learning_rate": 5.298723404255319e-06,
      "loss": 0.056,
      "step": 6833
    },
    {
      "epoch": 1.5703125,
      "grad_norm": 1.2375547885894775,
      "learning_rate": 5.297872340425533e-06,
      "loss": 0.0768,
      "step": 6834
    },
    {
      "epoch": 1.5705422794117647,
      "grad_norm": 0.9997873902320862,
      "learning_rate": 5.297021276595745e-06,
      "loss": 0.0525,
      "step": 6835
    },
    {
      "epoch": 1.5707720588235294,
      "grad_norm": 1.0982768535614014,
      "learning_rate": 5.296170212765958e-06,
      "loss": 0.0734,
      "step": 6836
    },
    {
      "epoch": 1.5710018382352942,
      "grad_norm": 1.1005462408065796,
      "learning_rate": 5.295319148936171e-06,
      "loss": 0.074,
      "step": 6837
    },
    {
      "epoch": 1.5712316176470589,
      "grad_norm": 1.2467600107192993,
      "learning_rate": 5.294468085106383e-06,
      "loss": 0.0696,
      "step": 6838
    },
    {
      "epoch": 1.5714613970588234,
      "grad_norm": 1.317465901374817,
      "learning_rate": 5.2936170212765955e-06,
      "loss": 0.0738,
      "step": 6839
    },
    {
      "epoch": 1.5716911764705883,
      "grad_norm": 1.2056304216384888,
      "learning_rate": 5.2927659574468095e-06,
      "loss": 0.0937,
      "step": 6840
    },
    {
      "epoch": 1.5719209558823528,
      "grad_norm": 1.2698696851730347,
      "learning_rate": 5.291914893617022e-06,
      "loss": 0.0744,
      "step": 6841
    },
    {
      "epoch": 1.5721507352941178,
      "grad_norm": 1.137349009513855,
      "learning_rate": 5.291063829787234e-06,
      "loss": 0.0608,
      "step": 6842
    },
    {
      "epoch": 1.5723805147058822,
      "grad_norm": 0.9229136109352112,
      "learning_rate": 5.290212765957447e-06,
      "loss": 0.0788,
      "step": 6843
    },
    {
      "epoch": 1.5726102941176472,
      "grad_norm": 1.569800853729248,
      "learning_rate": 5.28936170212766e-06,
      "loss": 0.0636,
      "step": 6844
    },
    {
      "epoch": 1.5728400735294117,
      "grad_norm": 1.1928017139434814,
      "learning_rate": 5.288510638297872e-06,
      "loss": 0.0837,
      "step": 6845
    },
    {
      "epoch": 1.5730698529411766,
      "grad_norm": 1.4779616594314575,
      "learning_rate": 5.287659574468086e-06,
      "loss": 0.0839,
      "step": 6846
    },
    {
      "epoch": 1.5732996323529411,
      "grad_norm": 1.2341203689575195,
      "learning_rate": 5.286808510638298e-06,
      "loss": 0.0712,
      "step": 6847
    },
    {
      "epoch": 1.5735294117647058,
      "grad_norm": 1.2694650888442993,
      "learning_rate": 5.285957446808511e-06,
      "loss": 0.0965,
      "step": 6848
    },
    {
      "epoch": 1.5737591911764706,
      "grad_norm": 1.0819342136383057,
      "learning_rate": 5.285106382978724e-06,
      "loss": 0.0557,
      "step": 6849
    },
    {
      "epoch": 1.5739889705882353,
      "grad_norm": 2.3123602867126465,
      "learning_rate": 5.284255319148936e-06,
      "loss": 0.0708,
      "step": 6850
    },
    {
      "epoch": 1.57421875,
      "grad_norm": 1.8543369770050049,
      "learning_rate": 5.283404255319149e-06,
      "loss": 0.1094,
      "step": 6851
    },
    {
      "epoch": 1.5744485294117647,
      "grad_norm": 1.3513014316558838,
      "learning_rate": 5.2825531914893625e-06,
      "loss": 0.0906,
      "step": 6852
    },
    {
      "epoch": 1.5746783088235294,
      "grad_norm": 1.229110836982727,
      "learning_rate": 5.281702127659575e-06,
      "loss": 0.0641,
      "step": 6853
    },
    {
      "epoch": 1.5749080882352942,
      "grad_norm": 1.5541201829910278,
      "learning_rate": 5.280851063829787e-06,
      "loss": 0.0724,
      "step": 6854
    },
    {
      "epoch": 1.5751378676470589,
      "grad_norm": 1.2864174842834473,
      "learning_rate": 5.28e-06,
      "loss": 0.0734,
      "step": 6855
    },
    {
      "epoch": 1.5753676470588234,
      "grad_norm": 1.2657078504562378,
      "learning_rate": 5.2791489361702134e-06,
      "loss": 0.0882,
      "step": 6856
    },
    {
      "epoch": 1.5755974264705883,
      "grad_norm": 1.1738651990890503,
      "learning_rate": 5.278297872340426e-06,
      "loss": 0.0617,
      "step": 6857
    },
    {
      "epoch": 1.5758272058823528,
      "grad_norm": 0.8850520849227905,
      "learning_rate": 5.277446808510639e-06,
      "loss": 0.0642,
      "step": 6858
    },
    {
      "epoch": 1.5760569852941178,
      "grad_norm": 1.1236029863357544,
      "learning_rate": 5.276595744680851e-06,
      "loss": 0.0767,
      "step": 6859
    },
    {
      "epoch": 1.5762867647058822,
      "grad_norm": 1.0178512334823608,
      "learning_rate": 5.275744680851064e-06,
      "loss": 0.1025,
      "step": 6860
    },
    {
      "epoch": 1.5765165441176472,
      "grad_norm": 1.0263723134994507,
      "learning_rate": 5.274893617021278e-06,
      "loss": 0.0558,
      "step": 6861
    },
    {
      "epoch": 1.5767463235294117,
      "grad_norm": 1.0835802555084229,
      "learning_rate": 5.27404255319149e-06,
      "loss": 0.0843,
      "step": 6862
    },
    {
      "epoch": 1.5769761029411766,
      "grad_norm": 1.0735758543014526,
      "learning_rate": 5.273191489361703e-06,
      "loss": 0.0829,
      "step": 6863
    },
    {
      "epoch": 1.5772058823529411,
      "grad_norm": 0.7803121209144592,
      "learning_rate": 5.272340425531915e-06,
      "loss": 0.0736,
      "step": 6864
    },
    {
      "epoch": 1.5774356617647058,
      "grad_norm": 1.173348069190979,
      "learning_rate": 5.271489361702128e-06,
      "loss": 0.0814,
      "step": 6865
    },
    {
      "epoch": 1.5776654411764706,
      "grad_norm": 1.3996376991271973,
      "learning_rate": 5.270638297872342e-06,
      "loss": 0.0956,
      "step": 6866
    },
    {
      "epoch": 1.5778952205882353,
      "grad_norm": 1.116511344909668,
      "learning_rate": 5.269787234042554e-06,
      "loss": 0.0697,
      "step": 6867
    },
    {
      "epoch": 1.578125,
      "grad_norm": 1.293976902961731,
      "learning_rate": 5.268936170212766e-06,
      "loss": 0.1061,
      "step": 6868
    },
    {
      "epoch": 1.5783547794117647,
      "grad_norm": 1.0316393375396729,
      "learning_rate": 5.2680851063829796e-06,
      "loss": 0.061,
      "step": 6869
    },
    {
      "epoch": 1.5785845588235294,
      "grad_norm": 0.7129318118095398,
      "learning_rate": 5.267234042553192e-06,
      "loss": 0.0383,
      "step": 6870
    },
    {
      "epoch": 1.5788143382352942,
      "grad_norm": 1.1649785041809082,
      "learning_rate": 5.266382978723404e-06,
      "loss": 0.075,
      "step": 6871
    },
    {
      "epoch": 1.5790441176470589,
      "grad_norm": 1.7067196369171143,
      "learning_rate": 5.265531914893618e-06,
      "loss": 0.084,
      "step": 6872
    },
    {
      "epoch": 1.5792738970588234,
      "grad_norm": 1.0120935440063477,
      "learning_rate": 5.2646808510638306e-06,
      "loss": 0.0551,
      "step": 6873
    },
    {
      "epoch": 1.5795036764705883,
      "grad_norm": 1.3945980072021484,
      "learning_rate": 5.263829787234043e-06,
      "loss": 0.0864,
      "step": 6874
    },
    {
      "epoch": 1.5797334558823528,
      "grad_norm": 1.4428082704544067,
      "learning_rate": 5.262978723404256e-06,
      "loss": 0.0788,
      "step": 6875
    },
    {
      "epoch": 1.5799632352941178,
      "grad_norm": 1.0774483680725098,
      "learning_rate": 5.262127659574468e-06,
      "loss": 0.0506,
      "step": 6876
    },
    {
      "epoch": 1.5801930147058822,
      "grad_norm": 1.5574922561645508,
      "learning_rate": 5.261276595744681e-06,
      "loss": 0.0896,
      "step": 6877
    },
    {
      "epoch": 1.5804227941176472,
      "grad_norm": 1.4314017295837402,
      "learning_rate": 5.260425531914895e-06,
      "loss": 0.095,
      "step": 6878
    },
    {
      "epoch": 1.5806525735294117,
      "grad_norm": 1.0401792526245117,
      "learning_rate": 5.259574468085107e-06,
      "loss": 0.0655,
      "step": 6879
    },
    {
      "epoch": 1.5808823529411766,
      "grad_norm": 1.318755030632019,
      "learning_rate": 5.258723404255319e-06,
      "loss": 0.0704,
      "step": 6880
    },
    {
      "epoch": 1.5811121323529411,
      "grad_norm": 1.2140045166015625,
      "learning_rate": 5.2578723404255325e-06,
      "loss": 0.0706,
      "step": 6881
    },
    {
      "epoch": 1.5813419117647058,
      "grad_norm": 1.1691408157348633,
      "learning_rate": 5.257021276595745e-06,
      "loss": 0.0658,
      "step": 6882
    },
    {
      "epoch": 1.5815716911764706,
      "grad_norm": 1.2110624313354492,
      "learning_rate": 5.256170212765957e-06,
      "loss": 0.0835,
      "step": 6883
    },
    {
      "epoch": 1.5818014705882353,
      "grad_norm": 2.0081255435943604,
      "learning_rate": 5.255319148936171e-06,
      "loss": 0.1122,
      "step": 6884
    },
    {
      "epoch": 1.58203125,
      "grad_norm": 1.3561660051345825,
      "learning_rate": 5.2544680851063835e-06,
      "loss": 0.0777,
      "step": 6885
    },
    {
      "epoch": 1.5822610294117647,
      "grad_norm": 1.2244746685028076,
      "learning_rate": 5.253617021276596e-06,
      "loss": 0.0821,
      "step": 6886
    },
    {
      "epoch": 1.5824908088235294,
      "grad_norm": 1.164199709892273,
      "learning_rate": 5.252765957446809e-06,
      "loss": 0.0892,
      "step": 6887
    },
    {
      "epoch": 1.5827205882352942,
      "grad_norm": 1.2440178394317627,
      "learning_rate": 5.251914893617021e-06,
      "loss": 0.0796,
      "step": 6888
    },
    {
      "epoch": 1.5829503676470589,
      "grad_norm": 1.25924813747406,
      "learning_rate": 5.251063829787234e-06,
      "loss": 0.0622,
      "step": 6889
    },
    {
      "epoch": 1.5831801470588234,
      "grad_norm": 1.1425130367279053,
      "learning_rate": 5.250212765957448e-06,
      "loss": 0.0689,
      "step": 6890
    },
    {
      "epoch": 1.5834099264705883,
      "grad_norm": 1.0686976909637451,
      "learning_rate": 5.24936170212766e-06,
      "loss": 0.0539,
      "step": 6891
    },
    {
      "epoch": 1.5836397058823528,
      "grad_norm": 1.2666136026382446,
      "learning_rate": 5.248510638297872e-06,
      "loss": 0.0997,
      "step": 6892
    },
    {
      "epoch": 1.5838694852941178,
      "grad_norm": 1.2509217262268066,
      "learning_rate": 5.2476595744680855e-06,
      "loss": 0.0644,
      "step": 6893
    },
    {
      "epoch": 1.5840992647058822,
      "grad_norm": 1.0427581071853638,
      "learning_rate": 5.246808510638298e-06,
      "loss": 0.0602,
      "step": 6894
    },
    {
      "epoch": 1.5843290441176472,
      "grad_norm": 1.2207547426223755,
      "learning_rate": 5.245957446808511e-06,
      "loss": 0.0869,
      "step": 6895
    },
    {
      "epoch": 1.5845588235294117,
      "grad_norm": 1.3318836688995361,
      "learning_rate": 5.245106382978724e-06,
      "loss": 0.0774,
      "step": 6896
    },
    {
      "epoch": 1.5847886029411766,
      "grad_norm": 1.1631633043289185,
      "learning_rate": 5.2442553191489365e-06,
      "loss": 0.0562,
      "step": 6897
    },
    {
      "epoch": 1.5850183823529411,
      "grad_norm": 1.515785813331604,
      "learning_rate": 5.243404255319149e-06,
      "loss": 0.0806,
      "step": 6898
    },
    {
      "epoch": 1.5852481617647058,
      "grad_norm": 1.6579312086105347,
      "learning_rate": 5.242553191489362e-06,
      "loss": 0.0685,
      "step": 6899
    },
    {
      "epoch": 1.5854779411764706,
      "grad_norm": 1.2591392993927002,
      "learning_rate": 5.241702127659575e-06,
      "loss": 0.0908,
      "step": 6900
    },
    {
      "epoch": 1.5857077205882353,
      "grad_norm": 1.4786466360092163,
      "learning_rate": 5.2408510638297875e-06,
      "loss": 0.0964,
      "step": 6901
    },
    {
      "epoch": 1.5859375,
      "grad_norm": 1.026731252670288,
      "learning_rate": 5.240000000000001e-06,
      "loss": 0.0548,
      "step": 6902
    },
    {
      "epoch": 1.5861672794117647,
      "grad_norm": 0.8185299634933472,
      "learning_rate": 5.239148936170213e-06,
      "loss": 0.0395,
      "step": 6903
    },
    {
      "epoch": 1.5863970588235294,
      "grad_norm": 0.9333840608596802,
      "learning_rate": 5.238297872340425e-06,
      "loss": 0.0503,
      "step": 6904
    },
    {
      "epoch": 1.5866268382352942,
      "grad_norm": 1.7348062992095947,
      "learning_rate": 5.237446808510639e-06,
      "loss": 0.1045,
      "step": 6905
    },
    {
      "epoch": 1.5868566176470589,
      "grad_norm": 0.7608533501625061,
      "learning_rate": 5.236595744680852e-06,
      "loss": 0.057,
      "step": 6906
    },
    {
      "epoch": 1.5870863970588234,
      "grad_norm": 1.108513355255127,
      "learning_rate": 5.235744680851065e-06,
      "loss": 0.0845,
      "step": 6907
    },
    {
      "epoch": 1.5873161764705883,
      "grad_norm": 1.4908018112182617,
      "learning_rate": 5.234893617021277e-06,
      "loss": 0.0955,
      "step": 6908
    },
    {
      "epoch": 1.5875459558823528,
      "grad_norm": 0.9621025919914246,
      "learning_rate": 5.2340425531914895e-06,
      "loss": 0.0593,
      "step": 6909
    },
    {
      "epoch": 1.5877757352941178,
      "grad_norm": 0.9608277082443237,
      "learning_rate": 5.2331914893617035e-06,
      "loss": 0.0519,
      "step": 6910
    },
    {
      "epoch": 1.5880055147058822,
      "grad_norm": 1.0582939386367798,
      "learning_rate": 5.232340425531916e-06,
      "loss": 0.0808,
      "step": 6911
    },
    {
      "epoch": 1.5882352941176472,
      "grad_norm": 1.344848871231079,
      "learning_rate": 5.231489361702128e-06,
      "loss": 0.0817,
      "step": 6912
    },
    {
      "epoch": 1.5884650735294117,
      "grad_norm": 1.262648344039917,
      "learning_rate": 5.230638297872341e-06,
      "loss": 0.1027,
      "step": 6913
    },
    {
      "epoch": 1.5886948529411766,
      "grad_norm": 0.913046658039093,
      "learning_rate": 5.229787234042554e-06,
      "loss": 0.0519,
      "step": 6914
    },
    {
      "epoch": 1.5889246323529411,
      "grad_norm": 1.6984034776687622,
      "learning_rate": 5.228936170212766e-06,
      "loss": 0.0975,
      "step": 6915
    },
    {
      "epoch": 1.5891544117647058,
      "grad_norm": 1.258527398109436,
      "learning_rate": 5.22808510638298e-06,
      "loss": 0.0859,
      "step": 6916
    },
    {
      "epoch": 1.5893841911764706,
      "grad_norm": 1.3009644746780396,
      "learning_rate": 5.227234042553192e-06,
      "loss": 0.0881,
      "step": 6917
    },
    {
      "epoch": 1.5896139705882353,
      "grad_norm": 1.1334733963012695,
      "learning_rate": 5.226382978723405e-06,
      "loss": 0.1059,
      "step": 6918
    },
    {
      "epoch": 1.58984375,
      "grad_norm": 1.5078080892562866,
      "learning_rate": 5.225531914893618e-06,
      "loss": 0.0831,
      "step": 6919
    },
    {
      "epoch": 1.5900735294117647,
      "grad_norm": 1.2129870653152466,
      "learning_rate": 5.22468085106383e-06,
      "loss": 0.0774,
      "step": 6920
    },
    {
      "epoch": 1.5903033088235294,
      "grad_norm": 1.1803187131881714,
      "learning_rate": 5.223829787234042e-06,
      "loss": 0.0967,
      "step": 6921
    },
    {
      "epoch": 1.5905330882352942,
      "grad_norm": 1.6135143041610718,
      "learning_rate": 5.2229787234042564e-06,
      "loss": 0.0905,
      "step": 6922
    },
    {
      "epoch": 1.5907628676470589,
      "grad_norm": 0.9063338041305542,
      "learning_rate": 5.222127659574469e-06,
      "loss": 0.0532,
      "step": 6923
    },
    {
      "epoch": 1.5909926470588234,
      "grad_norm": 0.9137589931488037,
      "learning_rate": 5.221276595744681e-06,
      "loss": 0.0763,
      "step": 6924
    },
    {
      "epoch": 1.5912224264705883,
      "grad_norm": 1.296905279159546,
      "learning_rate": 5.220425531914894e-06,
      "loss": 0.0621,
      "step": 6925
    },
    {
      "epoch": 1.5914522058823528,
      "grad_norm": 1.4934237003326416,
      "learning_rate": 5.219574468085107e-06,
      "loss": 0.1066,
      "step": 6926
    },
    {
      "epoch": 1.5916819852941178,
      "grad_norm": 1.7937953472137451,
      "learning_rate": 5.218723404255319e-06,
      "loss": 0.0921,
      "step": 6927
    },
    {
      "epoch": 1.5919117647058822,
      "grad_norm": 1.1972728967666626,
      "learning_rate": 5.217872340425533e-06,
      "loss": 0.0794,
      "step": 6928
    },
    {
      "epoch": 1.5921415441176472,
      "grad_norm": 0.9485195279121399,
      "learning_rate": 5.217021276595745e-06,
      "loss": 0.0595,
      "step": 6929
    },
    {
      "epoch": 1.5923713235294117,
      "grad_norm": 1.3459079265594482,
      "learning_rate": 5.2161702127659576e-06,
      "loss": 0.0904,
      "step": 6930
    },
    {
      "epoch": 1.5926011029411766,
      "grad_norm": 1.1544424295425415,
      "learning_rate": 5.215319148936171e-06,
      "loss": 0.0852,
      "step": 6931
    },
    {
      "epoch": 1.5928308823529411,
      "grad_norm": 1.0547415018081665,
      "learning_rate": 5.214468085106383e-06,
      "loss": 0.0786,
      "step": 6932
    },
    {
      "epoch": 1.5930606617647058,
      "grad_norm": 1.7146679162979126,
      "learning_rate": 5.213617021276595e-06,
      "loss": 0.0795,
      "step": 6933
    },
    {
      "epoch": 1.5932904411764706,
      "grad_norm": 1.153926968574524,
      "learning_rate": 5.212765957446809e-06,
      "loss": 0.0883,
      "step": 6934
    },
    {
      "epoch": 1.5935202205882353,
      "grad_norm": 1.133080244064331,
      "learning_rate": 5.211914893617022e-06,
      "loss": 0.078,
      "step": 6935
    },
    {
      "epoch": 1.59375,
      "grad_norm": 1.3717979192733765,
      "learning_rate": 5.211063829787234e-06,
      "loss": 0.0611,
      "step": 6936
    },
    {
      "epoch": 1.5939797794117647,
      "grad_norm": 1.517879843711853,
      "learning_rate": 5.210212765957447e-06,
      "loss": 0.0823,
      "step": 6937
    },
    {
      "epoch": 1.5942095588235294,
      "grad_norm": 1.2129789590835571,
      "learning_rate": 5.2093617021276595e-06,
      "loss": 0.0778,
      "step": 6938
    },
    {
      "epoch": 1.5944393382352942,
      "grad_norm": 1.0739328861236572,
      "learning_rate": 5.208510638297872e-06,
      "loss": 0.0627,
      "step": 6939
    },
    {
      "epoch": 1.5946691176470589,
      "grad_norm": 1.295805811882019,
      "learning_rate": 5.207659574468086e-06,
      "loss": 0.0778,
      "step": 6940
    },
    {
      "epoch": 1.5948988970588234,
      "grad_norm": 1.1788607835769653,
      "learning_rate": 5.206808510638298e-06,
      "loss": 0.0562,
      "step": 6941
    },
    {
      "epoch": 1.5951286764705883,
      "grad_norm": 1.172323226928711,
      "learning_rate": 5.2059574468085105e-06,
      "loss": 0.0652,
      "step": 6942
    },
    {
      "epoch": 1.5953584558823528,
      "grad_norm": 1.0211517810821533,
      "learning_rate": 5.205106382978724e-06,
      "loss": 0.0604,
      "step": 6943
    },
    {
      "epoch": 1.5955882352941178,
      "grad_norm": 1.2698187828063965,
      "learning_rate": 5.204255319148936e-06,
      "loss": 0.0717,
      "step": 6944
    },
    {
      "epoch": 1.5958180147058822,
      "grad_norm": 0.9617723822593689,
      "learning_rate": 5.203404255319149e-06,
      "loss": 0.086,
      "step": 6945
    },
    {
      "epoch": 1.5960477941176472,
      "grad_norm": 0.7505062818527222,
      "learning_rate": 5.202553191489362e-06,
      "loss": 0.0427,
      "step": 6946
    },
    {
      "epoch": 1.5962775735294117,
      "grad_norm": 0.9214761257171631,
      "learning_rate": 5.201702127659575e-06,
      "loss": 0.0554,
      "step": 6947
    },
    {
      "epoch": 1.5965073529411766,
      "grad_norm": 1.2005977630615234,
      "learning_rate": 5.200851063829787e-06,
      "loss": 0.0623,
      "step": 6948
    },
    {
      "epoch": 1.5967371323529411,
      "grad_norm": 1.0634121894836426,
      "learning_rate": 5.2e-06,
      "loss": 0.086,
      "step": 6949
    },
    {
      "epoch": 1.5969669117647058,
      "grad_norm": 1.3864542245864868,
      "learning_rate": 5.199148936170213e-06,
      "loss": 0.0603,
      "step": 6950
    },
    {
      "epoch": 1.5971966911764706,
      "grad_norm": 1.2784526348114014,
      "learning_rate": 5.1982978723404265e-06,
      "loss": 0.0919,
      "step": 6951
    },
    {
      "epoch": 1.5974264705882353,
      "grad_norm": 1.0328782796859741,
      "learning_rate": 5.197446808510639e-06,
      "loss": 0.0613,
      "step": 6952
    },
    {
      "epoch": 1.59765625,
      "grad_norm": 1.3338344097137451,
      "learning_rate": 5.196595744680851e-06,
      "loss": 0.0694,
      "step": 6953
    },
    {
      "epoch": 1.5978860294117647,
      "grad_norm": 1.0261930227279663,
      "learning_rate": 5.195744680851064e-06,
      "loss": 0.0645,
      "step": 6954
    },
    {
      "epoch": 1.5981158088235294,
      "grad_norm": 1.2508797645568848,
      "learning_rate": 5.1948936170212775e-06,
      "loss": 0.0855,
      "step": 6955
    },
    {
      "epoch": 1.5983455882352942,
      "grad_norm": 1.1090844869613647,
      "learning_rate": 5.19404255319149e-06,
      "loss": 0.0706,
      "step": 6956
    },
    {
      "epoch": 1.5985753676470589,
      "grad_norm": 1.1541718244552612,
      "learning_rate": 5.193191489361703e-06,
      "loss": 0.0606,
      "step": 6957
    },
    {
      "epoch": 1.5988051470588234,
      "grad_norm": 1.121464490890503,
      "learning_rate": 5.192340425531915e-06,
      "loss": 0.0755,
      "step": 6958
    },
    {
      "epoch": 1.5990349264705883,
      "grad_norm": 1.1013617515563965,
      "learning_rate": 5.191489361702128e-06,
      "loss": 0.057,
      "step": 6959
    },
    {
      "epoch": 1.5992647058823528,
      "grad_norm": 1.7120558023452759,
      "learning_rate": 5.190638297872342e-06,
      "loss": 0.0815,
      "step": 6960
    },
    {
      "epoch": 1.5994944852941178,
      "grad_norm": 1.0763347148895264,
      "learning_rate": 5.189787234042554e-06,
      "loss": 0.0842,
      "step": 6961
    },
    {
      "epoch": 1.5997242647058822,
      "grad_norm": 1.4367811679840088,
      "learning_rate": 5.188936170212766e-06,
      "loss": 0.0941,
      "step": 6962
    },
    {
      "epoch": 1.5999540441176472,
      "grad_norm": 1.2055718898773193,
      "learning_rate": 5.1880851063829795e-06,
      "loss": 0.0678,
      "step": 6963
    },
    {
      "epoch": 1.6001838235294117,
      "grad_norm": 1.0752729177474976,
      "learning_rate": 5.187234042553192e-06,
      "loss": 0.0683,
      "step": 6964
    },
    {
      "epoch": 1.6004136029411766,
      "grad_norm": 1.6849843263626099,
      "learning_rate": 5.186382978723404e-06,
      "loss": 0.0701,
      "step": 6965
    },
    {
      "epoch": 1.6006433823529411,
      "grad_norm": 1.3226563930511475,
      "learning_rate": 5.185531914893618e-06,
      "loss": 0.0815,
      "step": 6966
    },
    {
      "epoch": 1.6008731617647058,
      "grad_norm": 1.0501121282577515,
      "learning_rate": 5.1846808510638305e-06,
      "loss": 0.0536,
      "step": 6967
    },
    {
      "epoch": 1.6011029411764706,
      "grad_norm": 1.1113144159317017,
      "learning_rate": 5.183829787234043e-06,
      "loss": 0.0473,
      "step": 6968
    },
    {
      "epoch": 1.6013327205882353,
      "grad_norm": 1.1567059755325317,
      "learning_rate": 5.182978723404256e-06,
      "loss": 0.0842,
      "step": 6969
    },
    {
      "epoch": 1.6015625,
      "grad_norm": 1.3454316854476929,
      "learning_rate": 5.182127659574468e-06,
      "loss": 0.1013,
      "step": 6970
    },
    {
      "epoch": 1.6017922794117647,
      "grad_norm": 1.22957444190979,
      "learning_rate": 5.181276595744681e-06,
      "loss": 0.0683,
      "step": 6971
    },
    {
      "epoch": 1.6020220588235294,
      "grad_norm": 1.2035815715789795,
      "learning_rate": 5.180425531914895e-06,
      "loss": 0.0715,
      "step": 6972
    },
    {
      "epoch": 1.6022518382352942,
      "grad_norm": 1.0003286600112915,
      "learning_rate": 5.179574468085107e-06,
      "loss": 0.0686,
      "step": 6973
    },
    {
      "epoch": 1.6024816176470589,
      "grad_norm": 0.9888703227043152,
      "learning_rate": 5.178723404255319e-06,
      "loss": 0.0779,
      "step": 6974
    },
    {
      "epoch": 1.6027113970588234,
      "grad_norm": 0.9472901821136475,
      "learning_rate": 5.1778723404255325e-06,
      "loss": 0.0404,
      "step": 6975
    },
    {
      "epoch": 1.6029411764705883,
      "grad_norm": 1.2480493783950806,
      "learning_rate": 5.177021276595745e-06,
      "loss": 0.1032,
      "step": 6976
    },
    {
      "epoch": 1.6031709558823528,
      "grad_norm": 1.3285619020462036,
      "learning_rate": 5.176170212765957e-06,
      "loss": 0.0783,
      "step": 6977
    },
    {
      "epoch": 1.6034007352941178,
      "grad_norm": 1.0862045288085938,
      "learning_rate": 5.175319148936171e-06,
      "loss": 0.0749,
      "step": 6978
    },
    {
      "epoch": 1.6036305147058822,
      "grad_norm": 1.3838136196136475,
      "learning_rate": 5.1744680851063834e-06,
      "loss": 0.0732,
      "step": 6979
    },
    {
      "epoch": 1.6038602941176472,
      "grad_norm": 1.360559105873108,
      "learning_rate": 5.173617021276596e-06,
      "loss": 0.094,
      "step": 6980
    },
    {
      "epoch": 1.6040900735294117,
      "grad_norm": 0.9659406542778015,
      "learning_rate": 5.172765957446809e-06,
      "loss": 0.047,
      "step": 6981
    },
    {
      "epoch": 1.6043198529411766,
      "grad_norm": 1.6527775526046753,
      "learning_rate": 5.171914893617021e-06,
      "loss": 0.1102,
      "step": 6982
    },
    {
      "epoch": 1.6045496323529411,
      "grad_norm": 1.275415301322937,
      "learning_rate": 5.171063829787234e-06,
      "loss": 0.0825,
      "step": 6983
    },
    {
      "epoch": 1.6047794117647058,
      "grad_norm": 1.2351588010787964,
      "learning_rate": 5.170212765957448e-06,
      "loss": 0.0711,
      "step": 6984
    },
    {
      "epoch": 1.6050091911764706,
      "grad_norm": 1.5343290567398071,
      "learning_rate": 5.16936170212766e-06,
      "loss": 0.0739,
      "step": 6985
    },
    {
      "epoch": 1.6052389705882353,
      "grad_norm": 1.0143271684646606,
      "learning_rate": 5.168510638297872e-06,
      "loss": 0.0633,
      "step": 6986
    },
    {
      "epoch": 1.60546875,
      "grad_norm": 1.1918444633483887,
      "learning_rate": 5.1676595744680854e-06,
      "loss": 0.0724,
      "step": 6987
    },
    {
      "epoch": 1.6056985294117647,
      "grad_norm": 1.1342047452926636,
      "learning_rate": 5.166808510638298e-06,
      "loss": 0.0585,
      "step": 6988
    },
    {
      "epoch": 1.6059283088235294,
      "grad_norm": 1.0739805698394775,
      "learning_rate": 5.165957446808511e-06,
      "loss": 0.0702,
      "step": 6989
    },
    {
      "epoch": 1.6061580882352942,
      "grad_norm": 1.5307492017745972,
      "learning_rate": 5.165106382978724e-06,
      "loss": 0.0792,
      "step": 6990
    },
    {
      "epoch": 1.6063878676470589,
      "grad_norm": 1.2174997329711914,
      "learning_rate": 5.164255319148936e-06,
      "loss": 0.0739,
      "step": 6991
    },
    {
      "epoch": 1.6066176470588234,
      "grad_norm": 1.571724534034729,
      "learning_rate": 5.16340425531915e-06,
      "loss": 0.0822,
      "step": 6992
    },
    {
      "epoch": 1.6068474264705883,
      "grad_norm": 1.3677608966827393,
      "learning_rate": 5.162553191489362e-06,
      "loss": 0.0851,
      "step": 6993
    },
    {
      "epoch": 1.6070772058823528,
      "grad_norm": 1.1362273693084717,
      "learning_rate": 5.161702127659575e-06,
      "loss": 0.0729,
      "step": 6994
    },
    {
      "epoch": 1.6073069852941178,
      "grad_norm": 1.3216018676757812,
      "learning_rate": 5.160851063829788e-06,
      "loss": 0.0826,
      "step": 6995
    },
    {
      "epoch": 1.6075367647058822,
      "grad_norm": 1.3381409645080566,
      "learning_rate": 5.1600000000000006e-06,
      "loss": 0.0832,
      "step": 6996
    },
    {
      "epoch": 1.6077665441176472,
      "grad_norm": 1.1184154748916626,
      "learning_rate": 5.159148936170213e-06,
      "loss": 0.0539,
      "step": 6997
    },
    {
      "epoch": 1.6079963235294117,
      "grad_norm": 1.0276970863342285,
      "learning_rate": 5.158297872340426e-06,
      "loss": 0.058,
      "step": 6998
    },
    {
      "epoch": 1.6082261029411766,
      "grad_norm": 0.8556714057922363,
      "learning_rate": 5.157446808510639e-06,
      "loss": 0.0403,
      "step": 6999
    },
    {
      "epoch": 1.6084558823529411,
      "grad_norm": 1.439232587814331,
      "learning_rate": 5.1565957446808516e-06,
      "loss": 0.0901,
      "step": 7000
    },
    {
      "epoch": 1.6084558823529411,
      "eval_loss": 0.08280232548713684,
      "eval_runtime": 1965.7895,
      "eval_samples_per_second": 4.53,
      "eval_steps_per_second": 2.265,
      "step": 7000
    },
    {
      "epoch": 1.6086856617647058,
      "grad_norm": 1.2740570306777954,
      "learning_rate": 5.155744680851065e-06,
      "loss": 0.1053,
      "step": 7001
    },
    {
      "epoch": 1.6089154411764706,
      "grad_norm": 1.1405311822891235,
      "learning_rate": 5.154893617021277e-06,
      "loss": 0.0599,
      "step": 7002
    },
    {
      "epoch": 1.6091452205882353,
      "grad_norm": 1.505317211151123,
      "learning_rate": 5.154042553191489e-06,
      "loss": 0.1289,
      "step": 7003
    },
    {
      "epoch": 1.609375,
      "grad_norm": 1.2749849557876587,
      "learning_rate": 5.153191489361703e-06,
      "loss": 0.0793,
      "step": 7004
    },
    {
      "epoch": 1.6096047794117647,
      "grad_norm": 1.3299251794815063,
      "learning_rate": 5.152340425531916e-06,
      "loss": 0.0644,
      "step": 7005
    },
    {
      "epoch": 1.6098345588235294,
      "grad_norm": 1.4008934497833252,
      "learning_rate": 5.151489361702128e-06,
      "loss": 0.0894,
      "step": 7006
    },
    {
      "epoch": 1.6100643382352942,
      "grad_norm": 1.318145513534546,
      "learning_rate": 5.150638297872341e-06,
      "loss": 0.0962,
      "step": 7007
    },
    {
      "epoch": 1.6102941176470589,
      "grad_norm": 1.3565102815628052,
      "learning_rate": 5.1497872340425535e-06,
      "loss": 0.0803,
      "step": 7008
    },
    {
      "epoch": 1.6105238970588234,
      "grad_norm": 1.0821009874343872,
      "learning_rate": 5.148936170212766e-06,
      "loss": 0.0834,
      "step": 7009
    },
    {
      "epoch": 1.6107536764705883,
      "grad_norm": 0.9548087120056152,
      "learning_rate": 5.14808510638298e-06,
      "loss": 0.0595,
      "step": 7010
    },
    {
      "epoch": 1.6109834558823528,
      "grad_norm": 1.3306081295013428,
      "learning_rate": 5.147234042553192e-06,
      "loss": 0.0867,
      "step": 7011
    },
    {
      "epoch": 1.6112132352941178,
      "grad_norm": 1.4193150997161865,
      "learning_rate": 5.1463829787234045e-06,
      "loss": 0.0485,
      "step": 7012
    },
    {
      "epoch": 1.6114430147058822,
      "grad_norm": 1.0327671766281128,
      "learning_rate": 5.145531914893618e-06,
      "loss": 0.0934,
      "step": 7013
    },
    {
      "epoch": 1.6116727941176472,
      "grad_norm": 1.0039317607879639,
      "learning_rate": 5.14468085106383e-06,
      "loss": 0.073,
      "step": 7014
    },
    {
      "epoch": 1.6119025735294117,
      "grad_norm": 1.3496211767196655,
      "learning_rate": 5.143829787234042e-06,
      "loss": 0.0587,
      "step": 7015
    },
    {
      "epoch": 1.6121323529411766,
      "grad_norm": 1.0396955013275146,
      "learning_rate": 5.142978723404256e-06,
      "loss": 0.0716,
      "step": 7016
    },
    {
      "epoch": 1.6123621323529411,
      "grad_norm": 1.042015790939331,
      "learning_rate": 5.142127659574469e-06,
      "loss": 0.0549,
      "step": 7017
    },
    {
      "epoch": 1.6125919117647058,
      "grad_norm": 1.3722978830337524,
      "learning_rate": 5.141276595744681e-06,
      "loss": 0.0784,
      "step": 7018
    },
    {
      "epoch": 1.6128216911764706,
      "grad_norm": 1.5101327896118164,
      "learning_rate": 5.140425531914894e-06,
      "loss": 0.1054,
      "step": 7019
    },
    {
      "epoch": 1.6130514705882353,
      "grad_norm": 0.9999935626983643,
      "learning_rate": 5.1395744680851065e-06,
      "loss": 0.0801,
      "step": 7020
    },
    {
      "epoch": 1.61328125,
      "grad_norm": 1.379288911819458,
      "learning_rate": 5.138723404255319e-06,
      "loss": 0.0843,
      "step": 7021
    },
    {
      "epoch": 1.6135110294117647,
      "grad_norm": 1.1603691577911377,
      "learning_rate": 5.137872340425533e-06,
      "loss": 0.0818,
      "step": 7022
    },
    {
      "epoch": 1.6137408088235294,
      "grad_norm": 1.2719303369522095,
      "learning_rate": 5.137021276595745e-06,
      "loss": 0.0683,
      "step": 7023
    },
    {
      "epoch": 1.6139705882352942,
      "grad_norm": 0.8576281666755676,
      "learning_rate": 5.1361702127659575e-06,
      "loss": 0.079,
      "step": 7024
    },
    {
      "epoch": 1.6142003676470589,
      "grad_norm": 1.4730826616287231,
      "learning_rate": 5.135319148936171e-06,
      "loss": 0.0844,
      "step": 7025
    },
    {
      "epoch": 1.6144301470588234,
      "grad_norm": 0.96189284324646,
      "learning_rate": 5.134468085106383e-06,
      "loss": 0.0643,
      "step": 7026
    },
    {
      "epoch": 1.6146599264705883,
      "grad_norm": 1.3614356517791748,
      "learning_rate": 5.133617021276595e-06,
      "loss": 0.0843,
      "step": 7027
    },
    {
      "epoch": 1.6148897058823528,
      "grad_norm": 1.3410513401031494,
      "learning_rate": 5.132765957446809e-06,
      "loss": 0.0789,
      "step": 7028
    },
    {
      "epoch": 1.6151194852941178,
      "grad_norm": 1.2318949699401855,
      "learning_rate": 5.131914893617022e-06,
      "loss": 0.0826,
      "step": 7029
    },
    {
      "epoch": 1.6153492647058822,
      "grad_norm": 1.2973219156265259,
      "learning_rate": 5.131063829787234e-06,
      "loss": 0.0814,
      "step": 7030
    },
    {
      "epoch": 1.6155790441176472,
      "grad_norm": 1.3365012407302856,
      "learning_rate": 5.130212765957447e-06,
      "loss": 0.0946,
      "step": 7031
    },
    {
      "epoch": 1.6158088235294117,
      "grad_norm": 1.2776734828948975,
      "learning_rate": 5.1293617021276595e-06,
      "loss": 0.0769,
      "step": 7032
    },
    {
      "epoch": 1.6160386029411766,
      "grad_norm": 1.1924103498458862,
      "learning_rate": 5.128510638297872e-06,
      "loss": 0.0998,
      "step": 7033
    },
    {
      "epoch": 1.6162683823529411,
      "grad_norm": 1.3726688623428345,
      "learning_rate": 5.127659574468086e-06,
      "loss": 0.1023,
      "step": 7034
    },
    {
      "epoch": 1.6164981617647058,
      "grad_norm": 1.1386842727661133,
      "learning_rate": 5.126808510638298e-06,
      "loss": 0.0614,
      "step": 7035
    },
    {
      "epoch": 1.6167279411764706,
      "grad_norm": 1.210598349571228,
      "learning_rate": 5.125957446808511e-06,
      "loss": 0.0664,
      "step": 7036
    },
    {
      "epoch": 1.6169577205882353,
      "grad_norm": 1.1917363405227661,
      "learning_rate": 5.125106382978724e-06,
      "loss": 0.0924,
      "step": 7037
    },
    {
      "epoch": 1.6171875,
      "grad_norm": 1.0539807081222534,
      "learning_rate": 5.124255319148936e-06,
      "loss": 0.0856,
      "step": 7038
    },
    {
      "epoch": 1.6174172794117647,
      "grad_norm": 0.8934873938560486,
      "learning_rate": 5.12340425531915e-06,
      "loss": 0.0661,
      "step": 7039
    },
    {
      "epoch": 1.6176470588235294,
      "grad_norm": 1.3801443576812744,
      "learning_rate": 5.122553191489362e-06,
      "loss": 0.0841,
      "step": 7040
    },
    {
      "epoch": 1.6178768382352942,
      "grad_norm": 1.0690054893493652,
      "learning_rate": 5.121702127659575e-06,
      "loss": 0.0651,
      "step": 7041
    },
    {
      "epoch": 1.6181066176470589,
      "grad_norm": 1.231541633605957,
      "learning_rate": 5.120851063829788e-06,
      "loss": 0.0816,
      "step": 7042
    },
    {
      "epoch": 1.6183363970588234,
      "grad_norm": 1.3591253757476807,
      "learning_rate": 5.12e-06,
      "loss": 0.074,
      "step": 7043
    },
    {
      "epoch": 1.6185661764705883,
      "grad_norm": 1.0590976476669312,
      "learning_rate": 5.119148936170213e-06,
      "loss": 0.0618,
      "step": 7044
    },
    {
      "epoch": 1.6187959558823528,
      "grad_norm": 1.4943037033081055,
      "learning_rate": 5.1182978723404264e-06,
      "loss": 0.0873,
      "step": 7045
    },
    {
      "epoch": 1.6190257352941178,
      "grad_norm": 0.9500921368598938,
      "learning_rate": 5.117446808510639e-06,
      "loss": 0.0731,
      "step": 7046
    },
    {
      "epoch": 1.6192555147058822,
      "grad_norm": 1.0097780227661133,
      "learning_rate": 5.116595744680851e-06,
      "loss": 0.0478,
      "step": 7047
    },
    {
      "epoch": 1.6194852941176472,
      "grad_norm": 1.3400136232376099,
      "learning_rate": 5.115744680851064e-06,
      "loss": 0.0997,
      "step": 7048
    },
    {
      "epoch": 1.6197150735294117,
      "grad_norm": 1.6048067808151245,
      "learning_rate": 5.1148936170212774e-06,
      "loss": 0.0826,
      "step": 7049
    },
    {
      "epoch": 1.6199448529411766,
      "grad_norm": 1.605863332748413,
      "learning_rate": 5.11404255319149e-06,
      "loss": 0.1023,
      "step": 7050
    },
    {
      "epoch": 1.6201746323529411,
      "grad_norm": 1.5141323804855347,
      "learning_rate": 5.113191489361703e-06,
      "loss": 0.1171,
      "step": 7051
    },
    {
      "epoch": 1.6204044117647058,
      "grad_norm": 1.0475754737854004,
      "learning_rate": 5.112340425531915e-06,
      "loss": 0.0865,
      "step": 7052
    },
    {
      "epoch": 1.6206341911764706,
      "grad_norm": 1.3836729526519775,
      "learning_rate": 5.111489361702128e-06,
      "loss": 0.0815,
      "step": 7053
    },
    {
      "epoch": 1.6208639705882353,
      "grad_norm": 1.2241380214691162,
      "learning_rate": 5.110638297872342e-06,
      "loss": 0.0682,
      "step": 7054
    },
    {
      "epoch": 1.62109375,
      "grad_norm": 1.1397597789764404,
      "learning_rate": 5.109787234042554e-06,
      "loss": 0.0771,
      "step": 7055
    },
    {
      "epoch": 1.6213235294117647,
      "grad_norm": 2.0144693851470947,
      "learning_rate": 5.108936170212766e-06,
      "loss": 0.0956,
      "step": 7056
    },
    {
      "epoch": 1.6215533088235294,
      "grad_norm": 1.024135708808899,
      "learning_rate": 5.108085106382979e-06,
      "loss": 0.0673,
      "step": 7057
    },
    {
      "epoch": 1.6217830882352942,
      "grad_norm": 1.3952789306640625,
      "learning_rate": 5.107234042553192e-06,
      "loss": 0.0731,
      "step": 7058
    },
    {
      "epoch": 1.6220128676470589,
      "grad_norm": 1.9283947944641113,
      "learning_rate": 5.106382978723404e-06,
      "loss": 0.1048,
      "step": 7059
    },
    {
      "epoch": 1.6222426470588234,
      "grad_norm": 1.2562252283096313,
      "learning_rate": 5.105531914893618e-06,
      "loss": 0.0682,
      "step": 7060
    },
    {
      "epoch": 1.6224724264705883,
      "grad_norm": 1.551276683807373,
      "learning_rate": 5.10468085106383e-06,
      "loss": 0.0817,
      "step": 7061
    },
    {
      "epoch": 1.6227022058823528,
      "grad_norm": 1.3104603290557861,
      "learning_rate": 5.103829787234043e-06,
      "loss": 0.0886,
      "step": 7062
    },
    {
      "epoch": 1.6229319852941178,
      "grad_norm": 1.1002742052078247,
      "learning_rate": 5.102978723404256e-06,
      "loss": 0.0589,
      "step": 7063
    },
    {
      "epoch": 1.6231617647058822,
      "grad_norm": 1.1824244260787964,
      "learning_rate": 5.102127659574468e-06,
      "loss": 0.088,
      "step": 7064
    },
    {
      "epoch": 1.6233915441176472,
      "grad_norm": 1.3453686237335205,
      "learning_rate": 5.1012765957446805e-06,
      "loss": 0.0819,
      "step": 7065
    },
    {
      "epoch": 1.6236213235294117,
      "grad_norm": 1.4082298278808594,
      "learning_rate": 5.1004255319148946e-06,
      "loss": 0.0859,
      "step": 7066
    },
    {
      "epoch": 1.6238511029411766,
      "grad_norm": 0.9945626258850098,
      "learning_rate": 5.099574468085107e-06,
      "loss": 0.0829,
      "step": 7067
    },
    {
      "epoch": 1.6240808823529411,
      "grad_norm": 0.9869599342346191,
      "learning_rate": 5.098723404255319e-06,
      "loss": 0.0619,
      "step": 7068
    },
    {
      "epoch": 1.6243106617647058,
      "grad_norm": 1.0302151441574097,
      "learning_rate": 5.097872340425532e-06,
      "loss": 0.0644,
      "step": 7069
    },
    {
      "epoch": 1.6245404411764706,
      "grad_norm": 1.3132679462432861,
      "learning_rate": 5.097021276595745e-06,
      "loss": 0.0858,
      "step": 7070
    },
    {
      "epoch": 1.6247702205882353,
      "grad_norm": 1.13909113407135,
      "learning_rate": 5.096170212765957e-06,
      "loss": 0.0739,
      "step": 7071
    },
    {
      "epoch": 1.625,
      "grad_norm": 1.0392836332321167,
      "learning_rate": 5.095319148936171e-06,
      "loss": 0.0647,
      "step": 7072
    },
    {
      "epoch": 1.6252297794117647,
      "grad_norm": 1.1458560228347778,
      "learning_rate": 5.094468085106383e-06,
      "loss": 0.092,
      "step": 7073
    },
    {
      "epoch": 1.6254595588235294,
      "grad_norm": 1.161779761314392,
      "learning_rate": 5.093617021276596e-06,
      "loss": 0.0899,
      "step": 7074
    },
    {
      "epoch": 1.6256893382352942,
      "grad_norm": 1.3095595836639404,
      "learning_rate": 5.092765957446809e-06,
      "loss": 0.0831,
      "step": 7075
    },
    {
      "epoch": 1.6259191176470589,
      "grad_norm": 1.2217447757720947,
      "learning_rate": 5.091914893617021e-06,
      "loss": 0.061,
      "step": 7076
    },
    {
      "epoch": 1.6261488970588234,
      "grad_norm": 1.1296567916870117,
      "learning_rate": 5.091063829787235e-06,
      "loss": 0.0949,
      "step": 7077
    },
    {
      "epoch": 1.6263786764705883,
      "grad_norm": 1.1631501913070679,
      "learning_rate": 5.0902127659574475e-06,
      "loss": 0.0712,
      "step": 7078
    },
    {
      "epoch": 1.6266084558823528,
      "grad_norm": 1.2462670803070068,
      "learning_rate": 5.08936170212766e-06,
      "loss": 0.0878,
      "step": 7079
    },
    {
      "epoch": 1.6268382352941178,
      "grad_norm": 0.8691883087158203,
      "learning_rate": 5.088510638297873e-06,
      "loss": 0.0422,
      "step": 7080
    },
    {
      "epoch": 1.6270680147058822,
      "grad_norm": 1.044110655784607,
      "learning_rate": 5.087659574468085e-06,
      "loss": 0.092,
      "step": 7081
    },
    {
      "epoch": 1.6272977941176472,
      "grad_norm": 0.9291117191314697,
      "learning_rate": 5.086808510638298e-06,
      "loss": 0.0818,
      "step": 7082
    },
    {
      "epoch": 1.6275275735294117,
      "grad_norm": 1.2505749464035034,
      "learning_rate": 5.085957446808512e-06,
      "loss": 0.0841,
      "step": 7083
    },
    {
      "epoch": 1.6277573529411766,
      "grad_norm": 1.1896123886108398,
      "learning_rate": 5.085106382978724e-06,
      "loss": 0.0941,
      "step": 7084
    },
    {
      "epoch": 1.6279871323529411,
      "grad_norm": 1.2237530946731567,
      "learning_rate": 5.084255319148936e-06,
      "loss": 0.0811,
      "step": 7085
    },
    {
      "epoch": 1.6282169117647058,
      "grad_norm": 1.4118117094039917,
      "learning_rate": 5.0834042553191495e-06,
      "loss": 0.0989,
      "step": 7086
    },
    {
      "epoch": 1.6284466911764706,
      "grad_norm": 1.2667280435562134,
      "learning_rate": 5.082553191489362e-06,
      "loss": 0.0693,
      "step": 7087
    },
    {
      "epoch": 1.6286764705882353,
      "grad_norm": 1.0678162574768066,
      "learning_rate": 5.081702127659575e-06,
      "loss": 0.0629,
      "step": 7088
    },
    {
      "epoch": 1.62890625,
      "grad_norm": 0.9778632521629333,
      "learning_rate": 5.080851063829788e-06,
      "loss": 0.0678,
      "step": 7089
    },
    {
      "epoch": 1.6291360294117647,
      "grad_norm": 1.3302534818649292,
      "learning_rate": 5.0800000000000005e-06,
      "loss": 0.051,
      "step": 7090
    },
    {
      "epoch": 1.6293658088235294,
      "grad_norm": 1.3754549026489258,
      "learning_rate": 5.079148936170213e-06,
      "loss": 0.0792,
      "step": 7091
    },
    {
      "epoch": 1.6295955882352942,
      "grad_norm": 1.0203232765197754,
      "learning_rate": 5.078297872340426e-06,
      "loss": 0.0754,
      "step": 7092
    },
    {
      "epoch": 1.6298253676470589,
      "grad_norm": 1.076704740524292,
      "learning_rate": 5.077446808510639e-06,
      "loss": 0.0755,
      "step": 7093
    },
    {
      "epoch": 1.6300551470588234,
      "grad_norm": 1.1625231504440308,
      "learning_rate": 5.0765957446808515e-06,
      "loss": 0.0722,
      "step": 7094
    },
    {
      "epoch": 1.6302849264705883,
      "grad_norm": 0.9544639587402344,
      "learning_rate": 5.075744680851065e-06,
      "loss": 0.0707,
      "step": 7095
    },
    {
      "epoch": 1.6305147058823528,
      "grad_norm": 1.488309383392334,
      "learning_rate": 5.074893617021277e-06,
      "loss": 0.0776,
      "step": 7096
    },
    {
      "epoch": 1.6307444852941178,
      "grad_norm": 1.2751624584197998,
      "learning_rate": 5.074042553191489e-06,
      "loss": 0.0691,
      "step": 7097
    },
    {
      "epoch": 1.6309742647058822,
      "grad_norm": 1.2601420879364014,
      "learning_rate": 5.073191489361703e-06,
      "loss": 0.0857,
      "step": 7098
    },
    {
      "epoch": 1.6312040441176472,
      "grad_norm": 0.883857786655426,
      "learning_rate": 5.072340425531916e-06,
      "loss": 0.051,
      "step": 7099
    },
    {
      "epoch": 1.6314338235294117,
      "grad_norm": 0.9945416450500488,
      "learning_rate": 5.071489361702128e-06,
      "loss": 0.0631,
      "step": 7100
    },
    {
      "epoch": 1.6316636029411766,
      "grad_norm": 1.6973521709442139,
      "learning_rate": 5.070638297872341e-06,
      "loss": 0.1349,
      "step": 7101
    },
    {
      "epoch": 1.6318933823529411,
      "grad_norm": 1.1772409677505493,
      "learning_rate": 5.0697872340425535e-06,
      "loss": 0.0807,
      "step": 7102
    },
    {
      "epoch": 1.6321231617647058,
      "grad_norm": 1.2180544137954712,
      "learning_rate": 5.068936170212766e-06,
      "loss": 0.0554,
      "step": 7103
    },
    {
      "epoch": 1.6323529411764706,
      "grad_norm": 1.6115587949752808,
      "learning_rate": 5.06808510638298e-06,
      "loss": 0.1073,
      "step": 7104
    },
    {
      "epoch": 1.6325827205882353,
      "grad_norm": 1.1474875211715698,
      "learning_rate": 5.067234042553192e-06,
      "loss": 0.0785,
      "step": 7105
    },
    {
      "epoch": 1.6328125,
      "grad_norm": 1.3891849517822266,
      "learning_rate": 5.0663829787234044e-06,
      "loss": 0.0942,
      "step": 7106
    },
    {
      "epoch": 1.6330422794117647,
      "grad_norm": 1.4722071886062622,
      "learning_rate": 5.065531914893618e-06,
      "loss": 0.0793,
      "step": 7107
    },
    {
      "epoch": 1.6332720588235294,
      "grad_norm": 1.1380903720855713,
      "learning_rate": 5.06468085106383e-06,
      "loss": 0.0761,
      "step": 7108
    },
    {
      "epoch": 1.6335018382352942,
      "grad_norm": 0.9421581625938416,
      "learning_rate": 5.063829787234042e-06,
      "loss": 0.0625,
      "step": 7109
    },
    {
      "epoch": 1.6337316176470589,
      "grad_norm": 1.294620394706726,
      "learning_rate": 5.062978723404256e-06,
      "loss": 0.1018,
      "step": 7110
    },
    {
      "epoch": 1.6339613970588234,
      "grad_norm": 0.9856300950050354,
      "learning_rate": 5.062127659574469e-06,
      "loss": 0.0682,
      "step": 7111
    },
    {
      "epoch": 1.6341911764705883,
      "grad_norm": 1.0345817804336548,
      "learning_rate": 5.061276595744681e-06,
      "loss": 0.111,
      "step": 7112
    },
    {
      "epoch": 1.6344209558823528,
      "grad_norm": 1.1093567609786987,
      "learning_rate": 5.060425531914894e-06,
      "loss": 0.0571,
      "step": 7113
    },
    {
      "epoch": 1.6346507352941178,
      "grad_norm": 1.2623083591461182,
      "learning_rate": 5.059574468085106e-06,
      "loss": 0.0804,
      "step": 7114
    },
    {
      "epoch": 1.6348805147058822,
      "grad_norm": 1.0285017490386963,
      "learning_rate": 5.058723404255319e-06,
      "loss": 0.071,
      "step": 7115
    },
    {
      "epoch": 1.6351102941176472,
      "grad_norm": 1.026565670967102,
      "learning_rate": 5.057872340425533e-06,
      "loss": 0.081,
      "step": 7116
    },
    {
      "epoch": 1.6353400735294117,
      "grad_norm": 1.6300179958343506,
      "learning_rate": 5.057021276595745e-06,
      "loss": 0.0998,
      "step": 7117
    },
    {
      "epoch": 1.6355698529411766,
      "grad_norm": 1.0561907291412354,
      "learning_rate": 5.056170212765957e-06,
      "loss": 0.0758,
      "step": 7118
    },
    {
      "epoch": 1.6357996323529411,
      "grad_norm": 1.3422333002090454,
      "learning_rate": 5.055319148936171e-06,
      "loss": 0.0886,
      "step": 7119
    },
    {
      "epoch": 1.6360294117647058,
      "grad_norm": 1.7632319927215576,
      "learning_rate": 5.054468085106383e-06,
      "loss": 0.1044,
      "step": 7120
    },
    {
      "epoch": 1.6362591911764706,
      "grad_norm": 1.6720792055130005,
      "learning_rate": 5.053617021276597e-06,
      "loss": 0.0666,
      "step": 7121
    },
    {
      "epoch": 1.6364889705882353,
      "grad_norm": 1.4250487089157104,
      "learning_rate": 5.052765957446809e-06,
      "loss": 0.0856,
      "step": 7122
    },
    {
      "epoch": 1.63671875,
      "grad_norm": 1.137624740600586,
      "learning_rate": 5.0519148936170216e-06,
      "loss": 0.0701,
      "step": 7123
    },
    {
      "epoch": 1.6369485294117647,
      "grad_norm": 1.4119361639022827,
      "learning_rate": 5.051063829787235e-06,
      "loss": 0.0682,
      "step": 7124
    },
    {
      "epoch": 1.6371783088235294,
      "grad_norm": 1.4519435167312622,
      "learning_rate": 5.050212765957447e-06,
      "loss": 0.0943,
      "step": 7125
    },
    {
      "epoch": 1.6374080882352942,
      "grad_norm": 1.2966216802597046,
      "learning_rate": 5.049361702127659e-06,
      "loss": 0.064,
      "step": 7126
    },
    {
      "epoch": 1.6376378676470589,
      "grad_norm": 1.0614420175552368,
      "learning_rate": 5.048510638297873e-06,
      "loss": 0.0696,
      "step": 7127
    },
    {
      "epoch": 1.6378676470588234,
      "grad_norm": 1.2737517356872559,
      "learning_rate": 5.047659574468086e-06,
      "loss": 0.0563,
      "step": 7128
    },
    {
      "epoch": 1.6380974264705883,
      "grad_norm": 0.9936035871505737,
      "learning_rate": 5.046808510638298e-06,
      "loss": 0.0614,
      "step": 7129
    },
    {
      "epoch": 1.6383272058823528,
      "grad_norm": 1.060994029045105,
      "learning_rate": 5.045957446808511e-06,
      "loss": 0.0736,
      "step": 7130
    },
    {
      "epoch": 1.6385569852941178,
      "grad_norm": 1.1055628061294556,
      "learning_rate": 5.0451063829787235e-06,
      "loss": 0.0842,
      "step": 7131
    },
    {
      "epoch": 1.6387867647058822,
      "grad_norm": 1.1530696153640747,
      "learning_rate": 5.044255319148937e-06,
      "loss": 0.0526,
      "step": 7132
    },
    {
      "epoch": 1.6390165441176472,
      "grad_norm": 1.1863741874694824,
      "learning_rate": 5.04340425531915e-06,
      "loss": 0.0977,
      "step": 7133
    },
    {
      "epoch": 1.6392463235294117,
      "grad_norm": 1.143317461013794,
      "learning_rate": 5.042553191489362e-06,
      "loss": 0.0686,
      "step": 7134
    },
    {
      "epoch": 1.6394761029411766,
      "grad_norm": 2.1779730319976807,
      "learning_rate": 5.0417021276595745e-06,
      "loss": 0.1298,
      "step": 7135
    },
    {
      "epoch": 1.6397058823529411,
      "grad_norm": 0.8530787825584412,
      "learning_rate": 5.040851063829788e-06,
      "loss": 0.0637,
      "step": 7136
    },
    {
      "epoch": 1.6399356617647058,
      "grad_norm": 1.0346314907073975,
      "learning_rate": 5.04e-06,
      "loss": 0.0582,
      "step": 7137
    },
    {
      "epoch": 1.6401654411764706,
      "grad_norm": 1.3968027830123901,
      "learning_rate": 5.039148936170213e-06,
      "loss": 0.0633,
      "step": 7138
    },
    {
      "epoch": 1.6403952205882353,
      "grad_norm": 1.0809426307678223,
      "learning_rate": 5.038297872340426e-06,
      "loss": 0.0772,
      "step": 7139
    },
    {
      "epoch": 1.640625,
      "grad_norm": 1.2187879085540771,
      "learning_rate": 5.037446808510639e-06,
      "loss": 0.0754,
      "step": 7140
    },
    {
      "epoch": 1.6408547794117647,
      "grad_norm": 1.0830351114273071,
      "learning_rate": 5.036595744680851e-06,
      "loss": 0.0721,
      "step": 7141
    },
    {
      "epoch": 1.6410845588235294,
      "grad_norm": 1.1384958028793335,
      "learning_rate": 5.035744680851064e-06,
      "loss": 0.072,
      "step": 7142
    },
    {
      "epoch": 1.6413143382352942,
      "grad_norm": 1.48641037940979,
      "learning_rate": 5.034893617021277e-06,
      "loss": 0.0837,
      "step": 7143
    },
    {
      "epoch": 1.6415441176470589,
      "grad_norm": 1.739775538444519,
      "learning_rate": 5.03404255319149e-06,
      "loss": 0.0987,
      "step": 7144
    },
    {
      "epoch": 1.6417738970588234,
      "grad_norm": 1.0159519910812378,
      "learning_rate": 5.033191489361703e-06,
      "loss": 0.0701,
      "step": 7145
    },
    {
      "epoch": 1.6420036764705883,
      "grad_norm": 1.0882220268249512,
      "learning_rate": 5.032340425531915e-06,
      "loss": 0.0685,
      "step": 7146
    },
    {
      "epoch": 1.6422334558823528,
      "grad_norm": 1.545291781425476,
      "learning_rate": 5.0314893617021275e-06,
      "loss": 0.102,
      "step": 7147
    },
    {
      "epoch": 1.6424632352941178,
      "grad_norm": 1.0317012071609497,
      "learning_rate": 5.0306382978723415e-06,
      "loss": 0.0643,
      "step": 7148
    },
    {
      "epoch": 1.6426930147058822,
      "grad_norm": 1.2479922771453857,
      "learning_rate": 5.029787234042554e-06,
      "loss": 0.0611,
      "step": 7149
    },
    {
      "epoch": 1.6429227941176472,
      "grad_norm": 1.6793500185012817,
      "learning_rate": 5.028936170212766e-06,
      "loss": 0.0548,
      "step": 7150
    },
    {
      "epoch": 1.6431525735294117,
      "grad_norm": 1.3545621633529663,
      "learning_rate": 5.028085106382979e-06,
      "loss": 0.0848,
      "step": 7151
    },
    {
      "epoch": 1.6433823529411766,
      "grad_norm": 1.4836851358413696,
      "learning_rate": 5.027234042553192e-06,
      "loss": 0.0849,
      "step": 7152
    },
    {
      "epoch": 1.6436121323529411,
      "grad_norm": 1.0123138427734375,
      "learning_rate": 5.026382978723404e-06,
      "loss": 0.0651,
      "step": 7153
    },
    {
      "epoch": 1.6438419117647058,
      "grad_norm": 1.0540404319763184,
      "learning_rate": 5.025531914893618e-06,
      "loss": 0.0736,
      "step": 7154
    },
    {
      "epoch": 1.6440716911764706,
      "grad_norm": 1.347868800163269,
      "learning_rate": 5.02468085106383e-06,
      "loss": 0.1203,
      "step": 7155
    },
    {
      "epoch": 1.6443014705882353,
      "grad_norm": 1.3514353036880493,
      "learning_rate": 5.023829787234043e-06,
      "loss": 0.0886,
      "step": 7156
    },
    {
      "epoch": 1.64453125,
      "grad_norm": 1.1131887435913086,
      "learning_rate": 5.022978723404256e-06,
      "loss": 0.059,
      "step": 7157
    },
    {
      "epoch": 1.6447610294117647,
      "grad_norm": 1.4729162454605103,
      "learning_rate": 5.022127659574468e-06,
      "loss": 0.0696,
      "step": 7158
    },
    {
      "epoch": 1.6449908088235294,
      "grad_norm": 1.324285864830017,
      "learning_rate": 5.0212765957446805e-06,
      "loss": 0.0845,
      "step": 7159
    },
    {
      "epoch": 1.6452205882352942,
      "grad_norm": 1.754258394241333,
      "learning_rate": 5.0204255319148945e-06,
      "loss": 0.0924,
      "step": 7160
    },
    {
      "epoch": 1.6454503676470589,
      "grad_norm": 1.5892643928527832,
      "learning_rate": 5.019574468085107e-06,
      "loss": 0.0997,
      "step": 7161
    },
    {
      "epoch": 1.6456801470588234,
      "grad_norm": 1.234886884689331,
      "learning_rate": 5.018723404255319e-06,
      "loss": 0.0549,
      "step": 7162
    },
    {
      "epoch": 1.6459099264705883,
      "grad_norm": 1.1044552326202393,
      "learning_rate": 5.017872340425532e-06,
      "loss": 0.0785,
      "step": 7163
    },
    {
      "epoch": 1.6461397058823528,
      "grad_norm": 0.9273183345794678,
      "learning_rate": 5.017021276595745e-06,
      "loss": 0.0536,
      "step": 7164
    },
    {
      "epoch": 1.6463694852941178,
      "grad_norm": 1.209522008895874,
      "learning_rate": 5.016170212765959e-06,
      "loss": 0.0887,
      "step": 7165
    },
    {
      "epoch": 1.6465992647058822,
      "grad_norm": 1.4616036415100098,
      "learning_rate": 5.015319148936171e-06,
      "loss": 0.0843,
      "step": 7166
    },
    {
      "epoch": 1.6468290441176472,
      "grad_norm": 1.100305438041687,
      "learning_rate": 5.014468085106383e-06,
      "loss": 0.0504,
      "step": 7167
    },
    {
      "epoch": 1.6470588235294117,
      "grad_norm": 1.207872748374939,
      "learning_rate": 5.0136170212765965e-06,
      "loss": 0.0764,
      "step": 7168
    },
    {
      "epoch": 1.6472886029411766,
      "grad_norm": 1.1864210367202759,
      "learning_rate": 5.012765957446809e-06,
      "loss": 0.0853,
      "step": 7169
    },
    {
      "epoch": 1.6475183823529411,
      "grad_norm": 1.3220669031143188,
      "learning_rate": 5.011914893617021e-06,
      "loss": 0.1016,
      "step": 7170
    },
    {
      "epoch": 1.6477481617647058,
      "grad_norm": 0.9029994010925293,
      "learning_rate": 5.011063829787235e-06,
      "loss": 0.0503,
      "step": 7171
    },
    {
      "epoch": 1.6479779411764706,
      "grad_norm": 0.9566181898117065,
      "learning_rate": 5.0102127659574474e-06,
      "loss": 0.0656,
      "step": 7172
    },
    {
      "epoch": 1.6482077205882353,
      "grad_norm": 0.9483668208122253,
      "learning_rate": 5.00936170212766e-06,
      "loss": 0.0565,
      "step": 7173
    },
    {
      "epoch": 1.6484375,
      "grad_norm": 1.2344787120819092,
      "learning_rate": 5.008510638297873e-06,
      "loss": 0.087,
      "step": 7174
    },
    {
      "epoch": 1.6486672794117647,
      "grad_norm": 1.1011784076690674,
      "learning_rate": 5.007659574468085e-06,
      "loss": 0.0732,
      "step": 7175
    },
    {
      "epoch": 1.6488970588235294,
      "grad_norm": 1.6149667501449585,
      "learning_rate": 5.006808510638298e-06,
      "loss": 0.0937,
      "step": 7176
    },
    {
      "epoch": 1.6491268382352942,
      "grad_norm": 1.5196846723556519,
      "learning_rate": 5.005957446808512e-06,
      "loss": 0.1097,
      "step": 7177
    },
    {
      "epoch": 1.6493566176470589,
      "grad_norm": 1.1565189361572266,
      "learning_rate": 5.005106382978724e-06,
      "loss": 0.0701,
      "step": 7178
    },
    {
      "epoch": 1.6495863970588234,
      "grad_norm": 1.571446418762207,
      "learning_rate": 5.004255319148936e-06,
      "loss": 0.0838,
      "step": 7179
    },
    {
      "epoch": 1.6498161764705883,
      "grad_norm": 1.2090353965759277,
      "learning_rate": 5.003404255319149e-06,
      "loss": 0.0823,
      "step": 7180
    },
    {
      "epoch": 1.6500459558823528,
      "grad_norm": 1.5605236291885376,
      "learning_rate": 5.002553191489362e-06,
      "loss": 0.0782,
      "step": 7181
    },
    {
      "epoch": 1.6502757352941178,
      "grad_norm": 1.2962939739227295,
      "learning_rate": 5.001702127659575e-06,
      "loss": 0.0606,
      "step": 7182
    },
    {
      "epoch": 1.6505055147058822,
      "grad_norm": 1.4263691902160645,
      "learning_rate": 5.000851063829788e-06,
      "loss": 0.102,
      "step": 7183
    },
    {
      "epoch": 1.6507352941176472,
      "grad_norm": 1.3027018308639526,
      "learning_rate": 5e-06,
      "loss": 0.044,
      "step": 7184
    },
    {
      "epoch": 1.6509650735294117,
      "grad_norm": 1.1496542692184448,
      "learning_rate": 4.999148936170214e-06,
      "loss": 0.0742,
      "step": 7185
    },
    {
      "epoch": 1.6511948529411766,
      "grad_norm": 0.9459177255630493,
      "learning_rate": 4.998297872340426e-06,
      "loss": 0.05,
      "step": 7186
    },
    {
      "epoch": 1.6514246323529411,
      "grad_norm": 1.0221507549285889,
      "learning_rate": 4.997446808510639e-06,
      "loss": 0.0609,
      "step": 7187
    },
    {
      "epoch": 1.6516544117647058,
      "grad_norm": 1.2617491483688354,
      "learning_rate": 4.996595744680851e-06,
      "loss": 0.0723,
      "step": 7188
    },
    {
      "epoch": 1.6518841911764706,
      "grad_norm": 1.2306342124938965,
      "learning_rate": 4.995744680851064e-06,
      "loss": 0.0672,
      "step": 7189
    },
    {
      "epoch": 1.6521139705882353,
      "grad_norm": 1.1548601388931274,
      "learning_rate": 4.994893617021277e-06,
      "loss": 0.0736,
      "step": 7190
    },
    {
      "epoch": 1.65234375,
      "grad_norm": 1.2496349811553955,
      "learning_rate": 4.99404255319149e-06,
      "loss": 0.0957,
      "step": 7191
    },
    {
      "epoch": 1.6525735294117647,
      "grad_norm": 1.372741937637329,
      "learning_rate": 4.993191489361702e-06,
      "loss": 0.0972,
      "step": 7192
    },
    {
      "epoch": 1.6528033088235294,
      "grad_norm": 1.181849718093872,
      "learning_rate": 4.9923404255319156e-06,
      "loss": 0.0644,
      "step": 7193
    },
    {
      "epoch": 1.6530330882352942,
      "grad_norm": 1.462004542350769,
      "learning_rate": 4.991489361702128e-06,
      "loss": 0.0883,
      "step": 7194
    },
    {
      "epoch": 1.6532628676470589,
      "grad_norm": 1.6051430702209473,
      "learning_rate": 4.990638297872341e-06,
      "loss": 0.1144,
      "step": 7195
    },
    {
      "epoch": 1.6534926470588234,
      "grad_norm": 1.7057961225509644,
      "learning_rate": 4.989787234042553e-06,
      "loss": 0.0957,
      "step": 7196
    },
    {
      "epoch": 1.6537224264705883,
      "grad_norm": 1.6868144273757935,
      "learning_rate": 4.9889361702127665e-06,
      "loss": 0.0894,
      "step": 7197
    },
    {
      "epoch": 1.6539522058823528,
      "grad_norm": 1.0628103017807007,
      "learning_rate": 4.98808510638298e-06,
      "loss": 0.061,
      "step": 7198
    },
    {
      "epoch": 1.6541819852941178,
      "grad_norm": 1.0391803979873657,
      "learning_rate": 4.987234042553192e-06,
      "loss": 0.0884,
      "step": 7199
    },
    {
      "epoch": 1.6544117647058822,
      "grad_norm": 1.2201707363128662,
      "learning_rate": 4.986382978723404e-06,
      "loss": 0.063,
      "step": 7200
    },
    {
      "epoch": 1.6546415441176472,
      "grad_norm": 1.1752735376358032,
      "learning_rate": 4.9855319148936175e-06,
      "loss": 0.0705,
      "step": 7201
    },
    {
      "epoch": 1.6548713235294117,
      "grad_norm": 1.1755410432815552,
      "learning_rate": 4.98468085106383e-06,
      "loss": 0.069,
      "step": 7202
    },
    {
      "epoch": 1.6551011029411766,
      "grad_norm": 1.2918314933776855,
      "learning_rate": 4.983829787234043e-06,
      "loss": 0.0889,
      "step": 7203
    },
    {
      "epoch": 1.6553308823529411,
      "grad_norm": 1.2658658027648926,
      "learning_rate": 4.982978723404256e-06,
      "loss": 0.0917,
      "step": 7204
    },
    {
      "epoch": 1.6555606617647058,
      "grad_norm": 1.0270386934280396,
      "learning_rate": 4.9821276595744685e-06,
      "loss": 0.0645,
      "step": 7205
    },
    {
      "epoch": 1.6557904411764706,
      "grad_norm": 1.0400407314300537,
      "learning_rate": 4.981276595744681e-06,
      "loss": 0.0621,
      "step": 7206
    },
    {
      "epoch": 1.6560202205882353,
      "grad_norm": 1.2885661125183105,
      "learning_rate": 4.980425531914894e-06,
      "loss": 0.0738,
      "step": 7207
    },
    {
      "epoch": 1.65625,
      "grad_norm": 1.3659677505493164,
      "learning_rate": 4.979574468085106e-06,
      "loss": 0.0867,
      "step": 7208
    },
    {
      "epoch": 1.6564797794117647,
      "grad_norm": 1.1910191774368286,
      "learning_rate": 4.9787234042553195e-06,
      "loss": 0.0811,
      "step": 7209
    },
    {
      "epoch": 1.6567095588235294,
      "grad_norm": 1.5298634767532349,
      "learning_rate": 4.977872340425533e-06,
      "loss": 0.0626,
      "step": 7210
    },
    {
      "epoch": 1.6569393382352942,
      "grad_norm": 1.3247588872909546,
      "learning_rate": 4.977021276595745e-06,
      "loss": 0.0966,
      "step": 7211
    },
    {
      "epoch": 1.6571691176470589,
      "grad_norm": 1.378663420677185,
      "learning_rate": 4.976170212765958e-06,
      "loss": 0.0773,
      "step": 7212
    },
    {
      "epoch": 1.6573988970588234,
      "grad_norm": 1.4887640476226807,
      "learning_rate": 4.9753191489361705e-06,
      "loss": 0.1,
      "step": 7213
    },
    {
      "epoch": 1.6576286764705883,
      "grad_norm": 0.9680616855621338,
      "learning_rate": 4.974468085106383e-06,
      "loss": 0.0463,
      "step": 7214
    },
    {
      "epoch": 1.6578584558823528,
      "grad_norm": 1.0713918209075928,
      "learning_rate": 4.973617021276596e-06,
      "loss": 0.0715,
      "step": 7215
    },
    {
      "epoch": 1.6580882352941178,
      "grad_norm": 1.2858713865280151,
      "learning_rate": 4.972765957446809e-06,
      "loss": 0.0792,
      "step": 7216
    },
    {
      "epoch": 1.6583180147058822,
      "grad_norm": 1.268072247505188,
      "learning_rate": 4.971914893617022e-06,
      "loss": 0.0596,
      "step": 7217
    },
    {
      "epoch": 1.6585477941176472,
      "grad_norm": 1.636101484298706,
      "learning_rate": 4.971063829787235e-06,
      "loss": 0.0965,
      "step": 7218
    },
    {
      "epoch": 1.6587775735294117,
      "grad_norm": 0.9515252709388733,
      "learning_rate": 4.970212765957447e-06,
      "loss": 0.0686,
      "step": 7219
    },
    {
      "epoch": 1.6590073529411766,
      "grad_norm": 1.3064051866531372,
      "learning_rate": 4.96936170212766e-06,
      "loss": 0.0754,
      "step": 7220
    },
    {
      "epoch": 1.6592371323529411,
      "grad_norm": 1.3036205768585205,
      "learning_rate": 4.9685106382978725e-06,
      "loss": 0.0661,
      "step": 7221
    },
    {
      "epoch": 1.6594669117647058,
      "grad_norm": 1.1068570613861084,
      "learning_rate": 4.967659574468086e-06,
      "loss": 0.0807,
      "step": 7222
    },
    {
      "epoch": 1.6596966911764706,
      "grad_norm": 1.515031099319458,
      "learning_rate": 4.966808510638299e-06,
      "loss": 0.0862,
      "step": 7223
    },
    {
      "epoch": 1.6599264705882353,
      "grad_norm": 1.2124048471450806,
      "learning_rate": 4.965957446808511e-06,
      "loss": 0.0625,
      "step": 7224
    },
    {
      "epoch": 1.66015625,
      "grad_norm": 1.0354444980621338,
      "learning_rate": 4.9651063829787235e-06,
      "loss": 0.0662,
      "step": 7225
    },
    {
      "epoch": 1.6603860294117647,
      "grad_norm": 1.132932186126709,
      "learning_rate": 4.964255319148937e-06,
      "loss": 0.0663,
      "step": 7226
    },
    {
      "epoch": 1.6606158088235294,
      "grad_norm": 1.0819647312164307,
      "learning_rate": 4.963404255319149e-06,
      "loss": 0.0644,
      "step": 7227
    },
    {
      "epoch": 1.6608455882352942,
      "grad_norm": 1.4832967519760132,
      "learning_rate": 4.962553191489362e-06,
      "loss": 0.1058,
      "step": 7228
    },
    {
      "epoch": 1.6610753676470589,
      "grad_norm": 1.244033694267273,
      "learning_rate": 4.961702127659575e-06,
      "loss": 0.101,
      "step": 7229
    },
    {
      "epoch": 1.6613051470588234,
      "grad_norm": 1.6988866329193115,
      "learning_rate": 4.960851063829788e-06,
      "loss": 0.1137,
      "step": 7230
    },
    {
      "epoch": 1.6615349264705883,
      "grad_norm": 0.9881184101104736,
      "learning_rate": 4.960000000000001e-06,
      "loss": 0.0634,
      "step": 7231
    },
    {
      "epoch": 1.6617647058823528,
      "grad_norm": 1.6387391090393066,
      "learning_rate": 4.959148936170213e-06,
      "loss": 0.098,
      "step": 7232
    },
    {
      "epoch": 1.6619944852941178,
      "grad_norm": 1.5850741863250732,
      "learning_rate": 4.9582978723404254e-06,
      "loss": 0.0838,
      "step": 7233
    },
    {
      "epoch": 1.6622242647058822,
      "grad_norm": 1.0222477912902832,
      "learning_rate": 4.957446808510639e-06,
      "loss": 0.059,
      "step": 7234
    },
    {
      "epoch": 1.6624540441176472,
      "grad_norm": 1.6815245151519775,
      "learning_rate": 4.956595744680852e-06,
      "loss": 0.0839,
      "step": 7235
    },
    {
      "epoch": 1.6626838235294117,
      "grad_norm": 1.6204661130905151,
      "learning_rate": 4.955744680851064e-06,
      "loss": 0.0993,
      "step": 7236
    },
    {
      "epoch": 1.6629136029411766,
      "grad_norm": 1.3771873712539673,
      "learning_rate": 4.954893617021277e-06,
      "loss": 0.0794,
      "step": 7237
    },
    {
      "epoch": 1.6631433823529411,
      "grad_norm": 1.0340662002563477,
      "learning_rate": 4.95404255319149e-06,
      "loss": 0.0721,
      "step": 7238
    },
    {
      "epoch": 1.6633731617647058,
      "grad_norm": 1.0710517168045044,
      "learning_rate": 4.953191489361703e-06,
      "loss": 0.0666,
      "step": 7239
    },
    {
      "epoch": 1.6636029411764706,
      "grad_norm": 1.364937424659729,
      "learning_rate": 4.952340425531915e-06,
      "loss": 0.0843,
      "step": 7240
    },
    {
      "epoch": 1.6638327205882353,
      "grad_norm": 1.636623501777649,
      "learning_rate": 4.951489361702128e-06,
      "loss": 0.0797,
      "step": 7241
    },
    {
      "epoch": 1.6640625,
      "grad_norm": 1.117475152015686,
      "learning_rate": 4.9506382978723414e-06,
      "loss": 0.0618,
      "step": 7242
    },
    {
      "epoch": 1.6642922794117647,
      "grad_norm": 1.037785530090332,
      "learning_rate": 4.949787234042554e-06,
      "loss": 0.1024,
      "step": 7243
    },
    {
      "epoch": 1.6645220588235294,
      "grad_norm": 1.0685186386108398,
      "learning_rate": 4.948936170212766e-06,
      "loss": 0.0775,
      "step": 7244
    },
    {
      "epoch": 1.6647518382352942,
      "grad_norm": 0.986260712146759,
      "learning_rate": 4.948085106382979e-06,
      "loss": 0.0759,
      "step": 7245
    },
    {
      "epoch": 1.6649816176470589,
      "grad_norm": 0.7411748170852661,
      "learning_rate": 4.9472340425531916e-06,
      "loss": 0.0461,
      "step": 7246
    },
    {
      "epoch": 1.6652113970588234,
      "grad_norm": 1.5789614915847778,
      "learning_rate": 4.946382978723405e-06,
      "loss": 0.132,
      "step": 7247
    },
    {
      "epoch": 1.6654411764705883,
      "grad_norm": 1.068722128868103,
      "learning_rate": 4.945531914893618e-06,
      "loss": 0.0563,
      "step": 7248
    },
    {
      "epoch": 1.6656709558823528,
      "grad_norm": 1.4913588762283325,
      "learning_rate": 4.94468085106383e-06,
      "loss": 0.1079,
      "step": 7249
    },
    {
      "epoch": 1.6659007352941178,
      "grad_norm": 0.9635703563690186,
      "learning_rate": 4.9438297872340426e-06,
      "loss": 0.0539,
      "step": 7250
    },
    {
      "epoch": 1.6661305147058822,
      "grad_norm": 1.211294412612915,
      "learning_rate": 4.942978723404256e-06,
      "loss": 0.08,
      "step": 7251
    },
    {
      "epoch": 1.6663602941176472,
      "grad_norm": 1.0687061548233032,
      "learning_rate": 4.942127659574468e-06,
      "loss": 0.0855,
      "step": 7252
    },
    {
      "epoch": 1.6665900735294117,
      "grad_norm": 0.7495002746582031,
      "learning_rate": 4.941276595744681e-06,
      "loss": 0.0382,
      "step": 7253
    },
    {
      "epoch": 1.6668198529411766,
      "grad_norm": 1.5987714529037476,
      "learning_rate": 4.940425531914894e-06,
      "loss": 0.074,
      "step": 7254
    },
    {
      "epoch": 1.6670496323529411,
      "grad_norm": 1.077944040298462,
      "learning_rate": 4.939574468085107e-06,
      "loss": 0.0644,
      "step": 7255
    },
    {
      "epoch": 1.6672794117647058,
      "grad_norm": 1.2280213832855225,
      "learning_rate": 4.93872340425532e-06,
      "loss": 0.0623,
      "step": 7256
    },
    {
      "epoch": 1.6675091911764706,
      "grad_norm": 1.2170339822769165,
      "learning_rate": 4.937872340425532e-06,
      "loss": 0.074,
      "step": 7257
    },
    {
      "epoch": 1.6677389705882353,
      "grad_norm": 1.1508346796035767,
      "learning_rate": 4.9370212765957445e-06,
      "loss": 0.0764,
      "step": 7258
    },
    {
      "epoch": 1.66796875,
      "grad_norm": 1.1184606552124023,
      "learning_rate": 4.936170212765958e-06,
      "loss": 0.0652,
      "step": 7259
    },
    {
      "epoch": 1.6681985294117647,
      "grad_norm": 1.3528345823287964,
      "learning_rate": 4.935319148936171e-06,
      "loss": 0.0801,
      "step": 7260
    },
    {
      "epoch": 1.6684283088235294,
      "grad_norm": 0.9078806042671204,
      "learning_rate": 4.934468085106384e-06,
      "loss": 0.0801,
      "step": 7261
    },
    {
      "epoch": 1.6686580882352942,
      "grad_norm": 0.9624688029289246,
      "learning_rate": 4.933617021276596e-06,
      "loss": 0.0667,
      "step": 7262
    },
    {
      "epoch": 1.6688878676470589,
      "grad_norm": 1.1147611141204834,
      "learning_rate": 4.932765957446809e-06,
      "loss": 0.0997,
      "step": 7263
    },
    {
      "epoch": 1.6691176470588234,
      "grad_norm": 1.5110878944396973,
      "learning_rate": 4.931914893617022e-06,
      "loss": 0.0792,
      "step": 7264
    },
    {
      "epoch": 1.6693474264705883,
      "grad_norm": 1.1458383798599243,
      "learning_rate": 4.931063829787234e-06,
      "loss": 0.0761,
      "step": 7265
    },
    {
      "epoch": 1.6695772058823528,
      "grad_norm": 1.5427182912826538,
      "learning_rate": 4.930212765957447e-06,
      "loss": 0.0814,
      "step": 7266
    },
    {
      "epoch": 1.6698069852941178,
      "grad_norm": 0.9837896823883057,
      "learning_rate": 4.9293617021276605e-06,
      "loss": 0.0523,
      "step": 7267
    },
    {
      "epoch": 1.6700367647058822,
      "grad_norm": 1.1880311965942383,
      "learning_rate": 4.928510638297873e-06,
      "loss": 0.0855,
      "step": 7268
    },
    {
      "epoch": 1.6702665441176472,
      "grad_norm": 1.1419979333877563,
      "learning_rate": 4.927659574468085e-06,
      "loss": 0.0782,
      "step": 7269
    },
    {
      "epoch": 1.6704963235294117,
      "grad_norm": 1.0443940162658691,
      "learning_rate": 4.926808510638298e-06,
      "loss": 0.0695,
      "step": 7270
    },
    {
      "epoch": 1.6707261029411766,
      "grad_norm": 0.921652615070343,
      "learning_rate": 4.925957446808511e-06,
      "loss": 0.0614,
      "step": 7271
    },
    {
      "epoch": 1.6709558823529411,
      "grad_norm": 1.4085341691970825,
      "learning_rate": 4.925106382978724e-06,
      "loss": 0.0835,
      "step": 7272
    },
    {
      "epoch": 1.6711856617647058,
      "grad_norm": 1.195460319519043,
      "learning_rate": 4.924255319148937e-06,
      "loss": 0.0847,
      "step": 7273
    },
    {
      "epoch": 1.6714154411764706,
      "grad_norm": 0.9272955656051636,
      "learning_rate": 4.923404255319149e-06,
      "loss": 0.0393,
      "step": 7274
    },
    {
      "epoch": 1.6716452205882353,
      "grad_norm": 1.69550359249115,
      "learning_rate": 4.922553191489362e-06,
      "loss": 0.1232,
      "step": 7275
    },
    {
      "epoch": 1.671875,
      "grad_norm": 1.2952616214752197,
      "learning_rate": 4.921702127659575e-06,
      "loss": 0.0887,
      "step": 7276
    },
    {
      "epoch": 1.6721047794117647,
      "grad_norm": 1.5811481475830078,
      "learning_rate": 4.920851063829787e-06,
      "loss": 0.0698,
      "step": 7277
    },
    {
      "epoch": 1.6723345588235294,
      "grad_norm": 1.6022627353668213,
      "learning_rate": 4.92e-06,
      "loss": 0.0881,
      "step": 7278
    },
    {
      "epoch": 1.6725643382352942,
      "grad_norm": 1.2796066999435425,
      "learning_rate": 4.9191489361702135e-06,
      "loss": 0.0653,
      "step": 7279
    },
    {
      "epoch": 1.6727941176470589,
      "grad_norm": 1.0523372888565063,
      "learning_rate": 4.918297872340426e-06,
      "loss": 0.0622,
      "step": 7280
    },
    {
      "epoch": 1.6730238970588234,
      "grad_norm": 1.2811096906661987,
      "learning_rate": 4.917446808510639e-06,
      "loss": 0.0835,
      "step": 7281
    },
    {
      "epoch": 1.6732536764705883,
      "grad_norm": 1.4120973348617554,
      "learning_rate": 4.916595744680851e-06,
      "loss": 0.0918,
      "step": 7282
    },
    {
      "epoch": 1.6734834558823528,
      "grad_norm": 1.2797771692276,
      "learning_rate": 4.9157446808510645e-06,
      "loss": 0.0507,
      "step": 7283
    },
    {
      "epoch": 1.6737132352941178,
      "grad_norm": 1.5168907642364502,
      "learning_rate": 4.914893617021277e-06,
      "loss": 0.1123,
      "step": 7284
    },
    {
      "epoch": 1.6739430147058822,
      "grad_norm": 1.665998935699463,
      "learning_rate": 4.91404255319149e-06,
      "loss": 0.0874,
      "step": 7285
    },
    {
      "epoch": 1.6741727941176472,
      "grad_norm": 1.5817067623138428,
      "learning_rate": 4.913191489361703e-06,
      "loss": 0.0631,
      "step": 7286
    },
    {
      "epoch": 1.6744025735294117,
      "grad_norm": 1.0284818410873413,
      "learning_rate": 4.9123404255319155e-06,
      "loss": 0.0673,
      "step": 7287
    },
    {
      "epoch": 1.6746323529411766,
      "grad_norm": 1.507077693939209,
      "learning_rate": 4.911489361702128e-06,
      "loss": 0.1127,
      "step": 7288
    },
    {
      "epoch": 1.6748621323529411,
      "grad_norm": 1.3650470972061157,
      "learning_rate": 4.910638297872341e-06,
      "loss": 0.1117,
      "step": 7289
    },
    {
      "epoch": 1.6750919117647058,
      "grad_norm": 1.1820958852767944,
      "learning_rate": 4.909787234042553e-06,
      "loss": 0.0755,
      "step": 7290
    },
    {
      "epoch": 1.6753216911764706,
      "grad_norm": 1.4650379419326782,
      "learning_rate": 4.9089361702127665e-06,
      "loss": 0.0719,
      "step": 7291
    },
    {
      "epoch": 1.6755514705882353,
      "grad_norm": 1.0196038484573364,
      "learning_rate": 4.90808510638298e-06,
      "loss": 0.0751,
      "step": 7292
    },
    {
      "epoch": 1.67578125,
      "grad_norm": 1.572500228881836,
      "learning_rate": 4.907234042553192e-06,
      "loss": 0.0905,
      "step": 7293
    },
    {
      "epoch": 1.6760110294117647,
      "grad_norm": 1.3261098861694336,
      "learning_rate": 4.906382978723404e-06,
      "loss": 0.0855,
      "step": 7294
    },
    {
      "epoch": 1.6762408088235294,
      "grad_norm": 1.2479740381240845,
      "learning_rate": 4.9055319148936175e-06,
      "loss": 0.0886,
      "step": 7295
    },
    {
      "epoch": 1.6764705882352942,
      "grad_norm": 2.6658921241760254,
      "learning_rate": 4.90468085106383e-06,
      "loss": 0.0639,
      "step": 7296
    },
    {
      "epoch": 1.6767003676470589,
      "grad_norm": 1.0445748567581177,
      "learning_rate": 4.903829787234043e-06,
      "loss": 0.0696,
      "step": 7297
    },
    {
      "epoch": 1.6769301470588234,
      "grad_norm": 1.172333836555481,
      "learning_rate": 4.902978723404256e-06,
      "loss": 0.0692,
      "step": 7298
    },
    {
      "epoch": 1.6771599264705883,
      "grad_norm": 1.151750922203064,
      "learning_rate": 4.9021276595744684e-06,
      "loss": 0.0708,
      "step": 7299
    },
    {
      "epoch": 1.6773897058823528,
      "grad_norm": 1.2851568460464478,
      "learning_rate": 4.901276595744681e-06,
      "loss": 0.1012,
      "step": 7300
    },
    {
      "epoch": 1.6776194852941178,
      "grad_norm": 1.3302867412567139,
      "learning_rate": 4.900425531914894e-06,
      "loss": 0.0711,
      "step": 7301
    },
    {
      "epoch": 1.6778492647058822,
      "grad_norm": 1.063942313194275,
      "learning_rate": 4.899574468085107e-06,
      "loss": 0.0751,
      "step": 7302
    },
    {
      "epoch": 1.6780790441176472,
      "grad_norm": 0.9484830498695374,
      "learning_rate": 4.8987234042553194e-06,
      "loss": 0.0647,
      "step": 7303
    },
    {
      "epoch": 1.6783088235294117,
      "grad_norm": 1.2418956756591797,
      "learning_rate": 4.897872340425533e-06,
      "loss": 0.0908,
      "step": 7304
    },
    {
      "epoch": 1.6785386029411766,
      "grad_norm": 1.8934746980667114,
      "learning_rate": 4.897021276595745e-06,
      "loss": 0.1106,
      "step": 7305
    },
    {
      "epoch": 1.6787683823529411,
      "grad_norm": 1.0555996894836426,
      "learning_rate": 4.896170212765958e-06,
      "loss": 0.0592,
      "step": 7306
    },
    {
      "epoch": 1.6789981617647058,
      "grad_norm": 1.271501898765564,
      "learning_rate": 4.89531914893617e-06,
      "loss": 0.0919,
      "step": 7307
    },
    {
      "epoch": 1.6792279411764706,
      "grad_norm": 0.9269039034843445,
      "learning_rate": 4.894468085106384e-06,
      "loss": 0.0516,
      "step": 7308
    },
    {
      "epoch": 1.6794577205882353,
      "grad_norm": 1.0671402215957642,
      "learning_rate": 4.893617021276596e-06,
      "loss": 0.0688,
      "step": 7309
    },
    {
      "epoch": 1.6796875,
      "grad_norm": 0.9906179308891296,
      "learning_rate": 4.892765957446809e-06,
      "loss": 0.0887,
      "step": 7310
    },
    {
      "epoch": 1.6799172794117647,
      "grad_norm": 1.2595508098602295,
      "learning_rate": 4.891914893617022e-06,
      "loss": 0.0735,
      "step": 7311
    },
    {
      "epoch": 1.6801470588235294,
      "grad_norm": 1.3614869117736816,
      "learning_rate": 4.8910638297872346e-06,
      "loss": 0.0874,
      "step": 7312
    },
    {
      "epoch": 1.6803768382352942,
      "grad_norm": 1.1161243915557861,
      "learning_rate": 4.890212765957447e-06,
      "loss": 0.0604,
      "step": 7313
    },
    {
      "epoch": 1.6806066176470589,
      "grad_norm": 1.0652610063552856,
      "learning_rate": 4.88936170212766e-06,
      "loss": 0.0537,
      "step": 7314
    },
    {
      "epoch": 1.6808363970588234,
      "grad_norm": 1.2007033824920654,
      "learning_rate": 4.888510638297872e-06,
      "loss": 0.0682,
      "step": 7315
    },
    {
      "epoch": 1.6810661764705883,
      "grad_norm": 0.9763084053993225,
      "learning_rate": 4.8876595744680856e-06,
      "loss": 0.0644,
      "step": 7316
    },
    {
      "epoch": 1.6812959558823528,
      "grad_norm": 1.4425957202911377,
      "learning_rate": 4.886808510638299e-06,
      "loss": 0.1009,
      "step": 7317
    },
    {
      "epoch": 1.6815257352941178,
      "grad_norm": 1.0439691543579102,
      "learning_rate": 4.885957446808511e-06,
      "loss": 0.0502,
      "step": 7318
    },
    {
      "epoch": 1.6817555147058822,
      "grad_norm": 1.288280963897705,
      "learning_rate": 4.885106382978723e-06,
      "loss": 0.074,
      "step": 7319
    },
    {
      "epoch": 1.6819852941176472,
      "grad_norm": 1.096663475036621,
      "learning_rate": 4.8842553191489366e-06,
      "loss": 0.1082,
      "step": 7320
    },
    {
      "epoch": 1.6822150735294117,
      "grad_norm": 1.0817924737930298,
      "learning_rate": 4.883404255319149e-06,
      "loss": 0.0714,
      "step": 7321
    },
    {
      "epoch": 1.6824448529411766,
      "grad_norm": 1.6665558815002441,
      "learning_rate": 4.882553191489362e-06,
      "loss": 0.0725,
      "step": 7322
    },
    {
      "epoch": 1.6826746323529411,
      "grad_norm": 1.448738694190979,
      "learning_rate": 4.881702127659575e-06,
      "loss": 0.1001,
      "step": 7323
    },
    {
      "epoch": 1.6829044117647058,
      "grad_norm": 1.1631523370742798,
      "learning_rate": 4.8808510638297875e-06,
      "loss": 0.0572,
      "step": 7324
    },
    {
      "epoch": 1.6831341911764706,
      "grad_norm": 1.45035719871521,
      "learning_rate": 4.880000000000001e-06,
      "loss": 0.0907,
      "step": 7325
    },
    {
      "epoch": 1.6833639705882353,
      "grad_norm": 1.3060343265533447,
      "learning_rate": 4.879148936170213e-06,
      "loss": 0.0642,
      "step": 7326
    },
    {
      "epoch": 1.68359375,
      "grad_norm": 0.921509861946106,
      "learning_rate": 4.878297872340426e-06,
      "loss": 0.0817,
      "step": 7327
    },
    {
      "epoch": 1.6838235294117647,
      "grad_norm": 1.4261698722839355,
      "learning_rate": 4.8774468085106385e-06,
      "loss": 0.0838,
      "step": 7328
    },
    {
      "epoch": 1.6840533088235294,
      "grad_norm": 1.2754260301589966,
      "learning_rate": 4.876595744680852e-06,
      "loss": 0.1032,
      "step": 7329
    },
    {
      "epoch": 1.6842830882352942,
      "grad_norm": 0.8406969308853149,
      "learning_rate": 4.875744680851065e-06,
      "loss": 0.0825,
      "step": 7330
    },
    {
      "epoch": 1.6845128676470589,
      "grad_norm": 0.9654833078384399,
      "learning_rate": 4.874893617021277e-06,
      "loss": 0.0487,
      "step": 7331
    },
    {
      "epoch": 1.6847426470588234,
      "grad_norm": 0.9456846714019775,
      "learning_rate": 4.8740425531914895e-06,
      "loss": 0.0526,
      "step": 7332
    },
    {
      "epoch": 1.6849724264705883,
      "grad_norm": 1.2870943546295166,
      "learning_rate": 4.873191489361703e-06,
      "loss": 0.0621,
      "step": 7333
    },
    {
      "epoch": 1.6852022058823528,
      "grad_norm": 0.8383269906044006,
      "learning_rate": 4.872340425531915e-06,
      "loss": 0.0456,
      "step": 7334
    },
    {
      "epoch": 1.6854319852941178,
      "grad_norm": 1.2255353927612305,
      "learning_rate": 4.871489361702128e-06,
      "loss": 0.1067,
      "step": 7335
    },
    {
      "epoch": 1.6856617647058822,
      "grad_norm": 1.6043981313705444,
      "learning_rate": 4.870638297872341e-06,
      "loss": 0.0873,
      "step": 7336
    },
    {
      "epoch": 1.6858915441176472,
      "grad_norm": 1.7748135328292847,
      "learning_rate": 4.869787234042554e-06,
      "loss": 0.1007,
      "step": 7337
    },
    {
      "epoch": 1.6861213235294117,
      "grad_norm": 1.3589893579483032,
      "learning_rate": 4.868936170212766e-06,
      "loss": 0.0888,
      "step": 7338
    },
    {
      "epoch": 1.6863511029411766,
      "grad_norm": 1.8379778861999512,
      "learning_rate": 4.868085106382979e-06,
      "loss": 0.1044,
      "step": 7339
    },
    {
      "epoch": 1.6865808823529411,
      "grad_norm": 1.4319376945495605,
      "learning_rate": 4.8672340425531915e-06,
      "loss": 0.095,
      "step": 7340
    },
    {
      "epoch": 1.6868106617647058,
      "grad_norm": 0.9420042037963867,
      "learning_rate": 4.866382978723405e-06,
      "loss": 0.0574,
      "step": 7341
    },
    {
      "epoch": 1.6870404411764706,
      "grad_norm": 1.159361720085144,
      "learning_rate": 4.865531914893618e-06,
      "loss": 0.0705,
      "step": 7342
    },
    {
      "epoch": 1.6872702205882353,
      "grad_norm": 1.277470350265503,
      "learning_rate": 4.86468085106383e-06,
      "loss": 0.0703,
      "step": 7343
    },
    {
      "epoch": 1.6875,
      "grad_norm": 0.9802429676055908,
      "learning_rate": 4.8638297872340425e-06,
      "loss": 0.0457,
      "step": 7344
    },
    {
      "epoch": 1.6877297794117647,
      "grad_norm": 1.1660919189453125,
      "learning_rate": 4.862978723404256e-06,
      "loss": 0.081,
      "step": 7345
    },
    {
      "epoch": 1.6879595588235294,
      "grad_norm": 1.4652913808822632,
      "learning_rate": 4.862127659574469e-06,
      "loss": 0.112,
      "step": 7346
    },
    {
      "epoch": 1.6881893382352942,
      "grad_norm": 0.979973554611206,
      "learning_rate": 4.861276595744681e-06,
      "loss": 0.0722,
      "step": 7347
    },
    {
      "epoch": 1.6884191176470589,
      "grad_norm": 1.1380401849746704,
      "learning_rate": 4.860425531914894e-06,
      "loss": 0.0955,
      "step": 7348
    },
    {
      "epoch": 1.6886488970588234,
      "grad_norm": 1.0694897174835205,
      "learning_rate": 4.859574468085107e-06,
      "loss": 0.0658,
      "step": 7349
    },
    {
      "epoch": 1.6888786764705883,
      "grad_norm": 1.6213138103485107,
      "learning_rate": 4.85872340425532e-06,
      "loss": 0.0882,
      "step": 7350
    },
    {
      "epoch": 1.6891084558823528,
      "grad_norm": 1.3797545433044434,
      "learning_rate": 4.857872340425532e-06,
      "loss": 0.0789,
      "step": 7351
    },
    {
      "epoch": 1.6893382352941178,
      "grad_norm": 1.7765107154846191,
      "learning_rate": 4.857021276595745e-06,
      "loss": 0.1039,
      "step": 7352
    },
    {
      "epoch": 1.6895680147058822,
      "grad_norm": 0.907416820526123,
      "learning_rate": 4.856170212765958e-06,
      "loss": 0.0617,
      "step": 7353
    },
    {
      "epoch": 1.6897977941176472,
      "grad_norm": 1.4121257066726685,
      "learning_rate": 4.855319148936171e-06,
      "loss": 0.0682,
      "step": 7354
    },
    {
      "epoch": 1.6900275735294117,
      "grad_norm": 1.2212929725646973,
      "learning_rate": 4.854468085106384e-06,
      "loss": 0.0817,
      "step": 7355
    },
    {
      "epoch": 1.6902573529411766,
      "grad_norm": 1.007517695426941,
      "learning_rate": 4.853617021276596e-06,
      "loss": 0.0661,
      "step": 7356
    },
    {
      "epoch": 1.6904871323529411,
      "grad_norm": 1.0631455183029175,
      "learning_rate": 4.852765957446809e-06,
      "loss": 0.0612,
      "step": 7357
    },
    {
      "epoch": 1.6907169117647058,
      "grad_norm": 1.4287054538726807,
      "learning_rate": 4.851914893617022e-06,
      "loss": 0.0528,
      "step": 7358
    },
    {
      "epoch": 1.6909466911764706,
      "grad_norm": 1.2970858812332153,
      "learning_rate": 4.851063829787234e-06,
      "loss": 0.069,
      "step": 7359
    },
    {
      "epoch": 1.6911764705882353,
      "grad_norm": 0.9342213869094849,
      "learning_rate": 4.850212765957447e-06,
      "loss": 0.0575,
      "step": 7360
    },
    {
      "epoch": 1.69140625,
      "grad_norm": 0.9138851165771484,
      "learning_rate": 4.8493617021276605e-06,
      "loss": 0.0586,
      "step": 7361
    },
    {
      "epoch": 1.6916360294117647,
      "grad_norm": 0.9993481040000916,
      "learning_rate": 4.848510638297873e-06,
      "loss": 0.0708,
      "step": 7362
    },
    {
      "epoch": 1.6918658088235294,
      "grad_norm": 1.1393853425979614,
      "learning_rate": 4.847659574468085e-06,
      "loss": 0.0765,
      "step": 7363
    },
    {
      "epoch": 1.6920955882352942,
      "grad_norm": 1.1881297826766968,
      "learning_rate": 4.846808510638298e-06,
      "loss": 0.0921,
      "step": 7364
    },
    {
      "epoch": 1.6923253676470589,
      "grad_norm": 1.6390472650527954,
      "learning_rate": 4.845957446808511e-06,
      "loss": 0.1139,
      "step": 7365
    },
    {
      "epoch": 1.6925551470588234,
      "grad_norm": 1.2371091842651367,
      "learning_rate": 4.845106382978724e-06,
      "loss": 0.0581,
      "step": 7366
    },
    {
      "epoch": 1.6927849264705883,
      "grad_norm": 0.9996775984764099,
      "learning_rate": 4.844255319148937e-06,
      "loss": 0.0736,
      "step": 7367
    },
    {
      "epoch": 1.6930147058823528,
      "grad_norm": 1.400712490081787,
      "learning_rate": 4.843404255319149e-06,
      "loss": 0.0856,
      "step": 7368
    },
    {
      "epoch": 1.6932444852941178,
      "grad_norm": 1.6099926233291626,
      "learning_rate": 4.842553191489362e-06,
      "loss": 0.1243,
      "step": 7369
    },
    {
      "epoch": 1.6934742647058822,
      "grad_norm": 1.2027488946914673,
      "learning_rate": 4.841702127659575e-06,
      "loss": 0.0647,
      "step": 7370
    },
    {
      "epoch": 1.6937040441176472,
      "grad_norm": 0.9889740943908691,
      "learning_rate": 4.840851063829788e-06,
      "loss": 0.0471,
      "step": 7371
    },
    {
      "epoch": 1.6939338235294117,
      "grad_norm": 1.0983456373214722,
      "learning_rate": 4.84e-06,
      "loss": 0.0839,
      "step": 7372
    },
    {
      "epoch": 1.6941636029411766,
      "grad_norm": 1.1426019668579102,
      "learning_rate": 4.839148936170213e-06,
      "loss": 0.0566,
      "step": 7373
    },
    {
      "epoch": 1.6943933823529411,
      "grad_norm": 1.0642848014831543,
      "learning_rate": 4.838297872340426e-06,
      "loss": 0.0754,
      "step": 7374
    },
    {
      "epoch": 1.6946231617647058,
      "grad_norm": 1.2053488492965698,
      "learning_rate": 4.837446808510639e-06,
      "loss": 0.0637,
      "step": 7375
    },
    {
      "epoch": 1.6948529411764706,
      "grad_norm": 1.1042392253875732,
      "learning_rate": 4.836595744680851e-06,
      "loss": 0.0429,
      "step": 7376
    },
    {
      "epoch": 1.6950827205882353,
      "grad_norm": 0.9227433204650879,
      "learning_rate": 4.835744680851064e-06,
      "loss": 0.0718,
      "step": 7377
    },
    {
      "epoch": 1.6953125,
      "grad_norm": 1.9991830587387085,
      "learning_rate": 4.834893617021277e-06,
      "loss": 0.0841,
      "step": 7378
    },
    {
      "epoch": 1.6955422794117647,
      "grad_norm": 1.3344650268554688,
      "learning_rate": 4.83404255319149e-06,
      "loss": 0.0808,
      "step": 7379
    },
    {
      "epoch": 1.6957720588235294,
      "grad_norm": 0.8694419860839844,
      "learning_rate": 4.833191489361703e-06,
      "loss": 0.0484,
      "step": 7380
    },
    {
      "epoch": 1.6960018382352942,
      "grad_norm": 1.0198825597763062,
      "learning_rate": 4.832340425531915e-06,
      "loss": 0.0723,
      "step": 7381
    },
    {
      "epoch": 1.6962316176470589,
      "grad_norm": 0.9956981539726257,
      "learning_rate": 4.831489361702128e-06,
      "loss": 0.0358,
      "step": 7382
    },
    {
      "epoch": 1.6964613970588234,
      "grad_norm": 1.3071657419204712,
      "learning_rate": 4.830638297872341e-06,
      "loss": 0.0712,
      "step": 7383
    },
    {
      "epoch": 1.6966911764705883,
      "grad_norm": 1.9625853300094604,
      "learning_rate": 4.829787234042553e-06,
      "loss": 0.1751,
      "step": 7384
    },
    {
      "epoch": 1.6969209558823528,
      "grad_norm": 0.9755094051361084,
      "learning_rate": 4.828936170212766e-06,
      "loss": 0.0663,
      "step": 7385
    },
    {
      "epoch": 1.6971507352941178,
      "grad_norm": 1.4646602869033813,
      "learning_rate": 4.8280851063829796e-06,
      "loss": 0.0888,
      "step": 7386
    },
    {
      "epoch": 1.6973805147058822,
      "grad_norm": 1.2098244428634644,
      "learning_rate": 4.827234042553192e-06,
      "loss": 0.0688,
      "step": 7387
    },
    {
      "epoch": 1.6976102941176472,
      "grad_norm": 1.4863978624343872,
      "learning_rate": 4.826382978723404e-06,
      "loss": 0.0797,
      "step": 7388
    },
    {
      "epoch": 1.6978400735294117,
      "grad_norm": 1.6591788530349731,
      "learning_rate": 4.825531914893617e-06,
      "loss": 0.0851,
      "step": 7389
    },
    {
      "epoch": 1.6980698529411766,
      "grad_norm": 1.5088258981704712,
      "learning_rate": 4.8246808510638305e-06,
      "loss": 0.0889,
      "step": 7390
    },
    {
      "epoch": 1.6982996323529411,
      "grad_norm": 1.7280367612838745,
      "learning_rate": 4.823829787234043e-06,
      "loss": 0.0771,
      "step": 7391
    },
    {
      "epoch": 1.6985294117647058,
      "grad_norm": 1.1958622932434082,
      "learning_rate": 4.822978723404256e-06,
      "loss": 0.0793,
      "step": 7392
    },
    {
      "epoch": 1.6987591911764706,
      "grad_norm": 0.9429869055747986,
      "learning_rate": 4.822127659574468e-06,
      "loss": 0.0658,
      "step": 7393
    },
    {
      "epoch": 1.6989889705882353,
      "grad_norm": 0.9576539397239685,
      "learning_rate": 4.821276595744681e-06,
      "loss": 0.0691,
      "step": 7394
    },
    {
      "epoch": 1.69921875,
      "grad_norm": 1.4716606140136719,
      "learning_rate": 4.820425531914894e-06,
      "loss": 0.0824,
      "step": 7395
    },
    {
      "epoch": 1.6994485294117647,
      "grad_norm": 1.0915392637252808,
      "learning_rate": 4.819574468085107e-06,
      "loss": 0.096,
      "step": 7396
    },
    {
      "epoch": 1.6996783088235294,
      "grad_norm": 1.5496398210525513,
      "learning_rate": 4.818723404255319e-06,
      "loss": 0.0971,
      "step": 7397
    },
    {
      "epoch": 1.6999080882352942,
      "grad_norm": 1.14665949344635,
      "learning_rate": 4.8178723404255325e-06,
      "loss": 0.0932,
      "step": 7398
    },
    {
      "epoch": 1.7001378676470589,
      "grad_norm": 1.0197337865829468,
      "learning_rate": 4.817021276595745e-06,
      "loss": 0.0616,
      "step": 7399
    },
    {
      "epoch": 1.7003676470588234,
      "grad_norm": 1.449596881866455,
      "learning_rate": 4.816170212765958e-06,
      "loss": 0.0809,
      "step": 7400
    },
    {
      "epoch": 1.7005974264705883,
      "grad_norm": 0.8690694570541382,
      "learning_rate": 4.81531914893617e-06,
      "loss": 0.0657,
      "step": 7401
    },
    {
      "epoch": 1.7008272058823528,
      "grad_norm": 1.0971438884735107,
      "learning_rate": 4.8144680851063835e-06,
      "loss": 0.0629,
      "step": 7402
    },
    {
      "epoch": 1.7010569852941178,
      "grad_norm": 1.1462290287017822,
      "learning_rate": 4.813617021276596e-06,
      "loss": 0.0697,
      "step": 7403
    },
    {
      "epoch": 1.7012867647058822,
      "grad_norm": 1.612842082977295,
      "learning_rate": 4.812765957446809e-06,
      "loss": 0.0887,
      "step": 7404
    },
    {
      "epoch": 1.7015165441176472,
      "grad_norm": 1.3381577730178833,
      "learning_rate": 4.811914893617022e-06,
      "loss": 0.1195,
      "step": 7405
    },
    {
      "epoch": 1.7017463235294117,
      "grad_norm": 0.9910561442375183,
      "learning_rate": 4.8110638297872345e-06,
      "loss": 0.0752,
      "step": 7406
    },
    {
      "epoch": 1.7019761029411766,
      "grad_norm": 1.1122262477874756,
      "learning_rate": 4.810212765957447e-06,
      "loss": 0.0927,
      "step": 7407
    },
    {
      "epoch": 1.7022058823529411,
      "grad_norm": 1.630323052406311,
      "learning_rate": 4.80936170212766e-06,
      "loss": 0.1086,
      "step": 7408
    },
    {
      "epoch": 1.7024356617647058,
      "grad_norm": 1.431609869003296,
      "learning_rate": 4.808510638297872e-06,
      "loss": 0.0828,
      "step": 7409
    },
    {
      "epoch": 1.7026654411764706,
      "grad_norm": 1.0861828327178955,
      "learning_rate": 4.8076595744680855e-06,
      "loss": 0.0572,
      "step": 7410
    },
    {
      "epoch": 1.7028952205882353,
      "grad_norm": 1.4392222166061401,
      "learning_rate": 4.806808510638299e-06,
      "loss": 0.079,
      "step": 7411
    },
    {
      "epoch": 1.703125,
      "grad_norm": 0.8983474373817444,
      "learning_rate": 4.805957446808511e-06,
      "loss": 0.0603,
      "step": 7412
    },
    {
      "epoch": 1.7033547794117647,
      "grad_norm": 1.1299993991851807,
      "learning_rate": 4.805106382978723e-06,
      "loss": 0.066,
      "step": 7413
    },
    {
      "epoch": 1.7035845588235294,
      "grad_norm": 0.9113730192184448,
      "learning_rate": 4.8042553191489365e-06,
      "loss": 0.0614,
      "step": 7414
    },
    {
      "epoch": 1.7038143382352942,
      "grad_norm": 1.0445983409881592,
      "learning_rate": 4.80340425531915e-06,
      "loss": 0.0744,
      "step": 7415
    },
    {
      "epoch": 1.7040441176470589,
      "grad_norm": 1.0424493551254272,
      "learning_rate": 4.802553191489362e-06,
      "loss": 0.0555,
      "step": 7416
    },
    {
      "epoch": 1.7042738970588234,
      "grad_norm": 1.237987756729126,
      "learning_rate": 4.801702127659575e-06,
      "loss": 0.0762,
      "step": 7417
    },
    {
      "epoch": 1.7045036764705883,
      "grad_norm": 1.6641086339950562,
      "learning_rate": 4.8008510638297875e-06,
      "loss": 0.0988,
      "step": 7418
    },
    {
      "epoch": 1.7047334558823528,
      "grad_norm": 1.1395533084869385,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.0704,
      "step": 7419
    },
    {
      "epoch": 1.7049632352941178,
      "grad_norm": 0.9641576409339905,
      "learning_rate": 4.799148936170213e-06,
      "loss": 0.0681,
      "step": 7420
    },
    {
      "epoch": 1.7051930147058822,
      "grad_norm": 1.005346417427063,
      "learning_rate": 4.798297872340426e-06,
      "loss": 0.0503,
      "step": 7421
    },
    {
      "epoch": 1.7054227941176472,
      "grad_norm": 1.1019861698150635,
      "learning_rate": 4.7974468085106384e-06,
      "loss": 0.0678,
      "step": 7422
    },
    {
      "epoch": 1.7056525735294117,
      "grad_norm": 0.9334540367126465,
      "learning_rate": 4.796595744680852e-06,
      "loss": 0.0617,
      "step": 7423
    },
    {
      "epoch": 1.7058823529411766,
      "grad_norm": 0.91792893409729,
      "learning_rate": 4.795744680851065e-06,
      "loss": 0.0502,
      "step": 7424
    },
    {
      "epoch": 1.7061121323529411,
      "grad_norm": 1.3630398511886597,
      "learning_rate": 4.794893617021277e-06,
      "loss": 0.1054,
      "step": 7425
    },
    {
      "epoch": 1.7063419117647058,
      "grad_norm": 1.7123929262161255,
      "learning_rate": 4.7940425531914894e-06,
      "loss": 0.1232,
      "step": 7426
    },
    {
      "epoch": 1.7065716911764706,
      "grad_norm": 1.5430790185928345,
      "learning_rate": 4.793191489361703e-06,
      "loss": 0.0918,
      "step": 7427
    },
    {
      "epoch": 1.7068014705882353,
      "grad_norm": 1.0445256233215332,
      "learning_rate": 4.792340425531915e-06,
      "loss": 0.0515,
      "step": 7428
    },
    {
      "epoch": 1.70703125,
      "grad_norm": 1.5679752826690674,
      "learning_rate": 4.791489361702128e-06,
      "loss": 0.0969,
      "step": 7429
    },
    {
      "epoch": 1.7072610294117647,
      "grad_norm": 1.0401406288146973,
      "learning_rate": 4.790638297872341e-06,
      "loss": 0.0624,
      "step": 7430
    },
    {
      "epoch": 1.7074908088235294,
      "grad_norm": 1.1683961153030396,
      "learning_rate": 4.789787234042554e-06,
      "loss": 0.0804,
      "step": 7431
    },
    {
      "epoch": 1.7077205882352942,
      "grad_norm": 1.2247291803359985,
      "learning_rate": 4.788936170212766e-06,
      "loss": 0.0754,
      "step": 7432
    },
    {
      "epoch": 1.7079503676470589,
      "grad_norm": 1.5204236507415771,
      "learning_rate": 4.788085106382979e-06,
      "loss": 0.082,
      "step": 7433
    },
    {
      "epoch": 1.7081801470588234,
      "grad_norm": 1.3656055927276611,
      "learning_rate": 4.787234042553192e-06,
      "loss": 0.0949,
      "step": 7434
    },
    {
      "epoch": 1.7084099264705883,
      "grad_norm": 1.009909749031067,
      "learning_rate": 4.786382978723405e-06,
      "loss": 0.0663,
      "step": 7435
    },
    {
      "epoch": 1.7086397058823528,
      "grad_norm": 1.3342671394348145,
      "learning_rate": 4.785531914893618e-06,
      "loss": 0.082,
      "step": 7436
    },
    {
      "epoch": 1.7088694852941178,
      "grad_norm": 0.820338785648346,
      "learning_rate": 4.78468085106383e-06,
      "loss": 0.0419,
      "step": 7437
    },
    {
      "epoch": 1.7090992647058822,
      "grad_norm": 1.5350806713104248,
      "learning_rate": 4.783829787234042e-06,
      "loss": 0.1171,
      "step": 7438
    },
    {
      "epoch": 1.7093290441176472,
      "grad_norm": 1.1973518133163452,
      "learning_rate": 4.7829787234042556e-06,
      "loss": 0.0802,
      "step": 7439
    },
    {
      "epoch": 1.7095588235294117,
      "grad_norm": 1.3059344291687012,
      "learning_rate": 4.782127659574469e-06,
      "loss": 0.0969,
      "step": 7440
    },
    {
      "epoch": 1.7097886029411766,
      "grad_norm": 1.0917552709579468,
      "learning_rate": 4.781276595744681e-06,
      "loss": 0.0597,
      "step": 7441
    },
    {
      "epoch": 1.7100183823529411,
      "grad_norm": 1.1769856214523315,
      "learning_rate": 4.780425531914894e-06,
      "loss": 0.0694,
      "step": 7442
    },
    {
      "epoch": 1.7102481617647058,
      "grad_norm": 1.4838762283325195,
      "learning_rate": 4.7795744680851066e-06,
      "loss": 0.0996,
      "step": 7443
    },
    {
      "epoch": 1.7104779411764706,
      "grad_norm": 1.67340087890625,
      "learning_rate": 4.77872340425532e-06,
      "loss": 0.082,
      "step": 7444
    },
    {
      "epoch": 1.7107077205882353,
      "grad_norm": 1.1937865018844604,
      "learning_rate": 4.777872340425532e-06,
      "loss": 0.0607,
      "step": 7445
    },
    {
      "epoch": 1.7109375,
      "grad_norm": 1.2008087635040283,
      "learning_rate": 4.777021276595745e-06,
      "loss": 0.0869,
      "step": 7446
    },
    {
      "epoch": 1.7111672794117647,
      "grad_norm": 1.1284115314483643,
      "learning_rate": 4.7761702127659575e-06,
      "loss": 0.0714,
      "step": 7447
    },
    {
      "epoch": 1.7113970588235294,
      "grad_norm": 1.582709789276123,
      "learning_rate": 4.775319148936171e-06,
      "loss": 0.0774,
      "step": 7448
    },
    {
      "epoch": 1.7116268382352942,
      "grad_norm": 1.3559393882751465,
      "learning_rate": 4.774468085106384e-06,
      "loss": 0.0624,
      "step": 7449
    },
    {
      "epoch": 1.7118566176470589,
      "grad_norm": 0.9097499251365662,
      "learning_rate": 4.773617021276596e-06,
      "loss": 0.058,
      "step": 7450
    },
    {
      "epoch": 1.7120863970588234,
      "grad_norm": 1.3545165061950684,
      "learning_rate": 4.7727659574468085e-06,
      "loss": 0.1037,
      "step": 7451
    },
    {
      "epoch": 1.7123161764705883,
      "grad_norm": 1.1326724290847778,
      "learning_rate": 4.771914893617022e-06,
      "loss": 0.0834,
      "step": 7452
    },
    {
      "epoch": 1.7125459558823528,
      "grad_norm": 1.5512521266937256,
      "learning_rate": 4.771063829787235e-06,
      "loss": 0.0801,
      "step": 7453
    },
    {
      "epoch": 1.7127757352941178,
      "grad_norm": 0.9889331459999084,
      "learning_rate": 4.770212765957447e-06,
      "loss": 0.0691,
      "step": 7454
    },
    {
      "epoch": 1.7130055147058822,
      "grad_norm": 1.2402148246765137,
      "learning_rate": 4.76936170212766e-06,
      "loss": 0.0699,
      "step": 7455
    },
    {
      "epoch": 1.7132352941176472,
      "grad_norm": 1.6637299060821533,
      "learning_rate": 4.768510638297873e-06,
      "loss": 0.0764,
      "step": 7456
    },
    {
      "epoch": 1.7134650735294117,
      "grad_norm": 1.3825751543045044,
      "learning_rate": 4.767659574468085e-06,
      "loss": 0.0851,
      "step": 7457
    },
    {
      "epoch": 1.7136948529411766,
      "grad_norm": 1.2558413743972778,
      "learning_rate": 4.766808510638298e-06,
      "loss": 0.0921,
      "step": 7458
    },
    {
      "epoch": 1.7139246323529411,
      "grad_norm": 1.231550693511963,
      "learning_rate": 4.765957446808511e-06,
      "loss": 0.0871,
      "step": 7459
    },
    {
      "epoch": 1.7141544117647058,
      "grad_norm": 1.0581995248794556,
      "learning_rate": 4.765106382978724e-06,
      "loss": 0.0648,
      "step": 7460
    },
    {
      "epoch": 1.7143841911764706,
      "grad_norm": 1.206006407737732,
      "learning_rate": 4.764255319148937e-06,
      "loss": 0.0841,
      "step": 7461
    },
    {
      "epoch": 1.7146139705882353,
      "grad_norm": 1.5328718423843384,
      "learning_rate": 4.763404255319149e-06,
      "loss": 0.0864,
      "step": 7462
    },
    {
      "epoch": 1.71484375,
      "grad_norm": 1.5793615579605103,
      "learning_rate": 4.7625531914893615e-06,
      "loss": 0.0824,
      "step": 7463
    },
    {
      "epoch": 1.7150735294117647,
      "grad_norm": 1.2555866241455078,
      "learning_rate": 4.761702127659575e-06,
      "loss": 0.0766,
      "step": 7464
    },
    {
      "epoch": 1.7153033088235294,
      "grad_norm": 1.1191813945770264,
      "learning_rate": 4.760851063829788e-06,
      "loss": 0.0529,
      "step": 7465
    },
    {
      "epoch": 1.7155330882352942,
      "grad_norm": 1.3348114490509033,
      "learning_rate": 4.76e-06,
      "loss": 0.0827,
      "step": 7466
    },
    {
      "epoch": 1.7157628676470589,
      "grad_norm": 0.9651212692260742,
      "learning_rate": 4.759148936170213e-06,
      "loss": 0.0663,
      "step": 7467
    },
    {
      "epoch": 1.7159926470588234,
      "grad_norm": 2.0057132244110107,
      "learning_rate": 4.758297872340426e-06,
      "loss": 0.0958,
      "step": 7468
    },
    {
      "epoch": 1.7162224264705883,
      "grad_norm": 1.3104908466339111,
      "learning_rate": 4.757446808510639e-06,
      "loss": 0.0618,
      "step": 7469
    },
    {
      "epoch": 1.7164522058823528,
      "grad_norm": 1.2593804597854614,
      "learning_rate": 4.756595744680851e-06,
      "loss": 0.1022,
      "step": 7470
    },
    {
      "epoch": 1.7166819852941178,
      "grad_norm": 1.3112674951553345,
      "learning_rate": 4.755744680851064e-06,
      "loss": 0.0984,
      "step": 7471
    },
    {
      "epoch": 1.7169117647058822,
      "grad_norm": 0.985303521156311,
      "learning_rate": 4.754893617021277e-06,
      "loss": 0.0611,
      "step": 7472
    },
    {
      "epoch": 1.7171415441176472,
      "grad_norm": 1.2930294275283813,
      "learning_rate": 4.75404255319149e-06,
      "loss": 0.0705,
      "step": 7473
    },
    {
      "epoch": 1.7173713235294117,
      "grad_norm": 1.2361533641815186,
      "learning_rate": 4.753191489361703e-06,
      "loss": 0.0751,
      "step": 7474
    },
    {
      "epoch": 1.7176011029411766,
      "grad_norm": 1.2740874290466309,
      "learning_rate": 4.752340425531915e-06,
      "loss": 0.1076,
      "step": 7475
    },
    {
      "epoch": 1.7178308823529411,
      "grad_norm": 1.3838701248168945,
      "learning_rate": 4.751489361702128e-06,
      "loss": 0.0913,
      "step": 7476
    },
    {
      "epoch": 1.7180606617647058,
      "grad_norm": 1.0365740060806274,
      "learning_rate": 4.750638297872341e-06,
      "loss": 0.0629,
      "step": 7477
    },
    {
      "epoch": 1.7182904411764706,
      "grad_norm": 1.2344976663589478,
      "learning_rate": 4.749787234042554e-06,
      "loss": 0.0575,
      "step": 7478
    },
    {
      "epoch": 1.7185202205882353,
      "grad_norm": 1.2633414268493652,
      "learning_rate": 4.748936170212766e-06,
      "loss": 0.0759,
      "step": 7479
    },
    {
      "epoch": 1.71875,
      "grad_norm": 1.4177746772766113,
      "learning_rate": 4.7480851063829795e-06,
      "loss": 0.1042,
      "step": 7480
    },
    {
      "epoch": 1.7189797794117647,
      "grad_norm": 1.317482590675354,
      "learning_rate": 4.747234042553192e-06,
      "loss": 0.0924,
      "step": 7481
    },
    {
      "epoch": 1.7192095588235294,
      "grad_norm": 1.2596079111099243,
      "learning_rate": 4.746382978723404e-06,
      "loss": 0.0634,
      "step": 7482
    },
    {
      "epoch": 1.7194393382352942,
      "grad_norm": 1.3743494749069214,
      "learning_rate": 4.745531914893617e-06,
      "loss": 0.0934,
      "step": 7483
    },
    {
      "epoch": 1.7196691176470589,
      "grad_norm": 1.3088940382003784,
      "learning_rate": 4.7446808510638305e-06,
      "loss": 0.0762,
      "step": 7484
    },
    {
      "epoch": 1.7198988970588234,
      "grad_norm": 1.1936471462249756,
      "learning_rate": 4.743829787234043e-06,
      "loss": 0.0507,
      "step": 7485
    },
    {
      "epoch": 1.7201286764705883,
      "grad_norm": 1.0360493659973145,
      "learning_rate": 4.742978723404256e-06,
      "loss": 0.0695,
      "step": 7486
    },
    {
      "epoch": 1.7203584558823528,
      "grad_norm": 1.4919281005859375,
      "learning_rate": 4.742127659574468e-06,
      "loss": 0.1113,
      "step": 7487
    },
    {
      "epoch": 1.7205882352941178,
      "grad_norm": 1.037044882774353,
      "learning_rate": 4.741276595744681e-06,
      "loss": 0.0676,
      "step": 7488
    },
    {
      "epoch": 1.7208180147058822,
      "grad_norm": 0.9676260948181152,
      "learning_rate": 4.740425531914894e-06,
      "loss": 0.0561,
      "step": 7489
    },
    {
      "epoch": 1.7210477941176472,
      "grad_norm": 1.105515956878662,
      "learning_rate": 4.739574468085107e-06,
      "loss": 0.0698,
      "step": 7490
    },
    {
      "epoch": 1.7212775735294117,
      "grad_norm": 0.9612468481063843,
      "learning_rate": 4.738723404255319e-06,
      "loss": 0.0645,
      "step": 7491
    },
    {
      "epoch": 1.7215073529411766,
      "grad_norm": 1.3636387586593628,
      "learning_rate": 4.7378723404255324e-06,
      "loss": 0.098,
      "step": 7492
    },
    {
      "epoch": 1.7217371323529411,
      "grad_norm": 1.1349222660064697,
      "learning_rate": 4.737021276595745e-06,
      "loss": 0.0885,
      "step": 7493
    },
    {
      "epoch": 1.7219669117647058,
      "grad_norm": 0.9119304418563843,
      "learning_rate": 4.736170212765958e-06,
      "loss": 0.0711,
      "step": 7494
    },
    {
      "epoch": 1.7221966911764706,
      "grad_norm": 1.0792123079299927,
      "learning_rate": 4.73531914893617e-06,
      "loss": 0.0591,
      "step": 7495
    },
    {
      "epoch": 1.7224264705882353,
      "grad_norm": 1.1955790519714355,
      "learning_rate": 4.7344680851063834e-06,
      "loss": 0.0781,
      "step": 7496
    },
    {
      "epoch": 1.72265625,
      "grad_norm": 1.5660130977630615,
      "learning_rate": 4.733617021276597e-06,
      "loss": 0.08,
      "step": 7497
    },
    {
      "epoch": 1.7228860294117647,
      "grad_norm": 1.1762441396713257,
      "learning_rate": 4.732765957446809e-06,
      "loss": 0.0775,
      "step": 7498
    },
    {
      "epoch": 1.7231158088235294,
      "grad_norm": 1.610129714012146,
      "learning_rate": 4.731914893617022e-06,
      "loss": 0.1021,
      "step": 7499
    },
    {
      "epoch": 1.7233455882352942,
      "grad_norm": 1.2161602973937988,
      "learning_rate": 4.731063829787234e-06,
      "loss": 0.0792,
      "step": 7500
    },
    {
      "epoch": 1.7233455882352942,
      "eval_loss": 0.08013935387134552,
      "eval_runtime": 1965.4911,
      "eval_samples_per_second": 4.531,
      "eval_steps_per_second": 2.266,
      "step": 7500
    },
    {
      "epoch": 1.7235753676470589,
      "grad_norm": 1.0656081438064575,
      "learning_rate": 4.730212765957447e-06,
      "loss": 0.0643,
      "step": 7501
    },
    {
      "epoch": 1.7238051470588234,
      "grad_norm": 0.9899638295173645,
      "learning_rate": 4.72936170212766e-06,
      "loss": 0.1088,
      "step": 7502
    },
    {
      "epoch": 1.7240349264705883,
      "grad_norm": 1.095909595489502,
      "learning_rate": 4.728510638297873e-06,
      "loss": 0.0658,
      "step": 7503
    },
    {
      "epoch": 1.7242647058823528,
      "grad_norm": 0.9900797605514526,
      "learning_rate": 4.727659574468085e-06,
      "loss": 0.0455,
      "step": 7504
    },
    {
      "epoch": 1.7244944852941178,
      "grad_norm": 1.3230109214782715,
      "learning_rate": 4.7268085106382986e-06,
      "loss": 0.0508,
      "step": 7505
    },
    {
      "epoch": 1.7247242647058822,
      "grad_norm": 1.5014737844467163,
      "learning_rate": 4.725957446808511e-06,
      "loss": 0.0654,
      "step": 7506
    },
    {
      "epoch": 1.7249540441176472,
      "grad_norm": 1.1875035762786865,
      "learning_rate": 4.725106382978723e-06,
      "loss": 0.0748,
      "step": 7507
    },
    {
      "epoch": 1.7251838235294117,
      "grad_norm": 1.414110779762268,
      "learning_rate": 4.724255319148936e-06,
      "loss": 0.0798,
      "step": 7508
    },
    {
      "epoch": 1.7254136029411766,
      "grad_norm": 1.2078371047973633,
      "learning_rate": 4.7234042553191496e-06,
      "loss": 0.0595,
      "step": 7509
    },
    {
      "epoch": 1.7256433823529411,
      "grad_norm": 1.161825180053711,
      "learning_rate": 4.722553191489362e-06,
      "loss": 0.0537,
      "step": 7510
    },
    {
      "epoch": 1.7258731617647058,
      "grad_norm": 1.398916482925415,
      "learning_rate": 4.721702127659575e-06,
      "loss": 0.0788,
      "step": 7511
    },
    {
      "epoch": 1.7261029411764706,
      "grad_norm": 1.4123778343200684,
      "learning_rate": 4.720851063829787e-06,
      "loss": 0.0648,
      "step": 7512
    },
    {
      "epoch": 1.7263327205882353,
      "grad_norm": 1.6867690086364746,
      "learning_rate": 4.7200000000000005e-06,
      "loss": 0.1078,
      "step": 7513
    },
    {
      "epoch": 1.7265625,
      "grad_norm": 1.456284999847412,
      "learning_rate": 4.719148936170213e-06,
      "loss": 0.0945,
      "step": 7514
    },
    {
      "epoch": 1.7267922794117647,
      "grad_norm": 2.045807361602783,
      "learning_rate": 4.718297872340426e-06,
      "loss": 0.0967,
      "step": 7515
    },
    {
      "epoch": 1.7270220588235294,
      "grad_norm": 1.3176562786102295,
      "learning_rate": 4.717446808510638e-06,
      "loss": 0.0929,
      "step": 7516
    },
    {
      "epoch": 1.7272518382352942,
      "grad_norm": 1.2127039432525635,
      "learning_rate": 4.7165957446808515e-06,
      "loss": 0.0905,
      "step": 7517
    },
    {
      "epoch": 1.7274816176470589,
      "grad_norm": 1.1209397315979004,
      "learning_rate": 4.715744680851065e-06,
      "loss": 0.0482,
      "step": 7518
    },
    {
      "epoch": 1.7277113970588234,
      "grad_norm": 1.3899134397506714,
      "learning_rate": 4.714893617021277e-06,
      "loss": 0.0678,
      "step": 7519
    },
    {
      "epoch": 1.7279411764705883,
      "grad_norm": 0.9877580404281616,
      "learning_rate": 4.714042553191489e-06,
      "loss": 0.0534,
      "step": 7520
    },
    {
      "epoch": 1.7281709558823528,
      "grad_norm": 1.3535197973251343,
      "learning_rate": 4.7131914893617025e-06,
      "loss": 0.1008,
      "step": 7521
    },
    {
      "epoch": 1.7284007352941178,
      "grad_norm": 0.849907636642456,
      "learning_rate": 4.712340425531916e-06,
      "loss": 0.0488,
      "step": 7522
    },
    {
      "epoch": 1.7286305147058822,
      "grad_norm": 1.2002869844436646,
      "learning_rate": 4.711489361702128e-06,
      "loss": 0.0654,
      "step": 7523
    },
    {
      "epoch": 1.7288602941176472,
      "grad_norm": 1.3865723609924316,
      "learning_rate": 4.710638297872341e-06,
      "loss": 0.0751,
      "step": 7524
    },
    {
      "epoch": 1.7290900735294117,
      "grad_norm": 1.766284465789795,
      "learning_rate": 4.7097872340425535e-06,
      "loss": 0.0664,
      "step": 7525
    },
    {
      "epoch": 1.7293198529411766,
      "grad_norm": 1.7223047018051147,
      "learning_rate": 4.708936170212766e-06,
      "loss": 0.0773,
      "step": 7526
    },
    {
      "epoch": 1.7295496323529411,
      "grad_norm": 1.295906901359558,
      "learning_rate": 4.708085106382979e-06,
      "loss": 0.0626,
      "step": 7527
    },
    {
      "epoch": 1.7297794117647058,
      "grad_norm": 1.1487702131271362,
      "learning_rate": 4.707234042553192e-06,
      "loss": 0.0596,
      "step": 7528
    },
    {
      "epoch": 1.7300091911764706,
      "grad_norm": 1.261592984199524,
      "learning_rate": 4.7063829787234045e-06,
      "loss": 0.0736,
      "step": 7529
    },
    {
      "epoch": 1.7302389705882353,
      "grad_norm": 1.3542321920394897,
      "learning_rate": 4.705531914893618e-06,
      "loss": 0.076,
      "step": 7530
    },
    {
      "epoch": 1.73046875,
      "grad_norm": 1.247554063796997,
      "learning_rate": 4.70468085106383e-06,
      "loss": 0.0834,
      "step": 7531
    },
    {
      "epoch": 1.7306985294117647,
      "grad_norm": 1.397751808166504,
      "learning_rate": 4.703829787234042e-06,
      "loss": 0.0867,
      "step": 7532
    },
    {
      "epoch": 1.7309283088235294,
      "grad_norm": 1.2361760139465332,
      "learning_rate": 4.7029787234042555e-06,
      "loss": 0.0783,
      "step": 7533
    },
    {
      "epoch": 1.7311580882352942,
      "grad_norm": 0.9153937697410583,
      "learning_rate": 4.702127659574469e-06,
      "loss": 0.053,
      "step": 7534
    },
    {
      "epoch": 1.7313878676470589,
      "grad_norm": 1.3248342275619507,
      "learning_rate": 4.701276595744681e-06,
      "loss": 0.0889,
      "step": 7535
    },
    {
      "epoch": 1.7316176470588234,
      "grad_norm": 1.0369905233383179,
      "learning_rate": 4.700425531914894e-06,
      "loss": 0.0477,
      "step": 7536
    },
    {
      "epoch": 1.7318474264705883,
      "grad_norm": 1.3074175119400024,
      "learning_rate": 4.6995744680851065e-06,
      "loss": 0.0643,
      "step": 7537
    },
    {
      "epoch": 1.7320772058823528,
      "grad_norm": 1.4738855361938477,
      "learning_rate": 4.69872340425532e-06,
      "loss": 0.0995,
      "step": 7538
    },
    {
      "epoch": 1.7323069852941178,
      "grad_norm": 1.4240236282348633,
      "learning_rate": 4.697872340425532e-06,
      "loss": 0.0743,
      "step": 7539
    },
    {
      "epoch": 1.7325367647058822,
      "grad_norm": 1.432086706161499,
      "learning_rate": 4.697021276595745e-06,
      "loss": 0.056,
      "step": 7540
    },
    {
      "epoch": 1.7327665441176472,
      "grad_norm": 1.062483787536621,
      "learning_rate": 4.696170212765958e-06,
      "loss": 0.0754,
      "step": 7541
    },
    {
      "epoch": 1.7329963235294117,
      "grad_norm": 1.3570616245269775,
      "learning_rate": 4.695319148936171e-06,
      "loss": 0.0688,
      "step": 7542
    },
    {
      "epoch": 1.7332261029411766,
      "grad_norm": 1.198880910873413,
      "learning_rate": 4.694468085106384e-06,
      "loss": 0.0443,
      "step": 7543
    },
    {
      "epoch": 1.7334558823529411,
      "grad_norm": 1.1983321905136108,
      "learning_rate": 4.693617021276596e-06,
      "loss": 0.0729,
      "step": 7544
    },
    {
      "epoch": 1.7336856617647058,
      "grad_norm": 1.2263821363449097,
      "learning_rate": 4.6927659574468085e-06,
      "loss": 0.0708,
      "step": 7545
    },
    {
      "epoch": 1.7339154411764706,
      "grad_norm": 1.1619282960891724,
      "learning_rate": 4.691914893617022e-06,
      "loss": 0.0785,
      "step": 7546
    },
    {
      "epoch": 1.7341452205882353,
      "grad_norm": 1.3856533765792847,
      "learning_rate": 4.691063829787235e-06,
      "loss": 0.0607,
      "step": 7547
    },
    {
      "epoch": 1.734375,
      "grad_norm": 1.3738739490509033,
      "learning_rate": 4.690212765957447e-06,
      "loss": 0.0976,
      "step": 7548
    },
    {
      "epoch": 1.7346047794117647,
      "grad_norm": 1.3961771726608276,
      "learning_rate": 4.68936170212766e-06,
      "loss": 0.071,
      "step": 7549
    },
    {
      "epoch": 1.7348345588235294,
      "grad_norm": 1.4242842197418213,
      "learning_rate": 4.688510638297873e-06,
      "loss": 0.0817,
      "step": 7550
    },
    {
      "epoch": 1.7350643382352942,
      "grad_norm": 1.1900107860565186,
      "learning_rate": 4.687659574468085e-06,
      "loss": 0.0858,
      "step": 7551
    },
    {
      "epoch": 1.7352941176470589,
      "grad_norm": 1.210195779800415,
      "learning_rate": 4.686808510638298e-06,
      "loss": 0.0633,
      "step": 7552
    },
    {
      "epoch": 1.7355238970588234,
      "grad_norm": 0.8116568922996521,
      "learning_rate": 4.685957446808511e-06,
      "loss": 0.0539,
      "step": 7553
    },
    {
      "epoch": 1.7357536764705883,
      "grad_norm": 1.056261658668518,
      "learning_rate": 4.685106382978724e-06,
      "loss": 0.0557,
      "step": 7554
    },
    {
      "epoch": 1.7359834558823528,
      "grad_norm": 1.3190733194351196,
      "learning_rate": 4.684255319148937e-06,
      "loss": 0.0946,
      "step": 7555
    },
    {
      "epoch": 1.7362132352941178,
      "grad_norm": 1.6531811952590942,
      "learning_rate": 4.683404255319149e-06,
      "loss": 0.1036,
      "step": 7556
    },
    {
      "epoch": 1.7364430147058822,
      "grad_norm": 1.65700101852417,
      "learning_rate": 4.682553191489361e-06,
      "loss": 0.0801,
      "step": 7557
    },
    {
      "epoch": 1.7366727941176472,
      "grad_norm": 1.3286595344543457,
      "learning_rate": 4.681702127659575e-06,
      "loss": 0.0802,
      "step": 7558
    },
    {
      "epoch": 1.7369025735294117,
      "grad_norm": 1.2338056564331055,
      "learning_rate": 4.680851063829788e-06,
      "loss": 0.0679,
      "step": 7559
    },
    {
      "epoch": 1.7371323529411766,
      "grad_norm": 1.1160165071487427,
      "learning_rate": 4.680000000000001e-06,
      "loss": 0.0719,
      "step": 7560
    },
    {
      "epoch": 1.7373621323529411,
      "grad_norm": 1.061010718345642,
      "learning_rate": 4.679148936170213e-06,
      "loss": 0.0728,
      "step": 7561
    },
    {
      "epoch": 1.7375919117647058,
      "grad_norm": 1.200276494026184,
      "learning_rate": 4.678297872340426e-06,
      "loss": 0.0845,
      "step": 7562
    },
    {
      "epoch": 1.7378216911764706,
      "grad_norm": 1.1570311784744263,
      "learning_rate": 4.677446808510639e-06,
      "loss": 0.0742,
      "step": 7563
    },
    {
      "epoch": 1.7380514705882353,
      "grad_norm": 1.1793584823608398,
      "learning_rate": 4.676595744680851e-06,
      "loss": 0.057,
      "step": 7564
    },
    {
      "epoch": 1.73828125,
      "grad_norm": 1.0186201333999634,
      "learning_rate": 4.675744680851064e-06,
      "loss": 0.1038,
      "step": 7565
    },
    {
      "epoch": 1.7385110294117647,
      "grad_norm": 1.1763205528259277,
      "learning_rate": 4.674893617021277e-06,
      "loss": 0.0784,
      "step": 7566
    },
    {
      "epoch": 1.7387408088235294,
      "grad_norm": 1.2898706197738647,
      "learning_rate": 4.67404255319149e-06,
      "loss": 0.0768,
      "step": 7567
    },
    {
      "epoch": 1.7389705882352942,
      "grad_norm": 0.8254813551902771,
      "learning_rate": 4.673191489361703e-06,
      "loss": 0.0564,
      "step": 7568
    },
    {
      "epoch": 1.7392003676470589,
      "grad_norm": 1.0105451345443726,
      "learning_rate": 4.672340425531915e-06,
      "loss": 0.0808,
      "step": 7569
    },
    {
      "epoch": 1.7394301470588234,
      "grad_norm": 1.249515175819397,
      "learning_rate": 4.6714893617021276e-06,
      "loss": 0.083,
      "step": 7570
    },
    {
      "epoch": 1.7396599264705883,
      "grad_norm": 1.0242124795913696,
      "learning_rate": 4.670638297872341e-06,
      "loss": 0.055,
      "step": 7571
    },
    {
      "epoch": 1.7398897058823528,
      "grad_norm": 1.0493030548095703,
      "learning_rate": 4.669787234042554e-06,
      "loss": 0.0766,
      "step": 7572
    },
    {
      "epoch": 1.7401194852941178,
      "grad_norm": 1.355861783027649,
      "learning_rate": 4.668936170212766e-06,
      "loss": 0.0845,
      "step": 7573
    },
    {
      "epoch": 1.7403492647058822,
      "grad_norm": 1.1350250244140625,
      "learning_rate": 4.668085106382979e-06,
      "loss": 0.0646,
      "step": 7574
    },
    {
      "epoch": 1.7405790441176472,
      "grad_norm": 0.9574264287948608,
      "learning_rate": 4.667234042553192e-06,
      "loss": 0.0614,
      "step": 7575
    },
    {
      "epoch": 1.7408088235294117,
      "grad_norm": 1.3992455005645752,
      "learning_rate": 4.666382978723404e-06,
      "loss": 0.096,
      "step": 7576
    },
    {
      "epoch": 1.7410386029411766,
      "grad_norm": 1.2069993019104004,
      "learning_rate": 4.665531914893617e-06,
      "loss": 0.0753,
      "step": 7577
    },
    {
      "epoch": 1.7412683823529411,
      "grad_norm": 1.1121046543121338,
      "learning_rate": 4.66468085106383e-06,
      "loss": 0.0693,
      "step": 7578
    },
    {
      "epoch": 1.7414981617647058,
      "grad_norm": 1.2141884565353394,
      "learning_rate": 4.663829787234043e-06,
      "loss": 0.067,
      "step": 7579
    },
    {
      "epoch": 1.7417279411764706,
      "grad_norm": 1.0630583763122559,
      "learning_rate": 4.662978723404256e-06,
      "loss": 0.0694,
      "step": 7580
    },
    {
      "epoch": 1.7419577205882353,
      "grad_norm": 1.0110957622528076,
      "learning_rate": 4.662127659574468e-06,
      "loss": 0.0939,
      "step": 7581
    },
    {
      "epoch": 1.7421875,
      "grad_norm": 1.165462613105774,
      "learning_rate": 4.661276595744681e-06,
      "loss": 0.0785,
      "step": 7582
    },
    {
      "epoch": 1.7424172794117647,
      "grad_norm": 1.4395571947097778,
      "learning_rate": 4.660425531914894e-06,
      "loss": 0.1183,
      "step": 7583
    },
    {
      "epoch": 1.7426470588235294,
      "grad_norm": 0.9632229804992676,
      "learning_rate": 4.659574468085107e-06,
      "loss": 0.077,
      "step": 7584
    },
    {
      "epoch": 1.7428768382352942,
      "grad_norm": 1.2598484754562378,
      "learning_rate": 4.65872340425532e-06,
      "loss": 0.1139,
      "step": 7585
    },
    {
      "epoch": 1.7431066176470589,
      "grad_norm": 1.3755666017532349,
      "learning_rate": 4.657872340425532e-06,
      "loss": 0.0993,
      "step": 7586
    },
    {
      "epoch": 1.7433363970588234,
      "grad_norm": 0.9725555777549744,
      "learning_rate": 4.657021276595745e-06,
      "loss": 0.0464,
      "step": 7587
    },
    {
      "epoch": 1.7435661764705883,
      "grad_norm": 1.0195025205612183,
      "learning_rate": 4.656170212765958e-06,
      "loss": 0.0906,
      "step": 7588
    },
    {
      "epoch": 1.7437959558823528,
      "grad_norm": 1.0354464054107666,
      "learning_rate": 4.65531914893617e-06,
      "loss": 0.0822,
      "step": 7589
    },
    {
      "epoch": 1.7440257352941178,
      "grad_norm": 1.455796480178833,
      "learning_rate": 4.654468085106383e-06,
      "loss": 0.0819,
      "step": 7590
    },
    {
      "epoch": 1.7442555147058822,
      "grad_norm": 1.0717452764511108,
      "learning_rate": 4.6536170212765965e-06,
      "loss": 0.068,
      "step": 7591
    },
    {
      "epoch": 1.7444852941176472,
      "grad_norm": 1.2049461603164673,
      "learning_rate": 4.652765957446809e-06,
      "loss": 0.0697,
      "step": 7592
    },
    {
      "epoch": 1.7447150735294117,
      "grad_norm": 1.2938148975372314,
      "learning_rate": 4.651914893617022e-06,
      "loss": 0.1022,
      "step": 7593
    },
    {
      "epoch": 1.7449448529411766,
      "grad_norm": 0.9179996848106384,
      "learning_rate": 4.651063829787234e-06,
      "loss": 0.0532,
      "step": 7594
    },
    {
      "epoch": 1.7451746323529411,
      "grad_norm": 1.479514718055725,
      "learning_rate": 4.650212765957447e-06,
      "loss": 0.0925,
      "step": 7595
    },
    {
      "epoch": 1.7454044117647058,
      "grad_norm": 1.1245924234390259,
      "learning_rate": 4.64936170212766e-06,
      "loss": 0.0673,
      "step": 7596
    },
    {
      "epoch": 1.7456341911764706,
      "grad_norm": 1.0285242795944214,
      "learning_rate": 4.648510638297873e-06,
      "loss": 0.0484,
      "step": 7597
    },
    {
      "epoch": 1.7458639705882353,
      "grad_norm": 1.297705054283142,
      "learning_rate": 4.647659574468085e-06,
      "loss": 0.1014,
      "step": 7598
    },
    {
      "epoch": 1.74609375,
      "grad_norm": 1.2949265241622925,
      "learning_rate": 4.6468085106382985e-06,
      "loss": 0.0836,
      "step": 7599
    },
    {
      "epoch": 1.7463235294117647,
      "grad_norm": 1.1279534101486206,
      "learning_rate": 4.645957446808511e-06,
      "loss": 0.0464,
      "step": 7600
    },
    {
      "epoch": 1.7465533088235294,
      "grad_norm": 0.9103720784187317,
      "learning_rate": 4.645106382978723e-06,
      "loss": 0.0387,
      "step": 7601
    },
    {
      "epoch": 1.7467830882352942,
      "grad_norm": 0.9857016801834106,
      "learning_rate": 4.644255319148936e-06,
      "loss": 0.0738,
      "step": 7602
    },
    {
      "epoch": 1.7470128676470589,
      "grad_norm": 1.129990577697754,
      "learning_rate": 4.6434042553191495e-06,
      "loss": 0.055,
      "step": 7603
    },
    {
      "epoch": 1.7472426470588234,
      "grad_norm": 1.1009888648986816,
      "learning_rate": 4.642553191489363e-06,
      "loss": 0.0802,
      "step": 7604
    },
    {
      "epoch": 1.7474724264705883,
      "grad_norm": 1.3312811851501465,
      "learning_rate": 4.641702127659575e-06,
      "loss": 0.0792,
      "step": 7605
    },
    {
      "epoch": 1.7477022058823528,
      "grad_norm": 1.1344232559204102,
      "learning_rate": 4.640851063829787e-06,
      "loss": 0.0687,
      "step": 7606
    },
    {
      "epoch": 1.7479319852941178,
      "grad_norm": 1.3675971031188965,
      "learning_rate": 4.6400000000000005e-06,
      "loss": 0.0775,
      "step": 7607
    },
    {
      "epoch": 1.7481617647058822,
      "grad_norm": 1.1897419691085815,
      "learning_rate": 4.639148936170213e-06,
      "loss": 0.0594,
      "step": 7608
    },
    {
      "epoch": 1.7483915441176472,
      "grad_norm": 1.034072995185852,
      "learning_rate": 4.638297872340426e-06,
      "loss": 0.0597,
      "step": 7609
    },
    {
      "epoch": 1.7486213235294117,
      "grad_norm": 1.2924485206604004,
      "learning_rate": 4.637446808510639e-06,
      "loss": 0.0998,
      "step": 7610
    },
    {
      "epoch": 1.7488511029411766,
      "grad_norm": 1.0648633241653442,
      "learning_rate": 4.6365957446808515e-06,
      "loss": 0.0505,
      "step": 7611
    },
    {
      "epoch": 1.7490808823529411,
      "grad_norm": 1.1779077053070068,
      "learning_rate": 4.635744680851065e-06,
      "loss": 0.0669,
      "step": 7612
    },
    {
      "epoch": 1.7493106617647058,
      "grad_norm": 1.2632827758789062,
      "learning_rate": 4.634893617021277e-06,
      "loss": 0.0737,
      "step": 7613
    },
    {
      "epoch": 1.7495404411764706,
      "grad_norm": 1.0267791748046875,
      "learning_rate": 4.634042553191489e-06,
      "loss": 0.0675,
      "step": 7614
    },
    {
      "epoch": 1.7497702205882353,
      "grad_norm": 1.2915376424789429,
      "learning_rate": 4.6331914893617024e-06,
      "loss": 0.0987,
      "step": 7615
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.2954107522964478,
      "learning_rate": 4.632340425531916e-06,
      "loss": 0.0766,
      "step": 7616
    },
    {
      "epoch": 1.7502297794117647,
      "grad_norm": 0.9306867718696594,
      "learning_rate": 4.631489361702128e-06,
      "loss": 0.0783,
      "step": 7617
    },
    {
      "epoch": 1.7504595588235294,
      "grad_norm": 1.2045482397079468,
      "learning_rate": 4.630638297872341e-06,
      "loss": 0.0841,
      "step": 7618
    },
    {
      "epoch": 1.7506893382352942,
      "grad_norm": 1.4572702646255493,
      "learning_rate": 4.6297872340425534e-06,
      "loss": 0.0929,
      "step": 7619
    },
    {
      "epoch": 1.7509191176470589,
      "grad_norm": 1.3260012865066528,
      "learning_rate": 4.628936170212766e-06,
      "loss": 0.0653,
      "step": 7620
    },
    {
      "epoch": 1.7511488970588234,
      "grad_norm": 1.0101972818374634,
      "learning_rate": 4.628085106382979e-06,
      "loss": 0.0692,
      "step": 7621
    },
    {
      "epoch": 1.7513786764705883,
      "grad_norm": 1.4815565347671509,
      "learning_rate": 4.627234042553192e-06,
      "loss": 0.0915,
      "step": 7622
    },
    {
      "epoch": 1.7516084558823528,
      "grad_norm": 1.4127416610717773,
      "learning_rate": 4.626382978723404e-06,
      "loss": 0.0673,
      "step": 7623
    },
    {
      "epoch": 1.7518382352941178,
      "grad_norm": 1.8806830644607544,
      "learning_rate": 4.625531914893618e-06,
      "loss": 0.1045,
      "step": 7624
    },
    {
      "epoch": 1.7520680147058822,
      "grad_norm": 1.7018542289733887,
      "learning_rate": 4.62468085106383e-06,
      "loss": 0.0895,
      "step": 7625
    },
    {
      "epoch": 1.7522977941176472,
      "grad_norm": 0.9206714034080505,
      "learning_rate": 4.623829787234043e-06,
      "loss": 0.0594,
      "step": 7626
    },
    {
      "epoch": 1.7525275735294117,
      "grad_norm": 1.1757924556732178,
      "learning_rate": 4.622978723404255e-06,
      "loss": 0.0737,
      "step": 7627
    },
    {
      "epoch": 1.7527573529411766,
      "grad_norm": 1.0445822477340698,
      "learning_rate": 4.622127659574469e-06,
      "loss": 0.0558,
      "step": 7628
    },
    {
      "epoch": 1.7529871323529411,
      "grad_norm": 1.8055742979049683,
      "learning_rate": 4.621276595744682e-06,
      "loss": 0.1022,
      "step": 7629
    },
    {
      "epoch": 1.7532169117647058,
      "grad_norm": 1.2144818305969238,
      "learning_rate": 4.620425531914894e-06,
      "loss": 0.0583,
      "step": 7630
    },
    {
      "epoch": 1.7534466911764706,
      "grad_norm": 0.9715021848678589,
      "learning_rate": 4.619574468085106e-06,
      "loss": 0.0614,
      "step": 7631
    },
    {
      "epoch": 1.7536764705882353,
      "grad_norm": 2.13082218170166,
      "learning_rate": 4.6187234042553196e-06,
      "loss": 0.0898,
      "step": 7632
    },
    {
      "epoch": 1.75390625,
      "grad_norm": 1.6501826047897339,
      "learning_rate": 4.617872340425532e-06,
      "loss": 0.1112,
      "step": 7633
    },
    {
      "epoch": 1.7541360294117647,
      "grad_norm": 1.915512204170227,
      "learning_rate": 4.617021276595745e-06,
      "loss": 0.1004,
      "step": 7634
    },
    {
      "epoch": 1.7543658088235294,
      "grad_norm": 1.1384204626083374,
      "learning_rate": 4.616170212765958e-06,
      "loss": 0.065,
      "step": 7635
    },
    {
      "epoch": 1.7545955882352942,
      "grad_norm": 1.3293607234954834,
      "learning_rate": 4.6153191489361706e-06,
      "loss": 0.0729,
      "step": 7636
    },
    {
      "epoch": 1.7548253676470589,
      "grad_norm": 1.0929824113845825,
      "learning_rate": 4.614468085106384e-06,
      "loss": 0.0581,
      "step": 7637
    },
    {
      "epoch": 1.7550551470588234,
      "grad_norm": 1.9244327545166016,
      "learning_rate": 4.613617021276596e-06,
      "loss": 0.0772,
      "step": 7638
    },
    {
      "epoch": 1.7552849264705883,
      "grad_norm": 1.2493094205856323,
      "learning_rate": 4.612765957446808e-06,
      "loss": 0.0668,
      "step": 7639
    },
    {
      "epoch": 1.7555147058823528,
      "grad_norm": 1.2145134210586548,
      "learning_rate": 4.6119148936170215e-06,
      "loss": 0.1002,
      "step": 7640
    },
    {
      "epoch": 1.7557444852941178,
      "grad_norm": 1.1804202795028687,
      "learning_rate": 4.611063829787235e-06,
      "loss": 0.0678,
      "step": 7641
    },
    {
      "epoch": 1.7559742647058822,
      "grad_norm": 1.411259412765503,
      "learning_rate": 4.610212765957447e-06,
      "loss": 0.0844,
      "step": 7642
    },
    {
      "epoch": 1.7562040441176472,
      "grad_norm": 1.3617775440216064,
      "learning_rate": 4.60936170212766e-06,
      "loss": 0.0878,
      "step": 7643
    },
    {
      "epoch": 1.7564338235294117,
      "grad_norm": 1.4051930904388428,
      "learning_rate": 4.6085106382978725e-06,
      "loss": 0.0684,
      "step": 7644
    },
    {
      "epoch": 1.7566636029411766,
      "grad_norm": 1.0220470428466797,
      "learning_rate": 4.607659574468086e-06,
      "loss": 0.0685,
      "step": 7645
    },
    {
      "epoch": 1.7568933823529411,
      "grad_norm": 1.4650629758834839,
      "learning_rate": 4.606808510638298e-06,
      "loss": 0.1252,
      "step": 7646
    },
    {
      "epoch": 1.7571231617647058,
      "grad_norm": 1.434349536895752,
      "learning_rate": 4.605957446808511e-06,
      "loss": 0.09,
      "step": 7647
    },
    {
      "epoch": 1.7573529411764706,
      "grad_norm": 1.0125114917755127,
      "learning_rate": 4.605106382978724e-06,
      "loss": 0.0557,
      "step": 7648
    },
    {
      "epoch": 1.7575827205882353,
      "grad_norm": 1.4551433324813843,
      "learning_rate": 4.604255319148937e-06,
      "loss": 0.0899,
      "step": 7649
    },
    {
      "epoch": 1.7578125,
      "grad_norm": 1.1642905473709106,
      "learning_rate": 4.603404255319149e-06,
      "loss": 0.0752,
      "step": 7650
    },
    {
      "epoch": 1.7580422794117647,
      "grad_norm": 1.0381981134414673,
      "learning_rate": 4.602553191489362e-06,
      "loss": 0.0788,
      "step": 7651
    },
    {
      "epoch": 1.7582720588235294,
      "grad_norm": 0.9756820201873779,
      "learning_rate": 4.6017021276595745e-06,
      "loss": 0.0425,
      "step": 7652
    },
    {
      "epoch": 1.7585018382352942,
      "grad_norm": 1.2947306632995605,
      "learning_rate": 4.600851063829788e-06,
      "loss": 0.0737,
      "step": 7653
    },
    {
      "epoch": 1.7587316176470589,
      "grad_norm": 1.4560363292694092,
      "learning_rate": 4.600000000000001e-06,
      "loss": 0.1007,
      "step": 7654
    },
    {
      "epoch": 1.7589613970588234,
      "grad_norm": 1.0511993169784546,
      "learning_rate": 4.599148936170213e-06,
      "loss": 0.0707,
      "step": 7655
    },
    {
      "epoch": 1.7591911764705883,
      "grad_norm": 1.5820164680480957,
      "learning_rate": 4.5982978723404255e-06,
      "loss": 0.09,
      "step": 7656
    },
    {
      "epoch": 1.7594209558823528,
      "grad_norm": 1.2171083688735962,
      "learning_rate": 4.597446808510639e-06,
      "loss": 0.0866,
      "step": 7657
    },
    {
      "epoch": 1.7596507352941178,
      "grad_norm": 1.2032376527786255,
      "learning_rate": 4.596595744680851e-06,
      "loss": 0.0985,
      "step": 7658
    },
    {
      "epoch": 1.7598805147058822,
      "grad_norm": 1.2447764873504639,
      "learning_rate": 4.595744680851064e-06,
      "loss": 0.0939,
      "step": 7659
    },
    {
      "epoch": 1.7601102941176472,
      "grad_norm": 1.5061241388320923,
      "learning_rate": 4.594893617021277e-06,
      "loss": 0.0824,
      "step": 7660
    },
    {
      "epoch": 1.7603400735294117,
      "grad_norm": 1.4851685762405396,
      "learning_rate": 4.59404255319149e-06,
      "loss": 0.096,
      "step": 7661
    },
    {
      "epoch": 1.7605698529411766,
      "grad_norm": 1.0583724975585938,
      "learning_rate": 4.593191489361703e-06,
      "loss": 0.0515,
      "step": 7662
    },
    {
      "epoch": 1.7607996323529411,
      "grad_norm": 1.4233494997024536,
      "learning_rate": 4.592340425531915e-06,
      "loss": 0.0922,
      "step": 7663
    },
    {
      "epoch": 1.7610294117647058,
      "grad_norm": 1.2098724842071533,
      "learning_rate": 4.5914893617021275e-06,
      "loss": 0.0732,
      "step": 7664
    },
    {
      "epoch": 1.7612591911764706,
      "grad_norm": 1.2661240100860596,
      "learning_rate": 4.590638297872341e-06,
      "loss": 0.0758,
      "step": 7665
    },
    {
      "epoch": 1.7614889705882353,
      "grad_norm": 1.4458351135253906,
      "learning_rate": 4.589787234042554e-06,
      "loss": 0.1249,
      "step": 7666
    },
    {
      "epoch": 1.76171875,
      "grad_norm": 0.8770951628684998,
      "learning_rate": 4.588936170212767e-06,
      "loss": 0.0661,
      "step": 7667
    },
    {
      "epoch": 1.7619485294117647,
      "grad_norm": 1.0603001117706299,
      "learning_rate": 4.588085106382979e-06,
      "loss": 0.0775,
      "step": 7668
    },
    {
      "epoch": 1.7621783088235294,
      "grad_norm": 1.1677414178848267,
      "learning_rate": 4.587234042553192e-06,
      "loss": 0.0935,
      "step": 7669
    },
    {
      "epoch": 1.7624080882352942,
      "grad_norm": 0.899422824382782,
      "learning_rate": 4.586382978723405e-06,
      "loss": 0.0547,
      "step": 7670
    },
    {
      "epoch": 1.7626378676470589,
      "grad_norm": 1.1616510152816772,
      "learning_rate": 4.585531914893617e-06,
      "loss": 0.1029,
      "step": 7671
    },
    {
      "epoch": 1.7628676470588234,
      "grad_norm": 1.2077016830444336,
      "learning_rate": 4.58468085106383e-06,
      "loss": 0.0611,
      "step": 7672
    },
    {
      "epoch": 1.7630974264705883,
      "grad_norm": 1.5277084112167358,
      "learning_rate": 4.5838297872340435e-06,
      "loss": 0.0775,
      "step": 7673
    },
    {
      "epoch": 1.7633272058823528,
      "grad_norm": 1.5606211423873901,
      "learning_rate": 4.582978723404256e-06,
      "loss": 0.1136,
      "step": 7674
    },
    {
      "epoch": 1.7635569852941178,
      "grad_norm": 0.986378014087677,
      "learning_rate": 4.582127659574468e-06,
      "loss": 0.065,
      "step": 7675
    },
    {
      "epoch": 1.7637867647058822,
      "grad_norm": 0.8539578914642334,
      "learning_rate": 4.581276595744681e-06,
      "loss": 0.0813,
      "step": 7676
    },
    {
      "epoch": 1.7640165441176472,
      "grad_norm": 1.0421401262283325,
      "learning_rate": 4.580425531914894e-06,
      "loss": 0.0697,
      "step": 7677
    },
    {
      "epoch": 1.7642463235294117,
      "grad_norm": 1.0929920673370361,
      "learning_rate": 4.579574468085107e-06,
      "loss": 0.0585,
      "step": 7678
    },
    {
      "epoch": 1.7644761029411766,
      "grad_norm": 0.9390107989311218,
      "learning_rate": 4.57872340425532e-06,
      "loss": 0.0523,
      "step": 7679
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 1.5681623220443726,
      "learning_rate": 4.577872340425532e-06,
      "loss": 0.1172,
      "step": 7680
    },
    {
      "epoch": 1.7649356617647058,
      "grad_norm": 1.247851848602295,
      "learning_rate": 4.5770212765957454e-06,
      "loss": 0.0727,
      "step": 7681
    },
    {
      "epoch": 1.7651654411764706,
      "grad_norm": 1.1111468076705933,
      "learning_rate": 4.576170212765958e-06,
      "loss": 0.0557,
      "step": 7682
    },
    {
      "epoch": 1.7653952205882353,
      "grad_norm": 1.2431801557540894,
      "learning_rate": 4.57531914893617e-06,
      "loss": 0.0826,
      "step": 7683
    },
    {
      "epoch": 1.765625,
      "grad_norm": 1.473091959953308,
      "learning_rate": 4.574468085106383e-06,
      "loss": 0.077,
      "step": 7684
    },
    {
      "epoch": 1.7658547794117647,
      "grad_norm": 1.8764245510101318,
      "learning_rate": 4.5736170212765964e-06,
      "loss": 0.0627,
      "step": 7685
    },
    {
      "epoch": 1.7660845588235294,
      "grad_norm": 2.6294784545898438,
      "learning_rate": 4.572765957446809e-06,
      "loss": 0.0801,
      "step": 7686
    },
    {
      "epoch": 1.7663143382352942,
      "grad_norm": 1.1517552137374878,
      "learning_rate": 4.571914893617022e-06,
      "loss": 0.0868,
      "step": 7687
    },
    {
      "epoch": 1.7665441176470589,
      "grad_norm": 1.1108677387237549,
      "learning_rate": 4.571063829787234e-06,
      "loss": 0.0695,
      "step": 7688
    },
    {
      "epoch": 1.7667738970588234,
      "grad_norm": 1.0955085754394531,
      "learning_rate": 4.570212765957447e-06,
      "loss": 0.0705,
      "step": 7689
    },
    {
      "epoch": 1.7670036764705883,
      "grad_norm": 1.0836009979248047,
      "learning_rate": 4.56936170212766e-06,
      "loss": 0.078,
      "step": 7690
    },
    {
      "epoch": 1.7672334558823528,
      "grad_norm": 1.4233793020248413,
      "learning_rate": 4.568510638297873e-06,
      "loss": 0.0893,
      "step": 7691
    },
    {
      "epoch": 1.7674632352941178,
      "grad_norm": 1.267141580581665,
      "learning_rate": 4.567659574468086e-06,
      "loss": 0.0612,
      "step": 7692
    },
    {
      "epoch": 1.7676930147058822,
      "grad_norm": 1.3041571378707886,
      "learning_rate": 4.566808510638298e-06,
      "loss": 0.0776,
      "step": 7693
    },
    {
      "epoch": 1.7679227941176472,
      "grad_norm": 1.083040714263916,
      "learning_rate": 4.565957446808511e-06,
      "loss": 0.0729,
      "step": 7694
    },
    {
      "epoch": 1.7681525735294117,
      "grad_norm": 0.9865015745162964,
      "learning_rate": 4.565106382978724e-06,
      "loss": 0.0829,
      "step": 7695
    },
    {
      "epoch": 1.7683823529411766,
      "grad_norm": 0.6360830664634705,
      "learning_rate": 4.564255319148936e-06,
      "loss": 0.0418,
      "step": 7696
    },
    {
      "epoch": 1.7686121323529411,
      "grad_norm": 1.164980411529541,
      "learning_rate": 4.563404255319149e-06,
      "loss": 0.075,
      "step": 7697
    },
    {
      "epoch": 1.7688419117647058,
      "grad_norm": 1.5155680179595947,
      "learning_rate": 4.5625531914893626e-06,
      "loss": 0.0702,
      "step": 7698
    },
    {
      "epoch": 1.7690716911764706,
      "grad_norm": 1.190727710723877,
      "learning_rate": 4.561702127659575e-06,
      "loss": 0.0649,
      "step": 7699
    },
    {
      "epoch": 1.7693014705882353,
      "grad_norm": 1.4318352937698364,
      "learning_rate": 4.560851063829787e-06,
      "loss": 0.1243,
      "step": 7700
    },
    {
      "epoch": 1.76953125,
      "grad_norm": 1.2236067056655884,
      "learning_rate": 4.56e-06,
      "loss": 0.0793,
      "step": 7701
    },
    {
      "epoch": 1.7697610294117647,
      "grad_norm": 1.450254201889038,
      "learning_rate": 4.559148936170213e-06,
      "loss": 0.0624,
      "step": 7702
    },
    {
      "epoch": 1.7699908088235294,
      "grad_norm": 1.2417337894439697,
      "learning_rate": 4.558297872340426e-06,
      "loss": 0.0747,
      "step": 7703
    },
    {
      "epoch": 1.7702205882352942,
      "grad_norm": 1.0646389722824097,
      "learning_rate": 4.557446808510639e-06,
      "loss": 0.089,
      "step": 7704
    },
    {
      "epoch": 1.7704503676470589,
      "grad_norm": 1.2688170671463013,
      "learning_rate": 4.556595744680851e-06,
      "loss": 0.0995,
      "step": 7705
    },
    {
      "epoch": 1.7706801470588234,
      "grad_norm": 1.2176076173782349,
      "learning_rate": 4.5557446808510645e-06,
      "loss": 0.0618,
      "step": 7706
    },
    {
      "epoch": 1.7709099264705883,
      "grad_norm": 1.5352588891983032,
      "learning_rate": 4.554893617021277e-06,
      "loss": 0.0936,
      "step": 7707
    },
    {
      "epoch": 1.7711397058823528,
      "grad_norm": 0.9892722964286804,
      "learning_rate": 4.554042553191489e-06,
      "loss": 0.0414,
      "step": 7708
    },
    {
      "epoch": 1.7713694852941178,
      "grad_norm": 1.2549275159835815,
      "learning_rate": 4.553191489361702e-06,
      "loss": 0.0918,
      "step": 7709
    },
    {
      "epoch": 1.7715992647058822,
      "grad_norm": 1.0806244611740112,
      "learning_rate": 4.5523404255319155e-06,
      "loss": 0.0607,
      "step": 7710
    },
    {
      "epoch": 1.7718290441176472,
      "grad_norm": 0.8721470236778259,
      "learning_rate": 4.551489361702129e-06,
      "loss": 0.0499,
      "step": 7711
    },
    {
      "epoch": 1.7720588235294117,
      "grad_norm": 1.2507257461547852,
      "learning_rate": 4.550638297872341e-06,
      "loss": 0.0632,
      "step": 7712
    },
    {
      "epoch": 1.7722886029411766,
      "grad_norm": 1.0868548154830933,
      "learning_rate": 4.549787234042553e-06,
      "loss": 0.049,
      "step": 7713
    },
    {
      "epoch": 1.7725183823529411,
      "grad_norm": 1.2393059730529785,
      "learning_rate": 4.5489361702127665e-06,
      "loss": 0.0791,
      "step": 7714
    },
    {
      "epoch": 1.7727481617647058,
      "grad_norm": 0.9821290969848633,
      "learning_rate": 4.548085106382979e-06,
      "loss": 0.0457,
      "step": 7715
    },
    {
      "epoch": 1.7729779411764706,
      "grad_norm": 1.5992391109466553,
      "learning_rate": 4.547234042553192e-06,
      "loss": 0.0712,
      "step": 7716
    },
    {
      "epoch": 1.7732077205882353,
      "grad_norm": 1.2660117149353027,
      "learning_rate": 4.546382978723405e-06,
      "loss": 0.0889,
      "step": 7717
    },
    {
      "epoch": 1.7734375,
      "grad_norm": 1.373917579650879,
      "learning_rate": 4.5455319148936175e-06,
      "loss": 0.0747,
      "step": 7718
    },
    {
      "epoch": 1.7736672794117647,
      "grad_norm": 1.3062686920166016,
      "learning_rate": 4.54468085106383e-06,
      "loss": 0.0675,
      "step": 7719
    },
    {
      "epoch": 1.7738970588235294,
      "grad_norm": 1.8355594873428345,
      "learning_rate": 4.543829787234043e-06,
      "loss": 0.1061,
      "step": 7720
    },
    {
      "epoch": 1.7741268382352942,
      "grad_norm": 1.3847180604934692,
      "learning_rate": 4.542978723404255e-06,
      "loss": 0.1031,
      "step": 7721
    },
    {
      "epoch": 1.7743566176470589,
      "grad_norm": 1.7403231859207153,
      "learning_rate": 4.5421276595744685e-06,
      "loss": 0.0946,
      "step": 7722
    },
    {
      "epoch": 1.7745863970588234,
      "grad_norm": 1.17538583278656,
      "learning_rate": 4.541276595744682e-06,
      "loss": 0.0689,
      "step": 7723
    },
    {
      "epoch": 1.7748161764705883,
      "grad_norm": 1.2217466831207275,
      "learning_rate": 4.540425531914894e-06,
      "loss": 0.0636,
      "step": 7724
    },
    {
      "epoch": 1.7750459558823528,
      "grad_norm": 1.7615541219711304,
      "learning_rate": 4.539574468085106e-06,
      "loss": 0.0744,
      "step": 7725
    },
    {
      "epoch": 1.7752757352941178,
      "grad_norm": 1.461729645729065,
      "learning_rate": 4.5387234042553195e-06,
      "loss": 0.0679,
      "step": 7726
    },
    {
      "epoch": 1.7755055147058822,
      "grad_norm": 1.397884488105774,
      "learning_rate": 4.537872340425532e-06,
      "loss": 0.1001,
      "step": 7727
    },
    {
      "epoch": 1.7757352941176472,
      "grad_norm": 0.982154905796051,
      "learning_rate": 4.537021276595745e-06,
      "loss": 0.059,
      "step": 7728
    },
    {
      "epoch": 1.7759650735294117,
      "grad_norm": 1.4035171270370483,
      "learning_rate": 4.536170212765958e-06,
      "loss": 0.0695,
      "step": 7729
    },
    {
      "epoch": 1.7761948529411766,
      "grad_norm": 1.185887336730957,
      "learning_rate": 4.5353191489361705e-06,
      "loss": 0.0761,
      "step": 7730
    },
    {
      "epoch": 1.7764246323529411,
      "grad_norm": 1.365702748298645,
      "learning_rate": 4.534468085106384e-06,
      "loss": 0.0798,
      "step": 7731
    },
    {
      "epoch": 1.7766544117647058,
      "grad_norm": 1.3914506435394287,
      "learning_rate": 4.533617021276596e-06,
      "loss": 0.0783,
      "step": 7732
    },
    {
      "epoch": 1.7768841911764706,
      "grad_norm": 1.2996872663497925,
      "learning_rate": 4.532765957446809e-06,
      "loss": 0.0924,
      "step": 7733
    },
    {
      "epoch": 1.7771139705882353,
      "grad_norm": 1.0799168348312378,
      "learning_rate": 4.5319148936170215e-06,
      "loss": 0.0492,
      "step": 7734
    },
    {
      "epoch": 1.77734375,
      "grad_norm": 1.2511088848114014,
      "learning_rate": 4.531063829787235e-06,
      "loss": 0.0792,
      "step": 7735
    },
    {
      "epoch": 1.7775735294117647,
      "grad_norm": 1.1859463453292847,
      "learning_rate": 4.530212765957448e-06,
      "loss": 0.0789,
      "step": 7736
    },
    {
      "epoch": 1.7778033088235294,
      "grad_norm": 0.9666716456413269,
      "learning_rate": 4.52936170212766e-06,
      "loss": 0.0478,
      "step": 7737
    },
    {
      "epoch": 1.7780330882352942,
      "grad_norm": 0.9924293756484985,
      "learning_rate": 4.5285106382978725e-06,
      "loss": 0.0904,
      "step": 7738
    },
    {
      "epoch": 1.7782628676470589,
      "grad_norm": 0.9813830256462097,
      "learning_rate": 4.527659574468086e-06,
      "loss": 0.0524,
      "step": 7739
    },
    {
      "epoch": 1.7784926470588234,
      "grad_norm": 1.065212368965149,
      "learning_rate": 4.526808510638298e-06,
      "loss": 0.0715,
      "step": 7740
    },
    {
      "epoch": 1.7787224264705883,
      "grad_norm": 1.0399330854415894,
      "learning_rate": 4.525957446808511e-06,
      "loss": 0.0637,
      "step": 7741
    },
    {
      "epoch": 1.7789522058823528,
      "grad_norm": 1.502988338470459,
      "learning_rate": 4.525106382978724e-06,
      "loss": 0.0804,
      "step": 7742
    },
    {
      "epoch": 1.7791819852941178,
      "grad_norm": 1.2211264371871948,
      "learning_rate": 4.524255319148937e-06,
      "loss": 0.0568,
      "step": 7743
    },
    {
      "epoch": 1.7794117647058822,
      "grad_norm": 1.4083034992218018,
      "learning_rate": 4.523404255319149e-06,
      "loss": 0.1093,
      "step": 7744
    },
    {
      "epoch": 1.7796415441176472,
      "grad_norm": 1.49360191822052,
      "learning_rate": 4.522553191489362e-06,
      "loss": 0.0756,
      "step": 7745
    },
    {
      "epoch": 1.7798713235294117,
      "grad_norm": 1.1381574869155884,
      "learning_rate": 4.5217021276595744e-06,
      "loss": 0.0842,
      "step": 7746
    },
    {
      "epoch": 1.7801011029411766,
      "grad_norm": 1.733152985572815,
      "learning_rate": 4.520851063829788e-06,
      "loss": 0.1002,
      "step": 7747
    },
    {
      "epoch": 1.7803308823529411,
      "grad_norm": 1.3688923120498657,
      "learning_rate": 4.520000000000001e-06,
      "loss": 0.0624,
      "step": 7748
    },
    {
      "epoch": 1.7805606617647058,
      "grad_norm": 1.5309727191925049,
      "learning_rate": 4.519148936170213e-06,
      "loss": 0.083,
      "step": 7749
    },
    {
      "epoch": 1.7807904411764706,
      "grad_norm": 0.9694046378135681,
      "learning_rate": 4.518297872340425e-06,
      "loss": 0.0388,
      "step": 7750
    },
    {
      "epoch": 1.7810202205882353,
      "grad_norm": 1.161294937133789,
      "learning_rate": 4.517446808510639e-06,
      "loss": 0.0749,
      "step": 7751
    },
    {
      "epoch": 1.78125,
      "grad_norm": 1.3102521896362305,
      "learning_rate": 4.516595744680851e-06,
      "loss": 0.0732,
      "step": 7752
    },
    {
      "epoch": 1.7814797794117647,
      "grad_norm": 1.1901785135269165,
      "learning_rate": 4.515744680851064e-06,
      "loss": 0.1019,
      "step": 7753
    },
    {
      "epoch": 1.7817095588235294,
      "grad_norm": 1.608871340751648,
      "learning_rate": 4.514893617021277e-06,
      "loss": 0.0691,
      "step": 7754
    },
    {
      "epoch": 1.7819393382352942,
      "grad_norm": 0.7475965023040771,
      "learning_rate": 4.5140425531914896e-06,
      "loss": 0.0349,
      "step": 7755
    },
    {
      "epoch": 1.7821691176470589,
      "grad_norm": 1.2214471101760864,
      "learning_rate": 4.513191489361703e-06,
      "loss": 0.0737,
      "step": 7756
    },
    {
      "epoch": 1.7823988970588234,
      "grad_norm": 0.865750789642334,
      "learning_rate": 4.512340425531915e-06,
      "loss": 0.0415,
      "step": 7757
    },
    {
      "epoch": 1.7826286764705883,
      "grad_norm": 1.8343374729156494,
      "learning_rate": 4.511489361702128e-06,
      "loss": 0.0582,
      "step": 7758
    },
    {
      "epoch": 1.7828584558823528,
      "grad_norm": 1.1358128786087036,
      "learning_rate": 4.5106382978723406e-06,
      "loss": 0.0632,
      "step": 7759
    },
    {
      "epoch": 1.7830882352941178,
      "grad_norm": 1.163827657699585,
      "learning_rate": 4.509787234042554e-06,
      "loss": 0.0507,
      "step": 7760
    },
    {
      "epoch": 1.7833180147058822,
      "grad_norm": 1.1555343866348267,
      "learning_rate": 4.508936170212767e-06,
      "loss": 0.0732,
      "step": 7761
    },
    {
      "epoch": 1.7835477941176472,
      "grad_norm": 0.9997494220733643,
      "learning_rate": 4.508085106382979e-06,
      "loss": 0.0837,
      "step": 7762
    },
    {
      "epoch": 1.7837775735294117,
      "grad_norm": 1.1001121997833252,
      "learning_rate": 4.5072340425531916e-06,
      "loss": 0.0635,
      "step": 7763
    },
    {
      "epoch": 1.7840073529411766,
      "grad_norm": 1.249834656715393,
      "learning_rate": 4.506382978723405e-06,
      "loss": 0.0834,
      "step": 7764
    },
    {
      "epoch": 1.7842371323529411,
      "grad_norm": 1.033813714981079,
      "learning_rate": 4.505531914893617e-06,
      "loss": 0.0834,
      "step": 7765
    },
    {
      "epoch": 1.7844669117647058,
      "grad_norm": 1.1440460681915283,
      "learning_rate": 4.50468085106383e-06,
      "loss": 0.0798,
      "step": 7766
    },
    {
      "epoch": 1.7846966911764706,
      "grad_norm": 1.1735118627548218,
      "learning_rate": 4.503829787234043e-06,
      "loss": 0.0655,
      "step": 7767
    },
    {
      "epoch": 1.7849264705882353,
      "grad_norm": 0.9484632015228271,
      "learning_rate": 4.502978723404256e-06,
      "loss": 0.0553,
      "step": 7768
    },
    {
      "epoch": 1.78515625,
      "grad_norm": 1.0790009498596191,
      "learning_rate": 4.502127659574468e-06,
      "loss": 0.0673,
      "step": 7769
    },
    {
      "epoch": 1.7853860294117647,
      "grad_norm": 1.183692216873169,
      "learning_rate": 4.501276595744681e-06,
      "loss": 0.0446,
      "step": 7770
    },
    {
      "epoch": 1.7856158088235294,
      "grad_norm": 1.2601677179336548,
      "learning_rate": 4.5004255319148935e-06,
      "loss": 0.0814,
      "step": 7771
    },
    {
      "epoch": 1.7858455882352942,
      "grad_norm": 1.1756259202957153,
      "learning_rate": 4.499574468085107e-06,
      "loss": 0.0575,
      "step": 7772
    },
    {
      "epoch": 1.7860753676470589,
      "grad_norm": 1.9358803033828735,
      "learning_rate": 4.49872340425532e-06,
      "loss": 0.0702,
      "step": 7773
    },
    {
      "epoch": 1.7863051470588234,
      "grad_norm": 1.3268983364105225,
      "learning_rate": 4.497872340425532e-06,
      "loss": 0.0627,
      "step": 7774
    },
    {
      "epoch": 1.7865349264705883,
      "grad_norm": 1.0913549661636353,
      "learning_rate": 4.497021276595745e-06,
      "loss": 0.0808,
      "step": 7775
    },
    {
      "epoch": 1.7867647058823528,
      "grad_norm": 1.4066901206970215,
      "learning_rate": 4.496170212765958e-06,
      "loss": 0.0762,
      "step": 7776
    },
    {
      "epoch": 1.7869944852941178,
      "grad_norm": 1.6977851390838623,
      "learning_rate": 4.495319148936171e-06,
      "loss": 0.0841,
      "step": 7777
    },
    {
      "epoch": 1.7872242647058822,
      "grad_norm": 1.1251676082611084,
      "learning_rate": 4.494468085106383e-06,
      "loss": 0.0827,
      "step": 7778
    },
    {
      "epoch": 1.7874540441176472,
      "grad_norm": 1.657429575920105,
      "learning_rate": 4.493617021276596e-06,
      "loss": 0.1041,
      "step": 7779
    },
    {
      "epoch": 1.7876838235294117,
      "grad_norm": 1.1642898321151733,
      "learning_rate": 4.4927659574468095e-06,
      "loss": 0.0505,
      "step": 7780
    },
    {
      "epoch": 1.7879136029411766,
      "grad_norm": 1.1021393537521362,
      "learning_rate": 4.491914893617022e-06,
      "loss": 0.075,
      "step": 7781
    },
    {
      "epoch": 1.7881433823529411,
      "grad_norm": 1.2321274280548096,
      "learning_rate": 4.491063829787234e-06,
      "loss": 0.09,
      "step": 7782
    },
    {
      "epoch": 1.7883731617647058,
      "grad_norm": 1.3061673641204834,
      "learning_rate": 4.490212765957447e-06,
      "loss": 0.1035,
      "step": 7783
    },
    {
      "epoch": 1.7886029411764706,
      "grad_norm": 1.5254384279251099,
      "learning_rate": 4.48936170212766e-06,
      "loss": 0.0643,
      "step": 7784
    },
    {
      "epoch": 1.7888327205882353,
      "grad_norm": 1.229455590248108,
      "learning_rate": 4.488510638297873e-06,
      "loss": 0.0832,
      "step": 7785
    },
    {
      "epoch": 1.7890625,
      "grad_norm": 1.1998130083084106,
      "learning_rate": 4.487659574468086e-06,
      "loss": 0.0721,
      "step": 7786
    },
    {
      "epoch": 1.7892922794117647,
      "grad_norm": 1.079325795173645,
      "learning_rate": 4.486808510638298e-06,
      "loss": 0.0616,
      "step": 7787
    },
    {
      "epoch": 1.7895220588235294,
      "grad_norm": 1.198968529701233,
      "learning_rate": 4.485957446808511e-06,
      "loss": 0.0796,
      "step": 7788
    },
    {
      "epoch": 1.7897518382352942,
      "grad_norm": 0.7134273052215576,
      "learning_rate": 4.485106382978724e-06,
      "loss": 0.0563,
      "step": 7789
    },
    {
      "epoch": 1.7899816176470589,
      "grad_norm": 1.1888154745101929,
      "learning_rate": 4.484255319148936e-06,
      "loss": 0.0713,
      "step": 7790
    },
    {
      "epoch": 1.7902113970588234,
      "grad_norm": 1.0977824926376343,
      "learning_rate": 4.483404255319149e-06,
      "loss": 0.0666,
      "step": 7791
    },
    {
      "epoch": 1.7904411764705883,
      "grad_norm": 1.2666759490966797,
      "learning_rate": 4.4825531914893625e-06,
      "loss": 0.0627,
      "step": 7792
    },
    {
      "epoch": 1.7906709558823528,
      "grad_norm": 1.1488635540008545,
      "learning_rate": 4.481702127659575e-06,
      "loss": 0.0577,
      "step": 7793
    },
    {
      "epoch": 1.7909007352941178,
      "grad_norm": 1.2835606336593628,
      "learning_rate": 4.480851063829787e-06,
      "loss": 0.0948,
      "step": 7794
    },
    {
      "epoch": 1.7911305147058822,
      "grad_norm": 1.325120210647583,
      "learning_rate": 4.48e-06,
      "loss": 0.0823,
      "step": 7795
    },
    {
      "epoch": 1.7913602941176472,
      "grad_norm": 1.6782844066619873,
      "learning_rate": 4.4791489361702135e-06,
      "loss": 0.0924,
      "step": 7796
    },
    {
      "epoch": 1.7915900735294117,
      "grad_norm": 1.7872620820999146,
      "learning_rate": 4.478297872340426e-06,
      "loss": 0.0805,
      "step": 7797
    },
    {
      "epoch": 1.7918198529411766,
      "grad_norm": 1.1597026586532593,
      "learning_rate": 4.477446808510639e-06,
      "loss": 0.0866,
      "step": 7798
    },
    {
      "epoch": 1.7920496323529411,
      "grad_norm": 1.2283296585083008,
      "learning_rate": 4.476595744680851e-06,
      "loss": 0.0848,
      "step": 7799
    },
    {
      "epoch": 1.7922794117647058,
      "grad_norm": 1.2901599407196045,
      "learning_rate": 4.4757446808510645e-06,
      "loss": 0.0745,
      "step": 7800
    },
    {
      "epoch": 1.7925091911764706,
      "grad_norm": 1.3110382556915283,
      "learning_rate": 4.474893617021277e-06,
      "loss": 0.0703,
      "step": 7801
    },
    {
      "epoch": 1.7927389705882353,
      "grad_norm": 1.4136358499526978,
      "learning_rate": 4.47404255319149e-06,
      "loss": 0.0735,
      "step": 7802
    },
    {
      "epoch": 1.79296875,
      "grad_norm": 0.9210041165351868,
      "learning_rate": 4.473191489361702e-06,
      "loss": 0.0499,
      "step": 7803
    },
    {
      "epoch": 1.7931985294117647,
      "grad_norm": 2.3000729084014893,
      "learning_rate": 4.4723404255319155e-06,
      "loss": 0.0753,
      "step": 7804
    },
    {
      "epoch": 1.7934283088235294,
      "grad_norm": 1.0317645072937012,
      "learning_rate": 4.471489361702129e-06,
      "loss": 0.0542,
      "step": 7805
    },
    {
      "epoch": 1.7936580882352942,
      "grad_norm": 1.0359359979629517,
      "learning_rate": 4.470638297872341e-06,
      "loss": 0.0567,
      "step": 7806
    },
    {
      "epoch": 1.7938878676470589,
      "grad_norm": 1.6961361169815063,
      "learning_rate": 4.469787234042553e-06,
      "loss": 0.0804,
      "step": 7807
    },
    {
      "epoch": 1.7941176470588234,
      "grad_norm": 0.786823034286499,
      "learning_rate": 4.4689361702127664e-06,
      "loss": 0.0563,
      "step": 7808
    },
    {
      "epoch": 1.7943474264705883,
      "grad_norm": 1.3146408796310425,
      "learning_rate": 4.468085106382979e-06,
      "loss": 0.0674,
      "step": 7809
    },
    {
      "epoch": 1.7945772058823528,
      "grad_norm": 0.9118056893348694,
      "learning_rate": 4.467234042553192e-06,
      "loss": 0.0556,
      "step": 7810
    },
    {
      "epoch": 1.7948069852941178,
      "grad_norm": 1.3463597297668457,
      "learning_rate": 4.466382978723405e-06,
      "loss": 0.0592,
      "step": 7811
    },
    {
      "epoch": 1.7950367647058822,
      "grad_norm": 1.3328410387039185,
      "learning_rate": 4.4655319148936174e-06,
      "loss": 0.0999,
      "step": 7812
    },
    {
      "epoch": 1.7952665441176472,
      "grad_norm": 0.9474869966506958,
      "learning_rate": 4.46468085106383e-06,
      "loss": 0.0537,
      "step": 7813
    },
    {
      "epoch": 1.7954963235294117,
      "grad_norm": 1.1119848489761353,
      "learning_rate": 4.463829787234043e-06,
      "loss": 0.0482,
      "step": 7814
    },
    {
      "epoch": 1.7957261029411766,
      "grad_norm": 1.1988046169281006,
      "learning_rate": 4.462978723404255e-06,
      "loss": 0.0683,
      "step": 7815
    },
    {
      "epoch": 1.7959558823529411,
      "grad_norm": 1.53360116481781,
      "learning_rate": 4.462127659574468e-06,
      "loss": 0.0986,
      "step": 7816
    },
    {
      "epoch": 1.7961856617647058,
      "grad_norm": 1.7876219749450684,
      "learning_rate": 4.461276595744682e-06,
      "loss": 0.0948,
      "step": 7817
    },
    {
      "epoch": 1.7964154411764706,
      "grad_norm": 0.9345834255218506,
      "learning_rate": 4.460425531914894e-06,
      "loss": 0.0603,
      "step": 7818
    },
    {
      "epoch": 1.7966452205882353,
      "grad_norm": 1.011091947555542,
      "learning_rate": 4.459574468085106e-06,
      "loss": 0.0509,
      "step": 7819
    },
    {
      "epoch": 1.796875,
      "grad_norm": 1.1572606563568115,
      "learning_rate": 4.458723404255319e-06,
      "loss": 0.0778,
      "step": 7820
    },
    {
      "epoch": 1.7971047794117647,
      "grad_norm": 1.7911268472671509,
      "learning_rate": 4.4578723404255326e-06,
      "loss": 0.0693,
      "step": 7821
    },
    {
      "epoch": 1.7973345588235294,
      "grad_norm": 1.113294005393982,
      "learning_rate": 4.457021276595745e-06,
      "loss": 0.0757,
      "step": 7822
    },
    {
      "epoch": 1.7975643382352942,
      "grad_norm": 1.1078389883041382,
      "learning_rate": 4.456170212765958e-06,
      "loss": 0.0492,
      "step": 7823
    },
    {
      "epoch": 1.7977941176470589,
      "grad_norm": 1.315490484237671,
      "learning_rate": 4.45531914893617e-06,
      "loss": 0.0841,
      "step": 7824
    },
    {
      "epoch": 1.7980238970588234,
      "grad_norm": 1.0659464597702026,
      "learning_rate": 4.4544680851063836e-06,
      "loss": 0.0676,
      "step": 7825
    },
    {
      "epoch": 1.7982536764705883,
      "grad_norm": 1.5781139135360718,
      "learning_rate": 4.453617021276596e-06,
      "loss": 0.1074,
      "step": 7826
    },
    {
      "epoch": 1.7984834558823528,
      "grad_norm": 1.3162200450897217,
      "learning_rate": 4.452765957446809e-06,
      "loss": 0.0765,
      "step": 7827
    },
    {
      "epoch": 1.7987132352941178,
      "grad_norm": 1.18879234790802,
      "learning_rate": 4.451914893617021e-06,
      "loss": 0.088,
      "step": 7828
    },
    {
      "epoch": 1.7989430147058822,
      "grad_norm": 1.355814814567566,
      "learning_rate": 4.4510638297872346e-06,
      "loss": 0.0692,
      "step": 7829
    },
    {
      "epoch": 1.7991727941176472,
      "grad_norm": 0.9166048765182495,
      "learning_rate": 4.450212765957448e-06,
      "loss": 0.0586,
      "step": 7830
    },
    {
      "epoch": 1.7994025735294117,
      "grad_norm": 1.1768903732299805,
      "learning_rate": 4.44936170212766e-06,
      "loss": 0.0711,
      "step": 7831
    },
    {
      "epoch": 1.7996323529411766,
      "grad_norm": 1.0643188953399658,
      "learning_rate": 4.448510638297872e-06,
      "loss": 0.0698,
      "step": 7832
    },
    {
      "epoch": 1.7998621323529411,
      "grad_norm": 1.0812009572982788,
      "learning_rate": 4.4476595744680855e-06,
      "loss": 0.0552,
      "step": 7833
    },
    {
      "epoch": 1.8000919117647058,
      "grad_norm": 1.2592147588729858,
      "learning_rate": 4.446808510638298e-06,
      "loss": 0.0691,
      "step": 7834
    },
    {
      "epoch": 1.8003216911764706,
      "grad_norm": 1.9832080602645874,
      "learning_rate": 4.445957446808511e-06,
      "loss": 0.1363,
      "step": 7835
    },
    {
      "epoch": 1.8005514705882353,
      "grad_norm": 0.9475502967834473,
      "learning_rate": 4.445106382978724e-06,
      "loss": 0.0659,
      "step": 7836
    },
    {
      "epoch": 1.80078125,
      "grad_norm": 1.166662573814392,
      "learning_rate": 4.4442553191489365e-06,
      "loss": 0.0656,
      "step": 7837
    },
    {
      "epoch": 1.8010110294117647,
      "grad_norm": 0.8809515237808228,
      "learning_rate": 4.443404255319149e-06,
      "loss": 0.0492,
      "step": 7838
    },
    {
      "epoch": 1.8012408088235294,
      "grad_norm": 0.9146559238433838,
      "learning_rate": 4.442553191489362e-06,
      "loss": 0.0755,
      "step": 7839
    },
    {
      "epoch": 1.8014705882352942,
      "grad_norm": 1.0426959991455078,
      "learning_rate": 4.441702127659575e-06,
      "loss": 0.0732,
      "step": 7840
    },
    {
      "epoch": 1.8017003676470589,
      "grad_norm": 1.08302903175354,
      "learning_rate": 4.4408510638297875e-06,
      "loss": 0.0656,
      "step": 7841
    },
    {
      "epoch": 1.8019301470588234,
      "grad_norm": 1.274849772453308,
      "learning_rate": 4.440000000000001e-06,
      "loss": 0.0749,
      "step": 7842
    },
    {
      "epoch": 1.8021599264705883,
      "grad_norm": 1.1453533172607422,
      "learning_rate": 4.439148936170213e-06,
      "loss": 0.0801,
      "step": 7843
    },
    {
      "epoch": 1.8023897058823528,
      "grad_norm": 1.6634502410888672,
      "learning_rate": 4.438297872340425e-06,
      "loss": 0.0958,
      "step": 7844
    },
    {
      "epoch": 1.8026194852941178,
      "grad_norm": 1.1438794136047363,
      "learning_rate": 4.4374468085106385e-06,
      "loss": 0.0691,
      "step": 7845
    },
    {
      "epoch": 1.8028492647058822,
      "grad_norm": 1.4245994091033936,
      "learning_rate": 4.436595744680852e-06,
      "loss": 0.1005,
      "step": 7846
    },
    {
      "epoch": 1.8030790441176472,
      "grad_norm": 1.5529999732971191,
      "learning_rate": 4.435744680851064e-06,
      "loss": 0.0664,
      "step": 7847
    },
    {
      "epoch": 1.8033088235294117,
      "grad_norm": 1.029093623161316,
      "learning_rate": 4.434893617021277e-06,
      "loss": 0.0593,
      "step": 7848
    },
    {
      "epoch": 1.8035386029411766,
      "grad_norm": 1.3876874446868896,
      "learning_rate": 4.4340425531914895e-06,
      "loss": 0.0668,
      "step": 7849
    },
    {
      "epoch": 1.8037683823529411,
      "grad_norm": 1.0149024724960327,
      "learning_rate": 4.433191489361703e-06,
      "loss": 0.0898,
      "step": 7850
    },
    {
      "epoch": 1.8039981617647058,
      "grad_norm": 1.0556106567382812,
      "learning_rate": 4.432340425531915e-06,
      "loss": 0.0474,
      "step": 7851
    },
    {
      "epoch": 1.8042279411764706,
      "grad_norm": 1.7921401262283325,
      "learning_rate": 4.431489361702128e-06,
      "loss": 0.0988,
      "step": 7852
    },
    {
      "epoch": 1.8044577205882353,
      "grad_norm": 2.0387120246887207,
      "learning_rate": 4.4306382978723405e-06,
      "loss": 0.063,
      "step": 7853
    },
    {
      "epoch": 1.8046875,
      "grad_norm": 1.262383222579956,
      "learning_rate": 4.429787234042554e-06,
      "loss": 0.0873,
      "step": 7854
    },
    {
      "epoch": 1.8049172794117647,
      "grad_norm": 1.2438403367996216,
      "learning_rate": 4.428936170212767e-06,
      "loss": 0.1129,
      "step": 7855
    },
    {
      "epoch": 1.8051470588235294,
      "grad_norm": 2.2528626918792725,
      "learning_rate": 4.428085106382979e-06,
      "loss": 0.1121,
      "step": 7856
    },
    {
      "epoch": 1.8053768382352942,
      "grad_norm": 1.3226122856140137,
      "learning_rate": 4.4272340425531915e-06,
      "loss": 0.0737,
      "step": 7857
    },
    {
      "epoch": 1.8056066176470589,
      "grad_norm": 1.453937292098999,
      "learning_rate": 4.426382978723405e-06,
      "loss": 0.0889,
      "step": 7858
    },
    {
      "epoch": 1.8058363970588234,
      "grad_norm": 1.7891138792037964,
      "learning_rate": 4.425531914893617e-06,
      "loss": 0.0644,
      "step": 7859
    },
    {
      "epoch": 1.8060661764705883,
      "grad_norm": 0.8916705250740051,
      "learning_rate": 4.42468085106383e-06,
      "loss": 0.0601,
      "step": 7860
    },
    {
      "epoch": 1.8062959558823528,
      "grad_norm": 1.351531744003296,
      "learning_rate": 4.423829787234043e-06,
      "loss": 0.0842,
      "step": 7861
    },
    {
      "epoch": 1.8065257352941178,
      "grad_norm": 1.6886663436889648,
      "learning_rate": 4.422978723404256e-06,
      "loss": 0.0925,
      "step": 7862
    },
    {
      "epoch": 1.8067555147058822,
      "grad_norm": 1.365169882774353,
      "learning_rate": 4.422127659574468e-06,
      "loss": 0.0791,
      "step": 7863
    },
    {
      "epoch": 1.8069852941176472,
      "grad_norm": 0.7888864874839783,
      "learning_rate": 4.421276595744681e-06,
      "loss": 0.0577,
      "step": 7864
    },
    {
      "epoch": 1.8072150735294117,
      "grad_norm": 0.9981836080551147,
      "learning_rate": 4.420425531914894e-06,
      "loss": 0.0731,
      "step": 7865
    },
    {
      "epoch": 1.8074448529411766,
      "grad_norm": 1.4255704879760742,
      "learning_rate": 4.419574468085107e-06,
      "loss": 0.0725,
      "step": 7866
    },
    {
      "epoch": 1.8076746323529411,
      "grad_norm": 1.8467527627944946,
      "learning_rate": 4.41872340425532e-06,
      "loss": 0.0611,
      "step": 7867
    },
    {
      "epoch": 1.8079044117647058,
      "grad_norm": 1.876015543937683,
      "learning_rate": 4.417872340425532e-06,
      "loss": 0.0823,
      "step": 7868
    },
    {
      "epoch": 1.8081341911764706,
      "grad_norm": 0.8939349055290222,
      "learning_rate": 4.417021276595745e-06,
      "loss": 0.0799,
      "step": 7869
    },
    {
      "epoch": 1.8083639705882353,
      "grad_norm": 1.8413567543029785,
      "learning_rate": 4.416170212765958e-06,
      "loss": 0.0666,
      "step": 7870
    },
    {
      "epoch": 1.80859375,
      "grad_norm": 1.3598390817642212,
      "learning_rate": 4.415319148936171e-06,
      "loss": 0.0722,
      "step": 7871
    },
    {
      "epoch": 1.8088235294117647,
      "grad_norm": 1.6955991983413696,
      "learning_rate": 4.414468085106383e-06,
      "loss": 0.0872,
      "step": 7872
    },
    {
      "epoch": 1.8090533088235294,
      "grad_norm": 1.340875267982483,
      "learning_rate": 4.413617021276596e-06,
      "loss": 0.0894,
      "step": 7873
    },
    {
      "epoch": 1.8092830882352942,
      "grad_norm": 1.0050544738769531,
      "learning_rate": 4.4127659574468094e-06,
      "loss": 0.0616,
      "step": 7874
    },
    {
      "epoch": 1.8095128676470589,
      "grad_norm": 1.0934985876083374,
      "learning_rate": 4.411914893617022e-06,
      "loss": 0.058,
      "step": 7875
    },
    {
      "epoch": 1.8097426470588234,
      "grad_norm": 1.1537694931030273,
      "learning_rate": 4.411063829787234e-06,
      "loss": 0.0747,
      "step": 7876
    },
    {
      "epoch": 1.8099724264705883,
      "grad_norm": 1.3608149290084839,
      "learning_rate": 4.410212765957447e-06,
      "loss": 0.0923,
      "step": 7877
    },
    {
      "epoch": 1.8102022058823528,
      "grad_norm": 1.5612261295318604,
      "learning_rate": 4.40936170212766e-06,
      "loss": 0.0836,
      "step": 7878
    },
    {
      "epoch": 1.8104319852941178,
      "grad_norm": 1.0917894840240479,
      "learning_rate": 4.408510638297873e-06,
      "loss": 0.0695,
      "step": 7879
    },
    {
      "epoch": 1.8106617647058822,
      "grad_norm": 1.2134124040603638,
      "learning_rate": 4.407659574468086e-06,
      "loss": 0.0533,
      "step": 7880
    },
    {
      "epoch": 1.8108915441176472,
      "grad_norm": 1.20493483543396,
      "learning_rate": 4.406808510638298e-06,
      "loss": 0.0662,
      "step": 7881
    },
    {
      "epoch": 1.8111213235294117,
      "grad_norm": 1.297832727432251,
      "learning_rate": 4.4059574468085106e-06,
      "loss": 0.0611,
      "step": 7882
    },
    {
      "epoch": 1.8113511029411766,
      "grad_norm": 1.3741461038589478,
      "learning_rate": 4.405106382978724e-06,
      "loss": 0.0884,
      "step": 7883
    },
    {
      "epoch": 1.8115808823529411,
      "grad_norm": 1.4892488718032837,
      "learning_rate": 4.404255319148937e-06,
      "loss": 0.0753,
      "step": 7884
    },
    {
      "epoch": 1.8118106617647058,
      "grad_norm": 1.29318106174469,
      "learning_rate": 4.403404255319149e-06,
      "loss": 0.0819,
      "step": 7885
    },
    {
      "epoch": 1.8120404411764706,
      "grad_norm": 0.9852498769760132,
      "learning_rate": 4.402553191489362e-06,
      "loss": 0.0758,
      "step": 7886
    },
    {
      "epoch": 1.8122702205882353,
      "grad_norm": 1.2544865608215332,
      "learning_rate": 4.401702127659575e-06,
      "loss": 0.0609,
      "step": 7887
    },
    {
      "epoch": 1.8125,
      "grad_norm": 0.9799554347991943,
      "learning_rate": 4.400851063829787e-06,
      "loss": 0.0463,
      "step": 7888
    },
    {
      "epoch": 1.8127297794117647,
      "grad_norm": 1.179058313369751,
      "learning_rate": 4.4e-06,
      "loss": 0.0924,
      "step": 7889
    },
    {
      "epoch": 1.8129595588235294,
      "grad_norm": 1.4898284673690796,
      "learning_rate": 4.399148936170213e-06,
      "loss": 0.0541,
      "step": 7890
    },
    {
      "epoch": 1.8131893382352942,
      "grad_norm": 1.4235435724258423,
      "learning_rate": 4.398297872340426e-06,
      "loss": 0.0869,
      "step": 7891
    },
    {
      "epoch": 1.8134191176470589,
      "grad_norm": 1.1659986972808838,
      "learning_rate": 4.397446808510639e-06,
      "loss": 0.0609,
      "step": 7892
    },
    {
      "epoch": 1.8136488970588234,
      "grad_norm": 1.310792088508606,
      "learning_rate": 4.396595744680851e-06,
      "loss": 0.053,
      "step": 7893
    },
    {
      "epoch": 1.8138786764705883,
      "grad_norm": 0.8101825714111328,
      "learning_rate": 4.395744680851064e-06,
      "loss": 0.0501,
      "step": 7894
    },
    {
      "epoch": 1.8141084558823528,
      "grad_norm": 1.1585465669631958,
      "learning_rate": 4.394893617021277e-06,
      "loss": 0.0567,
      "step": 7895
    },
    {
      "epoch": 1.8143382352941178,
      "grad_norm": 1.1098389625549316,
      "learning_rate": 4.39404255319149e-06,
      "loss": 0.0874,
      "step": 7896
    },
    {
      "epoch": 1.8145680147058822,
      "grad_norm": 1.3504225015640259,
      "learning_rate": 4.393191489361702e-06,
      "loss": 0.0625,
      "step": 7897
    },
    {
      "epoch": 1.8147977941176472,
      "grad_norm": 1.1706187725067139,
      "learning_rate": 4.392340425531915e-06,
      "loss": 0.0818,
      "step": 7898
    },
    {
      "epoch": 1.8150275735294117,
      "grad_norm": 1.6158918142318726,
      "learning_rate": 4.3914893617021285e-06,
      "loss": 0.0858,
      "step": 7899
    },
    {
      "epoch": 1.8152573529411766,
      "grad_norm": 2.9415063858032227,
      "learning_rate": 4.390638297872341e-06,
      "loss": 0.0812,
      "step": 7900
    },
    {
      "epoch": 1.8154871323529411,
      "grad_norm": 1.0658961534500122,
      "learning_rate": 4.389787234042553e-06,
      "loss": 0.0799,
      "step": 7901
    },
    {
      "epoch": 1.8157169117647058,
      "grad_norm": 1.5492340326309204,
      "learning_rate": 4.388936170212766e-06,
      "loss": 0.0682,
      "step": 7902
    },
    {
      "epoch": 1.8159466911764706,
      "grad_norm": 1.0999990701675415,
      "learning_rate": 4.3880851063829795e-06,
      "loss": 0.0587,
      "step": 7903
    },
    {
      "epoch": 1.8161764705882353,
      "grad_norm": 0.9571982026100159,
      "learning_rate": 4.387234042553192e-06,
      "loss": 0.0552,
      "step": 7904
    },
    {
      "epoch": 1.81640625,
      "grad_norm": 1.2647100687026978,
      "learning_rate": 4.386382978723405e-06,
      "loss": 0.0621,
      "step": 7905
    },
    {
      "epoch": 1.8166360294117647,
      "grad_norm": 1.1998653411865234,
      "learning_rate": 4.385531914893617e-06,
      "loss": 0.0709,
      "step": 7906
    },
    {
      "epoch": 1.8168658088235294,
      "grad_norm": 1.151267409324646,
      "learning_rate": 4.38468085106383e-06,
      "loss": 0.0497,
      "step": 7907
    },
    {
      "epoch": 1.8170955882352942,
      "grad_norm": 1.1243952512741089,
      "learning_rate": 4.383829787234043e-06,
      "loss": 0.0687,
      "step": 7908
    },
    {
      "epoch": 1.8173253676470589,
      "grad_norm": 1.0884512662887573,
      "learning_rate": 4.382978723404256e-06,
      "loss": 0.06,
      "step": 7909
    },
    {
      "epoch": 1.8175551470588234,
      "grad_norm": 0.9378911852836609,
      "learning_rate": 4.382127659574468e-06,
      "loss": 0.0677,
      "step": 7910
    },
    {
      "epoch": 1.8177849264705883,
      "grad_norm": 1.1863234043121338,
      "learning_rate": 4.3812765957446815e-06,
      "loss": 0.0778,
      "step": 7911
    },
    {
      "epoch": 1.8180147058823528,
      "grad_norm": 1.1766191720962524,
      "learning_rate": 4.380425531914894e-06,
      "loss": 0.0708,
      "step": 7912
    },
    {
      "epoch": 1.8182444852941178,
      "grad_norm": 1.7088607549667358,
      "learning_rate": 4.379574468085106e-06,
      "loss": 0.1117,
      "step": 7913
    },
    {
      "epoch": 1.8184742647058822,
      "grad_norm": 1.5779536962509155,
      "learning_rate": 4.378723404255319e-06,
      "loss": 0.1223,
      "step": 7914
    },
    {
      "epoch": 1.8187040441176472,
      "grad_norm": 1.4071011543273926,
      "learning_rate": 4.3778723404255325e-06,
      "loss": 0.0878,
      "step": 7915
    },
    {
      "epoch": 1.8189338235294117,
      "grad_norm": 0.9562119841575623,
      "learning_rate": 4.377021276595745e-06,
      "loss": 0.0542,
      "step": 7916
    },
    {
      "epoch": 1.8191636029411766,
      "grad_norm": 0.941034734249115,
      "learning_rate": 4.376170212765958e-06,
      "loss": 0.0634,
      "step": 7917
    },
    {
      "epoch": 1.8193933823529411,
      "grad_norm": 1.174966812133789,
      "learning_rate": 4.37531914893617e-06,
      "loss": 0.0711,
      "step": 7918
    },
    {
      "epoch": 1.8196231617647058,
      "grad_norm": 1.1339130401611328,
      "learning_rate": 4.3744680851063835e-06,
      "loss": 0.0613,
      "step": 7919
    },
    {
      "epoch": 1.8198529411764706,
      "grad_norm": 1.2448179721832275,
      "learning_rate": 4.373617021276596e-06,
      "loss": 0.0858,
      "step": 7920
    },
    {
      "epoch": 1.8200827205882353,
      "grad_norm": 1.0961949825286865,
      "learning_rate": 4.372765957446809e-06,
      "loss": 0.059,
      "step": 7921
    },
    {
      "epoch": 1.8203125,
      "grad_norm": 1.3859667778015137,
      "learning_rate": 4.371914893617021e-06,
      "loss": 0.0654,
      "step": 7922
    },
    {
      "epoch": 1.8205422794117647,
      "grad_norm": 0.9594873189926147,
      "learning_rate": 4.3710638297872345e-06,
      "loss": 0.0526,
      "step": 7923
    },
    {
      "epoch": 1.8207720588235294,
      "grad_norm": 0.9735073447227478,
      "learning_rate": 4.370212765957448e-06,
      "loss": 0.0647,
      "step": 7924
    },
    {
      "epoch": 1.8210018382352942,
      "grad_norm": 1.3825860023498535,
      "learning_rate": 4.36936170212766e-06,
      "loss": 0.1038,
      "step": 7925
    },
    {
      "epoch": 1.8212316176470589,
      "grad_norm": 1.0529444217681885,
      "learning_rate": 4.368510638297872e-06,
      "loss": 0.064,
      "step": 7926
    },
    {
      "epoch": 1.8214613970588234,
      "grad_norm": 1.0286372900009155,
      "learning_rate": 4.3676595744680855e-06,
      "loss": 0.105,
      "step": 7927
    },
    {
      "epoch": 1.8216911764705883,
      "grad_norm": 1.7913142442703247,
      "learning_rate": 4.366808510638299e-06,
      "loss": 0.0974,
      "step": 7928
    },
    {
      "epoch": 1.8219209558823528,
      "grad_norm": 2.169689893722534,
      "learning_rate": 4.365957446808511e-06,
      "loss": 0.0939,
      "step": 7929
    },
    {
      "epoch": 1.8221507352941178,
      "grad_norm": 1.2389060258865356,
      "learning_rate": 4.365106382978724e-06,
      "loss": 0.0825,
      "step": 7930
    },
    {
      "epoch": 1.8223805147058822,
      "grad_norm": 0.9604520201683044,
      "learning_rate": 4.3642553191489364e-06,
      "loss": 0.0551,
      "step": 7931
    },
    {
      "epoch": 1.8226102941176472,
      "grad_norm": 1.0108015537261963,
      "learning_rate": 4.363404255319149e-06,
      "loss": 0.0637,
      "step": 7932
    },
    {
      "epoch": 1.8228400735294117,
      "grad_norm": 1.5097544193267822,
      "learning_rate": 4.362553191489362e-06,
      "loss": 0.0984,
      "step": 7933
    },
    {
      "epoch": 1.8230698529411766,
      "grad_norm": 1.3103898763656616,
      "learning_rate": 4.361702127659575e-06,
      "loss": 0.0844,
      "step": 7934
    },
    {
      "epoch": 1.8232996323529411,
      "grad_norm": 1.3251967430114746,
      "learning_rate": 4.3608510638297874e-06,
      "loss": 0.0802,
      "step": 7935
    },
    {
      "epoch": 1.8235294117647058,
      "grad_norm": 1.2528523206710815,
      "learning_rate": 4.360000000000001e-06,
      "loss": 0.0655,
      "step": 7936
    },
    {
      "epoch": 1.8237591911764706,
      "grad_norm": 1.6892552375793457,
      "learning_rate": 4.359148936170213e-06,
      "loss": 0.0963,
      "step": 7937
    },
    {
      "epoch": 1.8239889705882353,
      "grad_norm": 1.4640988111495972,
      "learning_rate": 4.358297872340425e-06,
      "loss": 0.0537,
      "step": 7938
    },
    {
      "epoch": 1.82421875,
      "grad_norm": 1.0995850563049316,
      "learning_rate": 4.3574468085106384e-06,
      "loss": 0.0663,
      "step": 7939
    },
    {
      "epoch": 1.8244485294117647,
      "grad_norm": 1.2741270065307617,
      "learning_rate": 4.356595744680852e-06,
      "loss": 0.0631,
      "step": 7940
    },
    {
      "epoch": 1.8246783088235294,
      "grad_norm": 1.7749191522598267,
      "learning_rate": 4.355744680851064e-06,
      "loss": 0.0595,
      "step": 7941
    },
    {
      "epoch": 1.8249080882352942,
      "grad_norm": 1.193473219871521,
      "learning_rate": 4.354893617021277e-06,
      "loss": 0.0792,
      "step": 7942
    },
    {
      "epoch": 1.8251378676470589,
      "grad_norm": 1.2348201274871826,
      "learning_rate": 4.354042553191489e-06,
      "loss": 0.105,
      "step": 7943
    },
    {
      "epoch": 1.8253676470588234,
      "grad_norm": 1.3013094663619995,
      "learning_rate": 4.353191489361703e-06,
      "loss": 0.0685,
      "step": 7944
    },
    {
      "epoch": 1.8255974264705883,
      "grad_norm": 1.4385652542114258,
      "learning_rate": 4.352340425531915e-06,
      "loss": 0.1016,
      "step": 7945
    },
    {
      "epoch": 1.8258272058823528,
      "grad_norm": 1.121064305305481,
      "learning_rate": 4.351489361702128e-06,
      "loss": 0.0677,
      "step": 7946
    },
    {
      "epoch": 1.8260569852941178,
      "grad_norm": 1.5798488855361938,
      "learning_rate": 4.350638297872341e-06,
      "loss": 0.093,
      "step": 7947
    },
    {
      "epoch": 1.8262867647058822,
      "grad_norm": 0.9821149110794067,
      "learning_rate": 4.3497872340425536e-06,
      "loss": 0.0668,
      "step": 7948
    },
    {
      "epoch": 1.8265165441176472,
      "grad_norm": 1.019730806350708,
      "learning_rate": 4.348936170212767e-06,
      "loss": 0.0529,
      "step": 7949
    },
    {
      "epoch": 1.8267463235294117,
      "grad_norm": 1.4252607822418213,
      "learning_rate": 4.348085106382979e-06,
      "loss": 0.1042,
      "step": 7950
    },
    {
      "epoch": 1.8269761029411766,
      "grad_norm": 1.817652702331543,
      "learning_rate": 4.347234042553191e-06,
      "loss": 0.0974,
      "step": 7951
    },
    {
      "epoch": 1.8272058823529411,
      "grad_norm": 1.3676000833511353,
      "learning_rate": 4.3463829787234046e-06,
      "loss": 0.064,
      "step": 7952
    },
    {
      "epoch": 1.8274356617647058,
      "grad_norm": 0.9647156000137329,
      "learning_rate": 4.345531914893618e-06,
      "loss": 0.0634,
      "step": 7953
    },
    {
      "epoch": 1.8276654411764706,
      "grad_norm": 1.1460084915161133,
      "learning_rate": 4.34468085106383e-06,
      "loss": 0.0814,
      "step": 7954
    },
    {
      "epoch": 1.8278952205882353,
      "grad_norm": 1.475728154182434,
      "learning_rate": 4.343829787234043e-06,
      "loss": 0.0945,
      "step": 7955
    },
    {
      "epoch": 1.828125,
      "grad_norm": 1.168711543083191,
      "learning_rate": 4.3429787234042555e-06,
      "loss": 0.0897,
      "step": 7956
    },
    {
      "epoch": 1.8283547794117647,
      "grad_norm": 1.3386486768722534,
      "learning_rate": 4.342127659574468e-06,
      "loss": 0.0799,
      "step": 7957
    },
    {
      "epoch": 1.8285845588235294,
      "grad_norm": 1.0604339838027954,
      "learning_rate": 4.341276595744681e-06,
      "loss": 0.0933,
      "step": 7958
    },
    {
      "epoch": 1.8288143382352942,
      "grad_norm": 1.09946870803833,
      "learning_rate": 4.340425531914894e-06,
      "loss": 0.0576,
      "step": 7959
    },
    {
      "epoch": 1.8290441176470589,
      "grad_norm": 1.8314259052276611,
      "learning_rate": 4.3395744680851065e-06,
      "loss": 0.0869,
      "step": 7960
    },
    {
      "epoch": 1.8292738970588234,
      "grad_norm": 1.480048418045044,
      "learning_rate": 4.33872340425532e-06,
      "loss": 0.0831,
      "step": 7961
    },
    {
      "epoch": 1.8295036764705883,
      "grad_norm": 0.9820500612258911,
      "learning_rate": 4.337872340425532e-06,
      "loss": 0.0843,
      "step": 7962
    },
    {
      "epoch": 1.8297334558823528,
      "grad_norm": 1.4791972637176514,
      "learning_rate": 4.337021276595745e-06,
      "loss": 0.0662,
      "step": 7963
    },
    {
      "epoch": 1.8299632352941178,
      "grad_norm": 1.23518705368042,
      "learning_rate": 4.3361702127659575e-06,
      "loss": 0.083,
      "step": 7964
    },
    {
      "epoch": 1.8301930147058822,
      "grad_norm": 1.245200753211975,
      "learning_rate": 4.335319148936171e-06,
      "loss": 0.0645,
      "step": 7965
    },
    {
      "epoch": 1.8304227941176472,
      "grad_norm": Infinity,
      "learning_rate": 4.334468085106383e-06,
      "loss": 0.081,
      "step": 7966
    },
    {
      "epoch": 1.8306525735294117,
      "grad_norm": 1.3631737232208252,
      "learning_rate": 4.334468085106383e-06,
      "loss": 0.0832,
      "step": 7967
    },
    {
      "epoch": 1.8308823529411766,
      "grad_norm": 1.5531660318374634,
      "learning_rate": 4.333617021276596e-06,
      "loss": 0.0729,
      "step": 7968
    },
    {
      "epoch": 1.8311121323529411,
      "grad_norm": 1.5149229764938354,
      "learning_rate": 4.332765957446809e-06,
      "loss": 0.0727,
      "step": 7969
    },
    {
      "epoch": 1.8313419117647058,
      "grad_norm": 2.2130608558654785,
      "learning_rate": 4.331914893617022e-06,
      "loss": 0.1465,
      "step": 7970
    },
    {
      "epoch": 1.8315716911764706,
      "grad_norm": 1.8904207944869995,
      "learning_rate": 4.331063829787234e-06,
      "loss": 0.1045,
      "step": 7971
    },
    {
      "epoch": 1.8318014705882353,
      "grad_norm": 1.1188987493515015,
      "learning_rate": 4.330212765957447e-06,
      "loss": 0.067,
      "step": 7972
    },
    {
      "epoch": 1.83203125,
      "grad_norm": 1.7824913263320923,
      "learning_rate": 4.32936170212766e-06,
      "loss": 0.0915,
      "step": 7973
    },
    {
      "epoch": 1.8322610294117647,
      "grad_norm": 1.0359375476837158,
      "learning_rate": 4.328510638297873e-06,
      "loss": 0.0663,
      "step": 7974
    },
    {
      "epoch": 1.8324908088235294,
      "grad_norm": 0.9136142730712891,
      "learning_rate": 4.327659574468086e-06,
      "loss": 0.0418,
      "step": 7975
    },
    {
      "epoch": 1.8327205882352942,
      "grad_norm": 1.3265334367752075,
      "learning_rate": 4.326808510638298e-06,
      "loss": 0.0636,
      "step": 7976
    },
    {
      "epoch": 1.8329503676470589,
      "grad_norm": 1.0783356428146362,
      "learning_rate": 4.3259574468085105e-06,
      "loss": 0.079,
      "step": 7977
    },
    {
      "epoch": 1.8331801470588234,
      "grad_norm": 1.0986067056655884,
      "learning_rate": 4.325106382978724e-06,
      "loss": 0.0762,
      "step": 7978
    },
    {
      "epoch": 1.8334099264705883,
      "grad_norm": 1.2901089191436768,
      "learning_rate": 4.324255319148937e-06,
      "loss": 0.0804,
      "step": 7979
    },
    {
      "epoch": 1.8336397058823528,
      "grad_norm": 1.1319223642349243,
      "learning_rate": 4.323404255319149e-06,
      "loss": 0.0652,
      "step": 7980
    },
    {
      "epoch": 1.8338694852941178,
      "grad_norm": 1.278952717781067,
      "learning_rate": 4.322553191489362e-06,
      "loss": 0.0887,
      "step": 7981
    },
    {
      "epoch": 1.8340992647058822,
      "grad_norm": 1.0958929061889648,
      "learning_rate": 4.321702127659575e-06,
      "loss": 0.0845,
      "step": 7982
    },
    {
      "epoch": 1.8343290441176472,
      "grad_norm": 1.6155531406402588,
      "learning_rate": 4.320851063829787e-06,
      "loss": 0.1009,
      "step": 7983
    },
    {
      "epoch": 1.8345588235294117,
      "grad_norm": 1.127184510231018,
      "learning_rate": 4.32e-06,
      "loss": 0.0627,
      "step": 7984
    },
    {
      "epoch": 1.8347886029411766,
      "grad_norm": 1.2441620826721191,
      "learning_rate": 4.319148936170213e-06,
      "loss": 0.0725,
      "step": 7985
    },
    {
      "epoch": 1.8350183823529411,
      "grad_norm": 1.1605403423309326,
      "learning_rate": 4.318297872340426e-06,
      "loss": 0.0863,
      "step": 7986
    },
    {
      "epoch": 1.8352481617647058,
      "grad_norm": 1.1038508415222168,
      "learning_rate": 4.317446808510639e-06,
      "loss": 0.0639,
      "step": 7987
    },
    {
      "epoch": 1.8354779411764706,
      "grad_norm": 2.6803908348083496,
      "learning_rate": 4.316595744680851e-06,
      "loss": 0.0854,
      "step": 7988
    },
    {
      "epoch": 1.8357077205882353,
      "grad_norm": 1.5543469190597534,
      "learning_rate": 4.315744680851064e-06,
      "loss": 0.1188,
      "step": 7989
    },
    {
      "epoch": 1.8359375,
      "grad_norm": 1.2191336154937744,
      "learning_rate": 4.314893617021277e-06,
      "loss": 0.0747,
      "step": 7990
    },
    {
      "epoch": 1.8361672794117647,
      "grad_norm": 0.8945454359054565,
      "learning_rate": 4.31404255319149e-06,
      "loss": 0.0567,
      "step": 7991
    },
    {
      "epoch": 1.8363970588235294,
      "grad_norm": 1.085513710975647,
      "learning_rate": 4.313191489361703e-06,
      "loss": 0.0566,
      "step": 7992
    },
    {
      "epoch": 1.8366268382352942,
      "grad_norm": 1.2195065021514893,
      "learning_rate": 4.312340425531915e-06,
      "loss": 0.0705,
      "step": 7993
    },
    {
      "epoch": 1.8368566176470589,
      "grad_norm": 0.7968612313270569,
      "learning_rate": 4.3114893617021285e-06,
      "loss": 0.0463,
      "step": 7994
    },
    {
      "epoch": 1.8370863970588234,
      "grad_norm": 1.362599492073059,
      "learning_rate": 4.310638297872341e-06,
      "loss": 0.0903,
      "step": 7995
    },
    {
      "epoch": 1.8373161764705883,
      "grad_norm": 1.0359165668487549,
      "learning_rate": 4.309787234042553e-06,
      "loss": 0.0603,
      "step": 7996
    },
    {
      "epoch": 1.8375459558823528,
      "grad_norm": 1.324534296989441,
      "learning_rate": 4.308936170212766e-06,
      "loss": 0.0965,
      "step": 7997
    },
    {
      "epoch": 1.8377757352941178,
      "grad_norm": 1.3768627643585205,
      "learning_rate": 4.3080851063829794e-06,
      "loss": 0.0745,
      "step": 7998
    },
    {
      "epoch": 1.8380055147058822,
      "grad_norm": 0.8637180924415588,
      "learning_rate": 4.307234042553192e-06,
      "loss": 0.0557,
      "step": 7999
    },
    {
      "epoch": 1.8382352941176472,
      "grad_norm": 1.1712712049484253,
      "learning_rate": 4.306382978723405e-06,
      "loss": 0.0649,
      "step": 8000
    },
    {
      "epoch": 1.8382352941176472,
      "eval_loss": 0.07840580493211746,
      "eval_runtime": 1964.196,
      "eval_samples_per_second": 4.534,
      "eval_steps_per_second": 2.267,
      "step": 8000
    },
    {
      "epoch": 1.8384650735294117,
      "grad_norm": 1.5210416316986084,
      "learning_rate": 4.305531914893617e-06,
      "loss": 0.0904,
      "step": 8001
    },
    {
      "epoch": 1.8386948529411766,
      "grad_norm": 1.6130633354187012,
      "learning_rate": 4.30468085106383e-06,
      "loss": 0.0991,
      "step": 8002
    },
    {
      "epoch": 1.8389246323529411,
      "grad_norm": 1.2279256582260132,
      "learning_rate": 4.303829787234043e-06,
      "loss": 0.0601,
      "step": 8003
    },
    {
      "epoch": 1.8391544117647058,
      "grad_norm": 1.0143812894821167,
      "learning_rate": 4.302978723404256e-06,
      "loss": 0.0542,
      "step": 8004
    },
    {
      "epoch": 1.8393841911764706,
      "grad_norm": 1.5552539825439453,
      "learning_rate": 4.302127659574468e-06,
      "loss": 0.1114,
      "step": 8005
    },
    {
      "epoch": 1.8396139705882353,
      "grad_norm": 1.1837602853775024,
      "learning_rate": 4.3012765957446814e-06,
      "loss": 0.0787,
      "step": 8006
    },
    {
      "epoch": 1.83984375,
      "grad_norm": 1.6515558958053589,
      "learning_rate": 4.300425531914894e-06,
      "loss": 0.101,
      "step": 8007
    },
    {
      "epoch": 1.8400735294117647,
      "grad_norm": 0.9941765069961548,
      "learning_rate": 4.299574468085106e-06,
      "loss": 0.0789,
      "step": 8008
    },
    {
      "epoch": 1.8403033088235294,
      "grad_norm": 1.0707114934921265,
      "learning_rate": 4.298723404255319e-06,
      "loss": 0.0609,
      "step": 8009
    },
    {
      "epoch": 1.8405330882352942,
      "grad_norm": 1.2282239198684692,
      "learning_rate": 4.297872340425532e-06,
      "loss": 0.0884,
      "step": 8010
    },
    {
      "epoch": 1.8407628676470589,
      "grad_norm": 1.258591651916504,
      "learning_rate": 4.297021276595746e-06,
      "loss": 0.0768,
      "step": 8011
    },
    {
      "epoch": 1.8409926470588234,
      "grad_norm": 1.25272536277771,
      "learning_rate": 4.296170212765958e-06,
      "loss": 0.0964,
      "step": 8012
    },
    {
      "epoch": 1.8412224264705883,
      "grad_norm": 1.1681970357894897,
      "learning_rate": 4.29531914893617e-06,
      "loss": 0.0805,
      "step": 8013
    },
    {
      "epoch": 1.8414522058823528,
      "grad_norm": 1.2992228269577026,
      "learning_rate": 4.294468085106383e-06,
      "loss": 0.0899,
      "step": 8014
    },
    {
      "epoch": 1.8416819852941178,
      "grad_norm": 1.3191672563552856,
      "learning_rate": 4.293617021276596e-06,
      "loss": 0.0739,
      "step": 8015
    },
    {
      "epoch": 1.8419117647058822,
      "grad_norm": 1.3507782220840454,
      "learning_rate": 4.292765957446809e-06,
      "loss": 0.0907,
      "step": 8016
    },
    {
      "epoch": 1.8421415441176472,
      "grad_norm": 1.3367705345153809,
      "learning_rate": 4.291914893617022e-06,
      "loss": 0.0755,
      "step": 8017
    },
    {
      "epoch": 1.8423713235294117,
      "grad_norm": 1.3342950344085693,
      "learning_rate": 4.291063829787234e-06,
      "loss": 0.0785,
      "step": 8018
    },
    {
      "epoch": 1.8426011029411766,
      "grad_norm": 1.3684417009353638,
      "learning_rate": 4.2902127659574476e-06,
      "loss": 0.0845,
      "step": 8019
    },
    {
      "epoch": 1.8428308823529411,
      "grad_norm": 0.9636107087135315,
      "learning_rate": 4.28936170212766e-06,
      "loss": 0.0663,
      "step": 8020
    },
    {
      "epoch": 1.8430606617647058,
      "grad_norm": 1.0255354642868042,
      "learning_rate": 4.288510638297872e-06,
      "loss": 0.0456,
      "step": 8021
    },
    {
      "epoch": 1.8432904411764706,
      "grad_norm": 1.1376680135726929,
      "learning_rate": 4.287659574468085e-06,
      "loss": 0.0688,
      "step": 8022
    },
    {
      "epoch": 1.8435202205882353,
      "grad_norm": 1.1921738386154175,
      "learning_rate": 4.2868085106382985e-06,
      "loss": 0.098,
      "step": 8023
    },
    {
      "epoch": 1.84375,
      "grad_norm": 0.9939579367637634,
      "learning_rate": 4.285957446808511e-06,
      "loss": 0.0715,
      "step": 8024
    },
    {
      "epoch": 1.8439797794117647,
      "grad_norm": 1.169543743133545,
      "learning_rate": 4.285106382978724e-06,
      "loss": 0.0544,
      "step": 8025
    },
    {
      "epoch": 1.8442095588235294,
      "grad_norm": 1.3272579908370972,
      "learning_rate": 4.284255319148936e-06,
      "loss": 0.0617,
      "step": 8026
    },
    {
      "epoch": 1.8444393382352942,
      "grad_norm": 1.079649567604065,
      "learning_rate": 4.283404255319149e-06,
      "loss": 0.0767,
      "step": 8027
    },
    {
      "epoch": 1.8446691176470589,
      "grad_norm": 1.1046111583709717,
      "learning_rate": 4.282553191489362e-06,
      "loss": 0.0668,
      "step": 8028
    },
    {
      "epoch": 1.8448988970588234,
      "grad_norm": 1.4411426782608032,
      "learning_rate": 4.281702127659575e-06,
      "loss": 0.0758,
      "step": 8029
    },
    {
      "epoch": 1.8451286764705883,
      "grad_norm": 1.0185261964797974,
      "learning_rate": 4.280851063829787e-06,
      "loss": 0.0612,
      "step": 8030
    },
    {
      "epoch": 1.8453584558823528,
      "grad_norm": 1.1160272359848022,
      "learning_rate": 4.2800000000000005e-06,
      "loss": 0.0616,
      "step": 8031
    },
    {
      "epoch": 1.8455882352941178,
      "grad_norm": 1.128368854522705,
      "learning_rate": 4.279148936170213e-06,
      "loss": 0.0728,
      "step": 8032
    },
    {
      "epoch": 1.8458180147058822,
      "grad_norm": 1.5278029441833496,
      "learning_rate": 4.278297872340426e-06,
      "loss": 0.0987,
      "step": 8033
    },
    {
      "epoch": 1.8460477941176472,
      "grad_norm": 1.1806219816207886,
      "learning_rate": 4.277446808510638e-06,
      "loss": 0.0516,
      "step": 8034
    },
    {
      "epoch": 1.8462775735294117,
      "grad_norm": 1.1114414930343628,
      "learning_rate": 4.2765957446808515e-06,
      "loss": 0.0595,
      "step": 8035
    },
    {
      "epoch": 1.8465073529411766,
      "grad_norm": 1.3230870962142944,
      "learning_rate": 4.275744680851065e-06,
      "loss": 0.0813,
      "step": 8036
    },
    {
      "epoch": 1.8467371323529411,
      "grad_norm": 0.9845018982887268,
      "learning_rate": 4.274893617021277e-06,
      "loss": 0.0661,
      "step": 8037
    },
    {
      "epoch": 1.8469669117647058,
      "grad_norm": 1.3211883306503296,
      "learning_rate": 4.274042553191489e-06,
      "loss": 0.0849,
      "step": 8038
    },
    {
      "epoch": 1.8471966911764706,
      "grad_norm": 1.7780479192733765,
      "learning_rate": 4.2731914893617025e-06,
      "loss": 0.1412,
      "step": 8039
    },
    {
      "epoch": 1.8474264705882353,
      "grad_norm": 1.344017505645752,
      "learning_rate": 4.272340425531915e-06,
      "loss": 0.0652,
      "step": 8040
    },
    {
      "epoch": 1.84765625,
      "grad_norm": 1.4415735006332397,
      "learning_rate": 4.271489361702128e-06,
      "loss": 0.113,
      "step": 8041
    },
    {
      "epoch": 1.8478860294117647,
      "grad_norm": 1.2205346822738647,
      "learning_rate": 4.270638297872341e-06,
      "loss": 0.0849,
      "step": 8042
    },
    {
      "epoch": 1.8481158088235294,
      "grad_norm": 0.8468119502067566,
      "learning_rate": 4.2697872340425535e-06,
      "loss": 0.0496,
      "step": 8043
    },
    {
      "epoch": 1.8483455882352942,
      "grad_norm": 0.9477863907814026,
      "learning_rate": 4.268936170212767e-06,
      "loss": 0.0597,
      "step": 8044
    },
    {
      "epoch": 1.8485753676470589,
      "grad_norm": 1.0765914916992188,
      "learning_rate": 4.268085106382979e-06,
      "loss": 0.076,
      "step": 8045
    },
    {
      "epoch": 1.8488051470588234,
      "grad_norm": 1.2042490243911743,
      "learning_rate": 4.267234042553191e-06,
      "loss": 0.0908,
      "step": 8046
    },
    {
      "epoch": 1.8490349264705883,
      "grad_norm": 1.2249712944030762,
      "learning_rate": 4.2663829787234045e-06,
      "loss": 0.0447,
      "step": 8047
    },
    {
      "epoch": 1.8492647058823528,
      "grad_norm": 1.1590323448181152,
      "learning_rate": 4.265531914893618e-06,
      "loss": 0.0721,
      "step": 8048
    },
    {
      "epoch": 1.8494944852941178,
      "grad_norm": 1.4595589637756348,
      "learning_rate": 4.26468085106383e-06,
      "loss": 0.1093,
      "step": 8049
    },
    {
      "epoch": 1.8497242647058822,
      "grad_norm": 1.224526047706604,
      "learning_rate": 4.263829787234043e-06,
      "loss": 0.0684,
      "step": 8050
    },
    {
      "epoch": 1.8499540441176472,
      "grad_norm": 1.2679091691970825,
      "learning_rate": 4.2629787234042555e-06,
      "loss": 0.0834,
      "step": 8051
    },
    {
      "epoch": 1.8501838235294117,
      "grad_norm": 1.1800113916397095,
      "learning_rate": 4.262127659574468e-06,
      "loss": 0.078,
      "step": 8052
    },
    {
      "epoch": 1.8504136029411766,
      "grad_norm": 1.1835453510284424,
      "learning_rate": 4.261276595744681e-06,
      "loss": 0.0764,
      "step": 8053
    },
    {
      "epoch": 1.8506433823529411,
      "grad_norm": 0.9218830466270447,
      "learning_rate": 4.260425531914894e-06,
      "loss": 0.0684,
      "step": 8054
    },
    {
      "epoch": 1.8508731617647058,
      "grad_norm": 1.0269455909729004,
      "learning_rate": 4.259574468085107e-06,
      "loss": 0.0592,
      "step": 8055
    },
    {
      "epoch": 1.8511029411764706,
      "grad_norm": 1.460782527923584,
      "learning_rate": 4.25872340425532e-06,
      "loss": 0.0892,
      "step": 8056
    },
    {
      "epoch": 1.8513327205882353,
      "grad_norm": 1.265987515449524,
      "learning_rate": 4.257872340425532e-06,
      "loss": 0.0564,
      "step": 8057
    },
    {
      "epoch": 1.8515625,
      "grad_norm": 1.406031608581543,
      "learning_rate": 4.257021276595745e-06,
      "loss": 0.0651,
      "step": 8058
    },
    {
      "epoch": 1.8517922794117647,
      "grad_norm": 1.7265249490737915,
      "learning_rate": 4.2561702127659574e-06,
      "loss": 0.1023,
      "step": 8059
    },
    {
      "epoch": 1.8520220588235294,
      "grad_norm": 1.524961233139038,
      "learning_rate": 4.255319148936171e-06,
      "loss": 0.1123,
      "step": 8060
    },
    {
      "epoch": 1.8522518382352942,
      "grad_norm": 0.8674424886703491,
      "learning_rate": 4.254468085106384e-06,
      "loss": 0.0505,
      "step": 8061
    },
    {
      "epoch": 1.8524816176470589,
      "grad_norm": 1.0637385845184326,
      "learning_rate": 4.253617021276596e-06,
      "loss": 0.0685,
      "step": 8062
    },
    {
      "epoch": 1.8527113970588234,
      "grad_norm": 0.9970756769180298,
      "learning_rate": 4.252765957446809e-06,
      "loss": 0.0429,
      "step": 8063
    },
    {
      "epoch": 1.8529411764705883,
      "grad_norm": 1.2817301750183105,
      "learning_rate": 4.251914893617022e-06,
      "loss": 0.076,
      "step": 8064
    },
    {
      "epoch": 1.8531709558823528,
      "grad_norm": 1.4682542085647583,
      "learning_rate": 4.251063829787234e-06,
      "loss": 0.0655,
      "step": 8065
    },
    {
      "epoch": 1.8534007352941178,
      "grad_norm": 1.3298499584197998,
      "learning_rate": 4.250212765957447e-06,
      "loss": 0.1142,
      "step": 8066
    },
    {
      "epoch": 1.8536305147058822,
      "grad_norm": 1.4298239946365356,
      "learning_rate": 4.24936170212766e-06,
      "loss": 0.0694,
      "step": 8067
    },
    {
      "epoch": 1.8538602941176472,
      "grad_norm": 1.061980962753296,
      "learning_rate": 4.248510638297873e-06,
      "loss": 0.0683,
      "step": 8068
    },
    {
      "epoch": 1.8540900735294117,
      "grad_norm": 0.9950392842292786,
      "learning_rate": 4.247659574468086e-06,
      "loss": 0.0666,
      "step": 8069
    },
    {
      "epoch": 1.8543198529411766,
      "grad_norm": 0.920150637626648,
      "learning_rate": 4.246808510638298e-06,
      "loss": 0.061,
      "step": 8070
    },
    {
      "epoch": 1.8545496323529411,
      "grad_norm": 0.924536406993866,
      "learning_rate": 4.24595744680851e-06,
      "loss": 0.0735,
      "step": 8071
    },
    {
      "epoch": 1.8547794117647058,
      "grad_norm": 1.4242727756500244,
      "learning_rate": 4.245106382978724e-06,
      "loss": 0.0749,
      "step": 8072
    },
    {
      "epoch": 1.8550091911764706,
      "grad_norm": 1.2882094383239746,
      "learning_rate": 4.244255319148937e-06,
      "loss": 0.0474,
      "step": 8073
    },
    {
      "epoch": 1.8552389705882353,
      "grad_norm": 1.2957996129989624,
      "learning_rate": 4.243404255319149e-06,
      "loss": 0.0612,
      "step": 8074
    },
    {
      "epoch": 1.85546875,
      "grad_norm": 1.2325056791305542,
      "learning_rate": 4.242553191489362e-06,
      "loss": 0.0748,
      "step": 8075
    },
    {
      "epoch": 1.8556985294117647,
      "grad_norm": 1.4380565881729126,
      "learning_rate": 4.2417021276595746e-06,
      "loss": 0.0679,
      "step": 8076
    },
    {
      "epoch": 1.8559283088235294,
      "grad_norm": 1.0251902341842651,
      "learning_rate": 4.240851063829788e-06,
      "loss": 0.0605,
      "step": 8077
    },
    {
      "epoch": 1.8561580882352942,
      "grad_norm": 0.9788068532943726,
      "learning_rate": 4.24e-06,
      "loss": 0.0636,
      "step": 8078
    },
    {
      "epoch": 1.8563878676470589,
      "grad_norm": 1.1833446025848389,
      "learning_rate": 4.239148936170213e-06,
      "loss": 0.0648,
      "step": 8079
    },
    {
      "epoch": 1.8566176470588234,
      "grad_norm": 0.986709713935852,
      "learning_rate": 4.238297872340426e-06,
      "loss": 0.0492,
      "step": 8080
    },
    {
      "epoch": 1.8568474264705883,
      "grad_norm": 1.8998514413833618,
      "learning_rate": 4.237446808510639e-06,
      "loss": 0.0809,
      "step": 8081
    },
    {
      "epoch": 1.8570772058823528,
      "grad_norm": 1.6079927682876587,
      "learning_rate": 4.236595744680851e-06,
      "loss": 0.0961,
      "step": 8082
    },
    {
      "epoch": 1.8573069852941178,
      "grad_norm": 1.4105045795440674,
      "learning_rate": 4.235744680851064e-06,
      "loss": 0.0949,
      "step": 8083
    },
    {
      "epoch": 1.8575367647058822,
      "grad_norm": 1.1323294639587402,
      "learning_rate": 4.2348936170212765e-06,
      "loss": 0.0613,
      "step": 8084
    },
    {
      "epoch": 1.8577665441176472,
      "grad_norm": 1.1699249744415283,
      "learning_rate": 4.23404255319149e-06,
      "loss": 0.0531,
      "step": 8085
    },
    {
      "epoch": 1.8579963235294117,
      "grad_norm": 1.1614856719970703,
      "learning_rate": 4.233191489361703e-06,
      "loss": 0.0928,
      "step": 8086
    },
    {
      "epoch": 1.8582261029411766,
      "grad_norm": 1.1989905834197998,
      "learning_rate": 4.232340425531915e-06,
      "loss": 0.0717,
      "step": 8087
    },
    {
      "epoch": 1.8584558823529411,
      "grad_norm": 1.7647308111190796,
      "learning_rate": 4.231489361702128e-06,
      "loss": 0.1183,
      "step": 8088
    },
    {
      "epoch": 1.8586856617647058,
      "grad_norm": 0.9882474541664124,
      "learning_rate": 4.230638297872341e-06,
      "loss": 0.0473,
      "step": 8089
    },
    {
      "epoch": 1.8589154411764706,
      "grad_norm": 1.5494664907455444,
      "learning_rate": 4.229787234042553e-06,
      "loss": 0.0771,
      "step": 8090
    },
    {
      "epoch": 1.8591452205882353,
      "grad_norm": 1.569367527961731,
      "learning_rate": 4.228936170212766e-06,
      "loss": 0.0754,
      "step": 8091
    },
    {
      "epoch": 1.859375,
      "grad_norm": 0.9369987845420837,
      "learning_rate": 4.228085106382979e-06,
      "loss": 0.044,
      "step": 8092
    },
    {
      "epoch": 1.8596047794117647,
      "grad_norm": 1.1101739406585693,
      "learning_rate": 4.227234042553192e-06,
      "loss": 0.0832,
      "step": 8093
    },
    {
      "epoch": 1.8598345588235294,
      "grad_norm": 1.2012122869491577,
      "learning_rate": 4.226382978723405e-06,
      "loss": 0.065,
      "step": 8094
    },
    {
      "epoch": 1.8600643382352942,
      "grad_norm": 1.0961287021636963,
      "learning_rate": 4.225531914893617e-06,
      "loss": 0.0847,
      "step": 8095
    },
    {
      "epoch": 1.8602941176470589,
      "grad_norm": 1.3587931394577026,
      "learning_rate": 4.2246808510638295e-06,
      "loss": 0.0622,
      "step": 8096
    },
    {
      "epoch": 1.8605238970588234,
      "grad_norm": 1.561098575592041,
      "learning_rate": 4.223829787234043e-06,
      "loss": 0.09,
      "step": 8097
    },
    {
      "epoch": 1.8607536764705883,
      "grad_norm": 1.1825255155563354,
      "learning_rate": 4.222978723404256e-06,
      "loss": 0.0751,
      "step": 8098
    },
    {
      "epoch": 1.8609834558823528,
      "grad_norm": 1.5976673364639282,
      "learning_rate": 4.222127659574469e-06,
      "loss": 0.0541,
      "step": 8099
    },
    {
      "epoch": 1.8612132352941178,
      "grad_norm": 0.9824458956718445,
      "learning_rate": 4.221276595744681e-06,
      "loss": 0.0781,
      "step": 8100
    },
    {
      "epoch": 1.8614430147058822,
      "grad_norm": 1.3911792039871216,
      "learning_rate": 4.220425531914894e-06,
      "loss": 0.0784,
      "step": 8101
    },
    {
      "epoch": 1.8616727941176472,
      "grad_norm": 1.0575114488601685,
      "learning_rate": 4.219574468085107e-06,
      "loss": 0.0793,
      "step": 8102
    },
    {
      "epoch": 1.8619025735294117,
      "grad_norm": 1.12608802318573,
      "learning_rate": 4.218723404255319e-06,
      "loss": 0.0567,
      "step": 8103
    },
    {
      "epoch": 1.8621323529411766,
      "grad_norm": 1.3725435733795166,
      "learning_rate": 4.217872340425532e-06,
      "loss": 0.0569,
      "step": 8104
    },
    {
      "epoch": 1.8623621323529411,
      "grad_norm": 1.6578041315078735,
      "learning_rate": 4.2170212765957455e-06,
      "loss": 0.0513,
      "step": 8105
    },
    {
      "epoch": 1.8625919117647058,
      "grad_norm": 1.1849536895751953,
      "learning_rate": 4.216170212765958e-06,
      "loss": 0.0642,
      "step": 8106
    },
    {
      "epoch": 1.8628216911764706,
      "grad_norm": 1.5547467470169067,
      "learning_rate": 4.21531914893617e-06,
      "loss": 0.0917,
      "step": 8107
    },
    {
      "epoch": 1.8630514705882353,
      "grad_norm": 1.6593830585479736,
      "learning_rate": 4.214468085106383e-06,
      "loss": 0.0744,
      "step": 8108
    },
    {
      "epoch": 1.86328125,
      "grad_norm": 1.1305572986602783,
      "learning_rate": 4.213617021276596e-06,
      "loss": 0.1072,
      "step": 8109
    },
    {
      "epoch": 1.8635110294117647,
      "grad_norm": 1.0003794431686401,
      "learning_rate": 4.212765957446809e-06,
      "loss": 0.0662,
      "step": 8110
    },
    {
      "epoch": 1.8637408088235294,
      "grad_norm": 0.9506652355194092,
      "learning_rate": 4.211914893617022e-06,
      "loss": 0.0514,
      "step": 8111
    },
    {
      "epoch": 1.8639705882352942,
      "grad_norm": 1.6945207118988037,
      "learning_rate": 4.211063829787234e-06,
      "loss": 0.1079,
      "step": 8112
    },
    {
      "epoch": 1.8642003676470589,
      "grad_norm": 1.212881326675415,
      "learning_rate": 4.2102127659574475e-06,
      "loss": 0.0713,
      "step": 8113
    },
    {
      "epoch": 1.8644301470588234,
      "grad_norm": 1.3063504695892334,
      "learning_rate": 4.20936170212766e-06,
      "loss": 0.092,
      "step": 8114
    },
    {
      "epoch": 1.8646599264705883,
      "grad_norm": 1.122933030128479,
      "learning_rate": 4.208510638297872e-06,
      "loss": 0.0687,
      "step": 8115
    },
    {
      "epoch": 1.8648897058823528,
      "grad_norm": 1.2213473320007324,
      "learning_rate": 4.207659574468085e-06,
      "loss": 0.0598,
      "step": 8116
    },
    {
      "epoch": 1.8651194852941178,
      "grad_norm": 1.5216727256774902,
      "learning_rate": 4.2068085106382985e-06,
      "loss": 0.0656,
      "step": 8117
    },
    {
      "epoch": 1.8653492647058822,
      "grad_norm": 1.3322712182998657,
      "learning_rate": 4.205957446808512e-06,
      "loss": 0.0684,
      "step": 8118
    },
    {
      "epoch": 1.8655790441176472,
      "grad_norm": 1.1150236129760742,
      "learning_rate": 4.205106382978724e-06,
      "loss": 0.0743,
      "step": 8119
    },
    {
      "epoch": 1.8658088235294117,
      "grad_norm": 0.9681201577186584,
      "learning_rate": 4.204255319148936e-06,
      "loss": 0.0701,
      "step": 8120
    },
    {
      "epoch": 1.8660386029411766,
      "grad_norm": 1.4031851291656494,
      "learning_rate": 4.2034042553191495e-06,
      "loss": 0.1226,
      "step": 8121
    },
    {
      "epoch": 1.8662683823529411,
      "grad_norm": 1.38420569896698,
      "learning_rate": 4.202553191489362e-06,
      "loss": 0.0611,
      "step": 8122
    },
    {
      "epoch": 1.8664981617647058,
      "grad_norm": 1.2097678184509277,
      "learning_rate": 4.201702127659575e-06,
      "loss": 0.0768,
      "step": 8123
    },
    {
      "epoch": 1.8667279411764706,
      "grad_norm": 1.3057668209075928,
      "learning_rate": 4.200851063829788e-06,
      "loss": 0.0778,
      "step": 8124
    },
    {
      "epoch": 1.8669577205882353,
      "grad_norm": 1.4956170320510864,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 0.0734,
      "step": 8125
    },
    {
      "epoch": 1.8671875,
      "grad_norm": 1.3259172439575195,
      "learning_rate": 4.199148936170213e-06,
      "loss": 0.0844,
      "step": 8126
    },
    {
      "epoch": 1.8674172794117647,
      "grad_norm": 2.388068199157715,
      "learning_rate": 4.198297872340426e-06,
      "loss": 0.0936,
      "step": 8127
    },
    {
      "epoch": 1.8676470588235294,
      "grad_norm": 1.1877901554107666,
      "learning_rate": 4.197446808510638e-06,
      "loss": 0.09,
      "step": 8128
    },
    {
      "epoch": 1.8678768382352942,
      "grad_norm": 1.1243162155151367,
      "learning_rate": 4.1965957446808514e-06,
      "loss": 0.0963,
      "step": 8129
    },
    {
      "epoch": 1.8681066176470589,
      "grad_norm": 0.9725964069366455,
      "learning_rate": 4.195744680851065e-06,
      "loss": 0.0702,
      "step": 8130
    },
    {
      "epoch": 1.8683363970588234,
      "grad_norm": 1.3177974224090576,
      "learning_rate": 4.194893617021277e-06,
      "loss": 0.0733,
      "step": 8131
    },
    {
      "epoch": 1.8685661764705883,
      "grad_norm": 1.0828094482421875,
      "learning_rate": 4.194042553191489e-06,
      "loss": 0.0493,
      "step": 8132
    },
    {
      "epoch": 1.8687959558823528,
      "grad_norm": 0.9450600743293762,
      "learning_rate": 4.193191489361702e-06,
      "loss": 0.0555,
      "step": 8133
    },
    {
      "epoch": 1.8690257352941178,
      "grad_norm": 1.159035563468933,
      "learning_rate": 4.192340425531915e-06,
      "loss": 0.0692,
      "step": 8134
    },
    {
      "epoch": 1.8692555147058822,
      "grad_norm": 1.1493929624557495,
      "learning_rate": 4.191489361702128e-06,
      "loss": 0.1037,
      "step": 8135
    },
    {
      "epoch": 1.8694852941176472,
      "grad_norm": 1.285013198852539,
      "learning_rate": 4.190638297872341e-06,
      "loss": 0.0838,
      "step": 8136
    },
    {
      "epoch": 1.8697150735294117,
      "grad_norm": 1.015809178352356,
      "learning_rate": 4.189787234042553e-06,
      "loss": 0.0639,
      "step": 8137
    },
    {
      "epoch": 1.8699448529411766,
      "grad_norm": 1.0591785907745361,
      "learning_rate": 4.188936170212767e-06,
      "loss": 0.0622,
      "step": 8138
    },
    {
      "epoch": 1.8701746323529411,
      "grad_norm": 1.4869745969772339,
      "learning_rate": 4.188085106382979e-06,
      "loss": 0.0718,
      "step": 8139
    },
    {
      "epoch": 1.8704044117647058,
      "grad_norm": 0.9484822154045105,
      "learning_rate": 4.187234042553192e-06,
      "loss": 0.06,
      "step": 8140
    },
    {
      "epoch": 1.8706341911764706,
      "grad_norm": 1.218217134475708,
      "learning_rate": 4.186382978723404e-06,
      "loss": 0.0889,
      "step": 8141
    },
    {
      "epoch": 1.8708639705882353,
      "grad_norm": 1.8242943286895752,
      "learning_rate": 4.1855319148936176e-06,
      "loss": 0.1035,
      "step": 8142
    },
    {
      "epoch": 1.87109375,
      "grad_norm": 1.236494541168213,
      "learning_rate": 4.184680851063831e-06,
      "loss": 0.0523,
      "step": 8143
    },
    {
      "epoch": 1.8713235294117647,
      "grad_norm": 1.0319924354553223,
      "learning_rate": 4.183829787234043e-06,
      "loss": 0.0656,
      "step": 8144
    },
    {
      "epoch": 1.8715533088235294,
      "grad_norm": 1.113760232925415,
      "learning_rate": 4.182978723404255e-06,
      "loss": 0.0643,
      "step": 8145
    },
    {
      "epoch": 1.8717830882352942,
      "grad_norm": 1.192344069480896,
      "learning_rate": 4.1821276595744686e-06,
      "loss": 0.0688,
      "step": 8146
    },
    {
      "epoch": 1.8720128676470589,
      "grad_norm": 1.242904543876648,
      "learning_rate": 4.181276595744681e-06,
      "loss": 0.054,
      "step": 8147
    },
    {
      "epoch": 1.8722426470588234,
      "grad_norm": 1.1089667081832886,
      "learning_rate": 4.180425531914894e-06,
      "loss": 0.0883,
      "step": 8148
    },
    {
      "epoch": 1.8724724264705883,
      "grad_norm": 0.8673547506332397,
      "learning_rate": 4.179574468085107e-06,
      "loss": 0.057,
      "step": 8149
    },
    {
      "epoch": 1.8727022058823528,
      "grad_norm": 1.2210973501205444,
      "learning_rate": 4.1787234042553195e-06,
      "loss": 0.06,
      "step": 8150
    },
    {
      "epoch": 1.8729319852941178,
      "grad_norm": 1.1222503185272217,
      "learning_rate": 4.177872340425532e-06,
      "loss": 0.0648,
      "step": 8151
    },
    {
      "epoch": 1.8731617647058822,
      "grad_norm": 1.2484480142593384,
      "learning_rate": 4.177021276595745e-06,
      "loss": 0.0658,
      "step": 8152
    },
    {
      "epoch": 1.8733915441176472,
      "grad_norm": 1.286857008934021,
      "learning_rate": 4.176170212765957e-06,
      "loss": 0.0887,
      "step": 8153
    },
    {
      "epoch": 1.8736213235294117,
      "grad_norm": 1.3274331092834473,
      "learning_rate": 4.1753191489361705e-06,
      "loss": 0.063,
      "step": 8154
    },
    {
      "epoch": 1.8738511029411766,
      "grad_norm": 1.420991063117981,
      "learning_rate": 4.174468085106384e-06,
      "loss": 0.0947,
      "step": 8155
    },
    {
      "epoch": 1.8740808823529411,
      "grad_norm": 1.2468969821929932,
      "learning_rate": 4.173617021276596e-06,
      "loss": 0.0765,
      "step": 8156
    },
    {
      "epoch": 1.8743106617647058,
      "grad_norm": 1.1372052431106567,
      "learning_rate": 4.172765957446809e-06,
      "loss": 0.0529,
      "step": 8157
    },
    {
      "epoch": 1.8745404411764706,
      "grad_norm": 1.1782424449920654,
      "learning_rate": 4.1719148936170215e-06,
      "loss": 0.0733,
      "step": 8158
    },
    {
      "epoch": 1.8747702205882353,
      "grad_norm": 1.2850183248519897,
      "learning_rate": 4.171063829787234e-06,
      "loss": 0.0643,
      "step": 8159
    },
    {
      "epoch": 1.875,
      "grad_norm": 1.6318607330322266,
      "learning_rate": 4.170212765957447e-06,
      "loss": 0.0644,
      "step": 8160
    },
    {
      "epoch": 1.8752297794117647,
      "grad_norm": 1.3326863050460815,
      "learning_rate": 4.16936170212766e-06,
      "loss": 0.1057,
      "step": 8161
    },
    {
      "epoch": 1.8754595588235294,
      "grad_norm": 1.4389885663986206,
      "learning_rate": 4.168510638297873e-06,
      "loss": 0.0735,
      "step": 8162
    },
    {
      "epoch": 1.8756893382352942,
      "grad_norm": 1.285459280014038,
      "learning_rate": 4.167659574468086e-06,
      "loss": 0.0579,
      "step": 8163
    },
    {
      "epoch": 1.8759191176470589,
      "grad_norm": 2.354069471359253,
      "learning_rate": 4.166808510638298e-06,
      "loss": 0.1136,
      "step": 8164
    },
    {
      "epoch": 1.8761488970588234,
      "grad_norm": 0.8705872893333435,
      "learning_rate": 4.165957446808511e-06,
      "loss": 0.0611,
      "step": 8165
    },
    {
      "epoch": 1.8763786764705883,
      "grad_norm": 1.4819732904434204,
      "learning_rate": 4.1651063829787235e-06,
      "loss": 0.085,
      "step": 8166
    },
    {
      "epoch": 1.8766084558823528,
      "grad_norm": 1.416455864906311,
      "learning_rate": 4.164255319148937e-06,
      "loss": 0.1042,
      "step": 8167
    },
    {
      "epoch": 1.8768382352941178,
      "grad_norm": 1.1134206056594849,
      "learning_rate": 4.16340425531915e-06,
      "loss": 0.072,
      "step": 8168
    },
    {
      "epoch": 1.8770680147058822,
      "grad_norm": 1.4167280197143555,
      "learning_rate": 4.162553191489362e-06,
      "loss": 0.0821,
      "step": 8169
    },
    {
      "epoch": 1.8772977941176472,
      "grad_norm": 1.2909431457519531,
      "learning_rate": 4.1617021276595745e-06,
      "loss": 0.0537,
      "step": 8170
    },
    {
      "epoch": 1.8775275735294117,
      "grad_norm": 1.5179141759872437,
      "learning_rate": 4.160851063829788e-06,
      "loss": 0.0868,
      "step": 8171
    },
    {
      "epoch": 1.8777573529411766,
      "grad_norm": 0.9347114562988281,
      "learning_rate": 4.16e-06,
      "loss": 0.0775,
      "step": 8172
    },
    {
      "epoch": 1.8779871323529411,
      "grad_norm": Infinity,
      "learning_rate": 4.159148936170213e-06,
      "loss": 0.0811,
      "step": 8173
    },
    {
      "epoch": 1.8782169117647058,
      "grad_norm": 1.497798204421997,
      "learning_rate": 4.159148936170213e-06,
      "loss": 0.1053,
      "step": 8174
    },
    {
      "epoch": 1.8784466911764706,
      "grad_norm": 1.795409083366394,
      "learning_rate": 4.158297872340426e-06,
      "loss": 0.1352,
      "step": 8175
    },
    {
      "epoch": 1.8786764705882353,
      "grad_norm": 1.4036476612091064,
      "learning_rate": 4.157446808510639e-06,
      "loss": 0.1028,
      "step": 8176
    },
    {
      "epoch": 1.87890625,
      "grad_norm": 0.8226845860481262,
      "learning_rate": 4.156595744680851e-06,
      "loss": 0.0624,
      "step": 8177
    },
    {
      "epoch": 1.8791360294117647,
      "grad_norm": 1.0202789306640625,
      "learning_rate": 4.155744680851064e-06,
      "loss": 0.0741,
      "step": 8178
    },
    {
      "epoch": 1.8793658088235294,
      "grad_norm": 1.5538395643234253,
      "learning_rate": 4.1548936170212765e-06,
      "loss": 0.0606,
      "step": 8179
    },
    {
      "epoch": 1.8795955882352942,
      "grad_norm": 1.0461699962615967,
      "learning_rate": 4.15404255319149e-06,
      "loss": 0.0628,
      "step": 8180
    },
    {
      "epoch": 1.8798253676470589,
      "grad_norm": 0.9678981900215149,
      "learning_rate": 4.153191489361703e-06,
      "loss": 0.0433,
      "step": 8181
    },
    {
      "epoch": 1.8800551470588234,
      "grad_norm": 1.586896538734436,
      "learning_rate": 4.152340425531915e-06,
      "loss": 0.0843,
      "step": 8182
    },
    {
      "epoch": 1.8802849264705883,
      "grad_norm": 1.180907964706421,
      "learning_rate": 4.151489361702128e-06,
      "loss": 0.0817,
      "step": 8183
    },
    {
      "epoch": 1.8805147058823528,
      "grad_norm": 1.2641109228134155,
      "learning_rate": 4.150638297872341e-06,
      "loss": 0.0665,
      "step": 8184
    },
    {
      "epoch": 1.8807444852941178,
      "grad_norm": 1.0304956436157227,
      "learning_rate": 4.149787234042554e-06,
      "loss": 0.0455,
      "step": 8185
    },
    {
      "epoch": 1.8809742647058822,
      "grad_norm": 1.4192326068878174,
      "learning_rate": 4.148936170212766e-06,
      "loss": 0.0715,
      "step": 8186
    },
    {
      "epoch": 1.8812040441176472,
      "grad_norm": 1.499647855758667,
      "learning_rate": 4.148085106382979e-06,
      "loss": 0.0704,
      "step": 8187
    },
    {
      "epoch": 1.8814338235294117,
      "grad_norm": 2.395651340484619,
      "learning_rate": 4.1472340425531925e-06,
      "loss": 0.0737,
      "step": 8188
    },
    {
      "epoch": 1.8816636029411766,
      "grad_norm": 1.2992552518844604,
      "learning_rate": 4.146382978723405e-06,
      "loss": 0.0661,
      "step": 8189
    },
    {
      "epoch": 1.8818933823529411,
      "grad_norm": 1.5818783044815063,
      "learning_rate": 4.145531914893617e-06,
      "loss": 0.0906,
      "step": 8190
    },
    {
      "epoch": 1.8821231617647058,
      "grad_norm": 1.3250614404678345,
      "learning_rate": 4.14468085106383e-06,
      "loss": 0.0587,
      "step": 8191
    },
    {
      "epoch": 1.8823529411764706,
      "grad_norm": 1.6482294797897339,
      "learning_rate": 4.143829787234043e-06,
      "loss": 0.0935,
      "step": 8192
    },
    {
      "epoch": 1.8825827205882353,
      "grad_norm": 1.0502721071243286,
      "learning_rate": 4.142978723404256e-06,
      "loss": 0.0645,
      "step": 8193
    },
    {
      "epoch": 1.8828125,
      "grad_norm": 1.496460199356079,
      "learning_rate": 4.142127659574469e-06,
      "loss": 0.065,
      "step": 8194
    },
    {
      "epoch": 1.8830422794117647,
      "grad_norm": 1.5472091436386108,
      "learning_rate": 4.141276595744681e-06,
      "loss": 0.0721,
      "step": 8195
    },
    {
      "epoch": 1.8832720588235294,
      "grad_norm": 1.2006813287734985,
      "learning_rate": 4.140425531914894e-06,
      "loss": 0.1066,
      "step": 8196
    },
    {
      "epoch": 1.8835018382352942,
      "grad_norm": 0.985918402671814,
      "learning_rate": 4.139574468085107e-06,
      "loss": 0.0749,
      "step": 8197
    },
    {
      "epoch": 1.8837316176470589,
      "grad_norm": 1.1283847093582153,
      "learning_rate": 4.138723404255319e-06,
      "loss": 0.0495,
      "step": 8198
    },
    {
      "epoch": 1.8839613970588234,
      "grad_norm": 1.241211175918579,
      "learning_rate": 4.137872340425532e-06,
      "loss": 0.0758,
      "step": 8199
    },
    {
      "epoch": 1.8841911764705883,
      "grad_norm": 1.2781928777694702,
      "learning_rate": 4.137021276595745e-06,
      "loss": 0.0679,
      "step": 8200
    },
    {
      "epoch": 1.8844209558823528,
      "grad_norm": 1.1548715829849243,
      "learning_rate": 4.136170212765958e-06,
      "loss": 0.077,
      "step": 8201
    },
    {
      "epoch": 1.8846507352941178,
      "grad_norm": 2.3316080570220947,
      "learning_rate": 4.13531914893617e-06,
      "loss": 0.0903,
      "step": 8202
    },
    {
      "epoch": 1.8848805147058822,
      "grad_norm": 1.3840125799179077,
      "learning_rate": 4.134468085106383e-06,
      "loss": 0.0939,
      "step": 8203
    },
    {
      "epoch": 1.8851102941176472,
      "grad_norm": 1.2214645147323608,
      "learning_rate": 4.1336170212765956e-06,
      "loss": 0.0616,
      "step": 8204
    },
    {
      "epoch": 1.8853400735294117,
      "grad_norm": 1.0030059814453125,
      "learning_rate": 4.132765957446809e-06,
      "loss": 0.0585,
      "step": 8205
    },
    {
      "epoch": 1.8855698529411766,
      "grad_norm": 1.2152305841445923,
      "learning_rate": 4.131914893617022e-06,
      "loss": 0.0629,
      "step": 8206
    },
    {
      "epoch": 1.8857996323529411,
      "grad_norm": 1.2261977195739746,
      "learning_rate": 4.131063829787234e-06,
      "loss": 0.0774,
      "step": 8207
    },
    {
      "epoch": 1.8860294117647058,
      "grad_norm": 1.1680525541305542,
      "learning_rate": 4.130212765957447e-06,
      "loss": 0.0618,
      "step": 8208
    },
    {
      "epoch": 1.8862591911764706,
      "grad_norm": 1.0788463354110718,
      "learning_rate": 4.12936170212766e-06,
      "loss": 0.0745,
      "step": 8209
    },
    {
      "epoch": 1.8864889705882353,
      "grad_norm": 1.335328459739685,
      "learning_rate": 4.128510638297873e-06,
      "loss": 0.0757,
      "step": 8210
    },
    {
      "epoch": 1.88671875,
      "grad_norm": 0.9442629218101501,
      "learning_rate": 4.127659574468085e-06,
      "loss": 0.0589,
      "step": 8211
    },
    {
      "epoch": 1.8869485294117647,
      "grad_norm": 1.1793861389160156,
      "learning_rate": 4.126808510638298e-06,
      "loss": 0.1037,
      "step": 8212
    },
    {
      "epoch": 1.8871783088235294,
      "grad_norm": 1.2651530504226685,
      "learning_rate": 4.1259574468085116e-06,
      "loss": 0.0857,
      "step": 8213
    },
    {
      "epoch": 1.8874080882352942,
      "grad_norm": 0.8537553548812866,
      "learning_rate": 4.125106382978724e-06,
      "loss": 0.0434,
      "step": 8214
    },
    {
      "epoch": 1.8876378676470589,
      "grad_norm": 1.1922080516815186,
      "learning_rate": 4.124255319148936e-06,
      "loss": 0.0609,
      "step": 8215
    },
    {
      "epoch": 1.8878676470588234,
      "grad_norm": 1.4250202178955078,
      "learning_rate": 4.123404255319149e-06,
      "loss": 0.0598,
      "step": 8216
    },
    {
      "epoch": 1.8880974264705883,
      "grad_norm": 1.147059440612793,
      "learning_rate": 4.122553191489362e-06,
      "loss": 0.0706,
      "step": 8217
    },
    {
      "epoch": 1.8883272058823528,
      "grad_norm": 1.298051118850708,
      "learning_rate": 4.121702127659575e-06,
      "loss": 0.1016,
      "step": 8218
    },
    {
      "epoch": 1.8885569852941178,
      "grad_norm": 0.9477207064628601,
      "learning_rate": 4.120851063829788e-06,
      "loss": 0.0484,
      "step": 8219
    },
    {
      "epoch": 1.8887867647058822,
      "grad_norm": 1.5163064002990723,
      "learning_rate": 4.12e-06,
      "loss": 0.0938,
      "step": 8220
    },
    {
      "epoch": 1.8890165441176472,
      "grad_norm": 1.8341856002807617,
      "learning_rate": 4.119148936170213e-06,
      "loss": 0.0994,
      "step": 8221
    },
    {
      "epoch": 1.8892463235294117,
      "grad_norm": 1.1373491287231445,
      "learning_rate": 4.118297872340426e-06,
      "loss": 0.0724,
      "step": 8222
    },
    {
      "epoch": 1.8894761029411766,
      "grad_norm": 1.3857110738754272,
      "learning_rate": 4.117446808510638e-06,
      "loss": 0.0507,
      "step": 8223
    },
    {
      "epoch": 1.8897058823529411,
      "grad_norm": 1.1411131620407104,
      "learning_rate": 4.116595744680851e-06,
      "loss": 0.0737,
      "step": 8224
    },
    {
      "epoch": 1.8899356617647058,
      "grad_norm": 1.4310476779937744,
      "learning_rate": 4.1157446808510645e-06,
      "loss": 0.0741,
      "step": 8225
    },
    {
      "epoch": 1.8901654411764706,
      "grad_norm": 1.7631727457046509,
      "learning_rate": 4.114893617021277e-06,
      "loss": 0.0886,
      "step": 8226
    },
    {
      "epoch": 1.8903952205882353,
      "grad_norm": 1.1930001974105835,
      "learning_rate": 4.11404255319149e-06,
      "loss": 0.0676,
      "step": 8227
    },
    {
      "epoch": 1.890625,
      "grad_norm": 1.4008761644363403,
      "learning_rate": 4.113191489361702e-06,
      "loss": 0.076,
      "step": 8228
    },
    {
      "epoch": 1.8908547794117647,
      "grad_norm": 1.1284986734390259,
      "learning_rate": 4.1123404255319155e-06,
      "loss": 0.0666,
      "step": 8229
    },
    {
      "epoch": 1.8910845588235294,
      "grad_norm": 0.9619287848472595,
      "learning_rate": 4.111489361702128e-06,
      "loss": 0.0697,
      "step": 8230
    },
    {
      "epoch": 1.8913143382352942,
      "grad_norm": 0.9693289399147034,
      "learning_rate": 4.110638297872341e-06,
      "loss": 0.0763,
      "step": 8231
    },
    {
      "epoch": 1.8915441176470589,
      "grad_norm": 1.28865647315979,
      "learning_rate": 4.109787234042554e-06,
      "loss": 0.0896,
      "step": 8232
    },
    {
      "epoch": 1.8917738970588234,
      "grad_norm": 1.3647491931915283,
      "learning_rate": 4.1089361702127665e-06,
      "loss": 0.0709,
      "step": 8233
    },
    {
      "epoch": 1.8920036764705883,
      "grad_norm": 1.3901511430740356,
      "learning_rate": 4.108085106382979e-06,
      "loss": 0.103,
      "step": 8234
    },
    {
      "epoch": 1.8922334558823528,
      "grad_norm": 1.0121188163757324,
      "learning_rate": 4.107234042553192e-06,
      "loss": 0.0685,
      "step": 8235
    },
    {
      "epoch": 1.8924632352941178,
      "grad_norm": 1.0477148294448853,
      "learning_rate": 4.106382978723404e-06,
      "loss": 0.0597,
      "step": 8236
    },
    {
      "epoch": 1.8926930147058822,
      "grad_norm": 0.984924852848053,
      "learning_rate": 4.1055319148936175e-06,
      "loss": 0.0512,
      "step": 8237
    },
    {
      "epoch": 1.8929227941176472,
      "grad_norm": 1.0462669134140015,
      "learning_rate": 4.104680851063831e-06,
      "loss": 0.0603,
      "step": 8238
    },
    {
      "epoch": 1.8931525735294117,
      "grad_norm": 1.3310561180114746,
      "learning_rate": 4.103829787234043e-06,
      "loss": 0.0558,
      "step": 8239
    },
    {
      "epoch": 1.8933823529411766,
      "grad_norm": 1.341050624847412,
      "learning_rate": 4.102978723404255e-06,
      "loss": 0.067,
      "step": 8240
    },
    {
      "epoch": 1.8936121323529411,
      "grad_norm": 1.8908766508102417,
      "learning_rate": 4.1021276595744685e-06,
      "loss": 0.0767,
      "step": 8241
    },
    {
      "epoch": 1.8938419117647058,
      "grad_norm": 1.0804052352905273,
      "learning_rate": 4.101276595744681e-06,
      "loss": 0.0662,
      "step": 8242
    },
    {
      "epoch": 1.8940716911764706,
      "grad_norm": 1.2877933979034424,
      "learning_rate": 4.100425531914894e-06,
      "loss": 0.0645,
      "step": 8243
    },
    {
      "epoch": 1.8943014705882353,
      "grad_norm": 1.0185189247131348,
      "learning_rate": 4.099574468085107e-06,
      "loss": 0.0629,
      "step": 8244
    },
    {
      "epoch": 1.89453125,
      "grad_norm": 1.0185803174972534,
      "learning_rate": 4.0987234042553195e-06,
      "loss": 0.0641,
      "step": 8245
    },
    {
      "epoch": 1.8947610294117647,
      "grad_norm": 0.9896543025970459,
      "learning_rate": 4.097872340425532e-06,
      "loss": 0.0652,
      "step": 8246
    },
    {
      "epoch": 1.8949908088235294,
      "grad_norm": 1.5115077495574951,
      "learning_rate": 4.097021276595745e-06,
      "loss": 0.0757,
      "step": 8247
    },
    {
      "epoch": 1.8952205882352942,
      "grad_norm": 1.3951501846313477,
      "learning_rate": 4.096170212765958e-06,
      "loss": 0.0718,
      "step": 8248
    },
    {
      "epoch": 1.8954503676470589,
      "grad_norm": 1.0693615674972534,
      "learning_rate": 4.0953191489361705e-06,
      "loss": 0.0529,
      "step": 8249
    },
    {
      "epoch": 1.8956801470588234,
      "grad_norm": 1.0618152618408203,
      "learning_rate": 4.094468085106384e-06,
      "loss": 0.0744,
      "step": 8250
    },
    {
      "epoch": 1.8959099264705883,
      "grad_norm": 1.6670163869857788,
      "learning_rate": 4.093617021276596e-06,
      "loss": 0.0864,
      "step": 8251
    },
    {
      "epoch": 1.8961397058823528,
      "grad_norm": 1.1498231887817383,
      "learning_rate": 4.092765957446809e-06,
      "loss": 0.065,
      "step": 8252
    },
    {
      "epoch": 1.8963694852941178,
      "grad_norm": 1.5264602899551392,
      "learning_rate": 4.0919148936170214e-06,
      "loss": 0.0778,
      "step": 8253
    },
    {
      "epoch": 1.8965992647058822,
      "grad_norm": 1.1800603866577148,
      "learning_rate": 4.091063829787235e-06,
      "loss": 0.0497,
      "step": 8254
    },
    {
      "epoch": 1.8968290441176472,
      "grad_norm": 0.9619850516319275,
      "learning_rate": 4.090212765957447e-06,
      "loss": 0.0802,
      "step": 8255
    },
    {
      "epoch": 1.8970588235294117,
      "grad_norm": 1.0998674631118774,
      "learning_rate": 4.08936170212766e-06,
      "loss": 0.0653,
      "step": 8256
    },
    {
      "epoch": 1.8972886029411766,
      "grad_norm": 1.7697227001190186,
      "learning_rate": 4.088510638297873e-06,
      "loss": 0.0975,
      "step": 8257
    },
    {
      "epoch": 1.8975183823529411,
      "grad_norm": 1.2580450773239136,
      "learning_rate": 4.087659574468086e-06,
      "loss": 0.0585,
      "step": 8258
    },
    {
      "epoch": 1.8977481617647058,
      "grad_norm": 1.1051483154296875,
      "learning_rate": 4.086808510638298e-06,
      "loss": 0.0564,
      "step": 8259
    },
    {
      "epoch": 1.8979779411764706,
      "grad_norm": 1.770034909248352,
      "learning_rate": 4.085957446808511e-06,
      "loss": 0.0785,
      "step": 8260
    },
    {
      "epoch": 1.8982077205882353,
      "grad_norm": 1.240483045578003,
      "learning_rate": 4.085106382978723e-06,
      "loss": 0.0583,
      "step": 8261
    },
    {
      "epoch": 1.8984375,
      "grad_norm": 1.22443687915802,
      "learning_rate": 4.084255319148937e-06,
      "loss": 0.0614,
      "step": 8262
    },
    {
      "epoch": 1.8986672794117647,
      "grad_norm": 1.1910712718963623,
      "learning_rate": 4.08340425531915e-06,
      "loss": 0.082,
      "step": 8263
    },
    {
      "epoch": 1.8988970588235294,
      "grad_norm": 1.0048456192016602,
      "learning_rate": 4.082553191489362e-06,
      "loss": 0.0492,
      "step": 8264
    },
    {
      "epoch": 1.8991268382352942,
      "grad_norm": 1.2808462381362915,
      "learning_rate": 4.081702127659574e-06,
      "loss": 0.0679,
      "step": 8265
    },
    {
      "epoch": 1.8993566176470589,
      "grad_norm": 1.401647686958313,
      "learning_rate": 4.080851063829788e-06,
      "loss": 0.0739,
      "step": 8266
    },
    {
      "epoch": 1.8995863970588234,
      "grad_norm": 1.5573198795318604,
      "learning_rate": 4.08e-06,
      "loss": 0.0895,
      "step": 8267
    },
    {
      "epoch": 1.8998161764705883,
      "grad_norm": 1.418175220489502,
      "learning_rate": 4.079148936170213e-06,
      "loss": 0.108,
      "step": 8268
    },
    {
      "epoch": 1.9000459558823528,
      "grad_norm": 1.6410330533981323,
      "learning_rate": 4.078297872340426e-06,
      "loss": 0.1016,
      "step": 8269
    },
    {
      "epoch": 1.9002757352941178,
      "grad_norm": 1.58811616897583,
      "learning_rate": 4.0774468085106386e-06,
      "loss": 0.1073,
      "step": 8270
    },
    {
      "epoch": 1.9005055147058822,
      "grad_norm": 0.7760332822799683,
      "learning_rate": 4.076595744680851e-06,
      "loss": 0.0434,
      "step": 8271
    },
    {
      "epoch": 1.9007352941176472,
      "grad_norm": 1.0133357048034668,
      "learning_rate": 4.075744680851064e-06,
      "loss": 0.0525,
      "step": 8272
    },
    {
      "epoch": 1.9009650735294117,
      "grad_norm": 2.2118465900421143,
      "learning_rate": 4.074893617021277e-06,
      "loss": 0.1009,
      "step": 8273
    },
    {
      "epoch": 1.9011948529411766,
      "grad_norm": 1.4395861625671387,
      "learning_rate": 4.0740425531914896e-06,
      "loss": 0.0687,
      "step": 8274
    },
    {
      "epoch": 1.9014246323529411,
      "grad_norm": 0.9872158169746399,
      "learning_rate": 4.073191489361703e-06,
      "loss": 0.0415,
      "step": 8275
    },
    {
      "epoch": 1.9016544117647058,
      "grad_norm": 1.4198133945465088,
      "learning_rate": 4.072340425531915e-06,
      "loss": 0.088,
      "step": 8276
    },
    {
      "epoch": 1.9018841911764706,
      "grad_norm": 1.1777111291885376,
      "learning_rate": 4.071489361702128e-06,
      "loss": 0.0749,
      "step": 8277
    },
    {
      "epoch": 1.9021139705882353,
      "grad_norm": 0.8567654490470886,
      "learning_rate": 4.0706382978723405e-06,
      "loss": 0.0666,
      "step": 8278
    },
    {
      "epoch": 1.90234375,
      "grad_norm": 1.5285943746566772,
      "learning_rate": 4.069787234042554e-06,
      "loss": 0.0873,
      "step": 8279
    },
    {
      "epoch": 1.9025735294117647,
      "grad_norm": 0.9487181305885315,
      "learning_rate": 4.068936170212766e-06,
      "loss": 0.056,
      "step": 8280
    },
    {
      "epoch": 1.9028033088235294,
      "grad_norm": 0.8852267861366272,
      "learning_rate": 4.068085106382979e-06,
      "loss": 0.0572,
      "step": 8281
    },
    {
      "epoch": 1.9030330882352942,
      "grad_norm": 1.097421646118164,
      "learning_rate": 4.067234042553192e-06,
      "loss": 0.0505,
      "step": 8282
    },
    {
      "epoch": 1.9032628676470589,
      "grad_norm": 1.1135107278823853,
      "learning_rate": 4.066382978723405e-06,
      "loss": 0.0787,
      "step": 8283
    },
    {
      "epoch": 1.9034926470588234,
      "grad_norm": 1.3675403594970703,
      "learning_rate": 4.065531914893617e-06,
      "loss": 0.0906,
      "step": 8284
    },
    {
      "epoch": 1.9037224264705883,
      "grad_norm": 1.7242467403411865,
      "learning_rate": 4.06468085106383e-06,
      "loss": 0.0626,
      "step": 8285
    },
    {
      "epoch": 1.9039522058823528,
      "grad_norm": 1.4102871417999268,
      "learning_rate": 4.0638297872340425e-06,
      "loss": 0.0893,
      "step": 8286
    },
    {
      "epoch": 1.9041819852941178,
      "grad_norm": 1.921878695487976,
      "learning_rate": 4.062978723404256e-06,
      "loss": 0.0817,
      "step": 8287
    },
    {
      "epoch": 1.9044117647058822,
      "grad_norm": 2.006364345550537,
      "learning_rate": 4.062127659574469e-06,
      "loss": 0.0972,
      "step": 8288
    },
    {
      "epoch": 1.9046415441176472,
      "grad_norm": 1.3339531421661377,
      "learning_rate": 4.061276595744681e-06,
      "loss": 0.0779,
      "step": 8289
    },
    {
      "epoch": 1.9048713235294117,
      "grad_norm": 1.1239973306655884,
      "learning_rate": 4.0604255319148935e-06,
      "loss": 0.0952,
      "step": 8290
    },
    {
      "epoch": 1.9051011029411766,
      "grad_norm": 2.054643154144287,
      "learning_rate": 4.059574468085107e-06,
      "loss": 0.0883,
      "step": 8291
    },
    {
      "epoch": 1.9053308823529411,
      "grad_norm": 0.9462072253227234,
      "learning_rate": 4.05872340425532e-06,
      "loss": 0.0659,
      "step": 8292
    },
    {
      "epoch": 1.9055606617647058,
      "grad_norm": 1.5588104724884033,
      "learning_rate": 4.057872340425532e-06,
      "loss": 0.0809,
      "step": 8293
    },
    {
      "epoch": 1.9057904411764706,
      "grad_norm": 1.1188215017318726,
      "learning_rate": 4.057021276595745e-06,
      "loss": 0.0615,
      "step": 8294
    },
    {
      "epoch": 1.9060202205882353,
      "grad_norm": 1.0470967292785645,
      "learning_rate": 4.056170212765958e-06,
      "loss": 0.0611,
      "step": 8295
    },
    {
      "epoch": 1.90625,
      "grad_norm": 1.188246488571167,
      "learning_rate": 4.05531914893617e-06,
      "loss": 0.0636,
      "step": 8296
    },
    {
      "epoch": 1.9064797794117647,
      "grad_norm": 1.4472935199737549,
      "learning_rate": 4.054468085106383e-06,
      "loss": 0.0879,
      "step": 8297
    },
    {
      "epoch": 1.9067095588235294,
      "grad_norm": 1.1645711660385132,
      "learning_rate": 4.053617021276596e-06,
      "loss": 0.077,
      "step": 8298
    },
    {
      "epoch": 1.9069393382352942,
      "grad_norm": 1.4557863473892212,
      "learning_rate": 4.052765957446809e-06,
      "loss": 0.0938,
      "step": 8299
    },
    {
      "epoch": 1.9071691176470589,
      "grad_norm": 1.147027611732483,
      "learning_rate": 4.051914893617022e-06,
      "loss": 0.0656,
      "step": 8300
    },
    {
      "epoch": 1.9073988970588234,
      "grad_norm": 1.2029756307601929,
      "learning_rate": 4.051063829787234e-06,
      "loss": 0.0693,
      "step": 8301
    },
    {
      "epoch": 1.9076286764705883,
      "grad_norm": 1.460582971572876,
      "learning_rate": 4.050212765957447e-06,
      "loss": 0.0603,
      "step": 8302
    },
    {
      "epoch": 1.9078584558823528,
      "grad_norm": 1.6823064088821411,
      "learning_rate": 4.04936170212766e-06,
      "loss": 0.0754,
      "step": 8303
    },
    {
      "epoch": 1.9080882352941178,
      "grad_norm": 1.3115463256835938,
      "learning_rate": 4.048510638297873e-06,
      "loss": 0.0819,
      "step": 8304
    },
    {
      "epoch": 1.9083180147058822,
      "grad_norm": 1.8366321325302124,
      "learning_rate": 4.047659574468085e-06,
      "loss": 0.0785,
      "step": 8305
    },
    {
      "epoch": 1.9085477941176472,
      "grad_norm": 1.0102744102478027,
      "learning_rate": 4.046808510638298e-06,
      "loss": 0.0607,
      "step": 8306
    },
    {
      "epoch": 1.9087775735294117,
      "grad_norm": 1.3045495748519897,
      "learning_rate": 4.0459574468085115e-06,
      "loss": 0.0854,
      "step": 8307
    },
    {
      "epoch": 1.9090073529411766,
      "grad_norm": 1.0774400234222412,
      "learning_rate": 4.045106382978724e-06,
      "loss": 0.0653,
      "step": 8308
    },
    {
      "epoch": 1.9092371323529411,
      "grad_norm": 1.3565175533294678,
      "learning_rate": 4.044255319148936e-06,
      "loss": 0.0551,
      "step": 8309
    },
    {
      "epoch": 1.9094669117647058,
      "grad_norm": 1.2946903705596924,
      "learning_rate": 4.043404255319149e-06,
      "loss": 0.0841,
      "step": 8310
    },
    {
      "epoch": 1.9096966911764706,
      "grad_norm": 1.0930625200271606,
      "learning_rate": 4.042553191489362e-06,
      "loss": 0.0729,
      "step": 8311
    },
    {
      "epoch": 1.9099264705882353,
      "grad_norm": 1.0873863697052002,
      "learning_rate": 4.041702127659575e-06,
      "loss": 0.0496,
      "step": 8312
    },
    {
      "epoch": 1.91015625,
      "grad_norm": 1.468894600868225,
      "learning_rate": 4.040851063829788e-06,
      "loss": 0.1115,
      "step": 8313
    },
    {
      "epoch": 1.9103860294117647,
      "grad_norm": 0.8376430869102478,
      "learning_rate": 4.04e-06,
      "loss": 0.0493,
      "step": 8314
    },
    {
      "epoch": 1.9106158088235294,
      "grad_norm": 1.1190587282180786,
      "learning_rate": 4.039148936170213e-06,
      "loss": 0.0613,
      "step": 8315
    },
    {
      "epoch": 1.9108455882352942,
      "grad_norm": 0.9937518239021301,
      "learning_rate": 4.038297872340426e-06,
      "loss": 0.0661,
      "step": 8316
    },
    {
      "epoch": 1.9110753676470589,
      "grad_norm": 1.1982481479644775,
      "learning_rate": 4.037446808510639e-06,
      "loss": 0.0456,
      "step": 8317
    },
    {
      "epoch": 1.9113051470588234,
      "grad_norm": 1.159587025642395,
      "learning_rate": 4.036595744680851e-06,
      "loss": 0.072,
      "step": 8318
    },
    {
      "epoch": 1.9115349264705883,
      "grad_norm": 0.9360690712928772,
      "learning_rate": 4.0357446808510644e-06,
      "loss": 0.0596,
      "step": 8319
    },
    {
      "epoch": 1.9117647058823528,
      "grad_norm": 1.3042007684707642,
      "learning_rate": 4.034893617021277e-06,
      "loss": 0.0867,
      "step": 8320
    },
    {
      "epoch": 1.9119944852941178,
      "grad_norm": 1.439820408821106,
      "learning_rate": 4.03404255319149e-06,
      "loss": 0.1075,
      "step": 8321
    },
    {
      "epoch": 1.9122242647058822,
      "grad_norm": 1.406042456626892,
      "learning_rate": 4.033191489361702e-06,
      "loss": 0.0791,
      "step": 8322
    },
    {
      "epoch": 1.9124540441176472,
      "grad_norm": 0.8809704184532166,
      "learning_rate": 4.0323404255319154e-06,
      "loss": 0.0431,
      "step": 8323
    },
    {
      "epoch": 1.9126838235294117,
      "grad_norm": 1.4573265314102173,
      "learning_rate": 4.031489361702128e-06,
      "loss": 0.0698,
      "step": 8324
    },
    {
      "epoch": 1.9129136029411766,
      "grad_norm": 1.3695213794708252,
      "learning_rate": 4.030638297872341e-06,
      "loss": 0.101,
      "step": 8325
    },
    {
      "epoch": 1.9131433823529411,
      "grad_norm": 1.4135284423828125,
      "learning_rate": 4.029787234042554e-06,
      "loss": 0.0767,
      "step": 8326
    },
    {
      "epoch": 1.9133731617647058,
      "grad_norm": 0.8798643350601196,
      "learning_rate": 4.028936170212766e-06,
      "loss": 0.0618,
      "step": 8327
    },
    {
      "epoch": 1.9136029411764706,
      "grad_norm": 1.9709200859069824,
      "learning_rate": 4.028085106382979e-06,
      "loss": 0.0728,
      "step": 8328
    },
    {
      "epoch": 1.9138327205882353,
      "grad_norm": 1.2414605617523193,
      "learning_rate": 4.027234042553192e-06,
      "loss": 0.0774,
      "step": 8329
    },
    {
      "epoch": 1.9140625,
      "grad_norm": 1.068385362625122,
      "learning_rate": 4.026382978723404e-06,
      "loss": 0.0563,
      "step": 8330
    },
    {
      "epoch": 1.9142922794117647,
      "grad_norm": 1.2983593940734863,
      "learning_rate": 4.025531914893617e-06,
      "loss": 0.0985,
      "step": 8331
    },
    {
      "epoch": 1.9145220588235294,
      "grad_norm": 2.0786664485931396,
      "learning_rate": 4.024680851063831e-06,
      "loss": 0.0977,
      "step": 8332
    },
    {
      "epoch": 1.9147518382352942,
      "grad_norm": 1.2453604936599731,
      "learning_rate": 4.023829787234043e-06,
      "loss": 0.1095,
      "step": 8333
    },
    {
      "epoch": 1.9149816176470589,
      "grad_norm": 1.4884233474731445,
      "learning_rate": 4.022978723404255e-06,
      "loss": 0.0715,
      "step": 8334
    },
    {
      "epoch": 1.9152113970588234,
      "grad_norm": 1.0872102975845337,
      "learning_rate": 4.022127659574468e-06,
      "loss": 0.0697,
      "step": 8335
    },
    {
      "epoch": 1.9154411764705883,
      "grad_norm": 1.8253720998764038,
      "learning_rate": 4.0212765957446816e-06,
      "loss": 0.066,
      "step": 8336
    },
    {
      "epoch": 1.9156709558823528,
      "grad_norm": 1.3909987211227417,
      "learning_rate": 4.020425531914894e-06,
      "loss": 0.0896,
      "step": 8337
    },
    {
      "epoch": 1.9159007352941178,
      "grad_norm": 1.2756140232086182,
      "learning_rate": 4.019574468085107e-06,
      "loss": 0.0717,
      "step": 8338
    },
    {
      "epoch": 1.9161305147058822,
      "grad_norm": 1.1672067642211914,
      "learning_rate": 4.018723404255319e-06,
      "loss": 0.0745,
      "step": 8339
    },
    {
      "epoch": 1.9163602941176472,
      "grad_norm": 0.9576853513717651,
      "learning_rate": 4.017872340425532e-06,
      "loss": 0.0699,
      "step": 8340
    },
    {
      "epoch": 1.9165900735294117,
      "grad_norm": 1.7777117490768433,
      "learning_rate": 4.017021276595745e-06,
      "loss": 0.1087,
      "step": 8341
    },
    {
      "epoch": 1.9168198529411766,
      "grad_norm": 1.5683006048202515,
      "learning_rate": 4.016170212765958e-06,
      "loss": 0.0584,
      "step": 8342
    },
    {
      "epoch": 1.9170496323529411,
      "grad_norm": 1.6012091636657715,
      "learning_rate": 4.01531914893617e-06,
      "loss": 0.1066,
      "step": 8343
    },
    {
      "epoch": 1.9172794117647058,
      "grad_norm": 2.062825918197632,
      "learning_rate": 4.0144680851063835e-06,
      "loss": 0.0759,
      "step": 8344
    },
    {
      "epoch": 1.9175091911764706,
      "grad_norm": 1.416701078414917,
      "learning_rate": 4.013617021276596e-06,
      "loss": 0.0708,
      "step": 8345
    },
    {
      "epoch": 1.9177389705882353,
      "grad_norm": 1.4469245672225952,
      "learning_rate": 4.012765957446809e-06,
      "loss": 0.0974,
      "step": 8346
    },
    {
      "epoch": 1.91796875,
      "grad_norm": 1.1503945589065552,
      "learning_rate": 4.011914893617021e-06,
      "loss": 0.0931,
      "step": 8347
    },
    {
      "epoch": 1.9181985294117647,
      "grad_norm": 1.5031832456588745,
      "learning_rate": 4.0110638297872345e-06,
      "loss": 0.0668,
      "step": 8348
    },
    {
      "epoch": 1.9184283088235294,
      "grad_norm": 1.4299207925796509,
      "learning_rate": 4.010212765957447e-06,
      "loss": 0.11,
      "step": 8349
    },
    {
      "epoch": 1.9186580882352942,
      "grad_norm": 1.5706754922866821,
      "learning_rate": 4.00936170212766e-06,
      "loss": 0.1122,
      "step": 8350
    },
    {
      "epoch": 1.9188878676470589,
      "grad_norm": 1.4083796739578247,
      "learning_rate": 4.008510638297873e-06,
      "loss": 0.1049,
      "step": 8351
    },
    {
      "epoch": 1.9191176470588234,
      "grad_norm": 1.140730619430542,
      "learning_rate": 4.0076595744680855e-06,
      "loss": 0.0535,
      "step": 8352
    },
    {
      "epoch": 1.9193474264705883,
      "grad_norm": 1.1903630495071411,
      "learning_rate": 4.006808510638298e-06,
      "loss": 0.0583,
      "step": 8353
    },
    {
      "epoch": 1.9195772058823528,
      "grad_norm": 1.0170222520828247,
      "learning_rate": 4.005957446808511e-06,
      "loss": 0.0641,
      "step": 8354
    },
    {
      "epoch": 1.9198069852941178,
      "grad_norm": 0.9654785990715027,
      "learning_rate": 4.005106382978724e-06,
      "loss": 0.0805,
      "step": 8355
    },
    {
      "epoch": 1.9200367647058822,
      "grad_norm": 1.196023941040039,
      "learning_rate": 4.0042553191489365e-06,
      "loss": 0.0886,
      "step": 8356
    },
    {
      "epoch": 1.9202665441176472,
      "grad_norm": 1.2687922716140747,
      "learning_rate": 4.00340425531915e-06,
      "loss": 0.0892,
      "step": 8357
    },
    {
      "epoch": 1.9204963235294117,
      "grad_norm": 1.1423577070236206,
      "learning_rate": 4.002553191489362e-06,
      "loss": 0.0561,
      "step": 8358
    },
    {
      "epoch": 1.9207261029411766,
      "grad_norm": 0.9327291250228882,
      "learning_rate": 4.001702127659574e-06,
      "loss": 0.0528,
      "step": 8359
    },
    {
      "epoch": 1.9209558823529411,
      "grad_norm": 1.3523839712142944,
      "learning_rate": 4.0008510638297875e-06,
      "loss": 0.0891,
      "step": 8360
    },
    {
      "epoch": 1.9211856617647058,
      "grad_norm": 1.0140620470046997,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0648,
      "step": 8361
    },
    {
      "epoch": 1.9214154411764706,
      "grad_norm": 1.3878933191299438,
      "learning_rate": 3.999148936170213e-06,
      "loss": 0.0945,
      "step": 8362
    },
    {
      "epoch": 1.9216452205882353,
      "grad_norm": 1.1175346374511719,
      "learning_rate": 3.998297872340426e-06,
      "loss": 0.0482,
      "step": 8363
    },
    {
      "epoch": 1.921875,
      "grad_norm": 1.2233637571334839,
      "learning_rate": 3.9974468085106385e-06,
      "loss": 0.0616,
      "step": 8364
    },
    {
      "epoch": 1.9221047794117647,
      "grad_norm": 0.9064357280731201,
      "learning_rate": 3.996595744680851e-06,
      "loss": 0.0624,
      "step": 8365
    },
    {
      "epoch": 1.9223345588235294,
      "grad_norm": 1.410830020904541,
      "learning_rate": 3.995744680851064e-06,
      "loss": 0.0824,
      "step": 8366
    },
    {
      "epoch": 1.9225643382352942,
      "grad_norm": 1.3698348999023438,
      "learning_rate": 3.994893617021277e-06,
      "loss": 0.0733,
      "step": 8367
    },
    {
      "epoch": 1.9227941176470589,
      "grad_norm": 1.2453306913375854,
      "learning_rate": 3.9940425531914895e-06,
      "loss": 0.0652,
      "step": 8368
    },
    {
      "epoch": 1.9230238970588234,
      "grad_norm": 0.9945067167282104,
      "learning_rate": 3.993191489361703e-06,
      "loss": 0.0623,
      "step": 8369
    },
    {
      "epoch": 1.9232536764705883,
      "grad_norm": 1.2361010313034058,
      "learning_rate": 3.992340425531915e-06,
      "loss": 0.0601,
      "step": 8370
    },
    {
      "epoch": 1.9234834558823528,
      "grad_norm": 1.017911434173584,
      "learning_rate": 3.991489361702128e-06,
      "loss": 0.0574,
      "step": 8371
    },
    {
      "epoch": 1.9237132352941178,
      "grad_norm": 1.1482312679290771,
      "learning_rate": 3.9906382978723405e-06,
      "loss": 0.049,
      "step": 8372
    },
    {
      "epoch": 1.9239430147058822,
      "grad_norm": 0.9558750987052917,
      "learning_rate": 3.989787234042554e-06,
      "loss": 0.0624,
      "step": 8373
    },
    {
      "epoch": 1.9241727941176472,
      "grad_norm": 1.2651567459106445,
      "learning_rate": 3.988936170212766e-06,
      "loss": 0.0747,
      "step": 8374
    },
    {
      "epoch": 1.9244025735294117,
      "grad_norm": 1.6690834760665894,
      "learning_rate": 3.988085106382979e-06,
      "loss": 0.063,
      "step": 8375
    },
    {
      "epoch": 1.9246323529411766,
      "grad_norm": 1.380061149597168,
      "learning_rate": 3.987234042553192e-06,
      "loss": 0.0612,
      "step": 8376
    },
    {
      "epoch": 1.9248621323529411,
      "grad_norm": 1.4432792663574219,
      "learning_rate": 3.986382978723405e-06,
      "loss": 0.0869,
      "step": 8377
    },
    {
      "epoch": 1.9250919117647058,
      "grad_norm": 1.4592140913009644,
      "learning_rate": 3.985531914893617e-06,
      "loss": 0.093,
      "step": 8378
    },
    {
      "epoch": 1.9253216911764706,
      "grad_norm": 0.6985376477241516,
      "learning_rate": 3.98468085106383e-06,
      "loss": 0.0443,
      "step": 8379
    },
    {
      "epoch": 1.9255514705882353,
      "grad_norm": 1.2911654710769653,
      "learning_rate": 3.983829787234043e-06,
      "loss": 0.0545,
      "step": 8380
    },
    {
      "epoch": 1.92578125,
      "grad_norm": 1.2704908847808838,
      "learning_rate": 3.982978723404256e-06,
      "loss": 0.064,
      "step": 8381
    },
    {
      "epoch": 1.9260110294117647,
      "grad_norm": 1.0854545831680298,
      "learning_rate": 3.982127659574469e-06,
      "loss": 0.0488,
      "step": 8382
    },
    {
      "epoch": 1.9262408088235294,
      "grad_norm": 0.9994146227836609,
      "learning_rate": 3.981276595744681e-06,
      "loss": 0.0748,
      "step": 8383
    },
    {
      "epoch": 1.9264705882352942,
      "grad_norm": 1.2112934589385986,
      "learning_rate": 3.9804255319148934e-06,
      "loss": 0.0824,
      "step": 8384
    },
    {
      "epoch": 1.9267003676470589,
      "grad_norm": 1.3368791341781616,
      "learning_rate": 3.979574468085107e-06,
      "loss": 0.0889,
      "step": 8385
    },
    {
      "epoch": 1.9269301470588234,
      "grad_norm": 1.0729916095733643,
      "learning_rate": 3.97872340425532e-06,
      "loss": 0.052,
      "step": 8386
    },
    {
      "epoch": 1.9271599264705883,
      "grad_norm": 1.4842472076416016,
      "learning_rate": 3.977872340425532e-06,
      "loss": 0.0519,
      "step": 8387
    },
    {
      "epoch": 1.9273897058823528,
      "grad_norm": 1.1077048778533936,
      "learning_rate": 3.977021276595745e-06,
      "loss": 0.0918,
      "step": 8388
    },
    {
      "epoch": 1.9276194852941178,
      "grad_norm": 1.266790509223938,
      "learning_rate": 3.976170212765958e-06,
      "loss": 0.0899,
      "step": 8389
    },
    {
      "epoch": 1.9278492647058822,
      "grad_norm": 1.4193185567855835,
      "learning_rate": 3.97531914893617e-06,
      "loss": 0.0678,
      "step": 8390
    },
    {
      "epoch": 1.9280790441176472,
      "grad_norm": 1.2931410074234009,
      "learning_rate": 3.974468085106383e-06,
      "loss": 0.08,
      "step": 8391
    },
    {
      "epoch": 1.9283088235294117,
      "grad_norm": 1.561026930809021,
      "learning_rate": 3.973617021276596e-06,
      "loss": 0.1034,
      "step": 8392
    },
    {
      "epoch": 1.9285386029411766,
      "grad_norm": 0.9751689434051514,
      "learning_rate": 3.9727659574468086e-06,
      "loss": 0.0487,
      "step": 8393
    },
    {
      "epoch": 1.9287683823529411,
      "grad_norm": 1.2617591619491577,
      "learning_rate": 3.971914893617022e-06,
      "loss": 0.0563,
      "step": 8394
    },
    {
      "epoch": 1.9289981617647058,
      "grad_norm": 1.155065655708313,
      "learning_rate": 3.971063829787234e-06,
      "loss": 0.0676,
      "step": 8395
    },
    {
      "epoch": 1.9292279411764706,
      "grad_norm": 1.1950273513793945,
      "learning_rate": 3.970212765957447e-06,
      "loss": 0.0777,
      "step": 8396
    },
    {
      "epoch": 1.9294577205882353,
      "grad_norm": 1.1923006772994995,
      "learning_rate": 3.9693617021276596e-06,
      "loss": 0.0589,
      "step": 8397
    },
    {
      "epoch": 1.9296875,
      "grad_norm": 1.1348308324813843,
      "learning_rate": 3.968510638297873e-06,
      "loss": 0.0617,
      "step": 8398
    },
    {
      "epoch": 1.9299172794117647,
      "grad_norm": 1.3778983354568481,
      "learning_rate": 3.967659574468086e-06,
      "loss": 0.076,
      "step": 8399
    },
    {
      "epoch": 1.9301470588235294,
      "grad_norm": 1.8569424152374268,
      "learning_rate": 3.966808510638298e-06,
      "loss": 0.0866,
      "step": 8400
    },
    {
      "epoch": 1.9303768382352942,
      "grad_norm": 1.3438891172409058,
      "learning_rate": 3.965957446808511e-06,
      "loss": 0.0673,
      "step": 8401
    },
    {
      "epoch": 1.9306066176470589,
      "grad_norm": 1.4409793615341187,
      "learning_rate": 3.965106382978724e-06,
      "loss": 0.098,
      "step": 8402
    },
    {
      "epoch": 1.9308363970588234,
      "grad_norm": 1.3455909490585327,
      "learning_rate": 3.964255319148936e-06,
      "loss": 0.0734,
      "step": 8403
    },
    {
      "epoch": 1.9310661764705883,
      "grad_norm": 1.7712411880493164,
      "learning_rate": 3.963404255319149e-06,
      "loss": 0.0709,
      "step": 8404
    },
    {
      "epoch": 1.9312959558823528,
      "grad_norm": 1.5425238609313965,
      "learning_rate": 3.962553191489362e-06,
      "loss": 0.0949,
      "step": 8405
    },
    {
      "epoch": 1.9315257352941178,
      "grad_norm": 2.071138381958008,
      "learning_rate": 3.961702127659575e-06,
      "loss": 0.0837,
      "step": 8406
    },
    {
      "epoch": 1.9317555147058822,
      "grad_norm": 0.9107359051704407,
      "learning_rate": 3.960851063829788e-06,
      "loss": 0.0476,
      "step": 8407
    },
    {
      "epoch": 1.9319852941176472,
      "grad_norm": 1.3990323543548584,
      "learning_rate": 3.96e-06,
      "loss": 0.0809,
      "step": 8408
    },
    {
      "epoch": 1.9322150735294117,
      "grad_norm": 1.5136923789978027,
      "learning_rate": 3.9591489361702125e-06,
      "loss": 0.1185,
      "step": 8409
    },
    {
      "epoch": 1.9324448529411766,
      "grad_norm": 0.8603202700614929,
      "learning_rate": 3.958297872340426e-06,
      "loss": 0.044,
      "step": 8410
    },
    {
      "epoch": 1.9326746323529411,
      "grad_norm": 1.4153938293457031,
      "learning_rate": 3.957446808510639e-06,
      "loss": 0.1275,
      "step": 8411
    },
    {
      "epoch": 1.9329044117647058,
      "grad_norm": 1.2663449048995972,
      "learning_rate": 3.956595744680851e-06,
      "loss": 0.0726,
      "step": 8412
    },
    {
      "epoch": 1.9331341911764706,
      "grad_norm": 1.1408421993255615,
      "learning_rate": 3.955744680851064e-06,
      "loss": 0.0603,
      "step": 8413
    },
    {
      "epoch": 1.9333639705882353,
      "grad_norm": 1.9368879795074463,
      "learning_rate": 3.954893617021277e-06,
      "loss": 0.0707,
      "step": 8414
    },
    {
      "epoch": 1.93359375,
      "grad_norm": 1.1552832126617432,
      "learning_rate": 3.95404255319149e-06,
      "loss": 0.0688,
      "step": 8415
    },
    {
      "epoch": 1.9338235294117647,
      "grad_norm": 0.9714161157608032,
      "learning_rate": 3.953191489361702e-06,
      "loss": 0.0601,
      "step": 8416
    },
    {
      "epoch": 1.9340533088235294,
      "grad_norm": 1.1358200311660767,
      "learning_rate": 3.952340425531915e-06,
      "loss": 0.0792,
      "step": 8417
    },
    {
      "epoch": 1.9342830882352942,
      "grad_norm": 0.911216676235199,
      "learning_rate": 3.951489361702128e-06,
      "loss": 0.0426,
      "step": 8418
    },
    {
      "epoch": 1.9345128676470589,
      "grad_norm": 1.0989197492599487,
      "learning_rate": 3.950638297872341e-06,
      "loss": 0.0499,
      "step": 8419
    },
    {
      "epoch": 1.9347426470588234,
      "grad_norm": 1.1079773902893066,
      "learning_rate": 3.949787234042554e-06,
      "loss": 0.0599,
      "step": 8420
    },
    {
      "epoch": 1.9349724264705883,
      "grad_norm": 1.3786901235580444,
      "learning_rate": 3.948936170212766e-06,
      "loss": 0.078,
      "step": 8421
    },
    {
      "epoch": 1.9352022058823528,
      "grad_norm": 1.3442744016647339,
      "learning_rate": 3.948085106382979e-06,
      "loss": 0.0801,
      "step": 8422
    },
    {
      "epoch": 1.9354319852941178,
      "grad_norm": 1.0619821548461914,
      "learning_rate": 3.947234042553192e-06,
      "loss": 0.0602,
      "step": 8423
    },
    {
      "epoch": 1.9356617647058822,
      "grad_norm": 1.094780683517456,
      "learning_rate": 3.946382978723405e-06,
      "loss": 0.0813,
      "step": 8424
    },
    {
      "epoch": 1.9358915441176472,
      "grad_norm": 1.0958020687103271,
      "learning_rate": 3.945531914893617e-06,
      "loss": 0.0528,
      "step": 8425
    },
    {
      "epoch": 1.9361213235294117,
      "grad_norm": 0.9336421489715576,
      "learning_rate": 3.9446808510638305e-06,
      "loss": 0.0575,
      "step": 8426
    },
    {
      "epoch": 1.9363511029411766,
      "grad_norm": 1.4870892763137817,
      "learning_rate": 3.943829787234043e-06,
      "loss": 0.0893,
      "step": 8427
    },
    {
      "epoch": 1.9365808823529411,
      "grad_norm": 1.2304648160934448,
      "learning_rate": 3.942978723404255e-06,
      "loss": 0.0617,
      "step": 8428
    },
    {
      "epoch": 1.9368106617647058,
      "grad_norm": 1.194933533668518,
      "learning_rate": 3.942127659574468e-06,
      "loss": 0.0786,
      "step": 8429
    },
    {
      "epoch": 1.9370404411764706,
      "grad_norm": 1.6436430215835571,
      "learning_rate": 3.9412765957446815e-06,
      "loss": 0.0716,
      "step": 8430
    },
    {
      "epoch": 1.9372702205882353,
      "grad_norm": 1.3510446548461914,
      "learning_rate": 3.940425531914894e-06,
      "loss": 0.1048,
      "step": 8431
    },
    {
      "epoch": 1.9375,
      "grad_norm": 1.0527162551879883,
      "learning_rate": 3.939574468085107e-06,
      "loss": 0.0687,
      "step": 8432
    },
    {
      "epoch": 1.9377297794117647,
      "grad_norm": 1.0891764163970947,
      "learning_rate": 3.938723404255319e-06,
      "loss": 0.0728,
      "step": 8433
    },
    {
      "epoch": 1.9379595588235294,
      "grad_norm": 1.0954474210739136,
      "learning_rate": 3.937872340425532e-06,
      "loss": 0.0609,
      "step": 8434
    },
    {
      "epoch": 1.9381893382352942,
      "grad_norm": 1.0950149297714233,
      "learning_rate": 3.937021276595745e-06,
      "loss": 0.0629,
      "step": 8435
    },
    {
      "epoch": 1.9384191176470589,
      "grad_norm": 1.3307982683181763,
      "learning_rate": 3.936170212765958e-06,
      "loss": 0.0781,
      "step": 8436
    },
    {
      "epoch": 1.9386488970588234,
      "grad_norm": 1.116398811340332,
      "learning_rate": 3.93531914893617e-06,
      "loss": 0.0722,
      "step": 8437
    },
    {
      "epoch": 1.9388786764705883,
      "grad_norm": 1.3202780485153198,
      "learning_rate": 3.9344680851063835e-06,
      "loss": 0.0768,
      "step": 8438
    },
    {
      "epoch": 1.9391084558823528,
      "grad_norm": 1.6336675882339478,
      "learning_rate": 3.933617021276596e-06,
      "loss": 0.0743,
      "step": 8439
    },
    {
      "epoch": 1.9393382352941178,
      "grad_norm": 1.0712451934814453,
      "learning_rate": 3.932765957446809e-06,
      "loss": 0.071,
      "step": 8440
    },
    {
      "epoch": 1.9395680147058822,
      "grad_norm": 1.3821603059768677,
      "learning_rate": 3.931914893617021e-06,
      "loss": 0.0579,
      "step": 8441
    },
    {
      "epoch": 1.9397977941176472,
      "grad_norm": 1.1041038036346436,
      "learning_rate": 3.9310638297872344e-06,
      "loss": 0.065,
      "step": 8442
    },
    {
      "epoch": 1.9400275735294117,
      "grad_norm": 1.585383415222168,
      "learning_rate": 3.930212765957448e-06,
      "loss": 0.1019,
      "step": 8443
    },
    {
      "epoch": 1.9402573529411766,
      "grad_norm": 1.1476852893829346,
      "learning_rate": 3.92936170212766e-06,
      "loss": 0.0512,
      "step": 8444
    },
    {
      "epoch": 1.9404871323529411,
      "grad_norm": 1.260629653930664,
      "learning_rate": 3.928510638297873e-06,
      "loss": 0.0651,
      "step": 8445
    },
    {
      "epoch": 1.9407169117647058,
      "grad_norm": 1.4743363857269287,
      "learning_rate": 3.9276595744680854e-06,
      "loss": 0.1122,
      "step": 8446
    },
    {
      "epoch": 1.9409466911764706,
      "grad_norm": 1.3668406009674072,
      "learning_rate": 3.926808510638298e-06,
      "loss": 0.0941,
      "step": 8447
    },
    {
      "epoch": 1.9411764705882353,
      "grad_norm": 1.555425763130188,
      "learning_rate": 3.925957446808511e-06,
      "loss": 0.109,
      "step": 8448
    },
    {
      "epoch": 1.94140625,
      "grad_norm": 1.134879231452942,
      "learning_rate": 3.925106382978724e-06,
      "loss": 0.0758,
      "step": 8449
    },
    {
      "epoch": 1.9416360294117647,
      "grad_norm": 1.1954622268676758,
      "learning_rate": 3.9242553191489364e-06,
      "loss": 0.0711,
      "step": 8450
    },
    {
      "epoch": 1.9418658088235294,
      "grad_norm": 0.887325644493103,
      "learning_rate": 3.92340425531915e-06,
      "loss": 0.046,
      "step": 8451
    },
    {
      "epoch": 1.9420955882352942,
      "grad_norm": 1.0829951763153076,
      "learning_rate": 3.922553191489362e-06,
      "loss": 0.0836,
      "step": 8452
    },
    {
      "epoch": 1.9423253676470589,
      "grad_norm": 1.425049901008606,
      "learning_rate": 3.921702127659574e-06,
      "loss": 0.0977,
      "step": 8453
    },
    {
      "epoch": 1.9425551470588234,
      "grad_norm": 1.6484979391098022,
      "learning_rate": 3.920851063829787e-06,
      "loss": 0.0829,
      "step": 8454
    },
    {
      "epoch": 1.9427849264705883,
      "grad_norm": 1.2679935693740845,
      "learning_rate": 3.920000000000001e-06,
      "loss": 0.0748,
      "step": 8455
    },
    {
      "epoch": 1.9430147058823528,
      "grad_norm": 1.0983835458755493,
      "learning_rate": 3.919148936170213e-06,
      "loss": 0.0772,
      "step": 8456
    },
    {
      "epoch": 1.9432444852941178,
      "grad_norm": 1.2045725584030151,
      "learning_rate": 3.918297872340426e-06,
      "loss": 0.0671,
      "step": 8457
    },
    {
      "epoch": 1.9434742647058822,
      "grad_norm": 0.9683040380477905,
      "learning_rate": 3.917446808510638e-06,
      "loss": 0.0645,
      "step": 8458
    },
    {
      "epoch": 1.9437040441176472,
      "grad_norm": 1.0490899085998535,
      "learning_rate": 3.916595744680851e-06,
      "loss": 0.0666,
      "step": 8459
    },
    {
      "epoch": 1.9439338235294117,
      "grad_norm": 1.1413038969039917,
      "learning_rate": 3.915744680851064e-06,
      "loss": 0.0465,
      "step": 8460
    },
    {
      "epoch": 1.9441636029411766,
      "grad_norm": 1.0105302333831787,
      "learning_rate": 3.914893617021277e-06,
      "loss": 0.0641,
      "step": 8461
    },
    {
      "epoch": 1.9443933823529411,
      "grad_norm": 1.0641474723815918,
      "learning_rate": 3.91404255319149e-06,
      "loss": 0.0812,
      "step": 8462
    },
    {
      "epoch": 1.9446231617647058,
      "grad_norm": 1.127504587173462,
      "learning_rate": 3.9131914893617026e-06,
      "loss": 0.0839,
      "step": 8463
    },
    {
      "epoch": 1.9448529411764706,
      "grad_norm": 0.9318146109580994,
      "learning_rate": 3.912340425531915e-06,
      "loss": 0.0601,
      "step": 8464
    },
    {
      "epoch": 1.9450827205882353,
      "grad_norm": 1.5711737871170044,
      "learning_rate": 3.911489361702128e-06,
      "loss": 0.0541,
      "step": 8465
    },
    {
      "epoch": 1.9453125,
      "grad_norm": 1.2274426221847534,
      "learning_rate": 3.91063829787234e-06,
      "loss": 0.0567,
      "step": 8466
    },
    {
      "epoch": 1.9455422794117647,
      "grad_norm": 1.3432457447052002,
      "learning_rate": 3.9097872340425535e-06,
      "loss": 0.0812,
      "step": 8467
    },
    {
      "epoch": 1.9457720588235294,
      "grad_norm": 1.145095944404602,
      "learning_rate": 3.908936170212767e-06,
      "loss": 0.0609,
      "step": 8468
    },
    {
      "epoch": 1.9460018382352942,
      "grad_norm": 1.2243461608886719,
      "learning_rate": 3.908085106382979e-06,
      "loss": 0.053,
      "step": 8469
    },
    {
      "epoch": 1.9462316176470589,
      "grad_norm": 1.4977902173995972,
      "learning_rate": 3.907234042553192e-06,
      "loss": 0.0881,
      "step": 8470
    },
    {
      "epoch": 1.9464613970588234,
      "grad_norm": 1.7476422786712646,
      "learning_rate": 3.9063829787234045e-06,
      "loss": 0.0808,
      "step": 8471
    },
    {
      "epoch": 1.9466911764705883,
      "grad_norm": 0.7595594525337219,
      "learning_rate": 3.905531914893617e-06,
      "loss": 0.0343,
      "step": 8472
    },
    {
      "epoch": 1.9469209558823528,
      "grad_norm": 1.2285313606262207,
      "learning_rate": 3.90468085106383e-06,
      "loss": 0.105,
      "step": 8473
    },
    {
      "epoch": 1.9471507352941178,
      "grad_norm": 1.0356401205062866,
      "learning_rate": 3.903829787234043e-06,
      "loss": 0.0575,
      "step": 8474
    },
    {
      "epoch": 1.9473805147058822,
      "grad_norm": 1.4143909215927124,
      "learning_rate": 3.9029787234042555e-06,
      "loss": 0.0956,
      "step": 8475
    },
    {
      "epoch": 1.9476102941176472,
      "grad_norm": 1.2363457679748535,
      "learning_rate": 3.902127659574469e-06,
      "loss": 0.0657,
      "step": 8476
    },
    {
      "epoch": 1.9478400735294117,
      "grad_norm": 1.1220014095306396,
      "learning_rate": 3.901276595744681e-06,
      "loss": 0.0552,
      "step": 8477
    },
    {
      "epoch": 1.9480698529411766,
      "grad_norm": 1.4186724424362183,
      "learning_rate": 3.900425531914893e-06,
      "loss": 0.1316,
      "step": 8478
    },
    {
      "epoch": 1.9482996323529411,
      "grad_norm": 0.8201838731765747,
      "learning_rate": 3.8995744680851065e-06,
      "loss": 0.0363,
      "step": 8479
    },
    {
      "epoch": 1.9485294117647058,
      "grad_norm": 1.167754888534546,
      "learning_rate": 3.89872340425532e-06,
      "loss": 0.0565,
      "step": 8480
    },
    {
      "epoch": 1.9487591911764706,
      "grad_norm": 1.2269424200057983,
      "learning_rate": 3.897872340425532e-06,
      "loss": 0.0781,
      "step": 8481
    },
    {
      "epoch": 1.9489889705882353,
      "grad_norm": 1.5817394256591797,
      "learning_rate": 3.897021276595745e-06,
      "loss": 0.065,
      "step": 8482
    },
    {
      "epoch": 1.94921875,
      "grad_norm": 1.2313615083694458,
      "learning_rate": 3.8961702127659575e-06,
      "loss": 0.0561,
      "step": 8483
    },
    {
      "epoch": 1.9494485294117647,
      "grad_norm": 1.4307711124420166,
      "learning_rate": 3.895319148936171e-06,
      "loss": 0.0973,
      "step": 8484
    },
    {
      "epoch": 1.9496783088235294,
      "grad_norm": 0.992727518081665,
      "learning_rate": 3.894468085106383e-06,
      "loss": 0.0454,
      "step": 8485
    },
    {
      "epoch": 1.9499080882352942,
      "grad_norm": 1.1700173616409302,
      "learning_rate": 3.893617021276596e-06,
      "loss": 0.0544,
      "step": 8486
    },
    {
      "epoch": 1.9501378676470589,
      "grad_norm": 1.3239532709121704,
      "learning_rate": 3.892765957446809e-06,
      "loss": 0.0797,
      "step": 8487
    },
    {
      "epoch": 1.9503676470588234,
      "grad_norm": 1.0249431133270264,
      "learning_rate": 3.891914893617022e-06,
      "loss": 0.0611,
      "step": 8488
    },
    {
      "epoch": 1.9505974264705883,
      "grad_norm": 1.5247968435287476,
      "learning_rate": 3.891063829787234e-06,
      "loss": 0.0938,
      "step": 8489
    },
    {
      "epoch": 1.9508272058823528,
      "grad_norm": 1.1322062015533447,
      "learning_rate": 3.890212765957447e-06,
      "loss": 0.0446,
      "step": 8490
    },
    {
      "epoch": 1.9510569852941178,
      "grad_norm": 1.2135990858078003,
      "learning_rate": 3.8893617021276595e-06,
      "loss": 0.0719,
      "step": 8491
    },
    {
      "epoch": 1.9512867647058822,
      "grad_norm": 1.0543264150619507,
      "learning_rate": 3.888510638297873e-06,
      "loss": 0.0557,
      "step": 8492
    },
    {
      "epoch": 1.9515165441176472,
      "grad_norm": 1.371830940246582,
      "learning_rate": 3.887659574468086e-06,
      "loss": 0.1093,
      "step": 8493
    },
    {
      "epoch": 1.9517463235294117,
      "grad_norm": 1.5283867120742798,
      "learning_rate": 3.886808510638298e-06,
      "loss": 0.0854,
      "step": 8494
    },
    {
      "epoch": 1.9519761029411766,
      "grad_norm": 1.4961036443710327,
      "learning_rate": 3.885957446808511e-06,
      "loss": 0.116,
      "step": 8495
    },
    {
      "epoch": 1.9522058823529411,
      "grad_norm": 1.393420934677124,
      "learning_rate": 3.885106382978724e-06,
      "loss": 0.0895,
      "step": 8496
    },
    {
      "epoch": 1.9524356617647058,
      "grad_norm": 0.998252809047699,
      "learning_rate": 3.884255319148936e-06,
      "loss": 0.0374,
      "step": 8497
    },
    {
      "epoch": 1.9526654411764706,
      "grad_norm": 2.1938107013702393,
      "learning_rate": 3.883404255319149e-06,
      "loss": 0.0804,
      "step": 8498
    },
    {
      "epoch": 1.9528952205882353,
      "grad_norm": 1.6188126802444458,
      "learning_rate": 3.882553191489362e-06,
      "loss": 0.0743,
      "step": 8499
    },
    {
      "epoch": 1.953125,
      "grad_norm": 1.4093104600906372,
      "learning_rate": 3.881702127659575e-06,
      "loss": 0.0764,
      "step": 8500
    },
    {
      "epoch": 1.953125,
      "eval_loss": 0.07696118950843811,
      "eval_runtime": 1966.2149,
      "eval_samples_per_second": 4.53,
      "eval_steps_per_second": 2.265,
      "step": 8500
    },
    {
      "epoch": 1.9533547794117647,
      "grad_norm": 1.2291665077209473,
      "learning_rate": 3.880851063829788e-06,
      "loss": 0.0758,
      "step": 8501
    },
    {
      "epoch": 1.9535845588235294,
      "grad_norm": 1.1438002586364746,
      "learning_rate": 3.88e-06,
      "loss": 0.0804,
      "step": 8502
    },
    {
      "epoch": 1.9538143382352942,
      "grad_norm": 0.9869441986083984,
      "learning_rate": 3.8791489361702124e-06,
      "loss": 0.0536,
      "step": 8503
    },
    {
      "epoch": 1.9540441176470589,
      "grad_norm": 1.3851814270019531,
      "learning_rate": 3.878297872340426e-06,
      "loss": 0.0814,
      "step": 8504
    },
    {
      "epoch": 1.9542738970588234,
      "grad_norm": 1.0094143152236938,
      "learning_rate": 3.877446808510639e-06,
      "loss": 0.0977,
      "step": 8505
    },
    {
      "epoch": 1.9545036764705883,
      "grad_norm": 1.2097033262252808,
      "learning_rate": 3.876595744680852e-06,
      "loss": 0.1041,
      "step": 8506
    },
    {
      "epoch": 1.9547334558823528,
      "grad_norm": 1.2012805938720703,
      "learning_rate": 3.875744680851064e-06,
      "loss": 0.0827,
      "step": 8507
    },
    {
      "epoch": 1.9549632352941178,
      "grad_norm": 1.4533799886703491,
      "learning_rate": 3.874893617021277e-06,
      "loss": 0.0558,
      "step": 8508
    },
    {
      "epoch": 1.9551930147058822,
      "grad_norm": 1.4055149555206299,
      "learning_rate": 3.87404255319149e-06,
      "loss": 0.0681,
      "step": 8509
    },
    {
      "epoch": 1.9554227941176472,
      "grad_norm": 0.9181613326072693,
      "learning_rate": 3.873191489361702e-06,
      "loss": 0.0616,
      "step": 8510
    },
    {
      "epoch": 1.9556525735294117,
      "grad_norm": 0.9455387592315674,
      "learning_rate": 3.872340425531915e-06,
      "loss": 0.0621,
      "step": 8511
    },
    {
      "epoch": 1.9558823529411766,
      "grad_norm": 1.359032154083252,
      "learning_rate": 3.8714893617021284e-06,
      "loss": 0.1203,
      "step": 8512
    },
    {
      "epoch": 1.9561121323529411,
      "grad_norm": 1.0972307920455933,
      "learning_rate": 3.870638297872341e-06,
      "loss": 0.0809,
      "step": 8513
    },
    {
      "epoch": 1.9563419117647058,
      "grad_norm": 0.8564239740371704,
      "learning_rate": 3.869787234042554e-06,
      "loss": 0.0534,
      "step": 8514
    },
    {
      "epoch": 1.9565716911764706,
      "grad_norm": 0.9421980381011963,
      "learning_rate": 3.868936170212766e-06,
      "loss": 0.06,
      "step": 8515
    },
    {
      "epoch": 1.9568014705882353,
      "grad_norm": 1.0607540607452393,
      "learning_rate": 3.868085106382979e-06,
      "loss": 0.0683,
      "step": 8516
    },
    {
      "epoch": 1.95703125,
      "grad_norm": 1.1804578304290771,
      "learning_rate": 3.867234042553192e-06,
      "loss": 0.0672,
      "step": 8517
    },
    {
      "epoch": 1.9572610294117647,
      "grad_norm": 0.9258363246917725,
      "learning_rate": 3.866382978723405e-06,
      "loss": 0.0423,
      "step": 8518
    },
    {
      "epoch": 1.9574908088235294,
      "grad_norm": 1.482621669769287,
      "learning_rate": 3.865531914893617e-06,
      "loss": 0.0804,
      "step": 8519
    },
    {
      "epoch": 1.9577205882352942,
      "grad_norm": 1.3693276643753052,
      "learning_rate": 3.86468085106383e-06,
      "loss": 0.0772,
      "step": 8520
    },
    {
      "epoch": 1.9579503676470589,
      "grad_norm": 0.9602774381637573,
      "learning_rate": 3.863829787234043e-06,
      "loss": 0.0779,
      "step": 8521
    },
    {
      "epoch": 1.9581801470588234,
      "grad_norm": 1.085375189781189,
      "learning_rate": 3.862978723404255e-06,
      "loss": 0.0821,
      "step": 8522
    },
    {
      "epoch": 1.9584099264705883,
      "grad_norm": 0.8596282005310059,
      "learning_rate": 3.862127659574468e-06,
      "loss": 0.0457,
      "step": 8523
    },
    {
      "epoch": 1.9586397058823528,
      "grad_norm": 1.394425630569458,
      "learning_rate": 3.861276595744681e-06,
      "loss": 0.0598,
      "step": 8524
    },
    {
      "epoch": 1.9588694852941178,
      "grad_norm": 0.9156794548034668,
      "learning_rate": 3.860425531914894e-06,
      "loss": 0.0579,
      "step": 8525
    },
    {
      "epoch": 1.9590992647058822,
      "grad_norm": 1.1550371646881104,
      "learning_rate": 3.859574468085107e-06,
      "loss": 0.0489,
      "step": 8526
    },
    {
      "epoch": 1.9593290441176472,
      "grad_norm": 1.1783612966537476,
      "learning_rate": 3.858723404255319e-06,
      "loss": 0.0862,
      "step": 8527
    },
    {
      "epoch": 1.9595588235294117,
      "grad_norm": 1.2163804769515991,
      "learning_rate": 3.857872340425532e-06,
      "loss": 0.0678,
      "step": 8528
    },
    {
      "epoch": 1.9597886029411766,
      "grad_norm": 1.2036436796188354,
      "learning_rate": 3.857021276595745e-06,
      "loss": 0.058,
      "step": 8529
    },
    {
      "epoch": 1.9600183823529411,
      "grad_norm": 1.1816952228546143,
      "learning_rate": 3.856170212765958e-06,
      "loss": 0.0737,
      "step": 8530
    },
    {
      "epoch": 1.9602481617647058,
      "grad_norm": 1.1264605522155762,
      "learning_rate": 3.855319148936171e-06,
      "loss": 0.0504,
      "step": 8531
    },
    {
      "epoch": 1.9604779411764706,
      "grad_norm": 1.3387516736984253,
      "learning_rate": 3.854468085106383e-06,
      "loss": 0.0647,
      "step": 8532
    },
    {
      "epoch": 1.9607077205882353,
      "grad_norm": 0.9150055050849915,
      "learning_rate": 3.853617021276596e-06,
      "loss": 0.0489,
      "step": 8533
    },
    {
      "epoch": 1.9609375,
      "grad_norm": 1.6153557300567627,
      "learning_rate": 3.852765957446809e-06,
      "loss": 0.0722,
      "step": 8534
    },
    {
      "epoch": 1.9611672794117647,
      "grad_norm": 0.977798342704773,
      "learning_rate": 3.851914893617021e-06,
      "loss": 0.0591,
      "step": 8535
    },
    {
      "epoch": 1.9613970588235294,
      "grad_norm": 1.2833619117736816,
      "learning_rate": 3.851063829787234e-06,
      "loss": 0.0891,
      "step": 8536
    },
    {
      "epoch": 1.9616268382352942,
      "grad_norm": 1.78635573387146,
      "learning_rate": 3.8502127659574475e-06,
      "loss": 0.095,
      "step": 8537
    },
    {
      "epoch": 1.9618566176470589,
      "grad_norm": 1.0162463188171387,
      "learning_rate": 3.84936170212766e-06,
      "loss": 0.0698,
      "step": 8538
    },
    {
      "epoch": 1.9620863970588234,
      "grad_norm": 1.0934590101242065,
      "learning_rate": 3.848510638297873e-06,
      "loss": 0.0513,
      "step": 8539
    },
    {
      "epoch": 1.9623161764705883,
      "grad_norm": 1.4436885118484497,
      "learning_rate": 3.847659574468085e-06,
      "loss": 0.082,
      "step": 8540
    },
    {
      "epoch": 1.9625459558823528,
      "grad_norm": 1.462638258934021,
      "learning_rate": 3.846808510638298e-06,
      "loss": 0.075,
      "step": 8541
    },
    {
      "epoch": 1.9627757352941178,
      "grad_norm": 1.0334919691085815,
      "learning_rate": 3.845957446808511e-06,
      "loss": 0.0736,
      "step": 8542
    },
    {
      "epoch": 1.9630055147058822,
      "grad_norm": 1.42789626121521,
      "learning_rate": 3.845106382978724e-06,
      "loss": 0.0849,
      "step": 8543
    },
    {
      "epoch": 1.9632352941176472,
      "grad_norm": 0.9334893226623535,
      "learning_rate": 3.844255319148936e-06,
      "loss": 0.0496,
      "step": 8544
    },
    {
      "epoch": 1.9634650735294117,
      "grad_norm": 0.9663048386573792,
      "learning_rate": 3.8434042553191495e-06,
      "loss": 0.0474,
      "step": 8545
    },
    {
      "epoch": 1.9636948529411766,
      "grad_norm": 1.1022140979766846,
      "learning_rate": 3.842553191489362e-06,
      "loss": 0.0613,
      "step": 8546
    },
    {
      "epoch": 1.9639246323529411,
      "grad_norm": 1.2836453914642334,
      "learning_rate": 3.841702127659574e-06,
      "loss": 0.0579,
      "step": 8547
    },
    {
      "epoch": 1.9641544117647058,
      "grad_norm": 2.4735779762268066,
      "learning_rate": 3.840851063829787e-06,
      "loss": 0.07,
      "step": 8548
    },
    {
      "epoch": 1.9643841911764706,
      "grad_norm": 1.481797456741333,
      "learning_rate": 3.8400000000000005e-06,
      "loss": 0.13,
      "step": 8549
    },
    {
      "epoch": 1.9646139705882353,
      "grad_norm": 1.4574328660964966,
      "learning_rate": 3.839148936170214e-06,
      "loss": 0.0668,
      "step": 8550
    },
    {
      "epoch": 1.96484375,
      "grad_norm": 1.2283269166946411,
      "learning_rate": 3.838297872340426e-06,
      "loss": 0.0977,
      "step": 8551
    },
    {
      "epoch": 1.9650735294117647,
      "grad_norm": 1.2980374097824097,
      "learning_rate": 3.837446808510638e-06,
      "loss": 0.0883,
      "step": 8552
    },
    {
      "epoch": 1.9653033088235294,
      "grad_norm": 1.4001561403274536,
      "learning_rate": 3.8365957446808515e-06,
      "loss": 0.1,
      "step": 8553
    },
    {
      "epoch": 1.9655330882352942,
      "grad_norm": 1.257163166999817,
      "learning_rate": 3.835744680851064e-06,
      "loss": 0.0673,
      "step": 8554
    },
    {
      "epoch": 1.9657628676470589,
      "grad_norm": 1.6015907526016235,
      "learning_rate": 3.834893617021277e-06,
      "loss": 0.0949,
      "step": 8555
    },
    {
      "epoch": 1.9659926470588234,
      "grad_norm": 0.8978231549263,
      "learning_rate": 3.83404255319149e-06,
      "loss": 0.0643,
      "step": 8556
    },
    {
      "epoch": 1.9662224264705883,
      "grad_norm": 1.267883539199829,
      "learning_rate": 3.8331914893617025e-06,
      "loss": 0.0754,
      "step": 8557
    },
    {
      "epoch": 1.9664522058823528,
      "grad_norm": 1.17085862159729,
      "learning_rate": 3.832340425531915e-06,
      "loss": 0.0556,
      "step": 8558
    },
    {
      "epoch": 1.9666819852941178,
      "grad_norm": 1.1069040298461914,
      "learning_rate": 3.831489361702128e-06,
      "loss": 0.07,
      "step": 8559
    },
    {
      "epoch": 1.9669117647058822,
      "grad_norm": 1.1729910373687744,
      "learning_rate": 3.83063829787234e-06,
      "loss": 0.0795,
      "step": 8560
    },
    {
      "epoch": 1.9671415441176472,
      "grad_norm": 1.3410069942474365,
      "learning_rate": 3.8297872340425535e-06,
      "loss": 0.0715,
      "step": 8561
    },
    {
      "epoch": 1.9673713235294117,
      "grad_norm": 1.5248243808746338,
      "learning_rate": 3.828936170212767e-06,
      "loss": 0.0799,
      "step": 8562
    },
    {
      "epoch": 1.9676011029411766,
      "grad_norm": 1.0260323286056519,
      "learning_rate": 3.828085106382979e-06,
      "loss": 0.0604,
      "step": 8563
    },
    {
      "epoch": 1.9678308823529411,
      "grad_norm": 1.431868314743042,
      "learning_rate": 3.827234042553192e-06,
      "loss": 0.0852,
      "step": 8564
    },
    {
      "epoch": 1.9680606617647058,
      "grad_norm": 1.7004512548446655,
      "learning_rate": 3.8263829787234045e-06,
      "loss": 0.1036,
      "step": 8565
    },
    {
      "epoch": 1.9682904411764706,
      "grad_norm": 1.1045074462890625,
      "learning_rate": 3.825531914893617e-06,
      "loss": 0.0858,
      "step": 8566
    },
    {
      "epoch": 1.9685202205882353,
      "grad_norm": 1.032151699066162,
      "learning_rate": 3.82468085106383e-06,
      "loss": 0.0822,
      "step": 8567
    },
    {
      "epoch": 1.96875,
      "grad_norm": 1.000221610069275,
      "learning_rate": 3.823829787234043e-06,
      "loss": 0.0596,
      "step": 8568
    },
    {
      "epoch": 1.9689797794117647,
      "grad_norm": 0.8407154083251953,
      "learning_rate": 3.822978723404256e-06,
      "loss": 0.063,
      "step": 8569
    },
    {
      "epoch": 1.9692095588235294,
      "grad_norm": 1.5609986782073975,
      "learning_rate": 3.822127659574469e-06,
      "loss": 0.0623,
      "step": 8570
    },
    {
      "epoch": 1.9694393382352942,
      "grad_norm": 1.4667869806289673,
      "learning_rate": 3.821276595744681e-06,
      "loss": 0.0753,
      "step": 8571
    },
    {
      "epoch": 1.9696691176470589,
      "grad_norm": 1.0124775171279907,
      "learning_rate": 3.820425531914894e-06,
      "loss": 0.0733,
      "step": 8572
    },
    {
      "epoch": 1.9698988970588234,
      "grad_norm": 0.9410101771354675,
      "learning_rate": 3.8195744680851064e-06,
      "loss": 0.0533,
      "step": 8573
    },
    {
      "epoch": 1.9701286764705883,
      "grad_norm": 1.7132984399795532,
      "learning_rate": 3.81872340425532e-06,
      "loss": 0.1147,
      "step": 8574
    },
    {
      "epoch": 1.9703584558823528,
      "grad_norm": 1.137155294418335,
      "learning_rate": 3.817872340425533e-06,
      "loss": 0.0592,
      "step": 8575
    },
    {
      "epoch": 1.9705882352941178,
      "grad_norm": 1.0545698404312134,
      "learning_rate": 3.817021276595745e-06,
      "loss": 0.0608,
      "step": 8576
    },
    {
      "epoch": 1.9708180147058822,
      "grad_norm": 1.003818154335022,
      "learning_rate": 3.816170212765957e-06,
      "loss": 0.0617,
      "step": 8577
    },
    {
      "epoch": 1.9710477941176472,
      "grad_norm": 1.2076001167297363,
      "learning_rate": 3.815319148936171e-06,
      "loss": 0.0529,
      "step": 8578
    },
    {
      "epoch": 1.9712775735294117,
      "grad_norm": 1.2202837467193604,
      "learning_rate": 3.814468085106383e-06,
      "loss": 0.0578,
      "step": 8579
    },
    {
      "epoch": 1.9715073529411766,
      "grad_norm": 1.2100309133529663,
      "learning_rate": 3.813617021276596e-06,
      "loss": 0.0606,
      "step": 8580
    },
    {
      "epoch": 1.9717371323529411,
      "grad_norm": 1.4320367574691772,
      "learning_rate": 3.812765957446809e-06,
      "loss": 0.0797,
      "step": 8581
    },
    {
      "epoch": 1.9719669117647058,
      "grad_norm": 1.0360469818115234,
      "learning_rate": 3.8119148936170216e-06,
      "loss": 0.0853,
      "step": 8582
    },
    {
      "epoch": 1.9721966911764706,
      "grad_norm": 1.254217505455017,
      "learning_rate": 3.8110638297872343e-06,
      "loss": 0.058,
      "step": 8583
    },
    {
      "epoch": 1.9724264705882353,
      "grad_norm": 1.3145837783813477,
      "learning_rate": 3.810212765957447e-06,
      "loss": 0.0696,
      "step": 8584
    },
    {
      "epoch": 1.97265625,
      "grad_norm": 1.0826236009597778,
      "learning_rate": 3.80936170212766e-06,
      "loss": 0.057,
      "step": 8585
    },
    {
      "epoch": 1.9728860294117647,
      "grad_norm": 0.9837414026260376,
      "learning_rate": 3.8085106382978726e-06,
      "loss": 0.0423,
      "step": 8586
    },
    {
      "epoch": 1.9731158088235294,
      "grad_norm": 1.4549578428268433,
      "learning_rate": 3.8076595744680857e-06,
      "loss": 0.0958,
      "step": 8587
    },
    {
      "epoch": 1.9733455882352942,
      "grad_norm": 1.253799319267273,
      "learning_rate": 3.806808510638298e-06,
      "loss": 0.0656,
      "step": 8588
    },
    {
      "epoch": 1.9735753676470589,
      "grad_norm": 1.248351812362671,
      "learning_rate": 3.805957446808511e-06,
      "loss": 0.0793,
      "step": 8589
    },
    {
      "epoch": 1.9738051470588234,
      "grad_norm": 1.264922857284546,
      "learning_rate": 3.805106382978724e-06,
      "loss": 0.0917,
      "step": 8590
    },
    {
      "epoch": 1.9740349264705883,
      "grad_norm": 0.8511403203010559,
      "learning_rate": 3.8042553191489367e-06,
      "loss": 0.0581,
      "step": 8591
    },
    {
      "epoch": 1.9742647058823528,
      "grad_norm": 1.0201096534729004,
      "learning_rate": 3.803404255319149e-06,
      "loss": 0.0504,
      "step": 8592
    },
    {
      "epoch": 1.9744944852941178,
      "grad_norm": 1.0460216999053955,
      "learning_rate": 3.8025531914893622e-06,
      "loss": 0.0465,
      "step": 8593
    },
    {
      "epoch": 1.9747242647058822,
      "grad_norm": 1.5989725589752197,
      "learning_rate": 3.801702127659575e-06,
      "loss": 0.0873,
      "step": 8594
    },
    {
      "epoch": 1.9749540441176472,
      "grad_norm": 1.188165545463562,
      "learning_rate": 3.8008510638297873e-06,
      "loss": 0.0956,
      "step": 8595
    },
    {
      "epoch": 1.9751838235294117,
      "grad_norm": 1.5296430587768555,
      "learning_rate": 3.8000000000000005e-06,
      "loss": 0.0885,
      "step": 8596
    },
    {
      "epoch": 1.9754136029411766,
      "grad_norm": 1.037951946258545,
      "learning_rate": 3.799148936170213e-06,
      "loss": 0.0372,
      "step": 8597
    },
    {
      "epoch": 1.9756433823529411,
      "grad_norm": 1.2999792098999023,
      "learning_rate": 3.7982978723404255e-06,
      "loss": 0.0752,
      "step": 8598
    },
    {
      "epoch": 1.9758731617647058,
      "grad_norm": 1.4116394519805908,
      "learning_rate": 3.7974468085106387e-06,
      "loss": 0.092,
      "step": 8599
    },
    {
      "epoch": 1.9761029411764706,
      "grad_norm": 1.2460284233093262,
      "learning_rate": 3.7965957446808515e-06,
      "loss": 0.0821,
      "step": 8600
    },
    {
      "epoch": 1.9763327205882353,
      "grad_norm": 1.5610414743423462,
      "learning_rate": 3.7957446808510638e-06,
      "loss": 0.0666,
      "step": 8601
    },
    {
      "epoch": 1.9765625,
      "grad_norm": 1.0413239002227783,
      "learning_rate": 3.794893617021277e-06,
      "loss": 0.0445,
      "step": 8602
    },
    {
      "epoch": 1.9767922794117647,
      "grad_norm": 1.009876012802124,
      "learning_rate": 3.7940425531914897e-06,
      "loss": 0.0554,
      "step": 8603
    },
    {
      "epoch": 1.9770220588235294,
      "grad_norm": 1.0415455102920532,
      "learning_rate": 3.7931914893617024e-06,
      "loss": 0.0599,
      "step": 8604
    },
    {
      "epoch": 1.9772518382352942,
      "grad_norm": 0.987676203250885,
      "learning_rate": 3.792340425531915e-06,
      "loss": 0.0641,
      "step": 8605
    },
    {
      "epoch": 1.9774816176470589,
      "grad_norm": 1.30536687374115,
      "learning_rate": 3.791489361702128e-06,
      "loss": 0.0895,
      "step": 8606
    },
    {
      "epoch": 1.9777113970588234,
      "grad_norm": 1.3718228340148926,
      "learning_rate": 3.7906382978723407e-06,
      "loss": 0.0798,
      "step": 8607
    },
    {
      "epoch": 1.9779411764705883,
      "grad_norm": 1.3650022745132446,
      "learning_rate": 3.7897872340425534e-06,
      "loss": 0.0817,
      "step": 8608
    },
    {
      "epoch": 1.9781709558823528,
      "grad_norm": 1.2933183908462524,
      "learning_rate": 3.788936170212766e-06,
      "loss": 0.0807,
      "step": 8609
    },
    {
      "epoch": 1.9784007352941178,
      "grad_norm": 1.135446310043335,
      "learning_rate": 3.788085106382979e-06,
      "loss": 0.083,
      "step": 8610
    },
    {
      "epoch": 1.9786305147058822,
      "grad_norm": 0.9113188982009888,
      "learning_rate": 3.7872340425531917e-06,
      "loss": 0.0606,
      "step": 8611
    },
    {
      "epoch": 1.9788602941176472,
      "grad_norm": 1.064093828201294,
      "learning_rate": 3.786382978723405e-06,
      "loss": 0.0629,
      "step": 8612
    },
    {
      "epoch": 1.9790900735294117,
      "grad_norm": 1.0614686012268066,
      "learning_rate": 3.7855319148936176e-06,
      "loss": 0.0595,
      "step": 8613
    },
    {
      "epoch": 1.9793198529411766,
      "grad_norm": 1.5441572666168213,
      "learning_rate": 3.78468085106383e-06,
      "loss": 0.1095,
      "step": 8614
    },
    {
      "epoch": 1.9795496323529411,
      "grad_norm": 1.0136301517486572,
      "learning_rate": 3.783829787234043e-06,
      "loss": 0.0575,
      "step": 8615
    },
    {
      "epoch": 1.9797794117647058,
      "grad_norm": 1.065029501914978,
      "learning_rate": 3.782978723404256e-06,
      "loss": 0.0678,
      "step": 8616
    },
    {
      "epoch": 1.9800091911764706,
      "grad_norm": 1.3248401880264282,
      "learning_rate": 3.782127659574468e-06,
      "loss": 0.0636,
      "step": 8617
    },
    {
      "epoch": 1.9802389705882353,
      "grad_norm": 1.6020667552947998,
      "learning_rate": 3.7812765957446813e-06,
      "loss": 0.0907,
      "step": 8618
    },
    {
      "epoch": 1.98046875,
      "grad_norm": 1.5738962888717651,
      "learning_rate": 3.780425531914894e-06,
      "loss": 0.0747,
      "step": 8619
    },
    {
      "epoch": 1.9806985294117647,
      "grad_norm": 1.168227195739746,
      "learning_rate": 3.7795744680851064e-06,
      "loss": 0.063,
      "step": 8620
    },
    {
      "epoch": 1.9809283088235294,
      "grad_norm": 1.7811905145645142,
      "learning_rate": 3.7787234042553196e-06,
      "loss": 0.0948,
      "step": 8621
    },
    {
      "epoch": 1.9811580882352942,
      "grad_norm": 1.2028613090515137,
      "learning_rate": 3.7778723404255323e-06,
      "loss": 0.061,
      "step": 8622
    },
    {
      "epoch": 1.9813878676470589,
      "grad_norm": 1.3977820873260498,
      "learning_rate": 3.7770212765957446e-06,
      "loss": 0.0894,
      "step": 8623
    },
    {
      "epoch": 1.9816176470588234,
      "grad_norm": 1.0896172523498535,
      "learning_rate": 3.776170212765958e-06,
      "loss": 0.0561,
      "step": 8624
    },
    {
      "epoch": 1.9818474264705883,
      "grad_norm": 1.5118032693862915,
      "learning_rate": 3.7753191489361706e-06,
      "loss": 0.0671,
      "step": 8625
    },
    {
      "epoch": 1.9820772058823528,
      "grad_norm": 1.1323176622390747,
      "learning_rate": 3.774468085106383e-06,
      "loss": 0.0552,
      "step": 8626
    },
    {
      "epoch": 1.9823069852941178,
      "grad_norm": 1.6825432777404785,
      "learning_rate": 3.773617021276596e-06,
      "loss": 0.0731,
      "step": 8627
    },
    {
      "epoch": 1.9825367647058822,
      "grad_norm": 1.2827149629592896,
      "learning_rate": 3.772765957446809e-06,
      "loss": 0.0672,
      "step": 8628
    },
    {
      "epoch": 1.9827665441176472,
      "grad_norm": 1.3674921989440918,
      "learning_rate": 3.7719148936170215e-06,
      "loss": 0.0885,
      "step": 8629
    },
    {
      "epoch": 1.9829963235294117,
      "grad_norm": 1.210009217262268,
      "learning_rate": 3.7710638297872343e-06,
      "loss": 0.074,
      "step": 8630
    },
    {
      "epoch": 1.9832261029411766,
      "grad_norm": 1.4019018411636353,
      "learning_rate": 3.770212765957447e-06,
      "loss": 0.0534,
      "step": 8631
    },
    {
      "epoch": 1.9834558823529411,
      "grad_norm": 1.1034934520721436,
      "learning_rate": 3.7693617021276598e-06,
      "loss": 0.0834,
      "step": 8632
    },
    {
      "epoch": 1.9836856617647058,
      "grad_norm": 1.3827332258224487,
      "learning_rate": 3.7685106382978725e-06,
      "loss": 0.0656,
      "step": 8633
    },
    {
      "epoch": 1.9839154411764706,
      "grad_norm": 1.4934577941894531,
      "learning_rate": 3.7676595744680857e-06,
      "loss": 0.0975,
      "step": 8634
    },
    {
      "epoch": 1.9841452205882353,
      "grad_norm": 1.3877227306365967,
      "learning_rate": 3.7668085106382984e-06,
      "loss": 0.0575,
      "step": 8635
    },
    {
      "epoch": 1.984375,
      "grad_norm": 1.4173996448516846,
      "learning_rate": 3.7659574468085108e-06,
      "loss": 0.0702,
      "step": 8636
    },
    {
      "epoch": 1.9846047794117647,
      "grad_norm": 0.9728463292121887,
      "learning_rate": 3.765106382978724e-06,
      "loss": 0.0579,
      "step": 8637
    },
    {
      "epoch": 1.9848345588235294,
      "grad_norm": 1.2122842073440552,
      "learning_rate": 3.7642553191489367e-06,
      "loss": 0.062,
      "step": 8638
    },
    {
      "epoch": 1.9850643382352942,
      "grad_norm": 1.1376895904541016,
      "learning_rate": 3.763404255319149e-06,
      "loss": 0.0692,
      "step": 8639
    },
    {
      "epoch": 1.9852941176470589,
      "grad_norm": 1.0840535163879395,
      "learning_rate": 3.762553191489362e-06,
      "loss": 0.0545,
      "step": 8640
    },
    {
      "epoch": 1.9855238970588234,
      "grad_norm": 1.2815154790878296,
      "learning_rate": 3.761702127659575e-06,
      "loss": 0.0921,
      "step": 8641
    },
    {
      "epoch": 1.9857536764705883,
      "grad_norm": 2.020505905151367,
      "learning_rate": 3.7608510638297873e-06,
      "loss": 0.1219,
      "step": 8642
    },
    {
      "epoch": 1.9859834558823528,
      "grad_norm": 1.128572940826416,
      "learning_rate": 3.7600000000000004e-06,
      "loss": 0.0561,
      "step": 8643
    },
    {
      "epoch": 1.9862132352941178,
      "grad_norm": 1.4125280380249023,
      "learning_rate": 3.759148936170213e-06,
      "loss": 0.1077,
      "step": 8644
    },
    {
      "epoch": 1.9864430147058822,
      "grad_norm": 1.075585961341858,
      "learning_rate": 3.7582978723404255e-06,
      "loss": 0.0577,
      "step": 8645
    },
    {
      "epoch": 1.9866727941176472,
      "grad_norm": 1.4154630899429321,
      "learning_rate": 3.7574468085106387e-06,
      "loss": 0.068,
      "step": 8646
    },
    {
      "epoch": 1.9869025735294117,
      "grad_norm": 1.4415265321731567,
      "learning_rate": 3.7565957446808514e-06,
      "loss": 0.0937,
      "step": 8647
    },
    {
      "epoch": 1.9871323529411766,
      "grad_norm": 1.0242388248443604,
      "learning_rate": 3.7557446808510637e-06,
      "loss": 0.0647,
      "step": 8648
    },
    {
      "epoch": 1.9873621323529411,
      "grad_norm": 1.1704432964324951,
      "learning_rate": 3.754893617021277e-06,
      "loss": 0.0713,
      "step": 8649
    },
    {
      "epoch": 1.9875919117647058,
      "grad_norm": 0.9088587164878845,
      "learning_rate": 3.7540425531914897e-06,
      "loss": 0.0488,
      "step": 8650
    },
    {
      "epoch": 1.9878216911764706,
      "grad_norm": 1.4629708528518677,
      "learning_rate": 3.7531914893617024e-06,
      "loss": 0.1151,
      "step": 8651
    },
    {
      "epoch": 1.9880514705882353,
      "grad_norm": 1.2989331483840942,
      "learning_rate": 3.752340425531915e-06,
      "loss": 0.0698,
      "step": 8652
    },
    {
      "epoch": 1.98828125,
      "grad_norm": 1.0633875131607056,
      "learning_rate": 3.751489361702128e-06,
      "loss": 0.0543,
      "step": 8653
    },
    {
      "epoch": 1.9885110294117647,
      "grad_norm": 1.5681759119033813,
      "learning_rate": 3.7506382978723406e-06,
      "loss": 0.0814,
      "step": 8654
    },
    {
      "epoch": 1.9887408088235294,
      "grad_norm": 1.4977900981903076,
      "learning_rate": 3.7497872340425534e-06,
      "loss": 0.0899,
      "step": 8655
    },
    {
      "epoch": 1.9889705882352942,
      "grad_norm": 1.2048522233963013,
      "learning_rate": 3.748936170212766e-06,
      "loss": 0.0715,
      "step": 8656
    },
    {
      "epoch": 1.9892003676470589,
      "grad_norm": 1.0283873081207275,
      "learning_rate": 3.7480851063829793e-06,
      "loss": 0.0639,
      "step": 8657
    },
    {
      "epoch": 1.9894301470588234,
      "grad_norm": 0.9842530488967896,
      "learning_rate": 3.7472340425531916e-06,
      "loss": 0.0825,
      "step": 8658
    },
    {
      "epoch": 1.9896599264705883,
      "grad_norm": 1.3898279666900635,
      "learning_rate": 3.746382978723405e-06,
      "loss": 0.0929,
      "step": 8659
    },
    {
      "epoch": 1.9898897058823528,
      "grad_norm": 1.2525070905685425,
      "learning_rate": 3.7455319148936175e-06,
      "loss": 0.0669,
      "step": 8660
    },
    {
      "epoch": 1.9901194852941178,
      "grad_norm": 1.0536218881607056,
      "learning_rate": 3.74468085106383e-06,
      "loss": 0.0624,
      "step": 8661
    },
    {
      "epoch": 1.9903492647058822,
      "grad_norm": 1.131121039390564,
      "learning_rate": 3.743829787234043e-06,
      "loss": 0.0764,
      "step": 8662
    },
    {
      "epoch": 1.9905790441176472,
      "grad_norm": 1.4966284036636353,
      "learning_rate": 3.7429787234042558e-06,
      "loss": 0.0785,
      "step": 8663
    },
    {
      "epoch": 1.9908088235294117,
      "grad_norm": 1.464224100112915,
      "learning_rate": 3.742127659574468e-06,
      "loss": 0.0755,
      "step": 8664
    },
    {
      "epoch": 1.9910386029411766,
      "grad_norm": 1.207810401916504,
      "learning_rate": 3.7412765957446813e-06,
      "loss": 0.0706,
      "step": 8665
    },
    {
      "epoch": 1.9912683823529411,
      "grad_norm": 1.936987280845642,
      "learning_rate": 3.740425531914894e-06,
      "loss": 0.0792,
      "step": 8666
    },
    {
      "epoch": 1.9914981617647058,
      "grad_norm": 0.9698772430419922,
      "learning_rate": 3.7395744680851064e-06,
      "loss": 0.0598,
      "step": 8667
    },
    {
      "epoch": 1.9917279411764706,
      "grad_norm": 0.9198191165924072,
      "learning_rate": 3.7387234042553195e-06,
      "loss": 0.0497,
      "step": 8668
    },
    {
      "epoch": 1.9919577205882353,
      "grad_norm": 0.9636721611022949,
      "learning_rate": 3.7378723404255323e-06,
      "loss": 0.0596,
      "step": 8669
    },
    {
      "epoch": 1.9921875,
      "grad_norm": 1.6373251676559448,
      "learning_rate": 3.7370212765957446e-06,
      "loss": 0.1002,
      "step": 8670
    },
    {
      "epoch": 1.9924172794117647,
      "grad_norm": 1.0812989473342896,
      "learning_rate": 3.7361702127659578e-06,
      "loss": 0.0793,
      "step": 8671
    },
    {
      "epoch": 1.9926470588235294,
      "grad_norm": 1.5859013795852661,
      "learning_rate": 3.7353191489361705e-06,
      "loss": 0.1141,
      "step": 8672
    },
    {
      "epoch": 1.9928768382352942,
      "grad_norm": 0.9991155862808228,
      "learning_rate": 3.734468085106383e-06,
      "loss": 0.0808,
      "step": 8673
    },
    {
      "epoch": 1.9931066176470589,
      "grad_norm": 1.1218798160552979,
      "learning_rate": 3.733617021276596e-06,
      "loss": 0.0588,
      "step": 8674
    },
    {
      "epoch": 1.9933363970588234,
      "grad_norm": 1.148641586303711,
      "learning_rate": 3.7327659574468088e-06,
      "loss": 0.0574,
      "step": 8675
    },
    {
      "epoch": 1.9935661764705883,
      "grad_norm": 0.7701224088668823,
      "learning_rate": 3.7319148936170215e-06,
      "loss": 0.0371,
      "step": 8676
    },
    {
      "epoch": 1.9937959558823528,
      "grad_norm": 1.3565385341644287,
      "learning_rate": 3.7310638297872342e-06,
      "loss": 0.0737,
      "step": 8677
    },
    {
      "epoch": 1.9940257352941178,
      "grad_norm": 1.0018846988677979,
      "learning_rate": 3.730212765957447e-06,
      "loss": 0.0475,
      "step": 8678
    },
    {
      "epoch": 1.9942555147058822,
      "grad_norm": 1.528901219367981,
      "learning_rate": 3.72936170212766e-06,
      "loss": 0.0986,
      "step": 8679
    },
    {
      "epoch": 1.9944852941176472,
      "grad_norm": 0.8415629863739014,
      "learning_rate": 3.7285106382978725e-06,
      "loss": 0.057,
      "step": 8680
    },
    {
      "epoch": 1.9947150735294117,
      "grad_norm": 1.3410240411758423,
      "learning_rate": 3.7276595744680857e-06,
      "loss": 0.085,
      "step": 8681
    },
    {
      "epoch": 1.9949448529411766,
      "grad_norm": 1.1138145923614502,
      "learning_rate": 3.7268085106382984e-06,
      "loss": 0.0638,
      "step": 8682
    },
    {
      "epoch": 1.9951746323529411,
      "grad_norm": 1.5149264335632324,
      "learning_rate": 3.7259574468085107e-06,
      "loss": 0.0928,
      "step": 8683
    },
    {
      "epoch": 1.9954044117647058,
      "grad_norm": 1.2666270732879639,
      "learning_rate": 3.725106382978724e-06,
      "loss": 0.0875,
      "step": 8684
    },
    {
      "epoch": 1.9956341911764706,
      "grad_norm": 1.293469786643982,
      "learning_rate": 3.7242553191489366e-06,
      "loss": 0.0719,
      "step": 8685
    },
    {
      "epoch": 1.9958639705882353,
      "grad_norm": 1.333479642868042,
      "learning_rate": 3.723404255319149e-06,
      "loss": 0.0711,
      "step": 8686
    },
    {
      "epoch": 1.99609375,
      "grad_norm": 1.1810606718063354,
      "learning_rate": 3.722553191489362e-06,
      "loss": 0.0808,
      "step": 8687
    },
    {
      "epoch": 1.9963235294117647,
      "grad_norm": 1.6997023820877075,
      "learning_rate": 3.721702127659575e-06,
      "loss": 0.0893,
      "step": 8688
    },
    {
      "epoch": 1.9965533088235294,
      "grad_norm": 0.988763689994812,
      "learning_rate": 3.720851063829787e-06,
      "loss": 0.062,
      "step": 8689
    },
    {
      "epoch": 1.9967830882352942,
      "grad_norm": 1.155216932296753,
      "learning_rate": 3.7200000000000004e-06,
      "loss": 0.068,
      "step": 8690
    },
    {
      "epoch": 1.9970128676470589,
      "grad_norm": 1.4663634300231934,
      "learning_rate": 3.719148936170213e-06,
      "loss": 0.0961,
      "step": 8691
    },
    {
      "epoch": 1.9972426470588234,
      "grad_norm": 1.0503703355789185,
      "learning_rate": 3.7182978723404255e-06,
      "loss": 0.0685,
      "step": 8692
    },
    {
      "epoch": 1.9974724264705883,
      "grad_norm": 1.21474027633667,
      "learning_rate": 3.7174468085106386e-06,
      "loss": 0.0753,
      "step": 8693
    },
    {
      "epoch": 1.9977022058823528,
      "grad_norm": 1.1062020063400269,
      "learning_rate": 3.7165957446808514e-06,
      "loss": 0.0669,
      "step": 8694
    },
    {
      "epoch": 1.9979319852941178,
      "grad_norm": 1.0432542562484741,
      "learning_rate": 3.7157446808510637e-06,
      "loss": 0.0604,
      "step": 8695
    },
    {
      "epoch": 1.9981617647058822,
      "grad_norm": 1.220718502998352,
      "learning_rate": 3.714893617021277e-06,
      "loss": 0.0995,
      "step": 8696
    },
    {
      "epoch": 1.9983915441176472,
      "grad_norm": 1.6804393529891968,
      "learning_rate": 3.7140425531914896e-06,
      "loss": 0.1006,
      "step": 8697
    },
    {
      "epoch": 1.9986213235294117,
      "grad_norm": 1.368550181388855,
      "learning_rate": 3.7131914893617028e-06,
      "loss": 0.0744,
      "step": 8698
    },
    {
      "epoch": 1.9988511029411766,
      "grad_norm": 1.6763317584991455,
      "learning_rate": 3.712340425531915e-06,
      "loss": 0.0993,
      "step": 8699
    },
    {
      "epoch": 1.9990808823529411,
      "grad_norm": 1.0031981468200684,
      "learning_rate": 3.711489361702128e-06,
      "loss": 0.057,
      "step": 8700
    },
    {
      "epoch": 1.9993106617647058,
      "grad_norm": 1.2766327857971191,
      "learning_rate": 3.710638297872341e-06,
      "loss": 0.0683,
      "step": 8701
    },
    {
      "epoch": 1.9995404411764706,
      "grad_norm": 1.4129359722137451,
      "learning_rate": 3.7097872340425533e-06,
      "loss": 0.1085,
      "step": 8702
    },
    {
      "epoch": 1.9997702205882353,
      "grad_norm": 1.0621707439422607,
      "learning_rate": 3.7089361702127665e-06,
      "loss": 0.0607,
      "step": 8703
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.825360655784607,
      "learning_rate": 3.7080851063829793e-06,
      "loss": 0.0924,
      "step": 8704
    }
  ],
  "logging_steps": 1,
  "max_steps": 13056,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.441920402328453e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
