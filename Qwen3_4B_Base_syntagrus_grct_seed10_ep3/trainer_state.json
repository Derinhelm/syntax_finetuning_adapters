{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 13056,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00022977941176470588,
      "grad_norm": 1.7368977069854736,
      "learning_rate": 0.0,
      "loss": 1.8037,
      "step": 1
    },
    {
      "epoch": 0.00045955882352941176,
      "grad_norm": 1.9783179759979248,
      "learning_rate": 4.595588235294118e-09,
      "loss": 1.9701,
      "step": 2
    },
    {
      "epoch": 0.0006893382352941177,
      "grad_norm": 1.6025197505950928,
      "learning_rate": 9.191176470588236e-09,
      "loss": 1.8189,
      "step": 3
    },
    {
      "epoch": 0.0009191176470588235,
      "grad_norm": 1.9243957996368408,
      "learning_rate": 1.3786764705882355e-08,
      "loss": 2.0371,
      "step": 4
    },
    {
      "epoch": 0.0011488970588235295,
      "grad_norm": 1.7099937200546265,
      "learning_rate": 1.8382352941176472e-08,
      "loss": 1.8565,
      "step": 5
    },
    {
      "epoch": 0.0013786764705882354,
      "grad_norm": 2.1033902168273926,
      "learning_rate": 2.297794117647059e-08,
      "loss": 2.1013,
      "step": 6
    },
    {
      "epoch": 0.001608455882352941,
      "grad_norm": 1.5919826030731201,
      "learning_rate": 2.757352941176471e-08,
      "loss": 1.6467,
      "step": 7
    },
    {
      "epoch": 0.001838235294117647,
      "grad_norm": 2.2938108444213867,
      "learning_rate": 3.216911764705883e-08,
      "loss": 2.0378,
      "step": 8
    },
    {
      "epoch": 0.002068014705882353,
      "grad_norm": 1.7681212425231934,
      "learning_rate": 3.6764705882352945e-08,
      "loss": 1.9926,
      "step": 9
    },
    {
      "epoch": 0.002297794117647059,
      "grad_norm": 2.0538582801818848,
      "learning_rate": 4.136029411764706e-08,
      "loss": 2.0372,
      "step": 10
    },
    {
      "epoch": 0.002527573529411765,
      "grad_norm": 2.1439974308013916,
      "learning_rate": 4.595588235294118e-08,
      "loss": 2.0831,
      "step": 11
    },
    {
      "epoch": 0.0027573529411764708,
      "grad_norm": 1.9659197330474854,
      "learning_rate": 5.05514705882353e-08,
      "loss": 1.9679,
      "step": 12
    },
    {
      "epoch": 0.0029871323529411763,
      "grad_norm": 1.8016071319580078,
      "learning_rate": 5.514705882352942e-08,
      "loss": 1.8649,
      "step": 13
    },
    {
      "epoch": 0.003216911764705882,
      "grad_norm": 1.9962271451950073,
      "learning_rate": 5.974264705882352e-08,
      "loss": 2.0931,
      "step": 14
    },
    {
      "epoch": 0.003446691176470588,
      "grad_norm": 2.1310622692108154,
      "learning_rate": 6.433823529411765e-08,
      "loss": 2.0111,
      "step": 15
    },
    {
      "epoch": 0.003676470588235294,
      "grad_norm": 1.9968626499176025,
      "learning_rate": 6.893382352941177e-08,
      "loss": 1.9955,
      "step": 16
    },
    {
      "epoch": 0.00390625,
      "grad_norm": 2.0317678451538086,
      "learning_rate": 7.352941176470589e-08,
      "loss": 2.1347,
      "step": 17
    },
    {
      "epoch": 0.004136029411764706,
      "grad_norm": 2.146031379699707,
      "learning_rate": 7.8125e-08,
      "loss": 2.1704,
      "step": 18
    },
    {
      "epoch": 0.004365808823529412,
      "grad_norm": 1.9645966291427612,
      "learning_rate": 8.272058823529412e-08,
      "loss": 1.9788,
      "step": 19
    },
    {
      "epoch": 0.004595588235294118,
      "grad_norm": 1.7857410907745361,
      "learning_rate": 8.731617647058824e-08,
      "loss": 2.0816,
      "step": 20
    },
    {
      "epoch": 0.004825367647058824,
      "grad_norm": 1.8315672874450684,
      "learning_rate": 9.191176470588236e-08,
      "loss": 2.0141,
      "step": 21
    },
    {
      "epoch": 0.00505514705882353,
      "grad_norm": 1.5728893280029297,
      "learning_rate": 9.650735294117649e-08,
      "loss": 1.7291,
      "step": 22
    },
    {
      "epoch": 0.005284926470588236,
      "grad_norm": 2.180874824523926,
      "learning_rate": 1.011029411764706e-07,
      "loss": 2.1562,
      "step": 23
    },
    {
      "epoch": 0.0055147058823529415,
      "grad_norm": 2.113752603530884,
      "learning_rate": 1.0569852941176472e-07,
      "loss": 2.0105,
      "step": 24
    },
    {
      "epoch": 0.0057444852941176475,
      "grad_norm": 1.9649714231491089,
      "learning_rate": 1.1029411764705884e-07,
      "loss": 1.9173,
      "step": 25
    },
    {
      "epoch": 0.0059742647058823525,
      "grad_norm": 2.23228120803833,
      "learning_rate": 1.1488970588235296e-07,
      "loss": 2.0811,
      "step": 26
    },
    {
      "epoch": 0.0062040441176470585,
      "grad_norm": 1.6035317182540894,
      "learning_rate": 1.1948529411764705e-07,
      "loss": 1.83,
      "step": 27
    },
    {
      "epoch": 0.006433823529411764,
      "grad_norm": 2.05595064163208,
      "learning_rate": 1.240808823529412e-07,
      "loss": 2.1841,
      "step": 28
    },
    {
      "epoch": 0.00666360294117647,
      "grad_norm": 1.6307326555252075,
      "learning_rate": 1.286764705882353e-07,
      "loss": 1.8877,
      "step": 29
    },
    {
      "epoch": 0.006893382352941176,
      "grad_norm": 1.938994288444519,
      "learning_rate": 1.3327205882352943e-07,
      "loss": 1.9074,
      "step": 30
    },
    {
      "epoch": 0.007123161764705882,
      "grad_norm": 2.2705721855163574,
      "learning_rate": 1.3786764705882354e-07,
      "loss": 1.997,
      "step": 31
    },
    {
      "epoch": 0.007352941176470588,
      "grad_norm": 1.7353664636611938,
      "learning_rate": 1.4246323529411766e-07,
      "loss": 1.883,
      "step": 32
    },
    {
      "epoch": 0.007582720588235294,
      "grad_norm": 2.0600194931030273,
      "learning_rate": 1.4705882352941178e-07,
      "loss": 2.018,
      "step": 33
    },
    {
      "epoch": 0.0078125,
      "grad_norm": 2.1586036682128906,
      "learning_rate": 1.516544117647059e-07,
      "loss": 1.9889,
      "step": 34
    },
    {
      "epoch": 0.008042279411764705,
      "grad_norm": 2.211827039718628,
      "learning_rate": 1.5625e-07,
      "loss": 2.2598,
      "step": 35
    },
    {
      "epoch": 0.008272058823529412,
      "grad_norm": 1.936892032623291,
      "learning_rate": 1.608455882352941e-07,
      "loss": 1.9713,
      "step": 36
    },
    {
      "epoch": 0.008501838235294117,
      "grad_norm": 1.877369999885559,
      "learning_rate": 1.6544117647058825e-07,
      "loss": 1.9923,
      "step": 37
    },
    {
      "epoch": 0.008731617647058824,
      "grad_norm": 1.7414950132369995,
      "learning_rate": 1.7003676470588236e-07,
      "loss": 1.9367,
      "step": 38
    },
    {
      "epoch": 0.008961397058823529,
      "grad_norm": 1.7814885377883911,
      "learning_rate": 1.7463235294117648e-07,
      "loss": 1.9591,
      "step": 39
    },
    {
      "epoch": 0.009191176470588236,
      "grad_norm": 1.870487928390503,
      "learning_rate": 1.792279411764706e-07,
      "loss": 1.9818,
      "step": 40
    },
    {
      "epoch": 0.00942095588235294,
      "grad_norm": 2.182936429977417,
      "learning_rate": 1.8382352941176472e-07,
      "loss": 2.0827,
      "step": 41
    },
    {
      "epoch": 0.009650735294117647,
      "grad_norm": 2.4573676586151123,
      "learning_rate": 1.8841911764705883e-07,
      "loss": 1.9254,
      "step": 42
    },
    {
      "epoch": 0.009880514705882353,
      "grad_norm": 1.7357665300369263,
      "learning_rate": 1.9301470588235298e-07,
      "loss": 1.8782,
      "step": 43
    },
    {
      "epoch": 0.01011029411764706,
      "grad_norm": 1.701114296913147,
      "learning_rate": 1.9761029411764707e-07,
      "loss": 1.8501,
      "step": 44
    },
    {
      "epoch": 0.010340073529411764,
      "grad_norm": 1.9743387699127197,
      "learning_rate": 2.022058823529412e-07,
      "loss": 2.0376,
      "step": 45
    },
    {
      "epoch": 0.010569852941176471,
      "grad_norm": 1.7295353412628174,
      "learning_rate": 2.068014705882353e-07,
      "loss": 1.8672,
      "step": 46
    },
    {
      "epoch": 0.010799632352941176,
      "grad_norm": 1.988693356513977,
      "learning_rate": 2.1139705882352945e-07,
      "loss": 2.0088,
      "step": 47
    },
    {
      "epoch": 0.011029411764705883,
      "grad_norm": 2.5648093223571777,
      "learning_rate": 2.1599264705882354e-07,
      "loss": 2.3578,
      "step": 48
    },
    {
      "epoch": 0.011259191176470588,
      "grad_norm": 2.400550127029419,
      "learning_rate": 2.2058823529411768e-07,
      "loss": 2.0367,
      "step": 49
    },
    {
      "epoch": 0.011488970588235295,
      "grad_norm": 1.894559621810913,
      "learning_rate": 2.2518382352941177e-07,
      "loss": 2.0082,
      "step": 50
    },
    {
      "epoch": 0.01171875,
      "grad_norm": 1.8638421297073364,
      "learning_rate": 2.2977941176470592e-07,
      "loss": 2.0057,
      "step": 51
    },
    {
      "epoch": 0.011948529411764705,
      "grad_norm": 2.0952601432800293,
      "learning_rate": 2.3437500000000003e-07,
      "loss": 1.8392,
      "step": 52
    },
    {
      "epoch": 0.012178308823529412,
      "grad_norm": 1.9068127870559692,
      "learning_rate": 2.389705882352941e-07,
      "loss": 2.0642,
      "step": 53
    },
    {
      "epoch": 0.012408088235294117,
      "grad_norm": 1.8074218034744263,
      "learning_rate": 2.4356617647058827e-07,
      "loss": 1.8129,
      "step": 54
    },
    {
      "epoch": 0.012637867647058824,
      "grad_norm": 1.6761690378189087,
      "learning_rate": 2.481617647058824e-07,
      "loss": 1.9287,
      "step": 55
    },
    {
      "epoch": 0.012867647058823529,
      "grad_norm": 1.8526862859725952,
      "learning_rate": 2.527573529411765e-07,
      "loss": 1.9639,
      "step": 56
    },
    {
      "epoch": 0.013097426470588236,
      "grad_norm": 2.1723084449768066,
      "learning_rate": 2.573529411764706e-07,
      "loss": 2.0896,
      "step": 57
    },
    {
      "epoch": 0.01332720588235294,
      "grad_norm": 2.088904619216919,
      "learning_rate": 2.6194852941176474e-07,
      "loss": 1.8224,
      "step": 58
    },
    {
      "epoch": 0.013556985294117647,
      "grad_norm": 1.7994440793991089,
      "learning_rate": 2.6654411764705885e-07,
      "loss": 1.8704,
      "step": 59
    },
    {
      "epoch": 0.013786764705882353,
      "grad_norm": 1.8028361797332764,
      "learning_rate": 2.7113970588235297e-07,
      "loss": 1.8798,
      "step": 60
    },
    {
      "epoch": 0.01401654411764706,
      "grad_norm": 1.856485366821289,
      "learning_rate": 2.757352941176471e-07,
      "loss": 1.9484,
      "step": 61
    },
    {
      "epoch": 0.014246323529411764,
      "grad_norm": 2.272010564804077,
      "learning_rate": 2.803308823529412e-07,
      "loss": 2.1359,
      "step": 62
    },
    {
      "epoch": 0.014476102941176471,
      "grad_norm": 1.8116027116775513,
      "learning_rate": 2.849264705882353e-07,
      "loss": 1.7711,
      "step": 63
    },
    {
      "epoch": 0.014705882352941176,
      "grad_norm": 1.9085781574249268,
      "learning_rate": 2.8952205882352944e-07,
      "loss": 2.1128,
      "step": 64
    },
    {
      "epoch": 0.014935661764705883,
      "grad_norm": 2.3076722621917725,
      "learning_rate": 2.9411764705882356e-07,
      "loss": 1.9497,
      "step": 65
    },
    {
      "epoch": 0.015165441176470588,
      "grad_norm": 1.919298768043518,
      "learning_rate": 2.987132352941177e-07,
      "loss": 1.881,
      "step": 66
    },
    {
      "epoch": 0.015395220588235295,
      "grad_norm": 2.2291979789733887,
      "learning_rate": 3.033088235294118e-07,
      "loss": 2.0453,
      "step": 67
    },
    {
      "epoch": 0.015625,
      "grad_norm": 2.168780565261841,
      "learning_rate": 3.079044117647059e-07,
      "loss": 1.7624,
      "step": 68
    },
    {
      "epoch": 0.015854779411764705,
      "grad_norm": 1.7582207918167114,
      "learning_rate": 3.125e-07,
      "loss": 1.8831,
      "step": 69
    },
    {
      "epoch": 0.01608455882352941,
      "grad_norm": 1.9463906288146973,
      "learning_rate": 3.1709558823529414e-07,
      "loss": 1.9533,
      "step": 70
    },
    {
      "epoch": 0.01631433823529412,
      "grad_norm": 1.948075294494629,
      "learning_rate": 3.216911764705882e-07,
      "loss": 2.0056,
      "step": 71
    },
    {
      "epoch": 0.016544117647058824,
      "grad_norm": 1.7172693014144897,
      "learning_rate": 3.262867647058824e-07,
      "loss": 1.7919,
      "step": 72
    },
    {
      "epoch": 0.01677389705882353,
      "grad_norm": 2.16477370262146,
      "learning_rate": 3.308823529411765e-07,
      "loss": 2.0787,
      "step": 73
    },
    {
      "epoch": 0.017003676470588234,
      "grad_norm": 1.7680045366287231,
      "learning_rate": 3.354779411764706e-07,
      "loss": 1.8256,
      "step": 74
    },
    {
      "epoch": 0.017233455882352942,
      "grad_norm": 2.112741231918335,
      "learning_rate": 3.4007352941176473e-07,
      "loss": 2.0878,
      "step": 75
    },
    {
      "epoch": 0.017463235294117647,
      "grad_norm": 1.619061827659607,
      "learning_rate": 3.446691176470589e-07,
      "loss": 1.8641,
      "step": 76
    },
    {
      "epoch": 0.017693014705882353,
      "grad_norm": 2.014533042907715,
      "learning_rate": 3.4926470588235296e-07,
      "loss": 1.8895,
      "step": 77
    },
    {
      "epoch": 0.017922794117647058,
      "grad_norm": 1.744889259338379,
      "learning_rate": 3.538602941176471e-07,
      "loss": 1.9165,
      "step": 78
    },
    {
      "epoch": 0.018152573529411766,
      "grad_norm": 2.140254259109497,
      "learning_rate": 3.584558823529412e-07,
      "loss": 2.1639,
      "step": 79
    },
    {
      "epoch": 0.01838235294117647,
      "grad_norm": 1.8989766836166382,
      "learning_rate": 3.6305147058823537e-07,
      "loss": 2.028,
      "step": 80
    },
    {
      "epoch": 0.018612132352941176,
      "grad_norm": 1.8945356607437134,
      "learning_rate": 3.6764705882352943e-07,
      "loss": 1.9357,
      "step": 81
    },
    {
      "epoch": 0.01884191176470588,
      "grad_norm": 1.9438987970352173,
      "learning_rate": 3.7224264705882355e-07,
      "loss": 1.9575,
      "step": 82
    },
    {
      "epoch": 0.01907169117647059,
      "grad_norm": 1.8500235080718994,
      "learning_rate": 3.7683823529411767e-07,
      "loss": 1.9337,
      "step": 83
    },
    {
      "epoch": 0.019301470588235295,
      "grad_norm": 1.9248720407485962,
      "learning_rate": 3.8143382352941184e-07,
      "loss": 1.8853,
      "step": 84
    },
    {
      "epoch": 0.01953125,
      "grad_norm": 1.8716585636138916,
      "learning_rate": 3.8602941176470595e-07,
      "loss": 2.0584,
      "step": 85
    },
    {
      "epoch": 0.019761029411764705,
      "grad_norm": 1.9827109575271606,
      "learning_rate": 3.90625e-07,
      "loss": 2.0491,
      "step": 86
    },
    {
      "epoch": 0.01999080882352941,
      "grad_norm": 1.9238661527633667,
      "learning_rate": 3.9522058823529414e-07,
      "loss": 2.0783,
      "step": 87
    },
    {
      "epoch": 0.02022058823529412,
      "grad_norm": 1.852596402168274,
      "learning_rate": 3.9981617647058825e-07,
      "loss": 1.9393,
      "step": 88
    },
    {
      "epoch": 0.020450367647058824,
      "grad_norm": 1.6860460042953491,
      "learning_rate": 4.044117647058824e-07,
      "loss": 1.798,
      "step": 89
    },
    {
      "epoch": 0.02068014705882353,
      "grad_norm": 2.0020246505737305,
      "learning_rate": 4.090073529411765e-07,
      "loss": 1.9192,
      "step": 90
    },
    {
      "epoch": 0.020909926470588234,
      "grad_norm": 1.6664683818817139,
      "learning_rate": 4.136029411764706e-07,
      "loss": 1.7958,
      "step": 91
    },
    {
      "epoch": 0.021139705882352942,
      "grad_norm": 2.2126450538635254,
      "learning_rate": 4.181985294117647e-07,
      "loss": 2.0073,
      "step": 92
    },
    {
      "epoch": 0.021369485294117647,
      "grad_norm": 1.942526936531067,
      "learning_rate": 4.227941176470589e-07,
      "loss": 1.9118,
      "step": 93
    },
    {
      "epoch": 0.021599264705882353,
      "grad_norm": 1.7641910314559937,
      "learning_rate": 4.27389705882353e-07,
      "loss": 1.7573,
      "step": 94
    },
    {
      "epoch": 0.021829044117647058,
      "grad_norm": 1.551040530204773,
      "learning_rate": 4.319852941176471e-07,
      "loss": 1.7437,
      "step": 95
    },
    {
      "epoch": 0.022058823529411766,
      "grad_norm": 2.0088279247283936,
      "learning_rate": 4.365808823529412e-07,
      "loss": 2.1034,
      "step": 96
    },
    {
      "epoch": 0.02228860294117647,
      "grad_norm": 2.0334534645080566,
      "learning_rate": 4.4117647058823536e-07,
      "loss": 2.1051,
      "step": 97
    },
    {
      "epoch": 0.022518382352941176,
      "grad_norm": 2.226264715194702,
      "learning_rate": 4.457720588235295e-07,
      "loss": 2.2872,
      "step": 98
    },
    {
      "epoch": 0.02274816176470588,
      "grad_norm": 1.9257862567901611,
      "learning_rate": 4.5036764705882354e-07,
      "loss": 2.0351,
      "step": 99
    },
    {
      "epoch": 0.02297794117647059,
      "grad_norm": 1.9662472009658813,
      "learning_rate": 4.5496323529411766e-07,
      "loss": 2.0326,
      "step": 100
    },
    {
      "epoch": 0.023207720588235295,
      "grad_norm": 1.9724311828613281,
      "learning_rate": 4.5955882352941183e-07,
      "loss": 1.8812,
      "step": 101
    },
    {
      "epoch": 0.0234375,
      "grad_norm": 2.1013381481170654,
      "learning_rate": 4.6415441176470595e-07,
      "loss": 1.938,
      "step": 102
    },
    {
      "epoch": 0.023667279411764705,
      "grad_norm": 2.547992467880249,
      "learning_rate": 4.6875000000000006e-07,
      "loss": 2.074,
      "step": 103
    },
    {
      "epoch": 0.02389705882352941,
      "grad_norm": 1.9956446886062622,
      "learning_rate": 4.7334558823529413e-07,
      "loss": 1.9701,
      "step": 104
    },
    {
      "epoch": 0.02412683823529412,
      "grad_norm": 2.0624773502349854,
      "learning_rate": 4.779411764705882e-07,
      "loss": 1.9441,
      "step": 105
    },
    {
      "epoch": 0.024356617647058824,
      "grad_norm": 1.8384730815887451,
      "learning_rate": 4.825367647058824e-07,
      "loss": 1.858,
      "step": 106
    },
    {
      "epoch": 0.02458639705882353,
      "grad_norm": 1.8916895389556885,
      "learning_rate": 4.871323529411765e-07,
      "loss": 1.919,
      "step": 107
    },
    {
      "epoch": 0.024816176470588234,
      "grad_norm": 2.056844711303711,
      "learning_rate": 4.917279411764707e-07,
      "loss": 2.1537,
      "step": 108
    },
    {
      "epoch": 0.025045955882352942,
      "grad_norm": 2.0238888263702393,
      "learning_rate": 4.963235294117648e-07,
      "loss": 1.9325,
      "step": 109
    },
    {
      "epoch": 0.025275735294117647,
      "grad_norm": 1.9213390350341797,
      "learning_rate": 5.009191176470589e-07,
      "loss": 1.8984,
      "step": 110
    },
    {
      "epoch": 0.025505514705882353,
      "grad_norm": 1.7064281702041626,
      "learning_rate": 5.05514705882353e-07,
      "loss": 1.7415,
      "step": 111
    },
    {
      "epoch": 0.025735294117647058,
      "grad_norm": 1.6340371370315552,
      "learning_rate": 5.101102941176471e-07,
      "loss": 1.8215,
      "step": 112
    },
    {
      "epoch": 0.025965073529411766,
      "grad_norm": 1.7296829223632812,
      "learning_rate": 5.147058823529412e-07,
      "loss": 1.8067,
      "step": 113
    },
    {
      "epoch": 0.02619485294117647,
      "grad_norm": 2.0491063594818115,
      "learning_rate": 5.193014705882354e-07,
      "loss": 2.1727,
      "step": 114
    },
    {
      "epoch": 0.026424632352941176,
      "grad_norm": 1.940002202987671,
      "learning_rate": 5.238970588235295e-07,
      "loss": 2.0908,
      "step": 115
    },
    {
      "epoch": 0.02665441176470588,
      "grad_norm": 1.6233292818069458,
      "learning_rate": 5.284926470588236e-07,
      "loss": 1.718,
      "step": 116
    },
    {
      "epoch": 0.02688419117647059,
      "grad_norm": 1.6369996070861816,
      "learning_rate": 5.330882352941177e-07,
      "loss": 1.8663,
      "step": 117
    },
    {
      "epoch": 0.027113970588235295,
      "grad_norm": 1.823441743850708,
      "learning_rate": 5.376838235294118e-07,
      "loss": 1.9482,
      "step": 118
    },
    {
      "epoch": 0.02734375,
      "grad_norm": 1.433451533317566,
      "learning_rate": 5.422794117647059e-07,
      "loss": 1.7089,
      "step": 119
    },
    {
      "epoch": 0.027573529411764705,
      "grad_norm": 2.572299003601074,
      "learning_rate": 5.468750000000001e-07,
      "loss": 1.8332,
      "step": 120
    },
    {
      "epoch": 0.02780330882352941,
      "grad_norm": 1.6479740142822266,
      "learning_rate": 5.514705882352942e-07,
      "loss": 1.8824,
      "step": 121
    },
    {
      "epoch": 0.02803308823529412,
      "grad_norm": 1.8233654499053955,
      "learning_rate": 5.560661764705883e-07,
      "loss": 1.9019,
      "step": 122
    },
    {
      "epoch": 0.028262867647058824,
      "grad_norm": 1.8245782852172852,
      "learning_rate": 5.606617647058824e-07,
      "loss": 2.0532,
      "step": 123
    },
    {
      "epoch": 0.02849264705882353,
      "grad_norm": 1.9367088079452515,
      "learning_rate": 5.652573529411765e-07,
      "loss": 2.0713,
      "step": 124
    },
    {
      "epoch": 0.028722426470588234,
      "grad_norm": 2.100538730621338,
      "learning_rate": 5.698529411764706e-07,
      "loss": 2.0113,
      "step": 125
    },
    {
      "epoch": 0.028952205882352942,
      "grad_norm": 2.025047540664673,
      "learning_rate": 5.744485294117648e-07,
      "loss": 1.9982,
      "step": 126
    },
    {
      "epoch": 0.029181985294117647,
      "grad_norm": 1.853567123413086,
      "learning_rate": 5.790441176470589e-07,
      "loss": 1.8523,
      "step": 127
    },
    {
      "epoch": 0.029411764705882353,
      "grad_norm": 1.7274061441421509,
      "learning_rate": 5.83639705882353e-07,
      "loss": 1.8114,
      "step": 128
    },
    {
      "epoch": 0.029641544117647058,
      "grad_norm": 1.7572945356369019,
      "learning_rate": 5.882352941176471e-07,
      "loss": 1.8629,
      "step": 129
    },
    {
      "epoch": 0.029871323529411766,
      "grad_norm": 1.6294018030166626,
      "learning_rate": 5.928308823529412e-07,
      "loss": 1.8344,
      "step": 130
    },
    {
      "epoch": 0.03010110294117647,
      "grad_norm": 1.945131540298462,
      "learning_rate": 5.974264705882353e-07,
      "loss": 1.9808,
      "step": 131
    },
    {
      "epoch": 0.030330882352941176,
      "grad_norm": 1.7995469570159912,
      "learning_rate": 6.020220588235295e-07,
      "loss": 1.9863,
      "step": 132
    },
    {
      "epoch": 0.03056066176470588,
      "grad_norm": 1.9384888410568237,
      "learning_rate": 6.066176470588236e-07,
      "loss": 2.0185,
      "step": 133
    },
    {
      "epoch": 0.03079044117647059,
      "grad_norm": 1.6208008527755737,
      "learning_rate": 6.112132352941177e-07,
      "loss": 1.6823,
      "step": 134
    },
    {
      "epoch": 0.031020220588235295,
      "grad_norm": 1.6364047527313232,
      "learning_rate": 6.158088235294118e-07,
      "loss": 1.6738,
      "step": 135
    },
    {
      "epoch": 0.03125,
      "grad_norm": 1.9337899684906006,
      "learning_rate": 6.204044117647059e-07,
      "loss": 1.822,
      "step": 136
    },
    {
      "epoch": 0.031479779411764705,
      "grad_norm": 1.9755929708480835,
      "learning_rate": 6.25e-07,
      "loss": 1.9666,
      "step": 137
    },
    {
      "epoch": 0.03170955882352941,
      "grad_norm": 2.0280990600585938,
      "learning_rate": 6.295955882352942e-07,
      "loss": 1.9539,
      "step": 138
    },
    {
      "epoch": 0.031939338235294115,
      "grad_norm": 2.0695512294769287,
      "learning_rate": 6.341911764705883e-07,
      "loss": 2.0237,
      "step": 139
    },
    {
      "epoch": 0.03216911764705882,
      "grad_norm": 1.482350468635559,
      "learning_rate": 6.387867647058824e-07,
      "loss": 1.6956,
      "step": 140
    },
    {
      "epoch": 0.03239889705882353,
      "grad_norm": 1.693613886833191,
      "learning_rate": 6.433823529411764e-07,
      "loss": 1.8631,
      "step": 141
    },
    {
      "epoch": 0.03262867647058824,
      "grad_norm": 1.9294179677963257,
      "learning_rate": 6.479779411764707e-07,
      "loss": 2.0271,
      "step": 142
    },
    {
      "epoch": 0.03285845588235294,
      "grad_norm": 1.4730243682861328,
      "learning_rate": 6.525735294117648e-07,
      "loss": 1.7058,
      "step": 143
    },
    {
      "epoch": 0.03308823529411765,
      "grad_norm": 2.124384880065918,
      "learning_rate": 6.571691176470589e-07,
      "loss": 2.0418,
      "step": 144
    },
    {
      "epoch": 0.03331801470588235,
      "grad_norm": 2.0340054035186768,
      "learning_rate": 6.61764705882353e-07,
      "loss": 2.125,
      "step": 145
    },
    {
      "epoch": 0.03354779411764706,
      "grad_norm": 2.0543503761291504,
      "learning_rate": 6.663602941176471e-07,
      "loss": 1.9723,
      "step": 146
    },
    {
      "epoch": 0.03377757352941176,
      "grad_norm": 1.6471858024597168,
      "learning_rate": 6.709558823529412e-07,
      "loss": 1.7707,
      "step": 147
    },
    {
      "epoch": 0.03400735294117647,
      "grad_norm": 1.9182828664779663,
      "learning_rate": 6.755514705882353e-07,
      "loss": 1.9279,
      "step": 148
    },
    {
      "epoch": 0.03423713235294118,
      "grad_norm": 2.2711732387542725,
      "learning_rate": 6.801470588235295e-07,
      "loss": 2.15,
      "step": 149
    },
    {
      "epoch": 0.034466911764705885,
      "grad_norm": 1.7612336874008179,
      "learning_rate": 6.847426470588237e-07,
      "loss": 1.9301,
      "step": 150
    },
    {
      "epoch": 0.03469669117647059,
      "grad_norm": 1.5342631340026855,
      "learning_rate": 6.893382352941178e-07,
      "loss": 1.7094,
      "step": 151
    },
    {
      "epoch": 0.034926470588235295,
      "grad_norm": 1.7609941959381104,
      "learning_rate": 6.939338235294118e-07,
      "loss": 1.9348,
      "step": 152
    },
    {
      "epoch": 0.03515625,
      "grad_norm": 2.19814133644104,
      "learning_rate": 6.985294117647059e-07,
      "loss": 2.1956,
      "step": 153
    },
    {
      "epoch": 0.035386029411764705,
      "grad_norm": 2.022446393966675,
      "learning_rate": 7.03125e-07,
      "loss": 2.0933,
      "step": 154
    },
    {
      "epoch": 0.03561580882352941,
      "grad_norm": 1.5792458057403564,
      "learning_rate": 7.077205882352942e-07,
      "loss": 1.7974,
      "step": 155
    },
    {
      "epoch": 0.035845588235294115,
      "grad_norm": 1.6546794176101685,
      "learning_rate": 7.123161764705883e-07,
      "loss": 1.6708,
      "step": 156
    },
    {
      "epoch": 0.03607536764705882,
      "grad_norm": 1.8751121759414673,
      "learning_rate": 7.169117647058824e-07,
      "loss": 1.9269,
      "step": 157
    },
    {
      "epoch": 0.03630514705882353,
      "grad_norm": 1.9089373350143433,
      "learning_rate": 7.215073529411765e-07,
      "loss": 1.8427,
      "step": 158
    },
    {
      "epoch": 0.03653492647058824,
      "grad_norm": 1.7082383632659912,
      "learning_rate": 7.261029411764707e-07,
      "loss": 1.8378,
      "step": 159
    },
    {
      "epoch": 0.03676470588235294,
      "grad_norm": 1.8039796352386475,
      "learning_rate": 7.306985294117649e-07,
      "loss": 1.8273,
      "step": 160
    },
    {
      "epoch": 0.03699448529411765,
      "grad_norm": 1.8705772161483765,
      "learning_rate": 7.352941176470589e-07,
      "loss": 1.8742,
      "step": 161
    },
    {
      "epoch": 0.03722426470588235,
      "grad_norm": 1.5361591577529907,
      "learning_rate": 7.39889705882353e-07,
      "loss": 1.7871,
      "step": 162
    },
    {
      "epoch": 0.03745404411764706,
      "grad_norm": 1.7565171718597412,
      "learning_rate": 7.444852941176471e-07,
      "loss": 1.8638,
      "step": 163
    },
    {
      "epoch": 0.03768382352941176,
      "grad_norm": 1.6595717668533325,
      "learning_rate": 7.490808823529412e-07,
      "loss": 1.8265,
      "step": 164
    },
    {
      "epoch": 0.03791360294117647,
      "grad_norm": 1.997755765914917,
      "learning_rate": 7.536764705882353e-07,
      "loss": 2.0388,
      "step": 165
    },
    {
      "epoch": 0.03814338235294118,
      "grad_norm": 1.6484870910644531,
      "learning_rate": 7.582720588235295e-07,
      "loss": 1.891,
      "step": 166
    },
    {
      "epoch": 0.038373161764705885,
      "grad_norm": 1.9060317277908325,
      "learning_rate": 7.628676470588237e-07,
      "loss": 1.9494,
      "step": 167
    },
    {
      "epoch": 0.03860294117647059,
      "grad_norm": 1.692050576210022,
      "learning_rate": 7.674632352941178e-07,
      "loss": 1.9198,
      "step": 168
    },
    {
      "epoch": 0.038832720588235295,
      "grad_norm": 1.611462950706482,
      "learning_rate": 7.720588235294119e-07,
      "loss": 1.6613,
      "step": 169
    },
    {
      "epoch": 0.0390625,
      "grad_norm": 1.4545660018920898,
      "learning_rate": 7.766544117647059e-07,
      "loss": 1.7445,
      "step": 170
    },
    {
      "epoch": 0.039292279411764705,
      "grad_norm": 2.136265277862549,
      "learning_rate": 7.8125e-07,
      "loss": 1.9739,
      "step": 171
    },
    {
      "epoch": 0.03952205882352941,
      "grad_norm": 1.8754287958145142,
      "learning_rate": 7.858455882352942e-07,
      "loss": 1.9194,
      "step": 172
    },
    {
      "epoch": 0.039751838235294115,
      "grad_norm": 2.1141977310180664,
      "learning_rate": 7.904411764705883e-07,
      "loss": 1.8923,
      "step": 173
    },
    {
      "epoch": 0.03998161764705882,
      "grad_norm": 1.8240976333618164,
      "learning_rate": 7.950367647058824e-07,
      "loss": 1.8293,
      "step": 174
    },
    {
      "epoch": 0.04021139705882353,
      "grad_norm": 1.6418355703353882,
      "learning_rate": 7.996323529411765e-07,
      "loss": 1.7884,
      "step": 175
    },
    {
      "epoch": 0.04044117647058824,
      "grad_norm": 2.515960931777954,
      "learning_rate": 8.042279411764707e-07,
      "loss": 2.0119,
      "step": 176
    },
    {
      "epoch": 0.04067095588235294,
      "grad_norm": 1.7101638317108154,
      "learning_rate": 8.088235294117648e-07,
      "loss": 1.8752,
      "step": 177
    },
    {
      "epoch": 0.04090073529411765,
      "grad_norm": 1.860927700996399,
      "learning_rate": 8.13419117647059e-07,
      "loss": 1.9094,
      "step": 178
    },
    {
      "epoch": 0.04113051470588235,
      "grad_norm": 1.8917255401611328,
      "learning_rate": 8.18014705882353e-07,
      "loss": 1.9008,
      "step": 179
    },
    {
      "epoch": 0.04136029411764706,
      "grad_norm": 2.2237277030944824,
      "learning_rate": 8.226102941176471e-07,
      "loss": 2.2684,
      "step": 180
    },
    {
      "epoch": 0.04159007352941176,
      "grad_norm": 1.9009045362472534,
      "learning_rate": 8.272058823529412e-07,
      "loss": 1.913,
      "step": 181
    },
    {
      "epoch": 0.04181985294117647,
      "grad_norm": 1.6107202768325806,
      "learning_rate": 8.318014705882353e-07,
      "loss": 1.7419,
      "step": 182
    },
    {
      "epoch": 0.04204963235294118,
      "grad_norm": 2.188363790512085,
      "learning_rate": 8.363970588235294e-07,
      "loss": 1.9615,
      "step": 183
    },
    {
      "epoch": 0.042279411764705885,
      "grad_norm": 2.1826164722442627,
      "learning_rate": 8.409926470588237e-07,
      "loss": 1.8383,
      "step": 184
    },
    {
      "epoch": 0.04250919117647059,
      "grad_norm": 2.3804991245269775,
      "learning_rate": 8.455882352941178e-07,
      "loss": 2.0839,
      "step": 185
    },
    {
      "epoch": 0.042738970588235295,
      "grad_norm": 1.7134497165679932,
      "learning_rate": 8.501838235294119e-07,
      "loss": 1.8921,
      "step": 186
    },
    {
      "epoch": 0.04296875,
      "grad_norm": 1.532666563987732,
      "learning_rate": 8.54779411764706e-07,
      "loss": 1.8223,
      "step": 187
    },
    {
      "epoch": 0.043198529411764705,
      "grad_norm": 2.4539387226104736,
      "learning_rate": 8.59375e-07,
      "loss": 1.7839,
      "step": 188
    },
    {
      "epoch": 0.04342830882352941,
      "grad_norm": 1.649360179901123,
      "learning_rate": 8.639705882352941e-07,
      "loss": 1.8868,
      "step": 189
    },
    {
      "epoch": 0.043658088235294115,
      "grad_norm": 1.7380361557006836,
      "learning_rate": 8.685661764705883e-07,
      "loss": 1.7074,
      "step": 190
    },
    {
      "epoch": 0.04388786764705882,
      "grad_norm": 1.7021145820617676,
      "learning_rate": 8.731617647058824e-07,
      "loss": 1.8785,
      "step": 191
    },
    {
      "epoch": 0.04411764705882353,
      "grad_norm": 1.6323565244674683,
      "learning_rate": 8.777573529411765e-07,
      "loss": 1.6955,
      "step": 192
    },
    {
      "epoch": 0.04434742647058824,
      "grad_norm": 1.8109899759292603,
      "learning_rate": 8.823529411764707e-07,
      "loss": 1.8537,
      "step": 193
    },
    {
      "epoch": 0.04457720588235294,
      "grad_norm": 2.1500093936920166,
      "learning_rate": 8.869485294117648e-07,
      "loss": 1.9957,
      "step": 194
    },
    {
      "epoch": 0.04480698529411765,
      "grad_norm": 1.8039379119873047,
      "learning_rate": 8.91544117647059e-07,
      "loss": 1.8909,
      "step": 195
    },
    {
      "epoch": 0.04503676470588235,
      "grad_norm": 1.92383873462677,
      "learning_rate": 8.961397058823531e-07,
      "loss": 1.9271,
      "step": 196
    },
    {
      "epoch": 0.04526654411764706,
      "grad_norm": 1.731013298034668,
      "learning_rate": 9.007352941176471e-07,
      "loss": 1.8966,
      "step": 197
    },
    {
      "epoch": 0.04549632352941176,
      "grad_norm": 1.9901809692382812,
      "learning_rate": 9.053308823529412e-07,
      "loss": 2.0337,
      "step": 198
    },
    {
      "epoch": 0.04572610294117647,
      "grad_norm": 2.1920688152313232,
      "learning_rate": 9.099264705882353e-07,
      "loss": 1.8811,
      "step": 199
    },
    {
      "epoch": 0.04595588235294118,
      "grad_norm": 1.8134998083114624,
      "learning_rate": 9.145220588235294e-07,
      "loss": 1.8175,
      "step": 200
    },
    {
      "epoch": 0.046185661764705885,
      "grad_norm": 1.775296926498413,
      "learning_rate": 9.191176470588237e-07,
      "loss": 1.8408,
      "step": 201
    },
    {
      "epoch": 0.04641544117647059,
      "grad_norm": 1.9136730432510376,
      "learning_rate": 9.237132352941178e-07,
      "loss": 1.8262,
      "step": 202
    },
    {
      "epoch": 0.046645220588235295,
      "grad_norm": 2.2231013774871826,
      "learning_rate": 9.283088235294119e-07,
      "loss": 2.056,
      "step": 203
    },
    {
      "epoch": 0.046875,
      "grad_norm": 1.5652775764465332,
      "learning_rate": 9.32904411764706e-07,
      "loss": 1.7009,
      "step": 204
    },
    {
      "epoch": 0.047104779411764705,
      "grad_norm": 2.0251030921936035,
      "learning_rate": 9.375000000000001e-07,
      "loss": 1.8779,
      "step": 205
    },
    {
      "epoch": 0.04733455882352941,
      "grad_norm": 2.3126063346862793,
      "learning_rate": 9.420955882352941e-07,
      "loss": 1.9354,
      "step": 206
    },
    {
      "epoch": 0.047564338235294115,
      "grad_norm": 2.0353875160217285,
      "learning_rate": 9.466911764705883e-07,
      "loss": 1.9995,
      "step": 207
    },
    {
      "epoch": 0.04779411764705882,
      "grad_norm": 1.4703454971313477,
      "learning_rate": 9.512867647058824e-07,
      "loss": 1.6885,
      "step": 208
    },
    {
      "epoch": 0.04802389705882353,
      "grad_norm": 1.6540064811706543,
      "learning_rate": 9.558823529411764e-07,
      "loss": 1.7934,
      "step": 209
    },
    {
      "epoch": 0.04825367647058824,
      "grad_norm": 1.4594502449035645,
      "learning_rate": 9.604779411764707e-07,
      "loss": 1.6029,
      "step": 210
    },
    {
      "epoch": 0.04848345588235294,
      "grad_norm": 2.221527099609375,
      "learning_rate": 9.650735294117648e-07,
      "loss": 1.7652,
      "step": 211
    },
    {
      "epoch": 0.04871323529411765,
      "grad_norm": 1.9417684078216553,
      "learning_rate": 9.69669117647059e-07,
      "loss": 1.8292,
      "step": 212
    },
    {
      "epoch": 0.04894301470588235,
      "grad_norm": 1.7594413757324219,
      "learning_rate": 9.74264705882353e-07,
      "loss": 1.7497,
      "step": 213
    },
    {
      "epoch": 0.04917279411764706,
      "grad_norm": 2.267686605453491,
      "learning_rate": 9.788602941176472e-07,
      "loss": 1.825,
      "step": 214
    },
    {
      "epoch": 0.04940257352941176,
      "grad_norm": 1.6691532135009766,
      "learning_rate": 9.834558823529413e-07,
      "loss": 1.7003,
      "step": 215
    },
    {
      "epoch": 0.04963235294117647,
      "grad_norm": 1.6191165447235107,
      "learning_rate": 9.880514705882354e-07,
      "loss": 1.7731,
      "step": 216
    },
    {
      "epoch": 0.04986213235294118,
      "grad_norm": 1.4398773908615112,
      "learning_rate": 9.926470588235295e-07,
      "loss": 1.6548,
      "step": 217
    },
    {
      "epoch": 0.050091911764705885,
      "grad_norm": 1.767333745956421,
      "learning_rate": 9.972426470588237e-07,
      "loss": 1.7762,
      "step": 218
    },
    {
      "epoch": 0.05032169117647059,
      "grad_norm": 1.704870343208313,
      "learning_rate": 1.0018382352941178e-06,
      "loss": 1.7206,
      "step": 219
    },
    {
      "epoch": 0.050551470588235295,
      "grad_norm": 1.9807239770889282,
      "learning_rate": 1.0064338235294119e-06,
      "loss": 1.7712,
      "step": 220
    },
    {
      "epoch": 0.05078125,
      "grad_norm": 1.8429310321807861,
      "learning_rate": 1.011029411764706e-06,
      "loss": 1.8439,
      "step": 221
    },
    {
      "epoch": 0.051011029411764705,
      "grad_norm": 1.91338050365448,
      "learning_rate": 1.0156250000000001e-06,
      "loss": 1.9781,
      "step": 222
    },
    {
      "epoch": 0.05124080882352941,
      "grad_norm": 1.5578069686889648,
      "learning_rate": 1.0202205882352942e-06,
      "loss": 1.6948,
      "step": 223
    },
    {
      "epoch": 0.051470588235294115,
      "grad_norm": 1.5371779203414917,
      "learning_rate": 1.0248161764705884e-06,
      "loss": 1.8206,
      "step": 224
    },
    {
      "epoch": 0.05170036764705882,
      "grad_norm": 1.8413687944412231,
      "learning_rate": 1.0294117647058825e-06,
      "loss": 1.8994,
      "step": 225
    },
    {
      "epoch": 0.05193014705882353,
      "grad_norm": 1.568776249885559,
      "learning_rate": 1.0340073529411766e-06,
      "loss": 1.8152,
      "step": 226
    },
    {
      "epoch": 0.05215992647058824,
      "grad_norm": 2.0079355239868164,
      "learning_rate": 1.0386029411764707e-06,
      "loss": 1.8848,
      "step": 227
    },
    {
      "epoch": 0.05238970588235294,
      "grad_norm": 1.8384884595870972,
      "learning_rate": 1.0431985294117648e-06,
      "loss": 1.8601,
      "step": 228
    },
    {
      "epoch": 0.05261948529411765,
      "grad_norm": 2.375056505203247,
      "learning_rate": 1.047794117647059e-06,
      "loss": 2.015,
      "step": 229
    },
    {
      "epoch": 0.05284926470588235,
      "grad_norm": 1.7904378175735474,
      "learning_rate": 1.052389705882353e-06,
      "loss": 1.8614,
      "step": 230
    },
    {
      "epoch": 0.05307904411764706,
      "grad_norm": 1.9098224639892578,
      "learning_rate": 1.0569852941176472e-06,
      "loss": 1.8356,
      "step": 231
    },
    {
      "epoch": 0.05330882352941176,
      "grad_norm": 1.5328351259231567,
      "learning_rate": 1.0615808823529413e-06,
      "loss": 1.7591,
      "step": 232
    },
    {
      "epoch": 0.05353860294117647,
      "grad_norm": 1.6942329406738281,
      "learning_rate": 1.0661764705882354e-06,
      "loss": 1.715,
      "step": 233
    },
    {
      "epoch": 0.05376838235294118,
      "grad_norm": 2.113100051879883,
      "learning_rate": 1.0707720588235295e-06,
      "loss": 1.939,
      "step": 234
    },
    {
      "epoch": 0.053998161764705885,
      "grad_norm": 1.8253530263900757,
      "learning_rate": 1.0753676470588236e-06,
      "loss": 1.7347,
      "step": 235
    },
    {
      "epoch": 0.05422794117647059,
      "grad_norm": 1.422561526298523,
      "learning_rate": 1.0799632352941178e-06,
      "loss": 1.7027,
      "step": 236
    },
    {
      "epoch": 0.054457720588235295,
      "grad_norm": 1.848053216934204,
      "learning_rate": 1.0845588235294119e-06,
      "loss": 1.9233,
      "step": 237
    },
    {
      "epoch": 0.0546875,
      "grad_norm": 1.7332638502120972,
      "learning_rate": 1.089154411764706e-06,
      "loss": 1.7482,
      "step": 238
    },
    {
      "epoch": 0.054917279411764705,
      "grad_norm": 1.7403392791748047,
      "learning_rate": 1.0937500000000001e-06,
      "loss": 1.7036,
      "step": 239
    },
    {
      "epoch": 0.05514705882352941,
      "grad_norm": 1.7666443586349487,
      "learning_rate": 1.0983455882352942e-06,
      "loss": 1.7148,
      "step": 240
    },
    {
      "epoch": 0.055376838235294115,
      "grad_norm": 1.5203548669815063,
      "learning_rate": 1.1029411764705884e-06,
      "loss": 1.6537,
      "step": 241
    },
    {
      "epoch": 0.05560661764705882,
      "grad_norm": 1.5894126892089844,
      "learning_rate": 1.1075367647058825e-06,
      "loss": 1.6395,
      "step": 242
    },
    {
      "epoch": 0.05583639705882353,
      "grad_norm": 1.541795253753662,
      "learning_rate": 1.1121323529411766e-06,
      "loss": 1.7226,
      "step": 243
    },
    {
      "epoch": 0.05606617647058824,
      "grad_norm": 1.633378028869629,
      "learning_rate": 1.1167279411764707e-06,
      "loss": 1.7003,
      "step": 244
    },
    {
      "epoch": 0.05629595588235294,
      "grad_norm": 1.9425655603408813,
      "learning_rate": 1.1213235294117648e-06,
      "loss": 1.821,
      "step": 245
    },
    {
      "epoch": 0.05652573529411765,
      "grad_norm": 1.9154225587844849,
      "learning_rate": 1.125919117647059e-06,
      "loss": 1.8925,
      "step": 246
    },
    {
      "epoch": 0.05675551470588235,
      "grad_norm": 1.4630070924758911,
      "learning_rate": 1.130514705882353e-06,
      "loss": 1.657,
      "step": 247
    },
    {
      "epoch": 0.05698529411764706,
      "grad_norm": 1.5449460744857788,
      "learning_rate": 1.1351102941176472e-06,
      "loss": 1.6353,
      "step": 248
    },
    {
      "epoch": 0.05721507352941176,
      "grad_norm": 2.057774066925049,
      "learning_rate": 1.1397058823529413e-06,
      "loss": 1.7775,
      "step": 249
    },
    {
      "epoch": 0.05744485294117647,
      "grad_norm": 2.27347993850708,
      "learning_rate": 1.1443014705882354e-06,
      "loss": 1.9045,
      "step": 250
    },
    {
      "epoch": 0.05767463235294118,
      "grad_norm": 1.5900894403457642,
      "learning_rate": 1.1488970588235295e-06,
      "loss": 1.6696,
      "step": 251
    },
    {
      "epoch": 0.057904411764705885,
      "grad_norm": 1.857038140296936,
      "learning_rate": 1.1534926470588236e-06,
      "loss": 1.7677,
      "step": 252
    },
    {
      "epoch": 0.05813419117647059,
      "grad_norm": 1.8010088205337524,
      "learning_rate": 1.1580882352941178e-06,
      "loss": 1.7301,
      "step": 253
    },
    {
      "epoch": 0.058363970588235295,
      "grad_norm": 2.172807455062866,
      "learning_rate": 1.1626838235294119e-06,
      "loss": 1.7616,
      "step": 254
    },
    {
      "epoch": 0.05859375,
      "grad_norm": 2.099332094192505,
      "learning_rate": 1.167279411764706e-06,
      "loss": 1.8844,
      "step": 255
    },
    {
      "epoch": 0.058823529411764705,
      "grad_norm": 1.7523963451385498,
      "learning_rate": 1.1718750000000001e-06,
      "loss": 1.6957,
      "step": 256
    },
    {
      "epoch": 0.05905330882352941,
      "grad_norm": 1.7920924425125122,
      "learning_rate": 1.1764705882352942e-06,
      "loss": 1.8356,
      "step": 257
    },
    {
      "epoch": 0.059283088235294115,
      "grad_norm": 1.4555169343948364,
      "learning_rate": 1.1810661764705883e-06,
      "loss": 1.5278,
      "step": 258
    },
    {
      "epoch": 0.05951286764705882,
      "grad_norm": 1.6549197435379028,
      "learning_rate": 1.1856617647058825e-06,
      "loss": 1.6271,
      "step": 259
    },
    {
      "epoch": 0.05974264705882353,
      "grad_norm": 1.776253581047058,
      "learning_rate": 1.1902573529411766e-06,
      "loss": 1.6458,
      "step": 260
    },
    {
      "epoch": 0.05997242647058824,
      "grad_norm": 2.370396614074707,
      "learning_rate": 1.1948529411764707e-06,
      "loss": 1.8951,
      "step": 261
    },
    {
      "epoch": 0.06020220588235294,
      "grad_norm": 1.7304595708847046,
      "learning_rate": 1.1994485294117648e-06,
      "loss": 1.6574,
      "step": 262
    },
    {
      "epoch": 0.06043198529411765,
      "grad_norm": 1.5735702514648438,
      "learning_rate": 1.204044117647059e-06,
      "loss": 1.7429,
      "step": 263
    },
    {
      "epoch": 0.06066176470588235,
      "grad_norm": 1.9633561372756958,
      "learning_rate": 1.208639705882353e-06,
      "loss": 1.6721,
      "step": 264
    },
    {
      "epoch": 0.06089154411764706,
      "grad_norm": 1.4708424806594849,
      "learning_rate": 1.2132352941176472e-06,
      "loss": 1.5585,
      "step": 265
    },
    {
      "epoch": 0.06112132352941176,
      "grad_norm": 1.5761770009994507,
      "learning_rate": 1.2178308823529413e-06,
      "loss": 1.5712,
      "step": 266
    },
    {
      "epoch": 0.06135110294117647,
      "grad_norm": 2.4643311500549316,
      "learning_rate": 1.2224264705882354e-06,
      "loss": 1.8486,
      "step": 267
    },
    {
      "epoch": 0.06158088235294118,
      "grad_norm": 1.6248151063919067,
      "learning_rate": 1.2270220588235295e-06,
      "loss": 1.6184,
      "step": 268
    },
    {
      "epoch": 0.061810661764705885,
      "grad_norm": 1.5433928966522217,
      "learning_rate": 1.2316176470588236e-06,
      "loss": 1.701,
      "step": 269
    },
    {
      "epoch": 0.06204044117647059,
      "grad_norm": 1.617006540298462,
      "learning_rate": 1.2362132352941178e-06,
      "loss": 1.6645,
      "step": 270
    },
    {
      "epoch": 0.062270220588235295,
      "grad_norm": 1.3835493326187134,
      "learning_rate": 1.2408088235294119e-06,
      "loss": 1.5209,
      "step": 271
    },
    {
      "epoch": 0.0625,
      "grad_norm": 1.6330569982528687,
      "learning_rate": 1.245404411764706e-06,
      "loss": 1.7183,
      "step": 272
    },
    {
      "epoch": 0.0627297794117647,
      "grad_norm": 1.5387730598449707,
      "learning_rate": 1.25e-06,
      "loss": 1.7155,
      "step": 273
    },
    {
      "epoch": 0.06295955882352941,
      "grad_norm": 1.4490312337875366,
      "learning_rate": 1.2545955882352942e-06,
      "loss": 1.5581,
      "step": 274
    },
    {
      "epoch": 0.06318933823529412,
      "grad_norm": 1.5949201583862305,
      "learning_rate": 1.2591911764705883e-06,
      "loss": 1.7362,
      "step": 275
    },
    {
      "epoch": 0.06341911764705882,
      "grad_norm": 1.5252963304519653,
      "learning_rate": 1.2637867647058825e-06,
      "loss": 1.6339,
      "step": 276
    },
    {
      "epoch": 0.06364889705882353,
      "grad_norm": 1.3743687868118286,
      "learning_rate": 1.2683823529411766e-06,
      "loss": 1.5836,
      "step": 277
    },
    {
      "epoch": 0.06387867647058823,
      "grad_norm": 2.352625608444214,
      "learning_rate": 1.2729779411764707e-06,
      "loss": 1.874,
      "step": 278
    },
    {
      "epoch": 0.06410845588235294,
      "grad_norm": 1.6687878370285034,
      "learning_rate": 1.2775735294117648e-06,
      "loss": 1.7217,
      "step": 279
    },
    {
      "epoch": 0.06433823529411764,
      "grad_norm": 1.4941298961639404,
      "learning_rate": 1.2821691176470587e-06,
      "loss": 1.5624,
      "step": 280
    },
    {
      "epoch": 0.06456801470588236,
      "grad_norm": 1.736560344696045,
      "learning_rate": 1.2867647058823528e-06,
      "loss": 1.7505,
      "step": 281
    },
    {
      "epoch": 0.06479779411764706,
      "grad_norm": 1.468104600906372,
      "learning_rate": 1.2913602941176474e-06,
      "loss": 1.5474,
      "step": 282
    },
    {
      "epoch": 0.06502757352941177,
      "grad_norm": 1.5129295587539673,
      "learning_rate": 1.2959558823529415e-06,
      "loss": 1.59,
      "step": 283
    },
    {
      "epoch": 0.06525735294117647,
      "grad_norm": 1.645503044128418,
      "learning_rate": 1.3005514705882356e-06,
      "loss": 1.708,
      "step": 284
    },
    {
      "epoch": 0.06548713235294118,
      "grad_norm": 1.926357388496399,
      "learning_rate": 1.3051470588235295e-06,
      "loss": 1.7207,
      "step": 285
    },
    {
      "epoch": 0.06571691176470588,
      "grad_norm": 1.6880182027816772,
      "learning_rate": 1.3097426470588236e-06,
      "loss": 1.6559,
      "step": 286
    },
    {
      "epoch": 0.06594669117647059,
      "grad_norm": 1.7416422367095947,
      "learning_rate": 1.3143382352941177e-06,
      "loss": 1.7234,
      "step": 287
    },
    {
      "epoch": 0.0661764705882353,
      "grad_norm": 1.7914363145828247,
      "learning_rate": 1.3189338235294119e-06,
      "loss": 1.7624,
      "step": 288
    },
    {
      "epoch": 0.06640625,
      "grad_norm": 1.759116768836975,
      "learning_rate": 1.323529411764706e-06,
      "loss": 1.6832,
      "step": 289
    },
    {
      "epoch": 0.0666360294117647,
      "grad_norm": 1.802850604057312,
      "learning_rate": 1.328125e-06,
      "loss": 1.6297,
      "step": 290
    },
    {
      "epoch": 0.06686580882352941,
      "grad_norm": 1.5979090929031372,
      "learning_rate": 1.3327205882352942e-06,
      "loss": 1.5886,
      "step": 291
    },
    {
      "epoch": 0.06709558823529412,
      "grad_norm": 1.7475167512893677,
      "learning_rate": 1.3373161764705883e-06,
      "loss": 1.8558,
      "step": 292
    },
    {
      "epoch": 0.06732536764705882,
      "grad_norm": 1.8569247722625732,
      "learning_rate": 1.3419117647058824e-06,
      "loss": 1.7282,
      "step": 293
    },
    {
      "epoch": 0.06755514705882353,
      "grad_norm": 1.7037060260772705,
      "learning_rate": 1.3465073529411766e-06,
      "loss": 1.6039,
      "step": 294
    },
    {
      "epoch": 0.06778492647058823,
      "grad_norm": 1.5694351196289062,
      "learning_rate": 1.3511029411764707e-06,
      "loss": 1.5781,
      "step": 295
    },
    {
      "epoch": 0.06801470588235294,
      "grad_norm": 1.383876919746399,
      "learning_rate": 1.3556985294117648e-06,
      "loss": 1.5914,
      "step": 296
    },
    {
      "epoch": 0.06824448529411764,
      "grad_norm": 1.727513313293457,
      "learning_rate": 1.360294117647059e-06,
      "loss": 1.6199,
      "step": 297
    },
    {
      "epoch": 0.06847426470588236,
      "grad_norm": 1.684501051902771,
      "learning_rate": 1.3648897058823528e-06,
      "loss": 1.7121,
      "step": 298
    },
    {
      "epoch": 0.06870404411764706,
      "grad_norm": 1.2919334173202515,
      "learning_rate": 1.3694852941176474e-06,
      "loss": 1.5511,
      "step": 299
    },
    {
      "epoch": 0.06893382352941177,
      "grad_norm": 2.008040428161621,
      "learning_rate": 1.3740808823529415e-06,
      "loss": 1.7358,
      "step": 300
    },
    {
      "epoch": 0.06916360294117647,
      "grad_norm": 1.8299870491027832,
      "learning_rate": 1.3786764705882356e-06,
      "loss": 1.7194,
      "step": 301
    },
    {
      "epoch": 0.06939338235294118,
      "grad_norm": 1.3699034452438354,
      "learning_rate": 1.3832720588235295e-06,
      "loss": 1.5457,
      "step": 302
    },
    {
      "epoch": 0.06962316176470588,
      "grad_norm": 1.5065172910690308,
      "learning_rate": 1.3878676470588236e-06,
      "loss": 1.5408,
      "step": 303
    },
    {
      "epoch": 0.06985294117647059,
      "grad_norm": 1.5750890970230103,
      "learning_rate": 1.3924632352941177e-06,
      "loss": 1.6328,
      "step": 304
    },
    {
      "epoch": 0.0700827205882353,
      "grad_norm": 1.7064402103424072,
      "learning_rate": 1.3970588235294119e-06,
      "loss": 1.6534,
      "step": 305
    },
    {
      "epoch": 0.0703125,
      "grad_norm": 1.5563551187515259,
      "learning_rate": 1.401654411764706e-06,
      "loss": 1.5336,
      "step": 306
    },
    {
      "epoch": 0.0705422794117647,
      "grad_norm": 1.721909523010254,
      "learning_rate": 1.40625e-06,
      "loss": 1.6231,
      "step": 307
    },
    {
      "epoch": 0.07077205882352941,
      "grad_norm": 1.4692411422729492,
      "learning_rate": 1.4108455882352942e-06,
      "loss": 1.6159,
      "step": 308
    },
    {
      "epoch": 0.07100183823529412,
      "grad_norm": 1.6532005071640015,
      "learning_rate": 1.4154411764705883e-06,
      "loss": 1.6407,
      "step": 309
    },
    {
      "epoch": 0.07123161764705882,
      "grad_norm": 1.499542474746704,
      "learning_rate": 1.4200367647058824e-06,
      "loss": 1.6607,
      "step": 310
    },
    {
      "epoch": 0.07146139705882353,
      "grad_norm": 1.9156794548034668,
      "learning_rate": 1.4246323529411766e-06,
      "loss": 1.7485,
      "step": 311
    },
    {
      "epoch": 0.07169117647058823,
      "grad_norm": 1.7966710329055786,
      "learning_rate": 1.4292279411764707e-06,
      "loss": 1.6855,
      "step": 312
    },
    {
      "epoch": 0.07192095588235294,
      "grad_norm": 1.4083127975463867,
      "learning_rate": 1.4338235294117648e-06,
      "loss": 1.4511,
      "step": 313
    },
    {
      "epoch": 0.07215073529411764,
      "grad_norm": 1.5589299201965332,
      "learning_rate": 1.438419117647059e-06,
      "loss": 1.687,
      "step": 314
    },
    {
      "epoch": 0.07238051470588236,
      "grad_norm": 1.6916496753692627,
      "learning_rate": 1.443014705882353e-06,
      "loss": 1.775,
      "step": 315
    },
    {
      "epoch": 0.07261029411764706,
      "grad_norm": 1.5327666997909546,
      "learning_rate": 1.4476102941176474e-06,
      "loss": 1.5168,
      "step": 316
    },
    {
      "epoch": 0.07284007352941177,
      "grad_norm": 1.4149268865585327,
      "learning_rate": 1.4522058823529415e-06,
      "loss": 1.5123,
      "step": 317
    },
    {
      "epoch": 0.07306985294117647,
      "grad_norm": 1.4677878618240356,
      "learning_rate": 1.4568014705882356e-06,
      "loss": 1.5126,
      "step": 318
    },
    {
      "epoch": 0.07329963235294118,
      "grad_norm": 1.7739591598510742,
      "learning_rate": 1.4613970588235297e-06,
      "loss": 1.6424,
      "step": 319
    },
    {
      "epoch": 0.07352941176470588,
      "grad_norm": 1.4061570167541504,
      "learning_rate": 1.4659926470588236e-06,
      "loss": 1.54,
      "step": 320
    },
    {
      "epoch": 0.07375919117647059,
      "grad_norm": 1.4701365232467651,
      "learning_rate": 1.4705882352941177e-06,
      "loss": 1.4719,
      "step": 321
    },
    {
      "epoch": 0.0739889705882353,
      "grad_norm": 1.3993470668792725,
      "learning_rate": 1.4751838235294118e-06,
      "loss": 1.541,
      "step": 322
    },
    {
      "epoch": 0.07421875,
      "grad_norm": 1.2597509622573853,
      "learning_rate": 1.479779411764706e-06,
      "loss": 1.5535,
      "step": 323
    },
    {
      "epoch": 0.0744485294117647,
      "grad_norm": 1.562726378440857,
      "learning_rate": 1.484375e-06,
      "loss": 1.5191,
      "step": 324
    },
    {
      "epoch": 0.07467830882352941,
      "grad_norm": 1.6795674562454224,
      "learning_rate": 1.4889705882352942e-06,
      "loss": 1.7238,
      "step": 325
    },
    {
      "epoch": 0.07490808823529412,
      "grad_norm": 1.2350966930389404,
      "learning_rate": 1.4935661764705883e-06,
      "loss": 1.4688,
      "step": 326
    },
    {
      "epoch": 0.07513786764705882,
      "grad_norm": 1.230141043663025,
      "learning_rate": 1.4981617647058824e-06,
      "loss": 1.468,
      "step": 327
    },
    {
      "epoch": 0.07536764705882353,
      "grad_norm": 2.220052719116211,
      "learning_rate": 1.5027573529411766e-06,
      "loss": 1.6982,
      "step": 328
    },
    {
      "epoch": 0.07559742647058823,
      "grad_norm": 1.3395344018936157,
      "learning_rate": 1.5073529411764707e-06,
      "loss": 1.5266,
      "step": 329
    },
    {
      "epoch": 0.07582720588235294,
      "grad_norm": 1.7744251489639282,
      "learning_rate": 1.5119485294117648e-06,
      "loss": 1.662,
      "step": 330
    },
    {
      "epoch": 0.07605698529411764,
      "grad_norm": 1.1001335382461548,
      "learning_rate": 1.516544117647059e-06,
      "loss": 1.4175,
      "step": 331
    },
    {
      "epoch": 0.07628676470588236,
      "grad_norm": 1.5173008441925049,
      "learning_rate": 1.521139705882353e-06,
      "loss": 1.624,
      "step": 332
    },
    {
      "epoch": 0.07651654411764706,
      "grad_norm": 1.593416690826416,
      "learning_rate": 1.5257352941176473e-06,
      "loss": 1.6333,
      "step": 333
    },
    {
      "epoch": 0.07674632352941177,
      "grad_norm": 1.7299325466156006,
      "learning_rate": 1.5303308823529415e-06,
      "loss": 1.5568,
      "step": 334
    },
    {
      "epoch": 0.07697610294117647,
      "grad_norm": 1.4969521760940552,
      "learning_rate": 1.5349264705882356e-06,
      "loss": 1.5811,
      "step": 335
    },
    {
      "epoch": 0.07720588235294118,
      "grad_norm": 1.731622576713562,
      "learning_rate": 1.5395220588235297e-06,
      "loss": 1.6333,
      "step": 336
    },
    {
      "epoch": 0.07743566176470588,
      "grad_norm": 1.5407898426055908,
      "learning_rate": 1.5441176470588238e-06,
      "loss": 1.5245,
      "step": 337
    },
    {
      "epoch": 0.07766544117647059,
      "grad_norm": 1.6698342561721802,
      "learning_rate": 1.5487132352941177e-06,
      "loss": 1.6719,
      "step": 338
    },
    {
      "epoch": 0.0778952205882353,
      "grad_norm": 1.4708738327026367,
      "learning_rate": 1.5533088235294118e-06,
      "loss": 1.5183,
      "step": 339
    },
    {
      "epoch": 0.078125,
      "grad_norm": 1.7410441637039185,
      "learning_rate": 1.557904411764706e-06,
      "loss": 1.5478,
      "step": 340
    },
    {
      "epoch": 0.0783547794117647,
      "grad_norm": 1.2830899953842163,
      "learning_rate": 1.5625e-06,
      "loss": 1.3432,
      "step": 341
    },
    {
      "epoch": 0.07858455882352941,
      "grad_norm": 1.9123570919036865,
      "learning_rate": 1.5670955882352942e-06,
      "loss": 1.5932,
      "step": 342
    },
    {
      "epoch": 0.07881433823529412,
      "grad_norm": 1.4492528438568115,
      "learning_rate": 1.5716911764705883e-06,
      "loss": 1.4474,
      "step": 343
    },
    {
      "epoch": 0.07904411764705882,
      "grad_norm": 1.5000081062316895,
      "learning_rate": 1.5762867647058824e-06,
      "loss": 1.4851,
      "step": 344
    },
    {
      "epoch": 0.07927389705882353,
      "grad_norm": 1.3625764846801758,
      "learning_rate": 1.5808823529411765e-06,
      "loss": 1.5401,
      "step": 345
    },
    {
      "epoch": 0.07950367647058823,
      "grad_norm": 1.2818357944488525,
      "learning_rate": 1.5854779411764707e-06,
      "loss": 1.4983,
      "step": 346
    },
    {
      "epoch": 0.07973345588235294,
      "grad_norm": 1.3051950931549072,
      "learning_rate": 1.5900735294117648e-06,
      "loss": 1.3638,
      "step": 347
    },
    {
      "epoch": 0.07996323529411764,
      "grad_norm": 1.5078173875808716,
      "learning_rate": 1.594669117647059e-06,
      "loss": 1.4627,
      "step": 348
    },
    {
      "epoch": 0.08019301470588236,
      "grad_norm": 1.2739405632019043,
      "learning_rate": 1.599264705882353e-06,
      "loss": 1.4272,
      "step": 349
    },
    {
      "epoch": 0.08042279411764706,
      "grad_norm": 1.5782026052474976,
      "learning_rate": 1.6038602941176473e-06,
      "loss": 1.5658,
      "step": 350
    },
    {
      "epoch": 0.08065257352941177,
      "grad_norm": 1.1961305141448975,
      "learning_rate": 1.6084558823529415e-06,
      "loss": 1.4218,
      "step": 351
    },
    {
      "epoch": 0.08088235294117647,
      "grad_norm": 1.5174845457077026,
      "learning_rate": 1.6130514705882356e-06,
      "loss": 1.5854,
      "step": 352
    },
    {
      "epoch": 0.08111213235294118,
      "grad_norm": 1.473878264427185,
      "learning_rate": 1.6176470588235297e-06,
      "loss": 1.3682,
      "step": 353
    },
    {
      "epoch": 0.08134191176470588,
      "grad_norm": 1.2594517469406128,
      "learning_rate": 1.6222426470588238e-06,
      "loss": 1.476,
      "step": 354
    },
    {
      "epoch": 0.08157169117647059,
      "grad_norm": 1.3934352397918701,
      "learning_rate": 1.626838235294118e-06,
      "loss": 1.5801,
      "step": 355
    },
    {
      "epoch": 0.0818014705882353,
      "grad_norm": 1.0959489345550537,
      "learning_rate": 1.6314338235294118e-06,
      "loss": 1.3962,
      "step": 356
    },
    {
      "epoch": 0.08203125,
      "grad_norm": 1.6445657014846802,
      "learning_rate": 1.636029411764706e-06,
      "loss": 1.4945,
      "step": 357
    },
    {
      "epoch": 0.0822610294117647,
      "grad_norm": 1.5090222358703613,
      "learning_rate": 1.640625e-06,
      "loss": 1.3794,
      "step": 358
    },
    {
      "epoch": 0.08249080882352941,
      "grad_norm": 2.0665652751922607,
      "learning_rate": 1.6452205882352942e-06,
      "loss": 1.7158,
      "step": 359
    },
    {
      "epoch": 0.08272058823529412,
      "grad_norm": 1.3115180730819702,
      "learning_rate": 1.6498161764705883e-06,
      "loss": 1.4751,
      "step": 360
    },
    {
      "epoch": 0.08295036764705882,
      "grad_norm": 1.4540746212005615,
      "learning_rate": 1.6544117647058824e-06,
      "loss": 1.4038,
      "step": 361
    },
    {
      "epoch": 0.08318014705882353,
      "grad_norm": 1.3789770603179932,
      "learning_rate": 1.6590073529411765e-06,
      "loss": 1.3816,
      "step": 362
    },
    {
      "epoch": 0.08340992647058823,
      "grad_norm": 1.3117576837539673,
      "learning_rate": 1.6636029411764707e-06,
      "loss": 1.4211,
      "step": 363
    },
    {
      "epoch": 0.08363970588235294,
      "grad_norm": 1.4273808002471924,
      "learning_rate": 1.6681985294117648e-06,
      "loss": 1.4384,
      "step": 364
    },
    {
      "epoch": 0.08386948529411764,
      "grad_norm": 1.4064754247665405,
      "learning_rate": 1.6727941176470589e-06,
      "loss": 1.5427,
      "step": 365
    },
    {
      "epoch": 0.08409926470588236,
      "grad_norm": 1.1862726211547852,
      "learning_rate": 1.677389705882353e-06,
      "loss": 1.4086,
      "step": 366
    },
    {
      "epoch": 0.08432904411764706,
      "grad_norm": 1.4874918460845947,
      "learning_rate": 1.6819852941176473e-06,
      "loss": 1.3792,
      "step": 367
    },
    {
      "epoch": 0.08455882352941177,
      "grad_norm": 1.554526448249817,
      "learning_rate": 1.6865808823529415e-06,
      "loss": 1.5271,
      "step": 368
    },
    {
      "epoch": 0.08478860294117647,
      "grad_norm": 1.395538568496704,
      "learning_rate": 1.6911764705882356e-06,
      "loss": 1.3795,
      "step": 369
    },
    {
      "epoch": 0.08501838235294118,
      "grad_norm": 1.3278135061264038,
      "learning_rate": 1.6957720588235297e-06,
      "loss": 1.4579,
      "step": 370
    },
    {
      "epoch": 0.08524816176470588,
      "grad_norm": 1.5932672023773193,
      "learning_rate": 1.7003676470588238e-06,
      "loss": 1.626,
      "step": 371
    },
    {
      "epoch": 0.08547794117647059,
      "grad_norm": 1.3859649896621704,
      "learning_rate": 1.704963235294118e-06,
      "loss": 1.4899,
      "step": 372
    },
    {
      "epoch": 0.0857077205882353,
      "grad_norm": 1.2660397291183472,
      "learning_rate": 1.709558823529412e-06,
      "loss": 1.386,
      "step": 373
    },
    {
      "epoch": 0.0859375,
      "grad_norm": 1.2914589643478394,
      "learning_rate": 1.714154411764706e-06,
      "loss": 1.3711,
      "step": 374
    },
    {
      "epoch": 0.0861672794117647,
      "grad_norm": 1.1531685590744019,
      "learning_rate": 1.71875e-06,
      "loss": 1.3669,
      "step": 375
    },
    {
      "epoch": 0.08639705882352941,
      "grad_norm": 1.4733967781066895,
      "learning_rate": 1.7233455882352942e-06,
      "loss": 1.5144,
      "step": 376
    },
    {
      "epoch": 0.08662683823529412,
      "grad_norm": 2.174651861190796,
      "learning_rate": 1.7279411764705883e-06,
      "loss": 1.5816,
      "step": 377
    },
    {
      "epoch": 0.08685661764705882,
      "grad_norm": 1.2839622497558594,
      "learning_rate": 1.7325367647058824e-06,
      "loss": 1.3994,
      "step": 378
    },
    {
      "epoch": 0.08708639705882353,
      "grad_norm": 1.2152901887893677,
      "learning_rate": 1.7371323529411765e-06,
      "loss": 1.4331,
      "step": 379
    },
    {
      "epoch": 0.08731617647058823,
      "grad_norm": 1.207240343093872,
      "learning_rate": 1.7417279411764706e-06,
      "loss": 1.4349,
      "step": 380
    },
    {
      "epoch": 0.08754595588235294,
      "grad_norm": 1.9739387035369873,
      "learning_rate": 1.7463235294117648e-06,
      "loss": 1.6224,
      "step": 381
    },
    {
      "epoch": 0.08777573529411764,
      "grad_norm": 1.469720721244812,
      "learning_rate": 1.7509191176470589e-06,
      "loss": 1.4694,
      "step": 382
    },
    {
      "epoch": 0.08800551470588236,
      "grad_norm": 1.4874646663665771,
      "learning_rate": 1.755514705882353e-06,
      "loss": 1.4437,
      "step": 383
    },
    {
      "epoch": 0.08823529411764706,
      "grad_norm": 1.459075927734375,
      "learning_rate": 1.7601102941176473e-06,
      "loss": 1.4831,
      "step": 384
    },
    {
      "epoch": 0.08846507352941177,
      "grad_norm": 1.2137539386749268,
      "learning_rate": 1.7647058823529414e-06,
      "loss": 1.302,
      "step": 385
    },
    {
      "epoch": 0.08869485294117647,
      "grad_norm": 1.4972295761108398,
      "learning_rate": 1.7693014705882356e-06,
      "loss": 1.3234,
      "step": 386
    },
    {
      "epoch": 0.08892463235294118,
      "grad_norm": 1.4571503400802612,
      "learning_rate": 1.7738970588235297e-06,
      "loss": 1.4345,
      "step": 387
    },
    {
      "epoch": 0.08915441176470588,
      "grad_norm": 1.3423237800598145,
      "learning_rate": 1.7784926470588238e-06,
      "loss": 1.4897,
      "step": 388
    },
    {
      "epoch": 0.08938419117647059,
      "grad_norm": 1.2846662998199463,
      "learning_rate": 1.783088235294118e-06,
      "loss": 1.3557,
      "step": 389
    },
    {
      "epoch": 0.0896139705882353,
      "grad_norm": 1.0731565952301025,
      "learning_rate": 1.787683823529412e-06,
      "loss": 1.2406,
      "step": 390
    },
    {
      "epoch": 0.08984375,
      "grad_norm": 1.2892028093338013,
      "learning_rate": 1.7922794117647061e-06,
      "loss": 1.4643,
      "step": 391
    },
    {
      "epoch": 0.0900735294117647,
      "grad_norm": 1.314746618270874,
      "learning_rate": 1.796875e-06,
      "loss": 1.427,
      "step": 392
    },
    {
      "epoch": 0.09030330882352941,
      "grad_norm": 1.3881245851516724,
      "learning_rate": 1.8014705882352942e-06,
      "loss": 1.4504,
      "step": 393
    },
    {
      "epoch": 0.09053308823529412,
      "grad_norm": 1.6029560565948486,
      "learning_rate": 1.8060661764705883e-06,
      "loss": 1.4749,
      "step": 394
    },
    {
      "epoch": 0.09076286764705882,
      "grad_norm": 1.6293319463729858,
      "learning_rate": 1.8106617647058824e-06,
      "loss": 1.6119,
      "step": 395
    },
    {
      "epoch": 0.09099264705882353,
      "grad_norm": 1.4135010242462158,
      "learning_rate": 1.8152573529411765e-06,
      "loss": 1.5086,
      "step": 396
    },
    {
      "epoch": 0.09122242647058823,
      "grad_norm": 1.2173640727996826,
      "learning_rate": 1.8198529411764706e-06,
      "loss": 1.31,
      "step": 397
    },
    {
      "epoch": 0.09145220588235294,
      "grad_norm": 1.6788339614868164,
      "learning_rate": 1.8244485294117648e-06,
      "loss": 1.4003,
      "step": 398
    },
    {
      "epoch": 0.09168198529411764,
      "grad_norm": 1.4701956510543823,
      "learning_rate": 1.8290441176470589e-06,
      "loss": 1.3039,
      "step": 399
    },
    {
      "epoch": 0.09191176470588236,
      "grad_norm": 1.2427582740783691,
      "learning_rate": 1.833639705882353e-06,
      "loss": 1.3665,
      "step": 400
    },
    {
      "epoch": 0.09214154411764706,
      "grad_norm": 1.2352430820465088,
      "learning_rate": 1.8382352941176473e-06,
      "loss": 1.3426,
      "step": 401
    },
    {
      "epoch": 0.09237132352941177,
      "grad_norm": 1.500923991203308,
      "learning_rate": 1.8428308823529414e-06,
      "loss": 1.3884,
      "step": 402
    },
    {
      "epoch": 0.09260110294117647,
      "grad_norm": 1.4509601593017578,
      "learning_rate": 1.8474264705882356e-06,
      "loss": 1.4334,
      "step": 403
    },
    {
      "epoch": 0.09283088235294118,
      "grad_norm": 1.23061203956604,
      "learning_rate": 1.8520220588235297e-06,
      "loss": 1.3213,
      "step": 404
    },
    {
      "epoch": 0.09306066176470588,
      "grad_norm": 1.1798559427261353,
      "learning_rate": 1.8566176470588238e-06,
      "loss": 1.3029,
      "step": 405
    },
    {
      "epoch": 0.09329044117647059,
      "grad_norm": 1.2064359188079834,
      "learning_rate": 1.861213235294118e-06,
      "loss": 1.2619,
      "step": 406
    },
    {
      "epoch": 0.0935202205882353,
      "grad_norm": 1.250044822692871,
      "learning_rate": 1.865808823529412e-06,
      "loss": 1.3169,
      "step": 407
    },
    {
      "epoch": 0.09375,
      "grad_norm": 1.148134708404541,
      "learning_rate": 1.8704044117647061e-06,
      "loss": 1.3387,
      "step": 408
    },
    {
      "epoch": 0.0939797794117647,
      "grad_norm": 1.5916286706924438,
      "learning_rate": 1.8750000000000003e-06,
      "loss": 1.462,
      "step": 409
    },
    {
      "epoch": 0.09420955882352941,
      "grad_norm": 1.2286335229873657,
      "learning_rate": 1.8795955882352942e-06,
      "loss": 1.3437,
      "step": 410
    },
    {
      "epoch": 0.09443933823529412,
      "grad_norm": 1.3511302471160889,
      "learning_rate": 1.8841911764705883e-06,
      "loss": 1.3427,
      "step": 411
    },
    {
      "epoch": 0.09466911764705882,
      "grad_norm": 1.0779362916946411,
      "learning_rate": 1.8887867647058824e-06,
      "loss": 1.2148,
      "step": 412
    },
    {
      "epoch": 0.09489889705882353,
      "grad_norm": 1.3857271671295166,
      "learning_rate": 1.8933823529411765e-06,
      "loss": 1.2914,
      "step": 413
    },
    {
      "epoch": 0.09512867647058823,
      "grad_norm": 1.1513653993606567,
      "learning_rate": 1.8979779411764706e-06,
      "loss": 1.1914,
      "step": 414
    },
    {
      "epoch": 0.09535845588235294,
      "grad_norm": 1.2426340579986572,
      "learning_rate": 1.9025735294117648e-06,
      "loss": 1.3029,
      "step": 415
    },
    {
      "epoch": 0.09558823529411764,
      "grad_norm": 1.1313605308532715,
      "learning_rate": 1.9071691176470589e-06,
      "loss": 1.1949,
      "step": 416
    },
    {
      "epoch": 0.09581801470588236,
      "grad_norm": 1.3613148927688599,
      "learning_rate": 1.9117647058823528e-06,
      "loss": 1.2359,
      "step": 417
    },
    {
      "epoch": 0.09604779411764706,
      "grad_norm": 1.3961093425750732,
      "learning_rate": 1.9163602941176475e-06,
      "loss": 1.3573,
      "step": 418
    },
    {
      "epoch": 0.09627757352941177,
      "grad_norm": 1.4078408479690552,
      "learning_rate": 1.9209558823529414e-06,
      "loss": 1.2826,
      "step": 419
    },
    {
      "epoch": 0.09650735294117647,
      "grad_norm": 1.321035623550415,
      "learning_rate": 1.9255514705882358e-06,
      "loss": 1.2779,
      "step": 420
    },
    {
      "epoch": 0.09673713235294118,
      "grad_norm": 1.2925735712051392,
      "learning_rate": 1.9301470588235297e-06,
      "loss": 1.1737,
      "step": 421
    },
    {
      "epoch": 0.09696691176470588,
      "grad_norm": 1.241004467010498,
      "learning_rate": 1.9347426470588236e-06,
      "loss": 1.3422,
      "step": 422
    },
    {
      "epoch": 0.09719669117647059,
      "grad_norm": 1.1147682666778564,
      "learning_rate": 1.939338235294118e-06,
      "loss": 1.1304,
      "step": 423
    },
    {
      "epoch": 0.0974264705882353,
      "grad_norm": 1.2983580827713013,
      "learning_rate": 1.943933823529412e-06,
      "loss": 1.4161,
      "step": 424
    },
    {
      "epoch": 0.09765625,
      "grad_norm": 1.4238646030426025,
      "learning_rate": 1.948529411764706e-06,
      "loss": 1.347,
      "step": 425
    },
    {
      "epoch": 0.0978860294117647,
      "grad_norm": 1.232068419456482,
      "learning_rate": 1.953125e-06,
      "loss": 1.3684,
      "step": 426
    },
    {
      "epoch": 0.09811580882352941,
      "grad_norm": 1.3532637357711792,
      "learning_rate": 1.9577205882352944e-06,
      "loss": 1.1927,
      "step": 427
    },
    {
      "epoch": 0.09834558823529412,
      "grad_norm": 1.0463449954986572,
      "learning_rate": 1.9623161764705883e-06,
      "loss": 1.1636,
      "step": 428
    },
    {
      "epoch": 0.09857536764705882,
      "grad_norm": 1.612680196762085,
      "learning_rate": 1.9669117647058826e-06,
      "loss": 1.421,
      "step": 429
    },
    {
      "epoch": 0.09880514705882353,
      "grad_norm": 1.6124038696289062,
      "learning_rate": 1.9715073529411765e-06,
      "loss": 1.3171,
      "step": 430
    },
    {
      "epoch": 0.09903492647058823,
      "grad_norm": 1.3829773664474487,
      "learning_rate": 1.976102941176471e-06,
      "loss": 1.3085,
      "step": 431
    },
    {
      "epoch": 0.09926470588235294,
      "grad_norm": 1.1692906618118286,
      "learning_rate": 1.9806985294117647e-06,
      "loss": 1.2172,
      "step": 432
    },
    {
      "epoch": 0.09949448529411764,
      "grad_norm": 1.309342622756958,
      "learning_rate": 1.985294117647059e-06,
      "loss": 1.2504,
      "step": 433
    },
    {
      "epoch": 0.09972426470588236,
      "grad_norm": 1.2955740690231323,
      "learning_rate": 1.989889705882353e-06,
      "loss": 1.2385,
      "step": 434
    },
    {
      "epoch": 0.09995404411764706,
      "grad_norm": 1.4031826257705688,
      "learning_rate": 1.9944852941176473e-06,
      "loss": 1.2587,
      "step": 435
    },
    {
      "epoch": 0.10018382352941177,
      "grad_norm": 1.2682971954345703,
      "learning_rate": 1.9990808823529416e-06,
      "loss": 1.1852,
      "step": 436
    },
    {
      "epoch": 0.10041360294117647,
      "grad_norm": 1.1884411573410034,
      "learning_rate": 2.0036764705882355e-06,
      "loss": 1.1596,
      "step": 437
    },
    {
      "epoch": 0.10064338235294118,
      "grad_norm": 1.2937599420547485,
      "learning_rate": 2.0082720588235294e-06,
      "loss": 1.2581,
      "step": 438
    },
    {
      "epoch": 0.10087316176470588,
      "grad_norm": 1.1609433889389038,
      "learning_rate": 2.0128676470588238e-06,
      "loss": 1.1638,
      "step": 439
    },
    {
      "epoch": 0.10110294117647059,
      "grad_norm": 1.2560145854949951,
      "learning_rate": 2.0174632352941177e-06,
      "loss": 1.3958,
      "step": 440
    },
    {
      "epoch": 0.1013327205882353,
      "grad_norm": 1.4951361417770386,
      "learning_rate": 2.022058823529412e-06,
      "loss": 1.27,
      "step": 441
    },
    {
      "epoch": 0.1015625,
      "grad_norm": 1.47807776927948,
      "learning_rate": 2.026654411764706e-06,
      "loss": 1.2789,
      "step": 442
    },
    {
      "epoch": 0.1017922794117647,
      "grad_norm": 1.5007858276367188,
      "learning_rate": 2.0312500000000002e-06,
      "loss": 1.2961,
      "step": 443
    },
    {
      "epoch": 0.10202205882352941,
      "grad_norm": 1.4239916801452637,
      "learning_rate": 2.035845588235294e-06,
      "loss": 1.2253,
      "step": 444
    },
    {
      "epoch": 0.10225183823529412,
      "grad_norm": 1.3202106952667236,
      "learning_rate": 2.0404411764705885e-06,
      "loss": 1.2621,
      "step": 445
    },
    {
      "epoch": 0.10248161764705882,
      "grad_norm": 1.3328486680984497,
      "learning_rate": 2.0450367647058824e-06,
      "loss": 1.2575,
      "step": 446
    },
    {
      "epoch": 0.10271139705882353,
      "grad_norm": 1.311589002609253,
      "learning_rate": 2.0496323529411767e-06,
      "loss": 1.1056,
      "step": 447
    },
    {
      "epoch": 0.10294117647058823,
      "grad_norm": 1.3461782932281494,
      "learning_rate": 2.0542279411764706e-06,
      "loss": 1.3541,
      "step": 448
    },
    {
      "epoch": 0.10317095588235294,
      "grad_norm": 1.3635913133621216,
      "learning_rate": 2.058823529411765e-06,
      "loss": 1.2205,
      "step": 449
    },
    {
      "epoch": 0.10340073529411764,
      "grad_norm": 1.5582187175750732,
      "learning_rate": 2.063419117647059e-06,
      "loss": 1.2434,
      "step": 450
    },
    {
      "epoch": 0.10363051470588236,
      "grad_norm": 1.182217001914978,
      "learning_rate": 2.068014705882353e-06,
      "loss": 1.167,
      "step": 451
    },
    {
      "epoch": 0.10386029411764706,
      "grad_norm": 1.45926833152771,
      "learning_rate": 2.0726102941176475e-06,
      "loss": 1.1702,
      "step": 452
    },
    {
      "epoch": 0.10409007352941177,
      "grad_norm": 1.413822889328003,
      "learning_rate": 2.0772058823529414e-06,
      "loss": 1.2401,
      "step": 453
    },
    {
      "epoch": 0.10431985294117647,
      "grad_norm": 0.9999046325683594,
      "learning_rate": 2.0818014705882357e-06,
      "loss": 1.1062,
      "step": 454
    },
    {
      "epoch": 0.10454963235294118,
      "grad_norm": 1.3048369884490967,
      "learning_rate": 2.0863970588235297e-06,
      "loss": 1.2075,
      "step": 455
    },
    {
      "epoch": 0.10477941176470588,
      "grad_norm": 1.4297834634780884,
      "learning_rate": 2.0909926470588236e-06,
      "loss": 1.2297,
      "step": 456
    },
    {
      "epoch": 0.10500919117647059,
      "grad_norm": 1.1660113334655762,
      "learning_rate": 2.095588235294118e-06,
      "loss": 1.0579,
      "step": 457
    },
    {
      "epoch": 0.1052389705882353,
      "grad_norm": 1.107283115386963,
      "learning_rate": 2.100183823529412e-06,
      "loss": 1.042,
      "step": 458
    },
    {
      "epoch": 0.10546875,
      "grad_norm": 1.4991308450698853,
      "learning_rate": 2.104779411764706e-06,
      "loss": 1.2404,
      "step": 459
    },
    {
      "epoch": 0.1056985294117647,
      "grad_norm": 1.1984939575195312,
      "learning_rate": 2.109375e-06,
      "loss": 1.1445,
      "step": 460
    },
    {
      "epoch": 0.10592830882352941,
      "grad_norm": 1.0486226081848145,
      "learning_rate": 2.1139705882352944e-06,
      "loss": 1.0955,
      "step": 461
    },
    {
      "epoch": 0.10615808823529412,
      "grad_norm": 1.3880515098571777,
      "learning_rate": 2.1185661764705883e-06,
      "loss": 1.3334,
      "step": 462
    },
    {
      "epoch": 0.10638786764705882,
      "grad_norm": 1.3646823167800903,
      "learning_rate": 2.1231617647058826e-06,
      "loss": 1.2005,
      "step": 463
    },
    {
      "epoch": 0.10661764705882353,
      "grad_norm": 1.0062572956085205,
      "learning_rate": 2.1277573529411765e-06,
      "loss": 0.9751,
      "step": 464
    },
    {
      "epoch": 0.10684742647058823,
      "grad_norm": 1.1359872817993164,
      "learning_rate": 2.132352941176471e-06,
      "loss": 1.1025,
      "step": 465
    },
    {
      "epoch": 0.10707720588235294,
      "grad_norm": 1.4407659769058228,
      "learning_rate": 2.1369485294117647e-06,
      "loss": 1.2242,
      "step": 466
    },
    {
      "epoch": 0.10730698529411764,
      "grad_norm": 1.152552843093872,
      "learning_rate": 2.141544117647059e-06,
      "loss": 1.0625,
      "step": 467
    },
    {
      "epoch": 0.10753676470588236,
      "grad_norm": 1.4494009017944336,
      "learning_rate": 2.146139705882353e-06,
      "loss": 1.1674,
      "step": 468
    },
    {
      "epoch": 0.10776654411764706,
      "grad_norm": 1.2111631631851196,
      "learning_rate": 2.1507352941176473e-06,
      "loss": 1.1357,
      "step": 469
    },
    {
      "epoch": 0.10799632352941177,
      "grad_norm": 1.287043809890747,
      "learning_rate": 2.1553308823529416e-06,
      "loss": 1.1498,
      "step": 470
    },
    {
      "epoch": 0.10822610294117647,
      "grad_norm": 1.2630741596221924,
      "learning_rate": 2.1599264705882355e-06,
      "loss": 1.0869,
      "step": 471
    },
    {
      "epoch": 0.10845588235294118,
      "grad_norm": 1.2033612728118896,
      "learning_rate": 2.16452205882353e-06,
      "loss": 1.1597,
      "step": 472
    },
    {
      "epoch": 0.10868566176470588,
      "grad_norm": 1.3546655178070068,
      "learning_rate": 2.1691176470588238e-06,
      "loss": 1.1332,
      "step": 473
    },
    {
      "epoch": 0.10891544117647059,
      "grad_norm": 1.4852185249328613,
      "learning_rate": 2.1737132352941177e-06,
      "loss": 1.1529,
      "step": 474
    },
    {
      "epoch": 0.1091452205882353,
      "grad_norm": 1.3756523132324219,
      "learning_rate": 2.178308823529412e-06,
      "loss": 1.1618,
      "step": 475
    },
    {
      "epoch": 0.109375,
      "grad_norm": 1.295958161354065,
      "learning_rate": 2.182904411764706e-06,
      "loss": 1.0955,
      "step": 476
    },
    {
      "epoch": 0.1096047794117647,
      "grad_norm": 1.2822911739349365,
      "learning_rate": 2.1875000000000002e-06,
      "loss": 1.1244,
      "step": 477
    },
    {
      "epoch": 0.10983455882352941,
      "grad_norm": 1.552990198135376,
      "learning_rate": 2.192095588235294e-06,
      "loss": 1.2003,
      "step": 478
    },
    {
      "epoch": 0.11006433823529412,
      "grad_norm": 1.3049331903457642,
      "learning_rate": 2.1966911764705885e-06,
      "loss": 1.0913,
      "step": 479
    },
    {
      "epoch": 0.11029411764705882,
      "grad_norm": 1.072290301322937,
      "learning_rate": 2.2012867647058824e-06,
      "loss": 0.9887,
      "step": 480
    },
    {
      "epoch": 0.11052389705882353,
      "grad_norm": 1.3329546451568604,
      "learning_rate": 2.2058823529411767e-06,
      "loss": 1.1335,
      "step": 481
    },
    {
      "epoch": 0.11075367647058823,
      "grad_norm": 1.5650750398635864,
      "learning_rate": 2.2104779411764706e-06,
      "loss": 1.2401,
      "step": 482
    },
    {
      "epoch": 0.11098345588235294,
      "grad_norm": 1.2357085943222046,
      "learning_rate": 2.215073529411765e-06,
      "loss": 1.0896,
      "step": 483
    },
    {
      "epoch": 0.11121323529411764,
      "grad_norm": 1.198853850364685,
      "learning_rate": 2.219669117647059e-06,
      "loss": 1.0519,
      "step": 484
    },
    {
      "epoch": 0.11144301470588236,
      "grad_norm": 1.5614770650863647,
      "learning_rate": 2.224264705882353e-06,
      "loss": 1.2011,
      "step": 485
    },
    {
      "epoch": 0.11167279411764706,
      "grad_norm": 1.2003062963485718,
      "learning_rate": 2.2288602941176475e-06,
      "loss": 1.0107,
      "step": 486
    },
    {
      "epoch": 0.11190257352941177,
      "grad_norm": 1.1523836851119995,
      "learning_rate": 2.2334558823529414e-06,
      "loss": 1.1062,
      "step": 487
    },
    {
      "epoch": 0.11213235294117647,
      "grad_norm": 1.1820412874221802,
      "learning_rate": 2.2380514705882357e-06,
      "loss": 1.1066,
      "step": 488
    },
    {
      "epoch": 0.11236213235294118,
      "grad_norm": 1.05619478225708,
      "learning_rate": 2.2426470588235296e-06,
      "loss": 1.0154,
      "step": 489
    },
    {
      "epoch": 0.11259191176470588,
      "grad_norm": 1.2769831418991089,
      "learning_rate": 2.247242647058824e-06,
      "loss": 1.0608,
      "step": 490
    },
    {
      "epoch": 0.11282169117647059,
      "grad_norm": 1.3840925693511963,
      "learning_rate": 2.251838235294118e-06,
      "loss": 1.0949,
      "step": 491
    },
    {
      "epoch": 0.1130514705882353,
      "grad_norm": 1.191678524017334,
      "learning_rate": 2.2564338235294118e-06,
      "loss": 1.0437,
      "step": 492
    },
    {
      "epoch": 0.11328125,
      "grad_norm": 1.1350828409194946,
      "learning_rate": 2.261029411764706e-06,
      "loss": 1.0966,
      "step": 493
    },
    {
      "epoch": 0.1135110294117647,
      "grad_norm": 1.2795608043670654,
      "learning_rate": 2.265625e-06,
      "loss": 1.0213,
      "step": 494
    },
    {
      "epoch": 0.11374080882352941,
      "grad_norm": 1.400311827659607,
      "learning_rate": 2.2702205882352943e-06,
      "loss": 0.9883,
      "step": 495
    },
    {
      "epoch": 0.11397058823529412,
      "grad_norm": 1.433390736579895,
      "learning_rate": 2.2748161764705882e-06,
      "loss": 1.0445,
      "step": 496
    },
    {
      "epoch": 0.11420036764705882,
      "grad_norm": 1.2590041160583496,
      "learning_rate": 2.2794117647058826e-06,
      "loss": 1.0688,
      "step": 497
    },
    {
      "epoch": 0.11443014705882353,
      "grad_norm": 1.1961193084716797,
      "learning_rate": 2.2840073529411765e-06,
      "loss": 1.0378,
      "step": 498
    },
    {
      "epoch": 0.11465992647058823,
      "grad_norm": 1.1324824094772339,
      "learning_rate": 2.288602941176471e-06,
      "loss": 1.0043,
      "step": 499
    },
    {
      "epoch": 0.11488970588235294,
      "grad_norm": 1.2162203788757324,
      "learning_rate": 2.2931985294117647e-06,
      "loss": 1.1368,
      "step": 500
    },
    {
      "epoch": 0.11488970588235294,
      "eval_loss": 1.0706913471221924,
      "eval_runtime": 2006.801,
      "eval_samples_per_second": 4.438,
      "eval_steps_per_second": 2.219,
      "step": 500
    },
    {
      "epoch": 0.11511948529411764,
      "grad_norm": 1.1967967748641968,
      "learning_rate": 2.297794117647059e-06,
      "loss": 1.0924,
      "step": 501
    },
    {
      "epoch": 0.11534926470588236,
      "grad_norm": 1.2987737655639648,
      "learning_rate": 2.302389705882353e-06,
      "loss": 0.9721,
      "step": 502
    },
    {
      "epoch": 0.11557904411764706,
      "grad_norm": 1.2172969579696655,
      "learning_rate": 2.3069852941176473e-06,
      "loss": 1.0083,
      "step": 503
    },
    {
      "epoch": 0.11580882352941177,
      "grad_norm": 1.3773560523986816,
      "learning_rate": 2.3115808823529416e-06,
      "loss": 1.1688,
      "step": 504
    },
    {
      "epoch": 0.11603860294117647,
      "grad_norm": 1.323630452156067,
      "learning_rate": 2.3161764705882355e-06,
      "loss": 1.0579,
      "step": 505
    },
    {
      "epoch": 0.11626838235294118,
      "grad_norm": 1.2063498497009277,
      "learning_rate": 2.32077205882353e-06,
      "loss": 0.9483,
      "step": 506
    },
    {
      "epoch": 0.11649816176470588,
      "grad_norm": 1.1286749839782715,
      "learning_rate": 2.3253676470588237e-06,
      "loss": 0.9933,
      "step": 507
    },
    {
      "epoch": 0.11672794117647059,
      "grad_norm": 1.388372540473938,
      "learning_rate": 2.329963235294118e-06,
      "loss": 1.0607,
      "step": 508
    },
    {
      "epoch": 0.1169577205882353,
      "grad_norm": 1.189502477645874,
      "learning_rate": 2.334558823529412e-06,
      "loss": 1.0117,
      "step": 509
    },
    {
      "epoch": 0.1171875,
      "grad_norm": 1.4381985664367676,
      "learning_rate": 2.339154411764706e-06,
      "loss": 0.9853,
      "step": 510
    },
    {
      "epoch": 0.1174172794117647,
      "grad_norm": 1.4115866422653198,
      "learning_rate": 2.3437500000000002e-06,
      "loss": 1.0516,
      "step": 511
    },
    {
      "epoch": 0.11764705882352941,
      "grad_norm": 1.084930658340454,
      "learning_rate": 2.348345588235294e-06,
      "loss": 0.9665,
      "step": 512
    },
    {
      "epoch": 0.11787683823529412,
      "grad_norm": 1.0751078128814697,
      "learning_rate": 2.3529411764705885e-06,
      "loss": 0.9482,
      "step": 513
    },
    {
      "epoch": 0.11810661764705882,
      "grad_norm": 1.2925337553024292,
      "learning_rate": 2.3575367647058824e-06,
      "loss": 1.104,
      "step": 514
    },
    {
      "epoch": 0.11833639705882353,
      "grad_norm": 1.3495333194732666,
      "learning_rate": 2.3621323529411767e-06,
      "loss": 1.0925,
      "step": 515
    },
    {
      "epoch": 0.11856617647058823,
      "grad_norm": 1.3141593933105469,
      "learning_rate": 2.3667279411764706e-06,
      "loss": 0.8972,
      "step": 516
    },
    {
      "epoch": 0.11879595588235294,
      "grad_norm": 1.1668696403503418,
      "learning_rate": 2.371323529411765e-06,
      "loss": 0.9779,
      "step": 517
    },
    {
      "epoch": 0.11902573529411764,
      "grad_norm": Infinity,
      "learning_rate": 2.375919117647059e-06,
      "loss": 1.081,
      "step": 518
    },
    {
      "epoch": 0.11925551470588236,
      "grad_norm": 1.1288424730300903,
      "learning_rate": 2.375919117647059e-06,
      "loss": 0.9462,
      "step": 519
    },
    {
      "epoch": 0.11948529411764706,
      "grad_norm": 1.278761386871338,
      "learning_rate": 2.380514705882353e-06,
      "loss": 0.9867,
      "step": 520
    },
    {
      "epoch": 0.11971507352941177,
      "grad_norm": 1.1927473545074463,
      "learning_rate": 2.3851102941176475e-06,
      "loss": 0.9863,
      "step": 521
    },
    {
      "epoch": 0.11994485294117647,
      "grad_norm": 1.2689489126205444,
      "learning_rate": 2.3897058823529414e-06,
      "loss": 1.0029,
      "step": 522
    },
    {
      "epoch": 0.12017463235294118,
      "grad_norm": 1.3546289205551147,
      "learning_rate": 2.3943014705882357e-06,
      "loss": 0.9625,
      "step": 523
    },
    {
      "epoch": 0.12040441176470588,
      "grad_norm": 1.0993925333023071,
      "learning_rate": 2.3988970588235296e-06,
      "loss": 1.0021,
      "step": 524
    },
    {
      "epoch": 0.12063419117647059,
      "grad_norm": 0.9959967732429504,
      "learning_rate": 2.403492647058824e-06,
      "loss": 0.8583,
      "step": 525
    },
    {
      "epoch": 0.1208639705882353,
      "grad_norm": 1.3338322639465332,
      "learning_rate": 2.408088235294118e-06,
      "loss": 0.9892,
      "step": 526
    },
    {
      "epoch": 0.12109375,
      "grad_norm": 1.321040391921997,
      "learning_rate": 2.412683823529412e-06,
      "loss": 0.9482,
      "step": 527
    },
    {
      "epoch": 0.1213235294117647,
      "grad_norm": 1.3863767385482788,
      "learning_rate": 2.417279411764706e-06,
      "loss": 0.9168,
      "step": 528
    },
    {
      "epoch": 0.12155330882352941,
      "grad_norm": 1.3139063119888306,
      "learning_rate": 2.421875e-06,
      "loss": 0.9037,
      "step": 529
    },
    {
      "epoch": 0.12178308823529412,
      "grad_norm": 1.335078239440918,
      "learning_rate": 2.4264705882352943e-06,
      "loss": 0.9598,
      "step": 530
    },
    {
      "epoch": 0.12201286764705882,
      "grad_norm": 1.1854989528656006,
      "learning_rate": 2.4310661764705882e-06,
      "loss": 0.9719,
      "step": 531
    },
    {
      "epoch": 0.12224264705882353,
      "grad_norm": 1.1483049392700195,
      "learning_rate": 2.4356617647058826e-06,
      "loss": 0.9034,
      "step": 532
    },
    {
      "epoch": 0.12247242647058823,
      "grad_norm": 1.163140058517456,
      "learning_rate": 2.4402573529411765e-06,
      "loss": 0.9244,
      "step": 533
    },
    {
      "epoch": 0.12270220588235294,
      "grad_norm": 1.3894556760787964,
      "learning_rate": 2.444852941176471e-06,
      "loss": 0.962,
      "step": 534
    },
    {
      "epoch": 0.12293198529411764,
      "grad_norm": 0.9537982940673828,
      "learning_rate": 2.4494485294117647e-06,
      "loss": 0.89,
      "step": 535
    },
    {
      "epoch": 0.12316176470588236,
      "grad_norm": 1.3994852304458618,
      "learning_rate": 2.454044117647059e-06,
      "loss": 1.004,
      "step": 536
    },
    {
      "epoch": 0.12339154411764706,
      "grad_norm": 1.418069839477539,
      "learning_rate": 2.458639705882353e-06,
      "loss": 0.9354,
      "step": 537
    },
    {
      "epoch": 0.12362132352941177,
      "grad_norm": 1.078048825263977,
      "learning_rate": 2.4632352941176473e-06,
      "loss": 0.8809,
      "step": 538
    },
    {
      "epoch": 0.12385110294117647,
      "grad_norm": 1.4245295524597168,
      "learning_rate": 2.4678308823529416e-06,
      "loss": 0.9379,
      "step": 539
    },
    {
      "epoch": 0.12408088235294118,
      "grad_norm": 1.0183802843093872,
      "learning_rate": 2.4724264705882355e-06,
      "loss": 0.7993,
      "step": 540
    },
    {
      "epoch": 0.12431066176470588,
      "grad_norm": 1.2319976091384888,
      "learning_rate": 2.47702205882353e-06,
      "loss": 0.9373,
      "step": 541
    },
    {
      "epoch": 0.12454044117647059,
      "grad_norm": 1.3710895776748657,
      "learning_rate": 2.4816176470588237e-06,
      "loss": 0.9067,
      "step": 542
    },
    {
      "epoch": 0.1247702205882353,
      "grad_norm": 1.1901116371154785,
      "learning_rate": 2.486213235294118e-06,
      "loss": 0.9298,
      "step": 543
    },
    {
      "epoch": 0.125,
      "grad_norm": 1.3100626468658447,
      "learning_rate": 2.490808823529412e-06,
      "loss": 0.9194,
      "step": 544
    },
    {
      "epoch": 0.12522977941176472,
      "grad_norm": 1.308875560760498,
      "learning_rate": 2.4954044117647063e-06,
      "loss": 0.9045,
      "step": 545
    },
    {
      "epoch": 0.1254595588235294,
      "grad_norm": 1.1184437274932861,
      "learning_rate": 2.5e-06,
      "loss": 0.9065,
      "step": 546
    },
    {
      "epoch": 0.12568933823529413,
      "grad_norm": 0.9883830547332764,
      "learning_rate": 2.5045955882352945e-06,
      "loss": 0.876,
      "step": 547
    },
    {
      "epoch": 0.12591911764705882,
      "grad_norm": 1.0716350078582764,
      "learning_rate": 2.5091911764705884e-06,
      "loss": 0.8981,
      "step": 548
    },
    {
      "epoch": 0.12614889705882354,
      "grad_norm": 1.2506091594696045,
      "learning_rate": 2.5137867647058828e-06,
      "loss": 0.7984,
      "step": 549
    },
    {
      "epoch": 0.12637867647058823,
      "grad_norm": 1.2592507600784302,
      "learning_rate": 2.5183823529411767e-06,
      "loss": 0.908,
      "step": 550
    },
    {
      "epoch": 0.12660845588235295,
      "grad_norm": 1.2143243551254272,
      "learning_rate": 2.522977941176471e-06,
      "loss": 0.8687,
      "step": 551
    },
    {
      "epoch": 0.12683823529411764,
      "grad_norm": 1.451914668083191,
      "learning_rate": 2.527573529411765e-06,
      "loss": 0.9257,
      "step": 552
    },
    {
      "epoch": 0.12706801470588236,
      "grad_norm": 1.1675761938095093,
      "learning_rate": 2.5321691176470592e-06,
      "loss": 0.878,
      "step": 553
    },
    {
      "epoch": 0.12729779411764705,
      "grad_norm": 1.2062643766403198,
      "learning_rate": 2.536764705882353e-06,
      "loss": 0.9052,
      "step": 554
    },
    {
      "epoch": 0.12752757352941177,
      "grad_norm": 1.1619718074798584,
      "learning_rate": 2.5413602941176475e-06,
      "loss": 0.8709,
      "step": 555
    },
    {
      "epoch": 0.12775735294117646,
      "grad_norm": 1.2836616039276123,
      "learning_rate": 2.5459558823529414e-06,
      "loss": 0.8208,
      "step": 556
    },
    {
      "epoch": 0.12798713235294118,
      "grad_norm": 1.1656328439712524,
      "learning_rate": 2.5505514705882357e-06,
      "loss": 0.825,
      "step": 557
    },
    {
      "epoch": 0.12821691176470587,
      "grad_norm": 1.0879364013671875,
      "learning_rate": 2.5551470588235296e-06,
      "loss": 0.8324,
      "step": 558
    },
    {
      "epoch": 0.1284466911764706,
      "grad_norm": 1.2954434156417847,
      "learning_rate": 2.559742647058824e-06,
      "loss": 0.9147,
      "step": 559
    },
    {
      "epoch": 0.12867647058823528,
      "grad_norm": 1.3256505727767944,
      "learning_rate": 2.5643382352941174e-06,
      "loss": 0.9006,
      "step": 560
    },
    {
      "epoch": 0.12890625,
      "grad_norm": 1.056666374206543,
      "learning_rate": 2.568933823529412e-06,
      "loss": 0.8331,
      "step": 561
    },
    {
      "epoch": 0.12913602941176472,
      "grad_norm": 1.2500532865524292,
      "learning_rate": 2.5735294117647057e-06,
      "loss": 0.8874,
      "step": 562
    },
    {
      "epoch": 0.1293658088235294,
      "grad_norm": 1.212335467338562,
      "learning_rate": 2.5781250000000004e-06,
      "loss": 0.8454,
      "step": 563
    },
    {
      "epoch": 0.12959558823529413,
      "grad_norm": 1.0481927394866943,
      "learning_rate": 2.5827205882352947e-06,
      "loss": 0.8176,
      "step": 564
    },
    {
      "epoch": 0.12982536764705882,
      "grad_norm": 1.3325146436691284,
      "learning_rate": 2.5873161764705882e-06,
      "loss": 0.8392,
      "step": 565
    },
    {
      "epoch": 0.13005514705882354,
      "grad_norm": 1.1534119844436646,
      "learning_rate": 2.591911764705883e-06,
      "loss": 0.8607,
      "step": 566
    },
    {
      "epoch": 0.13028492647058823,
      "grad_norm": 1.2588123083114624,
      "learning_rate": 2.5965073529411765e-06,
      "loss": 0.8679,
      "step": 567
    },
    {
      "epoch": 0.13051470588235295,
      "grad_norm": 1.2034484148025513,
      "learning_rate": 2.601102941176471e-06,
      "loss": 0.8991,
      "step": 568
    },
    {
      "epoch": 0.13074448529411764,
      "grad_norm": 1.3837476968765259,
      "learning_rate": 2.6056985294117647e-06,
      "loss": 0.9271,
      "step": 569
    },
    {
      "epoch": 0.13097426470588236,
      "grad_norm": 1.1959058046340942,
      "learning_rate": 2.610294117647059e-06,
      "loss": 0.8086,
      "step": 570
    },
    {
      "epoch": 0.13120404411764705,
      "grad_norm": 1.234495759010315,
      "learning_rate": 2.614889705882353e-06,
      "loss": 0.8086,
      "step": 571
    },
    {
      "epoch": 0.13143382352941177,
      "grad_norm": 1.2733103036880493,
      "learning_rate": 2.6194852941176473e-06,
      "loss": 0.7908,
      "step": 572
    },
    {
      "epoch": 0.13166360294117646,
      "grad_norm": 1.356253981590271,
      "learning_rate": 2.624080882352941e-06,
      "loss": 0.8955,
      "step": 573
    },
    {
      "epoch": 0.13189338235294118,
      "grad_norm": 1.4862556457519531,
      "learning_rate": 2.6286764705882355e-06,
      "loss": 0.8793,
      "step": 574
    },
    {
      "epoch": 0.13212316176470587,
      "grad_norm": 1.223915457725525,
      "learning_rate": 2.6332720588235294e-06,
      "loss": 0.7958,
      "step": 575
    },
    {
      "epoch": 0.1323529411764706,
      "grad_norm": 1.302894949913025,
      "learning_rate": 2.6378676470588237e-06,
      "loss": 0.7635,
      "step": 576
    },
    {
      "epoch": 0.13258272058823528,
      "grad_norm": 1.2045663595199585,
      "learning_rate": 2.6424632352941176e-06,
      "loss": 0.8346,
      "step": 577
    },
    {
      "epoch": 0.1328125,
      "grad_norm": 0.971737265586853,
      "learning_rate": 2.647058823529412e-06,
      "loss": 0.7442,
      "step": 578
    },
    {
      "epoch": 0.13304227941176472,
      "grad_norm": 1.2318000793457031,
      "learning_rate": 2.651654411764706e-06,
      "loss": 0.7694,
      "step": 579
    },
    {
      "epoch": 0.1332720588235294,
      "grad_norm": 1.0925817489624023,
      "learning_rate": 2.65625e-06,
      "loss": 0.7857,
      "step": 580
    },
    {
      "epoch": 0.13350183823529413,
      "grad_norm": 1.1778138875961304,
      "learning_rate": 2.6608455882352945e-06,
      "loss": 0.726,
      "step": 581
    },
    {
      "epoch": 0.13373161764705882,
      "grad_norm": 1.012621521949768,
      "learning_rate": 2.6654411764705884e-06,
      "loss": 0.7545,
      "step": 582
    },
    {
      "epoch": 0.13396139705882354,
      "grad_norm": 1.3588143587112427,
      "learning_rate": 2.6700367647058828e-06,
      "loss": 0.8272,
      "step": 583
    },
    {
      "epoch": 0.13419117647058823,
      "grad_norm": 1.0257585048675537,
      "learning_rate": 2.6746323529411767e-06,
      "loss": 0.7177,
      "step": 584
    },
    {
      "epoch": 0.13442095588235295,
      "grad_norm": 1.0064862966537476,
      "learning_rate": 2.679227941176471e-06,
      "loss": 0.7803,
      "step": 585
    },
    {
      "epoch": 0.13465073529411764,
      "grad_norm": 1.2072999477386475,
      "learning_rate": 2.683823529411765e-06,
      "loss": 0.8007,
      "step": 586
    },
    {
      "epoch": 0.13488051470588236,
      "grad_norm": 1.3565412759780884,
      "learning_rate": 2.6884191176470592e-06,
      "loss": 0.7201,
      "step": 587
    },
    {
      "epoch": 0.13511029411764705,
      "grad_norm": 1.1381794214248657,
      "learning_rate": 2.693014705882353e-06,
      "loss": 0.7735,
      "step": 588
    },
    {
      "epoch": 0.13534007352941177,
      "grad_norm": 1.0521256923675537,
      "learning_rate": 2.6976102941176475e-06,
      "loss": 0.7045,
      "step": 589
    },
    {
      "epoch": 0.13556985294117646,
      "grad_norm": 1.2683396339416504,
      "learning_rate": 2.7022058823529414e-06,
      "loss": 0.6898,
      "step": 590
    },
    {
      "epoch": 0.13579963235294118,
      "grad_norm": 1.1824458837509155,
      "learning_rate": 2.7068014705882357e-06,
      "loss": 0.7503,
      "step": 591
    },
    {
      "epoch": 0.13602941176470587,
      "grad_norm": 1.1428980827331543,
      "learning_rate": 2.7113970588235296e-06,
      "loss": 0.7327,
      "step": 592
    },
    {
      "epoch": 0.1362591911764706,
      "grad_norm": 1.1062946319580078,
      "learning_rate": 2.715992647058824e-06,
      "loss": 0.6771,
      "step": 593
    },
    {
      "epoch": 0.13648897058823528,
      "grad_norm": 1.2932308912277222,
      "learning_rate": 2.720588235294118e-06,
      "loss": 0.7689,
      "step": 594
    },
    {
      "epoch": 0.13671875,
      "grad_norm": 1.059671401977539,
      "learning_rate": 2.725183823529412e-06,
      "loss": 0.7681,
      "step": 595
    },
    {
      "epoch": 0.13694852941176472,
      "grad_norm": 1.134596824645996,
      "learning_rate": 2.7297794117647056e-06,
      "loss": 0.7166,
      "step": 596
    },
    {
      "epoch": 0.1371783088235294,
      "grad_norm": 1.0865432024002075,
      "learning_rate": 2.7343750000000004e-06,
      "loss": 0.6866,
      "step": 597
    },
    {
      "epoch": 0.13740808823529413,
      "grad_norm": 1.0058069229125977,
      "learning_rate": 2.7389705882352947e-06,
      "loss": 0.7079,
      "step": 598
    },
    {
      "epoch": 0.13763786764705882,
      "grad_norm": 1.0585447549819946,
      "learning_rate": 2.7435661764705886e-06,
      "loss": 0.6646,
      "step": 599
    },
    {
      "epoch": 0.13786764705882354,
      "grad_norm": 1.0325695276260376,
      "learning_rate": 2.748161764705883e-06,
      "loss": 0.7503,
      "step": 600
    },
    {
      "epoch": 0.13809742647058823,
      "grad_norm": 1.2577884197235107,
      "learning_rate": 2.7527573529411764e-06,
      "loss": 0.7553,
      "step": 601
    },
    {
      "epoch": 0.13832720588235295,
      "grad_norm": 1.219760537147522,
      "learning_rate": 2.757352941176471e-06,
      "loss": 0.7964,
      "step": 602
    },
    {
      "epoch": 0.13855698529411764,
      "grad_norm": 1.1588430404663086,
      "learning_rate": 2.7619485294117647e-06,
      "loss": 0.7798,
      "step": 603
    },
    {
      "epoch": 0.13878676470588236,
      "grad_norm": 1.1222546100616455,
      "learning_rate": 2.766544117647059e-06,
      "loss": 0.6587,
      "step": 604
    },
    {
      "epoch": 0.13901654411764705,
      "grad_norm": 1.1224673986434937,
      "learning_rate": 2.771139705882353e-06,
      "loss": 0.736,
      "step": 605
    },
    {
      "epoch": 0.13924632352941177,
      "grad_norm": 1.1449722051620483,
      "learning_rate": 2.7757352941176472e-06,
      "loss": 0.7497,
      "step": 606
    },
    {
      "epoch": 0.13947610294117646,
      "grad_norm": 1.0058107376098633,
      "learning_rate": 2.780330882352941e-06,
      "loss": 0.6841,
      "step": 607
    },
    {
      "epoch": 0.13970588235294118,
      "grad_norm": 1.0671191215515137,
      "learning_rate": 2.7849264705882355e-06,
      "loss": 0.7847,
      "step": 608
    },
    {
      "epoch": 0.13993566176470587,
      "grad_norm": 1.108058214187622,
      "learning_rate": 2.7895220588235294e-06,
      "loss": 0.7891,
      "step": 609
    },
    {
      "epoch": 0.1401654411764706,
      "grad_norm": 1.0738189220428467,
      "learning_rate": 2.7941176470588237e-06,
      "loss": 0.6612,
      "step": 610
    },
    {
      "epoch": 0.14039522058823528,
      "grad_norm": 1.0328516960144043,
      "learning_rate": 2.7987132352941176e-06,
      "loss": 0.6427,
      "step": 611
    },
    {
      "epoch": 0.140625,
      "grad_norm": 1.0954694747924805,
      "learning_rate": 2.803308823529412e-06,
      "loss": 0.7119,
      "step": 612
    },
    {
      "epoch": 0.14085477941176472,
      "grad_norm": 0.9737281203269958,
      "learning_rate": 2.807904411764706e-06,
      "loss": 0.6781,
      "step": 613
    },
    {
      "epoch": 0.1410845588235294,
      "grad_norm": 1.1126545667648315,
      "learning_rate": 2.8125e-06,
      "loss": 0.6932,
      "step": 614
    },
    {
      "epoch": 0.14131433823529413,
      "grad_norm": 1.0621163845062256,
      "learning_rate": 2.8170955882352945e-06,
      "loss": 0.6595,
      "step": 615
    },
    {
      "epoch": 0.14154411764705882,
      "grad_norm": 1.1061183214187622,
      "learning_rate": 2.8216911764705884e-06,
      "loss": 0.7564,
      "step": 616
    },
    {
      "epoch": 0.14177389705882354,
      "grad_norm": 0.9056537747383118,
      "learning_rate": 2.8262867647058827e-06,
      "loss": 0.7024,
      "step": 617
    },
    {
      "epoch": 0.14200367647058823,
      "grad_norm": 0.8721203207969666,
      "learning_rate": 2.8308823529411766e-06,
      "loss": 0.6535,
      "step": 618
    },
    {
      "epoch": 0.14223345588235295,
      "grad_norm": 1.0930194854736328,
      "learning_rate": 2.835477941176471e-06,
      "loss": 0.6347,
      "step": 619
    },
    {
      "epoch": 0.14246323529411764,
      "grad_norm": 0.9809154272079468,
      "learning_rate": 2.840073529411765e-06,
      "loss": 0.6796,
      "step": 620
    },
    {
      "epoch": 0.14269301470588236,
      "grad_norm": 0.8689509034156799,
      "learning_rate": 2.844669117647059e-06,
      "loss": 0.6287,
      "step": 621
    },
    {
      "epoch": 0.14292279411764705,
      "grad_norm": 1.1557568311691284,
      "learning_rate": 2.849264705882353e-06,
      "loss": 0.6223,
      "step": 622
    },
    {
      "epoch": 0.14315257352941177,
      "grad_norm": 1.1859838962554932,
      "learning_rate": 2.8538602941176474e-06,
      "loss": 0.781,
      "step": 623
    },
    {
      "epoch": 0.14338235294117646,
      "grad_norm": 1.0272011756896973,
      "learning_rate": 2.8584558823529413e-06,
      "loss": 0.6574,
      "step": 624
    },
    {
      "epoch": 0.14361213235294118,
      "grad_norm": 1.3001822233200073,
      "learning_rate": 2.8630514705882357e-06,
      "loss": 0.6456,
      "step": 625
    },
    {
      "epoch": 0.14384191176470587,
      "grad_norm": 1.1142600774765015,
      "learning_rate": 2.8676470588235296e-06,
      "loss": 0.6102,
      "step": 626
    },
    {
      "epoch": 0.1440716911764706,
      "grad_norm": 1.0177773237228394,
      "learning_rate": 2.872242647058824e-06,
      "loss": 0.6446,
      "step": 627
    },
    {
      "epoch": 0.14430147058823528,
      "grad_norm": 1.141684889793396,
      "learning_rate": 2.876838235294118e-06,
      "loss": 0.7021,
      "step": 628
    },
    {
      "epoch": 0.14453125,
      "grad_norm": 1.0182934999465942,
      "learning_rate": 2.881433823529412e-06,
      "loss": 0.6659,
      "step": 629
    },
    {
      "epoch": 0.14476102941176472,
      "grad_norm": 1.2585976123809814,
      "learning_rate": 2.886029411764706e-06,
      "loss": 0.6455,
      "step": 630
    },
    {
      "epoch": 0.1449908088235294,
      "grad_norm": 0.9772987961769104,
      "learning_rate": 2.8906250000000004e-06,
      "loss": 0.6909,
      "step": 631
    },
    {
      "epoch": 0.14522058823529413,
      "grad_norm": 1.3087880611419678,
      "learning_rate": 2.8952205882352947e-06,
      "loss": 0.7158,
      "step": 632
    },
    {
      "epoch": 0.14545036764705882,
      "grad_norm": 0.980284571647644,
      "learning_rate": 2.8998161764705886e-06,
      "loss": 0.6769,
      "step": 633
    },
    {
      "epoch": 0.14568014705882354,
      "grad_norm": 1.0093214511871338,
      "learning_rate": 2.904411764705883e-06,
      "loss": 0.6627,
      "step": 634
    },
    {
      "epoch": 0.14590992647058823,
      "grad_norm": 0.8967195749282837,
      "learning_rate": 2.909007352941177e-06,
      "loss": 0.7302,
      "step": 635
    },
    {
      "epoch": 0.14613970588235295,
      "grad_norm": 1.0676681995391846,
      "learning_rate": 2.913602941176471e-06,
      "loss": 0.6664,
      "step": 636
    },
    {
      "epoch": 0.14636948529411764,
      "grad_norm": 1.236073613166809,
      "learning_rate": 2.9181985294117647e-06,
      "loss": 0.6408,
      "step": 637
    },
    {
      "epoch": 0.14659926470588236,
      "grad_norm": 0.9829216599464417,
      "learning_rate": 2.9227941176470594e-06,
      "loss": 0.7055,
      "step": 638
    },
    {
      "epoch": 0.14682904411764705,
      "grad_norm": 1.144942283630371,
      "learning_rate": 2.927389705882353e-06,
      "loss": 0.6855,
      "step": 639
    },
    {
      "epoch": 0.14705882352941177,
      "grad_norm": 1.0382249355316162,
      "learning_rate": 2.9319852941176472e-06,
      "loss": 0.6904,
      "step": 640
    },
    {
      "epoch": 0.14728860294117646,
      "grad_norm": 1.1905035972595215,
      "learning_rate": 2.936580882352941e-06,
      "loss": 0.653,
      "step": 641
    },
    {
      "epoch": 0.14751838235294118,
      "grad_norm": 1.0926024913787842,
      "learning_rate": 2.9411764705882355e-06,
      "loss": 0.652,
      "step": 642
    },
    {
      "epoch": 0.14774816176470587,
      "grad_norm": 1.005150318145752,
      "learning_rate": 2.9457720588235294e-06,
      "loss": 0.5986,
      "step": 643
    },
    {
      "epoch": 0.1479779411764706,
      "grad_norm": 1.1100088357925415,
      "learning_rate": 2.9503676470588237e-06,
      "loss": 0.7056,
      "step": 644
    },
    {
      "epoch": 0.14820772058823528,
      "grad_norm": 1.0782804489135742,
      "learning_rate": 2.9549632352941176e-06,
      "loss": 0.6173,
      "step": 645
    },
    {
      "epoch": 0.1484375,
      "grad_norm": 0.9472765326499939,
      "learning_rate": 2.959558823529412e-06,
      "loss": 0.611,
      "step": 646
    },
    {
      "epoch": 0.14866727941176472,
      "grad_norm": 1.0970522165298462,
      "learning_rate": 2.964154411764706e-06,
      "loss": 0.6389,
      "step": 647
    },
    {
      "epoch": 0.1488970588235294,
      "grad_norm": 1.1041947603225708,
      "learning_rate": 2.96875e-06,
      "loss": 0.606,
      "step": 648
    },
    {
      "epoch": 0.14912683823529413,
      "grad_norm": 0.9545155167579651,
      "learning_rate": 2.9733455882352945e-06,
      "loss": 0.7093,
      "step": 649
    },
    {
      "epoch": 0.14935661764705882,
      "grad_norm": 1.263183355331421,
      "learning_rate": 2.9779411764705884e-06,
      "loss": 0.759,
      "step": 650
    },
    {
      "epoch": 0.14958639705882354,
      "grad_norm": 1.237087368965149,
      "learning_rate": 2.9825367647058827e-06,
      "loss": 0.6062,
      "step": 651
    },
    {
      "epoch": 0.14981617647058823,
      "grad_norm": 1.282156229019165,
      "learning_rate": 2.9871323529411766e-06,
      "loss": 0.6226,
      "step": 652
    },
    {
      "epoch": 0.15004595588235295,
      "grad_norm": 1.0785669088363647,
      "learning_rate": 2.991727941176471e-06,
      "loss": 0.6043,
      "step": 653
    },
    {
      "epoch": 0.15027573529411764,
      "grad_norm": 1.0708420276641846,
      "learning_rate": 2.996323529411765e-06,
      "loss": 0.6208,
      "step": 654
    },
    {
      "epoch": 0.15050551470588236,
      "grad_norm": 1.4114891290664673,
      "learning_rate": 3.000919117647059e-06,
      "loss": 0.7235,
      "step": 655
    },
    {
      "epoch": 0.15073529411764705,
      "grad_norm": 0.9560341238975525,
      "learning_rate": 3.005514705882353e-06,
      "loss": 0.5865,
      "step": 656
    },
    {
      "epoch": 0.15096507352941177,
      "grad_norm": 0.9919650554656982,
      "learning_rate": 3.0101102941176474e-06,
      "loss": 0.6743,
      "step": 657
    },
    {
      "epoch": 0.15119485294117646,
      "grad_norm": 1.0387003421783447,
      "learning_rate": 3.0147058823529413e-06,
      "loss": 0.611,
      "step": 658
    },
    {
      "epoch": 0.15142463235294118,
      "grad_norm": 1.1627695560455322,
      "learning_rate": 3.0193014705882357e-06,
      "loss": 0.5999,
      "step": 659
    },
    {
      "epoch": 0.15165441176470587,
      "grad_norm": 0.8074289560317993,
      "learning_rate": 3.0238970588235296e-06,
      "loss": 0.6094,
      "step": 660
    },
    {
      "epoch": 0.1518841911764706,
      "grad_norm": 1.1682682037353516,
      "learning_rate": 3.028492647058824e-06,
      "loss": 0.6883,
      "step": 661
    },
    {
      "epoch": 0.15211397058823528,
      "grad_norm": 1.1706411838531494,
      "learning_rate": 3.033088235294118e-06,
      "loss": 0.6469,
      "step": 662
    },
    {
      "epoch": 0.15234375,
      "grad_norm": 1.0985100269317627,
      "learning_rate": 3.037683823529412e-06,
      "loss": 0.6874,
      "step": 663
    },
    {
      "epoch": 0.15257352941176472,
      "grad_norm": 1.2353203296661377,
      "learning_rate": 3.042279411764706e-06,
      "loss": 0.6242,
      "step": 664
    },
    {
      "epoch": 0.1528033088235294,
      "grad_norm": 1.2568986415863037,
      "learning_rate": 3.0468750000000004e-06,
      "loss": 0.643,
      "step": 665
    },
    {
      "epoch": 0.15303308823529413,
      "grad_norm": 1.177273154258728,
      "learning_rate": 3.0514705882352947e-06,
      "loss": 0.6679,
      "step": 666
    },
    {
      "epoch": 0.15326286764705882,
      "grad_norm": 1.0082793235778809,
      "learning_rate": 3.0560661764705886e-06,
      "loss": 0.5973,
      "step": 667
    },
    {
      "epoch": 0.15349264705882354,
      "grad_norm": 0.9128146171569824,
      "learning_rate": 3.060661764705883e-06,
      "loss": 0.61,
      "step": 668
    },
    {
      "epoch": 0.15372242647058823,
      "grad_norm": 1.1109473705291748,
      "learning_rate": 3.065257352941177e-06,
      "loss": 0.6323,
      "step": 669
    },
    {
      "epoch": 0.15395220588235295,
      "grad_norm": 1.1351066827774048,
      "learning_rate": 3.069852941176471e-06,
      "loss": 0.6148,
      "step": 670
    },
    {
      "epoch": 0.15418198529411764,
      "grad_norm": 1.2244704961776733,
      "learning_rate": 3.0744485294117646e-06,
      "loss": 0.6313,
      "step": 671
    },
    {
      "epoch": 0.15441176470588236,
      "grad_norm": 0.9543877243995667,
      "learning_rate": 3.0790441176470594e-06,
      "loss": 0.5653,
      "step": 672
    },
    {
      "epoch": 0.15464154411764705,
      "grad_norm": 1.0543426275253296,
      "learning_rate": 3.083639705882353e-06,
      "loss": 0.6534,
      "step": 673
    },
    {
      "epoch": 0.15487132352941177,
      "grad_norm": 1.0254713296890259,
      "learning_rate": 3.0882352941176476e-06,
      "loss": 0.5588,
      "step": 674
    },
    {
      "epoch": 0.15510110294117646,
      "grad_norm": 1.0159292221069336,
      "learning_rate": 3.092830882352941e-06,
      "loss": 0.5655,
      "step": 675
    },
    {
      "epoch": 0.15533088235294118,
      "grad_norm": 1.1223551034927368,
      "learning_rate": 3.0974264705882354e-06,
      "loss": 0.6822,
      "step": 676
    },
    {
      "epoch": 0.15556066176470587,
      "grad_norm": 1.0486196279525757,
      "learning_rate": 3.1020220588235294e-06,
      "loss": 0.5796,
      "step": 677
    },
    {
      "epoch": 0.1557904411764706,
      "grad_norm": 1.1883935928344727,
      "learning_rate": 3.1066176470588237e-06,
      "loss": 0.6393,
      "step": 678
    },
    {
      "epoch": 0.15602022058823528,
      "grad_norm": 1.1458715200424194,
      "learning_rate": 3.1112132352941176e-06,
      "loss": 0.6254,
      "step": 679
    },
    {
      "epoch": 0.15625,
      "grad_norm": 1.0614062547683716,
      "learning_rate": 3.115808823529412e-06,
      "loss": 0.635,
      "step": 680
    },
    {
      "epoch": 0.15647977941176472,
      "grad_norm": 1.060933232307434,
      "learning_rate": 3.120404411764706e-06,
      "loss": 0.6014,
      "step": 681
    },
    {
      "epoch": 0.1567095588235294,
      "grad_norm": 1.0123393535614014,
      "learning_rate": 3.125e-06,
      "loss": 0.6294,
      "step": 682
    },
    {
      "epoch": 0.15693933823529413,
      "grad_norm": 1.1726809740066528,
      "learning_rate": 3.1295955882352945e-06,
      "loss": 0.5189,
      "step": 683
    },
    {
      "epoch": 0.15716911764705882,
      "grad_norm": 0.8643547892570496,
      "learning_rate": 3.1341911764705884e-06,
      "loss": 0.6178,
      "step": 684
    },
    {
      "epoch": 0.15739889705882354,
      "grad_norm": 1.0637283325195312,
      "learning_rate": 3.1387867647058827e-06,
      "loss": 0.5988,
      "step": 685
    },
    {
      "epoch": 0.15762867647058823,
      "grad_norm": 1.109710931777954,
      "learning_rate": 3.1433823529411766e-06,
      "loss": 0.5876,
      "step": 686
    },
    {
      "epoch": 0.15785845588235295,
      "grad_norm": 1.319117546081543,
      "learning_rate": 3.147977941176471e-06,
      "loss": 0.5905,
      "step": 687
    },
    {
      "epoch": 0.15808823529411764,
      "grad_norm": 1.0028399229049683,
      "learning_rate": 3.152573529411765e-06,
      "loss": 0.5811,
      "step": 688
    },
    {
      "epoch": 0.15831801470588236,
      "grad_norm": 1.2943023443222046,
      "learning_rate": 3.157169117647059e-06,
      "loss": 0.5839,
      "step": 689
    },
    {
      "epoch": 0.15854779411764705,
      "grad_norm": 0.907919704914093,
      "learning_rate": 3.161764705882353e-06,
      "loss": 0.5632,
      "step": 690
    },
    {
      "epoch": 0.15877757352941177,
      "grad_norm": 0.971993088722229,
      "learning_rate": 3.1663602941176474e-06,
      "loss": 0.5735,
      "step": 691
    },
    {
      "epoch": 0.15900735294117646,
      "grad_norm": 1.0363508462905884,
      "learning_rate": 3.1709558823529413e-06,
      "loss": 0.5234,
      "step": 692
    },
    {
      "epoch": 0.15923713235294118,
      "grad_norm": 1.0565273761749268,
      "learning_rate": 3.1755514705882357e-06,
      "loss": 0.5978,
      "step": 693
    },
    {
      "epoch": 0.15946691176470587,
      "grad_norm": 0.9357695579528809,
      "learning_rate": 3.1801470588235296e-06,
      "loss": 0.5483,
      "step": 694
    },
    {
      "epoch": 0.1596966911764706,
      "grad_norm": 1.1484471559524536,
      "learning_rate": 3.184742647058824e-06,
      "loss": 0.5962,
      "step": 695
    },
    {
      "epoch": 0.15992647058823528,
      "grad_norm": 1.0607686042785645,
      "learning_rate": 3.189338235294118e-06,
      "loss": 0.5897,
      "step": 696
    },
    {
      "epoch": 0.16015625,
      "grad_norm": 1.018742561340332,
      "learning_rate": 3.193933823529412e-06,
      "loss": 0.6067,
      "step": 697
    },
    {
      "epoch": 0.16038602941176472,
      "grad_norm": 0.9952551126480103,
      "learning_rate": 3.198529411764706e-06,
      "loss": 0.6105,
      "step": 698
    },
    {
      "epoch": 0.1606158088235294,
      "grad_norm": 1.2161760330200195,
      "learning_rate": 3.2031250000000004e-06,
      "loss": 0.6198,
      "step": 699
    },
    {
      "epoch": 0.16084558823529413,
      "grad_norm": 1.0936030149459839,
      "learning_rate": 3.2077205882352947e-06,
      "loss": 0.6122,
      "step": 700
    },
    {
      "epoch": 0.16107536764705882,
      "grad_norm": 1.1659541130065918,
      "learning_rate": 3.2123161764705886e-06,
      "loss": 0.6863,
      "step": 701
    },
    {
      "epoch": 0.16130514705882354,
      "grad_norm": 1.0653215646743774,
      "learning_rate": 3.216911764705883e-06,
      "loss": 0.5314,
      "step": 702
    },
    {
      "epoch": 0.16153492647058823,
      "grad_norm": 0.9928064346313477,
      "learning_rate": 3.221507352941177e-06,
      "loss": 0.5963,
      "step": 703
    },
    {
      "epoch": 0.16176470588235295,
      "grad_norm": 0.9145767092704773,
      "learning_rate": 3.226102941176471e-06,
      "loss": 0.5767,
      "step": 704
    },
    {
      "epoch": 0.16199448529411764,
      "grad_norm": 1.0622986555099487,
      "learning_rate": 3.230698529411765e-06,
      "loss": 0.6012,
      "step": 705
    },
    {
      "epoch": 0.16222426470588236,
      "grad_norm": 1.1043400764465332,
      "learning_rate": 3.2352941176470594e-06,
      "loss": 0.5369,
      "step": 706
    },
    {
      "epoch": 0.16245404411764705,
      "grad_norm": 1.0861294269561768,
      "learning_rate": 3.239889705882353e-06,
      "loss": 0.4729,
      "step": 707
    },
    {
      "epoch": 0.16268382352941177,
      "grad_norm": 0.9965981841087341,
      "learning_rate": 3.2444852941176476e-06,
      "loss": 0.5658,
      "step": 708
    },
    {
      "epoch": 0.16291360294117646,
      "grad_norm": 0.8658638000488281,
      "learning_rate": 3.249080882352941e-06,
      "loss": 0.5104,
      "step": 709
    },
    {
      "epoch": 0.16314338235294118,
      "grad_norm": 0.9802908301353455,
      "learning_rate": 3.253676470588236e-06,
      "loss": 0.5047,
      "step": 710
    },
    {
      "epoch": 0.16337316176470587,
      "grad_norm": 1.0323511362075806,
      "learning_rate": 3.2582720588235293e-06,
      "loss": 0.6313,
      "step": 711
    },
    {
      "epoch": 0.1636029411764706,
      "grad_norm": 0.9577611088752747,
      "learning_rate": 3.2628676470588237e-06,
      "loss": 0.5491,
      "step": 712
    },
    {
      "epoch": 0.16383272058823528,
      "grad_norm": 0.9315834641456604,
      "learning_rate": 3.2674632352941176e-06,
      "loss": 0.4919,
      "step": 713
    },
    {
      "epoch": 0.1640625,
      "grad_norm": 1.016109585762024,
      "learning_rate": 3.272058823529412e-06,
      "loss": 0.5468,
      "step": 714
    },
    {
      "epoch": 0.16429227941176472,
      "grad_norm": 1.0069550275802612,
      "learning_rate": 3.276654411764706e-06,
      "loss": 0.5012,
      "step": 715
    },
    {
      "epoch": 0.1645220588235294,
      "grad_norm": 1.0163612365722656,
      "learning_rate": 3.28125e-06,
      "loss": 0.5806,
      "step": 716
    },
    {
      "epoch": 0.16475183823529413,
      "grad_norm": 0.9459429979324341,
      "learning_rate": 3.2858455882352945e-06,
      "loss": 0.5242,
      "step": 717
    },
    {
      "epoch": 0.16498161764705882,
      "grad_norm": 0.9222198128700256,
      "learning_rate": 3.2904411764705884e-06,
      "loss": 0.5116,
      "step": 718
    },
    {
      "epoch": 0.16521139705882354,
      "grad_norm": 0.9065436720848083,
      "learning_rate": 3.2950367647058827e-06,
      "loss": 0.5373,
      "step": 719
    },
    {
      "epoch": 0.16544117647058823,
      "grad_norm": 0.9954060912132263,
      "learning_rate": 3.2996323529411766e-06,
      "loss": 0.5493,
      "step": 720
    },
    {
      "epoch": 0.16567095588235295,
      "grad_norm": 1.1109668016433716,
      "learning_rate": 3.304227941176471e-06,
      "loss": 0.5848,
      "step": 721
    },
    {
      "epoch": 0.16590073529411764,
      "grad_norm": 1.0623328685760498,
      "learning_rate": 3.308823529411765e-06,
      "loss": 0.5283,
      "step": 722
    },
    {
      "epoch": 0.16613051470588236,
      "grad_norm": 1.0867831707000732,
      "learning_rate": 3.313419117647059e-06,
      "loss": 0.5008,
      "step": 723
    },
    {
      "epoch": 0.16636029411764705,
      "grad_norm": 1.2593270540237427,
      "learning_rate": 3.318014705882353e-06,
      "loss": 0.5056,
      "step": 724
    },
    {
      "epoch": 0.16659007352941177,
      "grad_norm": 0.885043740272522,
      "learning_rate": 3.3226102941176474e-06,
      "loss": 0.5284,
      "step": 725
    },
    {
      "epoch": 0.16681985294117646,
      "grad_norm": 1.088998556137085,
      "learning_rate": 3.3272058823529413e-06,
      "loss": 0.546,
      "step": 726
    },
    {
      "epoch": 0.16704963235294118,
      "grad_norm": 0.9704282283782959,
      "learning_rate": 3.3318014705882356e-06,
      "loss": 0.5326,
      "step": 727
    },
    {
      "epoch": 0.16727941176470587,
      "grad_norm": 0.8684479594230652,
      "learning_rate": 3.3363970588235295e-06,
      "loss": 0.4833,
      "step": 728
    },
    {
      "epoch": 0.1675091911764706,
      "grad_norm": 1.17621648311615,
      "learning_rate": 3.340992647058824e-06,
      "loss": 0.5763,
      "step": 729
    },
    {
      "epoch": 0.16773897058823528,
      "grad_norm": 1.4432622194290161,
      "learning_rate": 3.3455882352941178e-06,
      "loss": 0.5606,
      "step": 730
    },
    {
      "epoch": 0.16796875,
      "grad_norm": 1.069771647453308,
      "learning_rate": 3.350183823529412e-06,
      "loss": 0.5502,
      "step": 731
    },
    {
      "epoch": 0.16819852941176472,
      "grad_norm": 0.8824946880340576,
      "learning_rate": 3.354779411764706e-06,
      "loss": 0.5039,
      "step": 732
    },
    {
      "epoch": 0.1684283088235294,
      "grad_norm": 1.1249334812164307,
      "learning_rate": 3.3593750000000003e-06,
      "loss": 0.5446,
      "step": 733
    },
    {
      "epoch": 0.16865808823529413,
      "grad_norm": 1.144078254699707,
      "learning_rate": 3.3639705882352947e-06,
      "loss": 0.5517,
      "step": 734
    },
    {
      "epoch": 0.16888786764705882,
      "grad_norm": 1.0951464176177979,
      "learning_rate": 3.3685661764705886e-06,
      "loss": 0.4808,
      "step": 735
    },
    {
      "epoch": 0.16911764705882354,
      "grad_norm": 1.0120348930358887,
      "learning_rate": 3.373161764705883e-06,
      "loss": 0.5598,
      "step": 736
    },
    {
      "epoch": 0.16934742647058823,
      "grad_norm": 1.0426959991455078,
      "learning_rate": 3.377757352941177e-06,
      "loss": 0.4803,
      "step": 737
    },
    {
      "epoch": 0.16957720588235295,
      "grad_norm": 1.001114010810852,
      "learning_rate": 3.382352941176471e-06,
      "loss": 0.5333,
      "step": 738
    },
    {
      "epoch": 0.16980698529411764,
      "grad_norm": 1.0440301895141602,
      "learning_rate": 3.386948529411765e-06,
      "loss": 0.523,
      "step": 739
    },
    {
      "epoch": 0.17003676470588236,
      "grad_norm": 0.9646821022033691,
      "learning_rate": 3.3915441176470594e-06,
      "loss": 0.483,
      "step": 740
    },
    {
      "epoch": 0.17026654411764705,
      "grad_norm": 1.0800302028656006,
      "learning_rate": 3.3961397058823533e-06,
      "loss": 0.484,
      "step": 741
    },
    {
      "epoch": 0.17049632352941177,
      "grad_norm": 1.0410634279251099,
      "learning_rate": 3.4007352941176476e-06,
      "loss": 0.51,
      "step": 742
    },
    {
      "epoch": 0.17072610294117646,
      "grad_norm": 1.1339237689971924,
      "learning_rate": 3.405330882352941e-06,
      "loss": 0.4718,
      "step": 743
    },
    {
      "epoch": 0.17095588235294118,
      "grad_norm": 1.2110602855682373,
      "learning_rate": 3.409926470588236e-06,
      "loss": 0.5193,
      "step": 744
    },
    {
      "epoch": 0.17118566176470587,
      "grad_norm": 1.1402099132537842,
      "learning_rate": 3.4145220588235293e-06,
      "loss": 0.517,
      "step": 745
    },
    {
      "epoch": 0.1714154411764706,
      "grad_norm": 1.024863600730896,
      "learning_rate": 3.419117647058824e-06,
      "loss": 0.4829,
      "step": 746
    },
    {
      "epoch": 0.17164522058823528,
      "grad_norm": 0.969651460647583,
      "learning_rate": 3.4237132352941176e-06,
      "loss": 0.4449,
      "step": 747
    },
    {
      "epoch": 0.171875,
      "grad_norm": 1.3145314455032349,
      "learning_rate": 3.428308823529412e-06,
      "loss": 0.5491,
      "step": 748
    },
    {
      "epoch": 0.17210477941176472,
      "grad_norm": 1.1170576810836792,
      "learning_rate": 3.432904411764706e-06,
      "loss": 0.5984,
      "step": 749
    },
    {
      "epoch": 0.1723345588235294,
      "grad_norm": 0.9430322051048279,
      "learning_rate": 3.4375e-06,
      "loss": 0.5051,
      "step": 750
    },
    {
      "epoch": 0.17256433823529413,
      "grad_norm": 0.9736616611480713,
      "learning_rate": 3.4420955882352945e-06,
      "loss": 0.4869,
      "step": 751
    },
    {
      "epoch": 0.17279411764705882,
      "grad_norm": 1.2338677644729614,
      "learning_rate": 3.4466911764705884e-06,
      "loss": 0.5848,
      "step": 752
    },
    {
      "epoch": 0.17302389705882354,
      "grad_norm": 1.2103986740112305,
      "learning_rate": 3.4512867647058827e-06,
      "loss": 0.5089,
      "step": 753
    },
    {
      "epoch": 0.17325367647058823,
      "grad_norm": 0.9780003428459167,
      "learning_rate": 3.4558823529411766e-06,
      "loss": 0.5059,
      "step": 754
    },
    {
      "epoch": 0.17348345588235295,
      "grad_norm": 1.0652824640274048,
      "learning_rate": 3.460477941176471e-06,
      "loss": 0.4564,
      "step": 755
    },
    {
      "epoch": 0.17371323529411764,
      "grad_norm": 1.3515597581863403,
      "learning_rate": 3.465073529411765e-06,
      "loss": 0.5085,
      "step": 756
    },
    {
      "epoch": 0.17394301470588236,
      "grad_norm": 0.9446923136711121,
      "learning_rate": 3.469669117647059e-06,
      "loss": 0.5082,
      "step": 757
    },
    {
      "epoch": 0.17417279411764705,
      "grad_norm": 1.0963557958602905,
      "learning_rate": 3.474264705882353e-06,
      "loss": 0.4603,
      "step": 758
    },
    {
      "epoch": 0.17440257352941177,
      "grad_norm": 0.9604848027229309,
      "learning_rate": 3.4788602941176474e-06,
      "loss": 0.4731,
      "step": 759
    },
    {
      "epoch": 0.17463235294117646,
      "grad_norm": 0.8968576192855835,
      "learning_rate": 3.4834558823529413e-06,
      "loss": 0.4987,
      "step": 760
    },
    {
      "epoch": 0.17486213235294118,
      "grad_norm": 1.0879836082458496,
      "learning_rate": 3.4880514705882356e-06,
      "loss": 0.4417,
      "step": 761
    },
    {
      "epoch": 0.17509191176470587,
      "grad_norm": 1.0047796964645386,
      "learning_rate": 3.4926470588235295e-06,
      "loss": 0.4959,
      "step": 762
    },
    {
      "epoch": 0.1753216911764706,
      "grad_norm": 1.2013272047042847,
      "learning_rate": 3.497242647058824e-06,
      "loss": 0.4758,
      "step": 763
    },
    {
      "epoch": 0.17555147058823528,
      "grad_norm": 1.0196598768234253,
      "learning_rate": 3.5018382352941178e-06,
      "loss": 0.4563,
      "step": 764
    },
    {
      "epoch": 0.17578125,
      "grad_norm": 1.0702813863754272,
      "learning_rate": 3.506433823529412e-06,
      "loss": 0.438,
      "step": 765
    },
    {
      "epoch": 0.17601102941176472,
      "grad_norm": 0.9801488518714905,
      "learning_rate": 3.511029411764706e-06,
      "loss": 0.5111,
      "step": 766
    },
    {
      "epoch": 0.1762408088235294,
      "grad_norm": 1.3707084655761719,
      "learning_rate": 3.5156250000000003e-06,
      "loss": 0.5019,
      "step": 767
    },
    {
      "epoch": 0.17647058823529413,
      "grad_norm": 0.9741411209106445,
      "learning_rate": 3.5202205882352947e-06,
      "loss": 0.4428,
      "step": 768
    },
    {
      "epoch": 0.17670036764705882,
      "grad_norm": 0.8645832538604736,
      "learning_rate": 3.5248161764705886e-06,
      "loss": 0.4906,
      "step": 769
    },
    {
      "epoch": 0.17693014705882354,
      "grad_norm": 1.245129108428955,
      "learning_rate": 3.529411764705883e-06,
      "loss": 0.5046,
      "step": 770
    },
    {
      "epoch": 0.17715992647058823,
      "grad_norm": 1.1415846347808838,
      "learning_rate": 3.534007352941177e-06,
      "loss": 0.4653,
      "step": 771
    },
    {
      "epoch": 0.17738970588235295,
      "grad_norm": 1.3208250999450684,
      "learning_rate": 3.538602941176471e-06,
      "loss": 0.5036,
      "step": 772
    },
    {
      "epoch": 0.17761948529411764,
      "grad_norm": 1.1111401319503784,
      "learning_rate": 3.543198529411765e-06,
      "loss": 0.5599,
      "step": 773
    },
    {
      "epoch": 0.17784926470588236,
      "grad_norm": 1.0431910753250122,
      "learning_rate": 3.5477941176470594e-06,
      "loss": 0.4834,
      "step": 774
    },
    {
      "epoch": 0.17807904411764705,
      "grad_norm": 1.0359517335891724,
      "learning_rate": 3.5523897058823533e-06,
      "loss": 0.4938,
      "step": 775
    },
    {
      "epoch": 0.17830882352941177,
      "grad_norm": 1.1499812602996826,
      "learning_rate": 3.5569852941176476e-06,
      "loss": 0.5244,
      "step": 776
    },
    {
      "epoch": 0.17853860294117646,
      "grad_norm": 0.9956185817718506,
      "learning_rate": 3.5615808823529415e-06,
      "loss": 0.5693,
      "step": 777
    },
    {
      "epoch": 0.17876838235294118,
      "grad_norm": 1.096658706665039,
      "learning_rate": 3.566176470588236e-06,
      "loss": 0.4336,
      "step": 778
    },
    {
      "epoch": 0.17899816176470587,
      "grad_norm": 1.0403656959533691,
      "learning_rate": 3.5707720588235293e-06,
      "loss": 0.4611,
      "step": 779
    },
    {
      "epoch": 0.1792279411764706,
      "grad_norm": 1.1532244682312012,
      "learning_rate": 3.575367647058824e-06,
      "loss": 0.4858,
      "step": 780
    },
    {
      "epoch": 0.17945772058823528,
      "grad_norm": 1.0595788955688477,
      "learning_rate": 3.5799632352941175e-06,
      "loss": 0.4736,
      "step": 781
    },
    {
      "epoch": 0.1796875,
      "grad_norm": 1.2188866138458252,
      "learning_rate": 3.5845588235294123e-06,
      "loss": 0.4229,
      "step": 782
    },
    {
      "epoch": 0.17991727941176472,
      "grad_norm": 0.9971193671226501,
      "learning_rate": 3.5891544117647058e-06,
      "loss": 0.4648,
      "step": 783
    },
    {
      "epoch": 0.1801470588235294,
      "grad_norm": 0.9417663812637329,
      "learning_rate": 3.59375e-06,
      "loss": 0.4865,
      "step": 784
    },
    {
      "epoch": 0.18037683823529413,
      "grad_norm": 1.2265608310699463,
      "learning_rate": 3.598345588235295e-06,
      "loss": 0.4423,
      "step": 785
    },
    {
      "epoch": 0.18060661764705882,
      "grad_norm": 0.8246596455574036,
      "learning_rate": 3.6029411764705883e-06,
      "loss": 0.4494,
      "step": 786
    },
    {
      "epoch": 0.18083639705882354,
      "grad_norm": 1.0477806329727173,
      "learning_rate": 3.6075367647058827e-06,
      "loss": 0.4283,
      "step": 787
    },
    {
      "epoch": 0.18106617647058823,
      "grad_norm": 1.1233108043670654,
      "learning_rate": 3.6121323529411766e-06,
      "loss": 0.4999,
      "step": 788
    },
    {
      "epoch": 0.18129595588235295,
      "grad_norm": 1.165897011756897,
      "learning_rate": 3.616727941176471e-06,
      "loss": 0.4417,
      "step": 789
    },
    {
      "epoch": 0.18152573529411764,
      "grad_norm": 1.1126399040222168,
      "learning_rate": 3.621323529411765e-06,
      "loss": 0.5209,
      "step": 790
    },
    {
      "epoch": 0.18175551470588236,
      "grad_norm": 1.057146668434143,
      "learning_rate": 3.625919117647059e-06,
      "loss": 0.4658,
      "step": 791
    },
    {
      "epoch": 0.18198529411764705,
      "grad_norm": 1.0800400972366333,
      "learning_rate": 3.630514705882353e-06,
      "loss": 0.4763,
      "step": 792
    },
    {
      "epoch": 0.18221507352941177,
      "grad_norm": 1.0006866455078125,
      "learning_rate": 3.6351102941176474e-06,
      "loss": 0.4731,
      "step": 793
    },
    {
      "epoch": 0.18244485294117646,
      "grad_norm": 0.8406693935394287,
      "learning_rate": 3.6397058823529413e-06,
      "loss": 0.44,
      "step": 794
    },
    {
      "epoch": 0.18267463235294118,
      "grad_norm": 1.0225871801376343,
      "learning_rate": 3.6443014705882356e-06,
      "loss": 0.47,
      "step": 795
    },
    {
      "epoch": 0.18290441176470587,
      "grad_norm": 1.0481605529785156,
      "learning_rate": 3.6488970588235295e-06,
      "loss": 0.4391,
      "step": 796
    },
    {
      "epoch": 0.1831341911764706,
      "grad_norm": 1.1253056526184082,
      "learning_rate": 3.653492647058824e-06,
      "loss": 0.4371,
      "step": 797
    },
    {
      "epoch": 0.18336397058823528,
      "grad_norm": 1.0502418279647827,
      "learning_rate": 3.6580882352941178e-06,
      "loss": 0.3848,
      "step": 798
    },
    {
      "epoch": 0.18359375,
      "grad_norm": 1.1271708011627197,
      "learning_rate": 3.662683823529412e-06,
      "loss": 0.4568,
      "step": 799
    },
    {
      "epoch": 0.18382352941176472,
      "grad_norm": 1.299795150756836,
      "learning_rate": 3.667279411764706e-06,
      "loss": 0.4077,
      "step": 800
    },
    {
      "epoch": 0.1840533088235294,
      "grad_norm": 0.8796355724334717,
      "learning_rate": 3.6718750000000003e-06,
      "loss": 0.4829,
      "step": 801
    },
    {
      "epoch": 0.18428308823529413,
      "grad_norm": 0.9827632904052734,
      "learning_rate": 3.6764705882352946e-06,
      "loss": 0.4163,
      "step": 802
    },
    {
      "epoch": 0.18451286764705882,
      "grad_norm": 1.1938124895095825,
      "learning_rate": 3.6810661764705885e-06,
      "loss": 0.4146,
      "step": 803
    },
    {
      "epoch": 0.18474264705882354,
      "grad_norm": 1.051579475402832,
      "learning_rate": 3.685661764705883e-06,
      "loss": 0.5071,
      "step": 804
    },
    {
      "epoch": 0.18497242647058823,
      "grad_norm": 1.0007448196411133,
      "learning_rate": 3.6902573529411768e-06,
      "loss": 0.411,
      "step": 805
    },
    {
      "epoch": 0.18520220588235295,
      "grad_norm": 0.9348827004432678,
      "learning_rate": 3.694852941176471e-06,
      "loss": 0.4061,
      "step": 806
    },
    {
      "epoch": 0.18543198529411764,
      "grad_norm": 1.0393062829971313,
      "learning_rate": 3.699448529411765e-06,
      "loss": 0.4289,
      "step": 807
    },
    {
      "epoch": 0.18566176470588236,
      "grad_norm": 0.8783314228057861,
      "learning_rate": 3.7040441176470593e-06,
      "loss": 0.4524,
      "step": 808
    },
    {
      "epoch": 0.18589154411764705,
      "grad_norm": 1.12386953830719,
      "learning_rate": 3.7086397058823533e-06,
      "loss": 0.4374,
      "step": 809
    },
    {
      "epoch": 0.18612132352941177,
      "grad_norm": 1.1696912050247192,
      "learning_rate": 3.7132352941176476e-06,
      "loss": 0.4933,
      "step": 810
    },
    {
      "epoch": 0.18635110294117646,
      "grad_norm": 1.2484325170516968,
      "learning_rate": 3.7178308823529415e-06,
      "loss": 0.4247,
      "step": 811
    },
    {
      "epoch": 0.18658088235294118,
      "grad_norm": 1.1168984174728394,
      "learning_rate": 3.722426470588236e-06,
      "loss": 0.4999,
      "step": 812
    },
    {
      "epoch": 0.18681066176470587,
      "grad_norm": 1.0605459213256836,
      "learning_rate": 3.7270220588235297e-06,
      "loss": 0.436,
      "step": 813
    },
    {
      "epoch": 0.1870404411764706,
      "grad_norm": 1.0487446784973145,
      "learning_rate": 3.731617647058824e-06,
      "loss": 0.4393,
      "step": 814
    },
    {
      "epoch": 0.18727022058823528,
      "grad_norm": 1.2362911701202393,
      "learning_rate": 3.7362132352941175e-06,
      "loss": 0.4202,
      "step": 815
    },
    {
      "epoch": 0.1875,
      "grad_norm": 1.0301121473312378,
      "learning_rate": 3.7408088235294123e-06,
      "loss": 0.4814,
      "step": 816
    },
    {
      "epoch": 0.18772977941176472,
      "grad_norm": 1.473644733428955,
      "learning_rate": 3.7454044117647058e-06,
      "loss": 0.5022,
      "step": 817
    },
    {
      "epoch": 0.1879595588235294,
      "grad_norm": 1.1627635955810547,
      "learning_rate": 3.7500000000000005e-06,
      "loss": 0.4429,
      "step": 818
    },
    {
      "epoch": 0.18818933823529413,
      "grad_norm": 1.0933282375335693,
      "learning_rate": 3.754595588235295e-06,
      "loss": 0.4278,
      "step": 819
    },
    {
      "epoch": 0.18841911764705882,
      "grad_norm": 1.1130861043930054,
      "learning_rate": 3.7591911764705883e-06,
      "loss": 0.4236,
      "step": 820
    },
    {
      "epoch": 0.18864889705882354,
      "grad_norm": 1.2546192407608032,
      "learning_rate": 3.763786764705883e-06,
      "loss": 0.4844,
      "step": 821
    },
    {
      "epoch": 0.18887867647058823,
      "grad_norm": 1.057113766670227,
      "learning_rate": 3.7683823529411766e-06,
      "loss": 0.4372,
      "step": 822
    },
    {
      "epoch": 0.18910845588235295,
      "grad_norm": 1.0460115671157837,
      "learning_rate": 3.772977941176471e-06,
      "loss": 0.4291,
      "step": 823
    },
    {
      "epoch": 0.18933823529411764,
      "grad_norm": 1.1387289762496948,
      "learning_rate": 3.777573529411765e-06,
      "loss": 0.3869,
      "step": 824
    },
    {
      "epoch": 0.18956801470588236,
      "grad_norm": 0.977728009223938,
      "learning_rate": 3.782169117647059e-06,
      "loss": 0.4853,
      "step": 825
    },
    {
      "epoch": 0.18979779411764705,
      "grad_norm": 1.0484445095062256,
      "learning_rate": 3.786764705882353e-06,
      "loss": 0.4248,
      "step": 826
    },
    {
      "epoch": 0.19002757352941177,
      "grad_norm": 1.254690170288086,
      "learning_rate": 3.7913602941176474e-06,
      "loss": 0.4222,
      "step": 827
    },
    {
      "epoch": 0.19025735294117646,
      "grad_norm": 0.9285345077514648,
      "learning_rate": 3.7959558823529413e-06,
      "loss": 0.4601,
      "step": 828
    },
    {
      "epoch": 0.19048713235294118,
      "grad_norm": 1.390729546546936,
      "learning_rate": 3.8005514705882356e-06,
      "loss": 0.5219,
      "step": 829
    },
    {
      "epoch": 0.19071691176470587,
      "grad_norm": 1.1169390678405762,
      "learning_rate": 3.8051470588235295e-06,
      "loss": 0.4568,
      "step": 830
    },
    {
      "epoch": 0.1909466911764706,
      "grad_norm": 0.9902878403663635,
      "learning_rate": 3.809742647058824e-06,
      "loss": 0.4234,
      "step": 831
    },
    {
      "epoch": 0.19117647058823528,
      "grad_norm": 1.2088255882263184,
      "learning_rate": 3.8143382352941177e-06,
      "loss": 0.4374,
      "step": 832
    },
    {
      "epoch": 0.19140625,
      "grad_norm": 0.8351646661758423,
      "learning_rate": 3.818933823529412e-06,
      "loss": 0.443,
      "step": 833
    },
    {
      "epoch": 0.19163602941176472,
      "grad_norm": 1.0235610008239746,
      "learning_rate": 3.8235294117647055e-06,
      "loss": 0.3931,
      "step": 834
    },
    {
      "epoch": 0.1918658088235294,
      "grad_norm": 1.012452483177185,
      "learning_rate": 3.828125000000001e-06,
      "loss": 0.4512,
      "step": 835
    },
    {
      "epoch": 0.19209558823529413,
      "grad_norm": 0.9863515496253967,
      "learning_rate": 3.832720588235295e-06,
      "loss": 0.4276,
      "step": 836
    },
    {
      "epoch": 0.19232536764705882,
      "grad_norm": 0.9499626159667969,
      "learning_rate": 3.8373161764705885e-06,
      "loss": 0.4148,
      "step": 837
    },
    {
      "epoch": 0.19255514705882354,
      "grad_norm": 0.9559216499328613,
      "learning_rate": 3.841911764705883e-06,
      "loss": 0.3985,
      "step": 838
    },
    {
      "epoch": 0.19278492647058823,
      "grad_norm": 1.2885631322860718,
      "learning_rate": 3.846507352941176e-06,
      "loss": 0.4044,
      "step": 839
    },
    {
      "epoch": 0.19301470588235295,
      "grad_norm": 1.0633792877197266,
      "learning_rate": 3.8511029411764715e-06,
      "loss": 0.384,
      "step": 840
    },
    {
      "epoch": 0.19324448529411764,
      "grad_norm": 0.9681954383850098,
      "learning_rate": 3.855698529411765e-06,
      "loss": 0.4772,
      "step": 841
    },
    {
      "epoch": 0.19347426470588236,
      "grad_norm": 0.9598826766014099,
      "learning_rate": 3.860294117647059e-06,
      "loss": 0.4332,
      "step": 842
    },
    {
      "epoch": 0.19370404411764705,
      "grad_norm": 1.1314353942871094,
      "learning_rate": 3.864889705882353e-06,
      "loss": 0.3914,
      "step": 843
    },
    {
      "epoch": 0.19393382352941177,
      "grad_norm": 0.9390583038330078,
      "learning_rate": 3.869485294117647e-06,
      "loss": 0.3787,
      "step": 844
    },
    {
      "epoch": 0.19416360294117646,
      "grad_norm": 0.9601563215255737,
      "learning_rate": 3.8740808823529415e-06,
      "loss": 0.4353,
      "step": 845
    },
    {
      "epoch": 0.19439338235294118,
      "grad_norm": 0.8309684991836548,
      "learning_rate": 3.878676470588236e-06,
      "loss": 0.4373,
      "step": 846
    },
    {
      "epoch": 0.19462316176470587,
      "grad_norm": 1.1056448221206665,
      "learning_rate": 3.883272058823529e-06,
      "loss": 0.4117,
      "step": 847
    },
    {
      "epoch": 0.1948529411764706,
      "grad_norm": 1.1009726524353027,
      "learning_rate": 3.887867647058824e-06,
      "loss": 0.4175,
      "step": 848
    },
    {
      "epoch": 0.19508272058823528,
      "grad_norm": 1.0137431621551514,
      "learning_rate": 3.892463235294118e-06,
      "loss": 0.396,
      "step": 849
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 0.977978527545929,
      "learning_rate": 3.897058823529412e-06,
      "loss": 0.414,
      "step": 850
    },
    {
      "epoch": 0.19554227941176472,
      "grad_norm": 1.046464204788208,
      "learning_rate": 3.901654411764706e-06,
      "loss": 0.3899,
      "step": 851
    },
    {
      "epoch": 0.1957720588235294,
      "grad_norm": 1.0590907335281372,
      "learning_rate": 3.90625e-06,
      "loss": 0.4051,
      "step": 852
    },
    {
      "epoch": 0.19600183823529413,
      "grad_norm": 0.9409183859825134,
      "learning_rate": 3.910845588235294e-06,
      "loss": 0.4521,
      "step": 853
    },
    {
      "epoch": 0.19623161764705882,
      "grad_norm": 0.9665935635566711,
      "learning_rate": 3.915441176470589e-06,
      "loss": 0.3822,
      "step": 854
    },
    {
      "epoch": 0.19646139705882354,
      "grad_norm": 1.092275619506836,
      "learning_rate": 3.920036764705883e-06,
      "loss": 0.4328,
      "step": 855
    },
    {
      "epoch": 0.19669117647058823,
      "grad_norm": 1.3108775615692139,
      "learning_rate": 3.9246323529411766e-06,
      "loss": 0.375,
      "step": 856
    },
    {
      "epoch": 0.19692095588235295,
      "grad_norm": 0.9725954532623291,
      "learning_rate": 3.929227941176471e-06,
      "loss": 0.4004,
      "step": 857
    },
    {
      "epoch": 0.19715073529411764,
      "grad_norm": 0.9526836276054382,
      "learning_rate": 3.933823529411765e-06,
      "loss": 0.3914,
      "step": 858
    },
    {
      "epoch": 0.19738051470588236,
      "grad_norm": 1.2621113061904907,
      "learning_rate": 3.9384191176470595e-06,
      "loss": 0.4196,
      "step": 859
    },
    {
      "epoch": 0.19761029411764705,
      "grad_norm": 1.1876771450042725,
      "learning_rate": 3.943014705882353e-06,
      "loss": 0.3626,
      "step": 860
    },
    {
      "epoch": 0.19784007352941177,
      "grad_norm": 1.4377068281173706,
      "learning_rate": 3.947610294117647e-06,
      "loss": 0.399,
      "step": 861
    },
    {
      "epoch": 0.19806985294117646,
      "grad_norm": 0.8752188682556152,
      "learning_rate": 3.952205882352942e-06,
      "loss": 0.4192,
      "step": 862
    },
    {
      "epoch": 0.19829963235294118,
      "grad_norm": 1.0027282238006592,
      "learning_rate": 3.956801470588236e-06,
      "loss": 0.4409,
      "step": 863
    },
    {
      "epoch": 0.19852941176470587,
      "grad_norm": 1.3002527952194214,
      "learning_rate": 3.9613970588235295e-06,
      "loss": 0.475,
      "step": 864
    },
    {
      "epoch": 0.1987591911764706,
      "grad_norm": 0.9336175918579102,
      "learning_rate": 3.965992647058824e-06,
      "loss": 0.3911,
      "step": 865
    },
    {
      "epoch": 0.19898897058823528,
      "grad_norm": 1.2756589651107788,
      "learning_rate": 3.970588235294118e-06,
      "loss": 0.4388,
      "step": 866
    },
    {
      "epoch": 0.19921875,
      "grad_norm": 1.0571080446243286,
      "learning_rate": 3.9751838235294125e-06,
      "loss": 0.4116,
      "step": 867
    },
    {
      "epoch": 0.19944852941176472,
      "grad_norm": 1.4592461585998535,
      "learning_rate": 3.979779411764706e-06,
      "loss": 0.4219,
      "step": 868
    },
    {
      "epoch": 0.1996783088235294,
      "grad_norm": 1.087990403175354,
      "learning_rate": 3.984375e-06,
      "loss": 0.377,
      "step": 869
    },
    {
      "epoch": 0.19990808823529413,
      "grad_norm": 0.9112169742584229,
      "learning_rate": 3.988970588235295e-06,
      "loss": 0.3716,
      "step": 870
    },
    {
      "epoch": 0.20013786764705882,
      "grad_norm": 1.0720434188842773,
      "learning_rate": 3.993566176470589e-06,
      "loss": 0.4398,
      "step": 871
    },
    {
      "epoch": 0.20036764705882354,
      "grad_norm": 1.0104105472564697,
      "learning_rate": 3.998161764705883e-06,
      "loss": 0.3831,
      "step": 872
    },
    {
      "epoch": 0.20059742647058823,
      "grad_norm": 1.265673279762268,
      "learning_rate": 4.002757352941177e-06,
      "loss": 0.3507,
      "step": 873
    },
    {
      "epoch": 0.20082720588235295,
      "grad_norm": 1.0394724607467651,
      "learning_rate": 4.007352941176471e-06,
      "loss": 0.4002,
      "step": 874
    },
    {
      "epoch": 0.20105698529411764,
      "grad_norm": 1.0728954076766968,
      "learning_rate": 4.0119485294117646e-06,
      "loss": 0.4223,
      "step": 875
    },
    {
      "epoch": 0.20128676470588236,
      "grad_norm": 1.0860793590545654,
      "learning_rate": 4.016544117647059e-06,
      "loss": 0.3966,
      "step": 876
    },
    {
      "epoch": 0.20151654411764705,
      "grad_norm": 1.040618896484375,
      "learning_rate": 4.021139705882353e-06,
      "loss": 0.3727,
      "step": 877
    },
    {
      "epoch": 0.20174632352941177,
      "grad_norm": 0.957589328289032,
      "learning_rate": 4.0257352941176476e-06,
      "loss": 0.3612,
      "step": 878
    },
    {
      "epoch": 0.20197610294117646,
      "grad_norm": 0.8692988157272339,
      "learning_rate": 4.030330882352941e-06,
      "loss": 0.4098,
      "step": 879
    },
    {
      "epoch": 0.20220588235294118,
      "grad_norm": 1.073477029800415,
      "learning_rate": 4.034926470588235e-06,
      "loss": 0.4022,
      "step": 880
    },
    {
      "epoch": 0.20243566176470587,
      "grad_norm": 1.0083190202713013,
      "learning_rate": 4.03952205882353e-06,
      "loss": 0.3506,
      "step": 881
    },
    {
      "epoch": 0.2026654411764706,
      "grad_norm": 1.2475165128707886,
      "learning_rate": 4.044117647058824e-06,
      "loss": 0.4366,
      "step": 882
    },
    {
      "epoch": 0.20289522058823528,
      "grad_norm": 1.0846790075302124,
      "learning_rate": 4.0487132352941175e-06,
      "loss": 0.4219,
      "step": 883
    },
    {
      "epoch": 0.203125,
      "grad_norm": 1.3374865055084229,
      "learning_rate": 4.053308823529412e-06,
      "loss": 0.4187,
      "step": 884
    },
    {
      "epoch": 0.20335477941176472,
      "grad_norm": 0.9584977030754089,
      "learning_rate": 4.057904411764706e-06,
      "loss": 0.3948,
      "step": 885
    },
    {
      "epoch": 0.2035845588235294,
      "grad_norm": 1.1244901418685913,
      "learning_rate": 4.0625000000000005e-06,
      "loss": 0.3589,
      "step": 886
    },
    {
      "epoch": 0.20381433823529413,
      "grad_norm": 1.205731987953186,
      "learning_rate": 4.067095588235295e-06,
      "loss": 0.3879,
      "step": 887
    },
    {
      "epoch": 0.20404411764705882,
      "grad_norm": 0.9135882258415222,
      "learning_rate": 4.071691176470588e-06,
      "loss": 0.407,
      "step": 888
    },
    {
      "epoch": 0.20427389705882354,
      "grad_norm": 1.3739817142486572,
      "learning_rate": 4.076286764705883e-06,
      "loss": 0.3888,
      "step": 889
    },
    {
      "epoch": 0.20450367647058823,
      "grad_norm": 0.9970332980155945,
      "learning_rate": 4.080882352941177e-06,
      "loss": 0.4398,
      "step": 890
    },
    {
      "epoch": 0.20473345588235295,
      "grad_norm": 0.9700625538825989,
      "learning_rate": 4.085477941176471e-06,
      "loss": 0.434,
      "step": 891
    },
    {
      "epoch": 0.20496323529411764,
      "grad_norm": 1.1166396141052246,
      "learning_rate": 4.090073529411765e-06,
      "loss": 0.4442,
      "step": 892
    },
    {
      "epoch": 0.20519301470588236,
      "grad_norm": 1.2087739706039429,
      "learning_rate": 4.094669117647059e-06,
      "loss": 0.3772,
      "step": 893
    },
    {
      "epoch": 0.20542279411764705,
      "grad_norm": 1.0511603355407715,
      "learning_rate": 4.0992647058823534e-06,
      "loss": 0.375,
      "step": 894
    },
    {
      "epoch": 0.20565257352941177,
      "grad_norm": 1.0251553058624268,
      "learning_rate": 4.103860294117648e-06,
      "loss": 0.3772,
      "step": 895
    },
    {
      "epoch": 0.20588235294117646,
      "grad_norm": 1.1128737926483154,
      "learning_rate": 4.108455882352941e-06,
      "loss": 0.3634,
      "step": 896
    },
    {
      "epoch": 0.20611213235294118,
      "grad_norm": 1.0983855724334717,
      "learning_rate": 4.1130514705882356e-06,
      "loss": 0.4328,
      "step": 897
    },
    {
      "epoch": 0.20634191176470587,
      "grad_norm": 1.008747935295105,
      "learning_rate": 4.11764705882353e-06,
      "loss": 0.4192,
      "step": 898
    },
    {
      "epoch": 0.2065716911764706,
      "grad_norm": 1.1478456258773804,
      "learning_rate": 4.122242647058824e-06,
      "loss": 0.3882,
      "step": 899
    },
    {
      "epoch": 0.20680147058823528,
      "grad_norm": 1.186296820640564,
      "learning_rate": 4.126838235294118e-06,
      "loss": 0.4269,
      "step": 900
    },
    {
      "epoch": 0.20703125,
      "grad_norm": 0.9637934565544128,
      "learning_rate": 4.131433823529412e-06,
      "loss": 0.4161,
      "step": 901
    },
    {
      "epoch": 0.20726102941176472,
      "grad_norm": 1.0304433107376099,
      "learning_rate": 4.136029411764706e-06,
      "loss": 0.4122,
      "step": 902
    },
    {
      "epoch": 0.2074908088235294,
      "grad_norm": 0.9292845726013184,
      "learning_rate": 4.140625000000001e-06,
      "loss": 0.3785,
      "step": 903
    },
    {
      "epoch": 0.20772058823529413,
      "grad_norm": 1.0551469326019287,
      "learning_rate": 4.145220588235295e-06,
      "loss": 0.4279,
      "step": 904
    },
    {
      "epoch": 0.20795036764705882,
      "grad_norm": 1.1967500448226929,
      "learning_rate": 4.1498161764705885e-06,
      "loss": 0.3657,
      "step": 905
    },
    {
      "epoch": 0.20818014705882354,
      "grad_norm": 1.0995490550994873,
      "learning_rate": 4.154411764705883e-06,
      "loss": 0.3836,
      "step": 906
    },
    {
      "epoch": 0.20840992647058823,
      "grad_norm": 1.1722419261932373,
      "learning_rate": 4.159007352941177e-06,
      "loss": 0.3852,
      "step": 907
    },
    {
      "epoch": 0.20863970588235295,
      "grad_norm": 0.9711920619010925,
      "learning_rate": 4.1636029411764715e-06,
      "loss": 0.355,
      "step": 908
    },
    {
      "epoch": 0.20886948529411764,
      "grad_norm": 0.9870673418045044,
      "learning_rate": 4.168198529411765e-06,
      "loss": 0.3988,
      "step": 909
    },
    {
      "epoch": 0.20909926470588236,
      "grad_norm": 0.8700819611549377,
      "learning_rate": 4.172794117647059e-06,
      "loss": 0.3656,
      "step": 910
    },
    {
      "epoch": 0.20932904411764705,
      "grad_norm": 1.172389030456543,
      "learning_rate": 4.177389705882353e-06,
      "loss": 0.3894,
      "step": 911
    },
    {
      "epoch": 0.20955882352941177,
      "grad_norm": 1.157202124595642,
      "learning_rate": 4.181985294117647e-06,
      "loss": 0.3508,
      "step": 912
    },
    {
      "epoch": 0.20978860294117646,
      "grad_norm": 1.300415277481079,
      "learning_rate": 4.1865808823529414e-06,
      "loss": 0.3833,
      "step": 913
    },
    {
      "epoch": 0.21001838235294118,
      "grad_norm": 0.9659076929092407,
      "learning_rate": 4.191176470588236e-06,
      "loss": 0.3549,
      "step": 914
    },
    {
      "epoch": 0.21024816176470587,
      "grad_norm": 1.2964131832122803,
      "learning_rate": 4.195772058823529e-06,
      "loss": 0.4036,
      "step": 915
    },
    {
      "epoch": 0.2104779411764706,
      "grad_norm": 0.9903771877288818,
      "learning_rate": 4.200367647058824e-06,
      "loss": 0.4183,
      "step": 916
    },
    {
      "epoch": 0.21070772058823528,
      "grad_norm": 1.005907654762268,
      "learning_rate": 4.204963235294118e-06,
      "loss": 0.3373,
      "step": 917
    },
    {
      "epoch": 0.2109375,
      "grad_norm": 1.0059030055999756,
      "learning_rate": 4.209558823529412e-06,
      "loss": 0.3708,
      "step": 918
    },
    {
      "epoch": 0.21116727941176472,
      "grad_norm": 1.2785600423812866,
      "learning_rate": 4.214154411764706e-06,
      "loss": 0.3721,
      "step": 919
    },
    {
      "epoch": 0.2113970588235294,
      "grad_norm": 0.9510043263435364,
      "learning_rate": 4.21875e-06,
      "loss": 0.3915,
      "step": 920
    },
    {
      "epoch": 0.21162683823529413,
      "grad_norm": 1.1969759464263916,
      "learning_rate": 4.223345588235294e-06,
      "loss": 0.3291,
      "step": 921
    },
    {
      "epoch": 0.21185661764705882,
      "grad_norm": 0.9671937227249146,
      "learning_rate": 4.227941176470589e-06,
      "loss": 0.36,
      "step": 922
    },
    {
      "epoch": 0.21208639705882354,
      "grad_norm": 0.9968861937522888,
      "learning_rate": 4.232536764705883e-06,
      "loss": 0.3521,
      "step": 923
    },
    {
      "epoch": 0.21231617647058823,
      "grad_norm": 0.8504454493522644,
      "learning_rate": 4.2371323529411765e-06,
      "loss": 0.384,
      "step": 924
    },
    {
      "epoch": 0.21254595588235295,
      "grad_norm": 1.3877410888671875,
      "learning_rate": 4.241727941176471e-06,
      "loss": 0.4016,
      "step": 925
    },
    {
      "epoch": 0.21277573529411764,
      "grad_norm": 0.9019438028335571,
      "learning_rate": 4.246323529411765e-06,
      "loss": 0.3631,
      "step": 926
    },
    {
      "epoch": 0.21300551470588236,
      "grad_norm": 0.9907230734825134,
      "learning_rate": 4.2509191176470595e-06,
      "loss": 0.4236,
      "step": 927
    },
    {
      "epoch": 0.21323529411764705,
      "grad_norm": 1.050748348236084,
      "learning_rate": 4.255514705882353e-06,
      "loss": 0.3523,
      "step": 928
    },
    {
      "epoch": 0.21346507352941177,
      "grad_norm": 0.9814279079437256,
      "learning_rate": 4.260110294117647e-06,
      "loss": 0.3989,
      "step": 929
    },
    {
      "epoch": 0.21369485294117646,
      "grad_norm": 1.241045594215393,
      "learning_rate": 4.264705882352942e-06,
      "loss": 0.4171,
      "step": 930
    },
    {
      "epoch": 0.21392463235294118,
      "grad_norm": 1.3578168153762817,
      "learning_rate": 4.269301470588236e-06,
      "loss": 0.3582,
      "step": 931
    },
    {
      "epoch": 0.21415441176470587,
      "grad_norm": 1.1004639863967896,
      "learning_rate": 4.2738970588235295e-06,
      "loss": 0.3691,
      "step": 932
    },
    {
      "epoch": 0.2143841911764706,
      "grad_norm": 1.1390049457550049,
      "learning_rate": 4.278492647058824e-06,
      "loss": 0.371,
      "step": 933
    },
    {
      "epoch": 0.21461397058823528,
      "grad_norm": 1.048034429550171,
      "learning_rate": 4.283088235294118e-06,
      "loss": 0.3458,
      "step": 934
    },
    {
      "epoch": 0.21484375,
      "grad_norm": 1.1143556833267212,
      "learning_rate": 4.2876838235294124e-06,
      "loss": 0.3449,
      "step": 935
    },
    {
      "epoch": 0.21507352941176472,
      "grad_norm": 1.2350597381591797,
      "learning_rate": 4.292279411764706e-06,
      "loss": 0.4171,
      "step": 936
    },
    {
      "epoch": 0.2153033088235294,
      "grad_norm": 0.8998420834541321,
      "learning_rate": 4.296875e-06,
      "loss": 0.3741,
      "step": 937
    },
    {
      "epoch": 0.21553308823529413,
      "grad_norm": 0.9279351234436035,
      "learning_rate": 4.301470588235295e-06,
      "loss": 0.3552,
      "step": 938
    },
    {
      "epoch": 0.21576286764705882,
      "grad_norm": 1.1529680490493774,
      "learning_rate": 4.306066176470589e-06,
      "loss": 0.387,
      "step": 939
    },
    {
      "epoch": 0.21599264705882354,
      "grad_norm": 1.3189517259597778,
      "learning_rate": 4.310661764705883e-06,
      "loss": 0.3385,
      "step": 940
    },
    {
      "epoch": 0.21622242647058823,
      "grad_norm": 1.0631072521209717,
      "learning_rate": 4.315257352941177e-06,
      "loss": 0.401,
      "step": 941
    },
    {
      "epoch": 0.21645220588235295,
      "grad_norm": 0.9344825744628906,
      "learning_rate": 4.319852941176471e-06,
      "loss": 0.3016,
      "step": 942
    },
    {
      "epoch": 0.21668198529411764,
      "grad_norm": 1.2022794485092163,
      "learning_rate": 4.3244485294117645e-06,
      "loss": 0.3853,
      "step": 943
    },
    {
      "epoch": 0.21691176470588236,
      "grad_norm": 1.238870620727539,
      "learning_rate": 4.32904411764706e-06,
      "loss": 0.3701,
      "step": 944
    },
    {
      "epoch": 0.21714154411764705,
      "grad_norm": 1.0346853733062744,
      "learning_rate": 4.333639705882353e-06,
      "loss": 0.3849,
      "step": 945
    },
    {
      "epoch": 0.21737132352941177,
      "grad_norm": 0.9842793345451355,
      "learning_rate": 4.3382352941176475e-06,
      "loss": 0.2965,
      "step": 946
    },
    {
      "epoch": 0.21760110294117646,
      "grad_norm": 0.9539182782173157,
      "learning_rate": 4.342830882352941e-06,
      "loss": 0.3584,
      "step": 947
    },
    {
      "epoch": 0.21783088235294118,
      "grad_norm": 1.2187703847885132,
      "learning_rate": 4.347426470588235e-06,
      "loss": 0.3303,
      "step": 948
    },
    {
      "epoch": 0.21806066176470587,
      "grad_norm": 1.1203197240829468,
      "learning_rate": 4.35202205882353e-06,
      "loss": 0.4198,
      "step": 949
    },
    {
      "epoch": 0.2182904411764706,
      "grad_norm": 1.057244062423706,
      "learning_rate": 4.356617647058824e-06,
      "loss": 0.3551,
      "step": 950
    },
    {
      "epoch": 0.21852022058823528,
      "grad_norm": 1.0026482343673706,
      "learning_rate": 4.3612132352941175e-06,
      "loss": 0.3851,
      "step": 951
    },
    {
      "epoch": 0.21875,
      "grad_norm": 1.1428378820419312,
      "learning_rate": 4.365808823529412e-06,
      "loss": 0.3266,
      "step": 952
    },
    {
      "epoch": 0.21897977941176472,
      "grad_norm": 1.2367613315582275,
      "learning_rate": 4.370404411764706e-06,
      "loss": 0.4488,
      "step": 953
    },
    {
      "epoch": 0.2192095588235294,
      "grad_norm": 1.1875606775283813,
      "learning_rate": 4.3750000000000005e-06,
      "loss": 0.3768,
      "step": 954
    },
    {
      "epoch": 0.21943933823529413,
      "grad_norm": 1.4678632020950317,
      "learning_rate": 4.379595588235295e-06,
      "loss": 0.4513,
      "step": 955
    },
    {
      "epoch": 0.21966911764705882,
      "grad_norm": 0.9710062742233276,
      "learning_rate": 4.384191176470588e-06,
      "loss": 0.3508,
      "step": 956
    },
    {
      "epoch": 0.21989889705882354,
      "grad_norm": 1.1225647926330566,
      "learning_rate": 4.388786764705883e-06,
      "loss": 0.3727,
      "step": 957
    },
    {
      "epoch": 0.22012867647058823,
      "grad_norm": 1.29239022731781,
      "learning_rate": 4.393382352941177e-06,
      "loss": 0.3543,
      "step": 958
    },
    {
      "epoch": 0.22035845588235295,
      "grad_norm": 0.9825146794319153,
      "learning_rate": 4.397977941176471e-06,
      "loss": 0.3841,
      "step": 959
    },
    {
      "epoch": 0.22058823529411764,
      "grad_norm": 0.9997788071632385,
      "learning_rate": 4.402573529411765e-06,
      "loss": 0.3711,
      "step": 960
    },
    {
      "epoch": 0.22081801470588236,
      "grad_norm": 1.083069086074829,
      "learning_rate": 4.407169117647059e-06,
      "loss": 0.3544,
      "step": 961
    },
    {
      "epoch": 0.22104779411764705,
      "grad_norm": 1.2364418506622314,
      "learning_rate": 4.411764705882353e-06,
      "loss": 0.3643,
      "step": 962
    },
    {
      "epoch": 0.22127757352941177,
      "grad_norm": 1.1783043146133423,
      "learning_rate": 4.416360294117648e-06,
      "loss": 0.3676,
      "step": 963
    },
    {
      "epoch": 0.22150735294117646,
      "grad_norm": 1.2729706764221191,
      "learning_rate": 4.420955882352941e-06,
      "loss": 0.3282,
      "step": 964
    },
    {
      "epoch": 0.22173713235294118,
      "grad_norm": 1.015907645225525,
      "learning_rate": 4.4255514705882355e-06,
      "loss": 0.3865,
      "step": 965
    },
    {
      "epoch": 0.22196691176470587,
      "grad_norm": 1.0177377462387085,
      "learning_rate": 4.43014705882353e-06,
      "loss": 0.3684,
      "step": 966
    },
    {
      "epoch": 0.2221966911764706,
      "grad_norm": 1.2418360710144043,
      "learning_rate": 4.434742647058824e-06,
      "loss": 0.3798,
      "step": 967
    },
    {
      "epoch": 0.22242647058823528,
      "grad_norm": 1.0094910860061646,
      "learning_rate": 4.439338235294118e-06,
      "loss": 0.3985,
      "step": 968
    },
    {
      "epoch": 0.22265625,
      "grad_norm": 1.045589566230774,
      "learning_rate": 4.443933823529412e-06,
      "loss": 0.3856,
      "step": 969
    },
    {
      "epoch": 0.22288602941176472,
      "grad_norm": 1.083041787147522,
      "learning_rate": 4.448529411764706e-06,
      "loss": 0.3913,
      "step": 970
    },
    {
      "epoch": 0.2231158088235294,
      "grad_norm": 1.019710659980774,
      "learning_rate": 4.453125000000001e-06,
      "loss": 0.3373,
      "step": 971
    },
    {
      "epoch": 0.22334558823529413,
      "grad_norm": 1.0931669473648071,
      "learning_rate": 4.457720588235295e-06,
      "loss": 0.2988,
      "step": 972
    },
    {
      "epoch": 0.22357536764705882,
      "grad_norm": 1.0084102153778076,
      "learning_rate": 4.4623161764705885e-06,
      "loss": 0.3802,
      "step": 973
    },
    {
      "epoch": 0.22380514705882354,
      "grad_norm": 0.9370905756950378,
      "learning_rate": 4.466911764705883e-06,
      "loss": 0.3606,
      "step": 974
    },
    {
      "epoch": 0.22403492647058823,
      "grad_norm": 0.8828199505805969,
      "learning_rate": 4.471507352941177e-06,
      "loss": 0.3362,
      "step": 975
    },
    {
      "epoch": 0.22426470588235295,
      "grad_norm": 0.9465774893760681,
      "learning_rate": 4.4761029411764715e-06,
      "loss": 0.3111,
      "step": 976
    },
    {
      "epoch": 0.22449448529411764,
      "grad_norm": 1.2378957271575928,
      "learning_rate": 4.480698529411765e-06,
      "loss": 0.4172,
      "step": 977
    },
    {
      "epoch": 0.22472426470588236,
      "grad_norm": 0.9648596048355103,
      "learning_rate": 4.485294117647059e-06,
      "loss": 0.2956,
      "step": 978
    },
    {
      "epoch": 0.22495404411764705,
      "grad_norm": 1.174797773361206,
      "learning_rate": 4.489889705882353e-06,
      "loss": 0.3004,
      "step": 979
    },
    {
      "epoch": 0.22518382352941177,
      "grad_norm": 1.0379823446273804,
      "learning_rate": 4.494485294117648e-06,
      "loss": 0.2912,
      "step": 980
    },
    {
      "epoch": 0.22541360294117646,
      "grad_norm": 1.1325339078903198,
      "learning_rate": 4.499080882352941e-06,
      "loss": 0.3565,
      "step": 981
    },
    {
      "epoch": 0.22564338235294118,
      "grad_norm": 1.271653413772583,
      "learning_rate": 4.503676470588236e-06,
      "loss": 0.437,
      "step": 982
    },
    {
      "epoch": 0.22587316176470587,
      "grad_norm": 1.0690218210220337,
      "learning_rate": 4.508272058823529e-06,
      "loss": 0.2837,
      "step": 983
    },
    {
      "epoch": 0.2261029411764706,
      "grad_norm": 1.2416203022003174,
      "learning_rate": 4.5128676470588236e-06,
      "loss": 0.3149,
      "step": 984
    },
    {
      "epoch": 0.22633272058823528,
      "grad_norm": 1.0891169309616089,
      "learning_rate": 4.517463235294118e-06,
      "loss": 0.3292,
      "step": 985
    },
    {
      "epoch": 0.2265625,
      "grad_norm": 0.9271758794784546,
      "learning_rate": 4.522058823529412e-06,
      "loss": 0.3406,
      "step": 986
    },
    {
      "epoch": 0.22679227941176472,
      "grad_norm": 0.9485753178596497,
      "learning_rate": 4.526654411764706e-06,
      "loss": 0.3117,
      "step": 987
    },
    {
      "epoch": 0.2270220588235294,
      "grad_norm": 1.2437949180603027,
      "learning_rate": 4.53125e-06,
      "loss": 0.3875,
      "step": 988
    },
    {
      "epoch": 0.22725183823529413,
      "grad_norm": 1.0076292753219604,
      "learning_rate": 4.535845588235294e-06,
      "loss": 0.3178,
      "step": 989
    },
    {
      "epoch": 0.22748161764705882,
      "grad_norm": 1.0466128587722778,
      "learning_rate": 4.540441176470589e-06,
      "loss": 0.3059,
      "step": 990
    },
    {
      "epoch": 0.22771139705882354,
      "grad_norm": 0.9912638664245605,
      "learning_rate": 4.545036764705883e-06,
      "loss": 0.2996,
      "step": 991
    },
    {
      "epoch": 0.22794117647058823,
      "grad_norm": 0.9885923862457275,
      "learning_rate": 4.5496323529411765e-06,
      "loss": 0.3228,
      "step": 992
    },
    {
      "epoch": 0.22817095588235295,
      "grad_norm": 1.2668976783752441,
      "learning_rate": 4.554227941176471e-06,
      "loss": 0.3666,
      "step": 993
    },
    {
      "epoch": 0.22840073529411764,
      "grad_norm": 1.2870254516601562,
      "learning_rate": 4.558823529411765e-06,
      "loss": 0.3218,
      "step": 994
    },
    {
      "epoch": 0.22863051470588236,
      "grad_norm": 1.018431544303894,
      "learning_rate": 4.5634191176470595e-06,
      "loss": 0.3539,
      "step": 995
    },
    {
      "epoch": 0.22886029411764705,
      "grad_norm": 1.0816254615783691,
      "learning_rate": 4.568014705882353e-06,
      "loss": 0.3346,
      "step": 996
    },
    {
      "epoch": 0.22909007352941177,
      "grad_norm": 1.0747931003570557,
      "learning_rate": 4.572610294117647e-06,
      "loss": 0.2863,
      "step": 997
    },
    {
      "epoch": 0.22931985294117646,
      "grad_norm": 1.0810381174087524,
      "learning_rate": 4.577205882352942e-06,
      "loss": 0.3432,
      "step": 998
    },
    {
      "epoch": 0.22954963235294118,
      "grad_norm": 1.255303144454956,
      "learning_rate": 4.581801470588236e-06,
      "loss": 0.3354,
      "step": 999
    },
    {
      "epoch": 0.22977941176470587,
      "grad_norm": 0.8944181799888611,
      "learning_rate": 4.5863970588235294e-06,
      "loss": 0.2755,
      "step": 1000
    },
    {
      "epoch": 0.22977941176470587,
      "eval_loss": 0.3311558961868286,
      "eval_runtime": 2007.2548,
      "eval_samples_per_second": 4.437,
      "eval_steps_per_second": 2.218,
      "step": 1000
    },
    {
      "epoch": 0.2300091911764706,
      "grad_norm": 1.099928617477417,
      "learning_rate": 4.590992647058824e-06,
      "loss": 0.3458,
      "step": 1001
    },
    {
      "epoch": 0.23023897058823528,
      "grad_norm": 0.9947894215583801,
      "learning_rate": 4.595588235294118e-06,
      "loss": 0.355,
      "step": 1002
    },
    {
      "epoch": 0.23046875,
      "grad_norm": 1.266532063484192,
      "learning_rate": 4.600183823529412e-06,
      "loss": 0.3185,
      "step": 1003
    },
    {
      "epoch": 0.23069852941176472,
      "grad_norm": 0.9970049858093262,
      "learning_rate": 4.604779411764706e-06,
      "loss": 0.3243,
      "step": 1004
    },
    {
      "epoch": 0.2309283088235294,
      "grad_norm": 1.345206379890442,
      "learning_rate": 4.609375e-06,
      "loss": 0.3556,
      "step": 1005
    },
    {
      "epoch": 0.23115808823529413,
      "grad_norm": 1.064062237739563,
      "learning_rate": 4.6139705882352946e-06,
      "loss": 0.3255,
      "step": 1006
    },
    {
      "epoch": 0.23138786764705882,
      "grad_norm": 1.188537359237671,
      "learning_rate": 4.618566176470589e-06,
      "loss": 0.3069,
      "step": 1007
    },
    {
      "epoch": 0.23161764705882354,
      "grad_norm": 1.0429896116256714,
      "learning_rate": 4.623161764705883e-06,
      "loss": 0.3411,
      "step": 1008
    },
    {
      "epoch": 0.23184742647058823,
      "grad_norm": 0.9993480443954468,
      "learning_rate": 4.627757352941177e-06,
      "loss": 0.3072,
      "step": 1009
    },
    {
      "epoch": 0.23207720588235295,
      "grad_norm": 1.0780409574508667,
      "learning_rate": 4.632352941176471e-06,
      "loss": 0.3062,
      "step": 1010
    },
    {
      "epoch": 0.23230698529411764,
      "grad_norm": 0.9762949347496033,
      "learning_rate": 4.636948529411765e-06,
      "loss": 0.3566,
      "step": 1011
    },
    {
      "epoch": 0.23253676470588236,
      "grad_norm": 1.3038676977157593,
      "learning_rate": 4.64154411764706e-06,
      "loss": 0.4079,
      "step": 1012
    },
    {
      "epoch": 0.23276654411764705,
      "grad_norm": 1.0341922044754028,
      "learning_rate": 4.646139705882353e-06,
      "loss": 0.2913,
      "step": 1013
    },
    {
      "epoch": 0.23299632352941177,
      "grad_norm": 1.0465941429138184,
      "learning_rate": 4.6507352941176475e-06,
      "loss": 0.2781,
      "step": 1014
    },
    {
      "epoch": 0.23322610294117646,
      "grad_norm": 1.4412399530410767,
      "learning_rate": 4.655330882352941e-06,
      "loss": 0.313,
      "step": 1015
    },
    {
      "epoch": 0.23345588235294118,
      "grad_norm": 1.3235664367675781,
      "learning_rate": 4.659926470588236e-06,
      "loss": 0.3964,
      "step": 1016
    },
    {
      "epoch": 0.23368566176470587,
      "grad_norm": 1.2152212858200073,
      "learning_rate": 4.66452205882353e-06,
      "loss": 0.3833,
      "step": 1017
    },
    {
      "epoch": 0.2339154411764706,
      "grad_norm": 1.0877962112426758,
      "learning_rate": 4.669117647058824e-06,
      "loss": 0.2916,
      "step": 1018
    },
    {
      "epoch": 0.23414522058823528,
      "grad_norm": 0.9622652530670166,
      "learning_rate": 4.6737132352941174e-06,
      "loss": 0.3298,
      "step": 1019
    },
    {
      "epoch": 0.234375,
      "grad_norm": 1.2475247383117676,
      "learning_rate": 4.678308823529412e-06,
      "loss": 0.3226,
      "step": 1020
    },
    {
      "epoch": 0.23460477941176472,
      "grad_norm": 0.8492234349250793,
      "learning_rate": 4.682904411764706e-06,
      "loss": 0.352,
      "step": 1021
    },
    {
      "epoch": 0.2348345588235294,
      "grad_norm": 1.0331001281738281,
      "learning_rate": 4.6875000000000004e-06,
      "loss": 0.37,
      "step": 1022
    },
    {
      "epoch": 0.23506433823529413,
      "grad_norm": 1.1209501028060913,
      "learning_rate": 4.692095588235295e-06,
      "loss": 0.3494,
      "step": 1023
    },
    {
      "epoch": 0.23529411764705882,
      "grad_norm": 0.8923375606536865,
      "learning_rate": 4.696691176470588e-06,
      "loss": 0.2975,
      "step": 1024
    },
    {
      "epoch": 0.23552389705882354,
      "grad_norm": 1.0613783597946167,
      "learning_rate": 4.7012867647058826e-06,
      "loss": 0.3,
      "step": 1025
    },
    {
      "epoch": 0.23575367647058823,
      "grad_norm": 1.0644606351852417,
      "learning_rate": 4.705882352941177e-06,
      "loss": 0.3113,
      "step": 1026
    },
    {
      "epoch": 0.23598345588235295,
      "grad_norm": 1.0419963598251343,
      "learning_rate": 4.710477941176471e-06,
      "loss": 0.2932,
      "step": 1027
    },
    {
      "epoch": 0.23621323529411764,
      "grad_norm": 1.1888751983642578,
      "learning_rate": 4.715073529411765e-06,
      "loss": 0.3123,
      "step": 1028
    },
    {
      "epoch": 0.23644301470588236,
      "grad_norm": 0.911156952381134,
      "learning_rate": 4.719669117647059e-06,
      "loss": 0.3351,
      "step": 1029
    },
    {
      "epoch": 0.23667279411764705,
      "grad_norm": 1.2034229040145874,
      "learning_rate": 4.724264705882353e-06,
      "loss": 0.2498,
      "step": 1030
    },
    {
      "epoch": 0.23690257352941177,
      "grad_norm": 1.0819369554519653,
      "learning_rate": 4.728860294117648e-06,
      "loss": 0.417,
      "step": 1031
    },
    {
      "epoch": 0.23713235294117646,
      "grad_norm": 1.0058951377868652,
      "learning_rate": 4.733455882352941e-06,
      "loss": 0.3457,
      "step": 1032
    },
    {
      "epoch": 0.23736213235294118,
      "grad_norm": 0.9943448305130005,
      "learning_rate": 4.7380514705882355e-06,
      "loss": 0.3236,
      "step": 1033
    },
    {
      "epoch": 0.23759191176470587,
      "grad_norm": 1.0776604413986206,
      "learning_rate": 4.74264705882353e-06,
      "loss": 0.4021,
      "step": 1034
    },
    {
      "epoch": 0.2378216911764706,
      "grad_norm": 1.086924433708191,
      "learning_rate": 4.747242647058824e-06,
      "loss": 0.3009,
      "step": 1035
    },
    {
      "epoch": 0.23805147058823528,
      "grad_norm": 1.007982611656189,
      "learning_rate": 4.751838235294118e-06,
      "loss": 0.2851,
      "step": 1036
    },
    {
      "epoch": 0.23828125,
      "grad_norm": 1.0745121240615845,
      "learning_rate": 4.756433823529412e-06,
      "loss": 0.31,
      "step": 1037
    },
    {
      "epoch": 0.23851102941176472,
      "grad_norm": 1.049167513847351,
      "learning_rate": 4.761029411764706e-06,
      "loss": 0.28,
      "step": 1038
    },
    {
      "epoch": 0.2387408088235294,
      "grad_norm": 0.9779611229896545,
      "learning_rate": 4.765625000000001e-06,
      "loss": 0.3057,
      "step": 1039
    },
    {
      "epoch": 0.23897058823529413,
      "grad_norm": 0.9710384011268616,
      "learning_rate": 4.770220588235295e-06,
      "loss": 0.3207,
      "step": 1040
    },
    {
      "epoch": 0.23920036764705882,
      "grad_norm": 0.8902207016944885,
      "learning_rate": 4.7748161764705885e-06,
      "loss": 0.2984,
      "step": 1041
    },
    {
      "epoch": 0.23943014705882354,
      "grad_norm": 1.1825881004333496,
      "learning_rate": 4.779411764705883e-06,
      "loss": 0.326,
      "step": 1042
    },
    {
      "epoch": 0.23965992647058823,
      "grad_norm": 0.9596081376075745,
      "learning_rate": 4.784007352941177e-06,
      "loss": 0.2717,
      "step": 1043
    },
    {
      "epoch": 0.23988970588235295,
      "grad_norm": 0.7917286157608032,
      "learning_rate": 4.7886029411764714e-06,
      "loss": 0.2509,
      "step": 1044
    },
    {
      "epoch": 0.24011948529411764,
      "grad_norm": 1.3293330669403076,
      "learning_rate": 4.793198529411765e-06,
      "loss": 0.3029,
      "step": 1045
    },
    {
      "epoch": 0.24034926470588236,
      "grad_norm": 1.1149356365203857,
      "learning_rate": 4.797794117647059e-06,
      "loss": 0.322,
      "step": 1046
    },
    {
      "epoch": 0.24057904411764705,
      "grad_norm": 1.0784043073654175,
      "learning_rate": 4.802389705882354e-06,
      "loss": 0.3127,
      "step": 1047
    },
    {
      "epoch": 0.24080882352941177,
      "grad_norm": 0.8390645980834961,
      "learning_rate": 4.806985294117648e-06,
      "loss": 0.2751,
      "step": 1048
    },
    {
      "epoch": 0.24103860294117646,
      "grad_norm": 1.1420189142227173,
      "learning_rate": 4.811580882352941e-06,
      "loss": 0.3118,
      "step": 1049
    },
    {
      "epoch": 0.24126838235294118,
      "grad_norm": 0.9728800058364868,
      "learning_rate": 4.816176470588236e-06,
      "loss": 0.3033,
      "step": 1050
    },
    {
      "epoch": 0.24149816176470587,
      "grad_norm": 1.1488523483276367,
      "learning_rate": 4.820772058823529e-06,
      "loss": 0.3001,
      "step": 1051
    },
    {
      "epoch": 0.2417279411764706,
      "grad_norm": 1.2609158754348755,
      "learning_rate": 4.825367647058824e-06,
      "loss": 0.3109,
      "step": 1052
    },
    {
      "epoch": 0.24195772058823528,
      "grad_norm": 0.991899847984314,
      "learning_rate": 4.829963235294118e-06,
      "loss": 0.3043,
      "step": 1053
    },
    {
      "epoch": 0.2421875,
      "grad_norm": 1.0282269716262817,
      "learning_rate": 4.834558823529412e-06,
      "loss": 0.3117,
      "step": 1054
    },
    {
      "epoch": 0.24241727941176472,
      "grad_norm": 0.8630538582801819,
      "learning_rate": 4.839154411764706e-06,
      "loss": 0.3131,
      "step": 1055
    },
    {
      "epoch": 0.2426470588235294,
      "grad_norm": 0.9691726565361023,
      "learning_rate": 4.84375e-06,
      "loss": 0.3015,
      "step": 1056
    },
    {
      "epoch": 0.24287683823529413,
      "grad_norm": 0.9758180379867554,
      "learning_rate": 4.848345588235295e-06,
      "loss": 0.2846,
      "step": 1057
    },
    {
      "epoch": 0.24310661764705882,
      "grad_norm": 1.325891375541687,
      "learning_rate": 4.852941176470589e-06,
      "loss": 0.3027,
      "step": 1058
    },
    {
      "epoch": 0.24333639705882354,
      "grad_norm": 0.9809940457344055,
      "learning_rate": 4.857536764705883e-06,
      "loss": 0.3,
      "step": 1059
    },
    {
      "epoch": 0.24356617647058823,
      "grad_norm": 1.1501843929290771,
      "learning_rate": 4.8621323529411765e-06,
      "loss": 0.327,
      "step": 1060
    },
    {
      "epoch": 0.24379595588235295,
      "grad_norm": 1.0682175159454346,
      "learning_rate": 4.866727941176471e-06,
      "loss": 0.2885,
      "step": 1061
    },
    {
      "epoch": 0.24402573529411764,
      "grad_norm": 1.0279735326766968,
      "learning_rate": 4.871323529411765e-06,
      "loss": 0.2498,
      "step": 1062
    },
    {
      "epoch": 0.24425551470588236,
      "grad_norm": 1.4109549522399902,
      "learning_rate": 4.8759191176470595e-06,
      "loss": 0.3913,
      "step": 1063
    },
    {
      "epoch": 0.24448529411764705,
      "grad_norm": 1.206673502922058,
      "learning_rate": 4.880514705882353e-06,
      "loss": 0.3531,
      "step": 1064
    },
    {
      "epoch": 0.24471507352941177,
      "grad_norm": 1.4740763902664185,
      "learning_rate": 4.885110294117647e-06,
      "loss": 0.3014,
      "step": 1065
    },
    {
      "epoch": 0.24494485294117646,
      "grad_norm": 1.1378909349441528,
      "learning_rate": 4.889705882352942e-06,
      "loss": 0.2775,
      "step": 1066
    },
    {
      "epoch": 0.24517463235294118,
      "grad_norm": 1.000591516494751,
      "learning_rate": 4.894301470588236e-06,
      "loss": 0.2809,
      "step": 1067
    },
    {
      "epoch": 0.24540441176470587,
      "grad_norm": 1.118860125541687,
      "learning_rate": 4.898897058823529e-06,
      "loss": 0.3185,
      "step": 1068
    },
    {
      "epoch": 0.2456341911764706,
      "grad_norm": 1.3525819778442383,
      "learning_rate": 4.903492647058824e-06,
      "loss": 0.2986,
      "step": 1069
    },
    {
      "epoch": 0.24586397058823528,
      "grad_norm": 1.094702959060669,
      "learning_rate": 4.908088235294118e-06,
      "loss": 0.3086,
      "step": 1070
    },
    {
      "epoch": 0.24609375,
      "grad_norm": 1.138020634651184,
      "learning_rate": 4.912683823529412e-06,
      "loss": 0.3151,
      "step": 1071
    },
    {
      "epoch": 0.24632352941176472,
      "grad_norm": 1.1029105186462402,
      "learning_rate": 4.917279411764706e-06,
      "loss": 0.3002,
      "step": 1072
    },
    {
      "epoch": 0.2465533088235294,
      "grad_norm": 1.250758171081543,
      "learning_rate": 4.921875e-06,
      "loss": 0.3168,
      "step": 1073
    },
    {
      "epoch": 0.24678308823529413,
      "grad_norm": 1.132867693901062,
      "learning_rate": 4.9264705882352945e-06,
      "loss": 0.3483,
      "step": 1074
    },
    {
      "epoch": 0.24701286764705882,
      "grad_norm": 1.309419870376587,
      "learning_rate": 4.931066176470589e-06,
      "loss": 0.2871,
      "step": 1075
    },
    {
      "epoch": 0.24724264705882354,
      "grad_norm": 1.0578980445861816,
      "learning_rate": 4.935661764705883e-06,
      "loss": 0.3085,
      "step": 1076
    },
    {
      "epoch": 0.24747242647058823,
      "grad_norm": 1.2203593254089355,
      "learning_rate": 4.940257352941177e-06,
      "loss": 0.3166,
      "step": 1077
    },
    {
      "epoch": 0.24770220588235295,
      "grad_norm": 1.4860926866531372,
      "learning_rate": 4.944852941176471e-06,
      "loss": 0.27,
      "step": 1078
    },
    {
      "epoch": 0.24793198529411764,
      "grad_norm": 0.8418651223182678,
      "learning_rate": 4.949448529411765e-06,
      "loss": 0.3043,
      "step": 1079
    },
    {
      "epoch": 0.24816176470588236,
      "grad_norm": 0.9513278007507324,
      "learning_rate": 4.95404411764706e-06,
      "loss": 0.306,
      "step": 1080
    },
    {
      "epoch": 0.24839154411764705,
      "grad_norm": 1.316440224647522,
      "learning_rate": 4.958639705882353e-06,
      "loss": 0.3646,
      "step": 1081
    },
    {
      "epoch": 0.24862132352941177,
      "grad_norm": 1.5953574180603027,
      "learning_rate": 4.9632352941176475e-06,
      "loss": 0.2921,
      "step": 1082
    },
    {
      "epoch": 0.24885110294117646,
      "grad_norm": 1.1079241037368774,
      "learning_rate": 4.967830882352942e-06,
      "loss": 0.2417,
      "step": 1083
    },
    {
      "epoch": 0.24908088235294118,
      "grad_norm": 1.1190688610076904,
      "learning_rate": 4.972426470588236e-06,
      "loss": 0.2657,
      "step": 1084
    },
    {
      "epoch": 0.24931066176470587,
      "grad_norm": 0.929428219795227,
      "learning_rate": 4.97702205882353e-06,
      "loss": 0.2952,
      "step": 1085
    },
    {
      "epoch": 0.2495404411764706,
      "grad_norm": 1.474273920059204,
      "learning_rate": 4.981617647058824e-06,
      "loss": 0.2533,
      "step": 1086
    },
    {
      "epoch": 0.24977022058823528,
      "grad_norm": 1.424072265625,
      "learning_rate": 4.986213235294117e-06,
      "loss": 0.3392,
      "step": 1087
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.3300150632858276,
      "learning_rate": 4.990808823529413e-06,
      "loss": 0.3216,
      "step": 1088
    },
    {
      "epoch": 0.2502297794117647,
      "grad_norm": 0.9241880774497986,
      "learning_rate": 4.995404411764706e-06,
      "loss": 0.2784,
      "step": 1089
    },
    {
      "epoch": 0.25045955882352944,
      "grad_norm": 1.1432065963745117,
      "learning_rate": 5e-06,
      "loss": 0.3059,
      "step": 1090
    },
    {
      "epoch": 0.2506893382352941,
      "grad_norm": 0.9904559850692749,
      "learning_rate": 5.004595588235295e-06,
      "loss": 0.3375,
      "step": 1091
    },
    {
      "epoch": 0.2509191176470588,
      "grad_norm": 1.0999971628189087,
      "learning_rate": 5.009191176470589e-06,
      "loss": 0.2885,
      "step": 1092
    },
    {
      "epoch": 0.25114889705882354,
      "grad_norm": 1.2236188650131226,
      "learning_rate": 5.0137867647058825e-06,
      "loss": 0.3135,
      "step": 1093
    },
    {
      "epoch": 0.25137867647058826,
      "grad_norm": 1.2477021217346191,
      "learning_rate": 5.018382352941177e-06,
      "loss": 0.2516,
      "step": 1094
    },
    {
      "epoch": 0.2516084558823529,
      "grad_norm": 1.427363634109497,
      "learning_rate": 5.022977941176471e-06,
      "loss": 0.2997,
      "step": 1095
    },
    {
      "epoch": 0.25183823529411764,
      "grad_norm": 1.2443325519561768,
      "learning_rate": 5.0275735294117655e-06,
      "loss": 0.3263,
      "step": 1096
    },
    {
      "epoch": 0.25206801470588236,
      "grad_norm": 1.0382429361343384,
      "learning_rate": 5.032169117647059e-06,
      "loss": 0.428,
      "step": 1097
    },
    {
      "epoch": 0.2522977941176471,
      "grad_norm": 1.0809742212295532,
      "learning_rate": 5.036764705882353e-06,
      "loss": 0.2483,
      "step": 1098
    },
    {
      "epoch": 0.25252757352941174,
      "grad_norm": 1.0633465051651,
      "learning_rate": 5.041360294117648e-06,
      "loss": 0.2365,
      "step": 1099
    },
    {
      "epoch": 0.25275735294117646,
      "grad_norm": 1.1317485570907593,
      "learning_rate": 5.045955882352942e-06,
      "loss": 0.2854,
      "step": 1100
    },
    {
      "epoch": 0.2529871323529412,
      "grad_norm": 1.183538556098938,
      "learning_rate": 5.0505514705882355e-06,
      "loss": 0.2881,
      "step": 1101
    },
    {
      "epoch": 0.2532169117647059,
      "grad_norm": 1.48096764087677,
      "learning_rate": 5.05514705882353e-06,
      "loss": 0.3303,
      "step": 1102
    },
    {
      "epoch": 0.25344669117647056,
      "grad_norm": 0.944169819355011,
      "learning_rate": 5.059742647058824e-06,
      "loss": 0.2777,
      "step": 1103
    },
    {
      "epoch": 0.2536764705882353,
      "grad_norm": 0.9985782504081726,
      "learning_rate": 5.0643382352941185e-06,
      "loss": 0.2858,
      "step": 1104
    },
    {
      "epoch": 0.25390625,
      "grad_norm": 1.130361557006836,
      "learning_rate": 5.068933823529412e-06,
      "loss": 0.2977,
      "step": 1105
    },
    {
      "epoch": 0.2541360294117647,
      "grad_norm": 1.1041361093521118,
      "learning_rate": 5.073529411764706e-06,
      "loss": 0.2767,
      "step": 1106
    },
    {
      "epoch": 0.25436580882352944,
      "grad_norm": 1.0873368978500366,
      "learning_rate": 5.078125000000001e-06,
      "loss": 0.272,
      "step": 1107
    },
    {
      "epoch": 0.2545955882352941,
      "grad_norm": 1.2901966571807861,
      "learning_rate": 5.082720588235295e-06,
      "loss": 0.3623,
      "step": 1108
    },
    {
      "epoch": 0.2548253676470588,
      "grad_norm": 1.2540327310562134,
      "learning_rate": 5.087316176470589e-06,
      "loss": 0.301,
      "step": 1109
    },
    {
      "epoch": 0.25505514705882354,
      "grad_norm": 1.24970543384552,
      "learning_rate": 5.091911764705883e-06,
      "loss": 0.2856,
      "step": 1110
    },
    {
      "epoch": 0.25528492647058826,
      "grad_norm": 1.1338101625442505,
      "learning_rate": 5.096507352941177e-06,
      "loss": 0.3286,
      "step": 1111
    },
    {
      "epoch": 0.2555147058823529,
      "grad_norm": 1.0177570581436157,
      "learning_rate": 5.101102941176471e-06,
      "loss": 0.2736,
      "step": 1112
    },
    {
      "epoch": 0.25574448529411764,
      "grad_norm": 0.9871717691421509,
      "learning_rate": 5.105698529411766e-06,
      "loss": 0.2351,
      "step": 1113
    },
    {
      "epoch": 0.25597426470588236,
      "grad_norm": 1.0030754804611206,
      "learning_rate": 5.110294117647059e-06,
      "loss": 0.252,
      "step": 1114
    },
    {
      "epoch": 0.2562040441176471,
      "grad_norm": 1.0108355283737183,
      "learning_rate": 5.1148897058823536e-06,
      "loss": 0.3263,
      "step": 1115
    },
    {
      "epoch": 0.25643382352941174,
      "grad_norm": 0.991584837436676,
      "learning_rate": 5.119485294117648e-06,
      "loss": 0.2391,
      "step": 1116
    },
    {
      "epoch": 0.25666360294117646,
      "grad_norm": 1.0589513778686523,
      "learning_rate": 5.124080882352942e-06,
      "loss": 0.2497,
      "step": 1117
    },
    {
      "epoch": 0.2568933823529412,
      "grad_norm": 1.187231421470642,
      "learning_rate": 5.128676470588235e-06,
      "loss": 0.2996,
      "step": 1118
    },
    {
      "epoch": 0.2571231617647059,
      "grad_norm": 1.2489264011383057,
      "learning_rate": 5.13327205882353e-06,
      "loss": 0.3186,
      "step": 1119
    },
    {
      "epoch": 0.25735294117647056,
      "grad_norm": 1.3006492853164673,
      "learning_rate": 5.137867647058824e-06,
      "loss": 0.2756,
      "step": 1120
    },
    {
      "epoch": 0.2575827205882353,
      "grad_norm": 1.1531494855880737,
      "learning_rate": 5.142463235294119e-06,
      "loss": 0.2943,
      "step": 1121
    },
    {
      "epoch": 0.2578125,
      "grad_norm": 0.9163739681243896,
      "learning_rate": 5.147058823529411e-06,
      "loss": 0.2598,
      "step": 1122
    },
    {
      "epoch": 0.2580422794117647,
      "grad_norm": 1.1001378297805786,
      "learning_rate": 5.151654411764706e-06,
      "loss": 0.2778,
      "step": 1123
    },
    {
      "epoch": 0.25827205882352944,
      "grad_norm": 1.1000893115997314,
      "learning_rate": 5.156250000000001e-06,
      "loss": 0.2702,
      "step": 1124
    },
    {
      "epoch": 0.2585018382352941,
      "grad_norm": 0.995535671710968,
      "learning_rate": 5.160845588235295e-06,
      "loss": 0.2962,
      "step": 1125
    },
    {
      "epoch": 0.2587316176470588,
      "grad_norm": 1.4071099758148193,
      "learning_rate": 5.1654411764705895e-06,
      "loss": 0.2866,
      "step": 1126
    },
    {
      "epoch": 0.25896139705882354,
      "grad_norm": 1.1752939224243164,
      "learning_rate": 5.170036764705882e-06,
      "loss": 0.2768,
      "step": 1127
    },
    {
      "epoch": 0.25919117647058826,
      "grad_norm": 1.140352487564087,
      "learning_rate": 5.1746323529411764e-06,
      "loss": 0.2974,
      "step": 1128
    },
    {
      "epoch": 0.2594209558823529,
      "grad_norm": 0.8618686199188232,
      "learning_rate": 5.179227941176472e-06,
      "loss": 0.2551,
      "step": 1129
    },
    {
      "epoch": 0.25965073529411764,
      "grad_norm": 1.1712956428527832,
      "learning_rate": 5.183823529411766e-06,
      "loss": 0.2999,
      "step": 1130
    },
    {
      "epoch": 0.25988051470588236,
      "grad_norm": 0.8923957943916321,
      "learning_rate": 5.188419117647059e-06,
      "loss": 0.2143,
      "step": 1131
    },
    {
      "epoch": 0.2601102941176471,
      "grad_norm": 1.148476481437683,
      "learning_rate": 5.193014705882353e-06,
      "loss": 0.3259,
      "step": 1132
    },
    {
      "epoch": 0.26034007352941174,
      "grad_norm": 1.26544988155365,
      "learning_rate": 5.197610294117647e-06,
      "loss": 0.2638,
      "step": 1133
    },
    {
      "epoch": 0.26056985294117646,
      "grad_norm": 1.2020697593688965,
      "learning_rate": 5.202205882352942e-06,
      "loss": 0.2753,
      "step": 1134
    },
    {
      "epoch": 0.2607996323529412,
      "grad_norm": 1.2961770296096802,
      "learning_rate": 5.206801470588235e-06,
      "loss": 0.2756,
      "step": 1135
    },
    {
      "epoch": 0.2610294117647059,
      "grad_norm": 0.9732182621955872,
      "learning_rate": 5.211397058823529e-06,
      "loss": 0.2688,
      "step": 1136
    },
    {
      "epoch": 0.26125919117647056,
      "grad_norm": 1.6167510747909546,
      "learning_rate": 5.215992647058824e-06,
      "loss": 0.3068,
      "step": 1137
    },
    {
      "epoch": 0.2614889705882353,
      "grad_norm": 1.0102360248565674,
      "learning_rate": 5.220588235294118e-06,
      "loss": 0.2612,
      "step": 1138
    },
    {
      "epoch": 0.26171875,
      "grad_norm": 1.0699936151504517,
      "learning_rate": 5.2251838235294115e-06,
      "loss": 0.3165,
      "step": 1139
    },
    {
      "epoch": 0.2619485294117647,
      "grad_norm": 0.9652478098869324,
      "learning_rate": 5.229779411764706e-06,
      "loss": 0.2834,
      "step": 1140
    },
    {
      "epoch": 0.26217830882352944,
      "grad_norm": 1.063802719116211,
      "learning_rate": 5.234375e-06,
      "loss": 0.2497,
      "step": 1141
    },
    {
      "epoch": 0.2624080882352941,
      "grad_norm": 1.0485895872116089,
      "learning_rate": 5.2389705882352945e-06,
      "loss": 0.2698,
      "step": 1142
    },
    {
      "epoch": 0.2626378676470588,
      "grad_norm": 1.0596458911895752,
      "learning_rate": 5.243566176470589e-06,
      "loss": 0.2203,
      "step": 1143
    },
    {
      "epoch": 0.26286764705882354,
      "grad_norm": 1.0507625341415405,
      "learning_rate": 5.248161764705882e-06,
      "loss": 0.2423,
      "step": 1144
    },
    {
      "epoch": 0.26309742647058826,
      "grad_norm": 0.9703408479690552,
      "learning_rate": 5.252757352941177e-06,
      "loss": 0.3147,
      "step": 1145
    },
    {
      "epoch": 0.2633272058823529,
      "grad_norm": 1.0698509216308594,
      "learning_rate": 5.257352941176471e-06,
      "loss": 0.2672,
      "step": 1146
    },
    {
      "epoch": 0.26355698529411764,
      "grad_norm": 1.1559786796569824,
      "learning_rate": 5.261948529411765e-06,
      "loss": 0.2417,
      "step": 1147
    },
    {
      "epoch": 0.26378676470588236,
      "grad_norm": 1.8779422044754028,
      "learning_rate": 5.266544117647059e-06,
      "loss": 0.3027,
      "step": 1148
    },
    {
      "epoch": 0.2640165441176471,
      "grad_norm": 0.918596625328064,
      "learning_rate": 5.271139705882353e-06,
      "loss": 0.2717,
      "step": 1149
    },
    {
      "epoch": 0.26424632352941174,
      "grad_norm": 1.138284683227539,
      "learning_rate": 5.2757352941176474e-06,
      "loss": 0.2789,
      "step": 1150
    },
    {
      "epoch": 0.26447610294117646,
      "grad_norm": 1.214733362197876,
      "learning_rate": 5.280330882352942e-06,
      "loss": 0.2763,
      "step": 1151
    },
    {
      "epoch": 0.2647058823529412,
      "grad_norm": 1.0866923332214355,
      "learning_rate": 5.284926470588235e-06,
      "loss": 0.2655,
      "step": 1152
    },
    {
      "epoch": 0.2649356617647059,
      "grad_norm": 1.1801456212997437,
      "learning_rate": 5.28952205882353e-06,
      "loss": 0.2082,
      "step": 1153
    },
    {
      "epoch": 0.26516544117647056,
      "grad_norm": 1.0462419986724854,
      "learning_rate": 5.294117647058824e-06,
      "loss": 0.2745,
      "step": 1154
    },
    {
      "epoch": 0.2653952205882353,
      "grad_norm": 0.981044590473175,
      "learning_rate": 5.298713235294118e-06,
      "loss": 0.2762,
      "step": 1155
    },
    {
      "epoch": 0.265625,
      "grad_norm": 0.9196180701255798,
      "learning_rate": 5.303308823529412e-06,
      "loss": 0.2121,
      "step": 1156
    },
    {
      "epoch": 0.2658547794117647,
      "grad_norm": 1.0792369842529297,
      "learning_rate": 5.307904411764706e-06,
      "loss": 0.2828,
      "step": 1157
    },
    {
      "epoch": 0.26608455882352944,
      "grad_norm": 0.9822713732719421,
      "learning_rate": 5.3125e-06,
      "loss": 0.2564,
      "step": 1158
    },
    {
      "epoch": 0.2663143382352941,
      "grad_norm": 1.0523635149002075,
      "learning_rate": 5.317095588235295e-06,
      "loss": 0.2388,
      "step": 1159
    },
    {
      "epoch": 0.2665441176470588,
      "grad_norm": 1.2217538356781006,
      "learning_rate": 5.321691176470589e-06,
      "loss": 0.3203,
      "step": 1160
    },
    {
      "epoch": 0.26677389705882354,
      "grad_norm": 1.1413512229919434,
      "learning_rate": 5.3262867647058825e-06,
      "loss": 0.2422,
      "step": 1161
    },
    {
      "epoch": 0.26700367647058826,
      "grad_norm": 1.3436928987503052,
      "learning_rate": 5.330882352941177e-06,
      "loss": 0.2744,
      "step": 1162
    },
    {
      "epoch": 0.2672334558823529,
      "grad_norm": 1.260878086090088,
      "learning_rate": 5.335477941176471e-06,
      "loss": 0.2704,
      "step": 1163
    },
    {
      "epoch": 0.26746323529411764,
      "grad_norm": 1.1216695308685303,
      "learning_rate": 5.3400735294117655e-06,
      "loss": 0.2853,
      "step": 1164
    },
    {
      "epoch": 0.26769301470588236,
      "grad_norm": 1.0532883405685425,
      "learning_rate": 5.344669117647059e-06,
      "loss": 0.2835,
      "step": 1165
    },
    {
      "epoch": 0.2679227941176471,
      "grad_norm": 0.799543559551239,
      "learning_rate": 5.349264705882353e-06,
      "loss": 0.226,
      "step": 1166
    },
    {
      "epoch": 0.26815257352941174,
      "grad_norm": 1.0902398824691772,
      "learning_rate": 5.353860294117648e-06,
      "loss": 0.2484,
      "step": 1167
    },
    {
      "epoch": 0.26838235294117646,
      "grad_norm": 0.9691433906555176,
      "learning_rate": 5.358455882352942e-06,
      "loss": 0.2367,
      "step": 1168
    },
    {
      "epoch": 0.2686121323529412,
      "grad_norm": 1.2889971733093262,
      "learning_rate": 5.3630514705882355e-06,
      "loss": 0.3293,
      "step": 1169
    },
    {
      "epoch": 0.2688419117647059,
      "grad_norm": 1.1500648260116577,
      "learning_rate": 5.36764705882353e-06,
      "loss": 0.2449,
      "step": 1170
    },
    {
      "epoch": 0.26907169117647056,
      "grad_norm": 1.0323460102081299,
      "learning_rate": 5.372242647058824e-06,
      "loss": 0.2144,
      "step": 1171
    },
    {
      "epoch": 0.2693014705882353,
      "grad_norm": 1.282630443572998,
      "learning_rate": 5.3768382352941184e-06,
      "loss": 0.3373,
      "step": 1172
    },
    {
      "epoch": 0.26953125,
      "grad_norm": 1.0104467868804932,
      "learning_rate": 5.381433823529412e-06,
      "loss": 0.2758,
      "step": 1173
    },
    {
      "epoch": 0.2697610294117647,
      "grad_norm": 1.033834457397461,
      "learning_rate": 5.386029411764706e-06,
      "loss": 0.2701,
      "step": 1174
    },
    {
      "epoch": 0.26999080882352944,
      "grad_norm": 1.2209908962249756,
      "learning_rate": 5.390625000000001e-06,
      "loss": 0.2737,
      "step": 1175
    },
    {
      "epoch": 0.2702205882352941,
      "grad_norm": 1.2605979442596436,
      "learning_rate": 5.395220588235295e-06,
      "loss": 0.2623,
      "step": 1176
    },
    {
      "epoch": 0.2704503676470588,
      "grad_norm": 0.9589031338691711,
      "learning_rate": 5.399816176470589e-06,
      "loss": 0.298,
      "step": 1177
    },
    {
      "epoch": 0.27068014705882354,
      "grad_norm": 1.2045451402664185,
      "learning_rate": 5.404411764705883e-06,
      "loss": 0.2864,
      "step": 1178
    },
    {
      "epoch": 0.27090992647058826,
      "grad_norm": 1.1584548950195312,
      "learning_rate": 5.409007352941177e-06,
      "loss": 0.2668,
      "step": 1179
    },
    {
      "epoch": 0.2711397058823529,
      "grad_norm": 1.4286423921585083,
      "learning_rate": 5.413602941176471e-06,
      "loss": 0.2886,
      "step": 1180
    },
    {
      "epoch": 0.27136948529411764,
      "grad_norm": 1.1206544637680054,
      "learning_rate": 5.418198529411766e-06,
      "loss": 0.263,
      "step": 1181
    },
    {
      "epoch": 0.27159926470588236,
      "grad_norm": 1.1534429788589478,
      "learning_rate": 5.422794117647059e-06,
      "loss": 0.276,
      "step": 1182
    },
    {
      "epoch": 0.2718290441176471,
      "grad_norm": 0.9593186378479004,
      "learning_rate": 5.4273897058823535e-06,
      "loss": 0.2695,
      "step": 1183
    },
    {
      "epoch": 0.27205882352941174,
      "grad_norm": 1.0235806703567505,
      "learning_rate": 5.431985294117648e-06,
      "loss": 0.2481,
      "step": 1184
    },
    {
      "epoch": 0.27228860294117646,
      "grad_norm": 1.1518068313598633,
      "learning_rate": 5.436580882352942e-06,
      "loss": 0.2712,
      "step": 1185
    },
    {
      "epoch": 0.2725183823529412,
      "grad_norm": 0.9971255660057068,
      "learning_rate": 5.441176470588236e-06,
      "loss": 0.2522,
      "step": 1186
    },
    {
      "epoch": 0.2727481617647059,
      "grad_norm": 0.9377981424331665,
      "learning_rate": 5.44577205882353e-06,
      "loss": 0.2795,
      "step": 1187
    },
    {
      "epoch": 0.27297794117647056,
      "grad_norm": 1.1490685939788818,
      "learning_rate": 5.450367647058824e-06,
      "loss": 0.2991,
      "step": 1188
    },
    {
      "epoch": 0.2732077205882353,
      "grad_norm": 1.1925045251846313,
      "learning_rate": 5.454963235294119e-06,
      "loss": 0.2723,
      "step": 1189
    },
    {
      "epoch": 0.2734375,
      "grad_norm": 1.1650935411453247,
      "learning_rate": 5.459558823529411e-06,
      "loss": 0.2254,
      "step": 1190
    },
    {
      "epoch": 0.2736672794117647,
      "grad_norm": 1.1000455617904663,
      "learning_rate": 5.4641544117647065e-06,
      "loss": 0.2633,
      "step": 1191
    },
    {
      "epoch": 0.27389705882352944,
      "grad_norm": 1.2281928062438965,
      "learning_rate": 5.468750000000001e-06,
      "loss": 0.2485,
      "step": 1192
    },
    {
      "epoch": 0.2741268382352941,
      "grad_norm": 1.3006433248519897,
      "learning_rate": 5.473345588235295e-06,
      "loss": 0.2166,
      "step": 1193
    },
    {
      "epoch": 0.2743566176470588,
      "grad_norm": 1.0209752321243286,
      "learning_rate": 5.4779411764705894e-06,
      "loss": 0.2957,
      "step": 1194
    },
    {
      "epoch": 0.27458639705882354,
      "grad_norm": 1.0503513813018799,
      "learning_rate": 5.482536764705882e-06,
      "loss": 0.2316,
      "step": 1195
    },
    {
      "epoch": 0.27481617647058826,
      "grad_norm": 0.9764649271965027,
      "learning_rate": 5.487132352941177e-06,
      "loss": 0.3002,
      "step": 1196
    },
    {
      "epoch": 0.2750459558823529,
      "grad_norm": 1.3964722156524658,
      "learning_rate": 5.491727941176472e-06,
      "loss": 0.2378,
      "step": 1197
    },
    {
      "epoch": 0.27527573529411764,
      "grad_norm": 0.8806787729263306,
      "learning_rate": 5.496323529411766e-06,
      "loss": 0.2542,
      "step": 1198
    },
    {
      "epoch": 0.27550551470588236,
      "grad_norm": 0.9913163185119629,
      "learning_rate": 5.5009191176470586e-06,
      "loss": 0.262,
      "step": 1199
    },
    {
      "epoch": 0.2757352941176471,
      "grad_norm": 1.5123779773712158,
      "learning_rate": 5.505514705882353e-06,
      "loss": 0.2644,
      "step": 1200
    },
    {
      "epoch": 0.27596507352941174,
      "grad_norm": 1.0436158180236816,
      "learning_rate": 5.510110294117648e-06,
      "loss": 0.2777,
      "step": 1201
    },
    {
      "epoch": 0.27619485294117646,
      "grad_norm": 1.063691258430481,
      "learning_rate": 5.514705882352942e-06,
      "loss": 0.2804,
      "step": 1202
    },
    {
      "epoch": 0.2764246323529412,
      "grad_norm": 0.9451159238815308,
      "learning_rate": 5.519301470588235e-06,
      "loss": 0.2114,
      "step": 1203
    },
    {
      "epoch": 0.2766544117647059,
      "grad_norm": 1.0593125820159912,
      "learning_rate": 5.523897058823529e-06,
      "loss": 0.1929,
      "step": 1204
    },
    {
      "epoch": 0.27688419117647056,
      "grad_norm": 1.0903286933898926,
      "learning_rate": 5.528492647058824e-06,
      "loss": 0.3069,
      "step": 1205
    },
    {
      "epoch": 0.2771139705882353,
      "grad_norm": 1.2278997898101807,
      "learning_rate": 5.533088235294118e-06,
      "loss": 0.1948,
      "step": 1206
    },
    {
      "epoch": 0.27734375,
      "grad_norm": 0.9536787271499634,
      "learning_rate": 5.5376838235294115e-06,
      "loss": 0.2933,
      "step": 1207
    },
    {
      "epoch": 0.2775735294117647,
      "grad_norm": 1.1000970602035522,
      "learning_rate": 5.542279411764706e-06,
      "loss": 0.2487,
      "step": 1208
    },
    {
      "epoch": 0.27780330882352944,
      "grad_norm": 1.1028226613998413,
      "learning_rate": 5.546875e-06,
      "loss": 0.2683,
      "step": 1209
    },
    {
      "epoch": 0.2780330882352941,
      "grad_norm": 0.9899017214775085,
      "learning_rate": 5.5514705882352945e-06,
      "loss": 0.2257,
      "step": 1210
    },
    {
      "epoch": 0.2782628676470588,
      "grad_norm": 1.2740951776504517,
      "learning_rate": 5.556066176470589e-06,
      "loss": 0.2395,
      "step": 1211
    },
    {
      "epoch": 0.27849264705882354,
      "grad_norm": 0.9356458783149719,
      "learning_rate": 5.560661764705882e-06,
      "loss": 0.2585,
      "step": 1212
    },
    {
      "epoch": 0.27872242647058826,
      "grad_norm": 1.0709298849105835,
      "learning_rate": 5.565257352941177e-06,
      "loss": 0.3092,
      "step": 1213
    },
    {
      "epoch": 0.2789522058823529,
      "grad_norm": 0.9204646348953247,
      "learning_rate": 5.569852941176471e-06,
      "loss": 0.2528,
      "step": 1214
    },
    {
      "epoch": 0.27918198529411764,
      "grad_norm": 1.106074571609497,
      "learning_rate": 5.574448529411765e-06,
      "loss": 0.2444,
      "step": 1215
    },
    {
      "epoch": 0.27941176470588236,
      "grad_norm": 1.1398853063583374,
      "learning_rate": 5.579044117647059e-06,
      "loss": 0.2717,
      "step": 1216
    },
    {
      "epoch": 0.2796415441176471,
      "grad_norm": 1.0852104425430298,
      "learning_rate": 5.583639705882353e-06,
      "loss": 0.1942,
      "step": 1217
    },
    {
      "epoch": 0.27987132352941174,
      "grad_norm": 1.2684987783432007,
      "learning_rate": 5.588235294117647e-06,
      "loss": 0.2047,
      "step": 1218
    },
    {
      "epoch": 0.28010110294117646,
      "grad_norm": 1.0427978038787842,
      "learning_rate": 5.592830882352942e-06,
      "loss": 0.2509,
      "step": 1219
    },
    {
      "epoch": 0.2803308823529412,
      "grad_norm": 1.2372795343399048,
      "learning_rate": 5.597426470588235e-06,
      "loss": 0.2484,
      "step": 1220
    },
    {
      "epoch": 0.2805606617647059,
      "grad_norm": 0.912919819355011,
      "learning_rate": 5.6020220588235296e-06,
      "loss": 0.1697,
      "step": 1221
    },
    {
      "epoch": 0.28079044117647056,
      "grad_norm": 1.2275373935699463,
      "learning_rate": 5.606617647058824e-06,
      "loss": 0.2779,
      "step": 1222
    },
    {
      "epoch": 0.2810202205882353,
      "grad_norm": 1.1854848861694336,
      "learning_rate": 5.611213235294118e-06,
      "loss": 0.2565,
      "step": 1223
    },
    {
      "epoch": 0.28125,
      "grad_norm": 1.0275152921676636,
      "learning_rate": 5.615808823529412e-06,
      "loss": 0.2392,
      "step": 1224
    },
    {
      "epoch": 0.2814797794117647,
      "grad_norm": 1.0417134761810303,
      "learning_rate": 5.620404411764706e-06,
      "loss": 0.2671,
      "step": 1225
    },
    {
      "epoch": 0.28170955882352944,
      "grad_norm": 0.9360134601593018,
      "learning_rate": 5.625e-06,
      "loss": 0.2535,
      "step": 1226
    },
    {
      "epoch": 0.2819393382352941,
      "grad_norm": 0.9052702188491821,
      "learning_rate": 5.629595588235295e-06,
      "loss": 0.2053,
      "step": 1227
    },
    {
      "epoch": 0.2821691176470588,
      "grad_norm": 1.1958589553833008,
      "learning_rate": 5.634191176470589e-06,
      "loss": 0.2553,
      "step": 1228
    },
    {
      "epoch": 0.28239889705882354,
      "grad_norm": 1.0817654132843018,
      "learning_rate": 5.6387867647058825e-06,
      "loss": 0.2809,
      "step": 1229
    },
    {
      "epoch": 0.28262867647058826,
      "grad_norm": 1.2322529554367065,
      "learning_rate": 5.643382352941177e-06,
      "loss": 0.2169,
      "step": 1230
    },
    {
      "epoch": 0.2828584558823529,
      "grad_norm": 1.035901427268982,
      "learning_rate": 5.647977941176471e-06,
      "loss": 0.2574,
      "step": 1231
    },
    {
      "epoch": 0.28308823529411764,
      "grad_norm": 1.1624982357025146,
      "learning_rate": 5.6525735294117655e-06,
      "loss": 0.2024,
      "step": 1232
    },
    {
      "epoch": 0.28331801470588236,
      "grad_norm": 1.0251455307006836,
      "learning_rate": 5.657169117647059e-06,
      "loss": 0.2874,
      "step": 1233
    },
    {
      "epoch": 0.2835477941176471,
      "grad_norm": 1.1543962955474854,
      "learning_rate": 5.661764705882353e-06,
      "loss": 0.214,
      "step": 1234
    },
    {
      "epoch": 0.28377757352941174,
      "grad_norm": 1.0760092735290527,
      "learning_rate": 5.666360294117648e-06,
      "loss": 0.2527,
      "step": 1235
    },
    {
      "epoch": 0.28400735294117646,
      "grad_norm": 1.1834450960159302,
      "learning_rate": 5.670955882352942e-06,
      "loss": 0.2088,
      "step": 1236
    },
    {
      "epoch": 0.2842371323529412,
      "grad_norm": 1.269716501235962,
      "learning_rate": 5.6755514705882354e-06,
      "loss": 0.2512,
      "step": 1237
    },
    {
      "epoch": 0.2844669117647059,
      "grad_norm": 1.297432541847229,
      "learning_rate": 5.68014705882353e-06,
      "loss": 0.2124,
      "step": 1238
    },
    {
      "epoch": 0.28469669117647056,
      "grad_norm": 1.26148521900177,
      "learning_rate": 5.684742647058824e-06,
      "loss": 0.2232,
      "step": 1239
    },
    {
      "epoch": 0.2849264705882353,
      "grad_norm": 0.9463388323783875,
      "learning_rate": 5.689338235294118e-06,
      "loss": 0.211,
      "step": 1240
    },
    {
      "epoch": 0.28515625,
      "grad_norm": 0.933627188205719,
      "learning_rate": 5.693933823529412e-06,
      "loss": 0.1978,
      "step": 1241
    },
    {
      "epoch": 0.2853860294117647,
      "grad_norm": 1.426387906074524,
      "learning_rate": 5.698529411764706e-06,
      "loss": 0.2989,
      "step": 1242
    },
    {
      "epoch": 0.28561580882352944,
      "grad_norm": 1.4372037649154663,
      "learning_rate": 5.7031250000000006e-06,
      "loss": 0.3132,
      "step": 1243
    },
    {
      "epoch": 0.2858455882352941,
      "grad_norm": 1.3481029272079468,
      "learning_rate": 5.707720588235295e-06,
      "loss": 0.2884,
      "step": 1244
    },
    {
      "epoch": 0.2860753676470588,
      "grad_norm": 1.3128255605697632,
      "learning_rate": 5.712316176470589e-06,
      "loss": 0.2868,
      "step": 1245
    },
    {
      "epoch": 0.28630514705882354,
      "grad_norm": 1.240684986114502,
      "learning_rate": 5.716911764705883e-06,
      "loss": 0.2259,
      "step": 1246
    },
    {
      "epoch": 0.28653492647058826,
      "grad_norm": 1.387953281402588,
      "learning_rate": 5.721507352941177e-06,
      "loss": 0.276,
      "step": 1247
    },
    {
      "epoch": 0.2867647058823529,
      "grad_norm": 0.9097644686698914,
      "learning_rate": 5.726102941176471e-06,
      "loss": 0.2131,
      "step": 1248
    },
    {
      "epoch": 0.28699448529411764,
      "grad_norm": 0.9482296705245972,
      "learning_rate": 5.730698529411766e-06,
      "loss": 0.2396,
      "step": 1249
    },
    {
      "epoch": 0.28722426470588236,
      "grad_norm": 0.9765090346336365,
      "learning_rate": 5.735294117647059e-06,
      "loss": 0.2337,
      "step": 1250
    },
    {
      "epoch": 0.2874540441176471,
      "grad_norm": 1.1823076009750366,
      "learning_rate": 5.7398897058823535e-06,
      "loss": 0.2853,
      "step": 1251
    },
    {
      "epoch": 0.28768382352941174,
      "grad_norm": 1.3137831687927246,
      "learning_rate": 5.744485294117648e-06,
      "loss": 0.2128,
      "step": 1252
    },
    {
      "epoch": 0.28791360294117646,
      "grad_norm": 0.859940767288208,
      "learning_rate": 5.749080882352942e-06,
      "loss": 0.2676,
      "step": 1253
    },
    {
      "epoch": 0.2881433823529412,
      "grad_norm": 1.1114660501480103,
      "learning_rate": 5.753676470588236e-06,
      "loss": 0.2455,
      "step": 1254
    },
    {
      "epoch": 0.2883731617647059,
      "grad_norm": 0.9975464344024658,
      "learning_rate": 5.75827205882353e-06,
      "loss": 0.2405,
      "step": 1255
    },
    {
      "epoch": 0.28860294117647056,
      "grad_norm": 1.143145203590393,
      "learning_rate": 5.762867647058824e-06,
      "loss": 0.2201,
      "step": 1256
    },
    {
      "epoch": 0.2888327205882353,
      "grad_norm": 1.0098557472229004,
      "learning_rate": 5.767463235294119e-06,
      "loss": 0.205,
      "step": 1257
    },
    {
      "epoch": 0.2890625,
      "grad_norm": 1.4621391296386719,
      "learning_rate": 5.772058823529412e-06,
      "loss": 0.2755,
      "step": 1258
    },
    {
      "epoch": 0.2892922794117647,
      "grad_norm": 1.0561872720718384,
      "learning_rate": 5.7766544117647064e-06,
      "loss": 0.2484,
      "step": 1259
    },
    {
      "epoch": 0.28952205882352944,
      "grad_norm": 1.428889274597168,
      "learning_rate": 5.781250000000001e-06,
      "loss": 0.2357,
      "step": 1260
    },
    {
      "epoch": 0.2897518382352941,
      "grad_norm": 1.0197737216949463,
      "learning_rate": 5.785845588235295e-06,
      "loss": 0.2042,
      "step": 1261
    },
    {
      "epoch": 0.2899816176470588,
      "grad_norm": 1.0046268701553345,
      "learning_rate": 5.790441176470589e-06,
      "loss": 0.221,
      "step": 1262
    },
    {
      "epoch": 0.29021139705882354,
      "grad_norm": 1.2729542255401611,
      "learning_rate": 5.795036764705883e-06,
      "loss": 0.2223,
      "step": 1263
    },
    {
      "epoch": 0.29044117647058826,
      "grad_norm": 1.2850433588027954,
      "learning_rate": 5.799632352941177e-06,
      "loss": 0.2279,
      "step": 1264
    },
    {
      "epoch": 0.2906709558823529,
      "grad_norm": 1.0945090055465698,
      "learning_rate": 5.8042279411764716e-06,
      "loss": 0.2425,
      "step": 1265
    },
    {
      "epoch": 0.29090073529411764,
      "grad_norm": 1.287887454032898,
      "learning_rate": 5.808823529411766e-06,
      "loss": 0.3283,
      "step": 1266
    },
    {
      "epoch": 0.29113051470588236,
      "grad_norm": 1.243116021156311,
      "learning_rate": 5.8134191176470585e-06,
      "loss": 0.2658,
      "step": 1267
    },
    {
      "epoch": 0.2913602941176471,
      "grad_norm": 1.075124979019165,
      "learning_rate": 5.818014705882354e-06,
      "loss": 0.2595,
      "step": 1268
    },
    {
      "epoch": 0.29159007352941174,
      "grad_norm": 1.1671178340911865,
      "learning_rate": 5.822610294117648e-06,
      "loss": 0.2541,
      "step": 1269
    },
    {
      "epoch": 0.29181985294117646,
      "grad_norm": 0.9984310865402222,
      "learning_rate": 5.827205882352942e-06,
      "loss": 0.2459,
      "step": 1270
    },
    {
      "epoch": 0.2920496323529412,
      "grad_norm": 0.9347397685050964,
      "learning_rate": 5.831801470588235e-06,
      "loss": 0.1939,
      "step": 1271
    },
    {
      "epoch": 0.2922794117647059,
      "grad_norm": 1.2149560451507568,
      "learning_rate": 5.836397058823529e-06,
      "loss": 0.2285,
      "step": 1272
    },
    {
      "epoch": 0.29250919117647056,
      "grad_norm": 1.2372201681137085,
      "learning_rate": 5.840992647058824e-06,
      "loss": 0.2871,
      "step": 1273
    },
    {
      "epoch": 0.2927389705882353,
      "grad_norm": 1.130323052406311,
      "learning_rate": 5.845588235294119e-06,
      "loss": 0.2294,
      "step": 1274
    },
    {
      "epoch": 0.29296875,
      "grad_norm": 0.9995507597923279,
      "learning_rate": 5.8501838235294115e-06,
      "loss": 0.2509,
      "step": 1275
    },
    {
      "epoch": 0.2931985294117647,
      "grad_norm": 1.7775495052337646,
      "learning_rate": 5.854779411764706e-06,
      "loss": 0.2689,
      "step": 1276
    },
    {
      "epoch": 0.29342830882352944,
      "grad_norm": 1.1547601222991943,
      "learning_rate": 5.859375e-06,
      "loss": 0.2259,
      "step": 1277
    },
    {
      "epoch": 0.2936580882352941,
      "grad_norm": 1.2649112939834595,
      "learning_rate": 5.8639705882352945e-06,
      "loss": 0.2228,
      "step": 1278
    },
    {
      "epoch": 0.2938878676470588,
      "grad_norm": 0.9302016496658325,
      "learning_rate": 5.86856617647059e-06,
      "loss": 0.2213,
      "step": 1279
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 1.213388442993164,
      "learning_rate": 5.873161764705882e-06,
      "loss": 0.262,
      "step": 1280
    },
    {
      "epoch": 0.29434742647058826,
      "grad_norm": 1.027118444442749,
      "learning_rate": 5.877757352941177e-06,
      "loss": 0.1718,
      "step": 1281
    },
    {
      "epoch": 0.2945772058823529,
      "grad_norm": 1.3153252601623535,
      "learning_rate": 5.882352941176471e-06,
      "loss": 0.215,
      "step": 1282
    },
    {
      "epoch": 0.29480698529411764,
      "grad_norm": 1.2845547199249268,
      "learning_rate": 5.886948529411765e-06,
      "loss": 0.2455,
      "step": 1283
    },
    {
      "epoch": 0.29503676470588236,
      "grad_norm": 1.3589850664138794,
      "learning_rate": 5.891544117647059e-06,
      "loss": 0.257,
      "step": 1284
    },
    {
      "epoch": 0.2952665441176471,
      "grad_norm": 1.0793012380599976,
      "learning_rate": 5.896139705882353e-06,
      "loss": 0.2474,
      "step": 1285
    },
    {
      "epoch": 0.29549632352941174,
      "grad_norm": 0.9237304329872131,
      "learning_rate": 5.900735294117647e-06,
      "loss": 0.2786,
      "step": 1286
    },
    {
      "epoch": 0.29572610294117646,
      "grad_norm": 1.241226315498352,
      "learning_rate": 5.905330882352942e-06,
      "loss": 0.2443,
      "step": 1287
    },
    {
      "epoch": 0.2959558823529412,
      "grad_norm": 1.055118441581726,
      "learning_rate": 5.909926470588235e-06,
      "loss": 0.2356,
      "step": 1288
    },
    {
      "epoch": 0.2961856617647059,
      "grad_norm": 1.1807695627212524,
      "learning_rate": 5.9145220588235295e-06,
      "loss": 0.244,
      "step": 1289
    },
    {
      "epoch": 0.29641544117647056,
      "grad_norm": 1.3706549406051636,
      "learning_rate": 5.919117647058824e-06,
      "loss": 0.1878,
      "step": 1290
    },
    {
      "epoch": 0.2966452205882353,
      "grad_norm": 1.200512170791626,
      "learning_rate": 5.923713235294118e-06,
      "loss": 0.2355,
      "step": 1291
    },
    {
      "epoch": 0.296875,
      "grad_norm": 1.094892144203186,
      "learning_rate": 5.928308823529412e-06,
      "loss": 0.2445,
      "step": 1292
    },
    {
      "epoch": 0.2971047794117647,
      "grad_norm": 1.221286416053772,
      "learning_rate": 5.932904411764706e-06,
      "loss": 0.2612,
      "step": 1293
    },
    {
      "epoch": 0.29733455882352944,
      "grad_norm": 1.1389857530593872,
      "learning_rate": 5.9375e-06,
      "loss": 0.268,
      "step": 1294
    },
    {
      "epoch": 0.2975643382352941,
      "grad_norm": 1.3591678142547607,
      "learning_rate": 5.942095588235295e-06,
      "loss": 0.2567,
      "step": 1295
    },
    {
      "epoch": 0.2977941176470588,
      "grad_norm": 1.0517088174819946,
      "learning_rate": 5.946691176470589e-06,
      "loss": 0.2402,
      "step": 1296
    },
    {
      "epoch": 0.29802389705882354,
      "grad_norm": 1.3008593320846558,
      "learning_rate": 5.9512867647058825e-06,
      "loss": 0.2671,
      "step": 1297
    },
    {
      "epoch": 0.29825367647058826,
      "grad_norm": 1.1883747577667236,
      "learning_rate": 5.955882352941177e-06,
      "loss": 0.2439,
      "step": 1298
    },
    {
      "epoch": 0.2984834558823529,
      "grad_norm": 0.9960448145866394,
      "learning_rate": 5.960477941176471e-06,
      "loss": 0.2447,
      "step": 1299
    },
    {
      "epoch": 0.29871323529411764,
      "grad_norm": 1.116766333580017,
      "learning_rate": 5.9650735294117655e-06,
      "loss": 0.2095,
      "step": 1300
    },
    {
      "epoch": 0.29894301470588236,
      "grad_norm": 1.293019413948059,
      "learning_rate": 5.969669117647059e-06,
      "loss": 0.23,
      "step": 1301
    },
    {
      "epoch": 0.2991727941176471,
      "grad_norm": 1.0007665157318115,
      "learning_rate": 5.974264705882353e-06,
      "loss": 0.2031,
      "step": 1302
    },
    {
      "epoch": 0.29940257352941174,
      "grad_norm": 1.0929917097091675,
      "learning_rate": 5.978860294117648e-06,
      "loss": 0.2178,
      "step": 1303
    },
    {
      "epoch": 0.29963235294117646,
      "grad_norm": 1.0629338026046753,
      "learning_rate": 5.983455882352942e-06,
      "loss": 0.206,
      "step": 1304
    },
    {
      "epoch": 0.2998621323529412,
      "grad_norm": 1.483689785003662,
      "learning_rate": 5.988051470588235e-06,
      "loss": 0.2284,
      "step": 1305
    },
    {
      "epoch": 0.3000919117647059,
      "grad_norm": 0.9478607773780823,
      "learning_rate": 5.99264705882353e-06,
      "loss": 0.1854,
      "step": 1306
    },
    {
      "epoch": 0.30032169117647056,
      "grad_norm": 1.0804836750030518,
      "learning_rate": 5.997242647058824e-06,
      "loss": 0.2861,
      "step": 1307
    },
    {
      "epoch": 0.3005514705882353,
      "grad_norm": 1.2879538536071777,
      "learning_rate": 6.001838235294118e-06,
      "loss": 0.2654,
      "step": 1308
    },
    {
      "epoch": 0.30078125,
      "grad_norm": 1.3635835647583008,
      "learning_rate": 6.006433823529412e-06,
      "loss": 0.3031,
      "step": 1309
    },
    {
      "epoch": 0.3010110294117647,
      "grad_norm": 1.089474081993103,
      "learning_rate": 6.011029411764706e-06,
      "loss": 0.1971,
      "step": 1310
    },
    {
      "epoch": 0.30124080882352944,
      "grad_norm": 1.2072038650512695,
      "learning_rate": 6.0156250000000005e-06,
      "loss": 0.219,
      "step": 1311
    },
    {
      "epoch": 0.3014705882352941,
      "grad_norm": 1.2593454122543335,
      "learning_rate": 6.020220588235295e-06,
      "loss": 0.2346,
      "step": 1312
    },
    {
      "epoch": 0.3017003676470588,
      "grad_norm": 1.2738592624664307,
      "learning_rate": 6.024816176470589e-06,
      "loss": 0.2091,
      "step": 1313
    },
    {
      "epoch": 0.30193014705882354,
      "grad_norm": 1.2432734966278076,
      "learning_rate": 6.029411764705883e-06,
      "loss": 0.2357,
      "step": 1314
    },
    {
      "epoch": 0.30215992647058826,
      "grad_norm": 0.9686111211776733,
      "learning_rate": 6.034007352941177e-06,
      "loss": 0.2108,
      "step": 1315
    },
    {
      "epoch": 0.3023897058823529,
      "grad_norm": 1.1752979755401611,
      "learning_rate": 6.038602941176471e-06,
      "loss": 0.2722,
      "step": 1316
    },
    {
      "epoch": 0.30261948529411764,
      "grad_norm": 1.0489366054534912,
      "learning_rate": 6.043198529411766e-06,
      "loss": 0.236,
      "step": 1317
    },
    {
      "epoch": 0.30284926470588236,
      "grad_norm": 0.8810742497444153,
      "learning_rate": 6.047794117647059e-06,
      "loss": 0.2051,
      "step": 1318
    },
    {
      "epoch": 0.3030790441176471,
      "grad_norm": 0.8552696108818054,
      "learning_rate": 6.0523897058823535e-06,
      "loss": 0.1822,
      "step": 1319
    },
    {
      "epoch": 0.30330882352941174,
      "grad_norm": 1.3580151796340942,
      "learning_rate": 6.056985294117648e-06,
      "loss": 0.2352,
      "step": 1320
    },
    {
      "epoch": 0.30353860294117646,
      "grad_norm": 0.9968512058258057,
      "learning_rate": 6.061580882352942e-06,
      "loss": 0.2079,
      "step": 1321
    },
    {
      "epoch": 0.3037683823529412,
      "grad_norm": 1.1775157451629639,
      "learning_rate": 6.066176470588236e-06,
      "loss": 0.2248,
      "step": 1322
    },
    {
      "epoch": 0.3039981617647059,
      "grad_norm": 1.013357400894165,
      "learning_rate": 6.07077205882353e-06,
      "loss": 0.2545,
      "step": 1323
    },
    {
      "epoch": 0.30422794117647056,
      "grad_norm": 1.0241100788116455,
      "learning_rate": 6.075367647058824e-06,
      "loss": 0.2113,
      "step": 1324
    },
    {
      "epoch": 0.3044577205882353,
      "grad_norm": 1.0094597339630127,
      "learning_rate": 6.079963235294119e-06,
      "loss": 0.2456,
      "step": 1325
    },
    {
      "epoch": 0.3046875,
      "grad_norm": 0.9297283291816711,
      "learning_rate": 6.084558823529412e-06,
      "loss": 0.1929,
      "step": 1326
    },
    {
      "epoch": 0.3049172794117647,
      "grad_norm": 1.1168866157531738,
      "learning_rate": 6.089154411764706e-06,
      "loss": 0.2153,
      "step": 1327
    },
    {
      "epoch": 0.30514705882352944,
      "grad_norm": 1.1135823726654053,
      "learning_rate": 6.093750000000001e-06,
      "loss": 0.2278,
      "step": 1328
    },
    {
      "epoch": 0.3053768382352941,
      "grad_norm": 1.0615030527114868,
      "learning_rate": 6.098345588235295e-06,
      "loss": 0.2347,
      "step": 1329
    },
    {
      "epoch": 0.3056066176470588,
      "grad_norm": 1.1843527555465698,
      "learning_rate": 6.102941176470589e-06,
      "loss": 0.2402,
      "step": 1330
    },
    {
      "epoch": 0.30583639705882354,
      "grad_norm": 1.2864700555801392,
      "learning_rate": 6.107536764705883e-06,
      "loss": 0.2758,
      "step": 1331
    },
    {
      "epoch": 0.30606617647058826,
      "grad_norm": 1.3683966398239136,
      "learning_rate": 6.112132352941177e-06,
      "loss": 0.2934,
      "step": 1332
    },
    {
      "epoch": 0.3062959558823529,
      "grad_norm": 1.2672160863876343,
      "learning_rate": 6.1167279411764715e-06,
      "loss": 0.2634,
      "step": 1333
    },
    {
      "epoch": 0.30652573529411764,
      "grad_norm": 1.2622617483139038,
      "learning_rate": 6.121323529411766e-06,
      "loss": 0.2204,
      "step": 1334
    },
    {
      "epoch": 0.30675551470588236,
      "grad_norm": 1.0813974142074585,
      "learning_rate": 6.125919117647059e-06,
      "loss": 0.2383,
      "step": 1335
    },
    {
      "epoch": 0.3069852941176471,
      "grad_norm": 1.1015419960021973,
      "learning_rate": 6.130514705882354e-06,
      "loss": 0.227,
      "step": 1336
    },
    {
      "epoch": 0.30721507352941174,
      "grad_norm": 1.1065748929977417,
      "learning_rate": 6.135110294117648e-06,
      "loss": 0.1822,
      "step": 1337
    },
    {
      "epoch": 0.30744485294117646,
      "grad_norm": 1.2578532695770264,
      "learning_rate": 6.139705882352942e-06,
      "loss": 0.2689,
      "step": 1338
    },
    {
      "epoch": 0.3076746323529412,
      "grad_norm": 1.0911924839019775,
      "learning_rate": 6.144301470588235e-06,
      "loss": 0.2226,
      "step": 1339
    },
    {
      "epoch": 0.3079044117647059,
      "grad_norm": 0.9654791951179504,
      "learning_rate": 6.148897058823529e-06,
      "loss": 0.2197,
      "step": 1340
    },
    {
      "epoch": 0.30813419117647056,
      "grad_norm": 1.4131182432174683,
      "learning_rate": 6.1534926470588245e-06,
      "loss": 0.246,
      "step": 1341
    },
    {
      "epoch": 0.3083639705882353,
      "grad_norm": 1.3259963989257812,
      "learning_rate": 6.158088235294119e-06,
      "loss": 0.2239,
      "step": 1342
    },
    {
      "epoch": 0.30859375,
      "grad_norm": 1.5448517799377441,
      "learning_rate": 6.1626838235294114e-06,
      "loss": 0.2266,
      "step": 1343
    },
    {
      "epoch": 0.3088235294117647,
      "grad_norm": 1.0859569311141968,
      "learning_rate": 6.167279411764706e-06,
      "loss": 0.2143,
      "step": 1344
    },
    {
      "epoch": 0.30905330882352944,
      "grad_norm": 1.3527817726135254,
      "learning_rate": 6.171875e-06,
      "loss": 0.1927,
      "step": 1345
    },
    {
      "epoch": 0.3092830882352941,
      "grad_norm": 1.1093679666519165,
      "learning_rate": 6.176470588235295e-06,
      "loss": 0.2661,
      "step": 1346
    },
    {
      "epoch": 0.3095128676470588,
      "grad_norm": 0.9237498044967651,
      "learning_rate": 6.18106617647059e-06,
      "loss": 0.232,
      "step": 1347
    },
    {
      "epoch": 0.30974264705882354,
      "grad_norm": 1.1032588481903076,
      "learning_rate": 6.185661764705882e-06,
      "loss": 0.1473,
      "step": 1348
    },
    {
      "epoch": 0.30997242647058826,
      "grad_norm": 1.2246510982513428,
      "learning_rate": 6.1902573529411766e-06,
      "loss": 0.1946,
      "step": 1349
    },
    {
      "epoch": 0.3102022058823529,
      "grad_norm": 1.118358850479126,
      "learning_rate": 6.194852941176471e-06,
      "loss": 0.2727,
      "step": 1350
    },
    {
      "epoch": 0.31043198529411764,
      "grad_norm": 1.072353482246399,
      "learning_rate": 6.199448529411766e-06,
      "loss": 0.2146,
      "step": 1351
    },
    {
      "epoch": 0.31066176470588236,
      "grad_norm": 0.9051848649978638,
      "learning_rate": 6.204044117647059e-06,
      "loss": 0.1844,
      "step": 1352
    },
    {
      "epoch": 0.3108915441176471,
      "grad_norm": 1.0772632360458374,
      "learning_rate": 6.208639705882353e-06,
      "loss": 0.2096,
      "step": 1353
    },
    {
      "epoch": 0.31112132352941174,
      "grad_norm": 0.9377658367156982,
      "learning_rate": 6.213235294117647e-06,
      "loss": 0.1922,
      "step": 1354
    },
    {
      "epoch": 0.31135110294117646,
      "grad_norm": 1.6360656023025513,
      "learning_rate": 6.217830882352942e-06,
      "loss": 0.2868,
      "step": 1355
    },
    {
      "epoch": 0.3115808823529412,
      "grad_norm": 1.0280787944793701,
      "learning_rate": 6.222426470588235e-06,
      "loss": 0.1664,
      "step": 1356
    },
    {
      "epoch": 0.3118106617647059,
      "grad_norm": 1.1390011310577393,
      "learning_rate": 6.2270220588235295e-06,
      "loss": 0.201,
      "step": 1357
    },
    {
      "epoch": 0.31204044117647056,
      "grad_norm": 1.0582424402236938,
      "learning_rate": 6.231617647058824e-06,
      "loss": 0.216,
      "step": 1358
    },
    {
      "epoch": 0.3122702205882353,
      "grad_norm": 1.0387780666351318,
      "learning_rate": 6.236213235294118e-06,
      "loss": 0.2364,
      "step": 1359
    },
    {
      "epoch": 0.3125,
      "grad_norm": 1.0225529670715332,
      "learning_rate": 6.240808823529412e-06,
      "loss": 0.1955,
      "step": 1360
    },
    {
      "epoch": 0.3127297794117647,
      "grad_norm": 1.4320001602172852,
      "learning_rate": 6.245404411764706e-06,
      "loss": 0.2519,
      "step": 1361
    },
    {
      "epoch": 0.31295955882352944,
      "grad_norm": 1.5131375789642334,
      "learning_rate": 6.25e-06,
      "loss": 0.1783,
      "step": 1362
    },
    {
      "epoch": 0.3131893382352941,
      "grad_norm": 1.1443285942077637,
      "learning_rate": 6.254595588235295e-06,
      "loss": 0.2036,
      "step": 1363
    },
    {
      "epoch": 0.3134191176470588,
      "grad_norm": 1.2026498317718506,
      "learning_rate": 6.259191176470589e-06,
      "loss": 0.2017,
      "step": 1364
    },
    {
      "epoch": 0.31364889705882354,
      "grad_norm": 1.1182142496109009,
      "learning_rate": 6.2637867647058824e-06,
      "loss": 0.2514,
      "step": 1365
    },
    {
      "epoch": 0.31387867647058826,
      "grad_norm": 1.177499771118164,
      "learning_rate": 6.268382352941177e-06,
      "loss": 0.2488,
      "step": 1366
    },
    {
      "epoch": 0.3141084558823529,
      "grad_norm": 1.0870695114135742,
      "learning_rate": 6.272977941176471e-06,
      "loss": 0.1882,
      "step": 1367
    },
    {
      "epoch": 0.31433823529411764,
      "grad_norm": 1.2995848655700684,
      "learning_rate": 6.2775735294117654e-06,
      "loss": 0.2399,
      "step": 1368
    },
    {
      "epoch": 0.31456801470588236,
      "grad_norm": 1.4713168144226074,
      "learning_rate": 6.282169117647059e-06,
      "loss": 0.2132,
      "step": 1369
    },
    {
      "epoch": 0.3147977941176471,
      "grad_norm": 1.0774626731872559,
      "learning_rate": 6.286764705882353e-06,
      "loss": 0.1806,
      "step": 1370
    },
    {
      "epoch": 0.31502757352941174,
      "grad_norm": 1.2677195072174072,
      "learning_rate": 6.2913602941176476e-06,
      "loss": 0.2302,
      "step": 1371
    },
    {
      "epoch": 0.31525735294117646,
      "grad_norm": 1.1749320030212402,
      "learning_rate": 6.295955882352942e-06,
      "loss": 0.2429,
      "step": 1372
    },
    {
      "epoch": 0.3154871323529412,
      "grad_norm": 1.4312268495559692,
      "learning_rate": 6.300551470588235e-06,
      "loss": 0.2086,
      "step": 1373
    },
    {
      "epoch": 0.3157169117647059,
      "grad_norm": 1.3377569913864136,
      "learning_rate": 6.30514705882353e-06,
      "loss": 0.225,
      "step": 1374
    },
    {
      "epoch": 0.31594669117647056,
      "grad_norm": 0.9880480170249939,
      "learning_rate": 6.309742647058824e-06,
      "loss": 0.2031,
      "step": 1375
    },
    {
      "epoch": 0.3161764705882353,
      "grad_norm": 1.361801028251648,
      "learning_rate": 6.314338235294118e-06,
      "loss": 0.2446,
      "step": 1376
    },
    {
      "epoch": 0.31640625,
      "grad_norm": 1.181991457939148,
      "learning_rate": 6.318933823529412e-06,
      "loss": 0.223,
      "step": 1377
    },
    {
      "epoch": 0.3166360294117647,
      "grad_norm": 1.189167857170105,
      "learning_rate": 6.323529411764706e-06,
      "loss": 0.184,
      "step": 1378
    },
    {
      "epoch": 0.31686580882352944,
      "grad_norm": 1.027522087097168,
      "learning_rate": 6.3281250000000005e-06,
      "loss": 0.2589,
      "step": 1379
    },
    {
      "epoch": 0.3170955882352941,
      "grad_norm": 1.0891189575195312,
      "learning_rate": 6.332720588235295e-06,
      "loss": 0.1866,
      "step": 1380
    },
    {
      "epoch": 0.3173253676470588,
      "grad_norm": 0.945496141910553,
      "learning_rate": 6.337316176470589e-06,
      "loss": 0.206,
      "step": 1381
    },
    {
      "epoch": 0.31755514705882354,
      "grad_norm": 1.0700154304504395,
      "learning_rate": 6.341911764705883e-06,
      "loss": 0.1941,
      "step": 1382
    },
    {
      "epoch": 0.31778492647058826,
      "grad_norm": 1.1863346099853516,
      "learning_rate": 6.346507352941177e-06,
      "loss": 0.2028,
      "step": 1383
    },
    {
      "epoch": 0.3180147058823529,
      "grad_norm": 1.163375973701477,
      "learning_rate": 6.351102941176471e-06,
      "loss": 0.187,
      "step": 1384
    },
    {
      "epoch": 0.31824448529411764,
      "grad_norm": 0.9722115397453308,
      "learning_rate": 6.355698529411766e-06,
      "loss": 0.1716,
      "step": 1385
    },
    {
      "epoch": 0.31847426470588236,
      "grad_norm": 1.483162760734558,
      "learning_rate": 6.360294117647059e-06,
      "loss": 0.3253,
      "step": 1386
    },
    {
      "epoch": 0.3187040441176471,
      "grad_norm": 1.3372942209243774,
      "learning_rate": 6.3648897058823534e-06,
      "loss": 0.2112,
      "step": 1387
    },
    {
      "epoch": 0.31893382352941174,
      "grad_norm": 1.469231367111206,
      "learning_rate": 6.369485294117648e-06,
      "loss": 0.2242,
      "step": 1388
    },
    {
      "epoch": 0.31916360294117646,
      "grad_norm": 0.910068929195404,
      "learning_rate": 6.374080882352942e-06,
      "loss": 0.1733,
      "step": 1389
    },
    {
      "epoch": 0.3193933823529412,
      "grad_norm": 1.4306179285049438,
      "learning_rate": 6.378676470588236e-06,
      "loss": 0.2511,
      "step": 1390
    },
    {
      "epoch": 0.3196231617647059,
      "grad_norm": 1.2477632761001587,
      "learning_rate": 6.38327205882353e-06,
      "loss": 0.2312,
      "step": 1391
    },
    {
      "epoch": 0.31985294117647056,
      "grad_norm": 0.9816159605979919,
      "learning_rate": 6.387867647058824e-06,
      "loss": 0.1907,
      "step": 1392
    },
    {
      "epoch": 0.3200827205882353,
      "grad_norm": 1.2864817380905151,
      "learning_rate": 6.3924632352941186e-06,
      "loss": 0.2094,
      "step": 1393
    },
    {
      "epoch": 0.3203125,
      "grad_norm": 1.6415133476257324,
      "learning_rate": 6.397058823529412e-06,
      "loss": 0.2788,
      "step": 1394
    },
    {
      "epoch": 0.3205422794117647,
      "grad_norm": 1.328487753868103,
      "learning_rate": 6.401654411764706e-06,
      "loss": 0.2026,
      "step": 1395
    },
    {
      "epoch": 0.32077205882352944,
      "grad_norm": 1.457556128501892,
      "learning_rate": 6.406250000000001e-06,
      "loss": 0.1726,
      "step": 1396
    },
    {
      "epoch": 0.3210018382352941,
      "grad_norm": 1.0708706378936768,
      "learning_rate": 6.410845588235295e-06,
      "loss": 0.1827,
      "step": 1397
    },
    {
      "epoch": 0.3212316176470588,
      "grad_norm": 1.0969421863555908,
      "learning_rate": 6.415441176470589e-06,
      "loss": 0.2289,
      "step": 1398
    },
    {
      "epoch": 0.32146139705882354,
      "grad_norm": 1.0579068660736084,
      "learning_rate": 6.420036764705883e-06,
      "loss": 0.2407,
      "step": 1399
    },
    {
      "epoch": 0.32169117647058826,
      "grad_norm": 1.2099660634994507,
      "learning_rate": 6.424632352941177e-06,
      "loss": 0.2518,
      "step": 1400
    },
    {
      "epoch": 0.3219209558823529,
      "grad_norm": 1.2707459926605225,
      "learning_rate": 6.4292279411764715e-06,
      "loss": 0.1771,
      "step": 1401
    },
    {
      "epoch": 0.32215073529411764,
      "grad_norm": 1.1507318019866943,
      "learning_rate": 6.433823529411766e-06,
      "loss": 0.2226,
      "step": 1402
    },
    {
      "epoch": 0.32238051470588236,
      "grad_norm": 1.4526492357254028,
      "learning_rate": 6.438419117647059e-06,
      "loss": 0.2103,
      "step": 1403
    },
    {
      "epoch": 0.3226102941176471,
      "grad_norm": 1.598029375076294,
      "learning_rate": 6.443014705882354e-06,
      "loss": 0.2839,
      "step": 1404
    },
    {
      "epoch": 0.32284007352941174,
      "grad_norm": 0.973875880241394,
      "learning_rate": 6.447610294117648e-06,
      "loss": 0.224,
      "step": 1405
    },
    {
      "epoch": 0.32306985294117646,
      "grad_norm": 1.0442724227905273,
      "learning_rate": 6.452205882352942e-06,
      "loss": 0.1994,
      "step": 1406
    },
    {
      "epoch": 0.3232996323529412,
      "grad_norm": 1.002353310585022,
      "learning_rate": 6.456801470588236e-06,
      "loss": 0.191,
      "step": 1407
    },
    {
      "epoch": 0.3235294117647059,
      "grad_norm": 1.1677608489990234,
      "learning_rate": 6.46139705882353e-06,
      "loss": 0.2463,
      "step": 1408
    },
    {
      "epoch": 0.32375919117647056,
      "grad_norm": 1.2992593050003052,
      "learning_rate": 6.4659926470588244e-06,
      "loss": 0.1991,
      "step": 1409
    },
    {
      "epoch": 0.3239889705882353,
      "grad_norm": 0.9922529458999634,
      "learning_rate": 6.470588235294119e-06,
      "loss": 0.1717,
      "step": 1410
    },
    {
      "epoch": 0.32421875,
      "grad_norm": 1.2212051153182983,
      "learning_rate": 6.475183823529411e-06,
      "loss": 0.1855,
      "step": 1411
    },
    {
      "epoch": 0.3244485294117647,
      "grad_norm": 1.1155223846435547,
      "learning_rate": 6.479779411764706e-06,
      "loss": 0.2183,
      "step": 1412
    },
    {
      "epoch": 0.32467830882352944,
      "grad_norm": 0.994432270526886,
      "learning_rate": 6.484375000000001e-06,
      "loss": 0.2095,
      "step": 1413
    },
    {
      "epoch": 0.3249080882352941,
      "grad_norm": 1.2957309484481812,
      "learning_rate": 6.488970588235295e-06,
      "loss": 0.2441,
      "step": 1414
    },
    {
      "epoch": 0.3251378676470588,
      "grad_norm": 1.2474842071533203,
      "learning_rate": 6.4935661764705896e-06,
      "loss": 0.1825,
      "step": 1415
    },
    {
      "epoch": 0.32536764705882354,
      "grad_norm": 0.9859731793403625,
      "learning_rate": 6.498161764705882e-06,
      "loss": 0.1975,
      "step": 1416
    },
    {
      "epoch": 0.32559742647058826,
      "grad_norm": 1.303861379623413,
      "learning_rate": 6.5027573529411765e-06,
      "loss": 0.238,
      "step": 1417
    },
    {
      "epoch": 0.3258272058823529,
      "grad_norm": 1.1964341402053833,
      "learning_rate": 6.507352941176472e-06,
      "loss": 0.224,
      "step": 1418
    },
    {
      "epoch": 0.32605698529411764,
      "grad_norm": 1.2499712705612183,
      "learning_rate": 6.511948529411766e-06,
      "loss": 0.2137,
      "step": 1419
    },
    {
      "epoch": 0.32628676470588236,
      "grad_norm": 1.033210039138794,
      "learning_rate": 6.516544117647059e-06,
      "loss": 0.2148,
      "step": 1420
    },
    {
      "epoch": 0.3265165441176471,
      "grad_norm": 1.020678162574768,
      "learning_rate": 6.521139705882353e-06,
      "loss": 0.2062,
      "step": 1421
    },
    {
      "epoch": 0.32674632352941174,
      "grad_norm": 1.0316991806030273,
      "learning_rate": 6.525735294117647e-06,
      "loss": 0.1944,
      "step": 1422
    },
    {
      "epoch": 0.32697610294117646,
      "grad_norm": 1.106703281402588,
      "learning_rate": 6.5303308823529425e-06,
      "loss": 0.2318,
      "step": 1423
    },
    {
      "epoch": 0.3272058823529412,
      "grad_norm": 1.4780241250991821,
      "learning_rate": 6.534926470588235e-06,
      "loss": 0.2365,
      "step": 1424
    },
    {
      "epoch": 0.3274356617647059,
      "grad_norm": 0.8954510688781738,
      "learning_rate": 6.5395220588235295e-06,
      "loss": 0.1938,
      "step": 1425
    },
    {
      "epoch": 0.32766544117647056,
      "grad_norm": 0.9829141497612,
      "learning_rate": 6.544117647058824e-06,
      "loss": 0.2114,
      "step": 1426
    },
    {
      "epoch": 0.3278952205882353,
      "grad_norm": 1.00994074344635,
      "learning_rate": 6.548713235294118e-06,
      "loss": 0.2243,
      "step": 1427
    },
    {
      "epoch": 0.328125,
      "grad_norm": 1.1255497932434082,
      "learning_rate": 6.553308823529412e-06,
      "loss": 0.1945,
      "step": 1428
    },
    {
      "epoch": 0.3283547794117647,
      "grad_norm": 1.063462257385254,
      "learning_rate": 6.557904411764706e-06,
      "loss": 0.1695,
      "step": 1429
    },
    {
      "epoch": 0.32858455882352944,
      "grad_norm": 1.0933781862258911,
      "learning_rate": 6.5625e-06,
      "loss": 0.2102,
      "step": 1430
    },
    {
      "epoch": 0.3288143382352941,
      "grad_norm": 1.1418349742889404,
      "learning_rate": 6.567095588235295e-06,
      "loss": 0.23,
      "step": 1431
    },
    {
      "epoch": 0.3290441176470588,
      "grad_norm": 1.18638014793396,
      "learning_rate": 6.571691176470589e-06,
      "loss": 0.2216,
      "step": 1432
    },
    {
      "epoch": 0.32927389705882354,
      "grad_norm": 1.0256785154342651,
      "learning_rate": 6.576286764705882e-06,
      "loss": 0.1623,
      "step": 1433
    },
    {
      "epoch": 0.32950367647058826,
      "grad_norm": 1.1573375463485718,
      "learning_rate": 6.580882352941177e-06,
      "loss": 0.2591,
      "step": 1434
    },
    {
      "epoch": 0.3297334558823529,
      "grad_norm": 1.2352092266082764,
      "learning_rate": 6.585477941176471e-06,
      "loss": 0.2061,
      "step": 1435
    },
    {
      "epoch": 0.32996323529411764,
      "grad_norm": 1.1471335887908936,
      "learning_rate": 6.590073529411765e-06,
      "loss": 0.2327,
      "step": 1436
    },
    {
      "epoch": 0.33019301470588236,
      "grad_norm": 0.9441105127334595,
      "learning_rate": 6.594669117647059e-06,
      "loss": 0.1976,
      "step": 1437
    },
    {
      "epoch": 0.3304227941176471,
      "grad_norm": 0.9386785626411438,
      "learning_rate": 6.599264705882353e-06,
      "loss": 0.1605,
      "step": 1438
    },
    {
      "epoch": 0.33065257352941174,
      "grad_norm": 1.0702975988388062,
      "learning_rate": 6.6038602941176475e-06,
      "loss": 0.2072,
      "step": 1439
    },
    {
      "epoch": 0.33088235294117646,
      "grad_norm": 1.1301649808883667,
      "learning_rate": 6.608455882352942e-06,
      "loss": 0.1767,
      "step": 1440
    },
    {
      "epoch": 0.3311121323529412,
      "grad_norm": 1.1568639278411865,
      "learning_rate": 6.613051470588235e-06,
      "loss": 0.2376,
      "step": 1441
    },
    {
      "epoch": 0.3313419117647059,
      "grad_norm": 1.1180670261383057,
      "learning_rate": 6.61764705882353e-06,
      "loss": 0.2065,
      "step": 1442
    },
    {
      "epoch": 0.33157169117647056,
      "grad_norm": 1.4299075603485107,
      "learning_rate": 6.622242647058824e-06,
      "loss": 0.2476,
      "step": 1443
    },
    {
      "epoch": 0.3318014705882353,
      "grad_norm": 1.1774730682373047,
      "learning_rate": 6.626838235294118e-06,
      "loss": 0.1934,
      "step": 1444
    },
    {
      "epoch": 0.33203125,
      "grad_norm": 1.3151934146881104,
      "learning_rate": 6.631433823529412e-06,
      "loss": 0.2316,
      "step": 1445
    },
    {
      "epoch": 0.3322610294117647,
      "grad_norm": 1.135265827178955,
      "learning_rate": 6.636029411764706e-06,
      "loss": 0.179,
      "step": 1446
    },
    {
      "epoch": 0.33249080882352944,
      "grad_norm": 1.1018595695495605,
      "learning_rate": 6.6406250000000005e-06,
      "loss": 0.2422,
      "step": 1447
    },
    {
      "epoch": 0.3327205882352941,
      "grad_norm": 1.0286792516708374,
      "learning_rate": 6.645220588235295e-06,
      "loss": 0.1603,
      "step": 1448
    },
    {
      "epoch": 0.3329503676470588,
      "grad_norm": 1.2508502006530762,
      "learning_rate": 6.649816176470589e-06,
      "loss": 0.2355,
      "step": 1449
    },
    {
      "epoch": 0.33318014705882354,
      "grad_norm": 1.0215094089508057,
      "learning_rate": 6.654411764705883e-06,
      "loss": 0.1865,
      "step": 1450
    },
    {
      "epoch": 0.33340992647058826,
      "grad_norm": 1.0388686656951904,
      "learning_rate": 6.659007352941177e-06,
      "loss": 0.1971,
      "step": 1451
    },
    {
      "epoch": 0.3336397058823529,
      "grad_norm": 1.007022738456726,
      "learning_rate": 6.663602941176471e-06,
      "loss": 0.1853,
      "step": 1452
    },
    {
      "epoch": 0.33386948529411764,
      "grad_norm": 0.9639096260070801,
      "learning_rate": 6.668198529411766e-06,
      "loss": 0.169,
      "step": 1453
    },
    {
      "epoch": 0.33409926470588236,
      "grad_norm": 1.3821821212768555,
      "learning_rate": 6.672794117647059e-06,
      "loss": 0.2142,
      "step": 1454
    },
    {
      "epoch": 0.3343290441176471,
      "grad_norm": 1.1588646173477173,
      "learning_rate": 6.677389705882353e-06,
      "loss": 0.204,
      "step": 1455
    },
    {
      "epoch": 0.33455882352941174,
      "grad_norm": 1.1549080610275269,
      "learning_rate": 6.681985294117648e-06,
      "loss": 0.1905,
      "step": 1456
    },
    {
      "epoch": 0.33478860294117646,
      "grad_norm": 1.1354899406433105,
      "learning_rate": 6.686580882352942e-06,
      "loss": 0.2087,
      "step": 1457
    },
    {
      "epoch": 0.3350183823529412,
      "grad_norm": 1.1695805788040161,
      "learning_rate": 6.6911764705882356e-06,
      "loss": 0.1637,
      "step": 1458
    },
    {
      "epoch": 0.3352481617647059,
      "grad_norm": 1.1263419389724731,
      "learning_rate": 6.69577205882353e-06,
      "loss": 0.172,
      "step": 1459
    },
    {
      "epoch": 0.33547794117647056,
      "grad_norm": 1.1221116781234741,
      "learning_rate": 6.700367647058824e-06,
      "loss": 0.187,
      "step": 1460
    },
    {
      "epoch": 0.3357077205882353,
      "grad_norm": 1.1093071699142456,
      "learning_rate": 6.7049632352941185e-06,
      "loss": 0.176,
      "step": 1461
    },
    {
      "epoch": 0.3359375,
      "grad_norm": 1.8832546472549438,
      "learning_rate": 6.709558823529412e-06,
      "loss": 0.178,
      "step": 1462
    },
    {
      "epoch": 0.3361672794117647,
      "grad_norm": 1.4923462867736816,
      "learning_rate": 6.714154411764706e-06,
      "loss": 0.2357,
      "step": 1463
    },
    {
      "epoch": 0.33639705882352944,
      "grad_norm": 1.297707200050354,
      "learning_rate": 6.718750000000001e-06,
      "loss": 0.2089,
      "step": 1464
    },
    {
      "epoch": 0.3366268382352941,
      "grad_norm": 0.989963710308075,
      "learning_rate": 6.723345588235295e-06,
      "loss": 0.1622,
      "step": 1465
    },
    {
      "epoch": 0.3368566176470588,
      "grad_norm": 1.1974854469299316,
      "learning_rate": 6.727941176470589e-06,
      "loss": 0.2213,
      "step": 1466
    },
    {
      "epoch": 0.33708639705882354,
      "grad_norm": 1.3576067686080933,
      "learning_rate": 6.732536764705883e-06,
      "loss": 0.1926,
      "step": 1467
    },
    {
      "epoch": 0.33731617647058826,
      "grad_norm": 1.2821094989776611,
      "learning_rate": 6.737132352941177e-06,
      "loss": 0.1681,
      "step": 1468
    },
    {
      "epoch": 0.3375459558823529,
      "grad_norm": 1.2719603776931763,
      "learning_rate": 6.7417279411764715e-06,
      "loss": 0.2608,
      "step": 1469
    },
    {
      "epoch": 0.33777573529411764,
      "grad_norm": 1.1456763744354248,
      "learning_rate": 6.746323529411766e-06,
      "loss": 0.2241,
      "step": 1470
    },
    {
      "epoch": 0.33800551470588236,
      "grad_norm": 0.9489449858665466,
      "learning_rate": 6.750919117647059e-06,
      "loss": 0.2317,
      "step": 1471
    },
    {
      "epoch": 0.3382352941176471,
      "grad_norm": 1.2304950952529907,
      "learning_rate": 6.755514705882354e-06,
      "loss": 0.2027,
      "step": 1472
    },
    {
      "epoch": 0.33846507352941174,
      "grad_norm": 1.1863927841186523,
      "learning_rate": 6.760110294117648e-06,
      "loss": 0.1877,
      "step": 1473
    },
    {
      "epoch": 0.33869485294117646,
      "grad_norm": 1.2308276891708374,
      "learning_rate": 6.764705882352942e-06,
      "loss": 0.1849,
      "step": 1474
    },
    {
      "epoch": 0.3389246323529412,
      "grad_norm": 0.94942706823349,
      "learning_rate": 6.769301470588236e-06,
      "loss": 0.155,
      "step": 1475
    },
    {
      "epoch": 0.3391544117647059,
      "grad_norm": 1.2859910726547241,
      "learning_rate": 6.77389705882353e-06,
      "loss": 0.2216,
      "step": 1476
    },
    {
      "epoch": 0.33938419117647056,
      "grad_norm": 1.1631102561950684,
      "learning_rate": 6.778492647058824e-06,
      "loss": 0.1755,
      "step": 1477
    },
    {
      "epoch": 0.3396139705882353,
      "grad_norm": 1.1852490901947021,
      "learning_rate": 6.783088235294119e-06,
      "loss": 0.1766,
      "step": 1478
    },
    {
      "epoch": 0.33984375,
      "grad_norm": 1.5098552703857422,
      "learning_rate": 6.787683823529411e-06,
      "loss": 0.155,
      "step": 1479
    },
    {
      "epoch": 0.3400735294117647,
      "grad_norm": 0.9915273189544678,
      "learning_rate": 6.7922794117647066e-06,
      "loss": 0.1565,
      "step": 1480
    },
    {
      "epoch": 0.34030330882352944,
      "grad_norm": 1.3477479219436646,
      "learning_rate": 6.796875000000001e-06,
      "loss": 0.2512,
      "step": 1481
    },
    {
      "epoch": 0.3405330882352941,
      "grad_norm": 1.0796184539794922,
      "learning_rate": 6.801470588235295e-06,
      "loss": 0.2072,
      "step": 1482
    },
    {
      "epoch": 0.3407628676470588,
      "grad_norm": 1.1440832614898682,
      "learning_rate": 6.8060661764705895e-06,
      "loss": 0.1925,
      "step": 1483
    },
    {
      "epoch": 0.34099264705882354,
      "grad_norm": 1.009036660194397,
      "learning_rate": 6.810661764705882e-06,
      "loss": 0.2072,
      "step": 1484
    },
    {
      "epoch": 0.34122242647058826,
      "grad_norm": 1.1327499151229858,
      "learning_rate": 6.815257352941177e-06,
      "loss": 0.2306,
      "step": 1485
    },
    {
      "epoch": 0.3414522058823529,
      "grad_norm": 1.2196805477142334,
      "learning_rate": 6.819852941176472e-06,
      "loss": 0.2547,
      "step": 1486
    },
    {
      "epoch": 0.34168198529411764,
      "grad_norm": 1.2038193941116333,
      "learning_rate": 6.824448529411766e-06,
      "loss": 0.1784,
      "step": 1487
    },
    {
      "epoch": 0.34191176470588236,
      "grad_norm": 1.0903971195220947,
      "learning_rate": 6.829044117647059e-06,
      "loss": 0.1798,
      "step": 1488
    },
    {
      "epoch": 0.3421415441176471,
      "grad_norm": 1.3524982929229736,
      "learning_rate": 6.833639705882353e-06,
      "loss": 0.2074,
      "step": 1489
    },
    {
      "epoch": 0.34237132352941174,
      "grad_norm": 1.1797510385513306,
      "learning_rate": 6.838235294117648e-06,
      "loss": 0.2242,
      "step": 1490
    },
    {
      "epoch": 0.34260110294117646,
      "grad_norm": 1.0812393426895142,
      "learning_rate": 6.8428308823529425e-06,
      "loss": 0.169,
      "step": 1491
    },
    {
      "epoch": 0.3428308823529412,
      "grad_norm": 1.1696687936782837,
      "learning_rate": 6.847426470588235e-06,
      "loss": 0.1976,
      "step": 1492
    },
    {
      "epoch": 0.3430606617647059,
      "grad_norm": 1.054487705230713,
      "learning_rate": 6.8520220588235294e-06,
      "loss": 0.2094,
      "step": 1493
    },
    {
      "epoch": 0.34329044117647056,
      "grad_norm": 1.1675065755844116,
      "learning_rate": 6.856617647058824e-06,
      "loss": 0.2389,
      "step": 1494
    },
    {
      "epoch": 0.3435202205882353,
      "grad_norm": 1.2527389526367188,
      "learning_rate": 6.861213235294119e-06,
      "loss": 0.1958,
      "step": 1495
    },
    {
      "epoch": 0.34375,
      "grad_norm": 1.1576026678085327,
      "learning_rate": 6.865808823529412e-06,
      "loss": 0.2317,
      "step": 1496
    },
    {
      "epoch": 0.3439797794117647,
      "grad_norm": 1.0606439113616943,
      "learning_rate": 6.870404411764706e-06,
      "loss": 0.2058,
      "step": 1497
    },
    {
      "epoch": 0.34420955882352944,
      "grad_norm": 1.1140499114990234,
      "learning_rate": 6.875e-06,
      "loss": 0.2107,
      "step": 1498
    },
    {
      "epoch": 0.3444393382352941,
      "grad_norm": 1.1195735931396484,
      "learning_rate": 6.8795955882352946e-06,
      "loss": 0.1616,
      "step": 1499
    },
    {
      "epoch": 0.3446691176470588,
      "grad_norm": 1.0653585195541382,
      "learning_rate": 6.884191176470589e-06,
      "loss": 0.1878,
      "step": 1500
    },
    {
      "epoch": 0.3446691176470588,
      "eval_loss": 0.18815813958644867,
      "eval_runtime": 2007.4062,
      "eval_samples_per_second": 4.437,
      "eval_steps_per_second": 2.218,
      "step": 1500
    },
    {
      "epoch": 0.34489889705882354,
      "grad_norm": 1.195924162864685,
      "learning_rate": 6.888786764705882e-06,
      "loss": 0.192,
      "step": 1501
    },
    {
      "epoch": 0.34512867647058826,
      "grad_norm": 1.2625354528427124,
      "learning_rate": 6.893382352941177e-06,
      "loss": 0.1628,
      "step": 1502
    },
    {
      "epoch": 0.3453584558823529,
      "grad_norm": 1.035666584968567,
      "learning_rate": 6.897977941176471e-06,
      "loss": 0.1757,
      "step": 1503
    },
    {
      "epoch": 0.34558823529411764,
      "grad_norm": 1.1188799142837524,
      "learning_rate": 6.902573529411765e-06,
      "loss": 0.152,
      "step": 1504
    },
    {
      "epoch": 0.34581801470588236,
      "grad_norm": 1.2986276149749756,
      "learning_rate": 6.907169117647059e-06,
      "loss": 0.216,
      "step": 1505
    },
    {
      "epoch": 0.3460477941176471,
      "grad_norm": 1.3757404088974,
      "learning_rate": 6.911764705882353e-06,
      "loss": 0.1957,
      "step": 1506
    },
    {
      "epoch": 0.34627757352941174,
      "grad_norm": 0.985273003578186,
      "learning_rate": 6.9163602941176475e-06,
      "loss": 0.1998,
      "step": 1507
    },
    {
      "epoch": 0.34650735294117646,
      "grad_norm": 1.2330503463745117,
      "learning_rate": 6.920955882352942e-06,
      "loss": 0.1703,
      "step": 1508
    },
    {
      "epoch": 0.3467371323529412,
      "grad_norm": 2.0986275672912598,
      "learning_rate": 6.925551470588235e-06,
      "loss": 0.1783,
      "step": 1509
    },
    {
      "epoch": 0.3469669117647059,
      "grad_norm": 1.528634786605835,
      "learning_rate": 6.93014705882353e-06,
      "loss": 0.276,
      "step": 1510
    },
    {
      "epoch": 0.34719669117647056,
      "grad_norm": 1.3639391660690308,
      "learning_rate": 6.934742647058824e-06,
      "loss": 0.258,
      "step": 1511
    },
    {
      "epoch": 0.3474264705882353,
      "grad_norm": 0.9584101438522339,
      "learning_rate": 6.939338235294118e-06,
      "loss": 0.165,
      "step": 1512
    },
    {
      "epoch": 0.34765625,
      "grad_norm": 1.1489542722702026,
      "learning_rate": 6.943933823529412e-06,
      "loss": 0.2203,
      "step": 1513
    },
    {
      "epoch": 0.3478860294117647,
      "grad_norm": 2.0444648265838623,
      "learning_rate": 6.948529411764706e-06,
      "loss": 0.1488,
      "step": 1514
    },
    {
      "epoch": 0.34811580882352944,
      "grad_norm": 1.2217614650726318,
      "learning_rate": 6.9531250000000004e-06,
      "loss": 0.1892,
      "step": 1515
    },
    {
      "epoch": 0.3483455882352941,
      "grad_norm": 1.0857384204864502,
      "learning_rate": 6.957720588235295e-06,
      "loss": 0.154,
      "step": 1516
    },
    {
      "epoch": 0.3485753676470588,
      "grad_norm": 1.0076484680175781,
      "learning_rate": 6.962316176470589e-06,
      "loss": 0.1606,
      "step": 1517
    },
    {
      "epoch": 0.34880514705882354,
      "grad_norm": 1.2176259756088257,
      "learning_rate": 6.966911764705883e-06,
      "loss": 0.1452,
      "step": 1518
    },
    {
      "epoch": 0.34903492647058826,
      "grad_norm": 1.06914484500885,
      "learning_rate": 6.971507352941177e-06,
      "loss": 0.2195,
      "step": 1519
    },
    {
      "epoch": 0.3492647058823529,
      "grad_norm": 1.2899754047393799,
      "learning_rate": 6.976102941176471e-06,
      "loss": 0.1791,
      "step": 1520
    },
    {
      "epoch": 0.34949448529411764,
      "grad_norm": 1.083899974822998,
      "learning_rate": 6.980698529411766e-06,
      "loss": 0.1954,
      "step": 1521
    },
    {
      "epoch": 0.34972426470588236,
      "grad_norm": 1.3435487747192383,
      "learning_rate": 6.985294117647059e-06,
      "loss": 0.1613,
      "step": 1522
    },
    {
      "epoch": 0.3499540441176471,
      "grad_norm": 1.3709533214569092,
      "learning_rate": 6.989889705882353e-06,
      "loss": 0.2321,
      "step": 1523
    },
    {
      "epoch": 0.35018382352941174,
      "grad_norm": 0.9878000617027283,
      "learning_rate": 6.994485294117648e-06,
      "loss": 0.1675,
      "step": 1524
    },
    {
      "epoch": 0.35041360294117646,
      "grad_norm": 1.290483832359314,
      "learning_rate": 6.999080882352942e-06,
      "loss": 0.214,
      "step": 1525
    },
    {
      "epoch": 0.3506433823529412,
      "grad_norm": 1.2626595497131348,
      "learning_rate": 7.0036764705882355e-06,
      "loss": 0.1818,
      "step": 1526
    },
    {
      "epoch": 0.3508731617647059,
      "grad_norm": 1.069083571434021,
      "learning_rate": 7.00827205882353e-06,
      "loss": 0.1332,
      "step": 1527
    },
    {
      "epoch": 0.35110294117647056,
      "grad_norm": 1.0822229385375977,
      "learning_rate": 7.012867647058824e-06,
      "loss": 0.1771,
      "step": 1528
    },
    {
      "epoch": 0.3513327205882353,
      "grad_norm": 0.7534035444259644,
      "learning_rate": 7.0174632352941185e-06,
      "loss": 0.1405,
      "step": 1529
    },
    {
      "epoch": 0.3515625,
      "grad_norm": 1.1564611196517944,
      "learning_rate": 7.022058823529412e-06,
      "loss": 0.1864,
      "step": 1530
    },
    {
      "epoch": 0.3517922794117647,
      "grad_norm": 1.180435299873352,
      "learning_rate": 7.026654411764706e-06,
      "loss": 0.1564,
      "step": 1531
    },
    {
      "epoch": 0.35202205882352944,
      "grad_norm": 1.0187368392944336,
      "learning_rate": 7.031250000000001e-06,
      "loss": 0.1635,
      "step": 1532
    },
    {
      "epoch": 0.3522518382352941,
      "grad_norm": 1.2494630813598633,
      "learning_rate": 7.035845588235295e-06,
      "loss": 0.2299,
      "step": 1533
    },
    {
      "epoch": 0.3524816176470588,
      "grad_norm": 1.0373870134353638,
      "learning_rate": 7.040441176470589e-06,
      "loss": 0.223,
      "step": 1534
    },
    {
      "epoch": 0.35271139705882354,
      "grad_norm": 1.123706340789795,
      "learning_rate": 7.045036764705883e-06,
      "loss": 0.1419,
      "step": 1535
    },
    {
      "epoch": 0.35294117647058826,
      "grad_norm": 1.2685688734054565,
      "learning_rate": 7.049632352941177e-06,
      "loss": 0.196,
      "step": 1536
    },
    {
      "epoch": 0.3531709558823529,
      "grad_norm": 1.3954286575317383,
      "learning_rate": 7.0542279411764715e-06,
      "loss": 0.1703,
      "step": 1537
    },
    {
      "epoch": 0.35340073529411764,
      "grad_norm": 1.1873369216918945,
      "learning_rate": 7.058823529411766e-06,
      "loss": 0.183,
      "step": 1538
    },
    {
      "epoch": 0.35363051470588236,
      "grad_norm": 1.1240826845169067,
      "learning_rate": 7.063419117647059e-06,
      "loss": 0.2144,
      "step": 1539
    },
    {
      "epoch": 0.3538602941176471,
      "grad_norm": 0.994320273399353,
      "learning_rate": 7.068014705882354e-06,
      "loss": 0.1453,
      "step": 1540
    },
    {
      "epoch": 0.35409007352941174,
      "grad_norm": 1.264508843421936,
      "learning_rate": 7.072610294117648e-06,
      "loss": 0.2207,
      "step": 1541
    },
    {
      "epoch": 0.35431985294117646,
      "grad_norm": 1.593474268913269,
      "learning_rate": 7.077205882352942e-06,
      "loss": 0.2449,
      "step": 1542
    },
    {
      "epoch": 0.3545496323529412,
      "grad_norm": 0.9681248664855957,
      "learning_rate": 7.081801470588236e-06,
      "loss": 0.1663,
      "step": 1543
    },
    {
      "epoch": 0.3547794117647059,
      "grad_norm": 1.013457179069519,
      "learning_rate": 7.08639705882353e-06,
      "loss": 0.1472,
      "step": 1544
    },
    {
      "epoch": 0.35500919117647056,
      "grad_norm": 0.9261028170585632,
      "learning_rate": 7.090992647058824e-06,
      "loss": 0.1391,
      "step": 1545
    },
    {
      "epoch": 0.3552389705882353,
      "grad_norm": 1.4884265661239624,
      "learning_rate": 7.095588235294119e-06,
      "loss": 0.1984,
      "step": 1546
    },
    {
      "epoch": 0.35546875,
      "grad_norm": 1.1356170177459717,
      "learning_rate": 7.100183823529412e-06,
      "loss": 0.1974,
      "step": 1547
    },
    {
      "epoch": 0.3556985294117647,
      "grad_norm": 1.1635063886642456,
      "learning_rate": 7.1047794117647065e-06,
      "loss": 0.2234,
      "step": 1548
    },
    {
      "epoch": 0.35592830882352944,
      "grad_norm": 1.123862624168396,
      "learning_rate": 7.109375000000001e-06,
      "loss": 0.1657,
      "step": 1549
    },
    {
      "epoch": 0.3561580882352941,
      "grad_norm": 1.1272916793823242,
      "learning_rate": 7.113970588235295e-06,
      "loss": 0.1872,
      "step": 1550
    },
    {
      "epoch": 0.3563878676470588,
      "grad_norm": 1.3563857078552246,
      "learning_rate": 7.1185661764705895e-06,
      "loss": 0.1954,
      "step": 1551
    },
    {
      "epoch": 0.35661764705882354,
      "grad_norm": 0.9397929906845093,
      "learning_rate": 7.123161764705883e-06,
      "loss": 0.1949,
      "step": 1552
    },
    {
      "epoch": 0.35684742647058826,
      "grad_norm": 1.3562273979187012,
      "learning_rate": 7.127757352941177e-06,
      "loss": 0.1618,
      "step": 1553
    },
    {
      "epoch": 0.3570772058823529,
      "grad_norm": 1.2310576438903809,
      "learning_rate": 7.132352941176472e-06,
      "loss": 0.1614,
      "step": 1554
    },
    {
      "epoch": 0.35730698529411764,
      "grad_norm": 1.4591585397720337,
      "learning_rate": 7.136948529411766e-06,
      "loss": 0.1802,
      "step": 1555
    },
    {
      "epoch": 0.35753676470588236,
      "grad_norm": 1.1200908422470093,
      "learning_rate": 7.141544117647059e-06,
      "loss": 0.1719,
      "step": 1556
    },
    {
      "epoch": 0.3577665441176471,
      "grad_norm": 0.8748902082443237,
      "learning_rate": 7.146139705882354e-06,
      "loss": 0.1441,
      "step": 1557
    },
    {
      "epoch": 0.35799632352941174,
      "grad_norm": 1.0917567014694214,
      "learning_rate": 7.150735294117648e-06,
      "loss": 0.1671,
      "step": 1558
    },
    {
      "epoch": 0.35822610294117646,
      "grad_norm": 1.260920524597168,
      "learning_rate": 7.1553308823529425e-06,
      "loss": 0.1921,
      "step": 1559
    },
    {
      "epoch": 0.3584558823529412,
      "grad_norm": 1.1192560195922852,
      "learning_rate": 7.159926470588235e-06,
      "loss": 0.1625,
      "step": 1560
    },
    {
      "epoch": 0.3586856617647059,
      "grad_norm": 1.3446904420852661,
      "learning_rate": 7.164522058823529e-06,
      "loss": 0.2003,
      "step": 1561
    },
    {
      "epoch": 0.35891544117647056,
      "grad_norm": 1.5237987041473389,
      "learning_rate": 7.169117647058825e-06,
      "loss": 0.1955,
      "step": 1562
    },
    {
      "epoch": 0.3591452205882353,
      "grad_norm": 1.8548049926757812,
      "learning_rate": 7.173713235294119e-06,
      "loss": 0.2263,
      "step": 1563
    },
    {
      "epoch": 0.359375,
      "grad_norm": 1.3525737524032593,
      "learning_rate": 7.1783088235294116e-06,
      "loss": 0.1714,
      "step": 1564
    },
    {
      "epoch": 0.3596047794117647,
      "grad_norm": 1.1126033067703247,
      "learning_rate": 7.182904411764706e-06,
      "loss": 0.1987,
      "step": 1565
    },
    {
      "epoch": 0.35983455882352944,
      "grad_norm": 0.9755445718765259,
      "learning_rate": 7.1875e-06,
      "loss": 0.1518,
      "step": 1566
    },
    {
      "epoch": 0.3600643382352941,
      "grad_norm": 1.1634373664855957,
      "learning_rate": 7.1920955882352945e-06,
      "loss": 0.1417,
      "step": 1567
    },
    {
      "epoch": 0.3602941176470588,
      "grad_norm": 1.2125155925750732,
      "learning_rate": 7.19669117647059e-06,
      "loss": 0.2002,
      "step": 1568
    },
    {
      "epoch": 0.36052389705882354,
      "grad_norm": 1.416995882987976,
      "learning_rate": 7.201286764705882e-06,
      "loss": 0.2302,
      "step": 1569
    },
    {
      "epoch": 0.36075367647058826,
      "grad_norm": 1.2351475954055786,
      "learning_rate": 7.205882352941177e-06,
      "loss": 0.2271,
      "step": 1570
    },
    {
      "epoch": 0.3609834558823529,
      "grad_norm": 1.1047147512435913,
      "learning_rate": 7.210477941176471e-06,
      "loss": 0.1826,
      "step": 1571
    },
    {
      "epoch": 0.36121323529411764,
      "grad_norm": 1.3307169675827026,
      "learning_rate": 7.215073529411765e-06,
      "loss": 0.1999,
      "step": 1572
    },
    {
      "epoch": 0.36144301470588236,
      "grad_norm": 1.1470781564712524,
      "learning_rate": 7.219669117647059e-06,
      "loss": 0.2124,
      "step": 1573
    },
    {
      "epoch": 0.3616727941176471,
      "grad_norm": 1.0616272687911987,
      "learning_rate": 7.224264705882353e-06,
      "loss": 0.1688,
      "step": 1574
    },
    {
      "epoch": 0.36190257352941174,
      "grad_norm": 1.0809520483016968,
      "learning_rate": 7.2288602941176475e-06,
      "loss": 0.2289,
      "step": 1575
    },
    {
      "epoch": 0.36213235294117646,
      "grad_norm": 1.0565149784088135,
      "learning_rate": 7.233455882352942e-06,
      "loss": 0.1809,
      "step": 1576
    },
    {
      "epoch": 0.3623621323529412,
      "grad_norm": 1.0259863138198853,
      "learning_rate": 7.238051470588235e-06,
      "loss": 0.1399,
      "step": 1577
    },
    {
      "epoch": 0.3625919117647059,
      "grad_norm": 1.0935195684432983,
      "learning_rate": 7.24264705882353e-06,
      "loss": 0.1821,
      "step": 1578
    },
    {
      "epoch": 0.36282169117647056,
      "grad_norm": 1.3600528240203857,
      "learning_rate": 7.247242647058824e-06,
      "loss": 0.1706,
      "step": 1579
    },
    {
      "epoch": 0.3630514705882353,
      "grad_norm": 1.0779131650924683,
      "learning_rate": 7.251838235294118e-06,
      "loss": 0.1437,
      "step": 1580
    },
    {
      "epoch": 0.36328125,
      "grad_norm": 1.3471969366073608,
      "learning_rate": 7.256433823529412e-06,
      "loss": 0.1589,
      "step": 1581
    },
    {
      "epoch": 0.3635110294117647,
      "grad_norm": 0.9025452733039856,
      "learning_rate": 7.261029411764706e-06,
      "loss": 0.1881,
      "step": 1582
    },
    {
      "epoch": 0.36374080882352944,
      "grad_norm": 1.0742543935775757,
      "learning_rate": 7.265625e-06,
      "loss": 0.1628,
      "step": 1583
    },
    {
      "epoch": 0.3639705882352941,
      "grad_norm": 1.2773932218551636,
      "learning_rate": 7.270220588235295e-06,
      "loss": 0.2314,
      "step": 1584
    },
    {
      "epoch": 0.3642003676470588,
      "grad_norm": 1.064192771911621,
      "learning_rate": 7.274816176470589e-06,
      "loss": 0.1587,
      "step": 1585
    },
    {
      "epoch": 0.36443014705882354,
      "grad_norm": 0.9689310193061829,
      "learning_rate": 7.2794117647058826e-06,
      "loss": 0.1479,
      "step": 1586
    },
    {
      "epoch": 0.36465992647058826,
      "grad_norm": 1.0368130207061768,
      "learning_rate": 7.284007352941177e-06,
      "loss": 0.1453,
      "step": 1587
    },
    {
      "epoch": 0.3648897058823529,
      "grad_norm": 1.1320621967315674,
      "learning_rate": 7.288602941176471e-06,
      "loss": 0.1787,
      "step": 1588
    },
    {
      "epoch": 0.36511948529411764,
      "grad_norm": 1.1242127418518066,
      "learning_rate": 7.2931985294117655e-06,
      "loss": 0.163,
      "step": 1589
    },
    {
      "epoch": 0.36534926470588236,
      "grad_norm": 1.2009471654891968,
      "learning_rate": 7.297794117647059e-06,
      "loss": 0.1253,
      "step": 1590
    },
    {
      "epoch": 0.3655790441176471,
      "grad_norm": 1.2890452146530151,
      "learning_rate": 7.302389705882353e-06,
      "loss": 0.1772,
      "step": 1591
    },
    {
      "epoch": 0.36580882352941174,
      "grad_norm": 1.1659812927246094,
      "learning_rate": 7.306985294117648e-06,
      "loss": 0.1985,
      "step": 1592
    },
    {
      "epoch": 0.36603860294117646,
      "grad_norm": 1.0906766653060913,
      "learning_rate": 7.311580882352942e-06,
      "loss": 0.189,
      "step": 1593
    },
    {
      "epoch": 0.3662683823529412,
      "grad_norm": 1.3517277240753174,
      "learning_rate": 7.3161764705882355e-06,
      "loss": 0.2092,
      "step": 1594
    },
    {
      "epoch": 0.3664981617647059,
      "grad_norm": 1.4810850620269775,
      "learning_rate": 7.32077205882353e-06,
      "loss": 0.1871,
      "step": 1595
    },
    {
      "epoch": 0.36672794117647056,
      "grad_norm": 1.385274887084961,
      "learning_rate": 7.325367647058824e-06,
      "loss": 0.2101,
      "step": 1596
    },
    {
      "epoch": 0.3669577205882353,
      "grad_norm": 0.9490074515342712,
      "learning_rate": 7.3299632352941185e-06,
      "loss": 0.1914,
      "step": 1597
    },
    {
      "epoch": 0.3671875,
      "grad_norm": 1.2750563621520996,
      "learning_rate": 7.334558823529412e-06,
      "loss": 0.2354,
      "step": 1598
    },
    {
      "epoch": 0.3674172794117647,
      "grad_norm": 1.329746961593628,
      "learning_rate": 7.339154411764706e-06,
      "loss": 0.2071,
      "step": 1599
    },
    {
      "epoch": 0.36764705882352944,
      "grad_norm": 1.059257984161377,
      "learning_rate": 7.343750000000001e-06,
      "loss": 0.1916,
      "step": 1600
    },
    {
      "epoch": 0.3678768382352941,
      "grad_norm": 1.0456990003585815,
      "learning_rate": 7.348345588235295e-06,
      "loss": 0.1206,
      "step": 1601
    },
    {
      "epoch": 0.3681066176470588,
      "grad_norm": 1.204284906387329,
      "learning_rate": 7.352941176470589e-06,
      "loss": 0.1449,
      "step": 1602
    },
    {
      "epoch": 0.36833639705882354,
      "grad_norm": 0.9686185121536255,
      "learning_rate": 7.357536764705883e-06,
      "loss": 0.1732,
      "step": 1603
    },
    {
      "epoch": 0.36856617647058826,
      "grad_norm": 1.0846285820007324,
      "learning_rate": 7.362132352941177e-06,
      "loss": 0.1306,
      "step": 1604
    },
    {
      "epoch": 0.3687959558823529,
      "grad_norm": 1.0291372537612915,
      "learning_rate": 7.3667279411764714e-06,
      "loss": 0.1637,
      "step": 1605
    },
    {
      "epoch": 0.36902573529411764,
      "grad_norm": 1.2344119548797607,
      "learning_rate": 7.371323529411766e-06,
      "loss": 0.2016,
      "step": 1606
    },
    {
      "epoch": 0.36925551470588236,
      "grad_norm": 1.2532223463058472,
      "learning_rate": 7.375919117647059e-06,
      "loss": 0.1921,
      "step": 1607
    },
    {
      "epoch": 0.3694852941176471,
      "grad_norm": 1.2302742004394531,
      "learning_rate": 7.3805147058823536e-06,
      "loss": 0.1478,
      "step": 1608
    },
    {
      "epoch": 0.36971507352941174,
      "grad_norm": 1.3987408876419067,
      "learning_rate": 7.385110294117648e-06,
      "loss": 0.1668,
      "step": 1609
    },
    {
      "epoch": 0.36994485294117646,
      "grad_norm": 1.1889516115188599,
      "learning_rate": 7.389705882352942e-06,
      "loss": 0.1664,
      "step": 1610
    },
    {
      "epoch": 0.3701746323529412,
      "grad_norm": 1.301619529724121,
      "learning_rate": 7.394301470588236e-06,
      "loss": 0.19,
      "step": 1611
    },
    {
      "epoch": 0.3704044117647059,
      "grad_norm": 1.3136208057403564,
      "learning_rate": 7.39889705882353e-06,
      "loss": 0.1552,
      "step": 1612
    },
    {
      "epoch": 0.37063419117647056,
      "grad_norm": 1.3039551973342896,
      "learning_rate": 7.403492647058824e-06,
      "loss": 0.1541,
      "step": 1613
    },
    {
      "epoch": 0.3708639705882353,
      "grad_norm": 0.844816267490387,
      "learning_rate": 7.408088235294119e-06,
      "loss": 0.158,
      "step": 1614
    },
    {
      "epoch": 0.37109375,
      "grad_norm": 0.9959018230438232,
      "learning_rate": 7.412683823529412e-06,
      "loss": 0.1668,
      "step": 1615
    },
    {
      "epoch": 0.3713235294117647,
      "grad_norm": 1.1650348901748657,
      "learning_rate": 7.4172794117647065e-06,
      "loss": 0.2259,
      "step": 1616
    },
    {
      "epoch": 0.37155330882352944,
      "grad_norm": 1.4351154565811157,
      "learning_rate": 7.421875000000001e-06,
      "loss": 0.2224,
      "step": 1617
    },
    {
      "epoch": 0.3717830882352941,
      "grad_norm": 1.1398794651031494,
      "learning_rate": 7.426470588235295e-06,
      "loss": 0.1713,
      "step": 1618
    },
    {
      "epoch": 0.3720128676470588,
      "grad_norm": 1.1602044105529785,
      "learning_rate": 7.4310661764705895e-06,
      "loss": 0.119,
      "step": 1619
    },
    {
      "epoch": 0.37224264705882354,
      "grad_norm": 1.4160635471343994,
      "learning_rate": 7.435661764705883e-06,
      "loss": 0.1892,
      "step": 1620
    },
    {
      "epoch": 0.37247242647058826,
      "grad_norm": 0.9334721565246582,
      "learning_rate": 7.440257352941177e-06,
      "loss": 0.1875,
      "step": 1621
    },
    {
      "epoch": 0.3727022058823529,
      "grad_norm": 1.195073127746582,
      "learning_rate": 7.444852941176472e-06,
      "loss": 0.1982,
      "step": 1622
    },
    {
      "epoch": 0.37293198529411764,
      "grad_norm": 1.0278325080871582,
      "learning_rate": 7.449448529411766e-06,
      "loss": 0.1586,
      "step": 1623
    },
    {
      "epoch": 0.37316176470588236,
      "grad_norm": 0.9360179901123047,
      "learning_rate": 7.4540441176470594e-06,
      "loss": 0.1637,
      "step": 1624
    },
    {
      "epoch": 0.3733915441176471,
      "grad_norm": 1.2571278810501099,
      "learning_rate": 7.458639705882354e-06,
      "loss": 0.1909,
      "step": 1625
    },
    {
      "epoch": 0.37362132352941174,
      "grad_norm": 1.0353792905807495,
      "learning_rate": 7.463235294117648e-06,
      "loss": 0.1739,
      "step": 1626
    },
    {
      "epoch": 0.37385110294117646,
      "grad_norm": 1.1173948049545288,
      "learning_rate": 7.4678308823529424e-06,
      "loss": 0.1196,
      "step": 1627
    },
    {
      "epoch": 0.3740808823529412,
      "grad_norm": 1.0649936199188232,
      "learning_rate": 7.472426470588235e-06,
      "loss": 0.17,
      "step": 1628
    },
    {
      "epoch": 0.3743106617647059,
      "grad_norm": 1.3557941913604736,
      "learning_rate": 7.47702205882353e-06,
      "loss": 0.1906,
      "step": 1629
    },
    {
      "epoch": 0.37454044117647056,
      "grad_norm": 0.9761610627174377,
      "learning_rate": 7.4816176470588246e-06,
      "loss": 0.1733,
      "step": 1630
    },
    {
      "epoch": 0.3747702205882353,
      "grad_norm": 0.9544889330863953,
      "learning_rate": 7.486213235294119e-06,
      "loss": 0.1488,
      "step": 1631
    },
    {
      "epoch": 0.375,
      "grad_norm": 1.0184985399246216,
      "learning_rate": 7.4908088235294115e-06,
      "loss": 0.1691,
      "step": 1632
    },
    {
      "epoch": 0.3752297794117647,
      "grad_norm": 1.2095047235488892,
      "learning_rate": 7.495404411764706e-06,
      "loss": 0.2051,
      "step": 1633
    },
    {
      "epoch": 0.37545955882352944,
      "grad_norm": 1.0992649793624878,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.1456,
      "step": 1634
    },
    {
      "epoch": 0.3756893382352941,
      "grad_norm": 1.1741306781768799,
      "learning_rate": 7.504595588235295e-06,
      "loss": 0.1249,
      "step": 1635
    },
    {
      "epoch": 0.3759191176470588,
      "grad_norm": 1.0710744857788086,
      "learning_rate": 7.50919117647059e-06,
      "loss": 0.1976,
      "step": 1636
    },
    {
      "epoch": 0.37614889705882354,
      "grad_norm": 1.112269639968872,
      "learning_rate": 7.513786764705882e-06,
      "loss": 0.2051,
      "step": 1637
    },
    {
      "epoch": 0.37637867647058826,
      "grad_norm": 1.485053300857544,
      "learning_rate": 7.518382352941177e-06,
      "loss": 0.2322,
      "step": 1638
    },
    {
      "epoch": 0.3766084558823529,
      "grad_norm": 1.220598578453064,
      "learning_rate": 7.522977941176471e-06,
      "loss": 0.1808,
      "step": 1639
    },
    {
      "epoch": 0.37683823529411764,
      "grad_norm": 1.1250839233398438,
      "learning_rate": 7.527573529411766e-06,
      "loss": 0.1618,
      "step": 1640
    },
    {
      "epoch": 0.37706801470588236,
      "grad_norm": 1.18961763381958,
      "learning_rate": 7.532169117647059e-06,
      "loss": 0.0942,
      "step": 1641
    },
    {
      "epoch": 0.3772977941176471,
      "grad_norm": 1.042400598526001,
      "learning_rate": 7.536764705882353e-06,
      "loss": 0.1741,
      "step": 1642
    },
    {
      "epoch": 0.37752757352941174,
      "grad_norm": 1.0207277536392212,
      "learning_rate": 7.5413602941176475e-06,
      "loss": 0.1267,
      "step": 1643
    },
    {
      "epoch": 0.37775735294117646,
      "grad_norm": 0.8920422196388245,
      "learning_rate": 7.545955882352942e-06,
      "loss": 0.173,
      "step": 1644
    },
    {
      "epoch": 0.3779871323529412,
      "grad_norm": 1.0076028108596802,
      "learning_rate": 7.550551470588235e-06,
      "loss": 0.157,
      "step": 1645
    },
    {
      "epoch": 0.3782169117647059,
      "grad_norm": 0.951123058795929,
      "learning_rate": 7.55514705882353e-06,
      "loss": 0.1704,
      "step": 1646
    },
    {
      "epoch": 0.37844669117647056,
      "grad_norm": 0.907531201839447,
      "learning_rate": 7.559742647058824e-06,
      "loss": 0.1616,
      "step": 1647
    },
    {
      "epoch": 0.3786764705882353,
      "grad_norm": 1.2022731304168701,
      "learning_rate": 7.564338235294118e-06,
      "loss": 0.1958,
      "step": 1648
    },
    {
      "epoch": 0.37890625,
      "grad_norm": 1.2657356262207031,
      "learning_rate": 7.568933823529412e-06,
      "loss": 0.1622,
      "step": 1649
    },
    {
      "epoch": 0.3791360294117647,
      "grad_norm": 1.2053043842315674,
      "learning_rate": 7.573529411764706e-06,
      "loss": 0.1319,
      "step": 1650
    },
    {
      "epoch": 0.37936580882352944,
      "grad_norm": 1.2643285989761353,
      "learning_rate": 7.578125e-06,
      "loss": 0.123,
      "step": 1651
    },
    {
      "epoch": 0.3795955882352941,
      "grad_norm": 1.1064281463623047,
      "learning_rate": 7.582720588235295e-06,
      "loss": 0.1707,
      "step": 1652
    },
    {
      "epoch": 0.3798253676470588,
      "grad_norm": 1.1395665407180786,
      "learning_rate": 7.587316176470589e-06,
      "loss": 0.1404,
      "step": 1653
    },
    {
      "epoch": 0.38005514705882354,
      "grad_norm": 1.0438992977142334,
      "learning_rate": 7.5919117647058825e-06,
      "loss": 0.1516,
      "step": 1654
    },
    {
      "epoch": 0.38028492647058826,
      "grad_norm": 1.2106654644012451,
      "learning_rate": 7.596507352941177e-06,
      "loss": 0.1749,
      "step": 1655
    },
    {
      "epoch": 0.3805147058823529,
      "grad_norm": 1.436216950416565,
      "learning_rate": 7.601102941176471e-06,
      "loss": 0.1781,
      "step": 1656
    },
    {
      "epoch": 0.38074448529411764,
      "grad_norm": 1.2439448833465576,
      "learning_rate": 7.6056985294117655e-06,
      "loss": 0.1918,
      "step": 1657
    },
    {
      "epoch": 0.38097426470588236,
      "grad_norm": 1.1403597593307495,
      "learning_rate": 7.610294117647059e-06,
      "loss": 0.166,
      "step": 1658
    },
    {
      "epoch": 0.3812040441176471,
      "grad_norm": 0.9707164168357849,
      "learning_rate": 7.614889705882353e-06,
      "loss": 0.1869,
      "step": 1659
    },
    {
      "epoch": 0.38143382352941174,
      "grad_norm": 1.5111489295959473,
      "learning_rate": 7.619485294117648e-06,
      "loss": 0.2057,
      "step": 1660
    },
    {
      "epoch": 0.38166360294117646,
      "grad_norm": 1.2196334600448608,
      "learning_rate": 7.624080882352942e-06,
      "loss": 0.1105,
      "step": 1661
    },
    {
      "epoch": 0.3818933823529412,
      "grad_norm": 1.2928738594055176,
      "learning_rate": 7.6286764705882355e-06,
      "loss": 0.1241,
      "step": 1662
    },
    {
      "epoch": 0.3821231617647059,
      "grad_norm": 0.9542847275733948,
      "learning_rate": 7.63327205882353e-06,
      "loss": 0.1661,
      "step": 1663
    },
    {
      "epoch": 0.38235294117647056,
      "grad_norm": 1.2319345474243164,
      "learning_rate": 7.637867647058824e-06,
      "loss": 0.1665,
      "step": 1664
    },
    {
      "epoch": 0.3825827205882353,
      "grad_norm": 1.2495701313018799,
      "learning_rate": 7.642463235294118e-06,
      "loss": 0.1572,
      "step": 1665
    },
    {
      "epoch": 0.3828125,
      "grad_norm": 1.350714087486267,
      "learning_rate": 7.647058823529411e-06,
      "loss": 0.1954,
      "step": 1666
    },
    {
      "epoch": 0.3830422794117647,
      "grad_norm": 0.9661955237388611,
      "learning_rate": 7.651654411764705e-06,
      "loss": 0.1572,
      "step": 1667
    },
    {
      "epoch": 0.38327205882352944,
      "grad_norm": 0.8760025501251221,
      "learning_rate": 7.656250000000001e-06,
      "loss": 0.1584,
      "step": 1668
    },
    {
      "epoch": 0.3835018382352941,
      "grad_norm": 1.2013860940933228,
      "learning_rate": 7.660845588235296e-06,
      "loss": 0.1805,
      "step": 1669
    },
    {
      "epoch": 0.3837316176470588,
      "grad_norm": 1.5085793733596802,
      "learning_rate": 7.66544117647059e-06,
      "loss": 0.1758,
      "step": 1670
    },
    {
      "epoch": 0.38396139705882354,
      "grad_norm": 1.2823243141174316,
      "learning_rate": 7.670036764705883e-06,
      "loss": 0.1653,
      "step": 1671
    },
    {
      "epoch": 0.38419117647058826,
      "grad_norm": 1.108772873878479,
      "learning_rate": 7.674632352941177e-06,
      "loss": 0.1283,
      "step": 1672
    },
    {
      "epoch": 0.3844209558823529,
      "grad_norm": 1.4870344400405884,
      "learning_rate": 7.679227941176471e-06,
      "loss": 0.1896,
      "step": 1673
    },
    {
      "epoch": 0.38465073529411764,
      "grad_norm": 1.2431780099868774,
      "learning_rate": 7.683823529411766e-06,
      "loss": 0.156,
      "step": 1674
    },
    {
      "epoch": 0.38488051470588236,
      "grad_norm": 1.4261411428451538,
      "learning_rate": 7.688419117647058e-06,
      "loss": 0.1818,
      "step": 1675
    },
    {
      "epoch": 0.3851102941176471,
      "grad_norm": 1.1296597719192505,
      "learning_rate": 7.693014705882353e-06,
      "loss": 0.1513,
      "step": 1676
    },
    {
      "epoch": 0.38534007352941174,
      "grad_norm": 1.3809093236923218,
      "learning_rate": 7.697610294117647e-06,
      "loss": 0.1248,
      "step": 1677
    },
    {
      "epoch": 0.38556985294117646,
      "grad_norm": 1.181549310684204,
      "learning_rate": 7.702205882352943e-06,
      "loss": 0.1648,
      "step": 1678
    },
    {
      "epoch": 0.3857996323529412,
      "grad_norm": 1.199495553970337,
      "learning_rate": 7.706801470588236e-06,
      "loss": 0.1723,
      "step": 1679
    },
    {
      "epoch": 0.3860294117647059,
      "grad_norm": 0.9968592524528503,
      "learning_rate": 7.71139705882353e-06,
      "loss": 0.1265,
      "step": 1680
    },
    {
      "epoch": 0.38625919117647056,
      "grad_norm": 1.3760584592819214,
      "learning_rate": 7.715992647058824e-06,
      "loss": 0.1108,
      "step": 1681
    },
    {
      "epoch": 0.3864889705882353,
      "grad_norm": 0.8607680797576904,
      "learning_rate": 7.720588235294119e-06,
      "loss": 0.1249,
      "step": 1682
    },
    {
      "epoch": 0.38671875,
      "grad_norm": 1.4692203998565674,
      "learning_rate": 7.725183823529411e-06,
      "loss": 0.1802,
      "step": 1683
    },
    {
      "epoch": 0.3869485294117647,
      "grad_norm": 1.0648623704910278,
      "learning_rate": 7.729779411764706e-06,
      "loss": 0.1496,
      "step": 1684
    },
    {
      "epoch": 0.38717830882352944,
      "grad_norm": 0.8171228766441345,
      "learning_rate": 7.734375e-06,
      "loss": 0.1475,
      "step": 1685
    },
    {
      "epoch": 0.3874080882352941,
      "grad_norm": 1.4051192998886108,
      "learning_rate": 7.738970588235294e-06,
      "loss": 0.1972,
      "step": 1686
    },
    {
      "epoch": 0.3876378676470588,
      "grad_norm": 1.5027657747268677,
      "learning_rate": 7.743566176470589e-06,
      "loss": 0.2059,
      "step": 1687
    },
    {
      "epoch": 0.38786764705882354,
      "grad_norm": 0.8850800395011902,
      "learning_rate": 7.748161764705883e-06,
      "loss": 0.1577,
      "step": 1688
    },
    {
      "epoch": 0.38809742647058826,
      "grad_norm": 1.0599160194396973,
      "learning_rate": 7.752757352941177e-06,
      "loss": 0.1351,
      "step": 1689
    },
    {
      "epoch": 0.3883272058823529,
      "grad_norm": 1.068963885307312,
      "learning_rate": 7.757352941176472e-06,
      "loss": 0.1833,
      "step": 1690
    },
    {
      "epoch": 0.38855698529411764,
      "grad_norm": 1.0935696363449097,
      "learning_rate": 7.761948529411766e-06,
      "loss": 0.1749,
      "step": 1691
    },
    {
      "epoch": 0.38878676470588236,
      "grad_norm": 1.1706674098968506,
      "learning_rate": 7.766544117647059e-06,
      "loss": 0.1933,
      "step": 1692
    },
    {
      "epoch": 0.3890165441176471,
      "grad_norm": 1.1038920879364014,
      "learning_rate": 7.771139705882353e-06,
      "loss": 0.1598,
      "step": 1693
    },
    {
      "epoch": 0.38924632352941174,
      "grad_norm": 1.0499296188354492,
      "learning_rate": 7.775735294117647e-06,
      "loss": 0.1582,
      "step": 1694
    },
    {
      "epoch": 0.38947610294117646,
      "grad_norm": 1.2121611833572388,
      "learning_rate": 7.780330882352942e-06,
      "loss": 0.1809,
      "step": 1695
    },
    {
      "epoch": 0.3897058823529412,
      "grad_norm": 0.90632164478302,
      "learning_rate": 7.784926470588236e-06,
      "loss": 0.1638,
      "step": 1696
    },
    {
      "epoch": 0.3899356617647059,
      "grad_norm": 1.2081613540649414,
      "learning_rate": 7.78952205882353e-06,
      "loss": 0.1788,
      "step": 1697
    },
    {
      "epoch": 0.39016544117647056,
      "grad_norm": 1.1481963396072388,
      "learning_rate": 7.794117647058825e-06,
      "loss": 0.1932,
      "step": 1698
    },
    {
      "epoch": 0.3903952205882353,
      "grad_norm": 1.4447364807128906,
      "learning_rate": 7.798713235294119e-06,
      "loss": 0.146,
      "step": 1699
    },
    {
      "epoch": 0.390625,
      "grad_norm": 1.2135244607925415,
      "learning_rate": 7.803308823529412e-06,
      "loss": 0.1827,
      "step": 1700
    },
    {
      "epoch": 0.3908547794117647,
      "grad_norm": 1.184043526649475,
      "learning_rate": 7.807904411764706e-06,
      "loss": 0.1874,
      "step": 1701
    },
    {
      "epoch": 0.39108455882352944,
      "grad_norm": 1.1118940114974976,
      "learning_rate": 7.8125e-06,
      "loss": 0.1387,
      "step": 1702
    },
    {
      "epoch": 0.3913143382352941,
      "grad_norm": 1.454012155532837,
      "learning_rate": 7.817095588235294e-06,
      "loss": 0.188,
      "step": 1703
    },
    {
      "epoch": 0.3915441176470588,
      "grad_norm": 0.9917290210723877,
      "learning_rate": 7.821691176470589e-06,
      "loss": 0.11,
      "step": 1704
    },
    {
      "epoch": 0.39177389705882354,
      "grad_norm": 1.2195690870285034,
      "learning_rate": 7.826286764705883e-06,
      "loss": 0.1544,
      "step": 1705
    },
    {
      "epoch": 0.39200367647058826,
      "grad_norm": 1.0945041179656982,
      "learning_rate": 7.830882352941177e-06,
      "loss": 0.1296,
      "step": 1706
    },
    {
      "epoch": 0.3922334558823529,
      "grad_norm": 0.936523973941803,
      "learning_rate": 7.835477941176472e-06,
      "loss": 0.1765,
      "step": 1707
    },
    {
      "epoch": 0.39246323529411764,
      "grad_norm": 1.2047141790390015,
      "learning_rate": 7.840073529411766e-06,
      "loss": 0.2088,
      "step": 1708
    },
    {
      "epoch": 0.39269301470588236,
      "grad_norm": 0.9445161819458008,
      "learning_rate": 7.844669117647059e-06,
      "loss": 0.1495,
      "step": 1709
    },
    {
      "epoch": 0.3929227941176471,
      "grad_norm": 1.3866573572158813,
      "learning_rate": 7.849264705882353e-06,
      "loss": 0.1443,
      "step": 1710
    },
    {
      "epoch": 0.39315257352941174,
      "grad_norm": 1.051783800125122,
      "learning_rate": 7.853860294117647e-06,
      "loss": 0.1636,
      "step": 1711
    },
    {
      "epoch": 0.39338235294117646,
      "grad_norm": 1.5190788507461548,
      "learning_rate": 7.858455882352942e-06,
      "loss": 0.1879,
      "step": 1712
    },
    {
      "epoch": 0.3936121323529412,
      "grad_norm": 1.3272069692611694,
      "learning_rate": 7.863051470588236e-06,
      "loss": 0.1487,
      "step": 1713
    },
    {
      "epoch": 0.3938419117647059,
      "grad_norm": 1.1299103498458862,
      "learning_rate": 7.86764705882353e-06,
      "loss": 0.1431,
      "step": 1714
    },
    {
      "epoch": 0.39407169117647056,
      "grad_norm": 1.022826910018921,
      "learning_rate": 7.872242647058825e-06,
      "loss": 0.1251,
      "step": 1715
    },
    {
      "epoch": 0.3943014705882353,
      "grad_norm": 0.9509928226470947,
      "learning_rate": 7.876838235294119e-06,
      "loss": 0.1468,
      "step": 1716
    },
    {
      "epoch": 0.39453125,
      "grad_norm": 1.6115366220474243,
      "learning_rate": 7.881433823529412e-06,
      "loss": 0.1932,
      "step": 1717
    },
    {
      "epoch": 0.3947610294117647,
      "grad_norm": 1.2181254625320435,
      "learning_rate": 7.886029411764706e-06,
      "loss": 0.1423,
      "step": 1718
    },
    {
      "epoch": 0.39499080882352944,
      "grad_norm": 1.254597783088684,
      "learning_rate": 7.890625e-06,
      "loss": 0.1862,
      "step": 1719
    },
    {
      "epoch": 0.3952205882352941,
      "grad_norm": 1.1509917974472046,
      "learning_rate": 7.895220588235295e-06,
      "loss": 0.146,
      "step": 1720
    },
    {
      "epoch": 0.3954503676470588,
      "grad_norm": 1.402480125427246,
      "learning_rate": 7.899816176470589e-06,
      "loss": 0.1149,
      "step": 1721
    },
    {
      "epoch": 0.39568014705882354,
      "grad_norm": 1.3804420232772827,
      "learning_rate": 7.904411764705883e-06,
      "loss": 0.1548,
      "step": 1722
    },
    {
      "epoch": 0.39590992647058826,
      "grad_norm": 1.3425118923187256,
      "learning_rate": 7.909007352941178e-06,
      "loss": 0.1733,
      "step": 1723
    },
    {
      "epoch": 0.3961397058823529,
      "grad_norm": 1.10173761844635,
      "learning_rate": 7.913602941176472e-06,
      "loss": 0.1394,
      "step": 1724
    },
    {
      "epoch": 0.39636948529411764,
      "grad_norm": 1.1946449279785156,
      "learning_rate": 7.918198529411766e-06,
      "loss": 0.1996,
      "step": 1725
    },
    {
      "epoch": 0.39659926470588236,
      "grad_norm": 1.2568823099136353,
      "learning_rate": 7.922794117647059e-06,
      "loss": 0.1753,
      "step": 1726
    },
    {
      "epoch": 0.3968290441176471,
      "grad_norm": 1.0952332019805908,
      "learning_rate": 7.927389705882353e-06,
      "loss": 0.1785,
      "step": 1727
    },
    {
      "epoch": 0.39705882352941174,
      "grad_norm": 1.230701208114624,
      "learning_rate": 7.931985294117648e-06,
      "loss": 0.1377,
      "step": 1728
    },
    {
      "epoch": 0.39728860294117646,
      "grad_norm": 1.073627233505249,
      "learning_rate": 7.936580882352942e-06,
      "loss": 0.1534,
      "step": 1729
    },
    {
      "epoch": 0.3975183823529412,
      "grad_norm": 1.037514090538025,
      "learning_rate": 7.941176470588236e-06,
      "loss": 0.1626,
      "step": 1730
    },
    {
      "epoch": 0.3977481617647059,
      "grad_norm": 1.4455602169036865,
      "learning_rate": 7.94577205882353e-06,
      "loss": 0.1478,
      "step": 1731
    },
    {
      "epoch": 0.39797794117647056,
      "grad_norm": 1.2880322933197021,
      "learning_rate": 7.950367647058825e-06,
      "loss": 0.1532,
      "step": 1732
    },
    {
      "epoch": 0.3982077205882353,
      "grad_norm": 1.3931517601013184,
      "learning_rate": 7.95496323529412e-06,
      "loss": 0.2278,
      "step": 1733
    },
    {
      "epoch": 0.3984375,
      "grad_norm": 1.1497899293899536,
      "learning_rate": 7.959558823529412e-06,
      "loss": 0.1436,
      "step": 1734
    },
    {
      "epoch": 0.3986672794117647,
      "grad_norm": 1.4667822122573853,
      "learning_rate": 7.964154411764706e-06,
      "loss": 0.1882,
      "step": 1735
    },
    {
      "epoch": 0.39889705882352944,
      "grad_norm": 0.9459007978439331,
      "learning_rate": 7.96875e-06,
      "loss": 0.1262,
      "step": 1736
    },
    {
      "epoch": 0.3991268382352941,
      "grad_norm": 0.9300460815429688,
      "learning_rate": 7.973345588235295e-06,
      "loss": 0.1644,
      "step": 1737
    },
    {
      "epoch": 0.3993566176470588,
      "grad_norm": 1.1437269449234009,
      "learning_rate": 7.97794117647059e-06,
      "loss": 0.1296,
      "step": 1738
    },
    {
      "epoch": 0.39958639705882354,
      "grad_norm": 1.4646481275558472,
      "learning_rate": 7.982536764705882e-06,
      "loss": 0.14,
      "step": 1739
    },
    {
      "epoch": 0.39981617647058826,
      "grad_norm": 1.6794493198394775,
      "learning_rate": 7.987132352941178e-06,
      "loss": 0.1638,
      "step": 1740
    },
    {
      "epoch": 0.4000459558823529,
      "grad_norm": 1.1407241821289062,
      "learning_rate": 7.991727941176472e-06,
      "loss": 0.1813,
      "step": 1741
    },
    {
      "epoch": 0.40027573529411764,
      "grad_norm": 1.2028286457061768,
      "learning_rate": 7.996323529411767e-06,
      "loss": 0.1744,
      "step": 1742
    },
    {
      "epoch": 0.40050551470588236,
      "grad_norm": 0.9776677489280701,
      "learning_rate": 8.00091911764706e-06,
      "loss": 0.1287,
      "step": 1743
    },
    {
      "epoch": 0.4007352941176471,
      "grad_norm": 1.1010876893997192,
      "learning_rate": 8.005514705882354e-06,
      "loss": 0.1523,
      "step": 1744
    },
    {
      "epoch": 0.40096507352941174,
      "grad_norm": 1.2278519868850708,
      "learning_rate": 8.010110294117648e-06,
      "loss": 0.1523,
      "step": 1745
    },
    {
      "epoch": 0.40119485294117646,
      "grad_norm": 1.215542197227478,
      "learning_rate": 8.014705882352942e-06,
      "loss": 0.1213,
      "step": 1746
    },
    {
      "epoch": 0.4014246323529412,
      "grad_norm": 1.6005795001983643,
      "learning_rate": 8.019301470588235e-06,
      "loss": 0.1727,
      "step": 1747
    },
    {
      "epoch": 0.4016544117647059,
      "grad_norm": 1.2602475881576538,
      "learning_rate": 8.023897058823529e-06,
      "loss": 0.1468,
      "step": 1748
    },
    {
      "epoch": 0.40188419117647056,
      "grad_norm": 1.398169994354248,
      "learning_rate": 8.028492647058823e-06,
      "loss": 0.1476,
      "step": 1749
    },
    {
      "epoch": 0.4021139705882353,
      "grad_norm": 1.3134368658065796,
      "learning_rate": 8.033088235294118e-06,
      "loss": 0.1773,
      "step": 1750
    },
    {
      "epoch": 0.40234375,
      "grad_norm": 1.4564138650894165,
      "learning_rate": 8.037683823529412e-06,
      "loss": 0.1686,
      "step": 1751
    },
    {
      "epoch": 0.4025735294117647,
      "grad_norm": 1.0048757791519165,
      "learning_rate": 8.042279411764706e-06,
      "loss": 0.138,
      "step": 1752
    },
    {
      "epoch": 0.40280330882352944,
      "grad_norm": 1.0890672206878662,
      "learning_rate": 8.046875e-06,
      "loss": 0.1205,
      "step": 1753
    },
    {
      "epoch": 0.4030330882352941,
      "grad_norm": 1.1899231672286987,
      "learning_rate": 8.051470588235295e-06,
      "loss": 0.1798,
      "step": 1754
    },
    {
      "epoch": 0.4032628676470588,
      "grad_norm": 1.178387999534607,
      "learning_rate": 8.05606617647059e-06,
      "loss": 0.104,
      "step": 1755
    },
    {
      "epoch": 0.40349264705882354,
      "grad_norm": 1.3820303678512573,
      "learning_rate": 8.060661764705882e-06,
      "loss": 0.0987,
      "step": 1756
    },
    {
      "epoch": 0.40372242647058826,
      "grad_norm": 1.3305152654647827,
      "learning_rate": 8.065257352941176e-06,
      "loss": 0.128,
      "step": 1757
    },
    {
      "epoch": 0.4039522058823529,
      "grad_norm": 1.284035086631775,
      "learning_rate": 8.06985294117647e-06,
      "loss": 0.1416,
      "step": 1758
    },
    {
      "epoch": 0.40418198529411764,
      "grad_norm": 1.2085514068603516,
      "learning_rate": 8.074448529411765e-06,
      "loss": 0.1368,
      "step": 1759
    },
    {
      "epoch": 0.40441176470588236,
      "grad_norm": 1.4105863571166992,
      "learning_rate": 8.07904411764706e-06,
      "loss": 0.1934,
      "step": 1760
    },
    {
      "epoch": 0.4046415441176471,
      "grad_norm": 1.609413981437683,
      "learning_rate": 8.083639705882354e-06,
      "loss": 0.194,
      "step": 1761
    },
    {
      "epoch": 0.40487132352941174,
      "grad_norm": 1.122540831565857,
      "learning_rate": 8.088235294117648e-06,
      "loss": 0.1585,
      "step": 1762
    },
    {
      "epoch": 0.40510110294117646,
      "grad_norm": 1.3144233226776123,
      "learning_rate": 8.092830882352942e-06,
      "loss": 0.1382,
      "step": 1763
    },
    {
      "epoch": 0.4053308823529412,
      "grad_norm": 1.3643909692764282,
      "learning_rate": 8.097426470588235e-06,
      "loss": 0.1418,
      "step": 1764
    },
    {
      "epoch": 0.4055606617647059,
      "grad_norm": 1.5471214056015015,
      "learning_rate": 8.10202205882353e-06,
      "loss": 0.1718,
      "step": 1765
    },
    {
      "epoch": 0.40579044117647056,
      "grad_norm": 1.5614866018295288,
      "learning_rate": 8.106617647058824e-06,
      "loss": 0.1767,
      "step": 1766
    },
    {
      "epoch": 0.4060202205882353,
      "grad_norm": 1.099644660949707,
      "learning_rate": 8.111213235294118e-06,
      "loss": 0.1305,
      "step": 1767
    },
    {
      "epoch": 0.40625,
      "grad_norm": 0.8719267845153809,
      "learning_rate": 8.115808823529412e-06,
      "loss": 0.0999,
      "step": 1768
    },
    {
      "epoch": 0.4064797794117647,
      "grad_norm": 1.2181068658828735,
      "learning_rate": 8.120404411764707e-06,
      "loss": 0.1639,
      "step": 1769
    },
    {
      "epoch": 0.40670955882352944,
      "grad_norm": 0.9367298483848572,
      "learning_rate": 8.125000000000001e-06,
      "loss": 0.1034,
      "step": 1770
    },
    {
      "epoch": 0.4069393382352941,
      "grad_norm": 1.2365663051605225,
      "learning_rate": 8.129595588235295e-06,
      "loss": 0.1416,
      "step": 1771
    },
    {
      "epoch": 0.4071691176470588,
      "grad_norm": 1.5341322422027588,
      "learning_rate": 8.13419117647059e-06,
      "loss": 0.2162,
      "step": 1772
    },
    {
      "epoch": 0.40739889705882354,
      "grad_norm": 1.3253886699676514,
      "learning_rate": 8.138786764705882e-06,
      "loss": 0.2123,
      "step": 1773
    },
    {
      "epoch": 0.40762867647058826,
      "grad_norm": 1.0942715406417847,
      "learning_rate": 8.143382352941177e-06,
      "loss": 0.1464,
      "step": 1774
    },
    {
      "epoch": 0.4078584558823529,
      "grad_norm": 1.4248361587524414,
      "learning_rate": 8.147977941176471e-06,
      "loss": 0.1421,
      "step": 1775
    },
    {
      "epoch": 0.40808823529411764,
      "grad_norm": 1.162961483001709,
      "learning_rate": 8.152573529411765e-06,
      "loss": 0.1672,
      "step": 1776
    },
    {
      "epoch": 0.40831801470588236,
      "grad_norm": 1.224103569984436,
      "learning_rate": 8.15716911764706e-06,
      "loss": 0.165,
      "step": 1777
    },
    {
      "epoch": 0.4085477941176471,
      "grad_norm": 1.0940767526626587,
      "learning_rate": 8.161764705882354e-06,
      "loss": 0.1439,
      "step": 1778
    },
    {
      "epoch": 0.40877757352941174,
      "grad_norm": 1.2232887744903564,
      "learning_rate": 8.166360294117648e-06,
      "loss": 0.1323,
      "step": 1779
    },
    {
      "epoch": 0.40900735294117646,
      "grad_norm": 1.2340761423110962,
      "learning_rate": 8.170955882352943e-06,
      "loss": 0.1531,
      "step": 1780
    },
    {
      "epoch": 0.4092371323529412,
      "grad_norm": 1.3725347518920898,
      "learning_rate": 8.175551470588235e-06,
      "loss": 0.1721,
      "step": 1781
    },
    {
      "epoch": 0.4094669117647059,
      "grad_norm": 1.3218806982040405,
      "learning_rate": 8.18014705882353e-06,
      "loss": 0.1469,
      "step": 1782
    },
    {
      "epoch": 0.40969669117647056,
      "grad_norm": 1.3655911684036255,
      "learning_rate": 8.184742647058824e-06,
      "loss": 0.1817,
      "step": 1783
    },
    {
      "epoch": 0.4099264705882353,
      "grad_norm": 0.9120039343833923,
      "learning_rate": 8.189338235294118e-06,
      "loss": 0.1419,
      "step": 1784
    },
    {
      "epoch": 0.41015625,
      "grad_norm": 1.4455084800720215,
      "learning_rate": 8.193933823529413e-06,
      "loss": 0.1679,
      "step": 1785
    },
    {
      "epoch": 0.4103860294117647,
      "grad_norm": 1.0547274351119995,
      "learning_rate": 8.198529411764707e-06,
      "loss": 0.1632,
      "step": 1786
    },
    {
      "epoch": 0.41061580882352944,
      "grad_norm": 1.0880358219146729,
      "learning_rate": 8.203125000000001e-06,
      "loss": 0.1321,
      "step": 1787
    },
    {
      "epoch": 0.4108455882352941,
      "grad_norm": 1.0436214208602905,
      "learning_rate": 8.207720588235296e-06,
      "loss": 0.0986,
      "step": 1788
    },
    {
      "epoch": 0.4110753676470588,
      "grad_norm": 1.588843822479248,
      "learning_rate": 8.21231617647059e-06,
      "loss": 0.1836,
      "step": 1789
    },
    {
      "epoch": 0.41130514705882354,
      "grad_norm": 1.2843366861343384,
      "learning_rate": 8.216911764705882e-06,
      "loss": 0.1413,
      "step": 1790
    },
    {
      "epoch": 0.41153492647058826,
      "grad_norm": 1.4011071920394897,
      "learning_rate": 8.221507352941177e-06,
      "loss": 0.1384,
      "step": 1791
    },
    {
      "epoch": 0.4117647058823529,
      "grad_norm": 1.359608769416809,
      "learning_rate": 8.226102941176471e-06,
      "loss": 0.183,
      "step": 1792
    },
    {
      "epoch": 0.41199448529411764,
      "grad_norm": 1.3826297521591187,
      "learning_rate": 8.230698529411765e-06,
      "loss": 0.1227,
      "step": 1793
    },
    {
      "epoch": 0.41222426470588236,
      "grad_norm": 1.0947273969650269,
      "learning_rate": 8.23529411764706e-06,
      "loss": 0.1742,
      "step": 1794
    },
    {
      "epoch": 0.4124540441176471,
      "grad_norm": 1.297961711883545,
      "learning_rate": 8.239889705882354e-06,
      "loss": 0.1611,
      "step": 1795
    },
    {
      "epoch": 0.41268382352941174,
      "grad_norm": 1.0656847953796387,
      "learning_rate": 8.244485294117648e-06,
      "loss": 0.1514,
      "step": 1796
    },
    {
      "epoch": 0.41291360294117646,
      "grad_norm": 1.1978288888931274,
      "learning_rate": 8.249080882352943e-06,
      "loss": 0.1788,
      "step": 1797
    },
    {
      "epoch": 0.4131433823529412,
      "grad_norm": 1.1224415302276611,
      "learning_rate": 8.253676470588235e-06,
      "loss": 0.1157,
      "step": 1798
    },
    {
      "epoch": 0.4133731617647059,
      "grad_norm": 1.0907783508300781,
      "learning_rate": 8.25827205882353e-06,
      "loss": 0.1741,
      "step": 1799
    },
    {
      "epoch": 0.41360294117647056,
      "grad_norm": 0.9494476318359375,
      "learning_rate": 8.262867647058824e-06,
      "loss": 0.126,
      "step": 1800
    },
    {
      "epoch": 0.4138327205882353,
      "grad_norm": 1.0228337049484253,
      "learning_rate": 8.267463235294118e-06,
      "loss": 0.0976,
      "step": 1801
    },
    {
      "epoch": 0.4140625,
      "grad_norm": 0.8705893754959106,
      "learning_rate": 8.272058823529413e-06,
      "loss": 0.1396,
      "step": 1802
    },
    {
      "epoch": 0.4142922794117647,
      "grad_norm": 1.0772007703781128,
      "learning_rate": 8.276654411764707e-06,
      "loss": 0.1512,
      "step": 1803
    },
    {
      "epoch": 0.41452205882352944,
      "grad_norm": 1.1540746688842773,
      "learning_rate": 8.281250000000001e-06,
      "loss": 0.1088,
      "step": 1804
    },
    {
      "epoch": 0.4147518382352941,
      "grad_norm": 1.082540512084961,
      "learning_rate": 8.285845588235296e-06,
      "loss": 0.1503,
      "step": 1805
    },
    {
      "epoch": 0.4149816176470588,
      "grad_norm": 1.1658366918563843,
      "learning_rate": 8.29044117647059e-06,
      "loss": 0.1335,
      "step": 1806
    },
    {
      "epoch": 0.41521139705882354,
      "grad_norm": 1.9777995347976685,
      "learning_rate": 8.295036764705883e-06,
      "loss": 0.1563,
      "step": 1807
    },
    {
      "epoch": 0.41544117647058826,
      "grad_norm": 1.516284704208374,
      "learning_rate": 8.299632352941177e-06,
      "loss": 0.1569,
      "step": 1808
    },
    {
      "epoch": 0.4156709558823529,
      "grad_norm": 1.21317458152771,
      "learning_rate": 8.304227941176471e-06,
      "loss": 0.1665,
      "step": 1809
    },
    {
      "epoch": 0.41590073529411764,
      "grad_norm": 1.1893819570541382,
      "learning_rate": 8.308823529411766e-06,
      "loss": 0.1767,
      "step": 1810
    },
    {
      "epoch": 0.41613051470588236,
      "grad_norm": 1.5489442348480225,
      "learning_rate": 8.313419117647058e-06,
      "loss": 0.1608,
      "step": 1811
    },
    {
      "epoch": 0.4163602941176471,
      "grad_norm": 1.0300573110580444,
      "learning_rate": 8.318014705882354e-06,
      "loss": 0.1351,
      "step": 1812
    },
    {
      "epoch": 0.41659007352941174,
      "grad_norm": 1.1745977401733398,
      "learning_rate": 8.322610294117649e-06,
      "loss": 0.1451,
      "step": 1813
    },
    {
      "epoch": 0.41681985294117646,
      "grad_norm": 1.3186705112457275,
      "learning_rate": 8.327205882352943e-06,
      "loss": 0.1245,
      "step": 1814
    },
    {
      "epoch": 0.4170496323529412,
      "grad_norm": 0.8088223338127136,
      "learning_rate": 8.331801470588236e-06,
      "loss": 0.0978,
      "step": 1815
    },
    {
      "epoch": 0.4172794117647059,
      "grad_norm": 1.4996219873428345,
      "learning_rate": 8.33639705882353e-06,
      "loss": 0.1667,
      "step": 1816
    },
    {
      "epoch": 0.41750919117647056,
      "grad_norm": 0.9597744941711426,
      "learning_rate": 8.340992647058824e-06,
      "loss": 0.1487,
      "step": 1817
    },
    {
      "epoch": 0.4177389705882353,
      "grad_norm": 1.366532564163208,
      "learning_rate": 8.345588235294119e-06,
      "loss": 0.1535,
      "step": 1818
    },
    {
      "epoch": 0.41796875,
      "grad_norm": 1.0996360778808594,
      "learning_rate": 8.350183823529411e-06,
      "loss": 0.1409,
      "step": 1819
    },
    {
      "epoch": 0.4181985294117647,
      "grad_norm": 1.352406620979309,
      "learning_rate": 8.354779411764706e-06,
      "loss": 0.1771,
      "step": 1820
    },
    {
      "epoch": 0.41842830882352944,
      "grad_norm": 1.0409505367279053,
      "learning_rate": 8.359375e-06,
      "loss": 0.1293,
      "step": 1821
    },
    {
      "epoch": 0.4186580882352941,
      "grad_norm": 1.393424391746521,
      "learning_rate": 8.363970588235294e-06,
      "loss": 0.1479,
      "step": 1822
    },
    {
      "epoch": 0.4188878676470588,
      "grad_norm": 1.293262004852295,
      "learning_rate": 8.36856617647059e-06,
      "loss": 0.1433,
      "step": 1823
    },
    {
      "epoch": 0.41911764705882354,
      "grad_norm": 1.114467978477478,
      "learning_rate": 8.373161764705883e-06,
      "loss": 0.1357,
      "step": 1824
    },
    {
      "epoch": 0.41934742647058826,
      "grad_norm": 1.6612434387207031,
      "learning_rate": 8.377757352941177e-06,
      "loss": 0.1798,
      "step": 1825
    },
    {
      "epoch": 0.4195772058823529,
      "grad_norm": 1.074973225593567,
      "learning_rate": 8.382352941176472e-06,
      "loss": 0.1533,
      "step": 1826
    },
    {
      "epoch": 0.41980698529411764,
      "grad_norm": 0.9825917482376099,
      "learning_rate": 8.386948529411766e-06,
      "loss": 0.1367,
      "step": 1827
    },
    {
      "epoch": 0.42003676470588236,
      "grad_norm": 1.0315171480178833,
      "learning_rate": 8.391544117647059e-06,
      "loss": 0.1507,
      "step": 1828
    },
    {
      "epoch": 0.4202665441176471,
      "grad_norm": 0.9555351138114929,
      "learning_rate": 8.396139705882353e-06,
      "loss": 0.1555,
      "step": 1829
    },
    {
      "epoch": 0.42049632352941174,
      "grad_norm": 1.3252019882202148,
      "learning_rate": 8.400735294117647e-06,
      "loss": 0.1814,
      "step": 1830
    },
    {
      "epoch": 0.42072610294117646,
      "grad_norm": 1.045518398284912,
      "learning_rate": 8.405330882352941e-06,
      "loss": 0.1622,
      "step": 1831
    },
    {
      "epoch": 0.4209558823529412,
      "grad_norm": 1.3003437519073486,
      "learning_rate": 8.409926470588236e-06,
      "loss": 0.1408,
      "step": 1832
    },
    {
      "epoch": 0.4211856617647059,
      "grad_norm": 1.0084004402160645,
      "learning_rate": 8.41452205882353e-06,
      "loss": 0.1317,
      "step": 1833
    },
    {
      "epoch": 0.42141544117647056,
      "grad_norm": 1.197986125946045,
      "learning_rate": 8.419117647058824e-06,
      "loss": 0.1607,
      "step": 1834
    },
    {
      "epoch": 0.4216452205882353,
      "grad_norm": 1.691348910331726,
      "learning_rate": 8.423713235294119e-06,
      "loss": 0.1512,
      "step": 1835
    },
    {
      "epoch": 0.421875,
      "grad_norm": 1.1573481559753418,
      "learning_rate": 8.428308823529411e-06,
      "loss": 0.1542,
      "step": 1836
    },
    {
      "epoch": 0.4221047794117647,
      "grad_norm": 0.9641566276550293,
      "learning_rate": 8.432904411764706e-06,
      "loss": 0.1173,
      "step": 1837
    },
    {
      "epoch": 0.42233455882352944,
      "grad_norm": 1.0201793909072876,
      "learning_rate": 8.4375e-06,
      "loss": 0.1178,
      "step": 1838
    },
    {
      "epoch": 0.4225643382352941,
      "grad_norm": 1.2737457752227783,
      "learning_rate": 8.442095588235294e-06,
      "loss": 0.1227,
      "step": 1839
    },
    {
      "epoch": 0.4227941176470588,
      "grad_norm": 1.0093215703964233,
      "learning_rate": 8.446691176470589e-06,
      "loss": 0.1331,
      "step": 1840
    },
    {
      "epoch": 0.42302389705882354,
      "grad_norm": 1.0668895244598389,
      "learning_rate": 8.451286764705883e-06,
      "loss": 0.1672,
      "step": 1841
    },
    {
      "epoch": 0.42325367647058826,
      "grad_norm": 1.9115089178085327,
      "learning_rate": 8.455882352941177e-06,
      "loss": 0.1164,
      "step": 1842
    },
    {
      "epoch": 0.4234834558823529,
      "grad_norm": 0.9972749948501587,
      "learning_rate": 8.460477941176472e-06,
      "loss": 0.1489,
      "step": 1843
    },
    {
      "epoch": 0.42371323529411764,
      "grad_norm": 1.1529450416564941,
      "learning_rate": 8.465073529411766e-06,
      "loss": 0.1485,
      "step": 1844
    },
    {
      "epoch": 0.42394301470588236,
      "grad_norm": 1.0972081422805786,
      "learning_rate": 8.469669117647059e-06,
      "loss": 0.1512,
      "step": 1845
    },
    {
      "epoch": 0.4241727941176471,
      "grad_norm": 1.2425129413604736,
      "learning_rate": 8.474264705882353e-06,
      "loss": 0.1502,
      "step": 1846
    },
    {
      "epoch": 0.42440257352941174,
      "grad_norm": 1.0968352556228638,
      "learning_rate": 8.478860294117647e-06,
      "loss": 0.1217,
      "step": 1847
    },
    {
      "epoch": 0.42463235294117646,
      "grad_norm": 1.0718947649002075,
      "learning_rate": 8.483455882352942e-06,
      "loss": 0.1494,
      "step": 1848
    },
    {
      "epoch": 0.4248621323529412,
      "grad_norm": 1.2216464281082153,
      "learning_rate": 8.488051470588236e-06,
      "loss": 0.152,
      "step": 1849
    },
    {
      "epoch": 0.4250919117647059,
      "grad_norm": 1.094045639038086,
      "learning_rate": 8.49264705882353e-06,
      "loss": 0.1561,
      "step": 1850
    },
    {
      "epoch": 0.42532169117647056,
      "grad_norm": 1.2113755941390991,
      "learning_rate": 8.497242647058825e-06,
      "loss": 0.1301,
      "step": 1851
    },
    {
      "epoch": 0.4255514705882353,
      "grad_norm": 1.1210967302322388,
      "learning_rate": 8.501838235294119e-06,
      "loss": 0.1268,
      "step": 1852
    },
    {
      "epoch": 0.42578125,
      "grad_norm": 1.1636254787445068,
      "learning_rate": 8.506433823529412e-06,
      "loss": 0.152,
      "step": 1853
    },
    {
      "epoch": 0.4260110294117647,
      "grad_norm": 1.018296718597412,
      "learning_rate": 8.511029411764706e-06,
      "loss": 0.1484,
      "step": 1854
    },
    {
      "epoch": 0.42624080882352944,
      "grad_norm": 1.0607422590255737,
      "learning_rate": 8.515625e-06,
      "loss": 0.1535,
      "step": 1855
    },
    {
      "epoch": 0.4264705882352941,
      "grad_norm": 0.9582228064537048,
      "learning_rate": 8.520220588235295e-06,
      "loss": 0.1636,
      "step": 1856
    },
    {
      "epoch": 0.4267003676470588,
      "grad_norm": 1.1040031909942627,
      "learning_rate": 8.524816176470589e-06,
      "loss": 0.1731,
      "step": 1857
    },
    {
      "epoch": 0.42693014705882354,
      "grad_norm": 1.2557586431503296,
      "learning_rate": 8.529411764705883e-06,
      "loss": 0.1442,
      "step": 1858
    },
    {
      "epoch": 0.42715992647058826,
      "grad_norm": 1.2476710081100464,
      "learning_rate": 8.534007352941178e-06,
      "loss": 0.1398,
      "step": 1859
    },
    {
      "epoch": 0.4273897058823529,
      "grad_norm": 1.4075216054916382,
      "learning_rate": 8.538602941176472e-06,
      "loss": 0.143,
      "step": 1860
    },
    {
      "epoch": 0.42761948529411764,
      "grad_norm": 0.9155037999153137,
      "learning_rate": 8.543198529411766e-06,
      "loss": 0.1152,
      "step": 1861
    },
    {
      "epoch": 0.42784926470588236,
      "grad_norm": 1.451157808303833,
      "learning_rate": 8.547794117647059e-06,
      "loss": 0.1739,
      "step": 1862
    },
    {
      "epoch": 0.4280790441176471,
      "grad_norm": 1.1296297311782837,
      "learning_rate": 8.552389705882353e-06,
      "loss": 0.1344,
      "step": 1863
    },
    {
      "epoch": 0.42830882352941174,
      "grad_norm": 0.9911193251609802,
      "learning_rate": 8.556985294117648e-06,
      "loss": 0.135,
      "step": 1864
    },
    {
      "epoch": 0.42853860294117646,
      "grad_norm": 1.1622164249420166,
      "learning_rate": 8.561580882352942e-06,
      "loss": 0.1266,
      "step": 1865
    },
    {
      "epoch": 0.4287683823529412,
      "grad_norm": 1.103369116783142,
      "learning_rate": 8.566176470588236e-06,
      "loss": 0.1509,
      "step": 1866
    },
    {
      "epoch": 0.4289981617647059,
      "grad_norm": 1.1174814701080322,
      "learning_rate": 8.57077205882353e-06,
      "loss": 0.1638,
      "step": 1867
    },
    {
      "epoch": 0.42922794117647056,
      "grad_norm": 0.9893536567687988,
      "learning_rate": 8.575367647058825e-06,
      "loss": 0.145,
      "step": 1868
    },
    {
      "epoch": 0.4294577205882353,
      "grad_norm": 1.3636555671691895,
      "learning_rate": 8.57996323529412e-06,
      "loss": 0.1438,
      "step": 1869
    },
    {
      "epoch": 0.4296875,
      "grad_norm": 0.9978560209274292,
      "learning_rate": 8.584558823529412e-06,
      "loss": 0.1364,
      "step": 1870
    },
    {
      "epoch": 0.4299172794117647,
      "grad_norm": 0.9605644941329956,
      "learning_rate": 8.589154411764706e-06,
      "loss": 0.1052,
      "step": 1871
    },
    {
      "epoch": 0.43014705882352944,
      "grad_norm": 1.3008042573928833,
      "learning_rate": 8.59375e-06,
      "loss": 0.1555,
      "step": 1872
    },
    {
      "epoch": 0.4303768382352941,
      "grad_norm": 1.0281099081039429,
      "learning_rate": 8.598345588235295e-06,
      "loss": 0.1525,
      "step": 1873
    },
    {
      "epoch": 0.4306066176470588,
      "grad_norm": 1.0808992385864258,
      "learning_rate": 8.60294117647059e-06,
      "loss": 0.1771,
      "step": 1874
    },
    {
      "epoch": 0.43083639705882354,
      "grad_norm": 1.0624290704727173,
      "learning_rate": 8.607536764705884e-06,
      "loss": 0.1108,
      "step": 1875
    },
    {
      "epoch": 0.43106617647058826,
      "grad_norm": 1.3751256465911865,
      "learning_rate": 8.612132352941178e-06,
      "loss": 0.1148,
      "step": 1876
    },
    {
      "epoch": 0.4312959558823529,
      "grad_norm": 0.9384075403213501,
      "learning_rate": 8.616727941176472e-06,
      "loss": 0.1423,
      "step": 1877
    },
    {
      "epoch": 0.43152573529411764,
      "grad_norm": 1.0436116456985474,
      "learning_rate": 8.621323529411766e-06,
      "loss": 0.1472,
      "step": 1878
    },
    {
      "epoch": 0.43175551470588236,
      "grad_norm": 1.1062179803848267,
      "learning_rate": 8.625919117647059e-06,
      "loss": 0.1187,
      "step": 1879
    },
    {
      "epoch": 0.4319852941176471,
      "grad_norm": 1.0350067615509033,
      "learning_rate": 8.630514705882353e-06,
      "loss": 0.1342,
      "step": 1880
    },
    {
      "epoch": 0.43221507352941174,
      "grad_norm": 0.9633251428604126,
      "learning_rate": 8.635110294117648e-06,
      "loss": 0.1544,
      "step": 1881
    },
    {
      "epoch": 0.43244485294117646,
      "grad_norm": 1.4266810417175293,
      "learning_rate": 8.639705882352942e-06,
      "loss": 0.1755,
      "step": 1882
    },
    {
      "epoch": 0.4326746323529412,
      "grad_norm": 1.082497239112854,
      "learning_rate": 8.644301470588235e-06,
      "loss": 0.1396,
      "step": 1883
    },
    {
      "epoch": 0.4329044117647059,
      "grad_norm": 1.0665644407272339,
      "learning_rate": 8.648897058823529e-06,
      "loss": 0.0977,
      "step": 1884
    },
    {
      "epoch": 0.43313419117647056,
      "grad_norm": 0.9595323801040649,
      "learning_rate": 8.653492647058825e-06,
      "loss": 0.1184,
      "step": 1885
    },
    {
      "epoch": 0.4333639705882353,
      "grad_norm": 1.4957467317581177,
      "learning_rate": 8.65808823529412e-06,
      "loss": 0.1543,
      "step": 1886
    },
    {
      "epoch": 0.43359375,
      "grad_norm": 1.1898646354675293,
      "learning_rate": 8.662683823529412e-06,
      "loss": 0.1617,
      "step": 1887
    },
    {
      "epoch": 0.4338235294117647,
      "grad_norm": 1.3153958320617676,
      "learning_rate": 8.667279411764706e-06,
      "loss": 0.1873,
      "step": 1888
    },
    {
      "epoch": 0.43405330882352944,
      "grad_norm": 0.9707929491996765,
      "learning_rate": 8.671875e-06,
      "loss": 0.1472,
      "step": 1889
    },
    {
      "epoch": 0.4342830882352941,
      "grad_norm": 0.8981870412826538,
      "learning_rate": 8.676470588235295e-06,
      "loss": 0.1212,
      "step": 1890
    },
    {
      "epoch": 0.4345128676470588,
      "grad_norm": 1.3777331113815308,
      "learning_rate": 8.68106617647059e-06,
      "loss": 0.1131,
      "step": 1891
    },
    {
      "epoch": 0.43474264705882354,
      "grad_norm": 1.324989914894104,
      "learning_rate": 8.685661764705882e-06,
      "loss": 0.1495,
      "step": 1892
    },
    {
      "epoch": 0.43497242647058826,
      "grad_norm": 1.0244040489196777,
      "learning_rate": 8.690257352941176e-06,
      "loss": 0.1304,
      "step": 1893
    },
    {
      "epoch": 0.4352022058823529,
      "grad_norm": 1.0728610754013062,
      "learning_rate": 8.69485294117647e-06,
      "loss": 0.1072,
      "step": 1894
    },
    {
      "epoch": 0.43543198529411764,
      "grad_norm": 0.9920419454574585,
      "learning_rate": 8.699448529411767e-06,
      "loss": 0.1471,
      "step": 1895
    },
    {
      "epoch": 0.43566176470588236,
      "grad_norm": 0.8787230849266052,
      "learning_rate": 8.70404411764706e-06,
      "loss": 0.1145,
      "step": 1896
    },
    {
      "epoch": 0.4358915441176471,
      "grad_norm": 1.3628578186035156,
      "learning_rate": 8.708639705882354e-06,
      "loss": 0.166,
      "step": 1897
    },
    {
      "epoch": 0.43612132352941174,
      "grad_norm": 0.9281853437423706,
      "learning_rate": 8.713235294117648e-06,
      "loss": 0.1242,
      "step": 1898
    },
    {
      "epoch": 0.43635110294117646,
      "grad_norm": 1.0229672193527222,
      "learning_rate": 8.717830882352942e-06,
      "loss": 0.1164,
      "step": 1899
    },
    {
      "epoch": 0.4365808823529412,
      "grad_norm": 1.0871163606643677,
      "learning_rate": 8.722426470588235e-06,
      "loss": 0.1319,
      "step": 1900
    },
    {
      "epoch": 0.4368106617647059,
      "grad_norm": 1.6823198795318604,
      "learning_rate": 8.72702205882353e-06,
      "loss": 0.1984,
      "step": 1901
    },
    {
      "epoch": 0.43704044117647056,
      "grad_norm": 1.1658284664154053,
      "learning_rate": 8.731617647058824e-06,
      "loss": 0.166,
      "step": 1902
    },
    {
      "epoch": 0.4372702205882353,
      "grad_norm": 1.4434581995010376,
      "learning_rate": 8.736213235294118e-06,
      "loss": 0.1714,
      "step": 1903
    },
    {
      "epoch": 0.4375,
      "grad_norm": 1.2925074100494385,
      "learning_rate": 8.740808823529412e-06,
      "loss": 0.1245,
      "step": 1904
    },
    {
      "epoch": 0.4377297794117647,
      "grad_norm": 0.9332113265991211,
      "learning_rate": 8.745404411764707e-06,
      "loss": 0.1141,
      "step": 1905
    },
    {
      "epoch": 0.43795955882352944,
      "grad_norm": 1.086766242980957,
      "learning_rate": 8.750000000000001e-06,
      "loss": 0.1437,
      "step": 1906
    },
    {
      "epoch": 0.4381893382352941,
      "grad_norm": 1.1146570444107056,
      "learning_rate": 8.754595588235295e-06,
      "loss": 0.1316,
      "step": 1907
    },
    {
      "epoch": 0.4384191176470588,
      "grad_norm": 1.3680967092514038,
      "learning_rate": 8.75919117647059e-06,
      "loss": 0.157,
      "step": 1908
    },
    {
      "epoch": 0.43864889705882354,
      "grad_norm": 1.0443625450134277,
      "learning_rate": 8.763786764705882e-06,
      "loss": 0.1261,
      "step": 1909
    },
    {
      "epoch": 0.43887867647058826,
      "grad_norm": 1.1726385354995728,
      "learning_rate": 8.768382352941177e-06,
      "loss": 0.0974,
      "step": 1910
    },
    {
      "epoch": 0.4391084558823529,
      "grad_norm": 1.0136057138442993,
      "learning_rate": 8.772977941176471e-06,
      "loss": 0.1273,
      "step": 1911
    },
    {
      "epoch": 0.43933823529411764,
      "grad_norm": 1.5210977792739868,
      "learning_rate": 8.777573529411765e-06,
      "loss": 0.1842,
      "step": 1912
    },
    {
      "epoch": 0.43956801470588236,
      "grad_norm": 1.199461579322815,
      "learning_rate": 8.78216911764706e-06,
      "loss": 0.1699,
      "step": 1913
    },
    {
      "epoch": 0.4397977941176471,
      "grad_norm": 1.205026626586914,
      "learning_rate": 8.786764705882354e-06,
      "loss": 0.1581,
      "step": 1914
    },
    {
      "epoch": 0.44002757352941174,
      "grad_norm": 1.1377357244491577,
      "learning_rate": 8.791360294117648e-06,
      "loss": 0.1075,
      "step": 1915
    },
    {
      "epoch": 0.44025735294117646,
      "grad_norm": 1.2406723499298096,
      "learning_rate": 8.795955882352943e-06,
      "loss": 0.1491,
      "step": 1916
    },
    {
      "epoch": 0.4404871323529412,
      "grad_norm": 1.2108114957809448,
      "learning_rate": 8.800551470588235e-06,
      "loss": 0.147,
      "step": 1917
    },
    {
      "epoch": 0.4407169117647059,
      "grad_norm": 0.8872689604759216,
      "learning_rate": 8.80514705882353e-06,
      "loss": 0.106,
      "step": 1918
    },
    {
      "epoch": 0.44094669117647056,
      "grad_norm": 0.8783034086227417,
      "learning_rate": 8.809742647058824e-06,
      "loss": 0.1174,
      "step": 1919
    },
    {
      "epoch": 0.4411764705882353,
      "grad_norm": 0.9676985740661621,
      "learning_rate": 8.814338235294118e-06,
      "loss": 0.1519,
      "step": 1920
    },
    {
      "epoch": 0.44140625,
      "grad_norm": 1.0512771606445312,
      "learning_rate": 8.818933823529412e-06,
      "loss": 0.1031,
      "step": 1921
    },
    {
      "epoch": 0.4416360294117647,
      "grad_norm": 1.34820556640625,
      "learning_rate": 8.823529411764707e-06,
      "loss": 0.1902,
      "step": 1922
    },
    {
      "epoch": 0.44186580882352944,
      "grad_norm": 1.0061986446380615,
      "learning_rate": 8.828125000000001e-06,
      "loss": 0.1745,
      "step": 1923
    },
    {
      "epoch": 0.4420955882352941,
      "grad_norm": 1.171748161315918,
      "learning_rate": 8.832720588235295e-06,
      "loss": 0.1238,
      "step": 1924
    },
    {
      "epoch": 0.4423253676470588,
      "grad_norm": 1.110090732574463,
      "learning_rate": 8.83731617647059e-06,
      "loss": 0.143,
      "step": 1925
    },
    {
      "epoch": 0.44255514705882354,
      "grad_norm": 1.3891416788101196,
      "learning_rate": 8.841911764705882e-06,
      "loss": 0.1816,
      "step": 1926
    },
    {
      "epoch": 0.44278492647058826,
      "grad_norm": 1.1420516967773438,
      "learning_rate": 8.846507352941177e-06,
      "loss": 0.14,
      "step": 1927
    },
    {
      "epoch": 0.4430147058823529,
      "grad_norm": 1.2131078243255615,
      "learning_rate": 8.851102941176471e-06,
      "loss": 0.1804,
      "step": 1928
    },
    {
      "epoch": 0.44324448529411764,
      "grad_norm": 1.2737427949905396,
      "learning_rate": 8.855698529411765e-06,
      "loss": 0.1017,
      "step": 1929
    },
    {
      "epoch": 0.44347426470588236,
      "grad_norm": 1.0882855653762817,
      "learning_rate": 8.86029411764706e-06,
      "loss": 0.1399,
      "step": 1930
    },
    {
      "epoch": 0.4437040441176471,
      "grad_norm": 1.131080150604248,
      "learning_rate": 8.864889705882354e-06,
      "loss": 0.1762,
      "step": 1931
    },
    {
      "epoch": 0.44393382352941174,
      "grad_norm": 0.9585956335067749,
      "learning_rate": 8.869485294117648e-06,
      "loss": 0.1391,
      "step": 1932
    },
    {
      "epoch": 0.44416360294117646,
      "grad_norm": 1.1106410026550293,
      "learning_rate": 8.874080882352943e-06,
      "loss": 0.108,
      "step": 1933
    },
    {
      "epoch": 0.4443933823529412,
      "grad_norm": 1.1534695625305176,
      "learning_rate": 8.878676470588235e-06,
      "loss": 0.1549,
      "step": 1934
    },
    {
      "epoch": 0.4446231617647059,
      "grad_norm": 1.2053477764129639,
      "learning_rate": 8.88327205882353e-06,
      "loss": 0.2267,
      "step": 1935
    },
    {
      "epoch": 0.44485294117647056,
      "grad_norm": 0.9295369386672974,
      "learning_rate": 8.887867647058824e-06,
      "loss": 0.1345,
      "step": 1936
    },
    {
      "epoch": 0.4450827205882353,
      "grad_norm": 1.6837499141693115,
      "learning_rate": 8.892463235294118e-06,
      "loss": 0.1615,
      "step": 1937
    },
    {
      "epoch": 0.4453125,
      "grad_norm": 1.3766634464263916,
      "learning_rate": 8.897058823529413e-06,
      "loss": 0.1514,
      "step": 1938
    },
    {
      "epoch": 0.4455422794117647,
      "grad_norm": 0.9600537419319153,
      "learning_rate": 8.901654411764707e-06,
      "loss": 0.126,
      "step": 1939
    },
    {
      "epoch": 0.44577205882352944,
      "grad_norm": 1.2219481468200684,
      "learning_rate": 8.906250000000001e-06,
      "loss": 0.1048,
      "step": 1940
    },
    {
      "epoch": 0.4460018382352941,
      "grad_norm": 1.1251434087753296,
      "learning_rate": 8.910845588235296e-06,
      "loss": 0.1208,
      "step": 1941
    },
    {
      "epoch": 0.4462316176470588,
      "grad_norm": 1.2299374341964722,
      "learning_rate": 8.91544117647059e-06,
      "loss": 0.1603,
      "step": 1942
    },
    {
      "epoch": 0.44646139705882354,
      "grad_norm": 1.10642671585083,
      "learning_rate": 8.920036764705883e-06,
      "loss": 0.1444,
      "step": 1943
    },
    {
      "epoch": 0.44669117647058826,
      "grad_norm": 1.217021107673645,
      "learning_rate": 8.924632352941177e-06,
      "loss": 0.1246,
      "step": 1944
    },
    {
      "epoch": 0.4469209558823529,
      "grad_norm": 1.2796376943588257,
      "learning_rate": 8.929227941176471e-06,
      "loss": 0.182,
      "step": 1945
    },
    {
      "epoch": 0.44715073529411764,
      "grad_norm": 1.272985577583313,
      "learning_rate": 8.933823529411766e-06,
      "loss": 0.1463,
      "step": 1946
    },
    {
      "epoch": 0.44738051470588236,
      "grad_norm": 0.8780290484428406,
      "learning_rate": 8.93841911764706e-06,
      "loss": 0.0991,
      "step": 1947
    },
    {
      "epoch": 0.4476102941176471,
      "grad_norm": 1.5911368131637573,
      "learning_rate": 8.943014705882354e-06,
      "loss": 0.1535,
      "step": 1948
    },
    {
      "epoch": 0.44784007352941174,
      "grad_norm": 1.7081983089447021,
      "learning_rate": 8.947610294117649e-06,
      "loss": 0.1683,
      "step": 1949
    },
    {
      "epoch": 0.44806985294117646,
      "grad_norm": 1.4193936586380005,
      "learning_rate": 8.952205882352943e-06,
      "loss": 0.1455,
      "step": 1950
    },
    {
      "epoch": 0.4482996323529412,
      "grad_norm": 0.9537605047225952,
      "learning_rate": 8.956801470588236e-06,
      "loss": 0.1281,
      "step": 1951
    },
    {
      "epoch": 0.4485294117647059,
      "grad_norm": 0.8780308365821838,
      "learning_rate": 8.96139705882353e-06,
      "loss": 0.1262,
      "step": 1952
    },
    {
      "epoch": 0.44875919117647056,
      "grad_norm": 0.915637731552124,
      "learning_rate": 8.965992647058824e-06,
      "loss": 0.1249,
      "step": 1953
    },
    {
      "epoch": 0.4489889705882353,
      "grad_norm": 1.2517131567001343,
      "learning_rate": 8.970588235294119e-06,
      "loss": 0.1245,
      "step": 1954
    },
    {
      "epoch": 0.44921875,
      "grad_norm": 1.2108486890792847,
      "learning_rate": 8.975183823529411e-06,
      "loss": 0.1455,
      "step": 1955
    },
    {
      "epoch": 0.4494485294117647,
      "grad_norm": 0.9612839221954346,
      "learning_rate": 8.979779411764706e-06,
      "loss": 0.1216,
      "step": 1956
    },
    {
      "epoch": 0.44967830882352944,
      "grad_norm": 1.1184600591659546,
      "learning_rate": 8.984375000000002e-06,
      "loss": 0.1584,
      "step": 1957
    },
    {
      "epoch": 0.4499080882352941,
      "grad_norm": 0.887141227722168,
      "learning_rate": 8.988970588235296e-06,
      "loss": 0.1329,
      "step": 1958
    },
    {
      "epoch": 0.4501378676470588,
      "grad_norm": 1.0081995725631714,
      "learning_rate": 8.99356617647059e-06,
      "loss": 0.1479,
      "step": 1959
    },
    {
      "epoch": 0.45036764705882354,
      "grad_norm": 1.0230062007904053,
      "learning_rate": 8.998161764705883e-06,
      "loss": 0.0994,
      "step": 1960
    },
    {
      "epoch": 0.45059742647058826,
      "grad_norm": 0.8710106611251831,
      "learning_rate": 9.002757352941177e-06,
      "loss": 0.1407,
      "step": 1961
    },
    {
      "epoch": 0.4508272058823529,
      "grad_norm": 0.9333794713020325,
      "learning_rate": 9.007352941176471e-06,
      "loss": 0.1472,
      "step": 1962
    },
    {
      "epoch": 0.45105698529411764,
      "grad_norm": 1.4223233461380005,
      "learning_rate": 9.011948529411766e-06,
      "loss": 0.169,
      "step": 1963
    },
    {
      "epoch": 0.45128676470588236,
      "grad_norm": 1.4706356525421143,
      "learning_rate": 9.016544117647058e-06,
      "loss": 0.2126,
      "step": 1964
    },
    {
      "epoch": 0.4515165441176471,
      "grad_norm": 0.9829584956169128,
      "learning_rate": 9.021139705882353e-06,
      "loss": 0.1315,
      "step": 1965
    },
    {
      "epoch": 0.45174632352941174,
      "grad_norm": 1.1929916143417358,
      "learning_rate": 9.025735294117647e-06,
      "loss": 0.1526,
      "step": 1966
    },
    {
      "epoch": 0.45197610294117646,
      "grad_norm": 0.9933194518089294,
      "learning_rate": 9.030330882352943e-06,
      "loss": 0.1214,
      "step": 1967
    },
    {
      "epoch": 0.4522058823529412,
      "grad_norm": 1.4657316207885742,
      "learning_rate": 9.034926470588236e-06,
      "loss": 0.1471,
      "step": 1968
    },
    {
      "epoch": 0.4524356617647059,
      "grad_norm": 1.4595896005630493,
      "learning_rate": 9.03952205882353e-06,
      "loss": 0.1512,
      "step": 1969
    },
    {
      "epoch": 0.45266544117647056,
      "grad_norm": 1.0601993799209595,
      "learning_rate": 9.044117647058824e-06,
      "loss": 0.1342,
      "step": 1970
    },
    {
      "epoch": 0.4528952205882353,
      "grad_norm": 1.2260972261428833,
      "learning_rate": 9.048713235294119e-06,
      "loss": 0.1144,
      "step": 1971
    },
    {
      "epoch": 0.453125,
      "grad_norm": 1.3375548124313354,
      "learning_rate": 9.053308823529411e-06,
      "loss": 0.162,
      "step": 1972
    },
    {
      "epoch": 0.4533547794117647,
      "grad_norm": 0.9982554912567139,
      "learning_rate": 9.057904411764706e-06,
      "loss": 0.116,
      "step": 1973
    },
    {
      "epoch": 0.45358455882352944,
      "grad_norm": 0.9088101387023926,
      "learning_rate": 9.0625e-06,
      "loss": 0.1101,
      "step": 1974
    },
    {
      "epoch": 0.4538143382352941,
      "grad_norm": 1.6706873178482056,
      "learning_rate": 9.067095588235294e-06,
      "loss": 0.1888,
      "step": 1975
    },
    {
      "epoch": 0.4540441176470588,
      "grad_norm": 1.0287306308746338,
      "learning_rate": 9.071691176470589e-06,
      "loss": 0.1627,
      "step": 1976
    },
    {
      "epoch": 0.45427389705882354,
      "grad_norm": 1.1157695055007935,
      "learning_rate": 9.076286764705883e-06,
      "loss": 0.1623,
      "step": 1977
    },
    {
      "epoch": 0.45450367647058826,
      "grad_norm": 1.3315908908843994,
      "learning_rate": 9.080882352941177e-06,
      "loss": 0.1237,
      "step": 1978
    },
    {
      "epoch": 0.4547334558823529,
      "grad_norm": 1.2483315467834473,
      "learning_rate": 9.085477941176472e-06,
      "loss": 0.1495,
      "step": 1979
    },
    {
      "epoch": 0.45496323529411764,
      "grad_norm": 1.0456024408340454,
      "learning_rate": 9.090073529411766e-06,
      "loss": 0.1275,
      "step": 1980
    },
    {
      "epoch": 0.45519301470588236,
      "grad_norm": 0.9862646460533142,
      "learning_rate": 9.094669117647059e-06,
      "loss": 0.1081,
      "step": 1981
    },
    {
      "epoch": 0.4554227941176471,
      "grad_norm": 1.5428375005722046,
      "learning_rate": 9.099264705882353e-06,
      "loss": 0.1971,
      "step": 1982
    },
    {
      "epoch": 0.45565257352941174,
      "grad_norm": 1.0070388317108154,
      "learning_rate": 9.103860294117647e-06,
      "loss": 0.1233,
      "step": 1983
    },
    {
      "epoch": 0.45588235294117646,
      "grad_norm": 1.0404596328735352,
      "learning_rate": 9.108455882352942e-06,
      "loss": 0.1484,
      "step": 1984
    },
    {
      "epoch": 0.4561121323529412,
      "grad_norm": 0.9514563679695129,
      "learning_rate": 9.113051470588236e-06,
      "loss": 0.1334,
      "step": 1985
    },
    {
      "epoch": 0.4563419117647059,
      "grad_norm": 1.0153543949127197,
      "learning_rate": 9.11764705882353e-06,
      "loss": 0.0896,
      "step": 1986
    },
    {
      "epoch": 0.45657169117647056,
      "grad_norm": 1.1330665349960327,
      "learning_rate": 9.122242647058825e-06,
      "loss": 0.1081,
      "step": 1987
    },
    {
      "epoch": 0.4568014705882353,
      "grad_norm": 1.071312665939331,
      "learning_rate": 9.126838235294119e-06,
      "loss": 0.1645,
      "step": 1988
    },
    {
      "epoch": 0.45703125,
      "grad_norm": 1.1206222772598267,
      "learning_rate": 9.131433823529412e-06,
      "loss": 0.1487,
      "step": 1989
    },
    {
      "epoch": 0.4572610294117647,
      "grad_norm": 1.2459611892700195,
      "learning_rate": 9.136029411764706e-06,
      "loss": 0.128,
      "step": 1990
    },
    {
      "epoch": 0.45749080882352944,
      "grad_norm": 0.966191828250885,
      "learning_rate": 9.140625e-06,
      "loss": 0.093,
      "step": 1991
    },
    {
      "epoch": 0.4577205882352941,
      "grad_norm": 1.5022889375686646,
      "learning_rate": 9.145220588235295e-06,
      "loss": 0.1298,
      "step": 1992
    },
    {
      "epoch": 0.4579503676470588,
      "grad_norm": 1.2140355110168457,
      "learning_rate": 9.149816176470589e-06,
      "loss": 0.1446,
      "step": 1993
    },
    {
      "epoch": 0.45818014705882354,
      "grad_norm": 1.1234632730484009,
      "learning_rate": 9.154411764705883e-06,
      "loss": 0.1126,
      "step": 1994
    },
    {
      "epoch": 0.45840992647058826,
      "grad_norm": 1.1787289381027222,
      "learning_rate": 9.159007352941178e-06,
      "loss": 0.1368,
      "step": 1995
    },
    {
      "epoch": 0.4586397058823529,
      "grad_norm": 1.4762814044952393,
      "learning_rate": 9.163602941176472e-06,
      "loss": 0.1479,
      "step": 1996
    },
    {
      "epoch": 0.45886948529411764,
      "grad_norm": 1.0744245052337646,
      "learning_rate": 9.168198529411766e-06,
      "loss": 0.1338,
      "step": 1997
    },
    {
      "epoch": 0.45909926470588236,
      "grad_norm": 1.212182641029358,
      "learning_rate": 9.172794117647059e-06,
      "loss": 0.1421,
      "step": 1998
    },
    {
      "epoch": 0.4593290441176471,
      "grad_norm": 1.0964586734771729,
      "learning_rate": 9.177389705882353e-06,
      "loss": 0.1699,
      "step": 1999
    },
    {
      "epoch": 0.45955882352941174,
      "grad_norm": 1.0069644451141357,
      "learning_rate": 9.181985294117648e-06,
      "loss": 0.104,
      "step": 2000
    },
    {
      "epoch": 0.45955882352941174,
      "eval_loss": 0.13247200846672058,
      "eval_runtime": 2007.3343,
      "eval_samples_per_second": 4.437,
      "eval_steps_per_second": 2.218,
      "step": 2000
    },
    {
      "epoch": 0.45978860294117646,
      "grad_norm": 0.9156777262687683,
      "learning_rate": 9.186580882352942e-06,
      "loss": 0.1205,
      "step": 2001
    },
    {
      "epoch": 0.4600183823529412,
      "grad_norm": 1.2566299438476562,
      "learning_rate": 9.191176470588236e-06,
      "loss": 0.1924,
      "step": 2002
    },
    {
      "epoch": 0.4602481617647059,
      "grad_norm": 1.3719269037246704,
      "learning_rate": 9.19577205882353e-06,
      "loss": 0.2041,
      "step": 2003
    },
    {
      "epoch": 0.46047794117647056,
      "grad_norm": 1.0804991722106934,
      "learning_rate": 9.200367647058825e-06,
      "loss": 0.128,
      "step": 2004
    },
    {
      "epoch": 0.4607077205882353,
      "grad_norm": 1.0854300260543823,
      "learning_rate": 9.20496323529412e-06,
      "loss": 0.1393,
      "step": 2005
    },
    {
      "epoch": 0.4609375,
      "grad_norm": 1.5815528631210327,
      "learning_rate": 9.209558823529412e-06,
      "loss": 0.1394,
      "step": 2006
    },
    {
      "epoch": 0.4611672794117647,
      "grad_norm": 0.9992592930793762,
      "learning_rate": 9.214154411764706e-06,
      "loss": 0.1168,
      "step": 2007
    },
    {
      "epoch": 0.46139705882352944,
      "grad_norm": 0.9187134504318237,
      "learning_rate": 9.21875e-06,
      "loss": 0.0916,
      "step": 2008
    },
    {
      "epoch": 0.4616268382352941,
      "grad_norm": 1.0419548749923706,
      "learning_rate": 9.223345588235295e-06,
      "loss": 0.1069,
      "step": 2009
    },
    {
      "epoch": 0.4618566176470588,
      "grad_norm": 1.046944499015808,
      "learning_rate": 9.227941176470589e-06,
      "loss": 0.1298,
      "step": 2010
    },
    {
      "epoch": 0.46208639705882354,
      "grad_norm": 1.1789919137954712,
      "learning_rate": 9.232536764705883e-06,
      "loss": 0.1538,
      "step": 2011
    },
    {
      "epoch": 0.46231617647058826,
      "grad_norm": 1.116786003112793,
      "learning_rate": 9.237132352941178e-06,
      "loss": 0.1242,
      "step": 2012
    },
    {
      "epoch": 0.4625459558823529,
      "grad_norm": 1.3102526664733887,
      "learning_rate": 9.241727941176472e-06,
      "loss": 0.1326,
      "step": 2013
    },
    {
      "epoch": 0.46277573529411764,
      "grad_norm": 1.5316309928894043,
      "learning_rate": 9.246323529411766e-06,
      "loss": 0.2093,
      "step": 2014
    },
    {
      "epoch": 0.46300551470588236,
      "grad_norm": 1.3692907094955444,
      "learning_rate": 9.250919117647059e-06,
      "loss": 0.14,
      "step": 2015
    },
    {
      "epoch": 0.4632352941176471,
      "grad_norm": 1.2171263694763184,
      "learning_rate": 9.255514705882353e-06,
      "loss": 0.1241,
      "step": 2016
    },
    {
      "epoch": 0.46346507352941174,
      "grad_norm": 1.2877696752548218,
      "learning_rate": 9.260110294117648e-06,
      "loss": 0.1209,
      "step": 2017
    },
    {
      "epoch": 0.46369485294117646,
      "grad_norm": 1.5892869234085083,
      "learning_rate": 9.264705882352942e-06,
      "loss": 0.1386,
      "step": 2018
    },
    {
      "epoch": 0.4639246323529412,
      "grad_norm": 1.258689045906067,
      "learning_rate": 9.269301470588236e-06,
      "loss": 0.1359,
      "step": 2019
    },
    {
      "epoch": 0.4641544117647059,
      "grad_norm": 1.0623050928115845,
      "learning_rate": 9.27389705882353e-06,
      "loss": 0.0905,
      "step": 2020
    },
    {
      "epoch": 0.46438419117647056,
      "grad_norm": 1.0753452777862549,
      "learning_rate": 9.278492647058825e-06,
      "loss": 0.1367,
      "step": 2021
    },
    {
      "epoch": 0.4646139705882353,
      "grad_norm": 1.1227871179580688,
      "learning_rate": 9.28308823529412e-06,
      "loss": 0.1142,
      "step": 2022
    },
    {
      "epoch": 0.46484375,
      "grad_norm": 1.1021857261657715,
      "learning_rate": 9.287683823529412e-06,
      "loss": 0.1269,
      "step": 2023
    },
    {
      "epoch": 0.4650735294117647,
      "grad_norm": 1.1755588054656982,
      "learning_rate": 9.292279411764706e-06,
      "loss": 0.1264,
      "step": 2024
    },
    {
      "epoch": 0.46530330882352944,
      "grad_norm": 1.6107267141342163,
      "learning_rate": 9.296875e-06,
      "loss": 0.1753,
      "step": 2025
    },
    {
      "epoch": 0.4655330882352941,
      "grad_norm": 1.8831543922424316,
      "learning_rate": 9.301470588235295e-06,
      "loss": 0.1245,
      "step": 2026
    },
    {
      "epoch": 0.4657628676470588,
      "grad_norm": 1.026104211807251,
      "learning_rate": 9.30606617647059e-06,
      "loss": 0.1116,
      "step": 2027
    },
    {
      "epoch": 0.46599264705882354,
      "grad_norm": 1.3533371686935425,
      "learning_rate": 9.310661764705882e-06,
      "loss": 0.1079,
      "step": 2028
    },
    {
      "epoch": 0.46622242647058826,
      "grad_norm": 1.364377498626709,
      "learning_rate": 9.315257352941178e-06,
      "loss": 0.1177,
      "step": 2029
    },
    {
      "epoch": 0.4664522058823529,
      "grad_norm": 1.252744197845459,
      "learning_rate": 9.319852941176472e-06,
      "loss": 0.1144,
      "step": 2030
    },
    {
      "epoch": 0.46668198529411764,
      "grad_norm": 1.4682127237319946,
      "learning_rate": 9.324448529411767e-06,
      "loss": 0.1833,
      "step": 2031
    },
    {
      "epoch": 0.46691176470588236,
      "grad_norm": 1.069692611694336,
      "learning_rate": 9.32904411764706e-06,
      "loss": 0.1024,
      "step": 2032
    },
    {
      "epoch": 0.4671415441176471,
      "grad_norm": 1.1988515853881836,
      "learning_rate": 9.333639705882354e-06,
      "loss": 0.1123,
      "step": 2033
    },
    {
      "epoch": 0.46737132352941174,
      "grad_norm": 1.282405972480774,
      "learning_rate": 9.338235294117648e-06,
      "loss": 0.1411,
      "step": 2034
    },
    {
      "epoch": 0.46760110294117646,
      "grad_norm": 1.3149608373641968,
      "learning_rate": 9.342830882352942e-06,
      "loss": 0.146,
      "step": 2035
    },
    {
      "epoch": 0.4678308823529412,
      "grad_norm": 1.4272983074188232,
      "learning_rate": 9.347426470588235e-06,
      "loss": 0.0928,
      "step": 2036
    },
    {
      "epoch": 0.4680606617647059,
      "grad_norm": 1.381150484085083,
      "learning_rate": 9.35202205882353e-06,
      "loss": 0.1285,
      "step": 2037
    },
    {
      "epoch": 0.46829044117647056,
      "grad_norm": 1.2605102062225342,
      "learning_rate": 9.356617647058824e-06,
      "loss": 0.0939,
      "step": 2038
    },
    {
      "epoch": 0.4685202205882353,
      "grad_norm": 1.4189141988754272,
      "learning_rate": 9.36121323529412e-06,
      "loss": 0.1326,
      "step": 2039
    },
    {
      "epoch": 0.46875,
      "grad_norm": 1.0545361042022705,
      "learning_rate": 9.365808823529412e-06,
      "loss": 0.1008,
      "step": 2040
    },
    {
      "epoch": 0.4689797794117647,
      "grad_norm": 1.3650202751159668,
      "learning_rate": 9.370404411764707e-06,
      "loss": 0.1385,
      "step": 2041
    },
    {
      "epoch": 0.46920955882352944,
      "grad_norm": 1.0497485399246216,
      "learning_rate": 9.375000000000001e-06,
      "loss": 0.1457,
      "step": 2042
    },
    {
      "epoch": 0.4694393382352941,
      "grad_norm": 1.179366946220398,
      "learning_rate": 9.379595588235295e-06,
      "loss": 0.1219,
      "step": 2043
    },
    {
      "epoch": 0.4696691176470588,
      "grad_norm": 1.3856576681137085,
      "learning_rate": 9.38419117647059e-06,
      "loss": 0.1387,
      "step": 2044
    },
    {
      "epoch": 0.46989889705882354,
      "grad_norm": 1.3680745363235474,
      "learning_rate": 9.388786764705882e-06,
      "loss": 0.1701,
      "step": 2045
    },
    {
      "epoch": 0.47012867647058826,
      "grad_norm": 1.2031382322311401,
      "learning_rate": 9.393382352941176e-06,
      "loss": 0.0961,
      "step": 2046
    },
    {
      "epoch": 0.4703584558823529,
      "grad_norm": 1.4505342245101929,
      "learning_rate": 9.39797794117647e-06,
      "loss": 0.1521,
      "step": 2047
    },
    {
      "epoch": 0.47058823529411764,
      "grad_norm": 1.2489277124404907,
      "learning_rate": 9.402573529411765e-06,
      "loss": 0.1259,
      "step": 2048
    },
    {
      "epoch": 0.47081801470588236,
      "grad_norm": 1.131425142288208,
      "learning_rate": 9.40716911764706e-06,
      "loss": 0.1408,
      "step": 2049
    },
    {
      "epoch": 0.4710477941176471,
      "grad_norm": 1.2295663356781006,
      "learning_rate": 9.411764705882354e-06,
      "loss": 0.1391,
      "step": 2050
    },
    {
      "epoch": 0.47127757352941174,
      "grad_norm": 1.0711371898651123,
      "learning_rate": 9.416360294117648e-06,
      "loss": 0.1081,
      "step": 2051
    },
    {
      "epoch": 0.47150735294117646,
      "grad_norm": 1.5213432312011719,
      "learning_rate": 9.420955882352942e-06,
      "loss": 0.1839,
      "step": 2052
    },
    {
      "epoch": 0.4717371323529412,
      "grad_norm": 1.0497575998306274,
      "learning_rate": 9.425551470588235e-06,
      "loss": 0.1128,
      "step": 2053
    },
    {
      "epoch": 0.4719669117647059,
      "grad_norm": 1.1661968231201172,
      "learning_rate": 9.43014705882353e-06,
      "loss": 0.1407,
      "step": 2054
    },
    {
      "epoch": 0.47219669117647056,
      "grad_norm": 1.338607907295227,
      "learning_rate": 9.434742647058824e-06,
      "loss": 0.1778,
      "step": 2055
    },
    {
      "epoch": 0.4724264705882353,
      "grad_norm": 1.1516143083572388,
      "learning_rate": 9.439338235294118e-06,
      "loss": 0.0922,
      "step": 2056
    },
    {
      "epoch": 0.47265625,
      "grad_norm": 1.0284862518310547,
      "learning_rate": 9.443933823529412e-06,
      "loss": 0.1126,
      "step": 2057
    },
    {
      "epoch": 0.4728860294117647,
      "grad_norm": 1.086513638496399,
      "learning_rate": 9.448529411764707e-06,
      "loss": 0.1318,
      "step": 2058
    },
    {
      "epoch": 0.47311580882352944,
      "grad_norm": 1.349465250968933,
      "learning_rate": 9.453125000000001e-06,
      "loss": 0.135,
      "step": 2059
    },
    {
      "epoch": 0.4733455882352941,
      "grad_norm": 1.0107841491699219,
      "learning_rate": 9.457720588235295e-06,
      "loss": 0.1471,
      "step": 2060
    },
    {
      "epoch": 0.4735753676470588,
      "grad_norm": 1.1794421672821045,
      "learning_rate": 9.46231617647059e-06,
      "loss": 0.1148,
      "step": 2061
    },
    {
      "epoch": 0.47380514705882354,
      "grad_norm": 1.2487255334854126,
      "learning_rate": 9.466911764705882e-06,
      "loss": 0.1042,
      "step": 2062
    },
    {
      "epoch": 0.47403492647058826,
      "grad_norm": 1.1087415218353271,
      "learning_rate": 9.471507352941177e-06,
      "loss": 0.1057,
      "step": 2063
    },
    {
      "epoch": 0.4742647058823529,
      "grad_norm": 1.171038031578064,
      "learning_rate": 9.476102941176471e-06,
      "loss": 0.0998,
      "step": 2064
    },
    {
      "epoch": 0.47449448529411764,
      "grad_norm": 0.9122062921524048,
      "learning_rate": 9.480698529411765e-06,
      "loss": 0.1077,
      "step": 2065
    },
    {
      "epoch": 0.47472426470588236,
      "grad_norm": 0.9017936587333679,
      "learning_rate": 9.48529411764706e-06,
      "loss": 0.1084,
      "step": 2066
    },
    {
      "epoch": 0.4749540441176471,
      "grad_norm": 1.2507014274597168,
      "learning_rate": 9.489889705882354e-06,
      "loss": 0.1177,
      "step": 2067
    },
    {
      "epoch": 0.47518382352941174,
      "grad_norm": 1.2528215646743774,
      "learning_rate": 9.494485294117648e-06,
      "loss": 0.1206,
      "step": 2068
    },
    {
      "epoch": 0.47541360294117646,
      "grad_norm": 1.2324638366699219,
      "learning_rate": 9.499080882352943e-06,
      "loss": 0.1805,
      "step": 2069
    },
    {
      "epoch": 0.4756433823529412,
      "grad_norm": 1.291764736175537,
      "learning_rate": 9.503676470588235e-06,
      "loss": 0.1271,
      "step": 2070
    },
    {
      "epoch": 0.4758731617647059,
      "grad_norm": 1.2370678186416626,
      "learning_rate": 9.50827205882353e-06,
      "loss": 0.1229,
      "step": 2071
    },
    {
      "epoch": 0.47610294117647056,
      "grad_norm": 1.2482175827026367,
      "learning_rate": 9.512867647058824e-06,
      "loss": 0.1563,
      "step": 2072
    },
    {
      "epoch": 0.4763327205882353,
      "grad_norm": 1.1174023151397705,
      "learning_rate": 9.517463235294118e-06,
      "loss": 0.1804,
      "step": 2073
    },
    {
      "epoch": 0.4765625,
      "grad_norm": 1.1247832775115967,
      "learning_rate": 9.522058823529413e-06,
      "loss": 0.129,
      "step": 2074
    },
    {
      "epoch": 0.4767922794117647,
      "grad_norm": 1.024532675743103,
      "learning_rate": 9.526654411764707e-06,
      "loss": 0.1095,
      "step": 2075
    },
    {
      "epoch": 0.47702205882352944,
      "grad_norm": 1.044908046722412,
      "learning_rate": 9.531250000000001e-06,
      "loss": 0.129,
      "step": 2076
    },
    {
      "epoch": 0.4772518382352941,
      "grad_norm": 0.9074631929397583,
      "learning_rate": 9.535845588235296e-06,
      "loss": 0.1283,
      "step": 2077
    },
    {
      "epoch": 0.4774816176470588,
      "grad_norm": 1.1501401662826538,
      "learning_rate": 9.54044117647059e-06,
      "loss": 0.1087,
      "step": 2078
    },
    {
      "epoch": 0.47771139705882354,
      "grad_norm": 1.3602337837219238,
      "learning_rate": 9.545036764705883e-06,
      "loss": 0.1197,
      "step": 2079
    },
    {
      "epoch": 0.47794117647058826,
      "grad_norm": 0.7906039953231812,
      "learning_rate": 9.549632352941177e-06,
      "loss": 0.0923,
      "step": 2080
    },
    {
      "epoch": 0.4781709558823529,
      "grad_norm": 1.15226149559021,
      "learning_rate": 9.554227941176471e-06,
      "loss": 0.1291,
      "step": 2081
    },
    {
      "epoch": 0.47840073529411764,
      "grad_norm": 1.2320530414581299,
      "learning_rate": 9.558823529411766e-06,
      "loss": 0.1048,
      "step": 2082
    },
    {
      "epoch": 0.47863051470588236,
      "grad_norm": 1.4688520431518555,
      "learning_rate": 9.56341911764706e-06,
      "loss": 0.1154,
      "step": 2083
    },
    {
      "epoch": 0.4788602941176471,
      "grad_norm": 1.0315191745758057,
      "learning_rate": 9.568014705882354e-06,
      "loss": 0.1158,
      "step": 2084
    },
    {
      "epoch": 0.47909007352941174,
      "grad_norm": 1.3343688249588013,
      "learning_rate": 9.572610294117649e-06,
      "loss": 0.1709,
      "step": 2085
    },
    {
      "epoch": 0.47931985294117646,
      "grad_norm": 1.223738193511963,
      "learning_rate": 9.577205882352943e-06,
      "loss": 0.1482,
      "step": 2086
    },
    {
      "epoch": 0.4795496323529412,
      "grad_norm": 0.9012192487716675,
      "learning_rate": 9.581801470588236e-06,
      "loss": 0.12,
      "step": 2087
    },
    {
      "epoch": 0.4797794117647059,
      "grad_norm": 1.1968927383422852,
      "learning_rate": 9.58639705882353e-06,
      "loss": 0.1511,
      "step": 2088
    },
    {
      "epoch": 0.48000919117647056,
      "grad_norm": 1.411771535873413,
      "learning_rate": 9.590992647058824e-06,
      "loss": 0.1423,
      "step": 2089
    },
    {
      "epoch": 0.4802389705882353,
      "grad_norm": 1.3683600425720215,
      "learning_rate": 9.595588235294119e-06,
      "loss": 0.1748,
      "step": 2090
    },
    {
      "epoch": 0.48046875,
      "grad_norm": 0.9211931228637695,
      "learning_rate": 9.600183823529413e-06,
      "loss": 0.1285,
      "step": 2091
    },
    {
      "epoch": 0.4806985294117647,
      "grad_norm": 1.0036420822143555,
      "learning_rate": 9.604779411764707e-06,
      "loss": 0.1162,
      "step": 2092
    },
    {
      "epoch": 0.48092830882352944,
      "grad_norm": 1.1427921056747437,
      "learning_rate": 9.609375000000001e-06,
      "loss": 0.1101,
      "step": 2093
    },
    {
      "epoch": 0.4811580882352941,
      "grad_norm": 1.1023145914077759,
      "learning_rate": 9.613970588235296e-06,
      "loss": 0.1561,
      "step": 2094
    },
    {
      "epoch": 0.4813878676470588,
      "grad_norm": 1.0410593748092651,
      "learning_rate": 9.61856617647059e-06,
      "loss": 0.123,
      "step": 2095
    },
    {
      "epoch": 0.48161764705882354,
      "grad_norm": 1.4060181379318237,
      "learning_rate": 9.623161764705883e-06,
      "loss": 0.1613,
      "step": 2096
    },
    {
      "epoch": 0.48184742647058826,
      "grad_norm": 0.9423950910568237,
      "learning_rate": 9.627757352941177e-06,
      "loss": 0.0919,
      "step": 2097
    },
    {
      "epoch": 0.4820772058823529,
      "grad_norm": 1.0645756721496582,
      "learning_rate": 9.632352941176471e-06,
      "loss": 0.0904,
      "step": 2098
    },
    {
      "epoch": 0.48230698529411764,
      "grad_norm": 1.0776937007904053,
      "learning_rate": 9.636948529411766e-06,
      "loss": 0.105,
      "step": 2099
    },
    {
      "epoch": 0.48253676470588236,
      "grad_norm": 1.0517997741699219,
      "learning_rate": 9.641544117647058e-06,
      "loss": 0.1085,
      "step": 2100
    },
    {
      "epoch": 0.4827665441176471,
      "grad_norm": 1.2257612943649292,
      "learning_rate": 9.646139705882354e-06,
      "loss": 0.1274,
      "step": 2101
    },
    {
      "epoch": 0.48299632352941174,
      "grad_norm": 1.405086636543274,
      "learning_rate": 9.650735294117649e-06,
      "loss": 0.1488,
      "step": 2102
    },
    {
      "epoch": 0.48322610294117646,
      "grad_norm": 1.3824975490570068,
      "learning_rate": 9.655330882352943e-06,
      "loss": 0.1367,
      "step": 2103
    },
    {
      "epoch": 0.4834558823529412,
      "grad_norm": 1.1156105995178223,
      "learning_rate": 9.659926470588236e-06,
      "loss": 0.1183,
      "step": 2104
    },
    {
      "epoch": 0.4836856617647059,
      "grad_norm": 0.9722620844841003,
      "learning_rate": 9.66452205882353e-06,
      "loss": 0.0986,
      "step": 2105
    },
    {
      "epoch": 0.48391544117647056,
      "grad_norm": 1.0528264045715332,
      "learning_rate": 9.669117647058824e-06,
      "loss": 0.1207,
      "step": 2106
    },
    {
      "epoch": 0.4841452205882353,
      "grad_norm": 0.9247828125953674,
      "learning_rate": 9.673713235294119e-06,
      "loss": 0.1058,
      "step": 2107
    },
    {
      "epoch": 0.484375,
      "grad_norm": 1.0185350179672241,
      "learning_rate": 9.678308823529411e-06,
      "loss": 0.092,
      "step": 2108
    },
    {
      "epoch": 0.4846047794117647,
      "grad_norm": 1.0975053310394287,
      "learning_rate": 9.682904411764706e-06,
      "loss": 0.1211,
      "step": 2109
    },
    {
      "epoch": 0.48483455882352944,
      "grad_norm": 1.138669490814209,
      "learning_rate": 9.6875e-06,
      "loss": 0.1185,
      "step": 2110
    },
    {
      "epoch": 0.4850643382352941,
      "grad_norm": 1.2301429510116577,
      "learning_rate": 9.692095588235294e-06,
      "loss": 0.0928,
      "step": 2111
    },
    {
      "epoch": 0.4852941176470588,
      "grad_norm": 1.1187834739685059,
      "learning_rate": 9.69669117647059e-06,
      "loss": 0.1611,
      "step": 2112
    },
    {
      "epoch": 0.48552389705882354,
      "grad_norm": 1.1534887552261353,
      "learning_rate": 9.701286764705883e-06,
      "loss": 0.1417,
      "step": 2113
    },
    {
      "epoch": 0.48575367647058826,
      "grad_norm": 1.3064686059951782,
      "learning_rate": 9.705882352941177e-06,
      "loss": 0.1253,
      "step": 2114
    },
    {
      "epoch": 0.4859834558823529,
      "grad_norm": 1.0813804864883423,
      "learning_rate": 9.710477941176472e-06,
      "loss": 0.0954,
      "step": 2115
    },
    {
      "epoch": 0.48621323529411764,
      "grad_norm": 1.1710928678512573,
      "learning_rate": 9.715073529411766e-06,
      "loss": 0.1157,
      "step": 2116
    },
    {
      "epoch": 0.48644301470588236,
      "grad_norm": 0.9248568415641785,
      "learning_rate": 9.719669117647059e-06,
      "loss": 0.1054,
      "step": 2117
    },
    {
      "epoch": 0.4866727941176471,
      "grad_norm": 1.0789828300476074,
      "learning_rate": 9.724264705882353e-06,
      "loss": 0.1239,
      "step": 2118
    },
    {
      "epoch": 0.48690257352941174,
      "grad_norm": 1.4553489685058594,
      "learning_rate": 9.728860294117647e-06,
      "loss": 0.1455,
      "step": 2119
    },
    {
      "epoch": 0.48713235294117646,
      "grad_norm": 1.3219794034957886,
      "learning_rate": 9.733455882352942e-06,
      "loss": 0.0917,
      "step": 2120
    },
    {
      "epoch": 0.4873621323529412,
      "grad_norm": 1.1839878559112549,
      "learning_rate": 9.738051470588236e-06,
      "loss": 0.1098,
      "step": 2121
    },
    {
      "epoch": 0.4875919117647059,
      "grad_norm": 1.410213589668274,
      "learning_rate": 9.74264705882353e-06,
      "loss": 0.1763,
      "step": 2122
    },
    {
      "epoch": 0.48782169117647056,
      "grad_norm": 1.3910415172576904,
      "learning_rate": 9.747242647058825e-06,
      "loss": 0.1657,
      "step": 2123
    },
    {
      "epoch": 0.4880514705882353,
      "grad_norm": 1.0207899808883667,
      "learning_rate": 9.751838235294119e-06,
      "loss": 0.1151,
      "step": 2124
    },
    {
      "epoch": 0.48828125,
      "grad_norm": 0.9108148813247681,
      "learning_rate": 9.756433823529412e-06,
      "loss": 0.1145,
      "step": 2125
    },
    {
      "epoch": 0.4885110294117647,
      "grad_norm": 1.239359974861145,
      "learning_rate": 9.761029411764706e-06,
      "loss": 0.0821,
      "step": 2126
    },
    {
      "epoch": 0.48874080882352944,
      "grad_norm": 0.9057214856147766,
      "learning_rate": 9.765625e-06,
      "loss": 0.0994,
      "step": 2127
    },
    {
      "epoch": 0.4889705882352941,
      "grad_norm": 1.208322525024414,
      "learning_rate": 9.770220588235295e-06,
      "loss": 0.1455,
      "step": 2128
    },
    {
      "epoch": 0.4892003676470588,
      "grad_norm": 1.1983604431152344,
      "learning_rate": 9.774816176470589e-06,
      "loss": 0.1413,
      "step": 2129
    },
    {
      "epoch": 0.48943014705882354,
      "grad_norm": 0.9232826828956604,
      "learning_rate": 9.779411764705883e-06,
      "loss": 0.1102,
      "step": 2130
    },
    {
      "epoch": 0.48965992647058826,
      "grad_norm": 1.2658783197402954,
      "learning_rate": 9.784007352941178e-06,
      "loss": 0.1261,
      "step": 2131
    },
    {
      "epoch": 0.4898897058823529,
      "grad_norm": 1.2238141298294067,
      "learning_rate": 9.788602941176472e-06,
      "loss": 0.1525,
      "step": 2132
    },
    {
      "epoch": 0.49011948529411764,
      "grad_norm": 1.0303730964660645,
      "learning_rate": 9.793198529411766e-06,
      "loss": 0.1065,
      "step": 2133
    },
    {
      "epoch": 0.49034926470588236,
      "grad_norm": 1.1656144857406616,
      "learning_rate": 9.797794117647059e-06,
      "loss": 0.133,
      "step": 2134
    },
    {
      "epoch": 0.4905790441176471,
      "grad_norm": 1.0870579481124878,
      "learning_rate": 9.802389705882353e-06,
      "loss": 0.099,
      "step": 2135
    },
    {
      "epoch": 0.49080882352941174,
      "grad_norm": 0.9049859046936035,
      "learning_rate": 9.806985294117647e-06,
      "loss": 0.1024,
      "step": 2136
    },
    {
      "epoch": 0.49103860294117646,
      "grad_norm": 0.9652726650238037,
      "learning_rate": 9.811580882352942e-06,
      "loss": 0.1064,
      "step": 2137
    },
    {
      "epoch": 0.4912683823529412,
      "grad_norm": 0.830405592918396,
      "learning_rate": 9.816176470588236e-06,
      "loss": 0.1035,
      "step": 2138
    },
    {
      "epoch": 0.4914981617647059,
      "grad_norm": 0.7962098717689514,
      "learning_rate": 9.82077205882353e-06,
      "loss": 0.0846,
      "step": 2139
    },
    {
      "epoch": 0.49172794117647056,
      "grad_norm": 1.104880928993225,
      "learning_rate": 9.825367647058825e-06,
      "loss": 0.1219,
      "step": 2140
    },
    {
      "epoch": 0.4919577205882353,
      "grad_norm": 0.9616323113441467,
      "learning_rate": 9.829963235294119e-06,
      "loss": 0.0934,
      "step": 2141
    },
    {
      "epoch": 0.4921875,
      "grad_norm": 1.4740201234817505,
      "learning_rate": 9.834558823529412e-06,
      "loss": 0.1646,
      "step": 2142
    },
    {
      "epoch": 0.4924172794117647,
      "grad_norm": 0.8042299747467041,
      "learning_rate": 9.839154411764706e-06,
      "loss": 0.0878,
      "step": 2143
    },
    {
      "epoch": 0.49264705882352944,
      "grad_norm": 1.2341870069503784,
      "learning_rate": 9.84375e-06,
      "loss": 0.1085,
      "step": 2144
    },
    {
      "epoch": 0.4928768382352941,
      "grad_norm": 1.0814491510391235,
      "learning_rate": 9.848345588235295e-06,
      "loss": 0.1401,
      "step": 2145
    },
    {
      "epoch": 0.4931066176470588,
      "grad_norm": 1.045772671699524,
      "learning_rate": 9.852941176470589e-06,
      "loss": 0.0988,
      "step": 2146
    },
    {
      "epoch": 0.49333639705882354,
      "grad_norm": 1.0563194751739502,
      "learning_rate": 9.857536764705883e-06,
      "loss": 0.1193,
      "step": 2147
    },
    {
      "epoch": 0.49356617647058826,
      "grad_norm": 1.0981706380844116,
      "learning_rate": 9.862132352941178e-06,
      "loss": 0.1225,
      "step": 2148
    },
    {
      "epoch": 0.4937959558823529,
      "grad_norm": 1.3242549896240234,
      "learning_rate": 9.866727941176472e-06,
      "loss": 0.1188,
      "step": 2149
    },
    {
      "epoch": 0.49402573529411764,
      "grad_norm": 1.1207032203674316,
      "learning_rate": 9.871323529411766e-06,
      "loss": 0.1315,
      "step": 2150
    },
    {
      "epoch": 0.49425551470588236,
      "grad_norm": 1.3320622444152832,
      "learning_rate": 9.875919117647059e-06,
      "loss": 0.142,
      "step": 2151
    },
    {
      "epoch": 0.4944852941176471,
      "grad_norm": 1.3653500080108643,
      "learning_rate": 9.880514705882353e-06,
      "loss": 0.0928,
      "step": 2152
    },
    {
      "epoch": 0.49471507352941174,
      "grad_norm": 1.0490951538085938,
      "learning_rate": 9.885110294117648e-06,
      "loss": 0.1505,
      "step": 2153
    },
    {
      "epoch": 0.49494485294117646,
      "grad_norm": 1.3365360498428345,
      "learning_rate": 9.889705882352942e-06,
      "loss": 0.1537,
      "step": 2154
    },
    {
      "epoch": 0.4951746323529412,
      "grad_norm": 1.2686104774475098,
      "learning_rate": 9.894301470588236e-06,
      "loss": 0.1391,
      "step": 2155
    },
    {
      "epoch": 0.4954044117647059,
      "grad_norm": 1.3187642097473145,
      "learning_rate": 9.89889705882353e-06,
      "loss": 0.1236,
      "step": 2156
    },
    {
      "epoch": 0.49563419117647056,
      "grad_norm": 1.2500077486038208,
      "learning_rate": 9.903492647058825e-06,
      "loss": 0.1303,
      "step": 2157
    },
    {
      "epoch": 0.4958639705882353,
      "grad_norm": 0.798213005065918,
      "learning_rate": 9.90808823529412e-06,
      "loss": 0.0768,
      "step": 2158
    },
    {
      "epoch": 0.49609375,
      "grad_norm": 0.9074397087097168,
      "learning_rate": 9.912683823529412e-06,
      "loss": 0.1304,
      "step": 2159
    },
    {
      "epoch": 0.4963235294117647,
      "grad_norm": 1.2042473554611206,
      "learning_rate": 9.917279411764706e-06,
      "loss": 0.1216,
      "step": 2160
    },
    {
      "epoch": 0.49655330882352944,
      "grad_norm": 1.3036106824874878,
      "learning_rate": 9.921875e-06,
      "loss": 0.1411,
      "step": 2161
    },
    {
      "epoch": 0.4967830882352941,
      "grad_norm": 1.0984601974487305,
      "learning_rate": 9.926470588235295e-06,
      "loss": 0.1332,
      "step": 2162
    },
    {
      "epoch": 0.4970128676470588,
      "grad_norm": 1.2169876098632812,
      "learning_rate": 9.93106617647059e-06,
      "loss": 0.1296,
      "step": 2163
    },
    {
      "epoch": 0.49724264705882354,
      "grad_norm": 1.2443501949310303,
      "learning_rate": 9.935661764705884e-06,
      "loss": 0.1286,
      "step": 2164
    },
    {
      "epoch": 0.49747242647058826,
      "grad_norm": 1.0932836532592773,
      "learning_rate": 9.940257352941178e-06,
      "loss": 0.1465,
      "step": 2165
    },
    {
      "epoch": 0.4977022058823529,
      "grad_norm": 1.0452301502227783,
      "learning_rate": 9.944852941176472e-06,
      "loss": 0.132,
      "step": 2166
    },
    {
      "epoch": 0.49793198529411764,
      "grad_norm": 1.2034555673599243,
      "learning_rate": 9.949448529411767e-06,
      "loss": 0.1111,
      "step": 2167
    },
    {
      "epoch": 0.49816176470588236,
      "grad_norm": 1.459521770477295,
      "learning_rate": 9.95404411764706e-06,
      "loss": 0.1348,
      "step": 2168
    },
    {
      "epoch": 0.4983915441176471,
      "grad_norm": 1.1010212898254395,
      "learning_rate": 9.958639705882354e-06,
      "loss": 0.0943,
      "step": 2169
    },
    {
      "epoch": 0.49862132352941174,
      "grad_norm": 1.2520047426223755,
      "learning_rate": 9.963235294117648e-06,
      "loss": 0.1205,
      "step": 2170
    },
    {
      "epoch": 0.49885110294117646,
      "grad_norm": 1.3354216814041138,
      "learning_rate": 9.967830882352942e-06,
      "loss": 0.1218,
      "step": 2171
    },
    {
      "epoch": 0.4990808823529412,
      "grad_norm": 0.8046383857727051,
      "learning_rate": 9.972426470588235e-06,
      "loss": 0.111,
      "step": 2172
    },
    {
      "epoch": 0.4993106617647059,
      "grad_norm": 0.7885599732398987,
      "learning_rate": 9.977022058823531e-06,
      "loss": 0.0907,
      "step": 2173
    },
    {
      "epoch": 0.49954044117647056,
      "grad_norm": 0.9770687818527222,
      "learning_rate": 9.981617647058825e-06,
      "loss": 0.1374,
      "step": 2174
    },
    {
      "epoch": 0.4997702205882353,
      "grad_norm": 1.2927838563919067,
      "learning_rate": 9.98621323529412e-06,
      "loss": 0.1381,
      "step": 2175
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.9898840188980103,
      "learning_rate": 9.990808823529412e-06,
      "loss": 0.0941,
      "step": 2176
    },
    {
      "epoch": 0.5002297794117647,
      "grad_norm": 1.2631206512451172,
      "learning_rate": 9.995404411764706e-06,
      "loss": 0.1465,
      "step": 2177
    },
    {
      "epoch": 0.5004595588235294,
      "grad_norm": 1.1615657806396484,
      "learning_rate": 1e-05,
      "loss": 0.1395,
      "step": 2178
    },
    {
      "epoch": 0.5006893382352942,
      "grad_norm": 1.1480695009231567,
      "learning_rate": 9.999489379084969e-06,
      "loss": 0.1229,
      "step": 2179
    },
    {
      "epoch": 0.5009191176470589,
      "grad_norm": 1.3057607412338257,
      "learning_rate": 9.998978758169935e-06,
      "loss": 0.1229,
      "step": 2180
    },
    {
      "epoch": 0.5011488970588235,
      "grad_norm": 0.9465891122817993,
      "learning_rate": 9.998468137254903e-06,
      "loss": 0.1285,
      "step": 2181
    },
    {
      "epoch": 0.5013786764705882,
      "grad_norm": 1.3223400115966797,
      "learning_rate": 9.99795751633987e-06,
      "loss": 0.145,
      "step": 2182
    },
    {
      "epoch": 0.5016084558823529,
      "grad_norm": 0.9787965416908264,
      "learning_rate": 9.997446895424837e-06,
      "loss": 0.103,
      "step": 2183
    },
    {
      "epoch": 0.5018382352941176,
      "grad_norm": 1.0052735805511475,
      "learning_rate": 9.996936274509805e-06,
      "loss": 0.107,
      "step": 2184
    },
    {
      "epoch": 0.5020680147058824,
      "grad_norm": 1.1477535963058472,
      "learning_rate": 9.996425653594772e-06,
      "loss": 0.1167,
      "step": 2185
    },
    {
      "epoch": 0.5022977941176471,
      "grad_norm": 1.1602082252502441,
      "learning_rate": 9.995915032679739e-06,
      "loss": 0.0805,
      "step": 2186
    },
    {
      "epoch": 0.5025275735294118,
      "grad_norm": 1.1177176237106323,
      "learning_rate": 9.995404411764706e-06,
      "loss": 0.128,
      "step": 2187
    },
    {
      "epoch": 0.5027573529411765,
      "grad_norm": 1.1938447952270508,
      "learning_rate": 9.994893790849673e-06,
      "loss": 0.1138,
      "step": 2188
    },
    {
      "epoch": 0.5029871323529411,
      "grad_norm": 1.193616271018982,
      "learning_rate": 9.994383169934642e-06,
      "loss": 0.1456,
      "step": 2189
    },
    {
      "epoch": 0.5032169117647058,
      "grad_norm": 1.0098462104797363,
      "learning_rate": 9.993872549019608e-06,
      "loss": 0.1192,
      "step": 2190
    },
    {
      "epoch": 0.5034466911764706,
      "grad_norm": 0.9422884583473206,
      "learning_rate": 9.993361928104576e-06,
      "loss": 0.0693,
      "step": 2191
    },
    {
      "epoch": 0.5036764705882353,
      "grad_norm": 1.1135127544403076,
      "learning_rate": 9.992851307189542e-06,
      "loss": 0.186,
      "step": 2192
    },
    {
      "epoch": 0.50390625,
      "grad_norm": 1.3025264739990234,
      "learning_rate": 9.99234068627451e-06,
      "loss": 0.1453,
      "step": 2193
    },
    {
      "epoch": 0.5041360294117647,
      "grad_norm": 1.5159521102905273,
      "learning_rate": 9.991830065359478e-06,
      "loss": 0.1662,
      "step": 2194
    },
    {
      "epoch": 0.5043658088235294,
      "grad_norm": 1.0629061460494995,
      "learning_rate": 9.991319444444444e-06,
      "loss": 0.1333,
      "step": 2195
    },
    {
      "epoch": 0.5045955882352942,
      "grad_norm": 0.8247624635696411,
      "learning_rate": 9.990808823529412e-06,
      "loss": 0.1015,
      "step": 2196
    },
    {
      "epoch": 0.5048253676470589,
      "grad_norm": 1.152003288269043,
      "learning_rate": 9.99029820261438e-06,
      "loss": 0.1054,
      "step": 2197
    },
    {
      "epoch": 0.5050551470588235,
      "grad_norm": 1.1112359762191772,
      "learning_rate": 9.989787581699348e-06,
      "loss": 0.0976,
      "step": 2198
    },
    {
      "epoch": 0.5052849264705882,
      "grad_norm": 1.1183836460113525,
      "learning_rate": 9.989276960784314e-06,
      "loss": 0.1094,
      "step": 2199
    },
    {
      "epoch": 0.5055147058823529,
      "grad_norm": 1.1332056522369385,
      "learning_rate": 9.988766339869282e-06,
      "loss": 0.11,
      "step": 2200
    },
    {
      "epoch": 0.5057444852941176,
      "grad_norm": 0.9531373381614685,
      "learning_rate": 9.98825571895425e-06,
      "loss": 0.1284,
      "step": 2201
    },
    {
      "epoch": 0.5059742647058824,
      "grad_norm": 1.0401288270950317,
      "learning_rate": 9.987745098039216e-06,
      "loss": 0.0983,
      "step": 2202
    },
    {
      "epoch": 0.5062040441176471,
      "grad_norm": 1.101193904876709,
      "learning_rate": 9.987234477124184e-06,
      "loss": 0.0973,
      "step": 2203
    },
    {
      "epoch": 0.5064338235294118,
      "grad_norm": 1.1807912588119507,
      "learning_rate": 9.98672385620915e-06,
      "loss": 0.0957,
      "step": 2204
    },
    {
      "epoch": 0.5066636029411765,
      "grad_norm": 1.0412334203720093,
      "learning_rate": 9.98621323529412e-06,
      "loss": 0.1041,
      "step": 2205
    },
    {
      "epoch": 0.5068933823529411,
      "grad_norm": 1.413476586341858,
      "learning_rate": 9.985702614379086e-06,
      "loss": 0.1496,
      "step": 2206
    },
    {
      "epoch": 0.5071231617647058,
      "grad_norm": 1.3085819482803345,
      "learning_rate": 9.985191993464054e-06,
      "loss": 0.1695,
      "step": 2207
    },
    {
      "epoch": 0.5073529411764706,
      "grad_norm": 1.3703944683074951,
      "learning_rate": 9.98468137254902e-06,
      "loss": 0.12,
      "step": 2208
    },
    {
      "epoch": 0.5075827205882353,
      "grad_norm": 1.4229929447174072,
      "learning_rate": 9.984170751633988e-06,
      "loss": 0.1424,
      "step": 2209
    },
    {
      "epoch": 0.5078125,
      "grad_norm": 1.175163745880127,
      "learning_rate": 9.983660130718955e-06,
      "loss": 0.0936,
      "step": 2210
    },
    {
      "epoch": 0.5080422794117647,
      "grad_norm": 1.0193912982940674,
      "learning_rate": 9.983149509803922e-06,
      "loss": 0.1367,
      "step": 2211
    },
    {
      "epoch": 0.5082720588235294,
      "grad_norm": 1.6166119575500488,
      "learning_rate": 9.98263888888889e-06,
      "loss": 0.1537,
      "step": 2212
    },
    {
      "epoch": 0.5085018382352942,
      "grad_norm": 1.4659475088119507,
      "learning_rate": 9.982128267973857e-06,
      "loss": 0.107,
      "step": 2213
    },
    {
      "epoch": 0.5087316176470589,
      "grad_norm": 1.0539391040802002,
      "learning_rate": 9.981617647058825e-06,
      "loss": 0.1168,
      "step": 2214
    },
    {
      "epoch": 0.5089613970588235,
      "grad_norm": 1.1358530521392822,
      "learning_rate": 9.981107026143791e-06,
      "loss": 0.117,
      "step": 2215
    },
    {
      "epoch": 0.5091911764705882,
      "grad_norm": 1.029954195022583,
      "learning_rate": 9.98059640522876e-06,
      "loss": 0.0619,
      "step": 2216
    },
    {
      "epoch": 0.5094209558823529,
      "grad_norm": 1.1732125282287598,
      "learning_rate": 9.980085784313727e-06,
      "loss": 0.1048,
      "step": 2217
    },
    {
      "epoch": 0.5096507352941176,
      "grad_norm": 1.24725341796875,
      "learning_rate": 9.979575163398693e-06,
      "loss": 0.1254,
      "step": 2218
    },
    {
      "epoch": 0.5098805147058824,
      "grad_norm": 1.4203439950942993,
      "learning_rate": 9.979064542483661e-06,
      "loss": 0.1355,
      "step": 2219
    },
    {
      "epoch": 0.5101102941176471,
      "grad_norm": 1.3841655254364014,
      "learning_rate": 9.978553921568627e-06,
      "loss": 0.1306,
      "step": 2220
    },
    {
      "epoch": 0.5103400735294118,
      "grad_norm": 0.8511819243431091,
      "learning_rate": 9.978043300653595e-06,
      "loss": 0.0779,
      "step": 2221
    },
    {
      "epoch": 0.5105698529411765,
      "grad_norm": 1.1953963041305542,
      "learning_rate": 9.977532679738563e-06,
      "loss": 0.132,
      "step": 2222
    },
    {
      "epoch": 0.5107996323529411,
      "grad_norm": 1.072077989578247,
      "learning_rate": 9.977022058823531e-06,
      "loss": 0.1252,
      "step": 2223
    },
    {
      "epoch": 0.5110294117647058,
      "grad_norm": 1.039328694343567,
      "learning_rate": 9.976511437908497e-06,
      "loss": 0.0957,
      "step": 2224
    },
    {
      "epoch": 0.5112591911764706,
      "grad_norm": 1.1533417701721191,
      "learning_rate": 9.976000816993465e-06,
      "loss": 0.114,
      "step": 2225
    },
    {
      "epoch": 0.5114889705882353,
      "grad_norm": 1.2452768087387085,
      "learning_rate": 9.975490196078433e-06,
      "loss": 0.1166,
      "step": 2226
    },
    {
      "epoch": 0.51171875,
      "grad_norm": 1.1998347043991089,
      "learning_rate": 9.974979575163399e-06,
      "loss": 0.0841,
      "step": 2227
    },
    {
      "epoch": 0.5119485294117647,
      "grad_norm": 1.0492521524429321,
      "learning_rate": 9.974468954248367e-06,
      "loss": 0.106,
      "step": 2228
    },
    {
      "epoch": 0.5121783088235294,
      "grad_norm": 1.0619428157806396,
      "learning_rate": 9.973958333333335e-06,
      "loss": 0.1114,
      "step": 2229
    },
    {
      "epoch": 0.5124080882352942,
      "grad_norm": 1.3173338174819946,
      "learning_rate": 9.9734477124183e-06,
      "loss": 0.1153,
      "step": 2230
    },
    {
      "epoch": 0.5126378676470589,
      "grad_norm": 1.011982798576355,
      "learning_rate": 9.972937091503269e-06,
      "loss": 0.119,
      "step": 2231
    },
    {
      "epoch": 0.5128676470588235,
      "grad_norm": 1.4322932958602905,
      "learning_rate": 9.972426470588235e-06,
      "loss": 0.1166,
      "step": 2232
    },
    {
      "epoch": 0.5130974264705882,
      "grad_norm": 1.088683009147644,
      "learning_rate": 9.971915849673204e-06,
      "loss": 0.1098,
      "step": 2233
    },
    {
      "epoch": 0.5133272058823529,
      "grad_norm": 1.2406284809112549,
      "learning_rate": 9.97140522875817e-06,
      "loss": 0.1057,
      "step": 2234
    },
    {
      "epoch": 0.5135569852941176,
      "grad_norm": 1.2275246381759644,
      "learning_rate": 9.970894607843138e-06,
      "loss": 0.1261,
      "step": 2235
    },
    {
      "epoch": 0.5137867647058824,
      "grad_norm": 1.5784682035446167,
      "learning_rate": 9.970383986928105e-06,
      "loss": 0.1261,
      "step": 2236
    },
    {
      "epoch": 0.5140165441176471,
      "grad_norm": 1.4282573461532593,
      "learning_rate": 9.969873366013072e-06,
      "loss": 0.1631,
      "step": 2237
    },
    {
      "epoch": 0.5142463235294118,
      "grad_norm": 1.0386221408843994,
      "learning_rate": 9.96936274509804e-06,
      "loss": 0.0979,
      "step": 2238
    },
    {
      "epoch": 0.5144761029411765,
      "grad_norm": 1.2625190019607544,
      "learning_rate": 9.968852124183006e-06,
      "loss": 0.147,
      "step": 2239
    },
    {
      "epoch": 0.5147058823529411,
      "grad_norm": 0.8039332628250122,
      "learning_rate": 9.968341503267974e-06,
      "loss": 0.075,
      "step": 2240
    },
    {
      "epoch": 0.5149356617647058,
      "grad_norm": 0.9756144881248474,
      "learning_rate": 9.967830882352942e-06,
      "loss": 0.1214,
      "step": 2241
    },
    {
      "epoch": 0.5151654411764706,
      "grad_norm": 1.4387692213058472,
      "learning_rate": 9.96732026143791e-06,
      "loss": 0.1453,
      "step": 2242
    },
    {
      "epoch": 0.5153952205882353,
      "grad_norm": 1.009425401687622,
      "learning_rate": 9.966809640522876e-06,
      "loss": 0.0884,
      "step": 2243
    },
    {
      "epoch": 0.515625,
      "grad_norm": 1.1317718029022217,
      "learning_rate": 9.966299019607844e-06,
      "loss": 0.0909,
      "step": 2244
    },
    {
      "epoch": 0.5158547794117647,
      "grad_norm": 1.232926845550537,
      "learning_rate": 9.965788398692812e-06,
      "loss": 0.0986,
      "step": 2245
    },
    {
      "epoch": 0.5160845588235294,
      "grad_norm": 1.3511134386062622,
      "learning_rate": 9.965277777777778e-06,
      "loss": 0.1319,
      "step": 2246
    },
    {
      "epoch": 0.5163143382352942,
      "grad_norm": 1.4539843797683716,
      "learning_rate": 9.964767156862746e-06,
      "loss": 0.1256,
      "step": 2247
    },
    {
      "epoch": 0.5165441176470589,
      "grad_norm": 1.2236765623092651,
      "learning_rate": 9.964256535947712e-06,
      "loss": 0.1353,
      "step": 2248
    },
    {
      "epoch": 0.5167738970588235,
      "grad_norm": 1.107567548751831,
      "learning_rate": 9.963745915032682e-06,
      "loss": 0.0929,
      "step": 2249
    },
    {
      "epoch": 0.5170036764705882,
      "grad_norm": 0.9666826128959656,
      "learning_rate": 9.963235294117648e-06,
      "loss": 0.0791,
      "step": 2250
    },
    {
      "epoch": 0.5172334558823529,
      "grad_norm": 1.2777854204177856,
      "learning_rate": 9.962724673202616e-06,
      "loss": 0.1297,
      "step": 2251
    },
    {
      "epoch": 0.5174632352941176,
      "grad_norm": 1.113118290901184,
      "learning_rate": 9.962214052287582e-06,
      "loss": 0.1047,
      "step": 2252
    },
    {
      "epoch": 0.5176930147058824,
      "grad_norm": 1.471163272857666,
      "learning_rate": 9.96170343137255e-06,
      "loss": 0.1533,
      "step": 2253
    },
    {
      "epoch": 0.5179227941176471,
      "grad_norm": 1.6498295068740845,
      "learning_rate": 9.961192810457518e-06,
      "loss": 0.1188,
      "step": 2254
    },
    {
      "epoch": 0.5181525735294118,
      "grad_norm": 1.518415093421936,
      "learning_rate": 9.960682189542484e-06,
      "loss": 0.0978,
      "step": 2255
    },
    {
      "epoch": 0.5183823529411765,
      "grad_norm": 1.2222894430160522,
      "learning_rate": 9.960171568627452e-06,
      "loss": 0.0996,
      "step": 2256
    },
    {
      "epoch": 0.5186121323529411,
      "grad_norm": 0.8971933722496033,
      "learning_rate": 9.95966094771242e-06,
      "loss": 0.0745,
      "step": 2257
    },
    {
      "epoch": 0.5188419117647058,
      "grad_norm": 1.5288810729980469,
      "learning_rate": 9.959150326797387e-06,
      "loss": 0.1864,
      "step": 2258
    },
    {
      "epoch": 0.5190716911764706,
      "grad_norm": 0.9643171429634094,
      "learning_rate": 9.958639705882354e-06,
      "loss": 0.0963,
      "step": 2259
    },
    {
      "epoch": 0.5193014705882353,
      "grad_norm": 1.381484031677246,
      "learning_rate": 9.958129084967321e-06,
      "loss": 0.1444,
      "step": 2260
    },
    {
      "epoch": 0.51953125,
      "grad_norm": 1.1610273122787476,
      "learning_rate": 9.95761846405229e-06,
      "loss": 0.1285,
      "step": 2261
    },
    {
      "epoch": 0.5197610294117647,
      "grad_norm": 1.4890803098678589,
      "learning_rate": 9.957107843137255e-06,
      "loss": 0.1565,
      "step": 2262
    },
    {
      "epoch": 0.5199908088235294,
      "grad_norm": 1.399876594543457,
      "learning_rate": 9.956597222222223e-06,
      "loss": 0.1176,
      "step": 2263
    },
    {
      "epoch": 0.5202205882352942,
      "grad_norm": 0.9560995101928711,
      "learning_rate": 9.95608660130719e-06,
      "loss": 0.1096,
      "step": 2264
    },
    {
      "epoch": 0.5204503676470589,
      "grad_norm": 1.2219607830047607,
      "learning_rate": 9.955575980392157e-06,
      "loss": 0.1296,
      "step": 2265
    },
    {
      "epoch": 0.5206801470588235,
      "grad_norm": 0.9996525049209595,
      "learning_rate": 9.955065359477125e-06,
      "loss": 0.0884,
      "step": 2266
    },
    {
      "epoch": 0.5209099264705882,
      "grad_norm": 1.248976707458496,
      "learning_rate": 9.954554738562091e-06,
      "loss": 0.1172,
      "step": 2267
    },
    {
      "epoch": 0.5211397058823529,
      "grad_norm": 1.0093722343444824,
      "learning_rate": 9.95404411764706e-06,
      "loss": 0.1011,
      "step": 2268
    },
    {
      "epoch": 0.5213694852941176,
      "grad_norm": 1.2022525072097778,
      "learning_rate": 9.953533496732027e-06,
      "loss": 0.1161,
      "step": 2269
    },
    {
      "epoch": 0.5215992647058824,
      "grad_norm": 0.8915655016899109,
      "learning_rate": 9.953022875816995e-06,
      "loss": 0.079,
      "step": 2270
    },
    {
      "epoch": 0.5218290441176471,
      "grad_norm": 0.8971571922302246,
      "learning_rate": 9.952512254901961e-06,
      "loss": 0.1029,
      "step": 2271
    },
    {
      "epoch": 0.5220588235294118,
      "grad_norm": 1.1163777112960815,
      "learning_rate": 9.952001633986929e-06,
      "loss": 0.1011,
      "step": 2272
    },
    {
      "epoch": 0.5222886029411765,
      "grad_norm": 1.1167079210281372,
      "learning_rate": 9.951491013071897e-06,
      "loss": 0.1023,
      "step": 2273
    },
    {
      "epoch": 0.5225183823529411,
      "grad_norm": 0.9568337798118591,
      "learning_rate": 9.950980392156863e-06,
      "loss": 0.0842,
      "step": 2274
    },
    {
      "epoch": 0.5227481617647058,
      "grad_norm": 1.2692466974258423,
      "learning_rate": 9.950469771241831e-06,
      "loss": 0.1625,
      "step": 2275
    },
    {
      "epoch": 0.5229779411764706,
      "grad_norm": 1.3861143589019775,
      "learning_rate": 9.949959150326797e-06,
      "loss": 0.1225,
      "step": 2276
    },
    {
      "epoch": 0.5232077205882353,
      "grad_norm": 1.0026873350143433,
      "learning_rate": 9.949448529411767e-06,
      "loss": 0.099,
      "step": 2277
    },
    {
      "epoch": 0.5234375,
      "grad_norm": 1.4139493703842163,
      "learning_rate": 9.948937908496733e-06,
      "loss": 0.1479,
      "step": 2278
    },
    {
      "epoch": 0.5236672794117647,
      "grad_norm": 1.6908117532730103,
      "learning_rate": 9.9484272875817e-06,
      "loss": 0.1413,
      "step": 2279
    },
    {
      "epoch": 0.5238970588235294,
      "grad_norm": 1.265028476715088,
      "learning_rate": 9.947916666666667e-06,
      "loss": 0.1358,
      "step": 2280
    },
    {
      "epoch": 0.5241268382352942,
      "grad_norm": 0.8887673020362854,
      "learning_rate": 9.947406045751635e-06,
      "loss": 0.1001,
      "step": 2281
    },
    {
      "epoch": 0.5243566176470589,
      "grad_norm": 1.1486644744873047,
      "learning_rate": 9.946895424836603e-06,
      "loss": 0.0995,
      "step": 2282
    },
    {
      "epoch": 0.5245863970588235,
      "grad_norm": 1.4798113107681274,
      "learning_rate": 9.946384803921569e-06,
      "loss": 0.1526,
      "step": 2283
    },
    {
      "epoch": 0.5248161764705882,
      "grad_norm": 1.2368699312210083,
      "learning_rate": 9.945874183006537e-06,
      "loss": 0.1282,
      "step": 2284
    },
    {
      "epoch": 0.5250459558823529,
      "grad_norm": 1.1238974332809448,
      "learning_rate": 9.945363562091504e-06,
      "loss": 0.1235,
      "step": 2285
    },
    {
      "epoch": 0.5252757352941176,
      "grad_norm": 1.1105530261993408,
      "learning_rate": 9.944852941176472e-06,
      "loss": 0.139,
      "step": 2286
    },
    {
      "epoch": 0.5255055147058824,
      "grad_norm": 1.043717622756958,
      "learning_rate": 9.944342320261438e-06,
      "loss": 0.0938,
      "step": 2287
    },
    {
      "epoch": 0.5257352941176471,
      "grad_norm": 1.0972083806991577,
      "learning_rate": 9.943831699346406e-06,
      "loss": 0.1359,
      "step": 2288
    },
    {
      "epoch": 0.5259650735294118,
      "grad_norm": 1.2223883867263794,
      "learning_rate": 9.943321078431374e-06,
      "loss": 0.1003,
      "step": 2289
    },
    {
      "epoch": 0.5261948529411765,
      "grad_norm": 0.8913204073905945,
      "learning_rate": 9.94281045751634e-06,
      "loss": 0.0872,
      "step": 2290
    },
    {
      "epoch": 0.5264246323529411,
      "grad_norm": 1.1327396631240845,
      "learning_rate": 9.942299836601308e-06,
      "loss": 0.148,
      "step": 2291
    },
    {
      "epoch": 0.5266544117647058,
      "grad_norm": 1.6116758584976196,
      "learning_rate": 9.941789215686274e-06,
      "loss": 0.1225,
      "step": 2292
    },
    {
      "epoch": 0.5268841911764706,
      "grad_norm": 1.0631800889968872,
      "learning_rate": 9.941278594771244e-06,
      "loss": 0.1024,
      "step": 2293
    },
    {
      "epoch": 0.5271139705882353,
      "grad_norm": 0.9963631629943848,
      "learning_rate": 9.94076797385621e-06,
      "loss": 0.1193,
      "step": 2294
    },
    {
      "epoch": 0.52734375,
      "grad_norm": 1.1598713397979736,
      "learning_rate": 9.940257352941178e-06,
      "loss": 0.1239,
      "step": 2295
    },
    {
      "epoch": 0.5275735294117647,
      "grad_norm": 1.507909893989563,
      "learning_rate": 9.939746732026144e-06,
      "loss": 0.1145,
      "step": 2296
    },
    {
      "epoch": 0.5278033088235294,
      "grad_norm": 0.9671367406845093,
      "learning_rate": 9.939236111111112e-06,
      "loss": 0.1473,
      "step": 2297
    },
    {
      "epoch": 0.5280330882352942,
      "grad_norm": 1.0760527849197388,
      "learning_rate": 9.93872549019608e-06,
      "loss": 0.1207,
      "step": 2298
    },
    {
      "epoch": 0.5282628676470589,
      "grad_norm": 1.0849298238754272,
      "learning_rate": 9.938214869281046e-06,
      "loss": 0.0791,
      "step": 2299
    },
    {
      "epoch": 0.5284926470588235,
      "grad_norm": 1.3357126712799072,
      "learning_rate": 9.937704248366014e-06,
      "loss": 0.0941,
      "step": 2300
    },
    {
      "epoch": 0.5287224264705882,
      "grad_norm": 1.0742262601852417,
      "learning_rate": 9.937193627450982e-06,
      "loss": 0.0792,
      "step": 2301
    },
    {
      "epoch": 0.5289522058823529,
      "grad_norm": 0.9269506335258484,
      "learning_rate": 9.93668300653595e-06,
      "loss": 0.0914,
      "step": 2302
    },
    {
      "epoch": 0.5291819852941176,
      "grad_norm": 1.0794163942337036,
      "learning_rate": 9.936172385620916e-06,
      "loss": 0.123,
      "step": 2303
    },
    {
      "epoch": 0.5294117647058824,
      "grad_norm": 1.2597496509552002,
      "learning_rate": 9.935661764705884e-06,
      "loss": 0.1397,
      "step": 2304
    },
    {
      "epoch": 0.5296415441176471,
      "grad_norm": 1.5726313591003418,
      "learning_rate": 9.935151143790851e-06,
      "loss": 0.1559,
      "step": 2305
    },
    {
      "epoch": 0.5298713235294118,
      "grad_norm": 1.0934381484985352,
      "learning_rate": 9.934640522875818e-06,
      "loss": 0.0935,
      "step": 2306
    },
    {
      "epoch": 0.5301011029411765,
      "grad_norm": 1.3583060503005981,
      "learning_rate": 9.934129901960785e-06,
      "loss": 0.1027,
      "step": 2307
    },
    {
      "epoch": 0.5303308823529411,
      "grad_norm": 1.0093907117843628,
      "learning_rate": 9.933619281045752e-06,
      "loss": 0.0947,
      "step": 2308
    },
    {
      "epoch": 0.5305606617647058,
      "grad_norm": 1.0800195932388306,
      "learning_rate": 9.93310866013072e-06,
      "loss": 0.122,
      "step": 2309
    },
    {
      "epoch": 0.5307904411764706,
      "grad_norm": 1.2114620208740234,
      "learning_rate": 9.932598039215687e-06,
      "loss": 0.0957,
      "step": 2310
    },
    {
      "epoch": 0.5310202205882353,
      "grad_norm": 1.0262150764465332,
      "learning_rate": 9.932087418300654e-06,
      "loss": 0.1017,
      "step": 2311
    },
    {
      "epoch": 0.53125,
      "grad_norm": 1.291818380355835,
      "learning_rate": 9.931576797385621e-06,
      "loss": 0.1228,
      "step": 2312
    },
    {
      "epoch": 0.5314797794117647,
      "grad_norm": 1.093904972076416,
      "learning_rate": 9.93106617647059e-06,
      "loss": 0.1081,
      "step": 2313
    },
    {
      "epoch": 0.5317095588235294,
      "grad_norm": 1.3334382772445679,
      "learning_rate": 9.930555555555557e-06,
      "loss": 0.1161,
      "step": 2314
    },
    {
      "epoch": 0.5319393382352942,
      "grad_norm": 1.089984655380249,
      "learning_rate": 9.930044934640523e-06,
      "loss": 0.1261,
      "step": 2315
    },
    {
      "epoch": 0.5321691176470589,
      "grad_norm": 1.10637366771698,
      "learning_rate": 9.929534313725491e-06,
      "loss": 0.1135,
      "step": 2316
    },
    {
      "epoch": 0.5323988970588235,
      "grad_norm": 1.169646143913269,
      "learning_rate": 9.929023692810459e-06,
      "loss": 0.1538,
      "step": 2317
    },
    {
      "epoch": 0.5326286764705882,
      "grad_norm": 1.1028915643692017,
      "learning_rate": 9.928513071895425e-06,
      "loss": 0.1237,
      "step": 2318
    },
    {
      "epoch": 0.5328584558823529,
      "grad_norm": 1.0507384538650513,
      "learning_rate": 9.928002450980393e-06,
      "loss": 0.1272,
      "step": 2319
    },
    {
      "epoch": 0.5330882352941176,
      "grad_norm": 1.0605123043060303,
      "learning_rate": 9.92749183006536e-06,
      "loss": 0.0958,
      "step": 2320
    },
    {
      "epoch": 0.5333180147058824,
      "grad_norm": 0.9891756772994995,
      "learning_rate": 9.926981209150329e-06,
      "loss": 0.1192,
      "step": 2321
    },
    {
      "epoch": 0.5335477941176471,
      "grad_norm": 1.0378990173339844,
      "learning_rate": 9.926470588235295e-06,
      "loss": 0.1168,
      "step": 2322
    },
    {
      "epoch": 0.5337775735294118,
      "grad_norm": 1.1957825422286987,
      "learning_rate": 9.925959967320263e-06,
      "loss": 0.1348,
      "step": 2323
    },
    {
      "epoch": 0.5340073529411765,
      "grad_norm": 1.0650835037231445,
      "learning_rate": 9.925449346405229e-06,
      "loss": 0.099,
      "step": 2324
    },
    {
      "epoch": 0.5342371323529411,
      "grad_norm": 0.8820004463195801,
      "learning_rate": 9.924938725490197e-06,
      "loss": 0.1032,
      "step": 2325
    },
    {
      "epoch": 0.5344669117647058,
      "grad_norm": 1.6015669107437134,
      "learning_rate": 9.924428104575165e-06,
      "loss": 0.1299,
      "step": 2326
    },
    {
      "epoch": 0.5346966911764706,
      "grad_norm": 1.1864855289459229,
      "learning_rate": 9.923917483660131e-06,
      "loss": 0.1132,
      "step": 2327
    },
    {
      "epoch": 0.5349264705882353,
      "grad_norm": 0.7393651604652405,
      "learning_rate": 9.923406862745099e-06,
      "loss": 0.064,
      "step": 2328
    },
    {
      "epoch": 0.53515625,
      "grad_norm": 1.1355983018875122,
      "learning_rate": 9.922896241830067e-06,
      "loss": 0.1049,
      "step": 2329
    },
    {
      "epoch": 0.5353860294117647,
      "grad_norm": 0.9257314205169678,
      "learning_rate": 9.922385620915034e-06,
      "loss": 0.0794,
      "step": 2330
    },
    {
      "epoch": 0.5356158088235294,
      "grad_norm": 1.1213184595108032,
      "learning_rate": 9.921875e-06,
      "loss": 0.0922,
      "step": 2331
    },
    {
      "epoch": 0.5358455882352942,
      "grad_norm": 1.1555707454681396,
      "learning_rate": 9.921364379084968e-06,
      "loss": 0.1087,
      "step": 2332
    },
    {
      "epoch": 0.5360753676470589,
      "grad_norm": 0.9914039373397827,
      "learning_rate": 9.920853758169935e-06,
      "loss": 0.1165,
      "step": 2333
    },
    {
      "epoch": 0.5363051470588235,
      "grad_norm": 1.3167448043823242,
      "learning_rate": 9.920343137254903e-06,
      "loss": 0.1501,
      "step": 2334
    },
    {
      "epoch": 0.5365349264705882,
      "grad_norm": 0.9290014505386353,
      "learning_rate": 9.91983251633987e-06,
      "loss": 0.1014,
      "step": 2335
    },
    {
      "epoch": 0.5367647058823529,
      "grad_norm": 1.5627533197402954,
      "learning_rate": 9.919321895424837e-06,
      "loss": 0.123,
      "step": 2336
    },
    {
      "epoch": 0.5369944852941176,
      "grad_norm": 0.8635360598564148,
      "learning_rate": 9.918811274509804e-06,
      "loss": 0.0992,
      "step": 2337
    },
    {
      "epoch": 0.5372242647058824,
      "grad_norm": 1.3868098258972168,
      "learning_rate": 9.918300653594772e-06,
      "loss": 0.1272,
      "step": 2338
    },
    {
      "epoch": 0.5374540441176471,
      "grad_norm": 1.1947230100631714,
      "learning_rate": 9.91779003267974e-06,
      "loss": 0.1094,
      "step": 2339
    },
    {
      "epoch": 0.5376838235294118,
      "grad_norm": 1.125981092453003,
      "learning_rate": 9.917279411764706e-06,
      "loss": 0.0795,
      "step": 2340
    },
    {
      "epoch": 0.5379136029411765,
      "grad_norm": 1.1610958576202393,
      "learning_rate": 9.916768790849674e-06,
      "loss": 0.0974,
      "step": 2341
    },
    {
      "epoch": 0.5381433823529411,
      "grad_norm": 1.235458493232727,
      "learning_rate": 9.916258169934642e-06,
      "loss": 0.0832,
      "step": 2342
    },
    {
      "epoch": 0.5383731617647058,
      "grad_norm": 1.0712223052978516,
      "learning_rate": 9.915747549019608e-06,
      "loss": 0.1188,
      "step": 2343
    },
    {
      "epoch": 0.5386029411764706,
      "grad_norm": 1.4505592584609985,
      "learning_rate": 9.915236928104576e-06,
      "loss": 0.1518,
      "step": 2344
    },
    {
      "epoch": 0.5388327205882353,
      "grad_norm": 1.439879298210144,
      "learning_rate": 9.914726307189542e-06,
      "loss": 0.1366,
      "step": 2345
    },
    {
      "epoch": 0.5390625,
      "grad_norm": 1.122983455657959,
      "learning_rate": 9.914215686274512e-06,
      "loss": 0.1531,
      "step": 2346
    },
    {
      "epoch": 0.5392922794117647,
      "grad_norm": 1.0590391159057617,
      "learning_rate": 9.913705065359478e-06,
      "loss": 0.1125,
      "step": 2347
    },
    {
      "epoch": 0.5395220588235294,
      "grad_norm": 1.0516234636306763,
      "learning_rate": 9.913194444444446e-06,
      "loss": 0.113,
      "step": 2348
    },
    {
      "epoch": 0.5397518382352942,
      "grad_norm": 1.0943677425384521,
      "learning_rate": 9.912683823529412e-06,
      "loss": 0.1032,
      "step": 2349
    },
    {
      "epoch": 0.5399816176470589,
      "grad_norm": 1.407224416732788,
      "learning_rate": 9.91217320261438e-06,
      "loss": 0.158,
      "step": 2350
    },
    {
      "epoch": 0.5402113970588235,
      "grad_norm": 1.2510491609573364,
      "learning_rate": 9.911662581699348e-06,
      "loss": 0.097,
      "step": 2351
    },
    {
      "epoch": 0.5404411764705882,
      "grad_norm": 0.9392780065536499,
      "learning_rate": 9.911151960784314e-06,
      "loss": 0.1096,
      "step": 2352
    },
    {
      "epoch": 0.5406709558823529,
      "grad_norm": 1.292999505996704,
      "learning_rate": 9.910641339869282e-06,
      "loss": 0.173,
      "step": 2353
    },
    {
      "epoch": 0.5409007352941176,
      "grad_norm": 0.9840829372406006,
      "learning_rate": 9.91013071895425e-06,
      "loss": 0.1121,
      "step": 2354
    },
    {
      "epoch": 0.5411305147058824,
      "grad_norm": 0.9851160645484924,
      "learning_rate": 9.909620098039216e-06,
      "loss": 0.114,
      "step": 2355
    },
    {
      "epoch": 0.5413602941176471,
      "grad_norm": 1.297231912612915,
      "learning_rate": 9.909109477124184e-06,
      "loss": 0.1019,
      "step": 2356
    },
    {
      "epoch": 0.5415900735294118,
      "grad_norm": 1.245642066001892,
      "learning_rate": 9.908598856209151e-06,
      "loss": 0.1012,
      "step": 2357
    },
    {
      "epoch": 0.5418198529411765,
      "grad_norm": 1.0954005718231201,
      "learning_rate": 9.90808823529412e-06,
      "loss": 0.0952,
      "step": 2358
    },
    {
      "epoch": 0.5420496323529411,
      "grad_norm": 1.2428959608078003,
      "learning_rate": 9.907577614379085e-06,
      "loss": 0.0909,
      "step": 2359
    },
    {
      "epoch": 0.5422794117647058,
      "grad_norm": 1.2498807907104492,
      "learning_rate": 9.907066993464053e-06,
      "loss": 0.0965,
      "step": 2360
    },
    {
      "epoch": 0.5425091911764706,
      "grad_norm": 1.2496368885040283,
      "learning_rate": 9.90655637254902e-06,
      "loss": 0.1249,
      "step": 2361
    },
    {
      "epoch": 0.5427389705882353,
      "grad_norm": 1.0354925394058228,
      "learning_rate": 9.906045751633987e-06,
      "loss": 0.1246,
      "step": 2362
    },
    {
      "epoch": 0.54296875,
      "grad_norm": 1.0249526500701904,
      "learning_rate": 9.905535130718955e-06,
      "loss": 0.0958,
      "step": 2363
    },
    {
      "epoch": 0.5431985294117647,
      "grad_norm": 1.0514779090881348,
      "learning_rate": 9.905024509803921e-06,
      "loss": 0.1061,
      "step": 2364
    },
    {
      "epoch": 0.5434283088235294,
      "grad_norm": 1.2977665662765503,
      "learning_rate": 9.90451388888889e-06,
      "loss": 0.097,
      "step": 2365
    },
    {
      "epoch": 0.5436580882352942,
      "grad_norm": 1.0521191358566284,
      "learning_rate": 9.904003267973857e-06,
      "loss": 0.0708,
      "step": 2366
    },
    {
      "epoch": 0.5438878676470589,
      "grad_norm": 1.0145796537399292,
      "learning_rate": 9.903492647058825e-06,
      "loss": 0.1082,
      "step": 2367
    },
    {
      "epoch": 0.5441176470588235,
      "grad_norm": 1.191209077835083,
      "learning_rate": 9.902982026143791e-06,
      "loss": 0.098,
      "step": 2368
    },
    {
      "epoch": 0.5443474264705882,
      "grad_norm": 0.892228364944458,
      "learning_rate": 9.902471405228759e-06,
      "loss": 0.0961,
      "step": 2369
    },
    {
      "epoch": 0.5445772058823529,
      "grad_norm": 1.4737409353256226,
      "learning_rate": 9.901960784313727e-06,
      "loss": 0.1527,
      "step": 2370
    },
    {
      "epoch": 0.5448069852941176,
      "grad_norm": 1.2829360961914062,
      "learning_rate": 9.901450163398693e-06,
      "loss": 0.1126,
      "step": 2371
    },
    {
      "epoch": 0.5450367647058824,
      "grad_norm": 1.4622998237609863,
      "learning_rate": 9.900939542483661e-06,
      "loss": 0.1435,
      "step": 2372
    },
    {
      "epoch": 0.5452665441176471,
      "grad_norm": 1.1021133661270142,
      "learning_rate": 9.900428921568627e-06,
      "loss": 0.1501,
      "step": 2373
    },
    {
      "epoch": 0.5454963235294118,
      "grad_norm": 1.1561716794967651,
      "learning_rate": 9.899918300653597e-06,
      "loss": 0.1226,
      "step": 2374
    },
    {
      "epoch": 0.5457261029411765,
      "grad_norm": 0.9607023596763611,
      "learning_rate": 9.899407679738563e-06,
      "loss": 0.095,
      "step": 2375
    },
    {
      "epoch": 0.5459558823529411,
      "grad_norm": 1.0115422010421753,
      "learning_rate": 9.89889705882353e-06,
      "loss": 0.1125,
      "step": 2376
    },
    {
      "epoch": 0.5461856617647058,
      "grad_norm": 1.5328744649887085,
      "learning_rate": 9.898386437908497e-06,
      "loss": 0.1356,
      "step": 2377
    },
    {
      "epoch": 0.5464154411764706,
      "grad_norm": 1.0290058851242065,
      "learning_rate": 9.897875816993465e-06,
      "loss": 0.0812,
      "step": 2378
    },
    {
      "epoch": 0.5466452205882353,
      "grad_norm": 1.1458948850631714,
      "learning_rate": 9.897365196078433e-06,
      "loss": 0.1332,
      "step": 2379
    },
    {
      "epoch": 0.546875,
      "grad_norm": 1.4131513833999634,
      "learning_rate": 9.896854575163399e-06,
      "loss": 0.1051,
      "step": 2380
    },
    {
      "epoch": 0.5471047794117647,
      "grad_norm": 1.1465815305709839,
      "learning_rate": 9.896343954248367e-06,
      "loss": 0.0923,
      "step": 2381
    },
    {
      "epoch": 0.5473345588235294,
      "grad_norm": 0.9441235661506653,
      "learning_rate": 9.895833333333334e-06,
      "loss": 0.0734,
      "step": 2382
    },
    {
      "epoch": 0.5475643382352942,
      "grad_norm": 1.7358567714691162,
      "learning_rate": 9.895322712418302e-06,
      "loss": 0.1874,
      "step": 2383
    },
    {
      "epoch": 0.5477941176470589,
      "grad_norm": 1.273742914199829,
      "learning_rate": 9.894812091503268e-06,
      "loss": 0.1668,
      "step": 2384
    },
    {
      "epoch": 0.5480238970588235,
      "grad_norm": 1.1267181634902954,
      "learning_rate": 9.894301470588236e-06,
      "loss": 0.1014,
      "step": 2385
    },
    {
      "epoch": 0.5482536764705882,
      "grad_norm": 1.2192515134811401,
      "learning_rate": 9.893790849673204e-06,
      "loss": 0.1256,
      "step": 2386
    },
    {
      "epoch": 0.5484834558823529,
      "grad_norm": 0.7924181818962097,
      "learning_rate": 9.89328022875817e-06,
      "loss": 0.0946,
      "step": 2387
    },
    {
      "epoch": 0.5487132352941176,
      "grad_norm": 1.3376117944717407,
      "learning_rate": 9.892769607843138e-06,
      "loss": 0.1474,
      "step": 2388
    },
    {
      "epoch": 0.5489430147058824,
      "grad_norm": 1.2939575910568237,
      "learning_rate": 9.892258986928104e-06,
      "loss": 0.1298,
      "step": 2389
    },
    {
      "epoch": 0.5491727941176471,
      "grad_norm": 1.0911505222320557,
      "learning_rate": 9.891748366013072e-06,
      "loss": 0.1211,
      "step": 2390
    },
    {
      "epoch": 0.5494025735294118,
      "grad_norm": 0.90421462059021,
      "learning_rate": 9.89123774509804e-06,
      "loss": 0.0827,
      "step": 2391
    },
    {
      "epoch": 0.5496323529411765,
      "grad_norm": 1.107378363609314,
      "learning_rate": 9.890727124183008e-06,
      "loss": 0.1045,
      "step": 2392
    },
    {
      "epoch": 0.5498621323529411,
      "grad_norm": 1.2321624755859375,
      "learning_rate": 9.890216503267974e-06,
      "loss": 0.1206,
      "step": 2393
    },
    {
      "epoch": 0.5500919117647058,
      "grad_norm": 1.298744559288025,
      "learning_rate": 9.889705882352942e-06,
      "loss": 0.1362,
      "step": 2394
    },
    {
      "epoch": 0.5503216911764706,
      "grad_norm": 1.0144531726837158,
      "learning_rate": 9.88919526143791e-06,
      "loss": 0.1007,
      "step": 2395
    },
    {
      "epoch": 0.5505514705882353,
      "grad_norm": 1.0296062231063843,
      "learning_rate": 9.888684640522876e-06,
      "loss": 0.09,
      "step": 2396
    },
    {
      "epoch": 0.55078125,
      "grad_norm": 1.2731945514678955,
      "learning_rate": 9.888174019607844e-06,
      "loss": 0.1207,
      "step": 2397
    },
    {
      "epoch": 0.5510110294117647,
      "grad_norm": 0.8696556687355042,
      "learning_rate": 9.887663398692812e-06,
      "loss": 0.0898,
      "step": 2398
    },
    {
      "epoch": 0.5512408088235294,
      "grad_norm": 1.2915358543395996,
      "learning_rate": 9.887152777777778e-06,
      "loss": 0.1142,
      "step": 2399
    },
    {
      "epoch": 0.5514705882352942,
      "grad_norm": 0.956652820110321,
      "learning_rate": 9.886642156862746e-06,
      "loss": 0.1257,
      "step": 2400
    },
    {
      "epoch": 0.5517003676470589,
      "grad_norm": 1.0317326784133911,
      "learning_rate": 9.886131535947712e-06,
      "loss": 0.0995,
      "step": 2401
    },
    {
      "epoch": 0.5519301470588235,
      "grad_norm": 1.176712989807129,
      "learning_rate": 9.885620915032682e-06,
      "loss": 0.1261,
      "step": 2402
    },
    {
      "epoch": 0.5521599264705882,
      "grad_norm": 1.012307047843933,
      "learning_rate": 9.885110294117648e-06,
      "loss": 0.1175,
      "step": 2403
    },
    {
      "epoch": 0.5523897058823529,
      "grad_norm": 1.1218528747558594,
      "learning_rate": 9.884599673202616e-06,
      "loss": 0.1106,
      "step": 2404
    },
    {
      "epoch": 0.5526194852941176,
      "grad_norm": 0.9925604462623596,
      "learning_rate": 9.884089052287582e-06,
      "loss": 0.1184,
      "step": 2405
    },
    {
      "epoch": 0.5528492647058824,
      "grad_norm": 0.8299647569656372,
      "learning_rate": 9.88357843137255e-06,
      "loss": 0.0914,
      "step": 2406
    },
    {
      "epoch": 0.5530790441176471,
      "grad_norm": 1.051000952720642,
      "learning_rate": 9.883067810457517e-06,
      "loss": 0.1097,
      "step": 2407
    },
    {
      "epoch": 0.5533088235294118,
      "grad_norm": 1.349560260772705,
      "learning_rate": 9.882557189542484e-06,
      "loss": 0.1268,
      "step": 2408
    },
    {
      "epoch": 0.5535386029411765,
      "grad_norm": 1.173923373222351,
      "learning_rate": 9.882046568627451e-06,
      "loss": 0.103,
      "step": 2409
    },
    {
      "epoch": 0.5537683823529411,
      "grad_norm": 1.143878698348999,
      "learning_rate": 9.88153594771242e-06,
      "loss": 0.0893,
      "step": 2410
    },
    {
      "epoch": 0.5539981617647058,
      "grad_norm": 1.148892879486084,
      "learning_rate": 9.881025326797387e-06,
      "loss": 0.1081,
      "step": 2411
    },
    {
      "epoch": 0.5542279411764706,
      "grad_norm": 1.0405157804489136,
      "learning_rate": 9.880514705882353e-06,
      "loss": 0.0985,
      "step": 2412
    },
    {
      "epoch": 0.5544577205882353,
      "grad_norm": 0.9057907462120056,
      "learning_rate": 9.880004084967321e-06,
      "loss": 0.0889,
      "step": 2413
    },
    {
      "epoch": 0.5546875,
      "grad_norm": 0.9187220931053162,
      "learning_rate": 9.879493464052289e-06,
      "loss": 0.0825,
      "step": 2414
    },
    {
      "epoch": 0.5549172794117647,
      "grad_norm": 0.8577021360397339,
      "learning_rate": 9.878982843137255e-06,
      "loss": 0.078,
      "step": 2415
    },
    {
      "epoch": 0.5551470588235294,
      "grad_norm": 1.5331156253814697,
      "learning_rate": 9.878472222222223e-06,
      "loss": 0.1258,
      "step": 2416
    },
    {
      "epoch": 0.5553768382352942,
      "grad_norm": 0.9278163313865662,
      "learning_rate": 9.87796160130719e-06,
      "loss": 0.1133,
      "step": 2417
    },
    {
      "epoch": 0.5556066176470589,
      "grad_norm": 1.0357426404953003,
      "learning_rate": 9.877450980392159e-06,
      "loss": 0.0969,
      "step": 2418
    },
    {
      "epoch": 0.5558363970588235,
      "grad_norm": 0.8958027958869934,
      "learning_rate": 9.876940359477125e-06,
      "loss": 0.1146,
      "step": 2419
    },
    {
      "epoch": 0.5560661764705882,
      "grad_norm": 1.2184945344924927,
      "learning_rate": 9.876429738562093e-06,
      "loss": 0.1137,
      "step": 2420
    },
    {
      "epoch": 0.5562959558823529,
      "grad_norm": 0.9412600994110107,
      "learning_rate": 9.875919117647059e-06,
      "loss": 0.0825,
      "step": 2421
    },
    {
      "epoch": 0.5565257352941176,
      "grad_norm": 0.9963588714599609,
      "learning_rate": 9.875408496732027e-06,
      "loss": 0.1028,
      "step": 2422
    },
    {
      "epoch": 0.5567555147058824,
      "grad_norm": 1.1570683717727661,
      "learning_rate": 9.874897875816995e-06,
      "loss": 0.1134,
      "step": 2423
    },
    {
      "epoch": 0.5569852941176471,
      "grad_norm": 1.0774396657943726,
      "learning_rate": 9.874387254901961e-06,
      "loss": 0.0861,
      "step": 2424
    },
    {
      "epoch": 0.5572150735294118,
      "grad_norm": 1.2656651735305786,
      "learning_rate": 9.873876633986929e-06,
      "loss": 0.1228,
      "step": 2425
    },
    {
      "epoch": 0.5574448529411765,
      "grad_norm": 0.9559096097946167,
      "learning_rate": 9.873366013071897e-06,
      "loss": 0.0774,
      "step": 2426
    },
    {
      "epoch": 0.5576746323529411,
      "grad_norm": 0.9411836862564087,
      "learning_rate": 9.872855392156864e-06,
      "loss": 0.0921,
      "step": 2427
    },
    {
      "epoch": 0.5579044117647058,
      "grad_norm": 1.2664296627044678,
      "learning_rate": 9.87234477124183e-06,
      "loss": 0.0916,
      "step": 2428
    },
    {
      "epoch": 0.5581341911764706,
      "grad_norm": 1.2157684564590454,
      "learning_rate": 9.871834150326799e-06,
      "loss": 0.1442,
      "step": 2429
    },
    {
      "epoch": 0.5583639705882353,
      "grad_norm": 1.5651572942733765,
      "learning_rate": 9.871323529411766e-06,
      "loss": 0.1588,
      "step": 2430
    },
    {
      "epoch": 0.55859375,
      "grad_norm": 1.3843423128128052,
      "learning_rate": 9.870812908496733e-06,
      "loss": 0.1156,
      "step": 2431
    },
    {
      "epoch": 0.5588235294117647,
      "grad_norm": 0.971285879611969,
      "learning_rate": 9.8703022875817e-06,
      "loss": 0.076,
      "step": 2432
    },
    {
      "epoch": 0.5590533088235294,
      "grad_norm": 0.8888388872146606,
      "learning_rate": 9.869791666666667e-06,
      "loss": 0.0669,
      "step": 2433
    },
    {
      "epoch": 0.5592830882352942,
      "grad_norm": 1.0183249711990356,
      "learning_rate": 9.869281045751634e-06,
      "loss": 0.101,
      "step": 2434
    },
    {
      "epoch": 0.5595128676470589,
      "grad_norm": 1.2042814493179321,
      "learning_rate": 9.868770424836602e-06,
      "loss": 0.1031,
      "step": 2435
    },
    {
      "epoch": 0.5597426470588235,
      "grad_norm": 1.3198692798614502,
      "learning_rate": 9.86825980392157e-06,
      "loss": 0.1413,
      "step": 2436
    },
    {
      "epoch": 0.5599724264705882,
      "grad_norm": 1.1745318174362183,
      "learning_rate": 9.867749183006536e-06,
      "loss": 0.1053,
      "step": 2437
    },
    {
      "epoch": 0.5602022058823529,
      "grad_norm": 0.9533587694168091,
      "learning_rate": 9.867238562091504e-06,
      "loss": 0.0686,
      "step": 2438
    },
    {
      "epoch": 0.5604319852941176,
      "grad_norm": 1.1457819938659668,
      "learning_rate": 9.866727941176472e-06,
      "loss": 0.1251,
      "step": 2439
    },
    {
      "epoch": 0.5606617647058824,
      "grad_norm": 1.236488699913025,
      "learning_rate": 9.866217320261438e-06,
      "loss": 0.1119,
      "step": 2440
    },
    {
      "epoch": 0.5608915441176471,
      "grad_norm": 1.0932308435440063,
      "learning_rate": 9.865706699346406e-06,
      "loss": 0.1162,
      "step": 2441
    },
    {
      "epoch": 0.5611213235294118,
      "grad_norm": 1.1091974973678589,
      "learning_rate": 9.865196078431374e-06,
      "loss": 0.1287,
      "step": 2442
    },
    {
      "epoch": 0.5613511029411765,
      "grad_norm": 0.8555285334587097,
      "learning_rate": 9.86468545751634e-06,
      "loss": 0.1019,
      "step": 2443
    },
    {
      "epoch": 0.5615808823529411,
      "grad_norm": 1.1104758977890015,
      "learning_rate": 9.864174836601308e-06,
      "loss": 0.0945,
      "step": 2444
    },
    {
      "epoch": 0.5618106617647058,
      "grad_norm": 1.0929948091506958,
      "learning_rate": 9.863664215686274e-06,
      "loss": 0.126,
      "step": 2445
    },
    {
      "epoch": 0.5620404411764706,
      "grad_norm": 1.3640646934509277,
      "learning_rate": 9.863153594771244e-06,
      "loss": 0.0977,
      "step": 2446
    },
    {
      "epoch": 0.5622702205882353,
      "grad_norm": 1.3796558380126953,
      "learning_rate": 9.86264297385621e-06,
      "loss": 0.0952,
      "step": 2447
    },
    {
      "epoch": 0.5625,
      "grad_norm": 0.9744487404823303,
      "learning_rate": 9.862132352941178e-06,
      "loss": 0.1025,
      "step": 2448
    },
    {
      "epoch": 0.5627297794117647,
      "grad_norm": 1.6488131284713745,
      "learning_rate": 9.861621732026144e-06,
      "loss": 0.1675,
      "step": 2449
    },
    {
      "epoch": 0.5629595588235294,
      "grad_norm": 1.237654447555542,
      "learning_rate": 9.861111111111112e-06,
      "loss": 0.0844,
      "step": 2450
    },
    {
      "epoch": 0.5631893382352942,
      "grad_norm": 1.1189906597137451,
      "learning_rate": 9.86060049019608e-06,
      "loss": 0.1039,
      "step": 2451
    },
    {
      "epoch": 0.5634191176470589,
      "grad_norm": 1.0856386423110962,
      "learning_rate": 9.860089869281046e-06,
      "loss": 0.1014,
      "step": 2452
    },
    {
      "epoch": 0.5636488970588235,
      "grad_norm": 0.9718071222305298,
      "learning_rate": 9.859579248366014e-06,
      "loss": 0.1111,
      "step": 2453
    },
    {
      "epoch": 0.5638786764705882,
      "grad_norm": 1.0951974391937256,
      "learning_rate": 9.859068627450982e-06,
      "loss": 0.1013,
      "step": 2454
    },
    {
      "epoch": 0.5641084558823529,
      "grad_norm": 0.9028110504150391,
      "learning_rate": 9.85855800653595e-06,
      "loss": 0.0752,
      "step": 2455
    },
    {
      "epoch": 0.5643382352941176,
      "grad_norm": 0.755487859249115,
      "learning_rate": 9.858047385620916e-06,
      "loss": 0.1125,
      "step": 2456
    },
    {
      "epoch": 0.5645680147058824,
      "grad_norm": 1.2393543720245361,
      "learning_rate": 9.857536764705883e-06,
      "loss": 0.1204,
      "step": 2457
    },
    {
      "epoch": 0.5647977941176471,
      "grad_norm": 1.187811017036438,
      "learning_rate": 9.857026143790851e-06,
      "loss": 0.1238,
      "step": 2458
    },
    {
      "epoch": 0.5650275735294118,
      "grad_norm": 1.0752923488616943,
      "learning_rate": 9.856515522875817e-06,
      "loss": 0.0715,
      "step": 2459
    },
    {
      "epoch": 0.5652573529411765,
      "grad_norm": 0.9667898416519165,
      "learning_rate": 9.856004901960785e-06,
      "loss": 0.111,
      "step": 2460
    },
    {
      "epoch": 0.5654871323529411,
      "grad_norm": 2.1106910705566406,
      "learning_rate": 9.855494281045751e-06,
      "loss": 0.1807,
      "step": 2461
    },
    {
      "epoch": 0.5657169117647058,
      "grad_norm": 1.202452540397644,
      "learning_rate": 9.854983660130721e-06,
      "loss": 0.095,
      "step": 2462
    },
    {
      "epoch": 0.5659466911764706,
      "grad_norm": 1.0278810262680054,
      "learning_rate": 9.854473039215687e-06,
      "loss": 0.1121,
      "step": 2463
    },
    {
      "epoch": 0.5661764705882353,
      "grad_norm": 0.9520588517189026,
      "learning_rate": 9.853962418300655e-06,
      "loss": 0.1018,
      "step": 2464
    },
    {
      "epoch": 0.56640625,
      "grad_norm": 0.9888231158256531,
      "learning_rate": 9.853451797385621e-06,
      "loss": 0.1152,
      "step": 2465
    },
    {
      "epoch": 0.5666360294117647,
      "grad_norm": 1.266688346862793,
      "learning_rate": 9.852941176470589e-06,
      "loss": 0.1043,
      "step": 2466
    },
    {
      "epoch": 0.5668658088235294,
      "grad_norm": 1.0562065839767456,
      "learning_rate": 9.852430555555557e-06,
      "loss": 0.0679,
      "step": 2467
    },
    {
      "epoch": 0.5670955882352942,
      "grad_norm": 0.9864773154258728,
      "learning_rate": 9.851919934640523e-06,
      "loss": 0.1276,
      "step": 2468
    },
    {
      "epoch": 0.5673253676470589,
      "grad_norm": 1.1526744365692139,
      "learning_rate": 9.851409313725491e-06,
      "loss": 0.1037,
      "step": 2469
    },
    {
      "epoch": 0.5675551470588235,
      "grad_norm": 0.9019576907157898,
      "learning_rate": 9.850898692810459e-06,
      "loss": 0.1119,
      "step": 2470
    },
    {
      "epoch": 0.5677849264705882,
      "grad_norm": 0.9841623902320862,
      "learning_rate": 9.850388071895427e-06,
      "loss": 0.1094,
      "step": 2471
    },
    {
      "epoch": 0.5680147058823529,
      "grad_norm": 1.0536412000656128,
      "learning_rate": 9.849877450980393e-06,
      "loss": 0.0966,
      "step": 2472
    },
    {
      "epoch": 0.5682444852941176,
      "grad_norm": 1.0585914850234985,
      "learning_rate": 9.84936683006536e-06,
      "loss": 0.0878,
      "step": 2473
    },
    {
      "epoch": 0.5684742647058824,
      "grad_norm": 0.9491922855377197,
      "learning_rate": 9.848856209150329e-06,
      "loss": 0.1051,
      "step": 2474
    },
    {
      "epoch": 0.5687040441176471,
      "grad_norm": 1.1731077432632446,
      "learning_rate": 9.848345588235295e-06,
      "loss": 0.0956,
      "step": 2475
    },
    {
      "epoch": 0.5689338235294118,
      "grad_norm": 1.1589545011520386,
      "learning_rate": 9.847834967320263e-06,
      "loss": 0.0883,
      "step": 2476
    },
    {
      "epoch": 0.5691636029411765,
      "grad_norm": 1.117029070854187,
      "learning_rate": 9.847324346405229e-06,
      "loss": 0.0868,
      "step": 2477
    },
    {
      "epoch": 0.5693933823529411,
      "grad_norm": 1.1013414859771729,
      "learning_rate": 9.846813725490197e-06,
      "loss": 0.1246,
      "step": 2478
    },
    {
      "epoch": 0.5696231617647058,
      "grad_norm": 1.5212119817733765,
      "learning_rate": 9.846303104575164e-06,
      "loss": 0.1136,
      "step": 2479
    },
    {
      "epoch": 0.5698529411764706,
      "grad_norm": 1.4958046674728394,
      "learning_rate": 9.845792483660132e-06,
      "loss": 0.1673,
      "step": 2480
    },
    {
      "epoch": 0.5700827205882353,
      "grad_norm": 1.0034282207489014,
      "learning_rate": 9.845281862745099e-06,
      "loss": 0.0798,
      "step": 2481
    },
    {
      "epoch": 0.5703125,
      "grad_norm": 0.9878559112548828,
      "learning_rate": 9.844771241830066e-06,
      "loss": 0.103,
      "step": 2482
    },
    {
      "epoch": 0.5705422794117647,
      "grad_norm": 0.9902399182319641,
      "learning_rate": 9.844260620915034e-06,
      "loss": 0.0888,
      "step": 2483
    },
    {
      "epoch": 0.5707720588235294,
      "grad_norm": 1.628570795059204,
      "learning_rate": 9.84375e-06,
      "loss": 0.1167,
      "step": 2484
    },
    {
      "epoch": 0.5710018382352942,
      "grad_norm": 1.727760910987854,
      "learning_rate": 9.843239379084968e-06,
      "loss": 0.1352,
      "step": 2485
    },
    {
      "epoch": 0.5712316176470589,
      "grad_norm": 1.2400569915771484,
      "learning_rate": 9.842728758169934e-06,
      "loss": 0.0805,
      "step": 2486
    },
    {
      "epoch": 0.5714613970588235,
      "grad_norm": 1.018879771232605,
      "learning_rate": 9.842218137254902e-06,
      "loss": 0.052,
      "step": 2487
    },
    {
      "epoch": 0.5716911764705882,
      "grad_norm": 1.0590022802352905,
      "learning_rate": 9.84170751633987e-06,
      "loss": 0.0958,
      "step": 2488
    },
    {
      "epoch": 0.5719209558823529,
      "grad_norm": 1.2028895616531372,
      "learning_rate": 9.841196895424836e-06,
      "loss": 0.1002,
      "step": 2489
    },
    {
      "epoch": 0.5721507352941176,
      "grad_norm": 1.2720316648483276,
      "learning_rate": 9.840686274509804e-06,
      "loss": 0.109,
      "step": 2490
    },
    {
      "epoch": 0.5723805147058824,
      "grad_norm": 1.209411859512329,
      "learning_rate": 9.840175653594772e-06,
      "loss": 0.1015,
      "step": 2491
    },
    {
      "epoch": 0.5726102941176471,
      "grad_norm": 0.863527774810791,
      "learning_rate": 9.83966503267974e-06,
      "loss": 0.0645,
      "step": 2492
    },
    {
      "epoch": 0.5728400735294118,
      "grad_norm": 1.4561711549758911,
      "learning_rate": 9.839154411764706e-06,
      "loss": 0.1063,
      "step": 2493
    },
    {
      "epoch": 0.5730698529411765,
      "grad_norm": 1.0336110591888428,
      "learning_rate": 9.838643790849674e-06,
      "loss": 0.1132,
      "step": 2494
    },
    {
      "epoch": 0.5732996323529411,
      "grad_norm": 0.9709437489509583,
      "learning_rate": 9.838133169934642e-06,
      "loss": 0.0942,
      "step": 2495
    },
    {
      "epoch": 0.5735294117647058,
      "grad_norm": 1.188677191734314,
      "learning_rate": 9.837622549019608e-06,
      "loss": 0.1043,
      "step": 2496
    },
    {
      "epoch": 0.5737591911764706,
      "grad_norm": 1.455277681350708,
      "learning_rate": 9.837111928104576e-06,
      "loss": 0.1139,
      "step": 2497
    },
    {
      "epoch": 0.5739889705882353,
      "grad_norm": 1.2894582748413086,
      "learning_rate": 9.836601307189542e-06,
      "loss": 0.1202,
      "step": 2498
    },
    {
      "epoch": 0.57421875,
      "grad_norm": 0.9000275135040283,
      "learning_rate": 9.836090686274512e-06,
      "loss": 0.0921,
      "step": 2499
    },
    {
      "epoch": 0.5744485294117647,
      "grad_norm": 1.2918980121612549,
      "learning_rate": 9.835580065359478e-06,
      "loss": 0.0961,
      "step": 2500
    },
    {
      "epoch": 0.5744485294117647,
      "eval_loss": 0.10616721957921982,
      "eval_runtime": 2007.1361,
      "eval_samples_per_second": 4.437,
      "eval_steps_per_second": 2.219,
      "step": 2500
    },
    {
      "epoch": 0.5746783088235294,
      "grad_norm": 1.3252112865447998,
      "learning_rate": 9.835069444444446e-06,
      "loss": 0.0868,
      "step": 2501
    },
    {
      "epoch": 0.5749080882352942,
      "grad_norm": 1.1487579345703125,
      "learning_rate": 9.834558823529412e-06,
      "loss": 0.0871,
      "step": 2502
    },
    {
      "epoch": 0.5751378676470589,
      "grad_norm": 1.454331874847412,
      "learning_rate": 9.83404820261438e-06,
      "loss": 0.1453,
      "step": 2503
    },
    {
      "epoch": 0.5753676470588235,
      "grad_norm": 0.8406856656074524,
      "learning_rate": 9.833537581699347e-06,
      "loss": 0.0724,
      "step": 2504
    },
    {
      "epoch": 0.5755974264705882,
      "grad_norm": 1.3499473333358765,
      "learning_rate": 9.833026960784314e-06,
      "loss": 0.1237,
      "step": 2505
    },
    {
      "epoch": 0.5758272058823529,
      "grad_norm": 1.0791720151901245,
      "learning_rate": 9.832516339869282e-06,
      "loss": 0.0888,
      "step": 2506
    },
    {
      "epoch": 0.5760569852941176,
      "grad_norm": 1.1422879695892334,
      "learning_rate": 9.83200571895425e-06,
      "loss": 0.0644,
      "step": 2507
    },
    {
      "epoch": 0.5762867647058824,
      "grad_norm": 1.2840490341186523,
      "learning_rate": 9.831495098039217e-06,
      "loss": 0.1332,
      "step": 2508
    },
    {
      "epoch": 0.5765165441176471,
      "grad_norm": 1.0986319780349731,
      "learning_rate": 9.830984477124183e-06,
      "loss": 0.0973,
      "step": 2509
    },
    {
      "epoch": 0.5767463235294118,
      "grad_norm": 0.9056594967842102,
      "learning_rate": 9.830473856209151e-06,
      "loss": 0.1043,
      "step": 2510
    },
    {
      "epoch": 0.5769761029411765,
      "grad_norm": 1.4689915180206299,
      "learning_rate": 9.829963235294119e-06,
      "loss": 0.1181,
      "step": 2511
    },
    {
      "epoch": 0.5772058823529411,
      "grad_norm": 0.9499284029006958,
      "learning_rate": 9.829452614379085e-06,
      "loss": 0.1155,
      "step": 2512
    },
    {
      "epoch": 0.5774356617647058,
      "grad_norm": 0.9171773791313171,
      "learning_rate": 9.828941993464053e-06,
      "loss": 0.088,
      "step": 2513
    },
    {
      "epoch": 0.5776654411764706,
      "grad_norm": 1.0648525953292847,
      "learning_rate": 9.82843137254902e-06,
      "loss": 0.0846,
      "step": 2514
    },
    {
      "epoch": 0.5778952205882353,
      "grad_norm": 1.2668101787567139,
      "learning_rate": 9.827920751633989e-06,
      "loss": 0.1022,
      "step": 2515
    },
    {
      "epoch": 0.578125,
      "grad_norm": 1.1924240589141846,
      "learning_rate": 9.827410130718955e-06,
      "loss": 0.1326,
      "step": 2516
    },
    {
      "epoch": 0.5783547794117647,
      "grad_norm": 1.0534788370132446,
      "learning_rate": 9.826899509803923e-06,
      "loss": 0.1101,
      "step": 2517
    },
    {
      "epoch": 0.5785845588235294,
      "grad_norm": 1.0097904205322266,
      "learning_rate": 9.826388888888889e-06,
      "loss": 0.0978,
      "step": 2518
    },
    {
      "epoch": 0.5788143382352942,
      "grad_norm": 1.6988334655761719,
      "learning_rate": 9.825878267973857e-06,
      "loss": 0.1654,
      "step": 2519
    },
    {
      "epoch": 0.5790441176470589,
      "grad_norm": 1.0872496366500854,
      "learning_rate": 9.825367647058825e-06,
      "loss": 0.0854,
      "step": 2520
    },
    {
      "epoch": 0.5792738970588235,
      "grad_norm": 1.0884515047073364,
      "learning_rate": 9.824857026143791e-06,
      "loss": 0.1285,
      "step": 2521
    },
    {
      "epoch": 0.5795036764705882,
      "grad_norm": 0.9955326914787292,
      "learning_rate": 9.824346405228759e-06,
      "loss": 0.0755,
      "step": 2522
    },
    {
      "epoch": 0.5797334558823529,
      "grad_norm": 1.4445174932479858,
      "learning_rate": 9.823835784313727e-06,
      "loss": 0.1062,
      "step": 2523
    },
    {
      "epoch": 0.5799632352941176,
      "grad_norm": 1.1509497165679932,
      "learning_rate": 9.823325163398693e-06,
      "loss": 0.1105,
      "step": 2524
    },
    {
      "epoch": 0.5801930147058824,
      "grad_norm": 1.177793025970459,
      "learning_rate": 9.82281454248366e-06,
      "loss": 0.0969,
      "step": 2525
    },
    {
      "epoch": 0.5804227941176471,
      "grad_norm": 1.1311157941818237,
      "learning_rate": 9.822303921568629e-06,
      "loss": 0.1139,
      "step": 2526
    },
    {
      "epoch": 0.5806525735294118,
      "grad_norm": 0.9699321985244751,
      "learning_rate": 9.821793300653596e-06,
      "loss": 0.1221,
      "step": 2527
    },
    {
      "epoch": 0.5808823529411765,
      "grad_norm": 0.9306278824806213,
      "learning_rate": 9.821282679738563e-06,
      "loss": 0.0904,
      "step": 2528
    },
    {
      "epoch": 0.5811121323529411,
      "grad_norm": 1.2481448650360107,
      "learning_rate": 9.82077205882353e-06,
      "loss": 0.086,
      "step": 2529
    },
    {
      "epoch": 0.5813419117647058,
      "grad_norm": 0.8263349533081055,
      "learning_rate": 9.820261437908497e-06,
      "loss": 0.0994,
      "step": 2530
    },
    {
      "epoch": 0.5815716911764706,
      "grad_norm": 1.352978229522705,
      "learning_rate": 9.819750816993464e-06,
      "loss": 0.1254,
      "step": 2531
    },
    {
      "epoch": 0.5818014705882353,
      "grad_norm": 1.0493179559707642,
      "learning_rate": 9.819240196078432e-06,
      "loss": 0.1049,
      "step": 2532
    },
    {
      "epoch": 0.58203125,
      "grad_norm": 1.159571647644043,
      "learning_rate": 9.818729575163399e-06,
      "loss": 0.0865,
      "step": 2533
    },
    {
      "epoch": 0.5822610294117647,
      "grad_norm": 1.1060744524002075,
      "learning_rate": 9.818218954248366e-06,
      "loss": 0.1585,
      "step": 2534
    },
    {
      "epoch": 0.5824908088235294,
      "grad_norm": 1.0967384576797485,
      "learning_rate": 9.817708333333334e-06,
      "loss": 0.1369,
      "step": 2535
    },
    {
      "epoch": 0.5827205882352942,
      "grad_norm": 1.1157231330871582,
      "learning_rate": 9.817197712418302e-06,
      "loss": 0.1073,
      "step": 2536
    },
    {
      "epoch": 0.5829503676470589,
      "grad_norm": 1.0783979892730713,
      "learning_rate": 9.816687091503268e-06,
      "loss": 0.0876,
      "step": 2537
    },
    {
      "epoch": 0.5831801470588235,
      "grad_norm": 1.1439656019210815,
      "learning_rate": 9.816176470588236e-06,
      "loss": 0.114,
      "step": 2538
    },
    {
      "epoch": 0.5834099264705882,
      "grad_norm": 0.8552457094192505,
      "learning_rate": 9.815665849673204e-06,
      "loss": 0.0841,
      "step": 2539
    },
    {
      "epoch": 0.5836397058823529,
      "grad_norm": 1.2721229791641235,
      "learning_rate": 9.81515522875817e-06,
      "loss": 0.1126,
      "step": 2540
    },
    {
      "epoch": 0.5838694852941176,
      "grad_norm": 0.9734159708023071,
      "learning_rate": 9.814644607843138e-06,
      "loss": 0.1008,
      "step": 2541
    },
    {
      "epoch": 0.5840992647058824,
      "grad_norm": 1.1876991987228394,
      "learning_rate": 9.814133986928104e-06,
      "loss": 0.1155,
      "step": 2542
    },
    {
      "epoch": 0.5843290441176471,
      "grad_norm": 1.207907795906067,
      "learning_rate": 9.813623366013074e-06,
      "loss": 0.108,
      "step": 2543
    },
    {
      "epoch": 0.5845588235294118,
      "grad_norm": 1.134926199913025,
      "learning_rate": 9.81311274509804e-06,
      "loss": 0.0865,
      "step": 2544
    },
    {
      "epoch": 0.5847886029411765,
      "grad_norm": 1.0184179544448853,
      "learning_rate": 9.812602124183008e-06,
      "loss": 0.0832,
      "step": 2545
    },
    {
      "epoch": 0.5850183823529411,
      "grad_norm": 1.1858307123184204,
      "learning_rate": 9.812091503267974e-06,
      "loss": 0.1066,
      "step": 2546
    },
    {
      "epoch": 0.5852481617647058,
      "grad_norm": 1.052231788635254,
      "learning_rate": 9.811580882352942e-06,
      "loss": 0.1079,
      "step": 2547
    },
    {
      "epoch": 0.5854779411764706,
      "grad_norm": 0.8945061564445496,
      "learning_rate": 9.81107026143791e-06,
      "loss": 0.0715,
      "step": 2548
    },
    {
      "epoch": 0.5857077205882353,
      "grad_norm": 1.0272102355957031,
      "learning_rate": 9.810559640522876e-06,
      "loss": 0.0882,
      "step": 2549
    },
    {
      "epoch": 0.5859375,
      "grad_norm": 1.049504280090332,
      "learning_rate": 9.810049019607844e-06,
      "loss": 0.0925,
      "step": 2550
    },
    {
      "epoch": 0.5861672794117647,
      "grad_norm": 0.9682004451751709,
      "learning_rate": 9.809538398692812e-06,
      "loss": 0.0667,
      "step": 2551
    },
    {
      "epoch": 0.5863970588235294,
      "grad_norm": 1.2352389097213745,
      "learning_rate": 9.80902777777778e-06,
      "loss": 0.0879,
      "step": 2552
    },
    {
      "epoch": 0.5866268382352942,
      "grad_norm": 1.007954478263855,
      "learning_rate": 9.808517156862746e-06,
      "loss": 0.115,
      "step": 2553
    },
    {
      "epoch": 0.5868566176470589,
      "grad_norm": 0.7868031859397888,
      "learning_rate": 9.808006535947713e-06,
      "loss": 0.0853,
      "step": 2554
    },
    {
      "epoch": 0.5870863970588235,
      "grad_norm": 1.134044885635376,
      "learning_rate": 9.807495915032681e-06,
      "loss": 0.0997,
      "step": 2555
    },
    {
      "epoch": 0.5873161764705882,
      "grad_norm": 1.032863974571228,
      "learning_rate": 9.806985294117647e-06,
      "loss": 0.081,
      "step": 2556
    },
    {
      "epoch": 0.5875459558823529,
      "grad_norm": 1.3579771518707275,
      "learning_rate": 9.806474673202615e-06,
      "loss": 0.1052,
      "step": 2557
    },
    {
      "epoch": 0.5877757352941176,
      "grad_norm": 1.1379060745239258,
      "learning_rate": 9.805964052287581e-06,
      "loss": 0.0869,
      "step": 2558
    },
    {
      "epoch": 0.5880055147058824,
      "grad_norm": 1.2168586254119873,
      "learning_rate": 9.805453431372551e-06,
      "loss": 0.1432,
      "step": 2559
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 1.3364542722702026,
      "learning_rate": 9.804942810457517e-06,
      "loss": 0.1065,
      "step": 2560
    },
    {
      "epoch": 0.5884650735294118,
      "grad_norm": 1.0660851001739502,
      "learning_rate": 9.804432189542485e-06,
      "loss": 0.1119,
      "step": 2561
    },
    {
      "epoch": 0.5886948529411765,
      "grad_norm": 1.0985671281814575,
      "learning_rate": 9.803921568627451e-06,
      "loss": 0.1257,
      "step": 2562
    },
    {
      "epoch": 0.5889246323529411,
      "grad_norm": 1.064684510231018,
      "learning_rate": 9.803410947712419e-06,
      "loss": 0.1051,
      "step": 2563
    },
    {
      "epoch": 0.5891544117647058,
      "grad_norm": 1.7150418758392334,
      "learning_rate": 9.802900326797387e-06,
      "loss": 0.149,
      "step": 2564
    },
    {
      "epoch": 0.5893841911764706,
      "grad_norm": 0.9209010601043701,
      "learning_rate": 9.802389705882353e-06,
      "loss": 0.0734,
      "step": 2565
    },
    {
      "epoch": 0.5896139705882353,
      "grad_norm": 1.2168891429901123,
      "learning_rate": 9.801879084967321e-06,
      "loss": 0.0647,
      "step": 2566
    },
    {
      "epoch": 0.58984375,
      "grad_norm": 1.1179252862930298,
      "learning_rate": 9.801368464052289e-06,
      "loss": 0.1201,
      "step": 2567
    },
    {
      "epoch": 0.5900735294117647,
      "grad_norm": 1.55135977268219,
      "learning_rate": 9.800857843137255e-06,
      "loss": 0.1129,
      "step": 2568
    },
    {
      "epoch": 0.5903033088235294,
      "grad_norm": 1.0944147109985352,
      "learning_rate": 9.800347222222223e-06,
      "loss": 0.1159,
      "step": 2569
    },
    {
      "epoch": 0.5905330882352942,
      "grad_norm": 1.0783908367156982,
      "learning_rate": 9.79983660130719e-06,
      "loss": 0.0956,
      "step": 2570
    },
    {
      "epoch": 0.5907628676470589,
      "grad_norm": 1.1474697589874268,
      "learning_rate": 9.799325980392159e-06,
      "loss": 0.1,
      "step": 2571
    },
    {
      "epoch": 0.5909926470588235,
      "grad_norm": 1.4899024963378906,
      "learning_rate": 9.798815359477125e-06,
      "loss": 0.1375,
      "step": 2572
    },
    {
      "epoch": 0.5912224264705882,
      "grad_norm": 1.3608125448226929,
      "learning_rate": 9.798304738562093e-06,
      "loss": 0.1192,
      "step": 2573
    },
    {
      "epoch": 0.5914522058823529,
      "grad_norm": 0.967264711856842,
      "learning_rate": 9.797794117647059e-06,
      "loss": 0.1066,
      "step": 2574
    },
    {
      "epoch": 0.5916819852941176,
      "grad_norm": 1.1686866283416748,
      "learning_rate": 9.797283496732027e-06,
      "loss": 0.1021,
      "step": 2575
    },
    {
      "epoch": 0.5919117647058824,
      "grad_norm": 1.2497495412826538,
      "learning_rate": 9.796772875816995e-06,
      "loss": 0.1037,
      "step": 2576
    },
    {
      "epoch": 0.5921415441176471,
      "grad_norm": 1.0343726873397827,
      "learning_rate": 9.79626225490196e-06,
      "loss": 0.1234,
      "step": 2577
    },
    {
      "epoch": 0.5923713235294118,
      "grad_norm": 1.1757959127426147,
      "learning_rate": 9.795751633986929e-06,
      "loss": 0.0963,
      "step": 2578
    },
    {
      "epoch": 0.5926011029411765,
      "grad_norm": 1.368317723274231,
      "learning_rate": 9.795241013071896e-06,
      "loss": 0.202,
      "step": 2579
    },
    {
      "epoch": 0.5928308823529411,
      "grad_norm": 0.9950820803642273,
      "learning_rate": 9.794730392156864e-06,
      "loss": 0.1197,
      "step": 2580
    },
    {
      "epoch": 0.5930606617647058,
      "grad_norm": 1.1806893348693848,
      "learning_rate": 9.79421977124183e-06,
      "loss": 0.1061,
      "step": 2581
    },
    {
      "epoch": 0.5932904411764706,
      "grad_norm": 1.1436712741851807,
      "learning_rate": 9.793709150326798e-06,
      "loss": 0.0833,
      "step": 2582
    },
    {
      "epoch": 0.5935202205882353,
      "grad_norm": 1.0882002115249634,
      "learning_rate": 9.793198529411766e-06,
      "loss": 0.1027,
      "step": 2583
    },
    {
      "epoch": 0.59375,
      "grad_norm": 1.0491863489151,
      "learning_rate": 9.792687908496732e-06,
      "loss": 0.1207,
      "step": 2584
    },
    {
      "epoch": 0.5939797794117647,
      "grad_norm": 0.999463677406311,
      "learning_rate": 9.7921772875817e-06,
      "loss": 0.0864,
      "step": 2585
    },
    {
      "epoch": 0.5942095588235294,
      "grad_norm": 1.1943482160568237,
      "learning_rate": 9.791666666666666e-06,
      "loss": 0.1469,
      "step": 2586
    },
    {
      "epoch": 0.5944393382352942,
      "grad_norm": 1.0628304481506348,
      "learning_rate": 9.791156045751636e-06,
      "loss": 0.1118,
      "step": 2587
    },
    {
      "epoch": 0.5946691176470589,
      "grad_norm": 1.2218044996261597,
      "learning_rate": 9.790645424836602e-06,
      "loss": 0.0857,
      "step": 2588
    },
    {
      "epoch": 0.5948988970588235,
      "grad_norm": 0.9802399277687073,
      "learning_rate": 9.79013480392157e-06,
      "loss": 0.1024,
      "step": 2589
    },
    {
      "epoch": 0.5951286764705882,
      "grad_norm": 1.0666077136993408,
      "learning_rate": 9.789624183006536e-06,
      "loss": 0.1003,
      "step": 2590
    },
    {
      "epoch": 0.5953584558823529,
      "grad_norm": 1.2533655166625977,
      "learning_rate": 9.789113562091504e-06,
      "loss": 0.1097,
      "step": 2591
    },
    {
      "epoch": 0.5955882352941176,
      "grad_norm": 1.1642788648605347,
      "learning_rate": 9.788602941176472e-06,
      "loss": 0.1025,
      "step": 2592
    },
    {
      "epoch": 0.5958180147058824,
      "grad_norm": 0.970830500125885,
      "learning_rate": 9.788092320261438e-06,
      "loss": 0.1255,
      "step": 2593
    },
    {
      "epoch": 0.5960477941176471,
      "grad_norm": 1.2326210737228394,
      "learning_rate": 9.787581699346406e-06,
      "loss": 0.1077,
      "step": 2594
    },
    {
      "epoch": 0.5962775735294118,
      "grad_norm": 1.0873974561691284,
      "learning_rate": 9.787071078431374e-06,
      "loss": 0.1036,
      "step": 2595
    },
    {
      "epoch": 0.5965073529411765,
      "grad_norm": 0.9637680649757385,
      "learning_rate": 9.786560457516342e-06,
      "loss": 0.0865,
      "step": 2596
    },
    {
      "epoch": 0.5967371323529411,
      "grad_norm": 1.2319719791412354,
      "learning_rate": 9.786049836601308e-06,
      "loss": 0.0848,
      "step": 2597
    },
    {
      "epoch": 0.5969669117647058,
      "grad_norm": 1.3166749477386475,
      "learning_rate": 9.785539215686276e-06,
      "loss": 0.0969,
      "step": 2598
    },
    {
      "epoch": 0.5971966911764706,
      "grad_norm": 1.2608017921447754,
      "learning_rate": 9.785028594771243e-06,
      "loss": 0.1126,
      "step": 2599
    },
    {
      "epoch": 0.5974264705882353,
      "grad_norm": 1.1029309034347534,
      "learning_rate": 9.78451797385621e-06,
      "loss": 0.1195,
      "step": 2600
    },
    {
      "epoch": 0.59765625,
      "grad_norm": 0.9034919738769531,
      "learning_rate": 9.784007352941178e-06,
      "loss": 0.086,
      "step": 2601
    },
    {
      "epoch": 0.5978860294117647,
      "grad_norm": 0.9807526469230652,
      "learning_rate": 9.783496732026144e-06,
      "loss": 0.0689,
      "step": 2602
    },
    {
      "epoch": 0.5981158088235294,
      "grad_norm": 1.0256295204162598,
      "learning_rate": 9.782986111111113e-06,
      "loss": 0.1127,
      "step": 2603
    },
    {
      "epoch": 0.5983455882352942,
      "grad_norm": 1.1974011659622192,
      "learning_rate": 9.78247549019608e-06,
      "loss": 0.1169,
      "step": 2604
    },
    {
      "epoch": 0.5985753676470589,
      "grad_norm": 1.1404134035110474,
      "learning_rate": 9.781964869281047e-06,
      "loss": 0.1024,
      "step": 2605
    },
    {
      "epoch": 0.5988051470588235,
      "grad_norm": 1.154616117477417,
      "learning_rate": 9.781454248366013e-06,
      "loss": 0.1076,
      "step": 2606
    },
    {
      "epoch": 0.5990349264705882,
      "grad_norm": 1.2610208988189697,
      "learning_rate": 9.780943627450981e-06,
      "loss": 0.1136,
      "step": 2607
    },
    {
      "epoch": 0.5992647058823529,
      "grad_norm": 1.2039645910263062,
      "learning_rate": 9.78043300653595e-06,
      "loss": 0.0694,
      "step": 2608
    },
    {
      "epoch": 0.5994944852941176,
      "grad_norm": 1.102624535560608,
      "learning_rate": 9.779922385620915e-06,
      "loss": 0.1065,
      "step": 2609
    },
    {
      "epoch": 0.5997242647058824,
      "grad_norm": 1.1808792352676392,
      "learning_rate": 9.779411764705883e-06,
      "loss": 0.09,
      "step": 2610
    },
    {
      "epoch": 0.5999540441176471,
      "grad_norm": 1.4288194179534912,
      "learning_rate": 9.778901143790851e-06,
      "loss": 0.1129,
      "step": 2611
    },
    {
      "epoch": 0.6001838235294118,
      "grad_norm": 1.156667947769165,
      "learning_rate": 9.778390522875817e-06,
      "loss": 0.1127,
      "step": 2612
    },
    {
      "epoch": 0.6004136029411765,
      "grad_norm": 1.0894979238510132,
      "learning_rate": 9.777879901960785e-06,
      "loss": 0.1198,
      "step": 2613
    },
    {
      "epoch": 0.6006433823529411,
      "grad_norm": 0.8997941613197327,
      "learning_rate": 9.777369281045753e-06,
      "loss": 0.069,
      "step": 2614
    },
    {
      "epoch": 0.6008731617647058,
      "grad_norm": 1.2395374774932861,
      "learning_rate": 9.77685866013072e-06,
      "loss": 0.1069,
      "step": 2615
    },
    {
      "epoch": 0.6011029411764706,
      "grad_norm": 0.9752118587493896,
      "learning_rate": 9.776348039215687e-06,
      "loss": 0.073,
      "step": 2616
    },
    {
      "epoch": 0.6013327205882353,
      "grad_norm": 1.074499487876892,
      "learning_rate": 9.775837418300655e-06,
      "loss": 0.0985,
      "step": 2617
    },
    {
      "epoch": 0.6015625,
      "grad_norm": 1.260589599609375,
      "learning_rate": 9.775326797385621e-06,
      "loss": 0.1182,
      "step": 2618
    },
    {
      "epoch": 0.6017922794117647,
      "grad_norm": 1.1515660285949707,
      "learning_rate": 9.774816176470589e-06,
      "loss": 0.0889,
      "step": 2619
    },
    {
      "epoch": 0.6020220588235294,
      "grad_norm": 0.753275454044342,
      "learning_rate": 9.774305555555557e-06,
      "loss": 0.0927,
      "step": 2620
    },
    {
      "epoch": 0.6022518382352942,
      "grad_norm": 0.8353182673454285,
      "learning_rate": 9.773794934640523e-06,
      "loss": 0.0854,
      "step": 2621
    },
    {
      "epoch": 0.6024816176470589,
      "grad_norm": 1.3497012853622437,
      "learning_rate": 9.77328431372549e-06,
      "loss": 0.1002,
      "step": 2622
    },
    {
      "epoch": 0.6027113970588235,
      "grad_norm": 1.0614557266235352,
      "learning_rate": 9.772773692810459e-06,
      "loss": 0.1068,
      "step": 2623
    },
    {
      "epoch": 0.6029411764705882,
      "grad_norm": 0.887925922870636,
      "learning_rate": 9.772263071895426e-06,
      "loss": 0.0838,
      "step": 2624
    },
    {
      "epoch": 0.6031709558823529,
      "grad_norm": 0.9273717999458313,
      "learning_rate": 9.771752450980393e-06,
      "loss": 0.0849,
      "step": 2625
    },
    {
      "epoch": 0.6034007352941176,
      "grad_norm": 1.248619556427002,
      "learning_rate": 9.77124183006536e-06,
      "loss": 0.0979,
      "step": 2626
    },
    {
      "epoch": 0.6036305147058824,
      "grad_norm": 1.0718690156936646,
      "learning_rate": 9.770731209150328e-06,
      "loss": 0.107,
      "step": 2627
    },
    {
      "epoch": 0.6038602941176471,
      "grad_norm": 1.338559865951538,
      "learning_rate": 9.770220588235295e-06,
      "loss": 0.1175,
      "step": 2628
    },
    {
      "epoch": 0.6040900735294118,
      "grad_norm": 1.0116056203842163,
      "learning_rate": 9.769709967320262e-06,
      "loss": 0.0719,
      "step": 2629
    },
    {
      "epoch": 0.6043198529411765,
      "grad_norm": 1.1217129230499268,
      "learning_rate": 9.769199346405229e-06,
      "loss": 0.0981,
      "step": 2630
    },
    {
      "epoch": 0.6045496323529411,
      "grad_norm": 1.1391931772232056,
      "learning_rate": 9.768688725490198e-06,
      "loss": 0.0952,
      "step": 2631
    },
    {
      "epoch": 0.6047794117647058,
      "grad_norm": 1.1556767225265503,
      "learning_rate": 9.768178104575164e-06,
      "loss": 0.1096,
      "step": 2632
    },
    {
      "epoch": 0.6050091911764706,
      "grad_norm": 0.9240356683731079,
      "learning_rate": 9.767667483660132e-06,
      "loss": 0.0846,
      "step": 2633
    },
    {
      "epoch": 0.6052389705882353,
      "grad_norm": 1.1495460271835327,
      "learning_rate": 9.767156862745098e-06,
      "loss": 0.0841,
      "step": 2634
    },
    {
      "epoch": 0.60546875,
      "grad_norm": 1.2285597324371338,
      "learning_rate": 9.766646241830066e-06,
      "loss": 0.1068,
      "step": 2635
    },
    {
      "epoch": 0.6056985294117647,
      "grad_norm": 1.383602499961853,
      "learning_rate": 9.766135620915034e-06,
      "loss": 0.1156,
      "step": 2636
    },
    {
      "epoch": 0.6059283088235294,
      "grad_norm": 1.4492589235305786,
      "learning_rate": 9.765625e-06,
      "loss": 0.1473,
      "step": 2637
    },
    {
      "epoch": 0.6061580882352942,
      "grad_norm": 0.9510647654533386,
      "learning_rate": 9.765114379084968e-06,
      "loss": 0.0736,
      "step": 2638
    },
    {
      "epoch": 0.6063878676470589,
      "grad_norm": 1.113747477531433,
      "learning_rate": 9.764603758169934e-06,
      "loss": 0.1214,
      "step": 2639
    },
    {
      "epoch": 0.6066176470588235,
      "grad_norm": 0.9187319874763489,
      "learning_rate": 9.764093137254904e-06,
      "loss": 0.1125,
      "step": 2640
    },
    {
      "epoch": 0.6068474264705882,
      "grad_norm": 1.066044569015503,
      "learning_rate": 9.76358251633987e-06,
      "loss": 0.1296,
      "step": 2641
    },
    {
      "epoch": 0.6070772058823529,
      "grad_norm": 1.0018329620361328,
      "learning_rate": 9.763071895424838e-06,
      "loss": 0.0842,
      "step": 2642
    },
    {
      "epoch": 0.6073069852941176,
      "grad_norm": 1.7838584184646606,
      "learning_rate": 9.762561274509804e-06,
      "loss": 0.1,
      "step": 2643
    },
    {
      "epoch": 0.6075367647058824,
      "grad_norm": 1.2540298700332642,
      "learning_rate": 9.762050653594772e-06,
      "loss": 0.0899,
      "step": 2644
    },
    {
      "epoch": 0.6077665441176471,
      "grad_norm": 1.2287245988845825,
      "learning_rate": 9.76154003267974e-06,
      "loss": 0.1578,
      "step": 2645
    },
    {
      "epoch": 0.6079963235294118,
      "grad_norm": 0.8593686819076538,
      "learning_rate": 9.761029411764706e-06,
      "loss": 0.0687,
      "step": 2646
    },
    {
      "epoch": 0.6082261029411765,
      "grad_norm": 1.3843672275543213,
      "learning_rate": 9.760518790849674e-06,
      "loss": 0.0826,
      "step": 2647
    },
    {
      "epoch": 0.6084558823529411,
      "grad_norm": 1.11667799949646,
      "learning_rate": 9.760008169934642e-06,
      "loss": 0.1166,
      "step": 2648
    },
    {
      "epoch": 0.6086856617647058,
      "grad_norm": 0.8687047958374023,
      "learning_rate": 9.75949754901961e-06,
      "loss": 0.1035,
      "step": 2649
    },
    {
      "epoch": 0.6089154411764706,
      "grad_norm": 1.155714988708496,
      "learning_rate": 9.758986928104576e-06,
      "loss": 0.0992,
      "step": 2650
    },
    {
      "epoch": 0.6091452205882353,
      "grad_norm": 1.0552953481674194,
      "learning_rate": 9.758476307189543e-06,
      "loss": 0.0974,
      "step": 2651
    },
    {
      "epoch": 0.609375,
      "grad_norm": 1.0194331407546997,
      "learning_rate": 9.757965686274511e-06,
      "loss": 0.086,
      "step": 2652
    },
    {
      "epoch": 0.6096047794117647,
      "grad_norm": 1.1362106800079346,
      "learning_rate": 9.757455065359478e-06,
      "loss": 0.1055,
      "step": 2653
    },
    {
      "epoch": 0.6098345588235294,
      "grad_norm": 0.8809403777122498,
      "learning_rate": 9.756944444444445e-06,
      "loss": 0.0907,
      "step": 2654
    },
    {
      "epoch": 0.6100643382352942,
      "grad_norm": 1.0613292455673218,
      "learning_rate": 9.756433823529412e-06,
      "loss": 0.0927,
      "step": 2655
    },
    {
      "epoch": 0.6102941176470589,
      "grad_norm": 0.8714528679847717,
      "learning_rate": 9.75592320261438e-06,
      "loss": 0.0892,
      "step": 2656
    },
    {
      "epoch": 0.6105238970588235,
      "grad_norm": 1.6325013637542725,
      "learning_rate": 9.755412581699347e-06,
      "loss": 0.1643,
      "step": 2657
    },
    {
      "epoch": 0.6107536764705882,
      "grad_norm": 1.1518080234527588,
      "learning_rate": 9.754901960784315e-06,
      "loss": 0.1015,
      "step": 2658
    },
    {
      "epoch": 0.6109834558823529,
      "grad_norm": 1.6058349609375,
      "learning_rate": 9.754391339869281e-06,
      "loss": 0.0834,
      "step": 2659
    },
    {
      "epoch": 0.6112132352941176,
      "grad_norm": 1.0391356945037842,
      "learning_rate": 9.75388071895425e-06,
      "loss": 0.088,
      "step": 2660
    },
    {
      "epoch": 0.6114430147058824,
      "grad_norm": 1.1221704483032227,
      "learning_rate": 9.753370098039217e-06,
      "loss": 0.093,
      "step": 2661
    },
    {
      "epoch": 0.6116727941176471,
      "grad_norm": 0.8894299268722534,
      "learning_rate": 9.752859477124183e-06,
      "loss": 0.0725,
      "step": 2662
    },
    {
      "epoch": 0.6119025735294118,
      "grad_norm": 1.4066566228866577,
      "learning_rate": 9.752348856209151e-06,
      "loss": 0.1129,
      "step": 2663
    },
    {
      "epoch": 0.6121323529411765,
      "grad_norm": 0.9918447732925415,
      "learning_rate": 9.751838235294119e-06,
      "loss": 0.1154,
      "step": 2664
    },
    {
      "epoch": 0.6123621323529411,
      "grad_norm": 1.055843710899353,
      "learning_rate": 9.751327614379085e-06,
      "loss": 0.0854,
      "step": 2665
    },
    {
      "epoch": 0.6125919117647058,
      "grad_norm": 0.8079013824462891,
      "learning_rate": 9.750816993464053e-06,
      "loss": 0.0934,
      "step": 2666
    },
    {
      "epoch": 0.6128216911764706,
      "grad_norm": 1.0548230409622192,
      "learning_rate": 9.750306372549019e-06,
      "loss": 0.1177,
      "step": 2667
    },
    {
      "epoch": 0.6130514705882353,
      "grad_norm": 0.9288914799690247,
      "learning_rate": 9.749795751633989e-06,
      "loss": 0.111,
      "step": 2668
    },
    {
      "epoch": 0.61328125,
      "grad_norm": 1.0682597160339355,
      "learning_rate": 9.749285130718955e-06,
      "loss": 0.0935,
      "step": 2669
    },
    {
      "epoch": 0.6135110294117647,
      "grad_norm": 1.0359456539154053,
      "learning_rate": 9.748774509803923e-06,
      "loss": 0.0769,
      "step": 2670
    },
    {
      "epoch": 0.6137408088235294,
      "grad_norm": 1.329073429107666,
      "learning_rate": 9.748263888888889e-06,
      "loss": 0.0997,
      "step": 2671
    },
    {
      "epoch": 0.6139705882352942,
      "grad_norm": 1.2267318964004517,
      "learning_rate": 9.747753267973857e-06,
      "loss": 0.1322,
      "step": 2672
    },
    {
      "epoch": 0.6142003676470589,
      "grad_norm": 0.8885302543640137,
      "learning_rate": 9.747242647058825e-06,
      "loss": 0.1018,
      "step": 2673
    },
    {
      "epoch": 0.6144301470588235,
      "grad_norm": 1.1553056240081787,
      "learning_rate": 9.74673202614379e-06,
      "loss": 0.0662,
      "step": 2674
    },
    {
      "epoch": 0.6146599264705882,
      "grad_norm": 0.9314952492713928,
      "learning_rate": 9.746221405228759e-06,
      "loss": 0.0833,
      "step": 2675
    },
    {
      "epoch": 0.6148897058823529,
      "grad_norm": 0.9928393363952637,
      "learning_rate": 9.745710784313726e-06,
      "loss": 0.0781,
      "step": 2676
    },
    {
      "epoch": 0.6151194852941176,
      "grad_norm": 1.2947078943252563,
      "learning_rate": 9.745200163398694e-06,
      "loss": 0.0947,
      "step": 2677
    },
    {
      "epoch": 0.6153492647058824,
      "grad_norm": 1.319389820098877,
      "learning_rate": 9.74468954248366e-06,
      "loss": 0.094,
      "step": 2678
    },
    {
      "epoch": 0.6155790441176471,
      "grad_norm": 0.9696422219276428,
      "learning_rate": 9.744178921568628e-06,
      "loss": 0.103,
      "step": 2679
    },
    {
      "epoch": 0.6158088235294118,
      "grad_norm": 1.1118714809417725,
      "learning_rate": 9.743668300653596e-06,
      "loss": 0.0742,
      "step": 2680
    },
    {
      "epoch": 0.6160386029411765,
      "grad_norm": 1.091115951538086,
      "learning_rate": 9.743157679738562e-06,
      "loss": 0.1075,
      "step": 2681
    },
    {
      "epoch": 0.6162683823529411,
      "grad_norm": 0.9584864377975464,
      "learning_rate": 9.74264705882353e-06,
      "loss": 0.1024,
      "step": 2682
    },
    {
      "epoch": 0.6164981617647058,
      "grad_norm": 1.3280175924301147,
      "learning_rate": 9.742136437908496e-06,
      "loss": 0.08,
      "step": 2683
    },
    {
      "epoch": 0.6167279411764706,
      "grad_norm": 1.0085418224334717,
      "learning_rate": 9.741625816993466e-06,
      "loss": 0.0858,
      "step": 2684
    },
    {
      "epoch": 0.6169577205882353,
      "grad_norm": 1.0002013444900513,
      "learning_rate": 9.741115196078432e-06,
      "loss": 0.0764,
      "step": 2685
    },
    {
      "epoch": 0.6171875,
      "grad_norm": 0.9561209082603455,
      "learning_rate": 9.7406045751634e-06,
      "loss": 0.0817,
      "step": 2686
    },
    {
      "epoch": 0.6174172794117647,
      "grad_norm": 1.3330763578414917,
      "learning_rate": 9.740093954248366e-06,
      "loss": 0.1168,
      "step": 2687
    },
    {
      "epoch": 0.6176470588235294,
      "grad_norm": 1.1973470449447632,
      "learning_rate": 9.739583333333334e-06,
      "loss": 0.0899,
      "step": 2688
    },
    {
      "epoch": 0.6178768382352942,
      "grad_norm": 0.9108852744102478,
      "learning_rate": 9.739072712418302e-06,
      "loss": 0.0761,
      "step": 2689
    },
    {
      "epoch": 0.6181066176470589,
      "grad_norm": 1.1515365839004517,
      "learning_rate": 9.738562091503268e-06,
      "loss": 0.1016,
      "step": 2690
    },
    {
      "epoch": 0.6183363970588235,
      "grad_norm": 1.3960366249084473,
      "learning_rate": 9.738051470588236e-06,
      "loss": 0.1164,
      "step": 2691
    },
    {
      "epoch": 0.6185661764705882,
      "grad_norm": 1.1361678838729858,
      "learning_rate": 9.737540849673204e-06,
      "loss": 0.0892,
      "step": 2692
    },
    {
      "epoch": 0.6187959558823529,
      "grad_norm": 1.0478154420852661,
      "learning_rate": 9.737030228758172e-06,
      "loss": 0.0982,
      "step": 2693
    },
    {
      "epoch": 0.6190257352941176,
      "grad_norm": 1.2537922859191895,
      "learning_rate": 9.736519607843138e-06,
      "loss": 0.11,
      "step": 2694
    },
    {
      "epoch": 0.6192555147058824,
      "grad_norm": 1.0290974378585815,
      "learning_rate": 9.736008986928106e-06,
      "loss": 0.087,
      "step": 2695
    },
    {
      "epoch": 0.6194852941176471,
      "grad_norm": 1.052677035331726,
      "learning_rate": 9.735498366013074e-06,
      "loss": 0.1131,
      "step": 2696
    },
    {
      "epoch": 0.6197150735294118,
      "grad_norm": 1.132871150970459,
      "learning_rate": 9.73498774509804e-06,
      "loss": 0.0943,
      "step": 2697
    },
    {
      "epoch": 0.6199448529411765,
      "grad_norm": 1.2802599668502808,
      "learning_rate": 9.734477124183008e-06,
      "loss": 0.1083,
      "step": 2698
    },
    {
      "epoch": 0.6201746323529411,
      "grad_norm": 0.852601170539856,
      "learning_rate": 9.733966503267974e-06,
      "loss": 0.0877,
      "step": 2699
    },
    {
      "epoch": 0.6204044117647058,
      "grad_norm": 1.068042516708374,
      "learning_rate": 9.733455882352942e-06,
      "loss": 0.1017,
      "step": 2700
    },
    {
      "epoch": 0.6206341911764706,
      "grad_norm": 1.153360366821289,
      "learning_rate": 9.73294526143791e-06,
      "loss": 0.1537,
      "step": 2701
    },
    {
      "epoch": 0.6208639705882353,
      "grad_norm": 0.8951497673988342,
      "learning_rate": 9.732434640522876e-06,
      "loss": 0.0763,
      "step": 2702
    },
    {
      "epoch": 0.62109375,
      "grad_norm": 1.3307435512542725,
      "learning_rate": 9.731924019607843e-06,
      "loss": 0.1014,
      "step": 2703
    },
    {
      "epoch": 0.6213235294117647,
      "grad_norm": 1.0105470418930054,
      "learning_rate": 9.731413398692811e-06,
      "loss": 0.0859,
      "step": 2704
    },
    {
      "epoch": 0.6215533088235294,
      "grad_norm": 1.0966877937316895,
      "learning_rate": 9.73090277777778e-06,
      "loss": 0.0769,
      "step": 2705
    },
    {
      "epoch": 0.6217830882352942,
      "grad_norm": 0.8458845019340515,
      "learning_rate": 9.730392156862745e-06,
      "loss": 0.077,
      "step": 2706
    },
    {
      "epoch": 0.6220128676470589,
      "grad_norm": 1.1029421091079712,
      "learning_rate": 9.729881535947713e-06,
      "loss": 0.0654,
      "step": 2707
    },
    {
      "epoch": 0.6222426470588235,
      "grad_norm": 1.5934333801269531,
      "learning_rate": 9.729370915032681e-06,
      "loss": 0.1667,
      "step": 2708
    },
    {
      "epoch": 0.6224724264705882,
      "grad_norm": 1.0606166124343872,
      "learning_rate": 9.728860294117647e-06,
      "loss": 0.1031,
      "step": 2709
    },
    {
      "epoch": 0.6227022058823529,
      "grad_norm": 1.2343533039093018,
      "learning_rate": 9.728349673202615e-06,
      "loss": 0.1045,
      "step": 2710
    },
    {
      "epoch": 0.6229319852941176,
      "grad_norm": 1.0592291355133057,
      "learning_rate": 9.727839052287581e-06,
      "loss": 0.0699,
      "step": 2711
    },
    {
      "epoch": 0.6231617647058824,
      "grad_norm": 0.9847689270973206,
      "learning_rate": 9.727328431372551e-06,
      "loss": 0.0938,
      "step": 2712
    },
    {
      "epoch": 0.6233915441176471,
      "grad_norm": 1.0847591161727905,
      "learning_rate": 9.726817810457517e-06,
      "loss": 0.0879,
      "step": 2713
    },
    {
      "epoch": 0.6236213235294118,
      "grad_norm": 1.0560003519058228,
      "learning_rate": 9.726307189542485e-06,
      "loss": 0.0496,
      "step": 2714
    },
    {
      "epoch": 0.6238511029411765,
      "grad_norm": 1.0125691890716553,
      "learning_rate": 9.725796568627451e-06,
      "loss": 0.1035,
      "step": 2715
    },
    {
      "epoch": 0.6240808823529411,
      "grad_norm": 1.6574398279190063,
      "learning_rate": 9.725285947712419e-06,
      "loss": 0.1301,
      "step": 2716
    },
    {
      "epoch": 0.6243106617647058,
      "grad_norm": 1.2061522006988525,
      "learning_rate": 9.724775326797387e-06,
      "loss": 0.1059,
      "step": 2717
    },
    {
      "epoch": 0.6245404411764706,
      "grad_norm": 1.242035984992981,
      "learning_rate": 9.724264705882353e-06,
      "loss": 0.0956,
      "step": 2718
    },
    {
      "epoch": 0.6247702205882353,
      "grad_norm": 1.153712511062622,
      "learning_rate": 9.72375408496732e-06,
      "loss": 0.1315,
      "step": 2719
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.9992436766624451,
      "learning_rate": 9.723243464052289e-06,
      "loss": 0.1001,
      "step": 2720
    },
    {
      "epoch": 0.6252297794117647,
      "grad_norm": 1.0463367700576782,
      "learning_rate": 9.722732843137257e-06,
      "loss": 0.1164,
      "step": 2721
    },
    {
      "epoch": 0.6254595588235294,
      "grad_norm": 1.2105562686920166,
      "learning_rate": 9.722222222222223e-06,
      "loss": 0.1027,
      "step": 2722
    },
    {
      "epoch": 0.6256893382352942,
      "grad_norm": 1.1858034133911133,
      "learning_rate": 9.72171160130719e-06,
      "loss": 0.0979,
      "step": 2723
    },
    {
      "epoch": 0.6259191176470589,
      "grad_norm": 0.9414271712303162,
      "learning_rate": 9.721200980392158e-06,
      "loss": 0.0672,
      "step": 2724
    },
    {
      "epoch": 0.6261488970588235,
      "grad_norm": 1.2327829599380493,
      "learning_rate": 9.720690359477125e-06,
      "loss": 0.1161,
      "step": 2725
    },
    {
      "epoch": 0.6263786764705882,
      "grad_norm": 1.3171308040618896,
      "learning_rate": 9.720179738562092e-06,
      "loss": 0.0963,
      "step": 2726
    },
    {
      "epoch": 0.6266084558823529,
      "grad_norm": 1.2400541305541992,
      "learning_rate": 9.719669117647059e-06,
      "loss": 0.0955,
      "step": 2727
    },
    {
      "epoch": 0.6268382352941176,
      "grad_norm": 1.0450383424758911,
      "learning_rate": 9.719158496732028e-06,
      "loss": 0.0775,
      "step": 2728
    },
    {
      "epoch": 0.6270680147058824,
      "grad_norm": 1.0221894979476929,
      "learning_rate": 9.718647875816994e-06,
      "loss": 0.1252,
      "step": 2729
    },
    {
      "epoch": 0.6272977941176471,
      "grad_norm": 1.116185188293457,
      "learning_rate": 9.718137254901962e-06,
      "loss": 0.085,
      "step": 2730
    },
    {
      "epoch": 0.6275275735294118,
      "grad_norm": 1.3197686672210693,
      "learning_rate": 9.717626633986928e-06,
      "loss": 0.0922,
      "step": 2731
    },
    {
      "epoch": 0.6277573529411765,
      "grad_norm": 1.2459466457366943,
      "learning_rate": 9.717116013071896e-06,
      "loss": 0.1086,
      "step": 2732
    },
    {
      "epoch": 0.6279871323529411,
      "grad_norm": 1.2519207000732422,
      "learning_rate": 9.716605392156864e-06,
      "loss": 0.0807,
      "step": 2733
    },
    {
      "epoch": 0.6282169117647058,
      "grad_norm": 0.9358385801315308,
      "learning_rate": 9.71609477124183e-06,
      "loss": 0.0921,
      "step": 2734
    },
    {
      "epoch": 0.6284466911764706,
      "grad_norm": 0.9206609725952148,
      "learning_rate": 9.715584150326798e-06,
      "loss": 0.089,
      "step": 2735
    },
    {
      "epoch": 0.6286764705882353,
      "grad_norm": 1.128659725189209,
      "learning_rate": 9.715073529411766e-06,
      "loss": 0.093,
      "step": 2736
    },
    {
      "epoch": 0.62890625,
      "grad_norm": 1.400315523147583,
      "learning_rate": 9.714562908496734e-06,
      "loss": 0.1106,
      "step": 2737
    },
    {
      "epoch": 0.6291360294117647,
      "grad_norm": 1.2615742683410645,
      "learning_rate": 9.7140522875817e-06,
      "loss": 0.0981,
      "step": 2738
    },
    {
      "epoch": 0.6293658088235294,
      "grad_norm": 1.0524786710739136,
      "learning_rate": 9.713541666666668e-06,
      "loss": 0.0817,
      "step": 2739
    },
    {
      "epoch": 0.6295955882352942,
      "grad_norm": 0.8363282680511475,
      "learning_rate": 9.713031045751636e-06,
      "loss": 0.0737,
      "step": 2740
    },
    {
      "epoch": 0.6298253676470589,
      "grad_norm": 1.0327154397964478,
      "learning_rate": 9.712520424836602e-06,
      "loss": 0.1252,
      "step": 2741
    },
    {
      "epoch": 0.6300551470588235,
      "grad_norm": 1.0760653018951416,
      "learning_rate": 9.71200980392157e-06,
      "loss": 0.1,
      "step": 2742
    },
    {
      "epoch": 0.6302849264705882,
      "grad_norm": 1.418225646018982,
      "learning_rate": 9.711499183006536e-06,
      "loss": 0.1272,
      "step": 2743
    },
    {
      "epoch": 0.6305147058823529,
      "grad_norm": 1.2664059400558472,
      "learning_rate": 9.710988562091504e-06,
      "loss": 0.1271,
      "step": 2744
    },
    {
      "epoch": 0.6307444852941176,
      "grad_norm": 0.9745067358016968,
      "learning_rate": 9.710477941176472e-06,
      "loss": 0.0822,
      "step": 2745
    },
    {
      "epoch": 0.6309742647058824,
      "grad_norm": 1.068566918373108,
      "learning_rate": 9.709967320261438e-06,
      "loss": 0.089,
      "step": 2746
    },
    {
      "epoch": 0.6312040441176471,
      "grad_norm": 0.8257643580436707,
      "learning_rate": 9.709456699346406e-06,
      "loss": 0.0687,
      "step": 2747
    },
    {
      "epoch": 0.6314338235294118,
      "grad_norm": 1.034163236618042,
      "learning_rate": 9.708946078431374e-06,
      "loss": 0.0916,
      "step": 2748
    },
    {
      "epoch": 0.6316636029411765,
      "grad_norm": 1.0742672681808472,
      "learning_rate": 9.708435457516341e-06,
      "loss": 0.109,
      "step": 2749
    },
    {
      "epoch": 0.6318933823529411,
      "grad_norm": 1.0369468927383423,
      "learning_rate": 9.707924836601308e-06,
      "loss": 0.0799,
      "step": 2750
    },
    {
      "epoch": 0.6321231617647058,
      "grad_norm": 1.313212275505066,
      "learning_rate": 9.707414215686275e-06,
      "loss": 0.1051,
      "step": 2751
    },
    {
      "epoch": 0.6323529411764706,
      "grad_norm": 1.0572872161865234,
      "learning_rate": 9.706903594771243e-06,
      "loss": 0.0957,
      "step": 2752
    },
    {
      "epoch": 0.6325827205882353,
      "grad_norm": 1.042842984199524,
      "learning_rate": 9.70639297385621e-06,
      "loss": 0.0802,
      "step": 2753
    },
    {
      "epoch": 0.6328125,
      "grad_norm": 1.091709017753601,
      "learning_rate": 9.705882352941177e-06,
      "loss": 0.1218,
      "step": 2754
    },
    {
      "epoch": 0.6330422794117647,
      "grad_norm": 1.1431410312652588,
      "learning_rate": 9.705371732026143e-06,
      "loss": 0.0971,
      "step": 2755
    },
    {
      "epoch": 0.6332720588235294,
      "grad_norm": 1.0630415678024292,
      "learning_rate": 9.704861111111113e-06,
      "loss": 0.1053,
      "step": 2756
    },
    {
      "epoch": 0.6335018382352942,
      "grad_norm": 0.9248437881469727,
      "learning_rate": 9.70435049019608e-06,
      "loss": 0.0797,
      "step": 2757
    },
    {
      "epoch": 0.6337316176470589,
      "grad_norm": 1.8738709688186646,
      "learning_rate": 9.703839869281047e-06,
      "loss": 0.1375,
      "step": 2758
    },
    {
      "epoch": 0.6339613970588235,
      "grad_norm": 1.279564380645752,
      "learning_rate": 9.703329248366013e-06,
      "loss": 0.094,
      "step": 2759
    },
    {
      "epoch": 0.6341911764705882,
      "grad_norm": 1.1582398414611816,
      "learning_rate": 9.702818627450981e-06,
      "loss": 0.0946,
      "step": 2760
    },
    {
      "epoch": 0.6344209558823529,
      "grad_norm": 1.3291497230529785,
      "learning_rate": 9.702308006535949e-06,
      "loss": 0.1103,
      "step": 2761
    },
    {
      "epoch": 0.6346507352941176,
      "grad_norm": 1.3864619731903076,
      "learning_rate": 9.701797385620915e-06,
      "loss": 0.0929,
      "step": 2762
    },
    {
      "epoch": 0.6348805147058824,
      "grad_norm": 1.0912365913391113,
      "learning_rate": 9.701286764705883e-06,
      "loss": 0.0846,
      "step": 2763
    },
    {
      "epoch": 0.6351102941176471,
      "grad_norm": 1.3827354907989502,
      "learning_rate": 9.70077614379085e-06,
      "loss": 0.1042,
      "step": 2764
    },
    {
      "epoch": 0.6353400735294118,
      "grad_norm": 1.4218732118606567,
      "learning_rate": 9.700265522875819e-06,
      "loss": 0.079,
      "step": 2765
    },
    {
      "epoch": 0.6355698529411765,
      "grad_norm": 1.09425687789917,
      "learning_rate": 9.699754901960785e-06,
      "loss": 0.0684,
      "step": 2766
    },
    {
      "epoch": 0.6357996323529411,
      "grad_norm": 1.2042587995529175,
      "learning_rate": 9.699244281045753e-06,
      "loss": 0.0913,
      "step": 2767
    },
    {
      "epoch": 0.6360294117647058,
      "grad_norm": 0.936859667301178,
      "learning_rate": 9.69873366013072e-06,
      "loss": 0.0695,
      "step": 2768
    },
    {
      "epoch": 0.6362591911764706,
      "grad_norm": 0.9412240982055664,
      "learning_rate": 9.698223039215687e-06,
      "loss": 0.0793,
      "step": 2769
    },
    {
      "epoch": 0.6364889705882353,
      "grad_norm": 0.9264914393424988,
      "learning_rate": 9.697712418300655e-06,
      "loss": 0.0758,
      "step": 2770
    },
    {
      "epoch": 0.63671875,
      "grad_norm": 1.1996790170669556,
      "learning_rate": 9.69720179738562e-06,
      "loss": 0.1214,
      "step": 2771
    },
    {
      "epoch": 0.6369485294117647,
      "grad_norm": 1.0873736143112183,
      "learning_rate": 9.69669117647059e-06,
      "loss": 0.084,
      "step": 2772
    },
    {
      "epoch": 0.6371783088235294,
      "grad_norm": 1.0188899040222168,
      "learning_rate": 9.696180555555557e-06,
      "loss": 0.0993,
      "step": 2773
    },
    {
      "epoch": 0.6374080882352942,
      "grad_norm": 1.367247223854065,
      "learning_rate": 9.695669934640524e-06,
      "loss": 0.0735,
      "step": 2774
    },
    {
      "epoch": 0.6376378676470589,
      "grad_norm": 0.995122492313385,
      "learning_rate": 9.69515931372549e-06,
      "loss": 0.0894,
      "step": 2775
    },
    {
      "epoch": 0.6378676470588235,
      "grad_norm": 1.2592332363128662,
      "learning_rate": 9.694648692810458e-06,
      "loss": 0.0912,
      "step": 2776
    },
    {
      "epoch": 0.6380974264705882,
      "grad_norm": 0.9656696319580078,
      "learning_rate": 9.694138071895426e-06,
      "loss": 0.0574,
      "step": 2777
    },
    {
      "epoch": 0.6383272058823529,
      "grad_norm": 0.8542351126670837,
      "learning_rate": 9.693627450980392e-06,
      "loss": 0.0882,
      "step": 2778
    },
    {
      "epoch": 0.6385569852941176,
      "grad_norm": 1.2036340236663818,
      "learning_rate": 9.69311683006536e-06,
      "loss": 0.0914,
      "step": 2779
    },
    {
      "epoch": 0.6387867647058824,
      "grad_norm": 1.2058933973312378,
      "learning_rate": 9.692606209150328e-06,
      "loss": 0.0773,
      "step": 2780
    },
    {
      "epoch": 0.6390165441176471,
      "grad_norm": 1.1774682998657227,
      "learning_rate": 9.692095588235294e-06,
      "loss": 0.1254,
      "step": 2781
    },
    {
      "epoch": 0.6392463235294118,
      "grad_norm": 1.1249442100524902,
      "learning_rate": 9.691584967320262e-06,
      "loss": 0.1001,
      "step": 2782
    },
    {
      "epoch": 0.6394761029411765,
      "grad_norm": 1.3856720924377441,
      "learning_rate": 9.69107434640523e-06,
      "loss": 0.1279,
      "step": 2783
    },
    {
      "epoch": 0.6397058823529411,
      "grad_norm": 1.037581443786621,
      "learning_rate": 9.690563725490198e-06,
      "loss": 0.0912,
      "step": 2784
    },
    {
      "epoch": 0.6399356617647058,
      "grad_norm": 1.236772894859314,
      "learning_rate": 9.690053104575164e-06,
      "loss": 0.0988,
      "step": 2785
    },
    {
      "epoch": 0.6401654411764706,
      "grad_norm": 0.836574137210846,
      "learning_rate": 9.689542483660132e-06,
      "loss": 0.0835,
      "step": 2786
    },
    {
      "epoch": 0.6403952205882353,
      "grad_norm": 0.9719253778457642,
      "learning_rate": 9.689031862745098e-06,
      "loss": 0.0826,
      "step": 2787
    },
    {
      "epoch": 0.640625,
      "grad_norm": 0.9579812288284302,
      "learning_rate": 9.688521241830066e-06,
      "loss": 0.0897,
      "step": 2788
    },
    {
      "epoch": 0.6408547794117647,
      "grad_norm": 1.2976423501968384,
      "learning_rate": 9.688010620915034e-06,
      "loss": 0.116,
      "step": 2789
    },
    {
      "epoch": 0.6410845588235294,
      "grad_norm": 1.2662975788116455,
      "learning_rate": 9.6875e-06,
      "loss": 0.1039,
      "step": 2790
    },
    {
      "epoch": 0.6413143382352942,
      "grad_norm": 1.0847904682159424,
      "learning_rate": 9.686989379084968e-06,
      "loss": 0.0813,
      "step": 2791
    },
    {
      "epoch": 0.6415441176470589,
      "grad_norm": 1.1114765405654907,
      "learning_rate": 9.686478758169936e-06,
      "loss": 0.0569,
      "step": 2792
    },
    {
      "epoch": 0.6417738970588235,
      "grad_norm": 0.9098833203315735,
      "learning_rate": 9.685968137254904e-06,
      "loss": 0.0861,
      "step": 2793
    },
    {
      "epoch": 0.6420036764705882,
      "grad_norm": 0.972724199295044,
      "learning_rate": 9.68545751633987e-06,
      "loss": 0.0958,
      "step": 2794
    },
    {
      "epoch": 0.6422334558823529,
      "grad_norm": 1.1134247779846191,
      "learning_rate": 9.684946895424838e-06,
      "loss": 0.0693,
      "step": 2795
    },
    {
      "epoch": 0.6424632352941176,
      "grad_norm": 0.7857028245925903,
      "learning_rate": 9.684436274509804e-06,
      "loss": 0.089,
      "step": 2796
    },
    {
      "epoch": 0.6426930147058824,
      "grad_norm": 1.105707049369812,
      "learning_rate": 9.683925653594772e-06,
      "loss": 0.1185,
      "step": 2797
    },
    {
      "epoch": 0.6429227941176471,
      "grad_norm": 1.2281699180603027,
      "learning_rate": 9.68341503267974e-06,
      "loss": 0.084,
      "step": 2798
    },
    {
      "epoch": 0.6431525735294118,
      "grad_norm": 1.0061964988708496,
      "learning_rate": 9.682904411764706e-06,
      "loss": 0.0945,
      "step": 2799
    },
    {
      "epoch": 0.6433823529411765,
      "grad_norm": 1.148147702217102,
      "learning_rate": 9.682393790849674e-06,
      "loss": 0.1163,
      "step": 2800
    },
    {
      "epoch": 0.6436121323529411,
      "grad_norm": 1.064214825630188,
      "learning_rate": 9.681883169934641e-06,
      "loss": 0.1077,
      "step": 2801
    },
    {
      "epoch": 0.6438419117647058,
      "grad_norm": 1.0975693464279175,
      "learning_rate": 9.68137254901961e-06,
      "loss": 0.0926,
      "step": 2802
    },
    {
      "epoch": 0.6440716911764706,
      "grad_norm": 1.2246307134628296,
      "learning_rate": 9.680861928104575e-06,
      "loss": 0.066,
      "step": 2803
    },
    {
      "epoch": 0.6443014705882353,
      "grad_norm": 0.9597296118736267,
      "learning_rate": 9.680351307189543e-06,
      "loss": 0.0667,
      "step": 2804
    },
    {
      "epoch": 0.64453125,
      "grad_norm": 1.2455790042877197,
      "learning_rate": 9.679840686274511e-06,
      "loss": 0.1019,
      "step": 2805
    },
    {
      "epoch": 0.6447610294117647,
      "grad_norm": 1.1153165102005005,
      "learning_rate": 9.679330065359477e-06,
      "loss": 0.1072,
      "step": 2806
    },
    {
      "epoch": 0.6449908088235294,
      "grad_norm": 1.1024047136306763,
      "learning_rate": 9.678819444444445e-06,
      "loss": 0.1078,
      "step": 2807
    },
    {
      "epoch": 0.6452205882352942,
      "grad_norm": 0.9272996783256531,
      "learning_rate": 9.678308823529411e-06,
      "loss": 0.0785,
      "step": 2808
    },
    {
      "epoch": 0.6454503676470589,
      "grad_norm": 1.1538443565368652,
      "learning_rate": 9.677798202614381e-06,
      "loss": 0.1072,
      "step": 2809
    },
    {
      "epoch": 0.6456801470588235,
      "grad_norm": 1.0442794561386108,
      "learning_rate": 9.677287581699347e-06,
      "loss": 0.0724,
      "step": 2810
    },
    {
      "epoch": 0.6459099264705882,
      "grad_norm": 1.1129961013793945,
      "learning_rate": 9.676776960784315e-06,
      "loss": 0.0828,
      "step": 2811
    },
    {
      "epoch": 0.6461397058823529,
      "grad_norm": 1.2523927688598633,
      "learning_rate": 9.676266339869281e-06,
      "loss": 0.0881,
      "step": 2812
    },
    {
      "epoch": 0.6463694852941176,
      "grad_norm": 1.0447967052459717,
      "learning_rate": 9.675755718954249e-06,
      "loss": 0.0881,
      "step": 2813
    },
    {
      "epoch": 0.6465992647058824,
      "grad_norm": 1.253453016281128,
      "learning_rate": 9.675245098039217e-06,
      "loss": 0.0676,
      "step": 2814
    },
    {
      "epoch": 0.6468290441176471,
      "grad_norm": 1.205213189125061,
      "learning_rate": 9.674734477124183e-06,
      "loss": 0.0814,
      "step": 2815
    },
    {
      "epoch": 0.6470588235294118,
      "grad_norm": 0.9467937350273132,
      "learning_rate": 9.67422385620915e-06,
      "loss": 0.0629,
      "step": 2816
    },
    {
      "epoch": 0.6472886029411765,
      "grad_norm": 1.0123662948608398,
      "learning_rate": 9.673713235294119e-06,
      "loss": 0.0891,
      "step": 2817
    },
    {
      "epoch": 0.6475183823529411,
      "grad_norm": 0.9784421920776367,
      "learning_rate": 9.673202614379087e-06,
      "loss": 0.0641,
      "step": 2818
    },
    {
      "epoch": 0.6477481617647058,
      "grad_norm": 1.2646845579147339,
      "learning_rate": 9.672691993464053e-06,
      "loss": 0.0732,
      "step": 2819
    },
    {
      "epoch": 0.6479779411764706,
      "grad_norm": 1.3753087520599365,
      "learning_rate": 9.67218137254902e-06,
      "loss": 0.098,
      "step": 2820
    },
    {
      "epoch": 0.6482077205882353,
      "grad_norm": 1.0560214519500732,
      "learning_rate": 9.671670751633988e-06,
      "loss": 0.0633,
      "step": 2821
    },
    {
      "epoch": 0.6484375,
      "grad_norm": 1.064627766609192,
      "learning_rate": 9.671160130718955e-06,
      "loss": 0.1062,
      "step": 2822
    },
    {
      "epoch": 0.6486672794117647,
      "grad_norm": 0.9168561100959778,
      "learning_rate": 9.670649509803922e-06,
      "loss": 0.0733,
      "step": 2823
    },
    {
      "epoch": 0.6488970588235294,
      "grad_norm": 1.034516453742981,
      "learning_rate": 9.670138888888889e-06,
      "loss": 0.1,
      "step": 2824
    },
    {
      "epoch": 0.6491268382352942,
      "grad_norm": 1.3496805429458618,
      "learning_rate": 9.669628267973857e-06,
      "loss": 0.1048,
      "step": 2825
    },
    {
      "epoch": 0.6493566176470589,
      "grad_norm": 0.8648793697357178,
      "learning_rate": 9.669117647058824e-06,
      "loss": 0.0808,
      "step": 2826
    },
    {
      "epoch": 0.6495863970588235,
      "grad_norm": 0.8371375799179077,
      "learning_rate": 9.668607026143792e-06,
      "loss": 0.0838,
      "step": 2827
    },
    {
      "epoch": 0.6498161764705882,
      "grad_norm": 1.1670482158660889,
      "learning_rate": 9.668096405228758e-06,
      "loss": 0.0944,
      "step": 2828
    },
    {
      "epoch": 0.6500459558823529,
      "grad_norm": 0.8092013597488403,
      "learning_rate": 9.667585784313726e-06,
      "loss": 0.065,
      "step": 2829
    },
    {
      "epoch": 0.6502757352941176,
      "grad_norm": 1.036454439163208,
      "learning_rate": 9.667075163398694e-06,
      "loss": 0.0833,
      "step": 2830
    },
    {
      "epoch": 0.6505055147058824,
      "grad_norm": 0.9645741581916809,
      "learning_rate": 9.66656454248366e-06,
      "loss": 0.0714,
      "step": 2831
    },
    {
      "epoch": 0.6507352941176471,
      "grad_norm": 1.1598063707351685,
      "learning_rate": 9.666053921568628e-06,
      "loss": 0.111,
      "step": 2832
    },
    {
      "epoch": 0.6509650735294118,
      "grad_norm": 1.397891879081726,
      "learning_rate": 9.665543300653596e-06,
      "loss": 0.1075,
      "step": 2833
    },
    {
      "epoch": 0.6511948529411765,
      "grad_norm": 1.1455366611480713,
      "learning_rate": 9.665032679738562e-06,
      "loss": 0.0895,
      "step": 2834
    },
    {
      "epoch": 0.6514246323529411,
      "grad_norm": 1.04324209690094,
      "learning_rate": 9.66452205882353e-06,
      "loss": 0.088,
      "step": 2835
    },
    {
      "epoch": 0.6516544117647058,
      "grad_norm": 1.1923930644989014,
      "learning_rate": 9.664011437908496e-06,
      "loss": 0.0659,
      "step": 2836
    },
    {
      "epoch": 0.6518841911764706,
      "grad_norm": 0.8809731602668762,
      "learning_rate": 9.663500816993466e-06,
      "loss": 0.092,
      "step": 2837
    },
    {
      "epoch": 0.6521139705882353,
      "grad_norm": 1.090617299079895,
      "learning_rate": 9.662990196078432e-06,
      "loss": 0.1121,
      "step": 2838
    },
    {
      "epoch": 0.65234375,
      "grad_norm": 1.21784245967865,
      "learning_rate": 9.6624795751634e-06,
      "loss": 0.1093,
      "step": 2839
    },
    {
      "epoch": 0.6525735294117647,
      "grad_norm": 1.207269549369812,
      "learning_rate": 9.661968954248366e-06,
      "loss": 0.0868,
      "step": 2840
    },
    {
      "epoch": 0.6528033088235294,
      "grad_norm": 1.3752033710479736,
      "learning_rate": 9.661458333333334e-06,
      "loss": 0.0754,
      "step": 2841
    },
    {
      "epoch": 0.6530330882352942,
      "grad_norm": 0.8469406366348267,
      "learning_rate": 9.660947712418302e-06,
      "loss": 0.0924,
      "step": 2842
    },
    {
      "epoch": 0.6532628676470589,
      "grad_norm": 0.9150564670562744,
      "learning_rate": 9.660437091503268e-06,
      "loss": 0.0911,
      "step": 2843
    },
    {
      "epoch": 0.6534926470588235,
      "grad_norm": 1.447798490524292,
      "learning_rate": 9.659926470588236e-06,
      "loss": 0.1117,
      "step": 2844
    },
    {
      "epoch": 0.6537224264705882,
      "grad_norm": 1.023880124092102,
      "learning_rate": 9.659415849673204e-06,
      "loss": 0.0916,
      "step": 2845
    },
    {
      "epoch": 0.6539522058823529,
      "grad_norm": 1.2456603050231934,
      "learning_rate": 9.658905228758171e-06,
      "loss": 0.0957,
      "step": 2846
    },
    {
      "epoch": 0.6541819852941176,
      "grad_norm": 1.1408913135528564,
      "learning_rate": 9.658394607843138e-06,
      "loss": 0.0782,
      "step": 2847
    },
    {
      "epoch": 0.6544117647058824,
      "grad_norm": 1.3226802349090576,
      "learning_rate": 9.657883986928105e-06,
      "loss": 0.0932,
      "step": 2848
    },
    {
      "epoch": 0.6546415441176471,
      "grad_norm": 1.0760303735733032,
      "learning_rate": 9.657373366013073e-06,
      "loss": 0.0912,
      "step": 2849
    },
    {
      "epoch": 0.6548713235294118,
      "grad_norm": 1.0126677751541138,
      "learning_rate": 9.65686274509804e-06,
      "loss": 0.0773,
      "step": 2850
    },
    {
      "epoch": 0.6551011029411765,
      "grad_norm": 0.9268330335617065,
      "learning_rate": 9.656352124183007e-06,
      "loss": 0.1005,
      "step": 2851
    },
    {
      "epoch": 0.6553308823529411,
      "grad_norm": 0.8772841095924377,
      "learning_rate": 9.655841503267974e-06,
      "loss": 0.0822,
      "step": 2852
    },
    {
      "epoch": 0.6555606617647058,
      "grad_norm": 0.8523821830749512,
      "learning_rate": 9.655330882352943e-06,
      "loss": 0.0651,
      "step": 2853
    },
    {
      "epoch": 0.6557904411764706,
      "grad_norm": 1.2340519428253174,
      "learning_rate": 9.65482026143791e-06,
      "loss": 0.1177,
      "step": 2854
    },
    {
      "epoch": 0.6560202205882353,
      "grad_norm": 1.0065703392028809,
      "learning_rate": 9.654309640522877e-06,
      "loss": 0.103,
      "step": 2855
    },
    {
      "epoch": 0.65625,
      "grad_norm": 0.9206777811050415,
      "learning_rate": 9.653799019607843e-06,
      "loss": 0.0833,
      "step": 2856
    },
    {
      "epoch": 0.6564797794117647,
      "grad_norm": 1.0491784811019897,
      "learning_rate": 9.653288398692811e-06,
      "loss": 0.08,
      "step": 2857
    },
    {
      "epoch": 0.6567095588235294,
      "grad_norm": 1.2574955224990845,
      "learning_rate": 9.652777777777779e-06,
      "loss": 0.0776,
      "step": 2858
    },
    {
      "epoch": 0.6569393382352942,
      "grad_norm": 1.3507310152053833,
      "learning_rate": 9.652267156862745e-06,
      "loss": 0.1054,
      "step": 2859
    },
    {
      "epoch": 0.6571691176470589,
      "grad_norm": 1.2693549394607544,
      "learning_rate": 9.651756535947713e-06,
      "loss": 0.0954,
      "step": 2860
    },
    {
      "epoch": 0.6573988970588235,
      "grad_norm": 1.0586533546447754,
      "learning_rate": 9.651245915032681e-06,
      "loss": 0.0886,
      "step": 2861
    },
    {
      "epoch": 0.6576286764705882,
      "grad_norm": 1.020293951034546,
      "learning_rate": 9.650735294117649e-06,
      "loss": 0.0834,
      "step": 2862
    },
    {
      "epoch": 0.6578584558823529,
      "grad_norm": 0.8747502565383911,
      "learning_rate": 9.650224673202615e-06,
      "loss": 0.0791,
      "step": 2863
    },
    {
      "epoch": 0.6580882352941176,
      "grad_norm": 1.0265165567398071,
      "learning_rate": 9.649714052287583e-06,
      "loss": 0.0731,
      "step": 2864
    },
    {
      "epoch": 0.6583180147058824,
      "grad_norm": 0.8559879064559937,
      "learning_rate": 9.64920343137255e-06,
      "loss": 0.0771,
      "step": 2865
    },
    {
      "epoch": 0.6585477941176471,
      "grad_norm": 0.972058892250061,
      "learning_rate": 9.648692810457517e-06,
      "loss": 0.0755,
      "step": 2866
    },
    {
      "epoch": 0.6587775735294118,
      "grad_norm": 0.9545909762382507,
      "learning_rate": 9.648182189542485e-06,
      "loss": 0.0981,
      "step": 2867
    },
    {
      "epoch": 0.6590073529411765,
      "grad_norm": 1.4322704076766968,
      "learning_rate": 9.64767156862745e-06,
      "loss": 0.1298,
      "step": 2868
    },
    {
      "epoch": 0.6592371323529411,
      "grad_norm": 0.7127625942230225,
      "learning_rate": 9.647160947712419e-06,
      "loss": 0.0679,
      "step": 2869
    },
    {
      "epoch": 0.6594669117647058,
      "grad_norm": 1.1200592517852783,
      "learning_rate": 9.646650326797387e-06,
      "loss": 0.0999,
      "step": 2870
    },
    {
      "epoch": 0.6596966911764706,
      "grad_norm": 1.1036471128463745,
      "learning_rate": 9.646139705882354e-06,
      "loss": 0.106,
      "step": 2871
    },
    {
      "epoch": 0.6599264705882353,
      "grad_norm": 0.929336428642273,
      "learning_rate": 9.64562908496732e-06,
      "loss": 0.0521,
      "step": 2872
    },
    {
      "epoch": 0.66015625,
      "grad_norm": 1.341464877128601,
      "learning_rate": 9.645118464052288e-06,
      "loss": 0.0911,
      "step": 2873
    },
    {
      "epoch": 0.6603860294117647,
      "grad_norm": 1.2606796026229858,
      "learning_rate": 9.644607843137256e-06,
      "loss": 0.0885,
      "step": 2874
    },
    {
      "epoch": 0.6606158088235294,
      "grad_norm": 1.2109140157699585,
      "learning_rate": 9.644097222222222e-06,
      "loss": 0.1014,
      "step": 2875
    },
    {
      "epoch": 0.6608455882352942,
      "grad_norm": 1.1520981788635254,
      "learning_rate": 9.64358660130719e-06,
      "loss": 0.0902,
      "step": 2876
    },
    {
      "epoch": 0.6610753676470589,
      "grad_norm": 1.2612870931625366,
      "learning_rate": 9.643075980392158e-06,
      "loss": 0.1224,
      "step": 2877
    },
    {
      "epoch": 0.6613051470588235,
      "grad_norm": 1.069836974143982,
      "learning_rate": 9.642565359477124e-06,
      "loss": 0.1461,
      "step": 2878
    },
    {
      "epoch": 0.6615349264705882,
      "grad_norm": 1.0241780281066895,
      "learning_rate": 9.642054738562092e-06,
      "loss": 0.0729,
      "step": 2879
    },
    {
      "epoch": 0.6617647058823529,
      "grad_norm": 1.575751543045044,
      "learning_rate": 9.641544117647058e-06,
      "loss": 0.1154,
      "step": 2880
    },
    {
      "epoch": 0.6619944852941176,
      "grad_norm": 0.9565521478652954,
      "learning_rate": 9.641033496732028e-06,
      "loss": 0.0697,
      "step": 2881
    },
    {
      "epoch": 0.6622242647058824,
      "grad_norm": 0.8888272047042847,
      "learning_rate": 9.640522875816994e-06,
      "loss": 0.0782,
      "step": 2882
    },
    {
      "epoch": 0.6624540441176471,
      "grad_norm": 1.2253549098968506,
      "learning_rate": 9.640012254901962e-06,
      "loss": 0.1357,
      "step": 2883
    },
    {
      "epoch": 0.6626838235294118,
      "grad_norm": 1.1256277561187744,
      "learning_rate": 9.639501633986928e-06,
      "loss": 0.0636,
      "step": 2884
    },
    {
      "epoch": 0.6629136029411765,
      "grad_norm": 1.1209055185317993,
      "learning_rate": 9.638991013071896e-06,
      "loss": 0.0863,
      "step": 2885
    },
    {
      "epoch": 0.6631433823529411,
      "grad_norm": 1.1850107908248901,
      "learning_rate": 9.638480392156864e-06,
      "loss": 0.1033,
      "step": 2886
    },
    {
      "epoch": 0.6633731617647058,
      "grad_norm": 1.0155620574951172,
      "learning_rate": 9.63796977124183e-06,
      "loss": 0.0916,
      "step": 2887
    },
    {
      "epoch": 0.6636029411764706,
      "grad_norm": 1.0286824703216553,
      "learning_rate": 9.637459150326798e-06,
      "loss": 0.0746,
      "step": 2888
    },
    {
      "epoch": 0.6638327205882353,
      "grad_norm": 1.0268006324768066,
      "learning_rate": 9.636948529411766e-06,
      "loss": 0.068,
      "step": 2889
    },
    {
      "epoch": 0.6640625,
      "grad_norm": 0.7920565605163574,
      "learning_rate": 9.636437908496734e-06,
      "loss": 0.0582,
      "step": 2890
    },
    {
      "epoch": 0.6642922794117647,
      "grad_norm": 0.8450143933296204,
      "learning_rate": 9.6359272875817e-06,
      "loss": 0.0802,
      "step": 2891
    },
    {
      "epoch": 0.6645220588235294,
      "grad_norm": 1.3668657541275024,
      "learning_rate": 9.635416666666668e-06,
      "loss": 0.137,
      "step": 2892
    },
    {
      "epoch": 0.6647518382352942,
      "grad_norm": 1.0503915548324585,
      "learning_rate": 9.634906045751636e-06,
      "loss": 0.098,
      "step": 2893
    },
    {
      "epoch": 0.6649816176470589,
      "grad_norm": 0.9300958514213562,
      "learning_rate": 9.634395424836602e-06,
      "loss": 0.0655,
      "step": 2894
    },
    {
      "epoch": 0.6652113970588235,
      "grad_norm": 1.0574722290039062,
      "learning_rate": 9.63388480392157e-06,
      "loss": 0.1058,
      "step": 2895
    },
    {
      "epoch": 0.6654411764705882,
      "grad_norm": 0.8819564580917358,
      "learning_rate": 9.633374183006536e-06,
      "loss": 0.1122,
      "step": 2896
    },
    {
      "epoch": 0.6656709558823529,
      "grad_norm": 1.0070720911026,
      "learning_rate": 9.632863562091505e-06,
      "loss": 0.082,
      "step": 2897
    },
    {
      "epoch": 0.6659007352941176,
      "grad_norm": 1.202736735343933,
      "learning_rate": 9.632352941176471e-06,
      "loss": 0.0911,
      "step": 2898
    },
    {
      "epoch": 0.6661305147058824,
      "grad_norm": 0.8709810376167297,
      "learning_rate": 9.63184232026144e-06,
      "loss": 0.0852,
      "step": 2899
    },
    {
      "epoch": 0.6663602941176471,
      "grad_norm": 0.814717710018158,
      "learning_rate": 9.631331699346405e-06,
      "loss": 0.062,
      "step": 2900
    },
    {
      "epoch": 0.6665900735294118,
      "grad_norm": 0.986630916595459,
      "learning_rate": 9.630821078431373e-06,
      "loss": 0.0802,
      "step": 2901
    },
    {
      "epoch": 0.6668198529411765,
      "grad_norm": 1.362325668334961,
      "learning_rate": 9.630310457516341e-06,
      "loss": 0.119,
      "step": 2902
    },
    {
      "epoch": 0.6670496323529411,
      "grad_norm": 1.1289246082305908,
      "learning_rate": 9.629799836601307e-06,
      "loss": 0.0761,
      "step": 2903
    },
    {
      "epoch": 0.6672794117647058,
      "grad_norm": 1.4260590076446533,
      "learning_rate": 9.629289215686275e-06,
      "loss": 0.0966,
      "step": 2904
    },
    {
      "epoch": 0.6675091911764706,
      "grad_norm": 0.9605420827865601,
      "learning_rate": 9.628778594771243e-06,
      "loss": 0.1039,
      "step": 2905
    },
    {
      "epoch": 0.6677389705882353,
      "grad_norm": 0.8236595392227173,
      "learning_rate": 9.628267973856211e-06,
      "loss": 0.0567,
      "step": 2906
    },
    {
      "epoch": 0.66796875,
      "grad_norm": 1.1395031213760376,
      "learning_rate": 9.627757352941177e-06,
      "loss": 0.0799,
      "step": 2907
    },
    {
      "epoch": 0.6681985294117647,
      "grad_norm": 1.0188977718353271,
      "learning_rate": 9.627246732026145e-06,
      "loss": 0.0859,
      "step": 2908
    },
    {
      "epoch": 0.6684283088235294,
      "grad_norm": 1.042098045349121,
      "learning_rate": 9.626736111111113e-06,
      "loss": 0.1123,
      "step": 2909
    },
    {
      "epoch": 0.6686580882352942,
      "grad_norm": 1.1268706321716309,
      "learning_rate": 9.626225490196079e-06,
      "loss": 0.0728,
      "step": 2910
    },
    {
      "epoch": 0.6688878676470589,
      "grad_norm": 1.2887836694717407,
      "learning_rate": 9.625714869281047e-06,
      "loss": 0.1079,
      "step": 2911
    },
    {
      "epoch": 0.6691176470588235,
      "grad_norm": 1.3544645309448242,
      "learning_rate": 9.625204248366013e-06,
      "loss": 0.1311,
      "step": 2912
    },
    {
      "epoch": 0.6693474264705882,
      "grad_norm": 0.8908024430274963,
      "learning_rate": 9.624693627450981e-06,
      "loss": 0.0537,
      "step": 2913
    },
    {
      "epoch": 0.6695772058823529,
      "grad_norm": 1.2302390336990356,
      "learning_rate": 9.624183006535949e-06,
      "loss": 0.1105,
      "step": 2914
    },
    {
      "epoch": 0.6698069852941176,
      "grad_norm": 1.1527926921844482,
      "learning_rate": 9.623672385620917e-06,
      "loss": 0.0969,
      "step": 2915
    },
    {
      "epoch": 0.6700367647058824,
      "grad_norm": 1.2460074424743652,
      "learning_rate": 9.623161764705883e-06,
      "loss": 0.078,
      "step": 2916
    },
    {
      "epoch": 0.6702665441176471,
      "grad_norm": 1.2027055025100708,
      "learning_rate": 9.62265114379085e-06,
      "loss": 0.1027,
      "step": 2917
    },
    {
      "epoch": 0.6704963235294118,
      "grad_norm": 1.0155062675476074,
      "learning_rate": 9.622140522875819e-06,
      "loss": 0.1016,
      "step": 2918
    },
    {
      "epoch": 0.6707261029411765,
      "grad_norm": 0.949308454990387,
      "learning_rate": 9.621629901960785e-06,
      "loss": 0.1033,
      "step": 2919
    },
    {
      "epoch": 0.6709558823529411,
      "grad_norm": 0.8942419290542603,
      "learning_rate": 9.621119281045753e-06,
      "loss": 0.0539,
      "step": 2920
    },
    {
      "epoch": 0.6711856617647058,
      "grad_norm": 1.1743671894073486,
      "learning_rate": 9.62060866013072e-06,
      "loss": 0.0956,
      "step": 2921
    },
    {
      "epoch": 0.6714154411764706,
      "grad_norm": 1.2258964776992798,
      "learning_rate": 9.620098039215687e-06,
      "loss": 0.1016,
      "step": 2922
    },
    {
      "epoch": 0.6716452205882353,
      "grad_norm": 1.1398953199386597,
      "learning_rate": 9.619587418300654e-06,
      "loss": 0.0781,
      "step": 2923
    },
    {
      "epoch": 0.671875,
      "grad_norm": 1.0081243515014648,
      "learning_rate": 9.61907679738562e-06,
      "loss": 0.0759,
      "step": 2924
    },
    {
      "epoch": 0.6721047794117647,
      "grad_norm": 1.749780297279358,
      "learning_rate": 9.61856617647059e-06,
      "loss": 0.1457,
      "step": 2925
    },
    {
      "epoch": 0.6723345588235294,
      "grad_norm": 1.5657352209091187,
      "learning_rate": 9.618055555555556e-06,
      "loss": 0.1292,
      "step": 2926
    },
    {
      "epoch": 0.6725643382352942,
      "grad_norm": 1.4506758451461792,
      "learning_rate": 9.617544934640524e-06,
      "loss": 0.1075,
      "step": 2927
    },
    {
      "epoch": 0.6727941176470589,
      "grad_norm": 0.7590158581733704,
      "learning_rate": 9.61703431372549e-06,
      "loss": 0.0676,
      "step": 2928
    },
    {
      "epoch": 0.6730238970588235,
      "grad_norm": 1.3344686031341553,
      "learning_rate": 9.616523692810458e-06,
      "loss": 0.0914,
      "step": 2929
    },
    {
      "epoch": 0.6732536764705882,
      "grad_norm": 0.9686499238014221,
      "learning_rate": 9.616013071895426e-06,
      "loss": 0.0798,
      "step": 2930
    },
    {
      "epoch": 0.6734834558823529,
      "grad_norm": 1.0276141166687012,
      "learning_rate": 9.615502450980392e-06,
      "loss": 0.0711,
      "step": 2931
    },
    {
      "epoch": 0.6737132352941176,
      "grad_norm": 1.08565354347229,
      "learning_rate": 9.61499183006536e-06,
      "loss": 0.1281,
      "step": 2932
    },
    {
      "epoch": 0.6739430147058824,
      "grad_norm": 1.08161199092865,
      "learning_rate": 9.614481209150328e-06,
      "loss": 0.0823,
      "step": 2933
    },
    {
      "epoch": 0.6741727941176471,
      "grad_norm": 1.0471973419189453,
      "learning_rate": 9.613970588235296e-06,
      "loss": 0.1195,
      "step": 2934
    },
    {
      "epoch": 0.6744025735294118,
      "grad_norm": 1.3853800296783447,
      "learning_rate": 9.613459967320262e-06,
      "loss": 0.1383,
      "step": 2935
    },
    {
      "epoch": 0.6746323529411765,
      "grad_norm": 0.8278338313102722,
      "learning_rate": 9.61294934640523e-06,
      "loss": 0.076,
      "step": 2936
    },
    {
      "epoch": 0.6748621323529411,
      "grad_norm": 0.8627845644950867,
      "learning_rate": 9.612438725490198e-06,
      "loss": 0.0686,
      "step": 2937
    },
    {
      "epoch": 0.6750919117647058,
      "grad_norm": 1.2568159103393555,
      "learning_rate": 9.611928104575164e-06,
      "loss": 0.0938,
      "step": 2938
    },
    {
      "epoch": 0.6753216911764706,
      "grad_norm": 1.022535800933838,
      "learning_rate": 9.611417483660132e-06,
      "loss": 0.1039,
      "step": 2939
    },
    {
      "epoch": 0.6755514705882353,
      "grad_norm": 0.9623469710350037,
      "learning_rate": 9.610906862745098e-06,
      "loss": 0.0776,
      "step": 2940
    },
    {
      "epoch": 0.67578125,
      "grad_norm": 1.4604679346084595,
      "learning_rate": 9.610396241830067e-06,
      "loss": 0.0899,
      "step": 2941
    },
    {
      "epoch": 0.6760110294117647,
      "grad_norm": 1.5307221412658691,
      "learning_rate": 9.609885620915034e-06,
      "loss": 0.092,
      "step": 2942
    },
    {
      "epoch": 0.6762408088235294,
      "grad_norm": 1.246211051940918,
      "learning_rate": 9.609375000000001e-06,
      "loss": 0.1006,
      "step": 2943
    },
    {
      "epoch": 0.6764705882352942,
      "grad_norm": 1.3595330715179443,
      "learning_rate": 9.608864379084968e-06,
      "loss": 0.1054,
      "step": 2944
    },
    {
      "epoch": 0.6767003676470589,
      "grad_norm": 1.0913631916046143,
      "learning_rate": 9.608353758169936e-06,
      "loss": 0.0901,
      "step": 2945
    },
    {
      "epoch": 0.6769301470588235,
      "grad_norm": 1.2117060422897339,
      "learning_rate": 9.607843137254903e-06,
      "loss": 0.0943,
      "step": 2946
    },
    {
      "epoch": 0.6771599264705882,
      "grad_norm": 1.0678550004959106,
      "learning_rate": 9.60733251633987e-06,
      "loss": 0.0698,
      "step": 2947
    },
    {
      "epoch": 0.6773897058823529,
      "grad_norm": 0.9000833630561829,
      "learning_rate": 9.606821895424837e-06,
      "loss": 0.0691,
      "step": 2948
    },
    {
      "epoch": 0.6776194852941176,
      "grad_norm": 1.1384620666503906,
      "learning_rate": 9.606311274509804e-06,
      "loss": 0.0863,
      "step": 2949
    },
    {
      "epoch": 0.6778492647058824,
      "grad_norm": 1.1493486166000366,
      "learning_rate": 9.605800653594773e-06,
      "loss": 0.099,
      "step": 2950
    },
    {
      "epoch": 0.6780790441176471,
      "grad_norm": 0.9372194409370422,
      "learning_rate": 9.60529003267974e-06,
      "loss": 0.1004,
      "step": 2951
    },
    {
      "epoch": 0.6783088235294118,
      "grad_norm": 1.0386080741882324,
      "learning_rate": 9.604779411764707e-06,
      "loss": 0.102,
      "step": 2952
    },
    {
      "epoch": 0.6785386029411765,
      "grad_norm": 1.2224535942077637,
      "learning_rate": 9.604268790849673e-06,
      "loss": 0.0875,
      "step": 2953
    },
    {
      "epoch": 0.6787683823529411,
      "grad_norm": 0.9851163029670715,
      "learning_rate": 9.603758169934641e-06,
      "loss": 0.0645,
      "step": 2954
    },
    {
      "epoch": 0.6789981617647058,
      "grad_norm": 0.8744238018989563,
      "learning_rate": 9.603247549019609e-06,
      "loss": 0.0811,
      "step": 2955
    },
    {
      "epoch": 0.6792279411764706,
      "grad_norm": 1.1425931453704834,
      "learning_rate": 9.602736928104575e-06,
      "loss": 0.0978,
      "step": 2956
    },
    {
      "epoch": 0.6794577205882353,
      "grad_norm": 1.5968657732009888,
      "learning_rate": 9.602226307189543e-06,
      "loss": 0.0975,
      "step": 2957
    },
    {
      "epoch": 0.6796875,
      "grad_norm": 1.1839067935943604,
      "learning_rate": 9.601715686274511e-06,
      "loss": 0.104,
      "step": 2958
    },
    {
      "epoch": 0.6799172794117647,
      "grad_norm": 1.0674254894256592,
      "learning_rate": 9.601205065359477e-06,
      "loss": 0.0913,
      "step": 2959
    },
    {
      "epoch": 0.6801470588235294,
      "grad_norm": 0.9865516424179077,
      "learning_rate": 9.600694444444445e-06,
      "loss": 0.1185,
      "step": 2960
    },
    {
      "epoch": 0.6803768382352942,
      "grad_norm": 0.9500628113746643,
      "learning_rate": 9.600183823529413e-06,
      "loss": 0.072,
      "step": 2961
    },
    {
      "epoch": 0.6806066176470589,
      "grad_norm": 1.6947416067123413,
      "learning_rate": 9.59967320261438e-06,
      "loss": 0.0935,
      "step": 2962
    },
    {
      "epoch": 0.6808363970588235,
      "grad_norm": 1.032962441444397,
      "learning_rate": 9.599162581699347e-06,
      "loss": 0.0833,
      "step": 2963
    },
    {
      "epoch": 0.6810661764705882,
      "grad_norm": 1.1216593980789185,
      "learning_rate": 9.598651960784315e-06,
      "loss": 0.0871,
      "step": 2964
    },
    {
      "epoch": 0.6812959558823529,
      "grad_norm": 1.322288155555725,
      "learning_rate": 9.598141339869281e-06,
      "loss": 0.114,
      "step": 2965
    },
    {
      "epoch": 0.6815257352941176,
      "grad_norm": 1.4109069108963013,
      "learning_rate": 9.597630718954249e-06,
      "loss": 0.139,
      "step": 2966
    },
    {
      "epoch": 0.6817555147058824,
      "grad_norm": 0.8761948943138123,
      "learning_rate": 9.597120098039217e-06,
      "loss": 0.0515,
      "step": 2967
    },
    {
      "epoch": 0.6819852941176471,
      "grad_norm": 1.0870192050933838,
      "learning_rate": 9.596609477124183e-06,
      "loss": 0.1133,
      "step": 2968
    },
    {
      "epoch": 0.6822150735294118,
      "grad_norm": 1.0668283700942993,
      "learning_rate": 9.59609885620915e-06,
      "loss": 0.0982,
      "step": 2969
    },
    {
      "epoch": 0.6824448529411765,
      "grad_norm": 1.0279264450073242,
      "learning_rate": 9.595588235294119e-06,
      "loss": 0.1005,
      "step": 2970
    },
    {
      "epoch": 0.6826746323529411,
      "grad_norm": 1.0984083414077759,
      "learning_rate": 9.595077614379086e-06,
      "loss": 0.0882,
      "step": 2971
    },
    {
      "epoch": 0.6829044117647058,
      "grad_norm": 0.8994048237800598,
      "learning_rate": 9.594566993464053e-06,
      "loss": 0.0736,
      "step": 2972
    },
    {
      "epoch": 0.6831341911764706,
      "grad_norm": 1.1725534200668335,
      "learning_rate": 9.59405637254902e-06,
      "loss": 0.1147,
      "step": 2973
    },
    {
      "epoch": 0.6833639705882353,
      "grad_norm": 0.9615345597267151,
      "learning_rate": 9.593545751633988e-06,
      "loss": 0.0745,
      "step": 2974
    },
    {
      "epoch": 0.68359375,
      "grad_norm": 1.3554493188858032,
      "learning_rate": 9.593035130718954e-06,
      "loss": 0.1165,
      "step": 2975
    },
    {
      "epoch": 0.6838235294117647,
      "grad_norm": 1.137587070465088,
      "learning_rate": 9.592524509803922e-06,
      "loss": 0.0767,
      "step": 2976
    },
    {
      "epoch": 0.6840533088235294,
      "grad_norm": 0.8761144280433655,
      "learning_rate": 9.592013888888888e-06,
      "loss": 0.0693,
      "step": 2977
    },
    {
      "epoch": 0.6842830882352942,
      "grad_norm": 0.669804573059082,
      "learning_rate": 9.591503267973858e-06,
      "loss": 0.0805,
      "step": 2978
    },
    {
      "epoch": 0.6845128676470589,
      "grad_norm": 1.1195615530014038,
      "learning_rate": 9.590992647058824e-06,
      "loss": 0.099,
      "step": 2979
    },
    {
      "epoch": 0.6847426470588235,
      "grad_norm": 1.0461926460266113,
      "learning_rate": 9.590482026143792e-06,
      "loss": 0.0889,
      "step": 2980
    },
    {
      "epoch": 0.6849724264705882,
      "grad_norm": 1.1590466499328613,
      "learning_rate": 9.589971405228758e-06,
      "loss": 0.0859,
      "step": 2981
    },
    {
      "epoch": 0.6852022058823529,
      "grad_norm": 1.2652623653411865,
      "learning_rate": 9.589460784313726e-06,
      "loss": 0.0837,
      "step": 2982
    },
    {
      "epoch": 0.6854319852941176,
      "grad_norm": 1.0359784364700317,
      "learning_rate": 9.588950163398694e-06,
      "loss": 0.0738,
      "step": 2983
    },
    {
      "epoch": 0.6856617647058824,
      "grad_norm": 1.0461655855178833,
      "learning_rate": 9.58843954248366e-06,
      "loss": 0.0639,
      "step": 2984
    },
    {
      "epoch": 0.6858915441176471,
      "grad_norm": 1.003097414970398,
      "learning_rate": 9.587928921568628e-06,
      "loss": 0.1058,
      "step": 2985
    },
    {
      "epoch": 0.6861213235294118,
      "grad_norm": 0.9651269912719727,
      "learning_rate": 9.587418300653596e-06,
      "loss": 0.0693,
      "step": 2986
    },
    {
      "epoch": 0.6863511029411765,
      "grad_norm": 1.1864569187164307,
      "learning_rate": 9.586907679738564e-06,
      "loss": 0.1273,
      "step": 2987
    },
    {
      "epoch": 0.6865808823529411,
      "grad_norm": 0.8559368848800659,
      "learning_rate": 9.58639705882353e-06,
      "loss": 0.0736,
      "step": 2988
    },
    {
      "epoch": 0.6868106617647058,
      "grad_norm": 0.8812410235404968,
      "learning_rate": 9.585886437908498e-06,
      "loss": 0.0777,
      "step": 2989
    },
    {
      "epoch": 0.6870404411764706,
      "grad_norm": 1.0305858850479126,
      "learning_rate": 9.585375816993466e-06,
      "loss": 0.0895,
      "step": 2990
    },
    {
      "epoch": 0.6872702205882353,
      "grad_norm": 1.0980807542800903,
      "learning_rate": 9.584865196078432e-06,
      "loss": 0.0867,
      "step": 2991
    },
    {
      "epoch": 0.6875,
      "grad_norm": 0.9160159230232239,
      "learning_rate": 9.5843545751634e-06,
      "loss": 0.0924,
      "step": 2992
    },
    {
      "epoch": 0.6877297794117647,
      "grad_norm": 1.0869436264038086,
      "learning_rate": 9.583843954248366e-06,
      "loss": 0.0903,
      "step": 2993
    },
    {
      "epoch": 0.6879595588235294,
      "grad_norm": 0.7935305237770081,
      "learning_rate": 9.583333333333335e-06,
      "loss": 0.0552,
      "step": 2994
    },
    {
      "epoch": 0.6881893382352942,
      "grad_norm": 1.217510461807251,
      "learning_rate": 9.582822712418301e-06,
      "loss": 0.0925,
      "step": 2995
    },
    {
      "epoch": 0.6884191176470589,
      "grad_norm": 0.78572678565979,
      "learning_rate": 9.58231209150327e-06,
      "loss": 0.0661,
      "step": 2996
    },
    {
      "epoch": 0.6886488970588235,
      "grad_norm": 1.1312037706375122,
      "learning_rate": 9.581801470588236e-06,
      "loss": 0.1036,
      "step": 2997
    },
    {
      "epoch": 0.6888786764705882,
      "grad_norm": 0.9329964518547058,
      "learning_rate": 9.581290849673203e-06,
      "loss": 0.0934,
      "step": 2998
    },
    {
      "epoch": 0.6891084558823529,
      "grad_norm": 1.3623884916305542,
      "learning_rate": 9.580780228758171e-06,
      "loss": 0.1131,
      "step": 2999
    },
    {
      "epoch": 0.6893382352941176,
      "grad_norm": 0.9180487990379333,
      "learning_rate": 9.580269607843137e-06,
      "loss": 0.0822,
      "step": 3000
    },
    {
      "epoch": 0.6893382352941176,
      "eval_loss": 0.08861786872148514,
      "eval_runtime": 2007.1366,
      "eval_samples_per_second": 4.437,
      "eval_steps_per_second": 2.219,
      "step": 3000
    },
    {
      "epoch": 0.6895680147058824,
      "grad_norm": 1.1461100578308105,
      "learning_rate": 9.579758986928105e-06,
      "loss": 0.1048,
      "step": 3001
    },
    {
      "epoch": 0.6897977941176471,
      "grad_norm": 1.0185004472732544,
      "learning_rate": 9.579248366013073e-06,
      "loss": 0.1129,
      "step": 3002
    },
    {
      "epoch": 0.6900275735294118,
      "grad_norm": 1.3273755311965942,
      "learning_rate": 9.57873774509804e-06,
      "loss": 0.0753,
      "step": 3003
    },
    {
      "epoch": 0.6902573529411765,
      "grad_norm": 1.2731729745864868,
      "learning_rate": 9.578227124183007e-06,
      "loss": 0.0882,
      "step": 3004
    },
    {
      "epoch": 0.6904871323529411,
      "grad_norm": 1.2585883140563965,
      "learning_rate": 9.577716503267975e-06,
      "loss": 0.1245,
      "step": 3005
    },
    {
      "epoch": 0.6907169117647058,
      "grad_norm": 1.0948913097381592,
      "learning_rate": 9.577205882352943e-06,
      "loss": 0.1187,
      "step": 3006
    },
    {
      "epoch": 0.6909466911764706,
      "grad_norm": 0.8611066341400146,
      "learning_rate": 9.576695261437909e-06,
      "loss": 0.0847,
      "step": 3007
    },
    {
      "epoch": 0.6911764705882353,
      "grad_norm": 0.936725914478302,
      "learning_rate": 9.576184640522877e-06,
      "loss": 0.082,
      "step": 3008
    },
    {
      "epoch": 0.69140625,
      "grad_norm": 1.4747039079666138,
      "learning_rate": 9.575674019607843e-06,
      "loss": 0.1383,
      "step": 3009
    },
    {
      "epoch": 0.6916360294117647,
      "grad_norm": 1.0776909589767456,
      "learning_rate": 9.575163398692811e-06,
      "loss": 0.08,
      "step": 3010
    },
    {
      "epoch": 0.6918658088235294,
      "grad_norm": 0.8303357362747192,
      "learning_rate": 9.574652777777779e-06,
      "loss": 0.0778,
      "step": 3011
    },
    {
      "epoch": 0.6920955882352942,
      "grad_norm": 0.9249687790870667,
      "learning_rate": 9.574142156862745e-06,
      "loss": 0.0865,
      "step": 3012
    },
    {
      "epoch": 0.6923253676470589,
      "grad_norm": 1.0356882810592651,
      "learning_rate": 9.573631535947713e-06,
      "loss": 0.0887,
      "step": 3013
    },
    {
      "epoch": 0.6925551470588235,
      "grad_norm": 1.0608806610107422,
      "learning_rate": 9.57312091503268e-06,
      "loss": 0.0952,
      "step": 3014
    },
    {
      "epoch": 0.6927849264705882,
      "grad_norm": 0.7334314584732056,
      "learning_rate": 9.572610294117649e-06,
      "loss": 0.0743,
      "step": 3015
    },
    {
      "epoch": 0.6930147058823529,
      "grad_norm": 1.196866750717163,
      "learning_rate": 9.572099673202615e-06,
      "loss": 0.063,
      "step": 3016
    },
    {
      "epoch": 0.6932444852941176,
      "grad_norm": 1.2095770835876465,
      "learning_rate": 9.571589052287583e-06,
      "loss": 0.0946,
      "step": 3017
    },
    {
      "epoch": 0.6934742647058824,
      "grad_norm": 1.1190186738967896,
      "learning_rate": 9.57107843137255e-06,
      "loss": 0.0712,
      "step": 3018
    },
    {
      "epoch": 0.6937040441176471,
      "grad_norm": 1.167471170425415,
      "learning_rate": 9.570567810457517e-06,
      "loss": 0.1054,
      "step": 3019
    },
    {
      "epoch": 0.6939338235294118,
      "grad_norm": 1.104270339012146,
      "learning_rate": 9.570057189542484e-06,
      "loss": 0.0688,
      "step": 3020
    },
    {
      "epoch": 0.6941636029411765,
      "grad_norm": 1.0748063325881958,
      "learning_rate": 9.56954656862745e-06,
      "loss": 0.089,
      "step": 3021
    },
    {
      "epoch": 0.6943933823529411,
      "grad_norm": 1.0370148420333862,
      "learning_rate": 9.56903594771242e-06,
      "loss": 0.0865,
      "step": 3022
    },
    {
      "epoch": 0.6946231617647058,
      "grad_norm": 1.2059354782104492,
      "learning_rate": 9.568525326797386e-06,
      "loss": 0.0968,
      "step": 3023
    },
    {
      "epoch": 0.6948529411764706,
      "grad_norm": 0.9520630836486816,
      "learning_rate": 9.568014705882354e-06,
      "loss": 0.071,
      "step": 3024
    },
    {
      "epoch": 0.6950827205882353,
      "grad_norm": 1.1522730588912964,
      "learning_rate": 9.56750408496732e-06,
      "loss": 0.0909,
      "step": 3025
    },
    {
      "epoch": 0.6953125,
      "grad_norm": 1.112343192100525,
      "learning_rate": 9.566993464052288e-06,
      "loss": 0.0807,
      "step": 3026
    },
    {
      "epoch": 0.6955422794117647,
      "grad_norm": 1.3255761861801147,
      "learning_rate": 9.566482843137256e-06,
      "loss": 0.0931,
      "step": 3027
    },
    {
      "epoch": 0.6957720588235294,
      "grad_norm": 1.7220146656036377,
      "learning_rate": 9.565972222222222e-06,
      "loss": 0.1493,
      "step": 3028
    },
    {
      "epoch": 0.6960018382352942,
      "grad_norm": 1.0771129131317139,
      "learning_rate": 9.56546160130719e-06,
      "loss": 0.1132,
      "step": 3029
    },
    {
      "epoch": 0.6962316176470589,
      "grad_norm": 0.8831732273101807,
      "learning_rate": 9.564950980392158e-06,
      "loss": 0.0641,
      "step": 3030
    },
    {
      "epoch": 0.6964613970588235,
      "grad_norm": 1.1766767501831055,
      "learning_rate": 9.564440359477126e-06,
      "loss": 0.0828,
      "step": 3031
    },
    {
      "epoch": 0.6966911764705882,
      "grad_norm": 1.0867582559585571,
      "learning_rate": 9.563929738562092e-06,
      "loss": 0.1073,
      "step": 3032
    },
    {
      "epoch": 0.6969209558823529,
      "grad_norm": 0.9849451184272766,
      "learning_rate": 9.56341911764706e-06,
      "loss": 0.0817,
      "step": 3033
    },
    {
      "epoch": 0.6971507352941176,
      "grad_norm": 1.1191269159317017,
      "learning_rate": 9.562908496732028e-06,
      "loss": 0.0924,
      "step": 3034
    },
    {
      "epoch": 0.6973805147058824,
      "grad_norm": 1.1304454803466797,
      "learning_rate": 9.562397875816994e-06,
      "loss": 0.0869,
      "step": 3035
    },
    {
      "epoch": 0.6976102941176471,
      "grad_norm": 1.088507056236267,
      "learning_rate": 9.561887254901962e-06,
      "loss": 0.0843,
      "step": 3036
    },
    {
      "epoch": 0.6978400735294118,
      "grad_norm": 0.9432241916656494,
      "learning_rate": 9.561376633986928e-06,
      "loss": 0.0886,
      "step": 3037
    },
    {
      "epoch": 0.6980698529411765,
      "grad_norm": 1.0866022109985352,
      "learning_rate": 9.560866013071896e-06,
      "loss": 0.116,
      "step": 3038
    },
    {
      "epoch": 0.6982996323529411,
      "grad_norm": 1.0378445386886597,
      "learning_rate": 9.560355392156864e-06,
      "loss": 0.0751,
      "step": 3039
    },
    {
      "epoch": 0.6985294117647058,
      "grad_norm": 0.9983782768249512,
      "learning_rate": 9.559844771241832e-06,
      "loss": 0.0875,
      "step": 3040
    },
    {
      "epoch": 0.6987591911764706,
      "grad_norm": 1.002170205116272,
      "learning_rate": 9.559334150326798e-06,
      "loss": 0.068,
      "step": 3041
    },
    {
      "epoch": 0.6989889705882353,
      "grad_norm": 0.9788731932640076,
      "learning_rate": 9.558823529411766e-06,
      "loss": 0.0848,
      "step": 3042
    },
    {
      "epoch": 0.69921875,
      "grad_norm": 1.0251423120498657,
      "learning_rate": 9.558312908496733e-06,
      "loss": 0.0842,
      "step": 3043
    },
    {
      "epoch": 0.6994485294117647,
      "grad_norm": 1.1954785585403442,
      "learning_rate": 9.5578022875817e-06,
      "loss": 0.0878,
      "step": 3044
    },
    {
      "epoch": 0.6996783088235294,
      "grad_norm": 1.3924115896224976,
      "learning_rate": 9.557291666666667e-06,
      "loss": 0.1012,
      "step": 3045
    },
    {
      "epoch": 0.6999080882352942,
      "grad_norm": 1.2836865186691284,
      "learning_rate": 9.556781045751635e-06,
      "loss": 0.1004,
      "step": 3046
    },
    {
      "epoch": 0.7001378676470589,
      "grad_norm": 1.1325691938400269,
      "learning_rate": 9.556270424836601e-06,
      "loss": 0.0864,
      "step": 3047
    },
    {
      "epoch": 0.7003676470588235,
      "grad_norm": 0.8162121772766113,
      "learning_rate": 9.55575980392157e-06,
      "loss": 0.0578,
      "step": 3048
    },
    {
      "epoch": 0.7005974264705882,
      "grad_norm": 1.6538503170013428,
      "learning_rate": 9.555249183006537e-06,
      "loss": 0.1167,
      "step": 3049
    },
    {
      "epoch": 0.7008272058823529,
      "grad_norm": 0.8237318396568298,
      "learning_rate": 9.554738562091505e-06,
      "loss": 0.0684,
      "step": 3050
    },
    {
      "epoch": 0.7010569852941176,
      "grad_norm": 0.8600330352783203,
      "learning_rate": 9.554227941176471e-06,
      "loss": 0.0792,
      "step": 3051
    },
    {
      "epoch": 0.7012867647058824,
      "grad_norm": 1.1597563028335571,
      "learning_rate": 9.553717320261439e-06,
      "loss": 0.1037,
      "step": 3052
    },
    {
      "epoch": 0.7015165441176471,
      "grad_norm": 0.9248019456863403,
      "learning_rate": 9.553206699346405e-06,
      "loss": 0.0682,
      "step": 3053
    },
    {
      "epoch": 0.7017463235294118,
      "grad_norm": 1.3934053182601929,
      "learning_rate": 9.552696078431373e-06,
      "loss": 0.0971,
      "step": 3054
    },
    {
      "epoch": 0.7019761029411765,
      "grad_norm": 1.0336625576019287,
      "learning_rate": 9.552185457516341e-06,
      "loss": 0.0973,
      "step": 3055
    },
    {
      "epoch": 0.7022058823529411,
      "grad_norm": 0.8085096478462219,
      "learning_rate": 9.551674836601307e-06,
      "loss": 0.0544,
      "step": 3056
    },
    {
      "epoch": 0.7024356617647058,
      "grad_norm": 1.2516769170761108,
      "learning_rate": 9.551164215686275e-06,
      "loss": 0.0784,
      "step": 3057
    },
    {
      "epoch": 0.7026654411764706,
      "grad_norm": 1.1190879344940186,
      "learning_rate": 9.550653594771243e-06,
      "loss": 0.0886,
      "step": 3058
    },
    {
      "epoch": 0.7028952205882353,
      "grad_norm": 0.97989422082901,
      "learning_rate": 9.55014297385621e-06,
      "loss": 0.0765,
      "step": 3059
    },
    {
      "epoch": 0.703125,
      "grad_norm": 1.1601167917251587,
      "learning_rate": 9.549632352941177e-06,
      "loss": 0.0771,
      "step": 3060
    },
    {
      "epoch": 0.7033547794117647,
      "grad_norm": 1.1882539987564087,
      "learning_rate": 9.549121732026145e-06,
      "loss": 0.12,
      "step": 3061
    },
    {
      "epoch": 0.7035845588235294,
      "grad_norm": 1.1940771341323853,
      "learning_rate": 9.548611111111113e-06,
      "loss": 0.1094,
      "step": 3062
    },
    {
      "epoch": 0.7038143382352942,
      "grad_norm": 0.9249327778816223,
      "learning_rate": 9.548100490196079e-06,
      "loss": 0.061,
      "step": 3063
    },
    {
      "epoch": 0.7040441176470589,
      "grad_norm": 1.0940563678741455,
      "learning_rate": 9.547589869281047e-06,
      "loss": 0.1011,
      "step": 3064
    },
    {
      "epoch": 0.7042738970588235,
      "grad_norm": 0.9390207529067993,
      "learning_rate": 9.547079248366013e-06,
      "loss": 0.1022,
      "step": 3065
    },
    {
      "epoch": 0.7045036764705882,
      "grad_norm": 1.1985619068145752,
      "learning_rate": 9.546568627450982e-06,
      "loss": 0.1057,
      "step": 3066
    },
    {
      "epoch": 0.7047334558823529,
      "grad_norm": 1.2944772243499756,
      "learning_rate": 9.546058006535949e-06,
      "loss": 0.0697,
      "step": 3067
    },
    {
      "epoch": 0.7049632352941176,
      "grad_norm": 0.737714946269989,
      "learning_rate": 9.545547385620916e-06,
      "loss": 0.0589,
      "step": 3068
    },
    {
      "epoch": 0.7051930147058824,
      "grad_norm": 1.1126762628555298,
      "learning_rate": 9.545036764705883e-06,
      "loss": 0.0828,
      "step": 3069
    },
    {
      "epoch": 0.7054227941176471,
      "grad_norm": 1.0813238620758057,
      "learning_rate": 9.54452614379085e-06,
      "loss": 0.0558,
      "step": 3070
    },
    {
      "epoch": 0.7056525735294118,
      "grad_norm": 1.2200201749801636,
      "learning_rate": 9.544015522875818e-06,
      "loss": 0.0597,
      "step": 3071
    },
    {
      "epoch": 0.7058823529411765,
      "grad_norm": 1.0678603649139404,
      "learning_rate": 9.543504901960784e-06,
      "loss": 0.0873,
      "step": 3072
    },
    {
      "epoch": 0.7061121323529411,
      "grad_norm": 0.992851972579956,
      "learning_rate": 9.542994281045752e-06,
      "loss": 0.0711,
      "step": 3073
    },
    {
      "epoch": 0.7063419117647058,
      "grad_norm": 0.9632640480995178,
      "learning_rate": 9.54248366013072e-06,
      "loss": 0.0746,
      "step": 3074
    },
    {
      "epoch": 0.7065716911764706,
      "grad_norm": 0.9168841242790222,
      "learning_rate": 9.541973039215688e-06,
      "loss": 0.0735,
      "step": 3075
    },
    {
      "epoch": 0.7068014705882353,
      "grad_norm": 1.2438486814498901,
      "learning_rate": 9.541462418300654e-06,
      "loss": 0.1022,
      "step": 3076
    },
    {
      "epoch": 0.70703125,
      "grad_norm": 1.0111249685287476,
      "learning_rate": 9.540951797385622e-06,
      "loss": 0.0636,
      "step": 3077
    },
    {
      "epoch": 0.7072610294117647,
      "grad_norm": 1.029252052307129,
      "learning_rate": 9.54044117647059e-06,
      "loss": 0.0631,
      "step": 3078
    },
    {
      "epoch": 0.7074908088235294,
      "grad_norm": 0.8730461597442627,
      "learning_rate": 9.539930555555556e-06,
      "loss": 0.0584,
      "step": 3079
    },
    {
      "epoch": 0.7077205882352942,
      "grad_norm": 1.2351148128509521,
      "learning_rate": 9.539419934640524e-06,
      "loss": 0.0811,
      "step": 3080
    },
    {
      "epoch": 0.7079503676470589,
      "grad_norm": 1.4380296468734741,
      "learning_rate": 9.53890931372549e-06,
      "loss": 0.0944,
      "step": 3081
    },
    {
      "epoch": 0.7081801470588235,
      "grad_norm": 1.1239027976989746,
      "learning_rate": 9.538398692810458e-06,
      "loss": 0.0835,
      "step": 3082
    },
    {
      "epoch": 0.7084099264705882,
      "grad_norm": 1.1080812215805054,
      "learning_rate": 9.537888071895426e-06,
      "loss": 0.1356,
      "step": 3083
    },
    {
      "epoch": 0.7086397058823529,
      "grad_norm": 1.1567021608352661,
      "learning_rate": 9.537377450980394e-06,
      "loss": 0.0805,
      "step": 3084
    },
    {
      "epoch": 0.7088694852941176,
      "grad_norm": 1.3482922315597534,
      "learning_rate": 9.53686683006536e-06,
      "loss": 0.0924,
      "step": 3085
    },
    {
      "epoch": 0.7090992647058824,
      "grad_norm": 0.8789784908294678,
      "learning_rate": 9.536356209150328e-06,
      "loss": 0.0602,
      "step": 3086
    },
    {
      "epoch": 0.7093290441176471,
      "grad_norm": 1.3217254877090454,
      "learning_rate": 9.535845588235296e-06,
      "loss": 0.1077,
      "step": 3087
    },
    {
      "epoch": 0.7095588235294118,
      "grad_norm": 0.758578360080719,
      "learning_rate": 9.535334967320262e-06,
      "loss": 0.0591,
      "step": 3088
    },
    {
      "epoch": 0.7097886029411765,
      "grad_norm": 1.1253221035003662,
      "learning_rate": 9.53482434640523e-06,
      "loss": 0.0832,
      "step": 3089
    },
    {
      "epoch": 0.7100183823529411,
      "grad_norm": 0.9991310238838196,
      "learning_rate": 9.534313725490198e-06,
      "loss": 0.0787,
      "step": 3090
    },
    {
      "epoch": 0.7102481617647058,
      "grad_norm": 1.2331310510635376,
      "learning_rate": 9.533803104575164e-06,
      "loss": 0.1187,
      "step": 3091
    },
    {
      "epoch": 0.7104779411764706,
      "grad_norm": 0.8407690525054932,
      "learning_rate": 9.533292483660132e-06,
      "loss": 0.0675,
      "step": 3092
    },
    {
      "epoch": 0.7107077205882353,
      "grad_norm": 1.0642237663269043,
      "learning_rate": 9.532781862745098e-06,
      "loss": 0.0775,
      "step": 3093
    },
    {
      "epoch": 0.7109375,
      "grad_norm": 1.2401095628738403,
      "learning_rate": 9.532271241830067e-06,
      "loss": 0.0804,
      "step": 3094
    },
    {
      "epoch": 0.7111672794117647,
      "grad_norm": 1.1032495498657227,
      "learning_rate": 9.531760620915033e-06,
      "loss": 0.0721,
      "step": 3095
    },
    {
      "epoch": 0.7113970588235294,
      "grad_norm": 1.206138014793396,
      "learning_rate": 9.531250000000001e-06,
      "loss": 0.1121,
      "step": 3096
    },
    {
      "epoch": 0.7116268382352942,
      "grad_norm": 0.9713979363441467,
      "learning_rate": 9.530739379084967e-06,
      "loss": 0.0843,
      "step": 3097
    },
    {
      "epoch": 0.7118566176470589,
      "grad_norm": 0.9517300128936768,
      "learning_rate": 9.530228758169935e-06,
      "loss": 0.0721,
      "step": 3098
    },
    {
      "epoch": 0.7120863970588235,
      "grad_norm": 0.8222869634628296,
      "learning_rate": 9.529718137254903e-06,
      "loss": 0.0586,
      "step": 3099
    },
    {
      "epoch": 0.7123161764705882,
      "grad_norm": 0.9859442114830017,
      "learning_rate": 9.52920751633987e-06,
      "loss": 0.072,
      "step": 3100
    },
    {
      "epoch": 0.7125459558823529,
      "grad_norm": 0.9602355360984802,
      "learning_rate": 9.528696895424837e-06,
      "loss": 0.0714,
      "step": 3101
    },
    {
      "epoch": 0.7127757352941176,
      "grad_norm": 1.0305594205856323,
      "learning_rate": 9.528186274509803e-06,
      "loss": 0.0835,
      "step": 3102
    },
    {
      "epoch": 0.7130055147058824,
      "grad_norm": 1.1182997226715088,
      "learning_rate": 9.527675653594773e-06,
      "loss": 0.074,
      "step": 3103
    },
    {
      "epoch": 0.7132352941176471,
      "grad_norm": 1.471483588218689,
      "learning_rate": 9.527165032679739e-06,
      "loss": 0.1364,
      "step": 3104
    },
    {
      "epoch": 0.7134650735294118,
      "grad_norm": 1.024829626083374,
      "learning_rate": 9.526654411764707e-06,
      "loss": 0.0614,
      "step": 3105
    },
    {
      "epoch": 0.7136948529411765,
      "grad_norm": 1.170001745223999,
      "learning_rate": 9.526143790849673e-06,
      "loss": 0.0909,
      "step": 3106
    },
    {
      "epoch": 0.7139246323529411,
      "grad_norm": 1.0439504384994507,
      "learning_rate": 9.525633169934641e-06,
      "loss": 0.0683,
      "step": 3107
    },
    {
      "epoch": 0.7141544117647058,
      "grad_norm": 0.93095463514328,
      "learning_rate": 9.525122549019609e-06,
      "loss": 0.0981,
      "step": 3108
    },
    {
      "epoch": 0.7143841911764706,
      "grad_norm": 1.1050256490707397,
      "learning_rate": 9.524611928104575e-06,
      "loss": 0.0853,
      "step": 3109
    },
    {
      "epoch": 0.7146139705882353,
      "grad_norm": 1.0827076435089111,
      "learning_rate": 9.524101307189543e-06,
      "loss": 0.0724,
      "step": 3110
    },
    {
      "epoch": 0.71484375,
      "grad_norm": 0.9638540148735046,
      "learning_rate": 9.52359068627451e-06,
      "loss": 0.0733,
      "step": 3111
    },
    {
      "epoch": 0.7150735294117647,
      "grad_norm": 0.8303921222686768,
      "learning_rate": 9.523080065359479e-06,
      "loss": 0.0702,
      "step": 3112
    },
    {
      "epoch": 0.7153033088235294,
      "grad_norm": 1.2784098386764526,
      "learning_rate": 9.522569444444445e-06,
      "loss": 0.1085,
      "step": 3113
    },
    {
      "epoch": 0.7155330882352942,
      "grad_norm": 0.9917389750480652,
      "learning_rate": 9.522058823529413e-06,
      "loss": 0.0676,
      "step": 3114
    },
    {
      "epoch": 0.7157628676470589,
      "grad_norm": 0.8220271468162537,
      "learning_rate": 9.52154820261438e-06,
      "loss": 0.0728,
      "step": 3115
    },
    {
      "epoch": 0.7159926470588235,
      "grad_norm": 1.0675562620162964,
      "learning_rate": 9.521037581699347e-06,
      "loss": 0.0797,
      "step": 3116
    },
    {
      "epoch": 0.7162224264705882,
      "grad_norm": 0.8286945819854736,
      "learning_rate": 9.520526960784315e-06,
      "loss": 0.0663,
      "step": 3117
    },
    {
      "epoch": 0.7164522058823529,
      "grad_norm": 1.0543767213821411,
      "learning_rate": 9.52001633986928e-06,
      "loss": 0.0773,
      "step": 3118
    },
    {
      "epoch": 0.7166819852941176,
      "grad_norm": 1.0535155534744263,
      "learning_rate": 9.51950571895425e-06,
      "loss": 0.0992,
      "step": 3119
    },
    {
      "epoch": 0.7169117647058824,
      "grad_norm": 1.1128528118133545,
      "learning_rate": 9.518995098039216e-06,
      "loss": 0.0965,
      "step": 3120
    },
    {
      "epoch": 0.7171415441176471,
      "grad_norm": 0.9036809206008911,
      "learning_rate": 9.518484477124184e-06,
      "loss": 0.0878,
      "step": 3121
    },
    {
      "epoch": 0.7173713235294118,
      "grad_norm": 0.9767116904258728,
      "learning_rate": 9.51797385620915e-06,
      "loss": 0.0544,
      "step": 3122
    },
    {
      "epoch": 0.7176011029411765,
      "grad_norm": 2.201418161392212,
      "learning_rate": 9.517463235294118e-06,
      "loss": 0.093,
      "step": 3123
    },
    {
      "epoch": 0.7178308823529411,
      "grad_norm": 1.0674939155578613,
      "learning_rate": 9.516952614379086e-06,
      "loss": 0.0856,
      "step": 3124
    },
    {
      "epoch": 0.7180606617647058,
      "grad_norm": 0.8764598965644836,
      "learning_rate": 9.516441993464052e-06,
      "loss": 0.072,
      "step": 3125
    },
    {
      "epoch": 0.7182904411764706,
      "grad_norm": 1.191299319267273,
      "learning_rate": 9.51593137254902e-06,
      "loss": 0.0749,
      "step": 3126
    },
    {
      "epoch": 0.7185202205882353,
      "grad_norm": 0.8550706505775452,
      "learning_rate": 9.515420751633988e-06,
      "loss": 0.0833,
      "step": 3127
    },
    {
      "epoch": 0.71875,
      "grad_norm": 1.3421975374221802,
      "learning_rate": 9.514910130718956e-06,
      "loss": 0.0914,
      "step": 3128
    },
    {
      "epoch": 0.7189797794117647,
      "grad_norm": 1.023787260055542,
      "learning_rate": 9.514399509803922e-06,
      "loss": 0.0886,
      "step": 3129
    },
    {
      "epoch": 0.7192095588235294,
      "grad_norm": 0.9727804064750671,
      "learning_rate": 9.51388888888889e-06,
      "loss": 0.0798,
      "step": 3130
    },
    {
      "epoch": 0.7194393382352942,
      "grad_norm": 0.8469656109809875,
      "learning_rate": 9.513378267973858e-06,
      "loss": 0.073,
      "step": 3131
    },
    {
      "epoch": 0.7196691176470589,
      "grad_norm": 1.2575150728225708,
      "learning_rate": 9.512867647058824e-06,
      "loss": 0.0984,
      "step": 3132
    },
    {
      "epoch": 0.7198988970588235,
      "grad_norm": 1.2664905786514282,
      "learning_rate": 9.512357026143792e-06,
      "loss": 0.1251,
      "step": 3133
    },
    {
      "epoch": 0.7201286764705882,
      "grad_norm": 1.0802199840545654,
      "learning_rate": 9.511846405228758e-06,
      "loss": 0.0835,
      "step": 3134
    },
    {
      "epoch": 0.7203584558823529,
      "grad_norm": 0.784043550491333,
      "learning_rate": 9.511335784313726e-06,
      "loss": 0.0371,
      "step": 3135
    },
    {
      "epoch": 0.7205882352941176,
      "grad_norm": 1.3025437593460083,
      "learning_rate": 9.510825163398694e-06,
      "loss": 0.0755,
      "step": 3136
    },
    {
      "epoch": 0.7208180147058824,
      "grad_norm": 1.1442049741744995,
      "learning_rate": 9.51031454248366e-06,
      "loss": 0.0903,
      "step": 3137
    },
    {
      "epoch": 0.7210477941176471,
      "grad_norm": 0.869892954826355,
      "learning_rate": 9.509803921568628e-06,
      "loss": 0.0805,
      "step": 3138
    },
    {
      "epoch": 0.7212775735294118,
      "grad_norm": 0.8714010119438171,
      "learning_rate": 9.509293300653596e-06,
      "loss": 0.0804,
      "step": 3139
    },
    {
      "epoch": 0.7215073529411765,
      "grad_norm": 1.321694016456604,
      "learning_rate": 9.508782679738563e-06,
      "loss": 0.0759,
      "step": 3140
    },
    {
      "epoch": 0.7217371323529411,
      "grad_norm": 1.0599164962768555,
      "learning_rate": 9.50827205882353e-06,
      "loss": 0.0848,
      "step": 3141
    },
    {
      "epoch": 0.7219669117647058,
      "grad_norm": 0.8009387850761414,
      "learning_rate": 9.507761437908497e-06,
      "loss": 0.0607,
      "step": 3142
    },
    {
      "epoch": 0.7221966911764706,
      "grad_norm": 0.9683680534362793,
      "learning_rate": 9.507250816993465e-06,
      "loss": 0.0772,
      "step": 3143
    },
    {
      "epoch": 0.7224264705882353,
      "grad_norm": 1.4857887029647827,
      "learning_rate": 9.506740196078432e-06,
      "loss": 0.0978,
      "step": 3144
    },
    {
      "epoch": 0.72265625,
      "grad_norm": 0.6953577399253845,
      "learning_rate": 9.5062295751634e-06,
      "loss": 0.0434,
      "step": 3145
    },
    {
      "epoch": 0.7228860294117647,
      "grad_norm": 1.1145222187042236,
      "learning_rate": 9.505718954248366e-06,
      "loss": 0.0952,
      "step": 3146
    },
    {
      "epoch": 0.7231158088235294,
      "grad_norm": 0.9880579113960266,
      "learning_rate": 9.505208333333335e-06,
      "loss": 0.0931,
      "step": 3147
    },
    {
      "epoch": 0.7233455882352942,
      "grad_norm": 1.1875022649765015,
      "learning_rate": 9.504697712418301e-06,
      "loss": 0.1,
      "step": 3148
    },
    {
      "epoch": 0.7235753676470589,
      "grad_norm": 1.3047170639038086,
      "learning_rate": 9.504187091503269e-06,
      "loss": 0.0972,
      "step": 3149
    },
    {
      "epoch": 0.7238051470588235,
      "grad_norm": 0.9477793574333191,
      "learning_rate": 9.503676470588235e-06,
      "loss": 0.0642,
      "step": 3150
    },
    {
      "epoch": 0.7240349264705882,
      "grad_norm": 0.7986035943031311,
      "learning_rate": 9.503165849673203e-06,
      "loss": 0.0655,
      "step": 3151
    },
    {
      "epoch": 0.7242647058823529,
      "grad_norm": 1.3738296031951904,
      "learning_rate": 9.502655228758171e-06,
      "loss": 0.114,
      "step": 3152
    },
    {
      "epoch": 0.7244944852941176,
      "grad_norm": 1.26657235622406,
      "learning_rate": 9.502144607843137e-06,
      "loss": 0.1024,
      "step": 3153
    },
    {
      "epoch": 0.7247242647058824,
      "grad_norm": 1.050434947013855,
      "learning_rate": 9.501633986928105e-06,
      "loss": 0.0703,
      "step": 3154
    },
    {
      "epoch": 0.7249540441176471,
      "grad_norm": 1.2144514322280884,
      "learning_rate": 9.501123366013073e-06,
      "loss": 0.0887,
      "step": 3155
    },
    {
      "epoch": 0.7251838235294118,
      "grad_norm": 0.9888240694999695,
      "learning_rate": 9.50061274509804e-06,
      "loss": 0.0824,
      "step": 3156
    },
    {
      "epoch": 0.7254136029411765,
      "grad_norm": 1.1857683658599854,
      "learning_rate": 9.500102124183007e-06,
      "loss": 0.0893,
      "step": 3157
    },
    {
      "epoch": 0.7256433823529411,
      "grad_norm": 1.1207573413848877,
      "learning_rate": 9.499591503267975e-06,
      "loss": 0.0844,
      "step": 3158
    },
    {
      "epoch": 0.7258731617647058,
      "grad_norm": 0.986038327217102,
      "learning_rate": 9.499080882352943e-06,
      "loss": 0.0808,
      "step": 3159
    },
    {
      "epoch": 0.7261029411764706,
      "grad_norm": 0.8968653678894043,
      "learning_rate": 9.498570261437909e-06,
      "loss": 0.0526,
      "step": 3160
    },
    {
      "epoch": 0.7263327205882353,
      "grad_norm": 0.8752719163894653,
      "learning_rate": 9.498059640522877e-06,
      "loss": 0.0668,
      "step": 3161
    },
    {
      "epoch": 0.7265625,
      "grad_norm": 0.7710367441177368,
      "learning_rate": 9.497549019607843e-06,
      "loss": 0.0546,
      "step": 3162
    },
    {
      "epoch": 0.7267922794117647,
      "grad_norm": 1.117451548576355,
      "learning_rate": 9.497038398692812e-06,
      "loss": 0.115,
      "step": 3163
    },
    {
      "epoch": 0.7270220588235294,
      "grad_norm": 1.3367305994033813,
      "learning_rate": 9.496527777777779e-06,
      "loss": 0.1114,
      "step": 3164
    },
    {
      "epoch": 0.7272518382352942,
      "grad_norm": 1.1113343238830566,
      "learning_rate": 9.496017156862746e-06,
      "loss": 0.1062,
      "step": 3165
    },
    {
      "epoch": 0.7274816176470589,
      "grad_norm": 1.5018996000289917,
      "learning_rate": 9.495506535947713e-06,
      "loss": 0.1193,
      "step": 3166
    },
    {
      "epoch": 0.7277113970588235,
      "grad_norm": 1.0086824893951416,
      "learning_rate": 9.49499591503268e-06,
      "loss": 0.0642,
      "step": 3167
    },
    {
      "epoch": 0.7279411764705882,
      "grad_norm": 0.8810281753540039,
      "learning_rate": 9.494485294117648e-06,
      "loss": 0.0654,
      "step": 3168
    },
    {
      "epoch": 0.7281709558823529,
      "grad_norm": 1.5082017183303833,
      "learning_rate": 9.493974673202615e-06,
      "loss": 0.1316,
      "step": 3169
    },
    {
      "epoch": 0.7284007352941176,
      "grad_norm": 1.1697242259979248,
      "learning_rate": 9.493464052287582e-06,
      "loss": 0.0685,
      "step": 3170
    },
    {
      "epoch": 0.7286305147058824,
      "grad_norm": 1.0139353275299072,
      "learning_rate": 9.49295343137255e-06,
      "loss": 0.0723,
      "step": 3171
    },
    {
      "epoch": 0.7288602941176471,
      "grad_norm": 1.2080632448196411,
      "learning_rate": 9.492442810457518e-06,
      "loss": 0.0723,
      "step": 3172
    },
    {
      "epoch": 0.7290900735294118,
      "grad_norm": 1.3010399341583252,
      "learning_rate": 9.491932189542484e-06,
      "loss": 0.1112,
      "step": 3173
    },
    {
      "epoch": 0.7293198529411765,
      "grad_norm": 1.0514838695526123,
      "learning_rate": 9.491421568627452e-06,
      "loss": 0.0583,
      "step": 3174
    },
    {
      "epoch": 0.7295496323529411,
      "grad_norm": 1.0893633365631104,
      "learning_rate": 9.49091094771242e-06,
      "loss": 0.0766,
      "step": 3175
    },
    {
      "epoch": 0.7297794117647058,
      "grad_norm": 1.156949520111084,
      "learning_rate": 9.490400326797386e-06,
      "loss": 0.086,
      "step": 3176
    },
    {
      "epoch": 0.7300091911764706,
      "grad_norm": 1.3744802474975586,
      "learning_rate": 9.489889705882354e-06,
      "loss": 0.0866,
      "step": 3177
    },
    {
      "epoch": 0.7302389705882353,
      "grad_norm": 0.8879278302192688,
      "learning_rate": 9.48937908496732e-06,
      "loss": 0.0694,
      "step": 3178
    },
    {
      "epoch": 0.73046875,
      "grad_norm": 1.3380407094955444,
      "learning_rate": 9.488868464052288e-06,
      "loss": 0.1224,
      "step": 3179
    },
    {
      "epoch": 0.7306985294117647,
      "grad_norm": 1.24020516872406,
      "learning_rate": 9.488357843137256e-06,
      "loss": 0.105,
      "step": 3180
    },
    {
      "epoch": 0.7309283088235294,
      "grad_norm": 0.9092475175857544,
      "learning_rate": 9.487847222222222e-06,
      "loss": 0.066,
      "step": 3181
    },
    {
      "epoch": 0.7311580882352942,
      "grad_norm": 1.2405041456222534,
      "learning_rate": 9.48733660130719e-06,
      "loss": 0.1029,
      "step": 3182
    },
    {
      "epoch": 0.7313878676470589,
      "grad_norm": 1.2503445148468018,
      "learning_rate": 9.486825980392158e-06,
      "loss": 0.1025,
      "step": 3183
    },
    {
      "epoch": 0.7316176470588235,
      "grad_norm": 0.9783819317817688,
      "learning_rate": 9.486315359477126e-06,
      "loss": 0.0929,
      "step": 3184
    },
    {
      "epoch": 0.7318474264705882,
      "grad_norm": 1.0434448719024658,
      "learning_rate": 9.485804738562092e-06,
      "loss": 0.0726,
      "step": 3185
    },
    {
      "epoch": 0.7320772058823529,
      "grad_norm": 1.4019906520843506,
      "learning_rate": 9.48529411764706e-06,
      "loss": 0.0933,
      "step": 3186
    },
    {
      "epoch": 0.7323069852941176,
      "grad_norm": 1.0082472562789917,
      "learning_rate": 9.484783496732028e-06,
      "loss": 0.0805,
      "step": 3187
    },
    {
      "epoch": 0.7325367647058824,
      "grad_norm": 1.0872292518615723,
      "learning_rate": 9.484272875816994e-06,
      "loss": 0.0935,
      "step": 3188
    },
    {
      "epoch": 0.7327665441176471,
      "grad_norm": 1.100302815437317,
      "learning_rate": 9.483762254901962e-06,
      "loss": 0.0957,
      "step": 3189
    },
    {
      "epoch": 0.7329963235294118,
      "grad_norm": 1.4401246309280396,
      "learning_rate": 9.483251633986928e-06,
      "loss": 0.1073,
      "step": 3190
    },
    {
      "epoch": 0.7332261029411765,
      "grad_norm": 1.0487247705459595,
      "learning_rate": 9.482741013071897e-06,
      "loss": 0.0678,
      "step": 3191
    },
    {
      "epoch": 0.7334558823529411,
      "grad_norm": 1.320716381072998,
      "learning_rate": 9.482230392156863e-06,
      "loss": 0.0895,
      "step": 3192
    },
    {
      "epoch": 0.7336856617647058,
      "grad_norm": 1.0325086116790771,
      "learning_rate": 9.481719771241831e-06,
      "loss": 0.1143,
      "step": 3193
    },
    {
      "epoch": 0.7339154411764706,
      "grad_norm": 1.3298529386520386,
      "learning_rate": 9.481209150326797e-06,
      "loss": 0.0991,
      "step": 3194
    },
    {
      "epoch": 0.7341452205882353,
      "grad_norm": 1.4810471534729004,
      "learning_rate": 9.480698529411765e-06,
      "loss": 0.0987,
      "step": 3195
    },
    {
      "epoch": 0.734375,
      "grad_norm": 1.1610161066055298,
      "learning_rate": 9.480187908496733e-06,
      "loss": 0.0671,
      "step": 3196
    },
    {
      "epoch": 0.7346047794117647,
      "grad_norm": 0.9429716467857361,
      "learning_rate": 9.4796772875817e-06,
      "loss": 0.0807,
      "step": 3197
    },
    {
      "epoch": 0.7348345588235294,
      "grad_norm": 1.1012482643127441,
      "learning_rate": 9.479166666666667e-06,
      "loss": 0.0907,
      "step": 3198
    },
    {
      "epoch": 0.7350643382352942,
      "grad_norm": 0.9583966732025146,
      "learning_rate": 9.478656045751635e-06,
      "loss": 0.0552,
      "step": 3199
    },
    {
      "epoch": 0.7352941176470589,
      "grad_norm": 1.0243721008300781,
      "learning_rate": 9.478145424836603e-06,
      "loss": 0.0718,
      "step": 3200
    },
    {
      "epoch": 0.7355238970588235,
      "grad_norm": 0.9670575857162476,
      "learning_rate": 9.477634803921569e-06,
      "loss": 0.0855,
      "step": 3201
    },
    {
      "epoch": 0.7357536764705882,
      "grad_norm": 1.2350205183029175,
      "learning_rate": 9.477124183006537e-06,
      "loss": 0.0793,
      "step": 3202
    },
    {
      "epoch": 0.7359834558823529,
      "grad_norm": 1.1055796146392822,
      "learning_rate": 9.476613562091505e-06,
      "loss": 0.0791,
      "step": 3203
    },
    {
      "epoch": 0.7362132352941176,
      "grad_norm": 1.0301001071929932,
      "learning_rate": 9.476102941176471e-06,
      "loss": 0.057,
      "step": 3204
    },
    {
      "epoch": 0.7364430147058824,
      "grad_norm": 1.0755283832550049,
      "learning_rate": 9.475592320261439e-06,
      "loss": 0.0843,
      "step": 3205
    },
    {
      "epoch": 0.7366727941176471,
      "grad_norm": 1.0635643005371094,
      "learning_rate": 9.475081699346405e-06,
      "loss": 0.0676,
      "step": 3206
    },
    {
      "epoch": 0.7369025735294118,
      "grad_norm": 1.0743170976638794,
      "learning_rate": 9.474571078431375e-06,
      "loss": 0.0841,
      "step": 3207
    },
    {
      "epoch": 0.7371323529411765,
      "grad_norm": 0.9797499775886536,
      "learning_rate": 9.47406045751634e-06,
      "loss": 0.0906,
      "step": 3208
    },
    {
      "epoch": 0.7373621323529411,
      "grad_norm": 1.2559276819229126,
      "learning_rate": 9.473549836601309e-06,
      "loss": 0.0984,
      "step": 3209
    },
    {
      "epoch": 0.7375919117647058,
      "grad_norm": 1.1414271593093872,
      "learning_rate": 9.473039215686275e-06,
      "loss": 0.0729,
      "step": 3210
    },
    {
      "epoch": 0.7378216911764706,
      "grad_norm": 1.6448240280151367,
      "learning_rate": 9.472528594771243e-06,
      "loss": 0.0867,
      "step": 3211
    },
    {
      "epoch": 0.7380514705882353,
      "grad_norm": 1.452431321144104,
      "learning_rate": 9.47201797385621e-06,
      "loss": 0.1219,
      "step": 3212
    },
    {
      "epoch": 0.73828125,
      "grad_norm": 0.849500298500061,
      "learning_rate": 9.471507352941177e-06,
      "loss": 0.0687,
      "step": 3213
    },
    {
      "epoch": 0.7385110294117647,
      "grad_norm": 1.1418837308883667,
      "learning_rate": 9.470996732026145e-06,
      "loss": 0.0995,
      "step": 3214
    },
    {
      "epoch": 0.7387408088235294,
      "grad_norm": 0.7926144003868103,
      "learning_rate": 9.470486111111112e-06,
      "loss": 0.0734,
      "step": 3215
    },
    {
      "epoch": 0.7389705882352942,
      "grad_norm": 1.0678279399871826,
      "learning_rate": 9.469975490196079e-06,
      "loss": 0.0953,
      "step": 3216
    },
    {
      "epoch": 0.7392003676470589,
      "grad_norm": 0.9894083738327026,
      "learning_rate": 9.469464869281046e-06,
      "loss": 0.0664,
      "step": 3217
    },
    {
      "epoch": 0.7394301470588235,
      "grad_norm": 1.2475652694702148,
      "learning_rate": 9.468954248366014e-06,
      "loss": 0.1134,
      "step": 3218
    },
    {
      "epoch": 0.7396599264705882,
      "grad_norm": 1.3959547281265259,
      "learning_rate": 9.468443627450982e-06,
      "loss": 0.0775,
      "step": 3219
    },
    {
      "epoch": 0.7398897058823529,
      "grad_norm": 1.1217784881591797,
      "learning_rate": 9.467933006535948e-06,
      "loss": 0.0776,
      "step": 3220
    },
    {
      "epoch": 0.7401194852941176,
      "grad_norm": 0.7560930252075195,
      "learning_rate": 9.467422385620916e-06,
      "loss": 0.0368,
      "step": 3221
    },
    {
      "epoch": 0.7403492647058824,
      "grad_norm": 1.167989730834961,
      "learning_rate": 9.466911764705882e-06,
      "loss": 0.0655,
      "step": 3222
    },
    {
      "epoch": 0.7405790441176471,
      "grad_norm": 1.0237165689468384,
      "learning_rate": 9.46640114379085e-06,
      "loss": 0.0777,
      "step": 3223
    },
    {
      "epoch": 0.7408088235294118,
      "grad_norm": 1.0877666473388672,
      "learning_rate": 9.465890522875818e-06,
      "loss": 0.0924,
      "step": 3224
    },
    {
      "epoch": 0.7410386029411765,
      "grad_norm": 1.7171127796173096,
      "learning_rate": 9.465379901960784e-06,
      "loss": 0.1616,
      "step": 3225
    },
    {
      "epoch": 0.7412683823529411,
      "grad_norm": 1.147740125656128,
      "learning_rate": 9.464869281045752e-06,
      "loss": 0.099,
      "step": 3226
    },
    {
      "epoch": 0.7414981617647058,
      "grad_norm": 1.1230571269989014,
      "learning_rate": 9.46435866013072e-06,
      "loss": 0.0834,
      "step": 3227
    },
    {
      "epoch": 0.7417279411764706,
      "grad_norm": 1.0631914138793945,
      "learning_rate": 9.463848039215688e-06,
      "loss": 0.089,
      "step": 3228
    },
    {
      "epoch": 0.7419577205882353,
      "grad_norm": 1.135410189628601,
      "learning_rate": 9.463337418300654e-06,
      "loss": 0.093,
      "step": 3229
    },
    {
      "epoch": 0.7421875,
      "grad_norm": 1.388643741607666,
      "learning_rate": 9.462826797385622e-06,
      "loss": 0.1022,
      "step": 3230
    },
    {
      "epoch": 0.7424172794117647,
      "grad_norm": 0.919659435749054,
      "learning_rate": 9.46231617647059e-06,
      "loss": 0.0595,
      "step": 3231
    },
    {
      "epoch": 0.7426470588235294,
      "grad_norm": 1.2397080659866333,
      "learning_rate": 9.461805555555556e-06,
      "loss": 0.1014,
      "step": 3232
    },
    {
      "epoch": 0.7428768382352942,
      "grad_norm": 0.9673476219177246,
      "learning_rate": 9.461294934640524e-06,
      "loss": 0.0902,
      "step": 3233
    },
    {
      "epoch": 0.7431066176470589,
      "grad_norm": 0.9568983316421509,
      "learning_rate": 9.46078431372549e-06,
      "loss": 0.0844,
      "step": 3234
    },
    {
      "epoch": 0.7433363970588235,
      "grad_norm": 1.0264275074005127,
      "learning_rate": 9.46027369281046e-06,
      "loss": 0.0689,
      "step": 3235
    },
    {
      "epoch": 0.7435661764705882,
      "grad_norm": 0.9952107667922974,
      "learning_rate": 9.459763071895426e-06,
      "loss": 0.0619,
      "step": 3236
    },
    {
      "epoch": 0.7437959558823529,
      "grad_norm": 1.1473177671432495,
      "learning_rate": 9.459252450980394e-06,
      "loss": 0.0873,
      "step": 3237
    },
    {
      "epoch": 0.7440257352941176,
      "grad_norm": 0.9100866913795471,
      "learning_rate": 9.45874183006536e-06,
      "loss": 0.0881,
      "step": 3238
    },
    {
      "epoch": 0.7442555147058824,
      "grad_norm": 1.0263420343399048,
      "learning_rate": 9.458231209150328e-06,
      "loss": 0.0954,
      "step": 3239
    },
    {
      "epoch": 0.7444852941176471,
      "grad_norm": 1.1972532272338867,
      "learning_rate": 9.457720588235295e-06,
      "loss": 0.076,
      "step": 3240
    },
    {
      "epoch": 0.7447150735294118,
      "grad_norm": 0.8823140263557434,
      "learning_rate": 9.457209967320262e-06,
      "loss": 0.0703,
      "step": 3241
    },
    {
      "epoch": 0.7449448529411765,
      "grad_norm": 0.8894786834716797,
      "learning_rate": 9.45669934640523e-06,
      "loss": 0.0626,
      "step": 3242
    },
    {
      "epoch": 0.7451746323529411,
      "grad_norm": 1.1497195959091187,
      "learning_rate": 9.456188725490197e-06,
      "loss": 0.1308,
      "step": 3243
    },
    {
      "epoch": 0.7454044117647058,
      "grad_norm": 1.1333976984024048,
      "learning_rate": 9.455678104575165e-06,
      "loss": 0.069,
      "step": 3244
    },
    {
      "epoch": 0.7456341911764706,
      "grad_norm": 1.018038272857666,
      "learning_rate": 9.455167483660131e-06,
      "loss": 0.0658,
      "step": 3245
    },
    {
      "epoch": 0.7458639705882353,
      "grad_norm": 1.0417641401290894,
      "learning_rate": 9.4546568627451e-06,
      "loss": 0.0853,
      "step": 3246
    },
    {
      "epoch": 0.74609375,
      "grad_norm": 0.7949775457382202,
      "learning_rate": 9.454146241830067e-06,
      "loss": 0.0509,
      "step": 3247
    },
    {
      "epoch": 0.7463235294117647,
      "grad_norm": 0.7656347155570984,
      "learning_rate": 9.453635620915033e-06,
      "loss": 0.0564,
      "step": 3248
    },
    {
      "epoch": 0.7465533088235294,
      "grad_norm": 0.9123755097389221,
      "learning_rate": 9.453125000000001e-06,
      "loss": 0.0794,
      "step": 3249
    },
    {
      "epoch": 0.7467830882352942,
      "grad_norm": 0.8543519377708435,
      "learning_rate": 9.452614379084967e-06,
      "loss": 0.0735,
      "step": 3250
    },
    {
      "epoch": 0.7470128676470589,
      "grad_norm": 1.033419132232666,
      "learning_rate": 9.452103758169935e-06,
      "loss": 0.0843,
      "step": 3251
    },
    {
      "epoch": 0.7472426470588235,
      "grad_norm": 0.8620268106460571,
      "learning_rate": 9.451593137254903e-06,
      "loss": 0.0644,
      "step": 3252
    },
    {
      "epoch": 0.7474724264705882,
      "grad_norm": 0.898413360118866,
      "learning_rate": 9.45108251633987e-06,
      "loss": 0.073,
      "step": 3253
    },
    {
      "epoch": 0.7477022058823529,
      "grad_norm": 1.0957030057907104,
      "learning_rate": 9.450571895424837e-06,
      "loss": 0.0857,
      "step": 3254
    },
    {
      "epoch": 0.7479319852941176,
      "grad_norm": 0.8689482808113098,
      "learning_rate": 9.450061274509805e-06,
      "loss": 0.0918,
      "step": 3255
    },
    {
      "epoch": 0.7481617647058824,
      "grad_norm": 1.122085690498352,
      "learning_rate": 9.449550653594773e-06,
      "loss": 0.0615,
      "step": 3256
    },
    {
      "epoch": 0.7483915441176471,
      "grad_norm": 0.7549949884414673,
      "learning_rate": 9.449040032679739e-06,
      "loss": 0.0759,
      "step": 3257
    },
    {
      "epoch": 0.7486213235294118,
      "grad_norm": 1.0195002555847168,
      "learning_rate": 9.448529411764707e-06,
      "loss": 0.0813,
      "step": 3258
    },
    {
      "epoch": 0.7488511029411765,
      "grad_norm": 1.1659821271896362,
      "learning_rate": 9.448018790849673e-06,
      "loss": 0.0677,
      "step": 3259
    },
    {
      "epoch": 0.7490808823529411,
      "grad_norm": 1.3238028287887573,
      "learning_rate": 9.44750816993464e-06,
      "loss": 0.0991,
      "step": 3260
    },
    {
      "epoch": 0.7493106617647058,
      "grad_norm": 0.9862850904464722,
      "learning_rate": 9.446997549019609e-06,
      "loss": 0.0728,
      "step": 3261
    },
    {
      "epoch": 0.7495404411764706,
      "grad_norm": 0.8411972522735596,
      "learning_rate": 9.446486928104577e-06,
      "loss": 0.0927,
      "step": 3262
    },
    {
      "epoch": 0.7497702205882353,
      "grad_norm": 0.8792616724967957,
      "learning_rate": 9.445976307189543e-06,
      "loss": 0.0802,
      "step": 3263
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.53432035446167,
      "learning_rate": 9.44546568627451e-06,
      "loss": 0.1195,
      "step": 3264
    },
    {
      "epoch": 0.7502297794117647,
      "grad_norm": 0.8752039074897766,
      "learning_rate": 9.444955065359478e-06,
      "loss": 0.0601,
      "step": 3265
    },
    {
      "epoch": 0.7504595588235294,
      "grad_norm": 1.3335634469985962,
      "learning_rate": 9.444444444444445e-06,
      "loss": 0.0742,
      "step": 3266
    },
    {
      "epoch": 0.7506893382352942,
      "grad_norm": 1.324520468711853,
      "learning_rate": 9.443933823529412e-06,
      "loss": 0.1257,
      "step": 3267
    },
    {
      "epoch": 0.7509191176470589,
      "grad_norm": 0.7571446895599365,
      "learning_rate": 9.44342320261438e-06,
      "loss": 0.062,
      "step": 3268
    },
    {
      "epoch": 0.7511488970588235,
      "grad_norm": 1.2539170980453491,
      "learning_rate": 9.442912581699346e-06,
      "loss": 0.0996,
      "step": 3269
    },
    {
      "epoch": 0.7513786764705882,
      "grad_norm": 1.1974326372146606,
      "learning_rate": 9.442401960784314e-06,
      "loss": 0.0762,
      "step": 3270
    },
    {
      "epoch": 0.7516084558823529,
      "grad_norm": 1.1212915182113647,
      "learning_rate": 9.44189133986928e-06,
      "loss": 0.11,
      "step": 3271
    },
    {
      "epoch": 0.7518382352941176,
      "grad_norm": 1.0423758029937744,
      "learning_rate": 9.44138071895425e-06,
      "loss": 0.0762,
      "step": 3272
    },
    {
      "epoch": 0.7520680147058824,
      "grad_norm": 1.1378071308135986,
      "learning_rate": 9.440870098039216e-06,
      "loss": 0.062,
      "step": 3273
    },
    {
      "epoch": 0.7522977941176471,
      "grad_norm": 1.2990750074386597,
      "learning_rate": 9.440359477124184e-06,
      "loss": 0.0809,
      "step": 3274
    },
    {
      "epoch": 0.7525275735294118,
      "grad_norm": 0.7997835874557495,
      "learning_rate": 9.43984885620915e-06,
      "loss": 0.0742,
      "step": 3275
    },
    {
      "epoch": 0.7527573529411765,
      "grad_norm": 0.8051013350486755,
      "learning_rate": 9.439338235294118e-06,
      "loss": 0.0491,
      "step": 3276
    },
    {
      "epoch": 0.7529871323529411,
      "grad_norm": 1.3212212324142456,
      "learning_rate": 9.438827614379086e-06,
      "loss": 0.0855,
      "step": 3277
    },
    {
      "epoch": 0.7532169117647058,
      "grad_norm": 1.4026920795440674,
      "learning_rate": 9.438316993464052e-06,
      "loss": 0.092,
      "step": 3278
    },
    {
      "epoch": 0.7534466911764706,
      "grad_norm": 1.1813377141952515,
      "learning_rate": 9.43780637254902e-06,
      "loss": 0.1303,
      "step": 3279
    },
    {
      "epoch": 0.7536764705882353,
      "grad_norm": 0.8673369288444519,
      "learning_rate": 9.437295751633988e-06,
      "loss": 0.068,
      "step": 3280
    },
    {
      "epoch": 0.75390625,
      "grad_norm": 1.0495474338531494,
      "learning_rate": 9.436785130718956e-06,
      "loss": 0.0765,
      "step": 3281
    },
    {
      "epoch": 0.7541360294117647,
      "grad_norm": 0.9808741807937622,
      "learning_rate": 9.436274509803922e-06,
      "loss": 0.0718,
      "step": 3282
    },
    {
      "epoch": 0.7543658088235294,
      "grad_norm": 1.0249143838882446,
      "learning_rate": 9.43576388888889e-06,
      "loss": 0.1036,
      "step": 3283
    },
    {
      "epoch": 0.7545955882352942,
      "grad_norm": 0.8956131339073181,
      "learning_rate": 9.435253267973858e-06,
      "loss": 0.0603,
      "step": 3284
    },
    {
      "epoch": 0.7548253676470589,
      "grad_norm": 1.1854517459869385,
      "learning_rate": 9.434742647058824e-06,
      "loss": 0.075,
      "step": 3285
    },
    {
      "epoch": 0.7550551470588235,
      "grad_norm": 1.0082545280456543,
      "learning_rate": 9.434232026143792e-06,
      "loss": 0.0688,
      "step": 3286
    },
    {
      "epoch": 0.7552849264705882,
      "grad_norm": 1.2959425449371338,
      "learning_rate": 9.433721405228758e-06,
      "loss": 0.0952,
      "step": 3287
    },
    {
      "epoch": 0.7555147058823529,
      "grad_norm": 1.1403635740280151,
      "learning_rate": 9.433210784313727e-06,
      "loss": 0.0779,
      "step": 3288
    },
    {
      "epoch": 0.7557444852941176,
      "grad_norm": 1.1101856231689453,
      "learning_rate": 9.432700163398694e-06,
      "loss": 0.1171,
      "step": 3289
    },
    {
      "epoch": 0.7559742647058824,
      "grad_norm": 1.1593163013458252,
      "learning_rate": 9.432189542483661e-06,
      "loss": 0.083,
      "step": 3290
    },
    {
      "epoch": 0.7562040441176471,
      "grad_norm": 1.2416396141052246,
      "learning_rate": 9.431678921568628e-06,
      "loss": 0.0948,
      "step": 3291
    },
    {
      "epoch": 0.7564338235294118,
      "grad_norm": 1.0411666631698608,
      "learning_rate": 9.431168300653595e-06,
      "loss": 0.12,
      "step": 3292
    },
    {
      "epoch": 0.7566636029411765,
      "grad_norm": 0.9574170112609863,
      "learning_rate": 9.430657679738563e-06,
      "loss": 0.0677,
      "step": 3293
    },
    {
      "epoch": 0.7568933823529411,
      "grad_norm": 0.9414641261100769,
      "learning_rate": 9.43014705882353e-06,
      "loss": 0.086,
      "step": 3294
    },
    {
      "epoch": 0.7571231617647058,
      "grad_norm": 1.1610527038574219,
      "learning_rate": 9.429636437908497e-06,
      "loss": 0.09,
      "step": 3295
    },
    {
      "epoch": 0.7573529411764706,
      "grad_norm": 0.9471791386604309,
      "learning_rate": 9.429125816993465e-06,
      "loss": 0.0569,
      "step": 3296
    },
    {
      "epoch": 0.7575827205882353,
      "grad_norm": 0.9203668832778931,
      "learning_rate": 9.428615196078433e-06,
      "loss": 0.057,
      "step": 3297
    },
    {
      "epoch": 0.7578125,
      "grad_norm": 0.7756357789039612,
      "learning_rate": 9.4281045751634e-06,
      "loss": 0.0389,
      "step": 3298
    },
    {
      "epoch": 0.7580422794117647,
      "grad_norm": 1.2104002237319946,
      "learning_rate": 9.427593954248367e-06,
      "loss": 0.1061,
      "step": 3299
    },
    {
      "epoch": 0.7582720588235294,
      "grad_norm": 0.7345750331878662,
      "learning_rate": 9.427083333333335e-06,
      "loss": 0.0425,
      "step": 3300
    },
    {
      "epoch": 0.7585018382352942,
      "grad_norm": 1.3647595643997192,
      "learning_rate": 9.426572712418301e-06,
      "loss": 0.0998,
      "step": 3301
    },
    {
      "epoch": 0.7587316176470589,
      "grad_norm": 1.1622169017791748,
      "learning_rate": 9.426062091503269e-06,
      "loss": 0.1035,
      "step": 3302
    },
    {
      "epoch": 0.7589613970588235,
      "grad_norm": 1.123556137084961,
      "learning_rate": 9.425551470588235e-06,
      "loss": 0.0669,
      "step": 3303
    },
    {
      "epoch": 0.7591911764705882,
      "grad_norm": 0.7867927551269531,
      "learning_rate": 9.425040849673203e-06,
      "loss": 0.0597,
      "step": 3304
    },
    {
      "epoch": 0.7594209558823529,
      "grad_norm": 0.808800220489502,
      "learning_rate": 9.42453022875817e-06,
      "loss": 0.0591,
      "step": 3305
    },
    {
      "epoch": 0.7596507352941176,
      "grad_norm": 0.9506106972694397,
      "learning_rate": 9.424019607843139e-06,
      "loss": 0.0897,
      "step": 3306
    },
    {
      "epoch": 0.7598805147058824,
      "grad_norm": 1.1734514236450195,
      "learning_rate": 9.423508986928105e-06,
      "loss": 0.0634,
      "step": 3307
    },
    {
      "epoch": 0.7601102941176471,
      "grad_norm": 0.9932358264923096,
      "learning_rate": 9.422998366013073e-06,
      "loss": 0.088,
      "step": 3308
    },
    {
      "epoch": 0.7603400735294118,
      "grad_norm": 0.8061588406562805,
      "learning_rate": 9.42248774509804e-06,
      "loss": 0.0611,
      "step": 3309
    },
    {
      "epoch": 0.7605698529411765,
      "grad_norm": 1.3161309957504272,
      "learning_rate": 9.421977124183007e-06,
      "loss": 0.0979,
      "step": 3310
    },
    {
      "epoch": 0.7607996323529411,
      "grad_norm": 1.0345255136489868,
      "learning_rate": 9.421466503267975e-06,
      "loss": 0.0814,
      "step": 3311
    },
    {
      "epoch": 0.7610294117647058,
      "grad_norm": 1.3679624795913696,
      "learning_rate": 9.420955882352942e-06,
      "loss": 0.1064,
      "step": 3312
    },
    {
      "epoch": 0.7612591911764706,
      "grad_norm": 0.902489960193634,
      "learning_rate": 9.420445261437909e-06,
      "loss": 0.0643,
      "step": 3313
    },
    {
      "epoch": 0.7614889705882353,
      "grad_norm": 1.1705204248428345,
      "learning_rate": 9.419934640522876e-06,
      "loss": 0.1013,
      "step": 3314
    },
    {
      "epoch": 0.76171875,
      "grad_norm": 1.1642416715621948,
      "learning_rate": 9.419424019607843e-06,
      "loss": 0.1205,
      "step": 3315
    },
    {
      "epoch": 0.7619485294117647,
      "grad_norm": 0.6924605369567871,
      "learning_rate": 9.418913398692812e-06,
      "loss": 0.0571,
      "step": 3316
    },
    {
      "epoch": 0.7621783088235294,
      "grad_norm": 1.2786329984664917,
      "learning_rate": 9.418402777777778e-06,
      "loss": 0.086,
      "step": 3317
    },
    {
      "epoch": 0.7624080882352942,
      "grad_norm": 0.835015594959259,
      "learning_rate": 9.417892156862746e-06,
      "loss": 0.0527,
      "step": 3318
    },
    {
      "epoch": 0.7626378676470589,
      "grad_norm": 0.9521813988685608,
      "learning_rate": 9.417381535947712e-06,
      "loss": 0.0567,
      "step": 3319
    },
    {
      "epoch": 0.7628676470588235,
      "grad_norm": 1.2377731800079346,
      "learning_rate": 9.41687091503268e-06,
      "loss": 0.0695,
      "step": 3320
    },
    {
      "epoch": 0.7630974264705882,
      "grad_norm": 1.8215969800949097,
      "learning_rate": 9.416360294117648e-06,
      "loss": 0.1474,
      "step": 3321
    },
    {
      "epoch": 0.7633272058823529,
      "grad_norm": 1.1547287702560425,
      "learning_rate": 9.415849673202614e-06,
      "loss": 0.0797,
      "step": 3322
    },
    {
      "epoch": 0.7635569852941176,
      "grad_norm": 1.1843352317810059,
      "learning_rate": 9.415339052287582e-06,
      "loss": 0.09,
      "step": 3323
    },
    {
      "epoch": 0.7637867647058824,
      "grad_norm": 0.9076696038246155,
      "learning_rate": 9.41482843137255e-06,
      "loss": 0.0888,
      "step": 3324
    },
    {
      "epoch": 0.7640165441176471,
      "grad_norm": 1.0574755668640137,
      "learning_rate": 9.414317810457518e-06,
      "loss": 0.109,
      "step": 3325
    },
    {
      "epoch": 0.7642463235294118,
      "grad_norm": 1.5371999740600586,
      "learning_rate": 9.413807189542484e-06,
      "loss": 0.1357,
      "step": 3326
    },
    {
      "epoch": 0.7644761029411765,
      "grad_norm": 0.9230104088783264,
      "learning_rate": 9.413296568627452e-06,
      "loss": 0.0902,
      "step": 3327
    },
    {
      "epoch": 0.7647058823529411,
      "grad_norm": 1.0572028160095215,
      "learning_rate": 9.41278594771242e-06,
      "loss": 0.0825,
      "step": 3328
    },
    {
      "epoch": 0.7649356617647058,
      "grad_norm": 0.9850835800170898,
      "learning_rate": 9.412275326797386e-06,
      "loss": 0.0727,
      "step": 3329
    },
    {
      "epoch": 0.7651654411764706,
      "grad_norm": 1.105934977531433,
      "learning_rate": 9.411764705882354e-06,
      "loss": 0.0798,
      "step": 3330
    },
    {
      "epoch": 0.7653952205882353,
      "grad_norm": 0.979012131690979,
      "learning_rate": 9.41125408496732e-06,
      "loss": 0.0498,
      "step": 3331
    },
    {
      "epoch": 0.765625,
      "grad_norm": 1.2098333835601807,
      "learning_rate": 9.41074346405229e-06,
      "loss": 0.0979,
      "step": 3332
    },
    {
      "epoch": 0.7658547794117647,
      "grad_norm": 0.9179118275642395,
      "learning_rate": 9.410232843137256e-06,
      "loss": 0.088,
      "step": 3333
    },
    {
      "epoch": 0.7660845588235294,
      "grad_norm": 0.9382418990135193,
      "learning_rate": 9.409722222222224e-06,
      "loss": 0.0767,
      "step": 3334
    },
    {
      "epoch": 0.7663143382352942,
      "grad_norm": 1.2833592891693115,
      "learning_rate": 9.40921160130719e-06,
      "loss": 0.1142,
      "step": 3335
    },
    {
      "epoch": 0.7665441176470589,
      "grad_norm": 1.1247978210449219,
      "learning_rate": 9.408700980392158e-06,
      "loss": 0.1004,
      "step": 3336
    },
    {
      "epoch": 0.7667738970588235,
      "grad_norm": 0.8362228870391846,
      "learning_rate": 9.408190359477125e-06,
      "loss": 0.0537,
      "step": 3337
    },
    {
      "epoch": 0.7670036764705882,
      "grad_norm": 1.195475459098816,
      "learning_rate": 9.407679738562092e-06,
      "loss": 0.0969,
      "step": 3338
    },
    {
      "epoch": 0.7672334558823529,
      "grad_norm": 0.8525652885437012,
      "learning_rate": 9.40716911764706e-06,
      "loss": 0.0577,
      "step": 3339
    },
    {
      "epoch": 0.7674632352941176,
      "grad_norm": 0.7988907694816589,
      "learning_rate": 9.406658496732027e-06,
      "loss": 0.0592,
      "step": 3340
    },
    {
      "epoch": 0.7676930147058824,
      "grad_norm": 1.136940598487854,
      "learning_rate": 9.406147875816995e-06,
      "loss": 0.1083,
      "step": 3341
    },
    {
      "epoch": 0.7679227941176471,
      "grad_norm": 0.6778379678726196,
      "learning_rate": 9.405637254901961e-06,
      "loss": 0.053,
      "step": 3342
    },
    {
      "epoch": 0.7681525735294118,
      "grad_norm": 1.2092853784561157,
      "learning_rate": 9.40512663398693e-06,
      "loss": 0.0919,
      "step": 3343
    },
    {
      "epoch": 0.7683823529411765,
      "grad_norm": 0.8329954147338867,
      "learning_rate": 9.404616013071897e-06,
      "loss": 0.05,
      "step": 3344
    },
    {
      "epoch": 0.7686121323529411,
      "grad_norm": 1.1613962650299072,
      "learning_rate": 9.404105392156863e-06,
      "loss": 0.0862,
      "step": 3345
    },
    {
      "epoch": 0.7688419117647058,
      "grad_norm": 0.7375219464302063,
      "learning_rate": 9.403594771241831e-06,
      "loss": 0.0624,
      "step": 3346
    },
    {
      "epoch": 0.7690716911764706,
      "grad_norm": 0.7753438353538513,
      "learning_rate": 9.403084150326797e-06,
      "loss": 0.0456,
      "step": 3347
    },
    {
      "epoch": 0.7693014705882353,
      "grad_norm": 1.2793824672698975,
      "learning_rate": 9.402573529411765e-06,
      "loss": 0.1068,
      "step": 3348
    },
    {
      "epoch": 0.76953125,
      "grad_norm": 1.19016432762146,
      "learning_rate": 9.402062908496733e-06,
      "loss": 0.0762,
      "step": 3349
    },
    {
      "epoch": 0.7697610294117647,
      "grad_norm": 0.7591624855995178,
      "learning_rate": 9.4015522875817e-06,
      "loss": 0.0588,
      "step": 3350
    },
    {
      "epoch": 0.7699908088235294,
      "grad_norm": 0.9940875172615051,
      "learning_rate": 9.401041666666667e-06,
      "loss": 0.0642,
      "step": 3351
    },
    {
      "epoch": 0.7702205882352942,
      "grad_norm": 1.6083449125289917,
      "learning_rate": 9.400531045751635e-06,
      "loss": 0.0882,
      "step": 3352
    },
    {
      "epoch": 0.7704503676470589,
      "grad_norm": 0.9296338558197021,
      "learning_rate": 9.400020424836603e-06,
      "loss": 0.0697,
      "step": 3353
    },
    {
      "epoch": 0.7706801470588235,
      "grad_norm": 1.2635000944137573,
      "learning_rate": 9.399509803921569e-06,
      "loss": 0.0873,
      "step": 3354
    },
    {
      "epoch": 0.7709099264705882,
      "grad_norm": 0.7455285787582397,
      "learning_rate": 9.398999183006537e-06,
      "loss": 0.073,
      "step": 3355
    },
    {
      "epoch": 0.7711397058823529,
      "grad_norm": 1.0243713855743408,
      "learning_rate": 9.398488562091505e-06,
      "loss": 0.081,
      "step": 3356
    },
    {
      "epoch": 0.7713694852941176,
      "grad_norm": 1.0687230825424194,
      "learning_rate": 9.39797794117647e-06,
      "loss": 0.0911,
      "step": 3357
    },
    {
      "epoch": 0.7715992647058824,
      "grad_norm": 1.074097752571106,
      "learning_rate": 9.397467320261439e-06,
      "loss": 0.0834,
      "step": 3358
    },
    {
      "epoch": 0.7718290441176471,
      "grad_norm": 0.9703729748725891,
      "learning_rate": 9.396956699346405e-06,
      "loss": 0.0811,
      "step": 3359
    },
    {
      "epoch": 0.7720588235294118,
      "grad_norm": 1.3196765184402466,
      "learning_rate": 9.396446078431374e-06,
      "loss": 0.1115,
      "step": 3360
    },
    {
      "epoch": 0.7722886029411765,
      "grad_norm": 0.9783565402030945,
      "learning_rate": 9.39593545751634e-06,
      "loss": 0.0691,
      "step": 3361
    },
    {
      "epoch": 0.7725183823529411,
      "grad_norm": 1.3019132614135742,
      "learning_rate": 9.395424836601308e-06,
      "loss": 0.0832,
      "step": 3362
    },
    {
      "epoch": 0.7727481617647058,
      "grad_norm": 1.4493324756622314,
      "learning_rate": 9.394914215686275e-06,
      "loss": 0.082,
      "step": 3363
    },
    {
      "epoch": 0.7729779411764706,
      "grad_norm": 1.0802844762802124,
      "learning_rate": 9.394403594771242e-06,
      "loss": 0.0552,
      "step": 3364
    },
    {
      "epoch": 0.7732077205882353,
      "grad_norm": 1.0934962034225464,
      "learning_rate": 9.39389297385621e-06,
      "loss": 0.0656,
      "step": 3365
    },
    {
      "epoch": 0.7734375,
      "grad_norm": 1.3608911037445068,
      "learning_rate": 9.393382352941176e-06,
      "loss": 0.1093,
      "step": 3366
    },
    {
      "epoch": 0.7736672794117647,
      "grad_norm": 1.09270441532135,
      "learning_rate": 9.392871732026144e-06,
      "loss": 0.0727,
      "step": 3367
    },
    {
      "epoch": 0.7738970588235294,
      "grad_norm": 1.61152982711792,
      "learning_rate": 9.392361111111112e-06,
      "loss": 0.1125,
      "step": 3368
    },
    {
      "epoch": 0.7741268382352942,
      "grad_norm": 1.16237211227417,
      "learning_rate": 9.39185049019608e-06,
      "loss": 0.0607,
      "step": 3369
    },
    {
      "epoch": 0.7743566176470589,
      "grad_norm": 1.2277597188949585,
      "learning_rate": 9.391339869281046e-06,
      "loss": 0.068,
      "step": 3370
    },
    {
      "epoch": 0.7745863970588235,
      "grad_norm": 0.8067463040351868,
      "learning_rate": 9.390829248366014e-06,
      "loss": 0.0377,
      "step": 3371
    },
    {
      "epoch": 0.7748161764705882,
      "grad_norm": 1.1625232696533203,
      "learning_rate": 9.390318627450982e-06,
      "loss": 0.1218,
      "step": 3372
    },
    {
      "epoch": 0.7750459558823529,
      "grad_norm": 1.0529543161392212,
      "learning_rate": 9.389808006535948e-06,
      "loss": 0.0863,
      "step": 3373
    },
    {
      "epoch": 0.7752757352941176,
      "grad_norm": 0.9287682771682739,
      "learning_rate": 9.389297385620916e-06,
      "loss": 0.0582,
      "step": 3374
    },
    {
      "epoch": 0.7755055147058824,
      "grad_norm": 0.964120090007782,
      "learning_rate": 9.388786764705882e-06,
      "loss": 0.0827,
      "step": 3375
    },
    {
      "epoch": 0.7757352941176471,
      "grad_norm": 1.3475744724273682,
      "learning_rate": 9.388276143790852e-06,
      "loss": 0.0981,
      "step": 3376
    },
    {
      "epoch": 0.7759650735294118,
      "grad_norm": 1.2444872856140137,
      "learning_rate": 9.387765522875818e-06,
      "loss": 0.1138,
      "step": 3377
    },
    {
      "epoch": 0.7761948529411765,
      "grad_norm": 0.9926382899284363,
      "learning_rate": 9.387254901960786e-06,
      "loss": 0.0751,
      "step": 3378
    },
    {
      "epoch": 0.7764246323529411,
      "grad_norm": 1.3119207620620728,
      "learning_rate": 9.386744281045752e-06,
      "loss": 0.086,
      "step": 3379
    },
    {
      "epoch": 0.7766544117647058,
      "grad_norm": 0.9444207549095154,
      "learning_rate": 9.38623366013072e-06,
      "loss": 0.0952,
      "step": 3380
    },
    {
      "epoch": 0.7768841911764706,
      "grad_norm": 1.1204636096954346,
      "learning_rate": 9.385723039215688e-06,
      "loss": 0.0803,
      "step": 3381
    },
    {
      "epoch": 0.7771139705882353,
      "grad_norm": 0.913533627986908,
      "learning_rate": 9.385212418300654e-06,
      "loss": 0.068,
      "step": 3382
    },
    {
      "epoch": 0.77734375,
      "grad_norm": 1.0289040803909302,
      "learning_rate": 9.384701797385622e-06,
      "loss": 0.0823,
      "step": 3383
    },
    {
      "epoch": 0.7775735294117647,
      "grad_norm": 1.1622366905212402,
      "learning_rate": 9.38419117647059e-06,
      "loss": 0.0846,
      "step": 3384
    },
    {
      "epoch": 0.7778033088235294,
      "grad_norm": 0.8439160585403442,
      "learning_rate": 9.383680555555557e-06,
      "loss": 0.0761,
      "step": 3385
    },
    {
      "epoch": 0.7780330882352942,
      "grad_norm": 0.8546562790870667,
      "learning_rate": 9.383169934640524e-06,
      "loss": 0.0757,
      "step": 3386
    },
    {
      "epoch": 0.7782628676470589,
      "grad_norm": 0.9927564263343811,
      "learning_rate": 9.382659313725491e-06,
      "loss": 0.0723,
      "step": 3387
    },
    {
      "epoch": 0.7784926470588235,
      "grad_norm": 1.0130418539047241,
      "learning_rate": 9.38214869281046e-06,
      "loss": 0.059,
      "step": 3388
    },
    {
      "epoch": 0.7787224264705882,
      "grad_norm": 1.7913844585418701,
      "learning_rate": 9.381638071895425e-06,
      "loss": 0.1392,
      "step": 3389
    },
    {
      "epoch": 0.7789522058823529,
      "grad_norm": 0.8844748139381409,
      "learning_rate": 9.381127450980393e-06,
      "loss": 0.0768,
      "step": 3390
    },
    {
      "epoch": 0.7791819852941176,
      "grad_norm": 1.1624093055725098,
      "learning_rate": 9.38061683006536e-06,
      "loss": 0.0668,
      "step": 3391
    },
    {
      "epoch": 0.7794117647058824,
      "grad_norm": 1.2903780937194824,
      "learning_rate": 9.380106209150327e-06,
      "loss": 0.1084,
      "step": 3392
    },
    {
      "epoch": 0.7796415441176471,
      "grad_norm": 1.3268731832504272,
      "learning_rate": 9.379595588235295e-06,
      "loss": 0.0959,
      "step": 3393
    },
    {
      "epoch": 0.7798713235294118,
      "grad_norm": 1.1007540225982666,
      "learning_rate": 9.379084967320261e-06,
      "loss": 0.0931,
      "step": 3394
    },
    {
      "epoch": 0.7801011029411765,
      "grad_norm": 1.0092713832855225,
      "learning_rate": 9.37857434640523e-06,
      "loss": 0.0949,
      "step": 3395
    },
    {
      "epoch": 0.7803308823529411,
      "grad_norm": 0.8894822597503662,
      "learning_rate": 9.378063725490197e-06,
      "loss": 0.0778,
      "step": 3396
    },
    {
      "epoch": 0.7805606617647058,
      "grad_norm": 1.186705231666565,
      "learning_rate": 9.377553104575165e-06,
      "loss": 0.0754,
      "step": 3397
    },
    {
      "epoch": 0.7807904411764706,
      "grad_norm": 0.932345986366272,
      "learning_rate": 9.377042483660131e-06,
      "loss": 0.0897,
      "step": 3398
    },
    {
      "epoch": 0.7810202205882353,
      "grad_norm": 1.253801703453064,
      "learning_rate": 9.376531862745099e-06,
      "loss": 0.0933,
      "step": 3399
    },
    {
      "epoch": 0.78125,
      "grad_norm": 1.1812891960144043,
      "learning_rate": 9.376021241830067e-06,
      "loss": 0.0777,
      "step": 3400
    },
    {
      "epoch": 0.7814797794117647,
      "grad_norm": 1.124435305595398,
      "learning_rate": 9.375510620915033e-06,
      "loss": 0.0546,
      "step": 3401
    },
    {
      "epoch": 0.7817095588235294,
      "grad_norm": 1.0346988439559937,
      "learning_rate": 9.375000000000001e-06,
      "loss": 0.0883,
      "step": 3402
    },
    {
      "epoch": 0.7819393382352942,
      "grad_norm": 0.9617751836776733,
      "learning_rate": 9.374489379084967e-06,
      "loss": 0.0641,
      "step": 3403
    },
    {
      "epoch": 0.7821691176470589,
      "grad_norm": 1.0125075578689575,
      "learning_rate": 9.373978758169935e-06,
      "loss": 0.0654,
      "step": 3404
    },
    {
      "epoch": 0.7823988970588235,
      "grad_norm": 0.9322535991668701,
      "learning_rate": 9.373468137254903e-06,
      "loss": 0.056,
      "step": 3405
    },
    {
      "epoch": 0.7826286764705882,
      "grad_norm": 0.948286235332489,
      "learning_rate": 9.37295751633987e-06,
      "loss": 0.0795,
      "step": 3406
    },
    {
      "epoch": 0.7828584558823529,
      "grad_norm": 0.9453433752059937,
      "learning_rate": 9.372446895424837e-06,
      "loss": 0.0418,
      "step": 3407
    },
    {
      "epoch": 0.7830882352941176,
      "grad_norm": 0.9778672456741333,
      "learning_rate": 9.371936274509805e-06,
      "loss": 0.0795,
      "step": 3408
    },
    {
      "epoch": 0.7833180147058824,
      "grad_norm": 1.173928141593933,
      "learning_rate": 9.371425653594773e-06,
      "loss": 0.0932,
      "step": 3409
    },
    {
      "epoch": 0.7835477941176471,
      "grad_norm": 0.8177125453948975,
      "learning_rate": 9.370915032679739e-06,
      "loss": 0.0607,
      "step": 3410
    },
    {
      "epoch": 0.7837775735294118,
      "grad_norm": 1.108384132385254,
      "learning_rate": 9.370404411764707e-06,
      "loss": 0.0878,
      "step": 3411
    },
    {
      "epoch": 0.7840073529411765,
      "grad_norm": 1.1295630931854248,
      "learning_rate": 9.369893790849673e-06,
      "loss": 0.1183,
      "step": 3412
    },
    {
      "epoch": 0.7842371323529411,
      "grad_norm": 0.9748058319091797,
      "learning_rate": 9.369383169934642e-06,
      "loss": 0.069,
      "step": 3413
    },
    {
      "epoch": 0.7844669117647058,
      "grad_norm": 1.0898538827896118,
      "learning_rate": 9.368872549019608e-06,
      "loss": 0.0829,
      "step": 3414
    },
    {
      "epoch": 0.7846966911764706,
      "grad_norm": 1.4324111938476562,
      "learning_rate": 9.368361928104576e-06,
      "loss": 0.125,
      "step": 3415
    },
    {
      "epoch": 0.7849264705882353,
      "grad_norm": 1.1206345558166504,
      "learning_rate": 9.367851307189542e-06,
      "loss": 0.0826,
      "step": 3416
    },
    {
      "epoch": 0.78515625,
      "grad_norm": 0.8099938631057739,
      "learning_rate": 9.36734068627451e-06,
      "loss": 0.0774,
      "step": 3417
    },
    {
      "epoch": 0.7853860294117647,
      "grad_norm": 1.0500260591506958,
      "learning_rate": 9.366830065359478e-06,
      "loss": 0.078,
      "step": 3418
    },
    {
      "epoch": 0.7856158088235294,
      "grad_norm": 1.0032790899276733,
      "learning_rate": 9.366319444444444e-06,
      "loss": 0.0912,
      "step": 3419
    },
    {
      "epoch": 0.7858455882352942,
      "grad_norm": 1.7179397344589233,
      "learning_rate": 9.365808823529412e-06,
      "loss": 0.0792,
      "step": 3420
    },
    {
      "epoch": 0.7860753676470589,
      "grad_norm": 1.1540998220443726,
      "learning_rate": 9.36529820261438e-06,
      "loss": 0.0749,
      "step": 3421
    },
    {
      "epoch": 0.7863051470588235,
      "grad_norm": 0.8023529052734375,
      "learning_rate": 9.364787581699348e-06,
      "loss": 0.0665,
      "step": 3422
    },
    {
      "epoch": 0.7865349264705882,
      "grad_norm": 1.0528888702392578,
      "learning_rate": 9.364276960784314e-06,
      "loss": 0.0744,
      "step": 3423
    },
    {
      "epoch": 0.7867647058823529,
      "grad_norm": 1.1298964023590088,
      "learning_rate": 9.363766339869282e-06,
      "loss": 0.0801,
      "step": 3424
    },
    {
      "epoch": 0.7869944852941176,
      "grad_norm": 1.4666742086410522,
      "learning_rate": 9.36325571895425e-06,
      "loss": 0.0527,
      "step": 3425
    },
    {
      "epoch": 0.7872242647058824,
      "grad_norm": 1.2230037450790405,
      "learning_rate": 9.362745098039216e-06,
      "loss": 0.0827,
      "step": 3426
    },
    {
      "epoch": 0.7874540441176471,
      "grad_norm": 1.4638593196868896,
      "learning_rate": 9.362234477124184e-06,
      "loss": 0.1334,
      "step": 3427
    },
    {
      "epoch": 0.7876838235294118,
      "grad_norm": 0.939838171005249,
      "learning_rate": 9.36172385620915e-06,
      "loss": 0.0617,
      "step": 3428
    },
    {
      "epoch": 0.7879136029411765,
      "grad_norm": 0.7143656611442566,
      "learning_rate": 9.36121323529412e-06,
      "loss": 0.0432,
      "step": 3429
    },
    {
      "epoch": 0.7881433823529411,
      "grad_norm": 0.798666775226593,
      "learning_rate": 9.360702614379086e-06,
      "loss": 0.0567,
      "step": 3430
    },
    {
      "epoch": 0.7883731617647058,
      "grad_norm": 1.3470983505249023,
      "learning_rate": 9.360191993464054e-06,
      "loss": 0.0846,
      "step": 3431
    },
    {
      "epoch": 0.7886029411764706,
      "grad_norm": 1.0203708410263062,
      "learning_rate": 9.35968137254902e-06,
      "loss": 0.0684,
      "step": 3432
    },
    {
      "epoch": 0.7888327205882353,
      "grad_norm": 1.2753862142562866,
      "learning_rate": 9.359170751633988e-06,
      "loss": 0.1136,
      "step": 3433
    },
    {
      "epoch": 0.7890625,
      "grad_norm": 0.8682037591934204,
      "learning_rate": 9.358660130718955e-06,
      "loss": 0.0622,
      "step": 3434
    },
    {
      "epoch": 0.7892922794117647,
      "grad_norm": 1.1928054094314575,
      "learning_rate": 9.358149509803922e-06,
      "loss": 0.0833,
      "step": 3435
    },
    {
      "epoch": 0.7895220588235294,
      "grad_norm": 1.0007874965667725,
      "learning_rate": 9.35763888888889e-06,
      "loss": 0.0829,
      "step": 3436
    },
    {
      "epoch": 0.7897518382352942,
      "grad_norm": 1.3171664476394653,
      "learning_rate": 9.357128267973857e-06,
      "loss": 0.0862,
      "step": 3437
    },
    {
      "epoch": 0.7899816176470589,
      "grad_norm": 1.13900625705719,
      "learning_rate": 9.356617647058824e-06,
      "loss": 0.1017,
      "step": 3438
    },
    {
      "epoch": 0.7902113970588235,
      "grad_norm": 1.5068817138671875,
      "learning_rate": 9.356107026143791e-06,
      "loss": 0.0717,
      "step": 3439
    },
    {
      "epoch": 0.7904411764705882,
      "grad_norm": 0.6747533082962036,
      "learning_rate": 9.35559640522876e-06,
      "loss": 0.0416,
      "step": 3440
    },
    {
      "epoch": 0.7906709558823529,
      "grad_norm": 0.748415470123291,
      "learning_rate": 9.355085784313727e-06,
      "loss": 0.0697,
      "step": 3441
    },
    {
      "epoch": 0.7909007352941176,
      "grad_norm": 1.0238977670669556,
      "learning_rate": 9.354575163398693e-06,
      "loss": 0.0681,
      "step": 3442
    },
    {
      "epoch": 0.7911305147058824,
      "grad_norm": 1.1206549406051636,
      "learning_rate": 9.354064542483661e-06,
      "loss": 0.0786,
      "step": 3443
    },
    {
      "epoch": 0.7913602941176471,
      "grad_norm": 0.9175742268562317,
      "learning_rate": 9.353553921568627e-06,
      "loss": 0.0708,
      "step": 3444
    },
    {
      "epoch": 0.7915900735294118,
      "grad_norm": 1.1037060022354126,
      "learning_rate": 9.353043300653595e-06,
      "loss": 0.0807,
      "step": 3445
    },
    {
      "epoch": 0.7918198529411765,
      "grad_norm": 0.8893880844116211,
      "learning_rate": 9.352532679738563e-06,
      "loss": 0.0643,
      "step": 3446
    },
    {
      "epoch": 0.7920496323529411,
      "grad_norm": 1.089389681816101,
      "learning_rate": 9.35202205882353e-06,
      "loss": 0.0886,
      "step": 3447
    },
    {
      "epoch": 0.7922794117647058,
      "grad_norm": 1.489626169204712,
      "learning_rate": 9.351511437908497e-06,
      "loss": 0.1023,
      "step": 3448
    },
    {
      "epoch": 0.7925091911764706,
      "grad_norm": 1.224987506866455,
      "learning_rate": 9.351000816993465e-06,
      "loss": 0.0866,
      "step": 3449
    },
    {
      "epoch": 0.7927389705882353,
      "grad_norm": 0.9529197216033936,
      "learning_rate": 9.350490196078433e-06,
      "loss": 0.0583,
      "step": 3450
    },
    {
      "epoch": 0.79296875,
      "grad_norm": 0.9814271330833435,
      "learning_rate": 9.349979575163399e-06,
      "loss": 0.0702,
      "step": 3451
    },
    {
      "epoch": 0.7931985294117647,
      "grad_norm": 1.008790135383606,
      "learning_rate": 9.349468954248367e-06,
      "loss": 0.0749,
      "step": 3452
    },
    {
      "epoch": 0.7934283088235294,
      "grad_norm": 1.1287132501602173,
      "learning_rate": 9.348958333333335e-06,
      "loss": 0.0876,
      "step": 3453
    },
    {
      "epoch": 0.7936580882352942,
      "grad_norm": 1.2203927040100098,
      "learning_rate": 9.348447712418301e-06,
      "loss": 0.0646,
      "step": 3454
    },
    {
      "epoch": 0.7938878676470589,
      "grad_norm": 1.5636965036392212,
      "learning_rate": 9.347937091503269e-06,
      "loss": 0.1155,
      "step": 3455
    },
    {
      "epoch": 0.7941176470588235,
      "grad_norm": 1.014996886253357,
      "learning_rate": 9.347426470588235e-06,
      "loss": 0.049,
      "step": 3456
    },
    {
      "epoch": 0.7943474264705882,
      "grad_norm": 1.1015117168426514,
      "learning_rate": 9.346915849673204e-06,
      "loss": 0.0931,
      "step": 3457
    },
    {
      "epoch": 0.7945772058823529,
      "grad_norm": 0.767733097076416,
      "learning_rate": 9.34640522875817e-06,
      "loss": 0.0357,
      "step": 3458
    },
    {
      "epoch": 0.7948069852941176,
      "grad_norm": 1.1505351066589355,
      "learning_rate": 9.345894607843138e-06,
      "loss": 0.0646,
      "step": 3459
    },
    {
      "epoch": 0.7950367647058824,
      "grad_norm": 0.9068195819854736,
      "learning_rate": 9.345383986928105e-06,
      "loss": 0.0691,
      "step": 3460
    },
    {
      "epoch": 0.7952665441176471,
      "grad_norm": 1.0075006484985352,
      "learning_rate": 9.344873366013073e-06,
      "loss": 0.0951,
      "step": 3461
    },
    {
      "epoch": 0.7954963235294118,
      "grad_norm": 0.7553215026855469,
      "learning_rate": 9.34436274509804e-06,
      "loss": 0.0472,
      "step": 3462
    },
    {
      "epoch": 0.7957261029411765,
      "grad_norm": 1.163048267364502,
      "learning_rate": 9.343852124183007e-06,
      "loss": 0.1319,
      "step": 3463
    },
    {
      "epoch": 0.7959558823529411,
      "grad_norm": 1.149280071258545,
      "learning_rate": 9.343341503267974e-06,
      "loss": 0.0815,
      "step": 3464
    },
    {
      "epoch": 0.7961856617647058,
      "grad_norm": 0.8613039255142212,
      "learning_rate": 9.342830882352942e-06,
      "loss": 0.063,
      "step": 3465
    },
    {
      "epoch": 0.7964154411764706,
      "grad_norm": 1.2655906677246094,
      "learning_rate": 9.34232026143791e-06,
      "loss": 0.0899,
      "step": 3466
    },
    {
      "epoch": 0.7966452205882353,
      "grad_norm": 0.9337692856788635,
      "learning_rate": 9.341809640522876e-06,
      "loss": 0.0538,
      "step": 3467
    },
    {
      "epoch": 0.796875,
      "grad_norm": 0.8857339024543762,
      "learning_rate": 9.341299019607844e-06,
      "loss": 0.0614,
      "step": 3468
    },
    {
      "epoch": 0.7971047794117647,
      "grad_norm": 0.8974927663803101,
      "learning_rate": 9.340788398692812e-06,
      "loss": 0.084,
      "step": 3469
    },
    {
      "epoch": 0.7973345588235294,
      "grad_norm": 1.0835403203964233,
      "learning_rate": 9.340277777777778e-06,
      "loss": 0.0643,
      "step": 3470
    },
    {
      "epoch": 0.7975643382352942,
      "grad_norm": 1.0553414821624756,
      "learning_rate": 9.339767156862746e-06,
      "loss": 0.0549,
      "step": 3471
    },
    {
      "epoch": 0.7977941176470589,
      "grad_norm": 1.24729585647583,
      "learning_rate": 9.339256535947712e-06,
      "loss": 0.081,
      "step": 3472
    },
    {
      "epoch": 0.7980238970588235,
      "grad_norm": 1.0000123977661133,
      "learning_rate": 9.33874591503268e-06,
      "loss": 0.0768,
      "step": 3473
    },
    {
      "epoch": 0.7982536764705882,
      "grad_norm": 0.903196394443512,
      "learning_rate": 9.338235294117648e-06,
      "loss": 0.0777,
      "step": 3474
    },
    {
      "epoch": 0.7984834558823529,
      "grad_norm": 0.8763917088508606,
      "learning_rate": 9.337724673202616e-06,
      "loss": 0.0732,
      "step": 3475
    },
    {
      "epoch": 0.7987132352941176,
      "grad_norm": 1.0621893405914307,
      "learning_rate": 9.337214052287582e-06,
      "loss": 0.0956,
      "step": 3476
    },
    {
      "epoch": 0.7989430147058824,
      "grad_norm": 1.1936204433441162,
      "learning_rate": 9.33670343137255e-06,
      "loss": 0.0737,
      "step": 3477
    },
    {
      "epoch": 0.7991727941176471,
      "grad_norm": 1.2284481525421143,
      "learning_rate": 9.336192810457518e-06,
      "loss": 0.1393,
      "step": 3478
    },
    {
      "epoch": 0.7994025735294118,
      "grad_norm": 0.853582501411438,
      "learning_rate": 9.335682189542484e-06,
      "loss": 0.0646,
      "step": 3479
    },
    {
      "epoch": 0.7996323529411765,
      "grad_norm": 1.1086297035217285,
      "learning_rate": 9.335171568627452e-06,
      "loss": 0.0806,
      "step": 3480
    },
    {
      "epoch": 0.7998621323529411,
      "grad_norm": 0.7466415166854858,
      "learning_rate": 9.33466094771242e-06,
      "loss": 0.0511,
      "step": 3481
    },
    {
      "epoch": 0.8000919117647058,
      "grad_norm": 0.921932578086853,
      "learning_rate": 9.334150326797386e-06,
      "loss": 0.0671,
      "step": 3482
    },
    {
      "epoch": 0.8003216911764706,
      "grad_norm": 1.092207670211792,
      "learning_rate": 9.333639705882354e-06,
      "loss": 0.0963,
      "step": 3483
    },
    {
      "epoch": 0.8005514705882353,
      "grad_norm": 0.876118004322052,
      "learning_rate": 9.33312908496732e-06,
      "loss": 0.0778,
      "step": 3484
    },
    {
      "epoch": 0.80078125,
      "grad_norm": 1.363647699356079,
      "learning_rate": 9.33261846405229e-06,
      "loss": 0.1214,
      "step": 3485
    },
    {
      "epoch": 0.8010110294117647,
      "grad_norm": 0.732603907585144,
      "learning_rate": 9.332107843137255e-06,
      "loss": 0.0594,
      "step": 3486
    },
    {
      "epoch": 0.8012408088235294,
      "grad_norm": 1.0428370237350464,
      "learning_rate": 9.331597222222223e-06,
      "loss": 0.064,
      "step": 3487
    },
    {
      "epoch": 0.8014705882352942,
      "grad_norm": 1.0821055173873901,
      "learning_rate": 9.33108660130719e-06,
      "loss": 0.1005,
      "step": 3488
    },
    {
      "epoch": 0.8017003676470589,
      "grad_norm": 1.0897833108901978,
      "learning_rate": 9.330575980392157e-06,
      "loss": 0.0835,
      "step": 3489
    },
    {
      "epoch": 0.8019301470588235,
      "grad_norm": 1.0560418367385864,
      "learning_rate": 9.330065359477125e-06,
      "loss": 0.0818,
      "step": 3490
    },
    {
      "epoch": 0.8021599264705882,
      "grad_norm": 0.9908829927444458,
      "learning_rate": 9.329554738562091e-06,
      "loss": 0.0673,
      "step": 3491
    },
    {
      "epoch": 0.8023897058823529,
      "grad_norm": 1.1552692651748657,
      "learning_rate": 9.32904411764706e-06,
      "loss": 0.1027,
      "step": 3492
    },
    {
      "epoch": 0.8026194852941176,
      "grad_norm": 0.9542967081069946,
      "learning_rate": 9.328533496732027e-06,
      "loss": 0.0942,
      "step": 3493
    },
    {
      "epoch": 0.8028492647058824,
      "grad_norm": 1.0789077281951904,
      "learning_rate": 9.328022875816995e-06,
      "loss": 0.1068,
      "step": 3494
    },
    {
      "epoch": 0.8030790441176471,
      "grad_norm": 1.0530452728271484,
      "learning_rate": 9.327512254901961e-06,
      "loss": 0.072,
      "step": 3495
    },
    {
      "epoch": 0.8033088235294118,
      "grad_norm": 1.233741044998169,
      "learning_rate": 9.327001633986929e-06,
      "loss": 0.0965,
      "step": 3496
    },
    {
      "epoch": 0.8035386029411765,
      "grad_norm": 0.9135215282440186,
      "learning_rate": 9.326491013071897e-06,
      "loss": 0.0671,
      "step": 3497
    },
    {
      "epoch": 0.8037683823529411,
      "grad_norm": 0.8965228199958801,
      "learning_rate": 9.325980392156863e-06,
      "loss": 0.0623,
      "step": 3498
    },
    {
      "epoch": 0.8039981617647058,
      "grad_norm": 1.2641773223876953,
      "learning_rate": 9.325469771241831e-06,
      "loss": 0.1303,
      "step": 3499
    },
    {
      "epoch": 0.8042279411764706,
      "grad_norm": 0.9629987478256226,
      "learning_rate": 9.324959150326797e-06,
      "loss": 0.092,
      "step": 3500
    },
    {
      "epoch": 0.8042279411764706,
      "eval_loss": 0.07880495488643646,
      "eval_runtime": 2007.2782,
      "eval_samples_per_second": 4.437,
      "eval_steps_per_second": 2.218,
      "step": 3500
    },
    {
      "epoch": 0.8044577205882353,
      "grad_norm": 0.8765658140182495,
      "learning_rate": 9.324448529411767e-06,
      "loss": 0.067,
      "step": 3501
    },
    {
      "epoch": 0.8046875,
      "grad_norm": 1.0435097217559814,
      "learning_rate": 9.323937908496733e-06,
      "loss": 0.0681,
      "step": 3502
    },
    {
      "epoch": 0.8049172794117647,
      "grad_norm": 0.9618347883224487,
      "learning_rate": 9.3234272875817e-06,
      "loss": 0.0647,
      "step": 3503
    },
    {
      "epoch": 0.8051470588235294,
      "grad_norm": 0.9855883121490479,
      "learning_rate": 9.322916666666667e-06,
      "loss": 0.0564,
      "step": 3504
    },
    {
      "epoch": 0.8053768382352942,
      "grad_norm": 1.2308989763259888,
      "learning_rate": 9.322406045751635e-06,
      "loss": 0.0712,
      "step": 3505
    },
    {
      "epoch": 0.8056066176470589,
      "grad_norm": 1.1071773767471313,
      "learning_rate": 9.321895424836603e-06,
      "loss": 0.0936,
      "step": 3506
    },
    {
      "epoch": 0.8058363970588235,
      "grad_norm": 0.785218358039856,
      "learning_rate": 9.321384803921569e-06,
      "loss": 0.0571,
      "step": 3507
    },
    {
      "epoch": 0.8060661764705882,
      "grad_norm": 0.7923787236213684,
      "learning_rate": 9.320874183006537e-06,
      "loss": 0.0648,
      "step": 3508
    },
    {
      "epoch": 0.8062959558823529,
      "grad_norm": 1.1935477256774902,
      "learning_rate": 9.320363562091504e-06,
      "loss": 0.0601,
      "step": 3509
    },
    {
      "epoch": 0.8065257352941176,
      "grad_norm": 0.9385014176368713,
      "learning_rate": 9.319852941176472e-06,
      "loss": 0.0702,
      "step": 3510
    },
    {
      "epoch": 0.8067555147058824,
      "grad_norm": 0.8441948294639587,
      "learning_rate": 9.319342320261438e-06,
      "loss": 0.0797,
      "step": 3511
    },
    {
      "epoch": 0.8069852941176471,
      "grad_norm": 0.9637395143508911,
      "learning_rate": 9.318831699346406e-06,
      "loss": 0.0712,
      "step": 3512
    },
    {
      "epoch": 0.8072150735294118,
      "grad_norm": 1.184403896331787,
      "learning_rate": 9.318321078431374e-06,
      "loss": 0.084,
      "step": 3513
    },
    {
      "epoch": 0.8074448529411765,
      "grad_norm": 1.9755973815917969,
      "learning_rate": 9.31781045751634e-06,
      "loss": 0.0827,
      "step": 3514
    },
    {
      "epoch": 0.8076746323529411,
      "grad_norm": 1.0633584260940552,
      "learning_rate": 9.317299836601308e-06,
      "loss": 0.0839,
      "step": 3515
    },
    {
      "epoch": 0.8079044117647058,
      "grad_norm": 1.1870731115341187,
      "learning_rate": 9.316789215686274e-06,
      "loss": 0.0699,
      "step": 3516
    },
    {
      "epoch": 0.8081341911764706,
      "grad_norm": 0.9825093746185303,
      "learning_rate": 9.316278594771242e-06,
      "loss": 0.0903,
      "step": 3517
    },
    {
      "epoch": 0.8083639705882353,
      "grad_norm": 1.4021508693695068,
      "learning_rate": 9.31576797385621e-06,
      "loss": 0.0912,
      "step": 3518
    },
    {
      "epoch": 0.80859375,
      "grad_norm": 0.9858325123786926,
      "learning_rate": 9.315257352941178e-06,
      "loss": 0.0665,
      "step": 3519
    },
    {
      "epoch": 0.8088235294117647,
      "grad_norm": 1.1400662660598755,
      "learning_rate": 9.314746732026144e-06,
      "loss": 0.0896,
      "step": 3520
    },
    {
      "epoch": 0.8090533088235294,
      "grad_norm": 0.9079017639160156,
      "learning_rate": 9.314236111111112e-06,
      "loss": 0.066,
      "step": 3521
    },
    {
      "epoch": 0.8092830882352942,
      "grad_norm": 1.085077166557312,
      "learning_rate": 9.31372549019608e-06,
      "loss": 0.0603,
      "step": 3522
    },
    {
      "epoch": 0.8095128676470589,
      "grad_norm": 0.6918225884437561,
      "learning_rate": 9.313214869281046e-06,
      "loss": 0.0389,
      "step": 3523
    },
    {
      "epoch": 0.8097426470588235,
      "grad_norm": 1.5277773141860962,
      "learning_rate": 9.312704248366014e-06,
      "loss": 0.1037,
      "step": 3524
    },
    {
      "epoch": 0.8099724264705882,
      "grad_norm": 0.8249098062515259,
      "learning_rate": 9.312193627450982e-06,
      "loss": 0.0585,
      "step": 3525
    },
    {
      "epoch": 0.8102022058823529,
      "grad_norm": 1.240588665008545,
      "learning_rate": 9.311683006535948e-06,
      "loss": 0.0794,
      "step": 3526
    },
    {
      "epoch": 0.8104319852941176,
      "grad_norm": 1.2719475030899048,
      "learning_rate": 9.311172385620916e-06,
      "loss": 0.0873,
      "step": 3527
    },
    {
      "epoch": 0.8106617647058824,
      "grad_norm": 1.4639500379562378,
      "learning_rate": 9.310661764705882e-06,
      "loss": 0.0911,
      "step": 3528
    },
    {
      "epoch": 0.8108915441176471,
      "grad_norm": 1.0370186567306519,
      "learning_rate": 9.310151143790852e-06,
      "loss": 0.0996,
      "step": 3529
    },
    {
      "epoch": 0.8111213235294118,
      "grad_norm": 0.6466642618179321,
      "learning_rate": 9.309640522875818e-06,
      "loss": 0.0286,
      "step": 3530
    },
    {
      "epoch": 0.8113511029411765,
      "grad_norm": 1.1251283884048462,
      "learning_rate": 9.309129901960786e-06,
      "loss": 0.099,
      "step": 3531
    },
    {
      "epoch": 0.8115808823529411,
      "grad_norm": 1.000468373298645,
      "learning_rate": 9.308619281045752e-06,
      "loss": 0.079,
      "step": 3532
    },
    {
      "epoch": 0.8118106617647058,
      "grad_norm": 1.028200387954712,
      "learning_rate": 9.30810866013072e-06,
      "loss": 0.0565,
      "step": 3533
    },
    {
      "epoch": 0.8120404411764706,
      "grad_norm": 1.394347906112671,
      "learning_rate": 9.307598039215687e-06,
      "loss": 0.0691,
      "step": 3534
    },
    {
      "epoch": 0.8122702205882353,
      "grad_norm": 0.809113085269928,
      "learning_rate": 9.307087418300654e-06,
      "loss": 0.0665,
      "step": 3535
    },
    {
      "epoch": 0.8125,
      "grad_norm": 1.0800868272781372,
      "learning_rate": 9.306576797385621e-06,
      "loss": 0.0628,
      "step": 3536
    },
    {
      "epoch": 0.8127297794117647,
      "grad_norm": 0.9439494609832764,
      "learning_rate": 9.30606617647059e-06,
      "loss": 0.0892,
      "step": 3537
    },
    {
      "epoch": 0.8129595588235294,
      "grad_norm": 0.9877285361289978,
      "learning_rate": 9.305555555555557e-06,
      "loss": 0.0752,
      "step": 3538
    },
    {
      "epoch": 0.8131893382352942,
      "grad_norm": 1.15451979637146,
      "learning_rate": 9.305044934640523e-06,
      "loss": 0.0798,
      "step": 3539
    },
    {
      "epoch": 0.8134191176470589,
      "grad_norm": 0.9597759246826172,
      "learning_rate": 9.304534313725491e-06,
      "loss": 0.0738,
      "step": 3540
    },
    {
      "epoch": 0.8136488970588235,
      "grad_norm": 1.536311388015747,
      "learning_rate": 9.304023692810459e-06,
      "loss": 0.0871,
      "step": 3541
    },
    {
      "epoch": 0.8138786764705882,
      "grad_norm": 1.0892246961593628,
      "learning_rate": 9.303513071895425e-06,
      "loss": 0.0637,
      "step": 3542
    },
    {
      "epoch": 0.8141084558823529,
      "grad_norm": 1.1443475484848022,
      "learning_rate": 9.303002450980393e-06,
      "loss": 0.0589,
      "step": 3543
    },
    {
      "epoch": 0.8143382352941176,
      "grad_norm": 1.0875849723815918,
      "learning_rate": 9.30249183006536e-06,
      "loss": 0.0752,
      "step": 3544
    },
    {
      "epoch": 0.8145680147058824,
      "grad_norm": 1.1883742809295654,
      "learning_rate": 9.301981209150329e-06,
      "loss": 0.0745,
      "step": 3545
    },
    {
      "epoch": 0.8147977941176471,
      "grad_norm": 1.1070500612258911,
      "learning_rate": 9.301470588235295e-06,
      "loss": 0.0765,
      "step": 3546
    },
    {
      "epoch": 0.8150275735294118,
      "grad_norm": 0.7215917706489563,
      "learning_rate": 9.300959967320263e-06,
      "loss": 0.0737,
      "step": 3547
    },
    {
      "epoch": 0.8152573529411765,
      "grad_norm": 1.1734176874160767,
      "learning_rate": 9.300449346405229e-06,
      "loss": 0.0761,
      "step": 3548
    },
    {
      "epoch": 0.8154871323529411,
      "grad_norm": 1.172027349472046,
      "learning_rate": 9.299938725490197e-06,
      "loss": 0.0991,
      "step": 3549
    },
    {
      "epoch": 0.8157169117647058,
      "grad_norm": 0.8226053714752197,
      "learning_rate": 9.299428104575165e-06,
      "loss": 0.0508,
      "step": 3550
    },
    {
      "epoch": 0.8159466911764706,
      "grad_norm": 1.300783395767212,
      "learning_rate": 9.298917483660131e-06,
      "loss": 0.086,
      "step": 3551
    },
    {
      "epoch": 0.8161764705882353,
      "grad_norm": 1.1062406301498413,
      "learning_rate": 9.298406862745099e-06,
      "loss": 0.0676,
      "step": 3552
    },
    {
      "epoch": 0.81640625,
      "grad_norm": 0.9883512854576111,
      "learning_rate": 9.297896241830067e-06,
      "loss": 0.0666,
      "step": 3553
    },
    {
      "epoch": 0.8166360294117647,
      "grad_norm": 1.2904095649719238,
      "learning_rate": 9.297385620915035e-06,
      "loss": 0.084,
      "step": 3554
    },
    {
      "epoch": 0.8168658088235294,
      "grad_norm": 1.6605430841445923,
      "learning_rate": 9.296875e-06,
      "loss": 0.0942,
      "step": 3555
    },
    {
      "epoch": 0.8170955882352942,
      "grad_norm": 1.089093804359436,
      "learning_rate": 9.296364379084969e-06,
      "loss": 0.0631,
      "step": 3556
    },
    {
      "epoch": 0.8173253676470589,
      "grad_norm": 1.083459496498108,
      "learning_rate": 9.295853758169935e-06,
      "loss": 0.083,
      "step": 3557
    },
    {
      "epoch": 0.8175551470588235,
      "grad_norm": 1.2173606157302856,
      "learning_rate": 9.295343137254903e-06,
      "loss": 0.0684,
      "step": 3558
    },
    {
      "epoch": 0.8177849264705882,
      "grad_norm": 1.116133689880371,
      "learning_rate": 9.29483251633987e-06,
      "loss": 0.0815,
      "step": 3559
    },
    {
      "epoch": 0.8180147058823529,
      "grad_norm": 0.9217010140419006,
      "learning_rate": 9.294321895424837e-06,
      "loss": 0.0621,
      "step": 3560
    },
    {
      "epoch": 0.8182444852941176,
      "grad_norm": 1.4567073583602905,
      "learning_rate": 9.293811274509804e-06,
      "loss": 0.1037,
      "step": 3561
    },
    {
      "epoch": 0.8184742647058824,
      "grad_norm": 0.8507261276245117,
      "learning_rate": 9.293300653594772e-06,
      "loss": 0.0503,
      "step": 3562
    },
    {
      "epoch": 0.8187040441176471,
      "grad_norm": 0.8396491408348083,
      "learning_rate": 9.29279003267974e-06,
      "loss": 0.0518,
      "step": 3563
    },
    {
      "epoch": 0.8189338235294118,
      "grad_norm": 1.0267695188522339,
      "learning_rate": 9.292279411764706e-06,
      "loss": 0.0755,
      "step": 3564
    },
    {
      "epoch": 0.8191636029411765,
      "grad_norm": 1.0754274129867554,
      "learning_rate": 9.291768790849674e-06,
      "loss": 0.0969,
      "step": 3565
    },
    {
      "epoch": 0.8193933823529411,
      "grad_norm": 1.1783885955810547,
      "learning_rate": 9.291258169934642e-06,
      "loss": 0.0833,
      "step": 3566
    },
    {
      "epoch": 0.8196231617647058,
      "grad_norm": 1.0404670238494873,
      "learning_rate": 9.290747549019608e-06,
      "loss": 0.0817,
      "step": 3567
    },
    {
      "epoch": 0.8198529411764706,
      "grad_norm": 1.0359135866165161,
      "learning_rate": 9.290236928104576e-06,
      "loss": 0.0741,
      "step": 3568
    },
    {
      "epoch": 0.8200827205882353,
      "grad_norm": 1.197340965270996,
      "learning_rate": 9.289726307189542e-06,
      "loss": 0.0999,
      "step": 3569
    },
    {
      "epoch": 0.8203125,
      "grad_norm": 1.3194226026535034,
      "learning_rate": 9.28921568627451e-06,
      "loss": 0.1124,
      "step": 3570
    },
    {
      "epoch": 0.8205422794117647,
      "grad_norm": 1.1031550168991089,
      "learning_rate": 9.288705065359478e-06,
      "loss": 0.0795,
      "step": 3571
    },
    {
      "epoch": 0.8207720588235294,
      "grad_norm": 1.4888211488723755,
      "learning_rate": 9.288194444444444e-06,
      "loss": 0.1052,
      "step": 3572
    },
    {
      "epoch": 0.8210018382352942,
      "grad_norm": 1.0737013816833496,
      "learning_rate": 9.287683823529412e-06,
      "loss": 0.1012,
      "step": 3573
    },
    {
      "epoch": 0.8212316176470589,
      "grad_norm": 0.8131967186927795,
      "learning_rate": 9.28717320261438e-06,
      "loss": 0.0522,
      "step": 3574
    },
    {
      "epoch": 0.8214613970588235,
      "grad_norm": 0.9370346069335938,
      "learning_rate": 9.286662581699348e-06,
      "loss": 0.0693,
      "step": 3575
    },
    {
      "epoch": 0.8216911764705882,
      "grad_norm": 1.337638020515442,
      "learning_rate": 9.286151960784314e-06,
      "loss": 0.0828,
      "step": 3576
    },
    {
      "epoch": 0.8219209558823529,
      "grad_norm": 1.0475600957870483,
      "learning_rate": 9.285641339869282e-06,
      "loss": 0.0823,
      "step": 3577
    },
    {
      "epoch": 0.8221507352941176,
      "grad_norm": 1.3634275197982788,
      "learning_rate": 9.28513071895425e-06,
      "loss": 0.0905,
      "step": 3578
    },
    {
      "epoch": 0.8223805147058824,
      "grad_norm": 0.9567527770996094,
      "learning_rate": 9.284620098039216e-06,
      "loss": 0.0578,
      "step": 3579
    },
    {
      "epoch": 0.8226102941176471,
      "grad_norm": 1.0112485885620117,
      "learning_rate": 9.284109477124184e-06,
      "loss": 0.063,
      "step": 3580
    },
    {
      "epoch": 0.8228400735294118,
      "grad_norm": 1.0735502243041992,
      "learning_rate": 9.28359885620915e-06,
      "loss": 0.0575,
      "step": 3581
    },
    {
      "epoch": 0.8230698529411765,
      "grad_norm": 0.8457698822021484,
      "learning_rate": 9.28308823529412e-06,
      "loss": 0.0631,
      "step": 3582
    },
    {
      "epoch": 0.8232996323529411,
      "grad_norm": 0.99321049451828,
      "learning_rate": 9.282577614379086e-06,
      "loss": 0.0609,
      "step": 3583
    },
    {
      "epoch": 0.8235294117647058,
      "grad_norm": 0.9255768656730652,
      "learning_rate": 9.282066993464053e-06,
      "loss": 0.1114,
      "step": 3584
    },
    {
      "epoch": 0.8237591911764706,
      "grad_norm": 1.3031355142593384,
      "learning_rate": 9.28155637254902e-06,
      "loss": 0.0796,
      "step": 3585
    },
    {
      "epoch": 0.8239889705882353,
      "grad_norm": 1.0599783658981323,
      "learning_rate": 9.281045751633987e-06,
      "loss": 0.0847,
      "step": 3586
    },
    {
      "epoch": 0.82421875,
      "grad_norm": 0.9635334014892578,
      "learning_rate": 9.280535130718955e-06,
      "loss": 0.0771,
      "step": 3587
    },
    {
      "epoch": 0.8244485294117647,
      "grad_norm": 1.418861985206604,
      "learning_rate": 9.280024509803921e-06,
      "loss": 0.0914,
      "step": 3588
    },
    {
      "epoch": 0.8246783088235294,
      "grad_norm": 1.310408592224121,
      "learning_rate": 9.27951388888889e-06,
      "loss": 0.09,
      "step": 3589
    },
    {
      "epoch": 0.8249080882352942,
      "grad_norm": 0.9377555847167969,
      "learning_rate": 9.279003267973857e-06,
      "loss": 0.0972,
      "step": 3590
    },
    {
      "epoch": 0.8251378676470589,
      "grad_norm": 1.118475317955017,
      "learning_rate": 9.278492647058825e-06,
      "loss": 0.0886,
      "step": 3591
    },
    {
      "epoch": 0.8253676470588235,
      "grad_norm": 0.9233722686767578,
      "learning_rate": 9.277982026143791e-06,
      "loss": 0.049,
      "step": 3592
    },
    {
      "epoch": 0.8255974264705882,
      "grad_norm": 1.09857976436615,
      "learning_rate": 9.277471405228759e-06,
      "loss": 0.0719,
      "step": 3593
    },
    {
      "epoch": 0.8258272058823529,
      "grad_norm": 0.9514373540878296,
      "learning_rate": 9.276960784313727e-06,
      "loss": 0.0631,
      "step": 3594
    },
    {
      "epoch": 0.8260569852941176,
      "grad_norm": 1.157531976699829,
      "learning_rate": 9.276450163398693e-06,
      "loss": 0.0831,
      "step": 3595
    },
    {
      "epoch": 0.8262867647058824,
      "grad_norm": 1.0258668661117554,
      "learning_rate": 9.275939542483661e-06,
      "loss": 0.1092,
      "step": 3596
    },
    {
      "epoch": 0.8265165441176471,
      "grad_norm": 0.8544110059738159,
      "learning_rate": 9.275428921568627e-06,
      "loss": 0.0865,
      "step": 3597
    },
    {
      "epoch": 0.8267463235294118,
      "grad_norm": 1.2603553533554077,
      "learning_rate": 9.274918300653597e-06,
      "loss": 0.105,
      "step": 3598
    },
    {
      "epoch": 0.8269761029411765,
      "grad_norm": 0.7159440517425537,
      "learning_rate": 9.274407679738563e-06,
      "loss": 0.0522,
      "step": 3599
    },
    {
      "epoch": 0.8272058823529411,
      "grad_norm": 1.012098789215088,
      "learning_rate": 9.27389705882353e-06,
      "loss": 0.0615,
      "step": 3600
    },
    {
      "epoch": 0.8274356617647058,
      "grad_norm": 0.7636616230010986,
      "learning_rate": 9.273386437908497e-06,
      "loss": 0.0428,
      "step": 3601
    },
    {
      "epoch": 0.8276654411764706,
      "grad_norm": 0.6737197637557983,
      "learning_rate": 9.272875816993465e-06,
      "loss": 0.0454,
      "step": 3602
    },
    {
      "epoch": 0.8278952205882353,
      "grad_norm": 1.206464171409607,
      "learning_rate": 9.272365196078433e-06,
      "loss": 0.0759,
      "step": 3603
    },
    {
      "epoch": 0.828125,
      "grad_norm": 0.942512035369873,
      "learning_rate": 9.271854575163399e-06,
      "loss": 0.0757,
      "step": 3604
    },
    {
      "epoch": 0.8283547794117647,
      "grad_norm": 1.4075284004211426,
      "learning_rate": 9.271343954248367e-06,
      "loss": 0.1026,
      "step": 3605
    },
    {
      "epoch": 0.8285845588235294,
      "grad_norm": 1.1641978025436401,
      "learning_rate": 9.270833333333334e-06,
      "loss": 0.0703,
      "step": 3606
    },
    {
      "epoch": 0.8288143382352942,
      "grad_norm": 1.0946308374404907,
      "learning_rate": 9.2703227124183e-06,
      "loss": 0.0798,
      "step": 3607
    },
    {
      "epoch": 0.8290441176470589,
      "grad_norm": 0.825796365737915,
      "learning_rate": 9.269812091503269e-06,
      "loss": 0.0605,
      "step": 3608
    },
    {
      "epoch": 0.8292738970588235,
      "grad_norm": 1.7684459686279297,
      "learning_rate": 9.269301470588236e-06,
      "loss": 0.1007,
      "step": 3609
    },
    {
      "epoch": 0.8295036764705882,
      "grad_norm": 1.1139464378356934,
      "learning_rate": 9.268790849673204e-06,
      "loss": 0.0621,
      "step": 3610
    },
    {
      "epoch": 0.8297334558823529,
      "grad_norm": 1.0351241827011108,
      "learning_rate": 9.26828022875817e-06,
      "loss": 0.0899,
      "step": 3611
    },
    {
      "epoch": 0.8299632352941176,
      "grad_norm": 0.9401694536209106,
      "learning_rate": 9.267769607843138e-06,
      "loss": 0.053,
      "step": 3612
    },
    {
      "epoch": 0.8301930147058824,
      "grad_norm": 1.0855928659439087,
      "learning_rate": 9.267258986928104e-06,
      "loss": 0.0801,
      "step": 3613
    },
    {
      "epoch": 0.8304227941176471,
      "grad_norm": 1.0930345058441162,
      "learning_rate": 9.266748366013072e-06,
      "loss": 0.0905,
      "step": 3614
    },
    {
      "epoch": 0.8306525735294118,
      "grad_norm": 1.5065758228302002,
      "learning_rate": 9.26623774509804e-06,
      "loss": 0.1017,
      "step": 3615
    },
    {
      "epoch": 0.8308823529411765,
      "grad_norm": 1.2768876552581787,
      "learning_rate": 9.265727124183006e-06,
      "loss": 0.0839,
      "step": 3616
    },
    {
      "epoch": 0.8311121323529411,
      "grad_norm": 0.6933169364929199,
      "learning_rate": 9.265216503267974e-06,
      "loss": 0.0521,
      "step": 3617
    },
    {
      "epoch": 0.8313419117647058,
      "grad_norm": 0.6373441815376282,
      "learning_rate": 9.264705882352942e-06,
      "loss": 0.0325,
      "step": 3618
    },
    {
      "epoch": 0.8315716911764706,
      "grad_norm": 1.5170427560806274,
      "learning_rate": 9.26419526143791e-06,
      "loss": 0.0585,
      "step": 3619
    },
    {
      "epoch": 0.8318014705882353,
      "grad_norm": 1.1393862962722778,
      "learning_rate": 9.263684640522876e-06,
      "loss": 0.0672,
      "step": 3620
    },
    {
      "epoch": 0.83203125,
      "grad_norm": 1.310190200805664,
      "learning_rate": 9.263174019607844e-06,
      "loss": 0.1101,
      "step": 3621
    },
    {
      "epoch": 0.8322610294117647,
      "grad_norm": 1.0536426305770874,
      "learning_rate": 9.262663398692812e-06,
      "loss": 0.0801,
      "step": 3622
    },
    {
      "epoch": 0.8324908088235294,
      "grad_norm": 1.3144842386245728,
      "learning_rate": 9.262152777777778e-06,
      "loss": 0.0738,
      "step": 3623
    },
    {
      "epoch": 0.8327205882352942,
      "grad_norm": 0.9298658967018127,
      "learning_rate": 9.261642156862746e-06,
      "loss": 0.065,
      "step": 3624
    },
    {
      "epoch": 0.8329503676470589,
      "grad_norm": 0.8137109875679016,
      "learning_rate": 9.261131535947712e-06,
      "loss": 0.0673,
      "step": 3625
    },
    {
      "epoch": 0.8331801470588235,
      "grad_norm": 1.2268970012664795,
      "learning_rate": 9.260620915032682e-06,
      "loss": 0.0917,
      "step": 3626
    },
    {
      "epoch": 0.8334099264705882,
      "grad_norm": 1.282365083694458,
      "learning_rate": 9.260110294117648e-06,
      "loss": 0.077,
      "step": 3627
    },
    {
      "epoch": 0.8336397058823529,
      "grad_norm": 0.8120384216308594,
      "learning_rate": 9.259599673202616e-06,
      "loss": 0.0691,
      "step": 3628
    },
    {
      "epoch": 0.8338694852941176,
      "grad_norm": 1.0274966955184937,
      "learning_rate": 9.259089052287582e-06,
      "loss": 0.0737,
      "step": 3629
    },
    {
      "epoch": 0.8340992647058824,
      "grad_norm": 0.9545958638191223,
      "learning_rate": 9.25857843137255e-06,
      "loss": 0.0682,
      "step": 3630
    },
    {
      "epoch": 0.8343290441176471,
      "grad_norm": 0.816615879535675,
      "learning_rate": 9.258067810457517e-06,
      "loss": 0.0575,
      "step": 3631
    },
    {
      "epoch": 0.8345588235294118,
      "grad_norm": 1.0630316734313965,
      "learning_rate": 9.257557189542484e-06,
      "loss": 0.0931,
      "step": 3632
    },
    {
      "epoch": 0.8347886029411765,
      "grad_norm": 1.096441626548767,
      "learning_rate": 9.257046568627452e-06,
      "loss": 0.0813,
      "step": 3633
    },
    {
      "epoch": 0.8350183823529411,
      "grad_norm": 0.8008115291595459,
      "learning_rate": 9.25653594771242e-06,
      "loss": 0.0573,
      "step": 3634
    },
    {
      "epoch": 0.8352481617647058,
      "grad_norm": 1.2032934427261353,
      "learning_rate": 9.256025326797387e-06,
      "loss": 0.0547,
      "step": 3635
    },
    {
      "epoch": 0.8354779411764706,
      "grad_norm": 1.1313881874084473,
      "learning_rate": 9.255514705882353e-06,
      "loss": 0.1027,
      "step": 3636
    },
    {
      "epoch": 0.8357077205882353,
      "grad_norm": 0.8297935724258423,
      "learning_rate": 9.255004084967321e-06,
      "loss": 0.0786,
      "step": 3637
    },
    {
      "epoch": 0.8359375,
      "grad_norm": 0.9965298771858215,
      "learning_rate": 9.254493464052289e-06,
      "loss": 0.0856,
      "step": 3638
    },
    {
      "epoch": 0.8361672794117647,
      "grad_norm": 1.1047179698944092,
      "learning_rate": 9.253982843137255e-06,
      "loss": 0.0924,
      "step": 3639
    },
    {
      "epoch": 0.8363970588235294,
      "grad_norm": 1.163601040840149,
      "learning_rate": 9.253472222222223e-06,
      "loss": 0.0591,
      "step": 3640
    },
    {
      "epoch": 0.8366268382352942,
      "grad_norm": 1.020215630531311,
      "learning_rate": 9.25296160130719e-06,
      "loss": 0.0736,
      "step": 3641
    },
    {
      "epoch": 0.8368566176470589,
      "grad_norm": 1.043725609779358,
      "learning_rate": 9.252450980392159e-06,
      "loss": 0.0596,
      "step": 3642
    },
    {
      "epoch": 0.8370863970588235,
      "grad_norm": 0.8108607530593872,
      "learning_rate": 9.251940359477125e-06,
      "loss": 0.0533,
      "step": 3643
    },
    {
      "epoch": 0.8373161764705882,
      "grad_norm": 0.7810651063919067,
      "learning_rate": 9.251429738562093e-06,
      "loss": 0.0599,
      "step": 3644
    },
    {
      "epoch": 0.8375459558823529,
      "grad_norm": 0.6838845014572144,
      "learning_rate": 9.250919117647059e-06,
      "loss": 0.0579,
      "step": 3645
    },
    {
      "epoch": 0.8377757352941176,
      "grad_norm": 0.8905156254768372,
      "learning_rate": 9.250408496732027e-06,
      "loss": 0.0661,
      "step": 3646
    },
    {
      "epoch": 0.8380055147058824,
      "grad_norm": 1.105230689048767,
      "learning_rate": 9.249897875816995e-06,
      "loss": 0.0799,
      "step": 3647
    },
    {
      "epoch": 0.8382352941176471,
      "grad_norm": 1.0844175815582275,
      "learning_rate": 9.249387254901961e-06,
      "loss": 0.0705,
      "step": 3648
    },
    {
      "epoch": 0.8384650735294118,
      "grad_norm": 1.1819850206375122,
      "learning_rate": 9.248876633986929e-06,
      "loss": 0.0892,
      "step": 3649
    },
    {
      "epoch": 0.8386948529411765,
      "grad_norm": 1.1647796630859375,
      "learning_rate": 9.248366013071897e-06,
      "loss": 0.1063,
      "step": 3650
    },
    {
      "epoch": 0.8389246323529411,
      "grad_norm": 1.5723921060562134,
      "learning_rate": 9.247855392156863e-06,
      "loss": 0.11,
      "step": 3651
    },
    {
      "epoch": 0.8391544117647058,
      "grad_norm": 1.0639039278030396,
      "learning_rate": 9.24734477124183e-06,
      "loss": 0.059,
      "step": 3652
    },
    {
      "epoch": 0.8393841911764706,
      "grad_norm": 1.1369510889053345,
      "learning_rate": 9.246834150326799e-06,
      "loss": 0.0643,
      "step": 3653
    },
    {
      "epoch": 0.8396139705882353,
      "grad_norm": 0.8630155324935913,
      "learning_rate": 9.246323529411766e-06,
      "loss": 0.0469,
      "step": 3654
    },
    {
      "epoch": 0.83984375,
      "grad_norm": 1.0109739303588867,
      "learning_rate": 9.245812908496733e-06,
      "loss": 0.08,
      "step": 3655
    },
    {
      "epoch": 0.8400735294117647,
      "grad_norm": 0.9656738638877869,
      "learning_rate": 9.2453022875817e-06,
      "loss": 0.0826,
      "step": 3656
    },
    {
      "epoch": 0.8403033088235294,
      "grad_norm": 1.0791740417480469,
      "learning_rate": 9.244791666666667e-06,
      "loss": 0.0646,
      "step": 3657
    },
    {
      "epoch": 0.8405330882352942,
      "grad_norm": 1.3586534261703491,
      "learning_rate": 9.244281045751634e-06,
      "loss": 0.0811,
      "step": 3658
    },
    {
      "epoch": 0.8407628676470589,
      "grad_norm": 0.9599481821060181,
      "learning_rate": 9.243770424836602e-06,
      "loss": 0.0765,
      "step": 3659
    },
    {
      "epoch": 0.8409926470588235,
      "grad_norm": 1.2543662786483765,
      "learning_rate": 9.243259803921569e-06,
      "loss": 0.1008,
      "step": 3660
    },
    {
      "epoch": 0.8412224264705882,
      "grad_norm": 1.2240211963653564,
      "learning_rate": 9.242749183006536e-06,
      "loss": 0.1103,
      "step": 3661
    },
    {
      "epoch": 0.8414522058823529,
      "grad_norm": 0.8138272166252136,
      "learning_rate": 9.242238562091504e-06,
      "loss": 0.0586,
      "step": 3662
    },
    {
      "epoch": 0.8416819852941176,
      "grad_norm": 1.1901482343673706,
      "learning_rate": 9.241727941176472e-06,
      "loss": 0.0829,
      "step": 3663
    },
    {
      "epoch": 0.8419117647058824,
      "grad_norm": 0.9488401412963867,
      "learning_rate": 9.241217320261438e-06,
      "loss": 0.0652,
      "step": 3664
    },
    {
      "epoch": 0.8421415441176471,
      "grad_norm": 1.074070692062378,
      "learning_rate": 9.240706699346406e-06,
      "loss": 0.0845,
      "step": 3665
    },
    {
      "epoch": 0.8423713235294118,
      "grad_norm": 0.9149641990661621,
      "learning_rate": 9.240196078431374e-06,
      "loss": 0.0662,
      "step": 3666
    },
    {
      "epoch": 0.8426011029411765,
      "grad_norm": 0.8778700232505798,
      "learning_rate": 9.23968545751634e-06,
      "loss": 0.0665,
      "step": 3667
    },
    {
      "epoch": 0.8428308823529411,
      "grad_norm": 1.1800590753555298,
      "learning_rate": 9.239174836601308e-06,
      "loss": 0.0984,
      "step": 3668
    },
    {
      "epoch": 0.8430606617647058,
      "grad_norm": 1.0612740516662598,
      "learning_rate": 9.238664215686274e-06,
      "loss": 0.083,
      "step": 3669
    },
    {
      "epoch": 0.8432904411764706,
      "grad_norm": 1.0806809663772583,
      "learning_rate": 9.238153594771244e-06,
      "loss": 0.0825,
      "step": 3670
    },
    {
      "epoch": 0.8435202205882353,
      "grad_norm": 0.9212359189987183,
      "learning_rate": 9.23764297385621e-06,
      "loss": 0.0434,
      "step": 3671
    },
    {
      "epoch": 0.84375,
      "grad_norm": 0.9457703232765198,
      "learning_rate": 9.237132352941178e-06,
      "loss": 0.0735,
      "step": 3672
    },
    {
      "epoch": 0.8439797794117647,
      "grad_norm": 1.3876250982284546,
      "learning_rate": 9.236621732026144e-06,
      "loss": 0.0729,
      "step": 3673
    },
    {
      "epoch": 0.8442095588235294,
      "grad_norm": 0.9010854959487915,
      "learning_rate": 9.236111111111112e-06,
      "loss": 0.0609,
      "step": 3674
    },
    {
      "epoch": 0.8444393382352942,
      "grad_norm": 1.4236853122711182,
      "learning_rate": 9.23560049019608e-06,
      "loss": 0.1127,
      "step": 3675
    },
    {
      "epoch": 0.8446691176470589,
      "grad_norm": 1.2098417282104492,
      "learning_rate": 9.235089869281046e-06,
      "loss": 0.0583,
      "step": 3676
    },
    {
      "epoch": 0.8448988970588235,
      "grad_norm": 0.866481363773346,
      "learning_rate": 9.234579248366014e-06,
      "loss": 0.0511,
      "step": 3677
    },
    {
      "epoch": 0.8451286764705882,
      "grad_norm": 1.2753654718399048,
      "learning_rate": 9.234068627450982e-06,
      "loss": 0.1231,
      "step": 3678
    },
    {
      "epoch": 0.8453584558823529,
      "grad_norm": 1.0438973903656006,
      "learning_rate": 9.23355800653595e-06,
      "loss": 0.0516,
      "step": 3679
    },
    {
      "epoch": 0.8455882352941176,
      "grad_norm": 0.9960333108901978,
      "learning_rate": 9.233047385620916e-06,
      "loss": 0.082,
      "step": 3680
    },
    {
      "epoch": 0.8458180147058824,
      "grad_norm": 1.1671631336212158,
      "learning_rate": 9.232536764705883e-06,
      "loss": 0.1014,
      "step": 3681
    },
    {
      "epoch": 0.8460477941176471,
      "grad_norm": 1.7239609956741333,
      "learning_rate": 9.232026143790851e-06,
      "loss": 0.1136,
      "step": 3682
    },
    {
      "epoch": 0.8462775735294118,
      "grad_norm": 0.8663210868835449,
      "learning_rate": 9.231515522875817e-06,
      "loss": 0.0668,
      "step": 3683
    },
    {
      "epoch": 0.8465073529411765,
      "grad_norm": 1.6180875301361084,
      "learning_rate": 9.231004901960785e-06,
      "loss": 0.0828,
      "step": 3684
    },
    {
      "epoch": 0.8467371323529411,
      "grad_norm": 0.8098028898239136,
      "learning_rate": 9.230494281045752e-06,
      "loss": 0.0732,
      "step": 3685
    },
    {
      "epoch": 0.8469669117647058,
      "grad_norm": 0.8643651604652405,
      "learning_rate": 9.229983660130721e-06,
      "loss": 0.0719,
      "step": 3686
    },
    {
      "epoch": 0.8471966911764706,
      "grad_norm": 1.143713116645813,
      "learning_rate": 9.229473039215687e-06,
      "loss": 0.0634,
      "step": 3687
    },
    {
      "epoch": 0.8474264705882353,
      "grad_norm": 1.1198787689208984,
      "learning_rate": 9.228962418300655e-06,
      "loss": 0.0864,
      "step": 3688
    },
    {
      "epoch": 0.84765625,
      "grad_norm": 1.0224937200546265,
      "learning_rate": 9.228451797385621e-06,
      "loss": 0.051,
      "step": 3689
    },
    {
      "epoch": 0.8478860294117647,
      "grad_norm": 0.9513416886329651,
      "learning_rate": 9.227941176470589e-06,
      "loss": 0.0598,
      "step": 3690
    },
    {
      "epoch": 0.8481158088235294,
      "grad_norm": 0.9174076318740845,
      "learning_rate": 9.227430555555557e-06,
      "loss": 0.0616,
      "step": 3691
    },
    {
      "epoch": 0.8483455882352942,
      "grad_norm": 1.087297797203064,
      "learning_rate": 9.226919934640523e-06,
      "loss": 0.0603,
      "step": 3692
    },
    {
      "epoch": 0.8485753676470589,
      "grad_norm": 0.81187504529953,
      "learning_rate": 9.226409313725491e-06,
      "loss": 0.0598,
      "step": 3693
    },
    {
      "epoch": 0.8488051470588235,
      "grad_norm": 1.0120645761489868,
      "learning_rate": 9.225898692810459e-06,
      "loss": 0.082,
      "step": 3694
    },
    {
      "epoch": 0.8490349264705882,
      "grad_norm": 1.1237250566482544,
      "learning_rate": 9.225388071895425e-06,
      "loss": 0.1354,
      "step": 3695
    },
    {
      "epoch": 0.8492647058823529,
      "grad_norm": 1.1736754179000854,
      "learning_rate": 9.224877450980393e-06,
      "loss": 0.1159,
      "step": 3696
    },
    {
      "epoch": 0.8494944852941176,
      "grad_norm": 0.6923692226409912,
      "learning_rate": 9.22436683006536e-06,
      "loss": 0.0462,
      "step": 3697
    },
    {
      "epoch": 0.8497242647058824,
      "grad_norm": 1.080056071281433,
      "learning_rate": 9.223856209150329e-06,
      "loss": 0.0752,
      "step": 3698
    },
    {
      "epoch": 0.8499540441176471,
      "grad_norm": 0.9103400707244873,
      "learning_rate": 9.223345588235295e-06,
      "loss": 0.0579,
      "step": 3699
    },
    {
      "epoch": 0.8501838235294118,
      "grad_norm": 0.871526837348938,
      "learning_rate": 9.222834967320263e-06,
      "loss": 0.0584,
      "step": 3700
    },
    {
      "epoch": 0.8504136029411765,
      "grad_norm": 1.268661618232727,
      "learning_rate": 9.222324346405229e-06,
      "loss": 0.089,
      "step": 3701
    },
    {
      "epoch": 0.8506433823529411,
      "grad_norm": 1.243508219718933,
      "learning_rate": 9.221813725490197e-06,
      "loss": 0.0898,
      "step": 3702
    },
    {
      "epoch": 0.8508731617647058,
      "grad_norm": 1.0236839056015015,
      "learning_rate": 9.221303104575165e-06,
      "loss": 0.0728,
      "step": 3703
    },
    {
      "epoch": 0.8511029411764706,
      "grad_norm": 0.9291144609451294,
      "learning_rate": 9.22079248366013e-06,
      "loss": 0.052,
      "step": 3704
    },
    {
      "epoch": 0.8513327205882353,
      "grad_norm": 0.9752129316329956,
      "learning_rate": 9.220281862745099e-06,
      "loss": 0.0488,
      "step": 3705
    },
    {
      "epoch": 0.8515625,
      "grad_norm": 0.9079030752182007,
      "learning_rate": 9.219771241830066e-06,
      "loss": 0.0704,
      "step": 3706
    },
    {
      "epoch": 0.8517922794117647,
      "grad_norm": 0.8628131151199341,
      "learning_rate": 9.219260620915034e-06,
      "loss": 0.067,
      "step": 3707
    },
    {
      "epoch": 0.8520220588235294,
      "grad_norm": 1.1105213165283203,
      "learning_rate": 9.21875e-06,
      "loss": 0.0625,
      "step": 3708
    },
    {
      "epoch": 0.8522518382352942,
      "grad_norm": 1.0987417697906494,
      "learning_rate": 9.218239379084968e-06,
      "loss": 0.0573,
      "step": 3709
    },
    {
      "epoch": 0.8524816176470589,
      "grad_norm": 1.035628080368042,
      "learning_rate": 9.217728758169934e-06,
      "loss": 0.077,
      "step": 3710
    },
    {
      "epoch": 0.8527113970588235,
      "grad_norm": 0.931869626045227,
      "learning_rate": 9.217218137254902e-06,
      "loss": 0.0675,
      "step": 3711
    },
    {
      "epoch": 0.8529411764705882,
      "grad_norm": 0.8491794466972351,
      "learning_rate": 9.21670751633987e-06,
      "loss": 0.068,
      "step": 3712
    },
    {
      "epoch": 0.8531709558823529,
      "grad_norm": 1.0808992385864258,
      "learning_rate": 9.216196895424836e-06,
      "loss": 0.0761,
      "step": 3713
    },
    {
      "epoch": 0.8534007352941176,
      "grad_norm": 1.1038919687271118,
      "learning_rate": 9.215686274509804e-06,
      "loss": 0.0773,
      "step": 3714
    },
    {
      "epoch": 0.8536305147058824,
      "grad_norm": 0.9646753072738647,
      "learning_rate": 9.215175653594772e-06,
      "loss": 0.0672,
      "step": 3715
    },
    {
      "epoch": 0.8538602941176471,
      "grad_norm": 1.0643010139465332,
      "learning_rate": 9.21466503267974e-06,
      "loss": 0.1123,
      "step": 3716
    },
    {
      "epoch": 0.8540900735294118,
      "grad_norm": 1.2749007940292358,
      "learning_rate": 9.214154411764706e-06,
      "loss": 0.0969,
      "step": 3717
    },
    {
      "epoch": 0.8543198529411765,
      "grad_norm": 1.472728967666626,
      "learning_rate": 9.213643790849674e-06,
      "loss": 0.0958,
      "step": 3718
    },
    {
      "epoch": 0.8545496323529411,
      "grad_norm": 1.4472323656082153,
      "learning_rate": 9.213133169934642e-06,
      "loss": 0.097,
      "step": 3719
    },
    {
      "epoch": 0.8547794117647058,
      "grad_norm": 1.1840001344680786,
      "learning_rate": 9.212622549019608e-06,
      "loss": 0.0663,
      "step": 3720
    },
    {
      "epoch": 0.8550091911764706,
      "grad_norm": 0.8631733059883118,
      "learning_rate": 9.212111928104576e-06,
      "loss": 0.0405,
      "step": 3721
    },
    {
      "epoch": 0.8552389705882353,
      "grad_norm": 1.1815152168273926,
      "learning_rate": 9.211601307189542e-06,
      "loss": 0.0746,
      "step": 3722
    },
    {
      "epoch": 0.85546875,
      "grad_norm": 1.2797001600265503,
      "learning_rate": 9.211090686274512e-06,
      "loss": 0.0817,
      "step": 3723
    },
    {
      "epoch": 0.8556985294117647,
      "grad_norm": 1.0679347515106201,
      "learning_rate": 9.210580065359478e-06,
      "loss": 0.0711,
      "step": 3724
    },
    {
      "epoch": 0.8559283088235294,
      "grad_norm": 1.0631903409957886,
      "learning_rate": 9.210069444444446e-06,
      "loss": 0.0893,
      "step": 3725
    },
    {
      "epoch": 0.8561580882352942,
      "grad_norm": 1.3715014457702637,
      "learning_rate": 9.209558823529412e-06,
      "loss": 0.0968,
      "step": 3726
    },
    {
      "epoch": 0.8563878676470589,
      "grad_norm": 0.973752498626709,
      "learning_rate": 9.20904820261438e-06,
      "loss": 0.0846,
      "step": 3727
    },
    {
      "epoch": 0.8566176470588235,
      "grad_norm": 1.1943228244781494,
      "learning_rate": 9.208537581699348e-06,
      "loss": 0.074,
      "step": 3728
    },
    {
      "epoch": 0.8568474264705882,
      "grad_norm": 1.5414797067642212,
      "learning_rate": 9.208026960784314e-06,
      "loss": 0.1239,
      "step": 3729
    },
    {
      "epoch": 0.8570772058823529,
      "grad_norm": 1.258174180984497,
      "learning_rate": 9.207516339869282e-06,
      "loss": 0.0909,
      "step": 3730
    },
    {
      "epoch": 0.8573069852941176,
      "grad_norm": 1.05997896194458,
      "learning_rate": 9.20700571895425e-06,
      "loss": 0.0843,
      "step": 3731
    },
    {
      "epoch": 0.8575367647058824,
      "grad_norm": 0.9889180064201355,
      "learning_rate": 9.206495098039217e-06,
      "loss": 0.0996,
      "step": 3732
    },
    {
      "epoch": 0.8577665441176471,
      "grad_norm": 1.197075366973877,
      "learning_rate": 9.205984477124183e-06,
      "loss": 0.0942,
      "step": 3733
    },
    {
      "epoch": 0.8579963235294118,
      "grad_norm": 1.1426312923431396,
      "learning_rate": 9.205473856209151e-06,
      "loss": 0.0683,
      "step": 3734
    },
    {
      "epoch": 0.8582261029411765,
      "grad_norm": 1.0291030406951904,
      "learning_rate": 9.20496323529412e-06,
      "loss": 0.0876,
      "step": 3735
    },
    {
      "epoch": 0.8584558823529411,
      "grad_norm": 1.0206607580184937,
      "learning_rate": 9.204452614379085e-06,
      "loss": 0.0698,
      "step": 3736
    },
    {
      "epoch": 0.8586856617647058,
      "grad_norm": 1.012506127357483,
      "learning_rate": 9.203941993464053e-06,
      "loss": 0.0726,
      "step": 3737
    },
    {
      "epoch": 0.8589154411764706,
      "grad_norm": 0.9594590067863464,
      "learning_rate": 9.20343137254902e-06,
      "loss": 0.0461,
      "step": 3738
    },
    {
      "epoch": 0.8591452205882353,
      "grad_norm": 0.8409956693649292,
      "learning_rate": 9.202920751633987e-06,
      "loss": 0.0607,
      "step": 3739
    },
    {
      "epoch": 0.859375,
      "grad_norm": 0.8299585580825806,
      "learning_rate": 9.202410130718955e-06,
      "loss": 0.0543,
      "step": 3740
    },
    {
      "epoch": 0.8596047794117647,
      "grad_norm": 0.9309160709381104,
      "learning_rate": 9.201899509803923e-06,
      "loss": 0.0661,
      "step": 3741
    },
    {
      "epoch": 0.8598345588235294,
      "grad_norm": 0.8823168277740479,
      "learning_rate": 9.201388888888889e-06,
      "loss": 0.0721,
      "step": 3742
    },
    {
      "epoch": 0.8600643382352942,
      "grad_norm": 1.1088321208953857,
      "learning_rate": 9.200878267973857e-06,
      "loss": 0.0457,
      "step": 3743
    },
    {
      "epoch": 0.8602941176470589,
      "grad_norm": 1.0367399454116821,
      "learning_rate": 9.200367647058825e-06,
      "loss": 0.0517,
      "step": 3744
    },
    {
      "epoch": 0.8605238970588235,
      "grad_norm": 0.6818814277648926,
      "learning_rate": 9.199857026143791e-06,
      "loss": 0.0349,
      "step": 3745
    },
    {
      "epoch": 0.8607536764705882,
      "grad_norm": 1.001978874206543,
      "learning_rate": 9.199346405228759e-06,
      "loss": 0.0642,
      "step": 3746
    },
    {
      "epoch": 0.8609834558823529,
      "grad_norm": 1.3950719833374023,
      "learning_rate": 9.198835784313727e-06,
      "loss": 0.0702,
      "step": 3747
    },
    {
      "epoch": 0.8612132352941176,
      "grad_norm": 0.9984630346298218,
      "learning_rate": 9.198325163398693e-06,
      "loss": 0.0737,
      "step": 3748
    },
    {
      "epoch": 0.8614430147058824,
      "grad_norm": 1.0483921766281128,
      "learning_rate": 9.19781454248366e-06,
      "loss": 0.069,
      "step": 3749
    },
    {
      "epoch": 0.8616727941176471,
      "grad_norm": 0.946051836013794,
      "learning_rate": 9.197303921568627e-06,
      "loss": 0.0644,
      "step": 3750
    },
    {
      "epoch": 0.8619025735294118,
      "grad_norm": 1.0831670761108398,
      "learning_rate": 9.196793300653596e-06,
      "loss": 0.0658,
      "step": 3751
    },
    {
      "epoch": 0.8621323529411765,
      "grad_norm": 1.0359212160110474,
      "learning_rate": 9.196282679738563e-06,
      "loss": 0.0658,
      "step": 3752
    },
    {
      "epoch": 0.8623621323529411,
      "grad_norm": 1.0088955163955688,
      "learning_rate": 9.19577205882353e-06,
      "loss": 0.0555,
      "step": 3753
    },
    {
      "epoch": 0.8625919117647058,
      "grad_norm": 1.1971627473831177,
      "learning_rate": 9.195261437908497e-06,
      "loss": 0.0804,
      "step": 3754
    },
    {
      "epoch": 0.8628216911764706,
      "grad_norm": 1.11161208152771,
      "learning_rate": 9.194750816993465e-06,
      "loss": 0.0401,
      "step": 3755
    },
    {
      "epoch": 0.8630514705882353,
      "grad_norm": 1.4680089950561523,
      "learning_rate": 9.194240196078432e-06,
      "loss": 0.0783,
      "step": 3756
    },
    {
      "epoch": 0.86328125,
      "grad_norm": 0.9491825699806213,
      "learning_rate": 9.193729575163399e-06,
      "loss": 0.0612,
      "step": 3757
    },
    {
      "epoch": 0.8635110294117647,
      "grad_norm": 1.4089760780334473,
      "learning_rate": 9.193218954248366e-06,
      "loss": 0.0896,
      "step": 3758
    },
    {
      "epoch": 0.8637408088235294,
      "grad_norm": 1.203832745552063,
      "learning_rate": 9.192708333333334e-06,
      "loss": 0.0735,
      "step": 3759
    },
    {
      "epoch": 0.8639705882352942,
      "grad_norm": 0.8867641687393188,
      "learning_rate": 9.192197712418302e-06,
      "loss": 0.056,
      "step": 3760
    },
    {
      "epoch": 0.8642003676470589,
      "grad_norm": 0.9796332716941833,
      "learning_rate": 9.191687091503268e-06,
      "loss": 0.0623,
      "step": 3761
    },
    {
      "epoch": 0.8644301470588235,
      "grad_norm": 1.306675672531128,
      "learning_rate": 9.191176470588236e-06,
      "loss": 0.0921,
      "step": 3762
    },
    {
      "epoch": 0.8646599264705882,
      "grad_norm": 0.7697691321372986,
      "learning_rate": 9.190665849673204e-06,
      "loss": 0.0437,
      "step": 3763
    },
    {
      "epoch": 0.8648897058823529,
      "grad_norm": 1.1337029933929443,
      "learning_rate": 9.19015522875817e-06,
      "loss": 0.0688,
      "step": 3764
    },
    {
      "epoch": 0.8651194852941176,
      "grad_norm": 1.1544103622436523,
      "learning_rate": 9.189644607843138e-06,
      "loss": 0.0824,
      "step": 3765
    },
    {
      "epoch": 0.8653492647058824,
      "grad_norm": 1.2114899158477783,
      "learning_rate": 9.189133986928104e-06,
      "loss": 0.0624,
      "step": 3766
    },
    {
      "epoch": 0.8655790441176471,
      "grad_norm": 0.9488057494163513,
      "learning_rate": 9.188623366013074e-06,
      "loss": 0.0859,
      "step": 3767
    },
    {
      "epoch": 0.8658088235294118,
      "grad_norm": 1.1844791173934937,
      "learning_rate": 9.18811274509804e-06,
      "loss": 0.0666,
      "step": 3768
    },
    {
      "epoch": 0.8660386029411765,
      "grad_norm": 0.8672359585762024,
      "learning_rate": 9.187602124183008e-06,
      "loss": 0.0649,
      "step": 3769
    },
    {
      "epoch": 0.8662683823529411,
      "grad_norm": 1.004709005355835,
      "learning_rate": 9.187091503267974e-06,
      "loss": 0.0556,
      "step": 3770
    },
    {
      "epoch": 0.8664981617647058,
      "grad_norm": 1.0355346202850342,
      "learning_rate": 9.186580882352942e-06,
      "loss": 0.0814,
      "step": 3771
    },
    {
      "epoch": 0.8667279411764706,
      "grad_norm": 1.2852978706359863,
      "learning_rate": 9.18607026143791e-06,
      "loss": 0.0747,
      "step": 3772
    },
    {
      "epoch": 0.8669577205882353,
      "grad_norm": 0.8674978613853455,
      "learning_rate": 9.185559640522876e-06,
      "loss": 0.059,
      "step": 3773
    },
    {
      "epoch": 0.8671875,
      "grad_norm": 1.2767277956008911,
      "learning_rate": 9.185049019607844e-06,
      "loss": 0.0651,
      "step": 3774
    },
    {
      "epoch": 0.8674172794117647,
      "grad_norm": 1.1504359245300293,
      "learning_rate": 9.184538398692812e-06,
      "loss": 0.0926,
      "step": 3775
    },
    {
      "epoch": 0.8676470588235294,
      "grad_norm": 1.271632194519043,
      "learning_rate": 9.18402777777778e-06,
      "loss": 0.0843,
      "step": 3776
    },
    {
      "epoch": 0.8678768382352942,
      "grad_norm": 0.7710122466087341,
      "learning_rate": 9.183517156862746e-06,
      "loss": 0.0313,
      "step": 3777
    },
    {
      "epoch": 0.8681066176470589,
      "grad_norm": 1.3637138605117798,
      "learning_rate": 9.183006535947713e-06,
      "loss": 0.0701,
      "step": 3778
    },
    {
      "epoch": 0.8683363970588235,
      "grad_norm": 1.1003026962280273,
      "learning_rate": 9.182495915032681e-06,
      "loss": 0.0623,
      "step": 3779
    },
    {
      "epoch": 0.8685661764705882,
      "grad_norm": 0.8874179720878601,
      "learning_rate": 9.181985294117648e-06,
      "loss": 0.0867,
      "step": 3780
    },
    {
      "epoch": 0.8687959558823529,
      "grad_norm": 0.9462749361991882,
      "learning_rate": 9.181474673202615e-06,
      "loss": 0.0705,
      "step": 3781
    },
    {
      "epoch": 0.8690257352941176,
      "grad_norm": 0.8805559277534485,
      "learning_rate": 9.180964052287582e-06,
      "loss": 0.0534,
      "step": 3782
    },
    {
      "epoch": 0.8692555147058824,
      "grad_norm": 1.1585941314697266,
      "learning_rate": 9.18045343137255e-06,
      "loss": 0.0782,
      "step": 3783
    },
    {
      "epoch": 0.8694852941176471,
      "grad_norm": 0.718344509601593,
      "learning_rate": 9.179942810457517e-06,
      "loss": 0.0697,
      "step": 3784
    },
    {
      "epoch": 0.8697150735294118,
      "grad_norm": 0.905985414981842,
      "learning_rate": 9.179432189542483e-06,
      "loss": 0.0618,
      "step": 3785
    },
    {
      "epoch": 0.8699448529411765,
      "grad_norm": 0.9700683355331421,
      "learning_rate": 9.178921568627451e-06,
      "loss": 0.0662,
      "step": 3786
    },
    {
      "epoch": 0.8701746323529411,
      "grad_norm": 0.9725895524024963,
      "learning_rate": 9.17841094771242e-06,
      "loss": 0.0662,
      "step": 3787
    },
    {
      "epoch": 0.8704044117647058,
      "grad_norm": 1.0070570707321167,
      "learning_rate": 9.177900326797387e-06,
      "loss": 0.0669,
      "step": 3788
    },
    {
      "epoch": 0.8706341911764706,
      "grad_norm": 1.208620548248291,
      "learning_rate": 9.177389705882353e-06,
      "loss": 0.0757,
      "step": 3789
    },
    {
      "epoch": 0.8708639705882353,
      "grad_norm": 1.034620761871338,
      "learning_rate": 9.176879084967321e-06,
      "loss": 0.0742,
      "step": 3790
    },
    {
      "epoch": 0.87109375,
      "grad_norm": 0.880387008190155,
      "learning_rate": 9.176368464052289e-06,
      "loss": 0.0562,
      "step": 3791
    },
    {
      "epoch": 0.8713235294117647,
      "grad_norm": 1.2190093994140625,
      "learning_rate": 9.175857843137255e-06,
      "loss": 0.0797,
      "step": 3792
    },
    {
      "epoch": 0.8715533088235294,
      "grad_norm": 0.9072455763816833,
      "learning_rate": 9.175347222222223e-06,
      "loss": 0.0724,
      "step": 3793
    },
    {
      "epoch": 0.8717830882352942,
      "grad_norm": 1.4052040576934814,
      "learning_rate": 9.174836601307189e-06,
      "loss": 0.0798,
      "step": 3794
    },
    {
      "epoch": 0.8720128676470589,
      "grad_norm": 1.1381251811981201,
      "learning_rate": 9.174325980392159e-06,
      "loss": 0.0622,
      "step": 3795
    },
    {
      "epoch": 0.8722426470588235,
      "grad_norm": 1.2249053716659546,
      "learning_rate": 9.173815359477125e-06,
      "loss": 0.0883,
      "step": 3796
    },
    {
      "epoch": 0.8724724264705882,
      "grad_norm": 1.0116190910339355,
      "learning_rate": 9.173304738562093e-06,
      "loss": 0.069,
      "step": 3797
    },
    {
      "epoch": 0.8727022058823529,
      "grad_norm": 0.8996759653091431,
      "learning_rate": 9.172794117647059e-06,
      "loss": 0.064,
      "step": 3798
    },
    {
      "epoch": 0.8729319852941176,
      "grad_norm": 0.7310687303543091,
      "learning_rate": 9.172283496732027e-06,
      "loss": 0.0566,
      "step": 3799
    },
    {
      "epoch": 0.8731617647058824,
      "grad_norm": 0.9347654581069946,
      "learning_rate": 9.171772875816995e-06,
      "loss": 0.0813,
      "step": 3800
    },
    {
      "epoch": 0.8733915441176471,
      "grad_norm": 1.4118317365646362,
      "learning_rate": 9.17126225490196e-06,
      "loss": 0.1053,
      "step": 3801
    },
    {
      "epoch": 0.8736213235294118,
      "grad_norm": 0.8815721273422241,
      "learning_rate": 9.170751633986929e-06,
      "loss": 0.0653,
      "step": 3802
    },
    {
      "epoch": 0.8738511029411765,
      "grad_norm": 1.4515742063522339,
      "learning_rate": 9.170241013071896e-06,
      "loss": 0.0756,
      "step": 3803
    },
    {
      "epoch": 0.8740808823529411,
      "grad_norm": 1.1836551427841187,
      "learning_rate": 9.169730392156864e-06,
      "loss": 0.0739,
      "step": 3804
    },
    {
      "epoch": 0.8743106617647058,
      "grad_norm": 1.9290977716445923,
      "learning_rate": 9.16921977124183e-06,
      "loss": 0.0908,
      "step": 3805
    },
    {
      "epoch": 0.8745404411764706,
      "grad_norm": 1.2801649570465088,
      "learning_rate": 9.168709150326798e-06,
      "loss": 0.0624,
      "step": 3806
    },
    {
      "epoch": 0.8747702205882353,
      "grad_norm": 1.2561143636703491,
      "learning_rate": 9.168198529411766e-06,
      "loss": 0.132,
      "step": 3807
    },
    {
      "epoch": 0.875,
      "grad_norm": 0.95173579454422,
      "learning_rate": 9.167687908496732e-06,
      "loss": 0.0773,
      "step": 3808
    },
    {
      "epoch": 0.8752297794117647,
      "grad_norm": 0.9715586304664612,
      "learning_rate": 9.1671772875817e-06,
      "loss": 0.0699,
      "step": 3809
    },
    {
      "epoch": 0.8754595588235294,
      "grad_norm": 1.2862756252288818,
      "learning_rate": 9.166666666666666e-06,
      "loss": 0.1053,
      "step": 3810
    },
    {
      "epoch": 0.8756893382352942,
      "grad_norm": 1.0514540672302246,
      "learning_rate": 9.166156045751636e-06,
      "loss": 0.09,
      "step": 3811
    },
    {
      "epoch": 0.8759191176470589,
      "grad_norm": 1.167465329170227,
      "learning_rate": 9.165645424836602e-06,
      "loss": 0.0727,
      "step": 3812
    },
    {
      "epoch": 0.8761488970588235,
      "grad_norm": 1.0122177600860596,
      "learning_rate": 9.16513480392157e-06,
      "loss": 0.0691,
      "step": 3813
    },
    {
      "epoch": 0.8763786764705882,
      "grad_norm": 1.1078368425369263,
      "learning_rate": 9.164624183006536e-06,
      "loss": 0.0635,
      "step": 3814
    },
    {
      "epoch": 0.8766084558823529,
      "grad_norm": 0.8121044039726257,
      "learning_rate": 9.164113562091504e-06,
      "loss": 0.0776,
      "step": 3815
    },
    {
      "epoch": 0.8768382352941176,
      "grad_norm": 0.7998133897781372,
      "learning_rate": 9.163602941176472e-06,
      "loss": 0.0598,
      "step": 3816
    },
    {
      "epoch": 0.8770680147058824,
      "grad_norm": 1.0910241603851318,
      "learning_rate": 9.163092320261438e-06,
      "loss": 0.0663,
      "step": 3817
    },
    {
      "epoch": 0.8772977941176471,
      "grad_norm": 0.8296198844909668,
      "learning_rate": 9.162581699346406e-06,
      "loss": 0.0819,
      "step": 3818
    },
    {
      "epoch": 0.8775275735294118,
      "grad_norm": 0.8735722303390503,
      "learning_rate": 9.162071078431374e-06,
      "loss": 0.0858,
      "step": 3819
    },
    {
      "epoch": 0.8777573529411765,
      "grad_norm": 0.9212071299552917,
      "learning_rate": 9.161560457516342e-06,
      "loss": 0.0561,
      "step": 3820
    },
    {
      "epoch": 0.8779871323529411,
      "grad_norm": 1.0983787775039673,
      "learning_rate": 9.161049836601308e-06,
      "loss": 0.092,
      "step": 3821
    },
    {
      "epoch": 0.8782169117647058,
      "grad_norm": 0.8544825911521912,
      "learning_rate": 9.160539215686276e-06,
      "loss": 0.0533,
      "step": 3822
    },
    {
      "epoch": 0.8784466911764706,
      "grad_norm": 1.0937942266464233,
      "learning_rate": 9.160028594771244e-06,
      "loss": 0.0806,
      "step": 3823
    },
    {
      "epoch": 0.8786764705882353,
      "grad_norm": 1.2199254035949707,
      "learning_rate": 9.15951797385621e-06,
      "loss": 0.0555,
      "step": 3824
    },
    {
      "epoch": 0.87890625,
      "grad_norm": 1.3850667476654053,
      "learning_rate": 9.159007352941178e-06,
      "loss": 0.0354,
      "step": 3825
    },
    {
      "epoch": 0.8791360294117647,
      "grad_norm": 0.8326379060745239,
      "learning_rate": 9.158496732026144e-06,
      "loss": 0.0732,
      "step": 3826
    },
    {
      "epoch": 0.8793658088235294,
      "grad_norm": 1.1268184185028076,
      "learning_rate": 9.157986111111112e-06,
      "loss": 0.0734,
      "step": 3827
    },
    {
      "epoch": 0.8795955882352942,
      "grad_norm": 1.1543986797332764,
      "learning_rate": 9.15747549019608e-06,
      "loss": 0.0718,
      "step": 3828
    },
    {
      "epoch": 0.8798253676470589,
      "grad_norm": 0.9928836226463318,
      "learning_rate": 9.156964869281046e-06,
      "loss": 0.0813,
      "step": 3829
    },
    {
      "epoch": 0.8800551470588235,
      "grad_norm": 1.155646800994873,
      "learning_rate": 9.156454248366013e-06,
      "loss": 0.0715,
      "step": 3830
    },
    {
      "epoch": 0.8802849264705882,
      "grad_norm": 1.2749124765396118,
      "learning_rate": 9.155943627450981e-06,
      "loss": 0.0565,
      "step": 3831
    },
    {
      "epoch": 0.8805147058823529,
      "grad_norm": 1.073441982269287,
      "learning_rate": 9.15543300653595e-06,
      "loss": 0.0607,
      "step": 3832
    },
    {
      "epoch": 0.8807444852941176,
      "grad_norm": 1.040537714958191,
      "learning_rate": 9.154922385620915e-06,
      "loss": 0.0914,
      "step": 3833
    },
    {
      "epoch": 0.8809742647058824,
      "grad_norm": 1.2350728511810303,
      "learning_rate": 9.154411764705883e-06,
      "loss": 0.0723,
      "step": 3834
    },
    {
      "epoch": 0.8812040441176471,
      "grad_norm": 1.100500464439392,
      "learning_rate": 9.153901143790851e-06,
      "loss": 0.067,
      "step": 3835
    },
    {
      "epoch": 0.8814338235294118,
      "grad_norm": 1.1520692110061646,
      "learning_rate": 9.153390522875817e-06,
      "loss": 0.0834,
      "step": 3836
    },
    {
      "epoch": 0.8816636029411765,
      "grad_norm": 0.9382896423339844,
      "learning_rate": 9.152879901960785e-06,
      "loss": 0.0634,
      "step": 3837
    },
    {
      "epoch": 0.8818933823529411,
      "grad_norm": 1.1923962831497192,
      "learning_rate": 9.152369281045751e-06,
      "loss": 0.0597,
      "step": 3838
    },
    {
      "epoch": 0.8821231617647058,
      "grad_norm": 0.9883930087089539,
      "learning_rate": 9.151858660130721e-06,
      "loss": 0.0685,
      "step": 3839
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 1.288679599761963,
      "learning_rate": 9.151348039215687e-06,
      "loss": 0.078,
      "step": 3840
    },
    {
      "epoch": 0.8825827205882353,
      "grad_norm": 1.3677818775177002,
      "learning_rate": 9.150837418300655e-06,
      "loss": 0.093,
      "step": 3841
    },
    {
      "epoch": 0.8828125,
      "grad_norm": 0.9515448808670044,
      "learning_rate": 9.150326797385621e-06,
      "loss": 0.0644,
      "step": 3842
    },
    {
      "epoch": 0.8830422794117647,
      "grad_norm": 1.0517446994781494,
      "learning_rate": 9.149816176470589e-06,
      "loss": 0.0782,
      "step": 3843
    },
    {
      "epoch": 0.8832720588235294,
      "grad_norm": 0.9770963788032532,
      "learning_rate": 9.149305555555557e-06,
      "loss": 0.0692,
      "step": 3844
    },
    {
      "epoch": 0.8835018382352942,
      "grad_norm": 1.375793218612671,
      "learning_rate": 9.148794934640523e-06,
      "loss": 0.1116,
      "step": 3845
    },
    {
      "epoch": 0.8837316176470589,
      "grad_norm": 1.0653676986694336,
      "learning_rate": 9.14828431372549e-06,
      "loss": 0.0682,
      "step": 3846
    },
    {
      "epoch": 0.8839613970588235,
      "grad_norm": 0.7530566453933716,
      "learning_rate": 9.147773692810459e-06,
      "loss": 0.0481,
      "step": 3847
    },
    {
      "epoch": 0.8841911764705882,
      "grad_norm": 1.3880929946899414,
      "learning_rate": 9.147263071895427e-06,
      "loss": 0.0926,
      "step": 3848
    },
    {
      "epoch": 0.8844209558823529,
      "grad_norm": 1.3667809963226318,
      "learning_rate": 9.146752450980393e-06,
      "loss": 0.0881,
      "step": 3849
    },
    {
      "epoch": 0.8846507352941176,
      "grad_norm": 0.8209062814712524,
      "learning_rate": 9.14624183006536e-06,
      "loss": 0.0776,
      "step": 3850
    },
    {
      "epoch": 0.8848805147058824,
      "grad_norm": 1.3319262266159058,
      "learning_rate": 9.145731209150328e-06,
      "loss": 0.11,
      "step": 3851
    },
    {
      "epoch": 0.8851102941176471,
      "grad_norm": 1.264111042022705,
      "learning_rate": 9.145220588235295e-06,
      "loss": 0.0752,
      "step": 3852
    },
    {
      "epoch": 0.8853400735294118,
      "grad_norm": 1.1316052675247192,
      "learning_rate": 9.144709967320262e-06,
      "loss": 0.0751,
      "step": 3853
    },
    {
      "epoch": 0.8855698529411765,
      "grad_norm": 1.3656542301177979,
      "learning_rate": 9.144199346405229e-06,
      "loss": 0.0922,
      "step": 3854
    },
    {
      "epoch": 0.8857996323529411,
      "grad_norm": 1.0954662561416626,
      "learning_rate": 9.143688725490198e-06,
      "loss": 0.1034,
      "step": 3855
    },
    {
      "epoch": 0.8860294117647058,
      "grad_norm": 1.0019794702529907,
      "learning_rate": 9.143178104575164e-06,
      "loss": 0.0696,
      "step": 3856
    },
    {
      "epoch": 0.8862591911764706,
      "grad_norm": 1.0213134288787842,
      "learning_rate": 9.142667483660132e-06,
      "loss": 0.0675,
      "step": 3857
    },
    {
      "epoch": 0.8864889705882353,
      "grad_norm": 0.8999089002609253,
      "learning_rate": 9.142156862745098e-06,
      "loss": 0.0781,
      "step": 3858
    },
    {
      "epoch": 0.88671875,
      "grad_norm": 1.0157535076141357,
      "learning_rate": 9.141646241830066e-06,
      "loss": 0.0619,
      "step": 3859
    },
    {
      "epoch": 0.8869485294117647,
      "grad_norm": 1.4312934875488281,
      "learning_rate": 9.141135620915034e-06,
      "loss": 0.1025,
      "step": 3860
    },
    {
      "epoch": 0.8871783088235294,
      "grad_norm": 0.9483217597007751,
      "learning_rate": 9.140625e-06,
      "loss": 0.0447,
      "step": 3861
    },
    {
      "epoch": 0.8874080882352942,
      "grad_norm": 0.7997746467590332,
      "learning_rate": 9.140114379084968e-06,
      "loss": 0.0429,
      "step": 3862
    },
    {
      "epoch": 0.8876378676470589,
      "grad_norm": 1.0111442804336548,
      "learning_rate": 9.139603758169934e-06,
      "loss": 0.0607,
      "step": 3863
    },
    {
      "epoch": 0.8878676470588235,
      "grad_norm": 1.0089865922927856,
      "learning_rate": 9.139093137254902e-06,
      "loss": 0.0948,
      "step": 3864
    },
    {
      "epoch": 0.8880974264705882,
      "grad_norm": 1.6850517988204956,
      "learning_rate": 9.13858251633987e-06,
      "loss": 0.0753,
      "step": 3865
    },
    {
      "epoch": 0.8883272058823529,
      "grad_norm": 0.8010952472686768,
      "learning_rate": 9.138071895424838e-06,
      "loss": 0.0633,
      "step": 3866
    },
    {
      "epoch": 0.8885569852941176,
      "grad_norm": 1.1589704751968384,
      "learning_rate": 9.137561274509804e-06,
      "loss": 0.0959,
      "step": 3867
    },
    {
      "epoch": 0.8887867647058824,
      "grad_norm": 0.8054187297821045,
      "learning_rate": 9.137050653594772e-06,
      "loss": 0.051,
      "step": 3868
    },
    {
      "epoch": 0.8890165441176471,
      "grad_norm": 0.7086247801780701,
      "learning_rate": 9.13654003267974e-06,
      "loss": 0.0441,
      "step": 3869
    },
    {
      "epoch": 0.8892463235294118,
      "grad_norm": 0.8976821899414062,
      "learning_rate": 9.136029411764706e-06,
      "loss": 0.0653,
      "step": 3870
    },
    {
      "epoch": 0.8894761029411765,
      "grad_norm": 0.842887282371521,
      "learning_rate": 9.135518790849674e-06,
      "loss": 0.0682,
      "step": 3871
    },
    {
      "epoch": 0.8897058823529411,
      "grad_norm": 0.9653258919715881,
      "learning_rate": 9.135008169934642e-06,
      "loss": 0.0523,
      "step": 3872
    },
    {
      "epoch": 0.8899356617647058,
      "grad_norm": 1.3249871730804443,
      "learning_rate": 9.134497549019608e-06,
      "loss": 0.0472,
      "step": 3873
    },
    {
      "epoch": 0.8901654411764706,
      "grad_norm": 0.9266092777252197,
      "learning_rate": 9.133986928104576e-06,
      "loss": 0.0821,
      "step": 3874
    },
    {
      "epoch": 0.8903952205882353,
      "grad_norm": 1.032950758934021,
      "learning_rate": 9.133476307189544e-06,
      "loss": 0.0623,
      "step": 3875
    },
    {
      "epoch": 0.890625,
      "grad_norm": 0.7934132218360901,
      "learning_rate": 9.132965686274511e-06,
      "loss": 0.0437,
      "step": 3876
    },
    {
      "epoch": 0.8908547794117647,
      "grad_norm": 1.011803150177002,
      "learning_rate": 9.132455065359478e-06,
      "loss": 0.0576,
      "step": 3877
    },
    {
      "epoch": 0.8910845588235294,
      "grad_norm": 1.1096320152282715,
      "learning_rate": 9.131944444444445e-06,
      "loss": 0.0982,
      "step": 3878
    },
    {
      "epoch": 0.8913143382352942,
      "grad_norm": 1.3714431524276733,
      "learning_rate": 9.131433823529412e-06,
      "loss": 0.1357,
      "step": 3879
    },
    {
      "epoch": 0.8915441176470589,
      "grad_norm": 0.860181987285614,
      "learning_rate": 9.13092320261438e-06,
      "loss": 0.0323,
      "step": 3880
    },
    {
      "epoch": 0.8917738970588235,
      "grad_norm": 1.4894171953201294,
      "learning_rate": 9.130412581699347e-06,
      "loss": 0.0855,
      "step": 3881
    },
    {
      "epoch": 0.8920036764705882,
      "grad_norm": 0.9909557700157166,
      "learning_rate": 9.129901960784313e-06,
      "loss": 0.0557,
      "step": 3882
    },
    {
      "epoch": 0.8922334558823529,
      "grad_norm": 0.9472879767417908,
      "learning_rate": 9.129391339869281e-06,
      "loss": 0.067,
      "step": 3883
    },
    {
      "epoch": 0.8924632352941176,
      "grad_norm": 0.7880618572235107,
      "learning_rate": 9.12888071895425e-06,
      "loss": 0.0464,
      "step": 3884
    },
    {
      "epoch": 0.8926930147058824,
      "grad_norm": 0.8608707189559937,
      "learning_rate": 9.128370098039217e-06,
      "loss": 0.0788,
      "step": 3885
    },
    {
      "epoch": 0.8929227941176471,
      "grad_norm": 0.9644854664802551,
      "learning_rate": 9.127859477124183e-06,
      "loss": 0.0874,
      "step": 3886
    },
    {
      "epoch": 0.8931525735294118,
      "grad_norm": 1.0105689764022827,
      "learning_rate": 9.127348856209151e-06,
      "loss": 0.0648,
      "step": 3887
    },
    {
      "epoch": 0.8933823529411765,
      "grad_norm": 1.2499579191207886,
      "learning_rate": 9.126838235294119e-06,
      "loss": 0.1009,
      "step": 3888
    },
    {
      "epoch": 0.8936121323529411,
      "grad_norm": 1.1755961179733276,
      "learning_rate": 9.126327614379085e-06,
      "loss": 0.0654,
      "step": 3889
    },
    {
      "epoch": 0.8938419117647058,
      "grad_norm": 1.1487059593200684,
      "learning_rate": 9.125816993464053e-06,
      "loss": 0.0917,
      "step": 3890
    },
    {
      "epoch": 0.8940716911764706,
      "grad_norm": 1.1932464838027954,
      "learning_rate": 9.12530637254902e-06,
      "loss": 0.079,
      "step": 3891
    },
    {
      "epoch": 0.8943014705882353,
      "grad_norm": 1.1963865756988525,
      "learning_rate": 9.124795751633989e-06,
      "loss": 0.0809,
      "step": 3892
    },
    {
      "epoch": 0.89453125,
      "grad_norm": 1.8170945644378662,
      "learning_rate": 9.124285130718955e-06,
      "loss": 0.0806,
      "step": 3893
    },
    {
      "epoch": 0.8947610294117647,
      "grad_norm": 1.3836160898208618,
      "learning_rate": 9.123774509803923e-06,
      "loss": 0.0945,
      "step": 3894
    },
    {
      "epoch": 0.8949908088235294,
      "grad_norm": 0.982473611831665,
      "learning_rate": 9.123263888888889e-06,
      "loss": 0.062,
      "step": 3895
    },
    {
      "epoch": 0.8952205882352942,
      "grad_norm": 0.7909700870513916,
      "learning_rate": 9.122753267973857e-06,
      "loss": 0.0524,
      "step": 3896
    },
    {
      "epoch": 0.8954503676470589,
      "grad_norm": 1.1496878862380981,
      "learning_rate": 9.122242647058825e-06,
      "loss": 0.0593,
      "step": 3897
    },
    {
      "epoch": 0.8956801470588235,
      "grad_norm": 1.0690529346466064,
      "learning_rate": 9.12173202614379e-06,
      "loss": 0.069,
      "step": 3898
    },
    {
      "epoch": 0.8959099264705882,
      "grad_norm": 1.0076613426208496,
      "learning_rate": 9.121221405228759e-06,
      "loss": 0.0778,
      "step": 3899
    },
    {
      "epoch": 0.8961397058823529,
      "grad_norm": 1.0429284572601318,
      "learning_rate": 9.120710784313727e-06,
      "loss": 0.0597,
      "step": 3900
    },
    {
      "epoch": 0.8963694852941176,
      "grad_norm": 0.9057517647743225,
      "learning_rate": 9.120200163398694e-06,
      "loss": 0.0594,
      "step": 3901
    },
    {
      "epoch": 0.8965992647058824,
      "grad_norm": 1.2713344097137451,
      "learning_rate": 9.11968954248366e-06,
      "loss": 0.0941,
      "step": 3902
    },
    {
      "epoch": 0.8968290441176471,
      "grad_norm": 0.9823480248451233,
      "learning_rate": 9.119178921568628e-06,
      "loss": 0.0797,
      "step": 3903
    },
    {
      "epoch": 0.8970588235294118,
      "grad_norm": 1.1478996276855469,
      "learning_rate": 9.118668300653596e-06,
      "loss": 0.0906,
      "step": 3904
    },
    {
      "epoch": 0.8972886029411765,
      "grad_norm": 1.05350661277771,
      "learning_rate": 9.118157679738562e-06,
      "loss": 0.0662,
      "step": 3905
    },
    {
      "epoch": 0.8975183823529411,
      "grad_norm": 1.0429881811141968,
      "learning_rate": 9.11764705882353e-06,
      "loss": 0.0746,
      "step": 3906
    },
    {
      "epoch": 0.8977481617647058,
      "grad_norm": 0.7313366532325745,
      "learning_rate": 9.117136437908496e-06,
      "loss": 0.0538,
      "step": 3907
    },
    {
      "epoch": 0.8979779411764706,
      "grad_norm": 1.401767373085022,
      "learning_rate": 9.116625816993464e-06,
      "loss": 0.0726,
      "step": 3908
    },
    {
      "epoch": 0.8982077205882353,
      "grad_norm": 0.9103284478187561,
      "learning_rate": 9.116115196078432e-06,
      "loss": 0.0606,
      "step": 3909
    },
    {
      "epoch": 0.8984375,
      "grad_norm": 1.4200608730316162,
      "learning_rate": 9.1156045751634e-06,
      "loss": 0.0871,
      "step": 3910
    },
    {
      "epoch": 0.8986672794117647,
      "grad_norm": 1.5375303030014038,
      "learning_rate": 9.115093954248366e-06,
      "loss": 0.0929,
      "step": 3911
    },
    {
      "epoch": 0.8988970588235294,
      "grad_norm": 1.0484720468521118,
      "learning_rate": 9.114583333333334e-06,
      "loss": 0.08,
      "step": 3912
    },
    {
      "epoch": 0.8991268382352942,
      "grad_norm": 0.9523903727531433,
      "learning_rate": 9.114072712418302e-06,
      "loss": 0.0699,
      "step": 3913
    },
    {
      "epoch": 0.8993566176470589,
      "grad_norm": 1.1196818351745605,
      "learning_rate": 9.113562091503268e-06,
      "loss": 0.1012,
      "step": 3914
    },
    {
      "epoch": 0.8995863970588235,
      "grad_norm": 1.1698240041732788,
      "learning_rate": 9.113051470588236e-06,
      "loss": 0.0876,
      "step": 3915
    },
    {
      "epoch": 0.8998161764705882,
      "grad_norm": 1.1539642810821533,
      "learning_rate": 9.112540849673204e-06,
      "loss": 0.1069,
      "step": 3916
    },
    {
      "epoch": 0.9000459558823529,
      "grad_norm": 0.9985268115997314,
      "learning_rate": 9.11203022875817e-06,
      "loss": 0.0932,
      "step": 3917
    },
    {
      "epoch": 0.9002757352941176,
      "grad_norm": 1.1340426206588745,
      "learning_rate": 9.111519607843138e-06,
      "loss": 0.0779,
      "step": 3918
    },
    {
      "epoch": 0.9005055147058824,
      "grad_norm": 1.0910354852676392,
      "learning_rate": 9.111008986928104e-06,
      "loss": 0.1176,
      "step": 3919
    },
    {
      "epoch": 0.9007352941176471,
      "grad_norm": 1.217344880104065,
      "learning_rate": 9.110498366013074e-06,
      "loss": 0.0849,
      "step": 3920
    },
    {
      "epoch": 0.9009650735294118,
      "grad_norm": 0.9999057054519653,
      "learning_rate": 9.10998774509804e-06,
      "loss": 0.0691,
      "step": 3921
    },
    {
      "epoch": 0.9011948529411765,
      "grad_norm": 1.2566465139389038,
      "learning_rate": 9.109477124183008e-06,
      "loss": 0.0855,
      "step": 3922
    },
    {
      "epoch": 0.9014246323529411,
      "grad_norm": 0.8677002191543579,
      "learning_rate": 9.108966503267974e-06,
      "loss": 0.0716,
      "step": 3923
    },
    {
      "epoch": 0.9016544117647058,
      "grad_norm": 1.1530427932739258,
      "learning_rate": 9.108455882352942e-06,
      "loss": 0.0687,
      "step": 3924
    },
    {
      "epoch": 0.9018841911764706,
      "grad_norm": 1.274237036705017,
      "learning_rate": 9.10794526143791e-06,
      "loss": 0.0752,
      "step": 3925
    },
    {
      "epoch": 0.9021139705882353,
      "grad_norm": 0.8992312550544739,
      "learning_rate": 9.107434640522876e-06,
      "loss": 0.0731,
      "step": 3926
    },
    {
      "epoch": 0.90234375,
      "grad_norm": 0.9696468114852905,
      "learning_rate": 9.106924019607844e-06,
      "loss": 0.0792,
      "step": 3927
    },
    {
      "epoch": 0.9025735294117647,
      "grad_norm": 1.213377833366394,
      "learning_rate": 9.106413398692811e-06,
      "loss": 0.127,
      "step": 3928
    },
    {
      "epoch": 0.9028033088235294,
      "grad_norm": 0.887405276298523,
      "learning_rate": 9.10590277777778e-06,
      "loss": 0.0588,
      "step": 3929
    },
    {
      "epoch": 0.9030330882352942,
      "grad_norm": 1.4445658922195435,
      "learning_rate": 9.105392156862745e-06,
      "loss": 0.1047,
      "step": 3930
    },
    {
      "epoch": 0.9032628676470589,
      "grad_norm": 0.7577574253082275,
      "learning_rate": 9.104881535947713e-06,
      "loss": 0.0709,
      "step": 3931
    },
    {
      "epoch": 0.9034926470588235,
      "grad_norm": 1.3899095058441162,
      "learning_rate": 9.104370915032681e-06,
      "loss": 0.0833,
      "step": 3932
    },
    {
      "epoch": 0.9037224264705882,
      "grad_norm": 0.9505661129951477,
      "learning_rate": 9.103860294117647e-06,
      "loss": 0.0769,
      "step": 3933
    },
    {
      "epoch": 0.9039522058823529,
      "grad_norm": 1.226462721824646,
      "learning_rate": 9.103349673202615e-06,
      "loss": 0.0945,
      "step": 3934
    },
    {
      "epoch": 0.9041819852941176,
      "grad_norm": 1.1611469984054565,
      "learning_rate": 9.102839052287581e-06,
      "loss": 0.0772,
      "step": 3935
    },
    {
      "epoch": 0.9044117647058824,
      "grad_norm": 1.293525218963623,
      "learning_rate": 9.102328431372551e-06,
      "loss": 0.0706,
      "step": 3936
    },
    {
      "epoch": 0.9046415441176471,
      "grad_norm": 0.9634649753570557,
      "learning_rate": 9.101817810457517e-06,
      "loss": 0.0624,
      "step": 3937
    },
    {
      "epoch": 0.9048713235294118,
      "grad_norm": 1.001688003540039,
      "learning_rate": 9.101307189542485e-06,
      "loss": 0.0741,
      "step": 3938
    },
    {
      "epoch": 0.9051011029411765,
      "grad_norm": 1.002448320388794,
      "learning_rate": 9.100796568627451e-06,
      "loss": 0.0878,
      "step": 3939
    },
    {
      "epoch": 0.9053308823529411,
      "grad_norm": 0.5713743567466736,
      "learning_rate": 9.100285947712419e-06,
      "loss": 0.0299,
      "step": 3940
    },
    {
      "epoch": 0.9055606617647058,
      "grad_norm": 0.938022255897522,
      "learning_rate": 9.099775326797387e-06,
      "loss": 0.0644,
      "step": 3941
    },
    {
      "epoch": 0.9057904411764706,
      "grad_norm": 1.317238450050354,
      "learning_rate": 9.099264705882353e-06,
      "loss": 0.1057,
      "step": 3942
    },
    {
      "epoch": 0.9060202205882353,
      "grad_norm": 0.9997433423995972,
      "learning_rate": 9.098754084967321e-06,
      "loss": 0.0786,
      "step": 3943
    },
    {
      "epoch": 0.90625,
      "grad_norm": 1.1427615880966187,
      "learning_rate": 9.098243464052289e-06,
      "loss": 0.0865,
      "step": 3944
    },
    {
      "epoch": 0.9064797794117647,
      "grad_norm": 1.0836951732635498,
      "learning_rate": 9.097732843137257e-06,
      "loss": 0.0867,
      "step": 3945
    },
    {
      "epoch": 0.9067095588235294,
      "grad_norm": 0.6912718415260315,
      "learning_rate": 9.097222222222223e-06,
      "loss": 0.0562,
      "step": 3946
    },
    {
      "epoch": 0.9069393382352942,
      "grad_norm": 0.9688614010810852,
      "learning_rate": 9.09671160130719e-06,
      "loss": 0.0903,
      "step": 3947
    },
    {
      "epoch": 0.9071691176470589,
      "grad_norm": 1.3114593029022217,
      "learning_rate": 9.096200980392158e-06,
      "loss": 0.0951,
      "step": 3948
    },
    {
      "epoch": 0.9073988970588235,
      "grad_norm": 0.8655071258544922,
      "learning_rate": 9.095690359477125e-06,
      "loss": 0.068,
      "step": 3949
    },
    {
      "epoch": 0.9076286764705882,
      "grad_norm": 1.1371707916259766,
      "learning_rate": 9.095179738562092e-06,
      "loss": 0.0607,
      "step": 3950
    },
    {
      "epoch": 0.9078584558823529,
      "grad_norm": 0.9785881638526917,
      "learning_rate": 9.094669117647059e-06,
      "loss": 0.0739,
      "step": 3951
    },
    {
      "epoch": 0.9080882352941176,
      "grad_norm": 0.8523542284965515,
      "learning_rate": 9.094158496732027e-06,
      "loss": 0.0606,
      "step": 3952
    },
    {
      "epoch": 0.9083180147058824,
      "grad_norm": 0.8188130855560303,
      "learning_rate": 9.093647875816994e-06,
      "loss": 0.0733,
      "step": 3953
    },
    {
      "epoch": 0.9085477941176471,
      "grad_norm": 1.0394567251205444,
      "learning_rate": 9.093137254901962e-06,
      "loss": 0.0712,
      "step": 3954
    },
    {
      "epoch": 0.9087775735294118,
      "grad_norm": 0.8152391314506531,
      "learning_rate": 9.092626633986928e-06,
      "loss": 0.0674,
      "step": 3955
    },
    {
      "epoch": 0.9090073529411765,
      "grad_norm": 1.1142891645431519,
      "learning_rate": 9.092116013071896e-06,
      "loss": 0.0718,
      "step": 3956
    },
    {
      "epoch": 0.9092371323529411,
      "grad_norm": 1.0691518783569336,
      "learning_rate": 9.091605392156864e-06,
      "loss": 0.0503,
      "step": 3957
    },
    {
      "epoch": 0.9094669117647058,
      "grad_norm": 1.1929115056991577,
      "learning_rate": 9.09109477124183e-06,
      "loss": 0.0806,
      "step": 3958
    },
    {
      "epoch": 0.9096966911764706,
      "grad_norm": 1.0623456239700317,
      "learning_rate": 9.090584150326798e-06,
      "loss": 0.0931,
      "step": 3959
    },
    {
      "epoch": 0.9099264705882353,
      "grad_norm": 1.3175212144851685,
      "learning_rate": 9.090073529411766e-06,
      "loss": 0.0707,
      "step": 3960
    },
    {
      "epoch": 0.91015625,
      "grad_norm": 1.3852053880691528,
      "learning_rate": 9.089562908496732e-06,
      "loss": 0.0855,
      "step": 3961
    },
    {
      "epoch": 0.9103860294117647,
      "grad_norm": 1.2289013862609863,
      "learning_rate": 9.0890522875817e-06,
      "loss": 0.0614,
      "step": 3962
    },
    {
      "epoch": 0.9106158088235294,
      "grad_norm": 1.2002873420715332,
      "learning_rate": 9.088541666666666e-06,
      "loss": 0.084,
      "step": 3963
    },
    {
      "epoch": 0.9108455882352942,
      "grad_norm": 1.2800008058547974,
      "learning_rate": 9.088031045751636e-06,
      "loss": 0.0986,
      "step": 3964
    },
    {
      "epoch": 0.9110753676470589,
      "grad_norm": 1.2764763832092285,
      "learning_rate": 9.087520424836602e-06,
      "loss": 0.082,
      "step": 3965
    },
    {
      "epoch": 0.9113051470588235,
      "grad_norm": 0.8542811274528503,
      "learning_rate": 9.08700980392157e-06,
      "loss": 0.0891,
      "step": 3966
    },
    {
      "epoch": 0.9115349264705882,
      "grad_norm": 1.3039652109146118,
      "learning_rate": 9.086499183006536e-06,
      "loss": 0.1096,
      "step": 3967
    },
    {
      "epoch": 0.9117647058823529,
      "grad_norm": 0.780655026435852,
      "learning_rate": 9.085988562091504e-06,
      "loss": 0.0484,
      "step": 3968
    },
    {
      "epoch": 0.9119944852941176,
      "grad_norm": 1.5352627038955688,
      "learning_rate": 9.085477941176472e-06,
      "loss": 0.078,
      "step": 3969
    },
    {
      "epoch": 0.9122242647058824,
      "grad_norm": 1.238654375076294,
      "learning_rate": 9.084967320261438e-06,
      "loss": 0.0713,
      "step": 3970
    },
    {
      "epoch": 0.9124540441176471,
      "grad_norm": 1.0905958414077759,
      "learning_rate": 9.084456699346406e-06,
      "loss": 0.0866,
      "step": 3971
    },
    {
      "epoch": 0.9126838235294118,
      "grad_norm": 1.0940567255020142,
      "learning_rate": 9.083946078431374e-06,
      "loss": 0.0754,
      "step": 3972
    },
    {
      "epoch": 0.9129136029411765,
      "grad_norm": 1.0639125108718872,
      "learning_rate": 9.083435457516341e-06,
      "loss": 0.0651,
      "step": 3973
    },
    {
      "epoch": 0.9131433823529411,
      "grad_norm": 0.8490080833435059,
      "learning_rate": 9.082924836601308e-06,
      "loss": 0.064,
      "step": 3974
    },
    {
      "epoch": 0.9133731617647058,
      "grad_norm": 1.0942909717559814,
      "learning_rate": 9.082414215686275e-06,
      "loss": 0.0997,
      "step": 3975
    },
    {
      "epoch": 0.9136029411764706,
      "grad_norm": 1.019234538078308,
      "learning_rate": 9.081903594771243e-06,
      "loss": 0.0934,
      "step": 3976
    },
    {
      "epoch": 0.9138327205882353,
      "grad_norm": 0.9865185618400574,
      "learning_rate": 9.08139297385621e-06,
      "loss": 0.0628,
      "step": 3977
    },
    {
      "epoch": 0.9140625,
      "grad_norm": 1.1281659603118896,
      "learning_rate": 9.080882352941177e-06,
      "loss": 0.075,
      "step": 3978
    },
    {
      "epoch": 0.9142922794117647,
      "grad_norm": 1.562793254852295,
      "learning_rate": 9.080371732026144e-06,
      "loss": 0.0824,
      "step": 3979
    },
    {
      "epoch": 0.9145220588235294,
      "grad_norm": 1.2134896516799927,
      "learning_rate": 9.079861111111113e-06,
      "loss": 0.0861,
      "step": 3980
    },
    {
      "epoch": 0.9147518382352942,
      "grad_norm": 1.0047844648361206,
      "learning_rate": 9.07935049019608e-06,
      "loss": 0.0587,
      "step": 3981
    },
    {
      "epoch": 0.9149816176470589,
      "grad_norm": 0.8508327007293701,
      "learning_rate": 9.078839869281047e-06,
      "loss": 0.0549,
      "step": 3982
    },
    {
      "epoch": 0.9152113970588235,
      "grad_norm": 1.0154980421066284,
      "learning_rate": 9.078329248366013e-06,
      "loss": 0.0696,
      "step": 3983
    },
    {
      "epoch": 0.9154411764705882,
      "grad_norm": 0.8800223469734192,
      "learning_rate": 9.077818627450981e-06,
      "loss": 0.0429,
      "step": 3984
    },
    {
      "epoch": 0.9156709558823529,
      "grad_norm": 1.321983814239502,
      "learning_rate": 9.077308006535949e-06,
      "loss": 0.0885,
      "step": 3985
    },
    {
      "epoch": 0.9159007352941176,
      "grad_norm": 0.7677904963493347,
      "learning_rate": 9.076797385620915e-06,
      "loss": 0.044,
      "step": 3986
    },
    {
      "epoch": 0.9161305147058824,
      "grad_norm": 1.0930172204971313,
      "learning_rate": 9.076286764705883e-06,
      "loss": 0.0878,
      "step": 3987
    },
    {
      "epoch": 0.9163602941176471,
      "grad_norm": 0.8761938810348511,
      "learning_rate": 9.075776143790851e-06,
      "loss": 0.0417,
      "step": 3988
    },
    {
      "epoch": 0.9165900735294118,
      "grad_norm": 1.130271315574646,
      "learning_rate": 9.075265522875819e-06,
      "loss": 0.0761,
      "step": 3989
    },
    {
      "epoch": 0.9168198529411765,
      "grad_norm": 0.8605441451072693,
      "learning_rate": 9.074754901960785e-06,
      "loss": 0.0608,
      "step": 3990
    },
    {
      "epoch": 0.9170496323529411,
      "grad_norm": 0.825738787651062,
      "learning_rate": 9.074244281045753e-06,
      "loss": 0.0521,
      "step": 3991
    },
    {
      "epoch": 0.9172794117647058,
      "grad_norm": 1.2513374090194702,
      "learning_rate": 9.07373366013072e-06,
      "loss": 0.0824,
      "step": 3992
    },
    {
      "epoch": 0.9175091911764706,
      "grad_norm": 0.8587360382080078,
      "learning_rate": 9.073223039215687e-06,
      "loss": 0.0713,
      "step": 3993
    },
    {
      "epoch": 0.9177389705882353,
      "grad_norm": 1.410120964050293,
      "learning_rate": 9.072712418300655e-06,
      "loss": 0.0801,
      "step": 3994
    },
    {
      "epoch": 0.91796875,
      "grad_norm": 1.1338188648223877,
      "learning_rate": 9.072201797385621e-06,
      "loss": 0.0726,
      "step": 3995
    },
    {
      "epoch": 0.9181985294117647,
      "grad_norm": 1.2640092372894287,
      "learning_rate": 9.071691176470589e-06,
      "loss": 0.0932,
      "step": 3996
    },
    {
      "epoch": 0.9184283088235294,
      "grad_norm": 0.9041348099708557,
      "learning_rate": 9.071180555555557e-06,
      "loss": 0.0545,
      "step": 3997
    },
    {
      "epoch": 0.9186580882352942,
      "grad_norm": 0.9380537271499634,
      "learning_rate": 9.070669934640524e-06,
      "loss": 0.0663,
      "step": 3998
    },
    {
      "epoch": 0.9188878676470589,
      "grad_norm": 1.1654943227767944,
      "learning_rate": 9.07015931372549e-06,
      "loss": 0.0655,
      "step": 3999
    },
    {
      "epoch": 0.9191176470588235,
      "grad_norm": 1.2397220134735107,
      "learning_rate": 9.069648692810458e-06,
      "loss": 0.0712,
      "step": 4000
    },
    {
      "epoch": 0.9191176470588235,
      "eval_loss": 0.07247491180896759,
      "eval_runtime": 2006.6319,
      "eval_samples_per_second": 4.438,
      "eval_steps_per_second": 2.219,
      "step": 4000
    },
    {
      "epoch": 0.9193474264705882,
      "grad_norm": 0.9584044218063354,
      "learning_rate": 9.069138071895426e-06,
      "loss": 0.0801,
      "step": 4001
    },
    {
      "epoch": 0.9195772058823529,
      "grad_norm": 0.8001915216445923,
      "learning_rate": 9.068627450980392e-06,
      "loss": 0.076,
      "step": 4002
    },
    {
      "epoch": 0.9198069852941176,
      "grad_norm": 0.9719427824020386,
      "learning_rate": 9.06811683006536e-06,
      "loss": 0.0716,
      "step": 4003
    },
    {
      "epoch": 0.9200367647058824,
      "grad_norm": 1.3032201528549194,
      "learning_rate": 9.067606209150328e-06,
      "loss": 0.0693,
      "step": 4004
    },
    {
      "epoch": 0.9202665441176471,
      "grad_norm": 1.0154292583465576,
      "learning_rate": 9.067095588235294e-06,
      "loss": 0.0779,
      "step": 4005
    },
    {
      "epoch": 0.9204963235294118,
      "grad_norm": 0.8232914209365845,
      "learning_rate": 9.066584967320262e-06,
      "loss": 0.05,
      "step": 4006
    },
    {
      "epoch": 0.9207261029411765,
      "grad_norm": 1.3471837043762207,
      "learning_rate": 9.066074346405228e-06,
      "loss": 0.0811,
      "step": 4007
    },
    {
      "epoch": 0.9209558823529411,
      "grad_norm": 1.1545791625976562,
      "learning_rate": 9.065563725490198e-06,
      "loss": 0.0763,
      "step": 4008
    },
    {
      "epoch": 0.9211856617647058,
      "grad_norm": 0.9480541348457336,
      "learning_rate": 9.065053104575164e-06,
      "loss": 0.0688,
      "step": 4009
    },
    {
      "epoch": 0.9214154411764706,
      "grad_norm": 0.8806858062744141,
      "learning_rate": 9.064542483660132e-06,
      "loss": 0.0425,
      "step": 4010
    },
    {
      "epoch": 0.9216452205882353,
      "grad_norm": 1.0959272384643555,
      "learning_rate": 9.064031862745098e-06,
      "loss": 0.0756,
      "step": 4011
    },
    {
      "epoch": 0.921875,
      "grad_norm": 1.1858716011047363,
      "learning_rate": 9.063521241830066e-06,
      "loss": 0.0782,
      "step": 4012
    },
    {
      "epoch": 0.9221047794117647,
      "grad_norm": 1.300094485282898,
      "learning_rate": 9.063010620915034e-06,
      "loss": 0.0733,
      "step": 4013
    },
    {
      "epoch": 0.9223345588235294,
      "grad_norm": 1.0358915328979492,
      "learning_rate": 9.0625e-06,
      "loss": 0.0789,
      "step": 4014
    },
    {
      "epoch": 0.9225643382352942,
      "grad_norm": 1.1651678085327148,
      "learning_rate": 9.061989379084968e-06,
      "loss": 0.0822,
      "step": 4015
    },
    {
      "epoch": 0.9227941176470589,
      "grad_norm": 0.902428388595581,
      "learning_rate": 9.061478758169934e-06,
      "loss": 0.0642,
      "step": 4016
    },
    {
      "epoch": 0.9230238970588235,
      "grad_norm": 1.1508638858795166,
      "learning_rate": 9.060968137254904e-06,
      "loss": 0.0717,
      "step": 4017
    },
    {
      "epoch": 0.9232536764705882,
      "grad_norm": 1.2005503177642822,
      "learning_rate": 9.06045751633987e-06,
      "loss": 0.072,
      "step": 4018
    },
    {
      "epoch": 0.9234834558823529,
      "grad_norm": 0.7496181726455688,
      "learning_rate": 9.059946895424838e-06,
      "loss": 0.0485,
      "step": 4019
    },
    {
      "epoch": 0.9237132352941176,
      "grad_norm": 1.067864179611206,
      "learning_rate": 9.059436274509804e-06,
      "loss": 0.0701,
      "step": 4020
    },
    {
      "epoch": 0.9239430147058824,
      "grad_norm": 1.1634418964385986,
      "learning_rate": 9.058925653594772e-06,
      "loss": 0.1062,
      "step": 4021
    },
    {
      "epoch": 0.9241727941176471,
      "grad_norm": 1.062581181526184,
      "learning_rate": 9.05841503267974e-06,
      "loss": 0.0579,
      "step": 4022
    },
    {
      "epoch": 0.9244025735294118,
      "grad_norm": 0.8981394171714783,
      "learning_rate": 9.057904411764706e-06,
      "loss": 0.0595,
      "step": 4023
    },
    {
      "epoch": 0.9246323529411765,
      "grad_norm": 1.1707264184951782,
      "learning_rate": 9.057393790849674e-06,
      "loss": 0.0715,
      "step": 4024
    },
    {
      "epoch": 0.9248621323529411,
      "grad_norm": 0.9522669315338135,
      "learning_rate": 9.056883169934641e-06,
      "loss": 0.082,
      "step": 4025
    },
    {
      "epoch": 0.9250919117647058,
      "grad_norm": 1.0838345289230347,
      "learning_rate": 9.05637254901961e-06,
      "loss": 0.0797,
      "step": 4026
    },
    {
      "epoch": 0.9253216911764706,
      "grad_norm": 1.003879427909851,
      "learning_rate": 9.055861928104575e-06,
      "loss": 0.0635,
      "step": 4027
    },
    {
      "epoch": 0.9255514705882353,
      "grad_norm": 1.151114583015442,
      "learning_rate": 9.055351307189543e-06,
      "loss": 0.0774,
      "step": 4028
    },
    {
      "epoch": 0.92578125,
      "grad_norm": 0.961850643157959,
      "learning_rate": 9.054840686274511e-06,
      "loss": 0.0697,
      "step": 4029
    },
    {
      "epoch": 0.9260110294117647,
      "grad_norm": 1.1150009632110596,
      "learning_rate": 9.054330065359477e-06,
      "loss": 0.062,
      "step": 4030
    },
    {
      "epoch": 0.9262408088235294,
      "grad_norm": 1.0973440408706665,
      "learning_rate": 9.053819444444445e-06,
      "loss": 0.0678,
      "step": 4031
    },
    {
      "epoch": 0.9264705882352942,
      "grad_norm": 0.7234480977058411,
      "learning_rate": 9.053308823529411e-06,
      "loss": 0.0332,
      "step": 4032
    },
    {
      "epoch": 0.9267003676470589,
      "grad_norm": 1.0889323949813843,
      "learning_rate": 9.052798202614381e-06,
      "loss": 0.0913,
      "step": 4033
    },
    {
      "epoch": 0.9269301470588235,
      "grad_norm": 0.8786482810974121,
      "learning_rate": 9.052287581699347e-06,
      "loss": 0.0621,
      "step": 4034
    },
    {
      "epoch": 0.9271599264705882,
      "grad_norm": 0.8896682262420654,
      "learning_rate": 9.051776960784315e-06,
      "loss": 0.07,
      "step": 4035
    },
    {
      "epoch": 0.9273897058823529,
      "grad_norm": 1.015313744544983,
      "learning_rate": 9.051266339869281e-06,
      "loss": 0.0708,
      "step": 4036
    },
    {
      "epoch": 0.9276194852941176,
      "grad_norm": 1.151556134223938,
      "learning_rate": 9.050755718954249e-06,
      "loss": 0.0687,
      "step": 4037
    },
    {
      "epoch": 0.9278492647058824,
      "grad_norm": 0.717387855052948,
      "learning_rate": 9.050245098039217e-06,
      "loss": 0.0422,
      "step": 4038
    },
    {
      "epoch": 0.9280790441176471,
      "grad_norm": 1.2071011066436768,
      "learning_rate": 9.049734477124183e-06,
      "loss": 0.0756,
      "step": 4039
    },
    {
      "epoch": 0.9283088235294118,
      "grad_norm": 1.150962233543396,
      "learning_rate": 9.049223856209151e-06,
      "loss": 0.0845,
      "step": 4040
    },
    {
      "epoch": 0.9285386029411765,
      "grad_norm": 0.9425977468490601,
      "learning_rate": 9.048713235294119e-06,
      "loss": 0.0667,
      "step": 4041
    },
    {
      "epoch": 0.9287683823529411,
      "grad_norm": 0.9688581228256226,
      "learning_rate": 9.048202614379085e-06,
      "loss": 0.0834,
      "step": 4042
    },
    {
      "epoch": 0.9289981617647058,
      "grad_norm": 0.9399148225784302,
      "learning_rate": 9.047691993464053e-06,
      "loss": 0.0771,
      "step": 4043
    },
    {
      "epoch": 0.9292279411764706,
      "grad_norm": 1.1623992919921875,
      "learning_rate": 9.04718137254902e-06,
      "loss": 0.093,
      "step": 4044
    },
    {
      "epoch": 0.9294577205882353,
      "grad_norm": 1.3943368196487427,
      "learning_rate": 9.046670751633989e-06,
      "loss": 0.082,
      "step": 4045
    },
    {
      "epoch": 0.9296875,
      "grad_norm": 1.0467970371246338,
      "learning_rate": 9.046160130718955e-06,
      "loss": 0.0804,
      "step": 4046
    },
    {
      "epoch": 0.9299172794117647,
      "grad_norm": 1.046248197555542,
      "learning_rate": 9.045649509803923e-06,
      "loss": 0.0628,
      "step": 4047
    },
    {
      "epoch": 0.9301470588235294,
      "grad_norm": 0.81733638048172,
      "learning_rate": 9.045138888888889e-06,
      "loss": 0.0568,
      "step": 4048
    },
    {
      "epoch": 0.9303768382352942,
      "grad_norm": 1.6741355657577515,
      "learning_rate": 9.044628267973857e-06,
      "loss": 0.1088,
      "step": 4049
    },
    {
      "epoch": 0.9306066176470589,
      "grad_norm": 1.089816927909851,
      "learning_rate": 9.044117647058824e-06,
      "loss": 0.0505,
      "step": 4050
    },
    {
      "epoch": 0.9308363970588235,
      "grad_norm": 1.20002019405365,
      "learning_rate": 9.04360702614379e-06,
      "loss": 0.0781,
      "step": 4051
    },
    {
      "epoch": 0.9310661764705882,
      "grad_norm": 0.905877947807312,
      "learning_rate": 9.043096405228758e-06,
      "loss": 0.0591,
      "step": 4052
    },
    {
      "epoch": 0.9312959558823529,
      "grad_norm": 0.9817638993263245,
      "learning_rate": 9.042585784313726e-06,
      "loss": 0.0626,
      "step": 4053
    },
    {
      "epoch": 0.9315257352941176,
      "grad_norm": 1.3775032758712769,
      "learning_rate": 9.042075163398694e-06,
      "loss": 0.1,
      "step": 4054
    },
    {
      "epoch": 0.9317555147058824,
      "grad_norm": 1.2170708179473877,
      "learning_rate": 9.04156454248366e-06,
      "loss": 0.0776,
      "step": 4055
    },
    {
      "epoch": 0.9319852941176471,
      "grad_norm": 0.9629380106925964,
      "learning_rate": 9.041053921568628e-06,
      "loss": 0.061,
      "step": 4056
    },
    {
      "epoch": 0.9322150735294118,
      "grad_norm": 1.023883581161499,
      "learning_rate": 9.040543300653596e-06,
      "loss": 0.0681,
      "step": 4057
    },
    {
      "epoch": 0.9324448529411765,
      "grad_norm": 0.93482506275177,
      "learning_rate": 9.040032679738562e-06,
      "loss": 0.0662,
      "step": 4058
    },
    {
      "epoch": 0.9326746323529411,
      "grad_norm": 1.1307876110076904,
      "learning_rate": 9.03952205882353e-06,
      "loss": 0.0815,
      "step": 4059
    },
    {
      "epoch": 0.9329044117647058,
      "grad_norm": 1.2965022325515747,
      "learning_rate": 9.039011437908496e-06,
      "loss": 0.0692,
      "step": 4060
    },
    {
      "epoch": 0.9331341911764706,
      "grad_norm": 1.7081278562545776,
      "learning_rate": 9.038500816993466e-06,
      "loss": 0.0594,
      "step": 4061
    },
    {
      "epoch": 0.9333639705882353,
      "grad_norm": 0.9649002552032471,
      "learning_rate": 9.037990196078432e-06,
      "loss": 0.0716,
      "step": 4062
    },
    {
      "epoch": 0.93359375,
      "grad_norm": 0.8507089614868164,
      "learning_rate": 9.0374795751634e-06,
      "loss": 0.0447,
      "step": 4063
    },
    {
      "epoch": 0.9338235294117647,
      "grad_norm": 0.9670835733413696,
      "learning_rate": 9.036968954248366e-06,
      "loss": 0.0715,
      "step": 4064
    },
    {
      "epoch": 0.9340533088235294,
      "grad_norm": 1.2309620380401611,
      "learning_rate": 9.036458333333334e-06,
      "loss": 0.0866,
      "step": 4065
    },
    {
      "epoch": 0.9342830882352942,
      "grad_norm": 1.5201910734176636,
      "learning_rate": 9.035947712418302e-06,
      "loss": 0.1189,
      "step": 4066
    },
    {
      "epoch": 0.9345128676470589,
      "grad_norm": 1.032689094543457,
      "learning_rate": 9.035437091503268e-06,
      "loss": 0.0709,
      "step": 4067
    },
    {
      "epoch": 0.9347426470588235,
      "grad_norm": 1.0869284868240356,
      "learning_rate": 9.034926470588236e-06,
      "loss": 0.0604,
      "step": 4068
    },
    {
      "epoch": 0.9349724264705882,
      "grad_norm": 1.0174521207809448,
      "learning_rate": 9.034415849673204e-06,
      "loss": 0.0668,
      "step": 4069
    },
    {
      "epoch": 0.9352022058823529,
      "grad_norm": 0.9538552165031433,
      "learning_rate": 9.033905228758171e-06,
      "loss": 0.084,
      "step": 4070
    },
    {
      "epoch": 0.9354319852941176,
      "grad_norm": 0.9351587295532227,
      "learning_rate": 9.033394607843138e-06,
      "loss": 0.0753,
      "step": 4071
    },
    {
      "epoch": 0.9356617647058824,
      "grad_norm": 0.9382181763648987,
      "learning_rate": 9.032883986928106e-06,
      "loss": 0.0622,
      "step": 4072
    },
    {
      "epoch": 0.9358915441176471,
      "grad_norm": 1.0456229448318481,
      "learning_rate": 9.032373366013073e-06,
      "loss": 0.0735,
      "step": 4073
    },
    {
      "epoch": 0.9361213235294118,
      "grad_norm": 1.3855031728744507,
      "learning_rate": 9.03186274509804e-06,
      "loss": 0.0892,
      "step": 4074
    },
    {
      "epoch": 0.9363511029411765,
      "grad_norm": 1.7177965641021729,
      "learning_rate": 9.031352124183007e-06,
      "loss": 0.0858,
      "step": 4075
    },
    {
      "epoch": 0.9365808823529411,
      "grad_norm": 0.7528671622276306,
      "learning_rate": 9.030841503267974e-06,
      "loss": 0.0624,
      "step": 4076
    },
    {
      "epoch": 0.9368106617647058,
      "grad_norm": 1.0368824005126953,
      "learning_rate": 9.030330882352943e-06,
      "loss": 0.0699,
      "step": 4077
    },
    {
      "epoch": 0.9370404411764706,
      "grad_norm": 1.0211293697357178,
      "learning_rate": 9.02982026143791e-06,
      "loss": 0.0643,
      "step": 4078
    },
    {
      "epoch": 0.9372702205882353,
      "grad_norm": 1.1058049201965332,
      "learning_rate": 9.029309640522877e-06,
      "loss": 0.0616,
      "step": 4079
    },
    {
      "epoch": 0.9375,
      "grad_norm": 1.1935453414916992,
      "learning_rate": 9.028799019607843e-06,
      "loss": 0.0719,
      "step": 4080
    },
    {
      "epoch": 0.9377297794117647,
      "grad_norm": 1.1173779964447021,
      "learning_rate": 9.028288398692811e-06,
      "loss": 0.0585,
      "step": 4081
    },
    {
      "epoch": 0.9379595588235294,
      "grad_norm": 1.0610668659210205,
      "learning_rate": 9.027777777777779e-06,
      "loss": 0.0738,
      "step": 4082
    },
    {
      "epoch": 0.9381893382352942,
      "grad_norm": 1.5141215324401855,
      "learning_rate": 9.027267156862745e-06,
      "loss": 0.0999,
      "step": 4083
    },
    {
      "epoch": 0.9384191176470589,
      "grad_norm": 0.9482290148735046,
      "learning_rate": 9.026756535947713e-06,
      "loss": 0.0507,
      "step": 4084
    },
    {
      "epoch": 0.9386488970588235,
      "grad_norm": 1.2197434902191162,
      "learning_rate": 9.026245915032681e-06,
      "loss": 0.107,
      "step": 4085
    },
    {
      "epoch": 0.9388786764705882,
      "grad_norm": 0.9646141529083252,
      "learning_rate": 9.025735294117647e-06,
      "loss": 0.0825,
      "step": 4086
    },
    {
      "epoch": 0.9391084558823529,
      "grad_norm": 0.9053969979286194,
      "learning_rate": 9.025224673202615e-06,
      "loss": 0.0668,
      "step": 4087
    },
    {
      "epoch": 0.9393382352941176,
      "grad_norm": 0.8780352473258972,
      "learning_rate": 9.024714052287583e-06,
      "loss": 0.0505,
      "step": 4088
    },
    {
      "epoch": 0.9395680147058824,
      "grad_norm": 0.9541186690330505,
      "learning_rate": 9.02420343137255e-06,
      "loss": 0.0598,
      "step": 4089
    },
    {
      "epoch": 0.9397977941176471,
      "grad_norm": 1.0793527364730835,
      "learning_rate": 9.023692810457517e-06,
      "loss": 0.0619,
      "step": 4090
    },
    {
      "epoch": 0.9400275735294118,
      "grad_norm": 0.7545413374900818,
      "learning_rate": 9.023182189542485e-06,
      "loss": 0.0571,
      "step": 4091
    },
    {
      "epoch": 0.9402573529411765,
      "grad_norm": 1.0388565063476562,
      "learning_rate": 9.022671568627451e-06,
      "loss": 0.0796,
      "step": 4092
    },
    {
      "epoch": 0.9404871323529411,
      "grad_norm": 1.0456162691116333,
      "learning_rate": 9.022160947712419e-06,
      "loss": 0.0759,
      "step": 4093
    },
    {
      "epoch": 0.9407169117647058,
      "grad_norm": 0.8942261338233948,
      "learning_rate": 9.021650326797387e-06,
      "loss": 0.0648,
      "step": 4094
    },
    {
      "epoch": 0.9409466911764706,
      "grad_norm": 1.1073790788650513,
      "learning_rate": 9.021139705882353e-06,
      "loss": 0.0656,
      "step": 4095
    },
    {
      "epoch": 0.9411764705882353,
      "grad_norm": 1.1673938035964966,
      "learning_rate": 9.02062908496732e-06,
      "loss": 0.0717,
      "step": 4096
    },
    {
      "epoch": 0.94140625,
      "grad_norm": 0.7942476272583008,
      "learning_rate": 9.020118464052289e-06,
      "loss": 0.0468,
      "step": 4097
    },
    {
      "epoch": 0.9416360294117647,
      "grad_norm": 1.171440601348877,
      "learning_rate": 9.019607843137256e-06,
      "loss": 0.0747,
      "step": 4098
    },
    {
      "epoch": 0.9418658088235294,
      "grad_norm": 0.9055489897727966,
      "learning_rate": 9.019097222222223e-06,
      "loss": 0.05,
      "step": 4099
    },
    {
      "epoch": 0.9420955882352942,
      "grad_norm": 1.0030943155288696,
      "learning_rate": 9.01858660130719e-06,
      "loss": 0.0842,
      "step": 4100
    },
    {
      "epoch": 0.9423253676470589,
      "grad_norm": 1.212538242340088,
      "learning_rate": 9.018075980392158e-06,
      "loss": 0.0787,
      "step": 4101
    },
    {
      "epoch": 0.9425551470588235,
      "grad_norm": 1.142608642578125,
      "learning_rate": 9.017565359477124e-06,
      "loss": 0.0637,
      "step": 4102
    },
    {
      "epoch": 0.9427849264705882,
      "grad_norm": 1.0529927015304565,
      "learning_rate": 9.017054738562092e-06,
      "loss": 0.0808,
      "step": 4103
    },
    {
      "epoch": 0.9430147058823529,
      "grad_norm": 0.9765946269035339,
      "learning_rate": 9.016544117647058e-06,
      "loss": 0.0449,
      "step": 4104
    },
    {
      "epoch": 0.9432444852941176,
      "grad_norm": 0.8444287180900574,
      "learning_rate": 9.016033496732028e-06,
      "loss": 0.0611,
      "step": 4105
    },
    {
      "epoch": 0.9434742647058824,
      "grad_norm": 0.9037941694259644,
      "learning_rate": 9.015522875816994e-06,
      "loss": 0.0711,
      "step": 4106
    },
    {
      "epoch": 0.9437040441176471,
      "grad_norm": 0.825487494468689,
      "learning_rate": 9.015012254901962e-06,
      "loss": 0.0442,
      "step": 4107
    },
    {
      "epoch": 0.9439338235294118,
      "grad_norm": 1.0381128787994385,
      "learning_rate": 9.014501633986928e-06,
      "loss": 0.088,
      "step": 4108
    },
    {
      "epoch": 0.9441636029411765,
      "grad_norm": 0.9617136120796204,
      "learning_rate": 9.013991013071896e-06,
      "loss": 0.0478,
      "step": 4109
    },
    {
      "epoch": 0.9443933823529411,
      "grad_norm": 1.356736183166504,
      "learning_rate": 9.013480392156864e-06,
      "loss": 0.0736,
      "step": 4110
    },
    {
      "epoch": 0.9446231617647058,
      "grad_norm": 1.0583875179290771,
      "learning_rate": 9.01296977124183e-06,
      "loss": 0.0694,
      "step": 4111
    },
    {
      "epoch": 0.9448529411764706,
      "grad_norm": 1.114432454109192,
      "learning_rate": 9.012459150326798e-06,
      "loss": 0.0448,
      "step": 4112
    },
    {
      "epoch": 0.9450827205882353,
      "grad_norm": 0.8065370321273804,
      "learning_rate": 9.011948529411766e-06,
      "loss": 0.0726,
      "step": 4113
    },
    {
      "epoch": 0.9453125,
      "grad_norm": 0.8006187677383423,
      "learning_rate": 9.011437908496734e-06,
      "loss": 0.0573,
      "step": 4114
    },
    {
      "epoch": 0.9455422794117647,
      "grad_norm": 1.0820915699005127,
      "learning_rate": 9.0109272875817e-06,
      "loss": 0.0751,
      "step": 4115
    },
    {
      "epoch": 0.9457720588235294,
      "grad_norm": 1.3682180643081665,
      "learning_rate": 9.010416666666668e-06,
      "loss": 0.0785,
      "step": 4116
    },
    {
      "epoch": 0.9460018382352942,
      "grad_norm": 1.1666547060012817,
      "learning_rate": 9.009906045751636e-06,
      "loss": 0.0768,
      "step": 4117
    },
    {
      "epoch": 0.9462316176470589,
      "grad_norm": 1.023205280303955,
      "learning_rate": 9.009395424836602e-06,
      "loss": 0.0327,
      "step": 4118
    },
    {
      "epoch": 0.9464613970588235,
      "grad_norm": 1.9273314476013184,
      "learning_rate": 9.00888480392157e-06,
      "loss": 0.0767,
      "step": 4119
    },
    {
      "epoch": 0.9466911764705882,
      "grad_norm": 1.2317157983779907,
      "learning_rate": 9.008374183006536e-06,
      "loss": 0.0711,
      "step": 4120
    },
    {
      "epoch": 0.9469209558823529,
      "grad_norm": 1.2130672931671143,
      "learning_rate": 9.007863562091504e-06,
      "loss": 0.1073,
      "step": 4121
    },
    {
      "epoch": 0.9471507352941176,
      "grad_norm": 0.8513170480728149,
      "learning_rate": 9.007352941176471e-06,
      "loss": 0.0526,
      "step": 4122
    },
    {
      "epoch": 0.9473805147058824,
      "grad_norm": 1.1796752214431763,
      "learning_rate": 9.00684232026144e-06,
      "loss": 0.0833,
      "step": 4123
    },
    {
      "epoch": 0.9476102941176471,
      "grad_norm": 1.0238757133483887,
      "learning_rate": 9.006331699346406e-06,
      "loss": 0.088,
      "step": 4124
    },
    {
      "epoch": 0.9478400735294118,
      "grad_norm": 0.8646443486213684,
      "learning_rate": 9.005821078431373e-06,
      "loss": 0.0668,
      "step": 4125
    },
    {
      "epoch": 0.9480698529411765,
      "grad_norm": 0.8419198393821716,
      "learning_rate": 9.005310457516341e-06,
      "loss": 0.0598,
      "step": 4126
    },
    {
      "epoch": 0.9482996323529411,
      "grad_norm": 1.2358152866363525,
      "learning_rate": 9.004799836601307e-06,
      "loss": 0.0983,
      "step": 4127
    },
    {
      "epoch": 0.9485294117647058,
      "grad_norm": 1.3060498237609863,
      "learning_rate": 9.004289215686275e-06,
      "loss": 0.0874,
      "step": 4128
    },
    {
      "epoch": 0.9487591911764706,
      "grad_norm": 1.209097146987915,
      "learning_rate": 9.003778594771243e-06,
      "loss": 0.0645,
      "step": 4129
    },
    {
      "epoch": 0.9489889705882353,
      "grad_norm": 1.217088222503662,
      "learning_rate": 9.00326797385621e-06,
      "loss": 0.0677,
      "step": 4130
    },
    {
      "epoch": 0.94921875,
      "grad_norm": 1.4056892395019531,
      "learning_rate": 9.002757352941177e-06,
      "loss": 0.0775,
      "step": 4131
    },
    {
      "epoch": 0.9494485294117647,
      "grad_norm": 1.0746599435806274,
      "learning_rate": 9.002246732026145e-06,
      "loss": 0.0722,
      "step": 4132
    },
    {
      "epoch": 0.9496783088235294,
      "grad_norm": 1.2315887212753296,
      "learning_rate": 9.001736111111113e-06,
      "loss": 0.0592,
      "step": 4133
    },
    {
      "epoch": 0.9499080882352942,
      "grad_norm": 0.8116980791091919,
      "learning_rate": 9.001225490196079e-06,
      "loss": 0.0496,
      "step": 4134
    },
    {
      "epoch": 0.9501378676470589,
      "grad_norm": 1.2124885320663452,
      "learning_rate": 9.000714869281047e-06,
      "loss": 0.0778,
      "step": 4135
    },
    {
      "epoch": 0.9503676470588235,
      "grad_norm": 1.6455583572387695,
      "learning_rate": 9.000204248366013e-06,
      "loss": 0.0841,
      "step": 4136
    },
    {
      "epoch": 0.9505974264705882,
      "grad_norm": 0.8237853646278381,
      "learning_rate": 8.999693627450981e-06,
      "loss": 0.047,
      "step": 4137
    },
    {
      "epoch": 0.9508272058823529,
      "grad_norm": 1.4242570400238037,
      "learning_rate": 8.999183006535949e-06,
      "loss": 0.0799,
      "step": 4138
    },
    {
      "epoch": 0.9510569852941176,
      "grad_norm": 1.1839467287063599,
      "learning_rate": 8.998672385620915e-06,
      "loss": 0.0813,
      "step": 4139
    },
    {
      "epoch": 0.9512867647058824,
      "grad_norm": 1.3034024238586426,
      "learning_rate": 8.998161764705883e-06,
      "loss": 0.072,
      "step": 4140
    },
    {
      "epoch": 0.9515165441176471,
      "grad_norm": 1.0187827348709106,
      "learning_rate": 8.99765114379085e-06,
      "loss": 0.0623,
      "step": 4141
    },
    {
      "epoch": 0.9517463235294118,
      "grad_norm": 0.7850359082221985,
      "learning_rate": 8.997140522875819e-06,
      "loss": 0.056,
      "step": 4142
    },
    {
      "epoch": 0.9519761029411765,
      "grad_norm": 1.0478476285934448,
      "learning_rate": 8.996629901960785e-06,
      "loss": 0.0628,
      "step": 4143
    },
    {
      "epoch": 0.9522058823529411,
      "grad_norm": 1.5083205699920654,
      "learning_rate": 8.996119281045753e-06,
      "loss": 0.0796,
      "step": 4144
    },
    {
      "epoch": 0.9524356617647058,
      "grad_norm": 0.9618106484413147,
      "learning_rate": 8.99560866013072e-06,
      "loss": 0.0972,
      "step": 4145
    },
    {
      "epoch": 0.9526654411764706,
      "grad_norm": 1.356359839439392,
      "learning_rate": 8.995098039215687e-06,
      "loss": 0.0627,
      "step": 4146
    },
    {
      "epoch": 0.9528952205882353,
      "grad_norm": 0.7363339066505432,
      "learning_rate": 8.994587418300654e-06,
      "loss": 0.0431,
      "step": 4147
    },
    {
      "epoch": 0.953125,
      "grad_norm": 0.8354798555374146,
      "learning_rate": 8.99407679738562e-06,
      "loss": 0.0492,
      "step": 4148
    },
    {
      "epoch": 0.9533547794117647,
      "grad_norm": 0.8473988771438599,
      "learning_rate": 8.99356617647059e-06,
      "loss": 0.0485,
      "step": 4149
    },
    {
      "epoch": 0.9535845588235294,
      "grad_norm": 0.9633535742759705,
      "learning_rate": 8.993055555555556e-06,
      "loss": 0.0613,
      "step": 4150
    },
    {
      "epoch": 0.9538143382352942,
      "grad_norm": 0.9216928482055664,
      "learning_rate": 8.992544934640524e-06,
      "loss": 0.0651,
      "step": 4151
    },
    {
      "epoch": 0.9540441176470589,
      "grad_norm": 1.019687294960022,
      "learning_rate": 8.99203431372549e-06,
      "loss": 0.0791,
      "step": 4152
    },
    {
      "epoch": 0.9542738970588235,
      "grad_norm": 0.6422182321548462,
      "learning_rate": 8.991523692810458e-06,
      "loss": 0.0343,
      "step": 4153
    },
    {
      "epoch": 0.9545036764705882,
      "grad_norm": 1.0353224277496338,
      "learning_rate": 8.991013071895426e-06,
      "loss": 0.0646,
      "step": 4154
    },
    {
      "epoch": 0.9547334558823529,
      "grad_norm": 1.2143291234970093,
      "learning_rate": 8.990502450980392e-06,
      "loss": 0.1091,
      "step": 4155
    },
    {
      "epoch": 0.9549632352941176,
      "grad_norm": 1.1801565885543823,
      "learning_rate": 8.98999183006536e-06,
      "loss": 0.1085,
      "step": 4156
    },
    {
      "epoch": 0.9551930147058824,
      "grad_norm": 1.0326107740402222,
      "learning_rate": 8.989481209150328e-06,
      "loss": 0.0778,
      "step": 4157
    },
    {
      "epoch": 0.9554227941176471,
      "grad_norm": 0.7768696546554565,
      "learning_rate": 8.988970588235296e-06,
      "loss": 0.051,
      "step": 4158
    },
    {
      "epoch": 0.9556525735294118,
      "grad_norm": 0.9591712355613708,
      "learning_rate": 8.988459967320262e-06,
      "loss": 0.0553,
      "step": 4159
    },
    {
      "epoch": 0.9558823529411765,
      "grad_norm": 0.9352782368659973,
      "learning_rate": 8.98794934640523e-06,
      "loss": 0.0692,
      "step": 4160
    },
    {
      "epoch": 0.9561121323529411,
      "grad_norm": 1.0448263883590698,
      "learning_rate": 8.987438725490198e-06,
      "loss": 0.0596,
      "step": 4161
    },
    {
      "epoch": 0.9563419117647058,
      "grad_norm": 1.213512897491455,
      "learning_rate": 8.986928104575164e-06,
      "loss": 0.0746,
      "step": 4162
    },
    {
      "epoch": 0.9565716911764706,
      "grad_norm": 1.1748476028442383,
      "learning_rate": 8.986417483660132e-06,
      "loss": 0.082,
      "step": 4163
    },
    {
      "epoch": 0.9568014705882353,
      "grad_norm": 0.6310504674911499,
      "learning_rate": 8.985906862745098e-06,
      "loss": 0.0418,
      "step": 4164
    },
    {
      "epoch": 0.95703125,
      "grad_norm": 1.0858001708984375,
      "learning_rate": 8.985396241830066e-06,
      "loss": 0.1014,
      "step": 4165
    },
    {
      "epoch": 0.9572610294117647,
      "grad_norm": 1.090935230255127,
      "learning_rate": 8.984885620915034e-06,
      "loss": 0.0884,
      "step": 4166
    },
    {
      "epoch": 0.9574908088235294,
      "grad_norm": 0.6941601037979126,
      "learning_rate": 8.984375000000002e-06,
      "loss": 0.0443,
      "step": 4167
    },
    {
      "epoch": 0.9577205882352942,
      "grad_norm": 0.9242823123931885,
      "learning_rate": 8.983864379084968e-06,
      "loss": 0.0803,
      "step": 4168
    },
    {
      "epoch": 0.9579503676470589,
      "grad_norm": 0.764794647693634,
      "learning_rate": 8.983353758169936e-06,
      "loss": 0.0469,
      "step": 4169
    },
    {
      "epoch": 0.9581801470588235,
      "grad_norm": 1.0994763374328613,
      "learning_rate": 8.982843137254903e-06,
      "loss": 0.0704,
      "step": 4170
    },
    {
      "epoch": 0.9584099264705882,
      "grad_norm": 1.005189061164856,
      "learning_rate": 8.98233251633987e-06,
      "loss": 0.071,
      "step": 4171
    },
    {
      "epoch": 0.9586397058823529,
      "grad_norm": 0.9195622801780701,
      "learning_rate": 8.981821895424837e-06,
      "loss": 0.0554,
      "step": 4172
    },
    {
      "epoch": 0.9588694852941176,
      "grad_norm": 1.0511677265167236,
      "learning_rate": 8.981311274509804e-06,
      "loss": 0.0849,
      "step": 4173
    },
    {
      "epoch": 0.9590992647058824,
      "grad_norm": 0.8636776804924011,
      "learning_rate": 8.980800653594771e-06,
      "loss": 0.0567,
      "step": 4174
    },
    {
      "epoch": 0.9593290441176471,
      "grad_norm": 0.835105836391449,
      "learning_rate": 8.98029003267974e-06,
      "loss": 0.0527,
      "step": 4175
    },
    {
      "epoch": 0.9595588235294118,
      "grad_norm": 0.8619384169578552,
      "learning_rate": 8.979779411764706e-06,
      "loss": 0.0609,
      "step": 4176
    },
    {
      "epoch": 0.9597886029411765,
      "grad_norm": 1.036665439605713,
      "learning_rate": 8.979268790849673e-06,
      "loss": 0.0757,
      "step": 4177
    },
    {
      "epoch": 0.9600183823529411,
      "grad_norm": 1.372814655303955,
      "learning_rate": 8.978758169934641e-06,
      "loss": 0.0706,
      "step": 4178
    },
    {
      "epoch": 0.9602481617647058,
      "grad_norm": 0.9766033887863159,
      "learning_rate": 8.978247549019609e-06,
      "loss": 0.0739,
      "step": 4179
    },
    {
      "epoch": 0.9604779411764706,
      "grad_norm": 1.2104307413101196,
      "learning_rate": 8.977736928104575e-06,
      "loss": 0.0602,
      "step": 4180
    },
    {
      "epoch": 0.9607077205882353,
      "grad_norm": 1.225277066230774,
      "learning_rate": 8.977226307189543e-06,
      "loss": 0.077,
      "step": 4181
    },
    {
      "epoch": 0.9609375,
      "grad_norm": 1.3983160257339478,
      "learning_rate": 8.976715686274511e-06,
      "loss": 0.0919,
      "step": 4182
    },
    {
      "epoch": 0.9611672794117647,
      "grad_norm": 1.251851201057434,
      "learning_rate": 8.976205065359477e-06,
      "loss": 0.0658,
      "step": 4183
    },
    {
      "epoch": 0.9613970588235294,
      "grad_norm": 0.8763911128044128,
      "learning_rate": 8.975694444444445e-06,
      "loss": 0.0746,
      "step": 4184
    },
    {
      "epoch": 0.9616268382352942,
      "grad_norm": 0.7551479339599609,
      "learning_rate": 8.975183823529411e-06,
      "loss": 0.0552,
      "step": 4185
    },
    {
      "epoch": 0.9618566176470589,
      "grad_norm": 1.0471748113632202,
      "learning_rate": 8.97467320261438e-06,
      "loss": 0.083,
      "step": 4186
    },
    {
      "epoch": 0.9620863970588235,
      "grad_norm": 1.126639723777771,
      "learning_rate": 8.974162581699347e-06,
      "loss": 0.0657,
      "step": 4187
    },
    {
      "epoch": 0.9623161764705882,
      "grad_norm": 1.1976161003112793,
      "learning_rate": 8.973651960784315e-06,
      "loss": 0.103,
      "step": 4188
    },
    {
      "epoch": 0.9625459558823529,
      "grad_norm": 1.0323278903961182,
      "learning_rate": 8.973141339869281e-06,
      "loss": 0.0761,
      "step": 4189
    },
    {
      "epoch": 0.9627757352941176,
      "grad_norm": 0.966314435005188,
      "learning_rate": 8.972630718954249e-06,
      "loss": 0.0846,
      "step": 4190
    },
    {
      "epoch": 0.9630055147058824,
      "grad_norm": 0.8876481652259827,
      "learning_rate": 8.972120098039217e-06,
      "loss": 0.0538,
      "step": 4191
    },
    {
      "epoch": 0.9632352941176471,
      "grad_norm": 1.1958603858947754,
      "learning_rate": 8.971609477124183e-06,
      "loss": 0.0816,
      "step": 4192
    },
    {
      "epoch": 0.9634650735294118,
      "grad_norm": 0.9621962308883667,
      "learning_rate": 8.97109885620915e-06,
      "loss": 0.0516,
      "step": 4193
    },
    {
      "epoch": 0.9636948529411765,
      "grad_norm": 0.8841180801391602,
      "learning_rate": 8.970588235294119e-06,
      "loss": 0.0637,
      "step": 4194
    },
    {
      "epoch": 0.9639246323529411,
      "grad_norm": 0.9997713565826416,
      "learning_rate": 8.970077614379086e-06,
      "loss": 0.0435,
      "step": 4195
    },
    {
      "epoch": 0.9641544117647058,
      "grad_norm": 0.9711139798164368,
      "learning_rate": 8.969566993464053e-06,
      "loss": 0.0474,
      "step": 4196
    },
    {
      "epoch": 0.9643841911764706,
      "grad_norm": 1.1888041496276855,
      "learning_rate": 8.96905637254902e-06,
      "loss": 0.0641,
      "step": 4197
    },
    {
      "epoch": 0.9646139705882353,
      "grad_norm": 0.9403887391090393,
      "learning_rate": 8.968545751633988e-06,
      "loss": 0.0766,
      "step": 4198
    },
    {
      "epoch": 0.96484375,
      "grad_norm": 1.0548348426818848,
      "learning_rate": 8.968035130718954e-06,
      "loss": 0.0602,
      "step": 4199
    },
    {
      "epoch": 0.9650735294117647,
      "grad_norm": 1.2717002630233765,
      "learning_rate": 8.967524509803922e-06,
      "loss": 0.0925,
      "step": 4200
    },
    {
      "epoch": 0.9653033088235294,
      "grad_norm": 0.911730945110321,
      "learning_rate": 8.967013888888889e-06,
      "loss": 0.0471,
      "step": 4201
    },
    {
      "epoch": 0.9655330882352942,
      "grad_norm": 1.2841495275497437,
      "learning_rate": 8.966503267973858e-06,
      "loss": 0.0639,
      "step": 4202
    },
    {
      "epoch": 0.9657628676470589,
      "grad_norm": 0.9749406576156616,
      "learning_rate": 8.965992647058824e-06,
      "loss": 0.0835,
      "step": 4203
    },
    {
      "epoch": 0.9659926470588235,
      "grad_norm": 0.9313331246376038,
      "learning_rate": 8.965482026143792e-06,
      "loss": 0.0562,
      "step": 4204
    },
    {
      "epoch": 0.9662224264705882,
      "grad_norm": 0.761752724647522,
      "learning_rate": 8.964971405228758e-06,
      "loss": 0.0517,
      "step": 4205
    },
    {
      "epoch": 0.9664522058823529,
      "grad_norm": 0.9005597233772278,
      "learning_rate": 8.964460784313726e-06,
      "loss": 0.056,
      "step": 4206
    },
    {
      "epoch": 0.9666819852941176,
      "grad_norm": 1.5215415954589844,
      "learning_rate": 8.963950163398694e-06,
      "loss": 0.0969,
      "step": 4207
    },
    {
      "epoch": 0.9669117647058824,
      "grad_norm": 1.1901891231536865,
      "learning_rate": 8.96343954248366e-06,
      "loss": 0.0635,
      "step": 4208
    },
    {
      "epoch": 0.9671415441176471,
      "grad_norm": 1.3362393379211426,
      "learning_rate": 8.962928921568628e-06,
      "loss": 0.0859,
      "step": 4209
    },
    {
      "epoch": 0.9673713235294118,
      "grad_norm": 1.1840219497680664,
      "learning_rate": 8.962418300653596e-06,
      "loss": 0.0639,
      "step": 4210
    },
    {
      "epoch": 0.9676011029411765,
      "grad_norm": 1.0364543199539185,
      "learning_rate": 8.961907679738564e-06,
      "loss": 0.0994,
      "step": 4211
    },
    {
      "epoch": 0.9678308823529411,
      "grad_norm": 0.9458850026130676,
      "learning_rate": 8.96139705882353e-06,
      "loss": 0.0639,
      "step": 4212
    },
    {
      "epoch": 0.9680606617647058,
      "grad_norm": 1.0632566213607788,
      "learning_rate": 8.960886437908498e-06,
      "loss": 0.0791,
      "step": 4213
    },
    {
      "epoch": 0.9682904411764706,
      "grad_norm": 0.9293521046638489,
      "learning_rate": 8.960375816993466e-06,
      "loss": 0.0524,
      "step": 4214
    },
    {
      "epoch": 0.9685202205882353,
      "grad_norm": 1.0613716840744019,
      "learning_rate": 8.959865196078432e-06,
      "loss": 0.0806,
      "step": 4215
    },
    {
      "epoch": 0.96875,
      "grad_norm": 1.229037880897522,
      "learning_rate": 8.9593545751634e-06,
      "loss": 0.0894,
      "step": 4216
    },
    {
      "epoch": 0.9689797794117647,
      "grad_norm": 1.1268419027328491,
      "learning_rate": 8.958843954248366e-06,
      "loss": 0.0927,
      "step": 4217
    },
    {
      "epoch": 0.9692095588235294,
      "grad_norm": 1.4296457767486572,
      "learning_rate": 8.958333333333334e-06,
      "loss": 0.1141,
      "step": 4218
    },
    {
      "epoch": 0.9694393382352942,
      "grad_norm": 0.867005467414856,
      "learning_rate": 8.957822712418302e-06,
      "loss": 0.0692,
      "step": 4219
    },
    {
      "epoch": 0.9696691176470589,
      "grad_norm": 1.3471819162368774,
      "learning_rate": 8.957312091503268e-06,
      "loss": 0.0941,
      "step": 4220
    },
    {
      "epoch": 0.9698988970588235,
      "grad_norm": 0.9165520071983337,
      "learning_rate": 8.956801470588236e-06,
      "loss": 0.0481,
      "step": 4221
    },
    {
      "epoch": 0.9701286764705882,
      "grad_norm": 1.3150207996368408,
      "learning_rate": 8.956290849673203e-06,
      "loss": 0.0747,
      "step": 4222
    },
    {
      "epoch": 0.9703584558823529,
      "grad_norm": 0.9323493242263794,
      "learning_rate": 8.955780228758171e-06,
      "loss": 0.0706,
      "step": 4223
    },
    {
      "epoch": 0.9705882352941176,
      "grad_norm": 0.9808169603347778,
      "learning_rate": 8.955269607843137e-06,
      "loss": 0.0595,
      "step": 4224
    },
    {
      "epoch": 0.9708180147058824,
      "grad_norm": 0.9206007122993469,
      "learning_rate": 8.954758986928105e-06,
      "loss": 0.0612,
      "step": 4225
    },
    {
      "epoch": 0.9710477941176471,
      "grad_norm": 0.9392486214637756,
      "learning_rate": 8.954248366013073e-06,
      "loss": 0.0694,
      "step": 4226
    },
    {
      "epoch": 0.9712775735294118,
      "grad_norm": 0.9407840967178345,
      "learning_rate": 8.95373774509804e-06,
      "loss": 0.0575,
      "step": 4227
    },
    {
      "epoch": 0.9715073529411765,
      "grad_norm": 1.1609400510787964,
      "learning_rate": 8.953227124183007e-06,
      "loss": 0.0713,
      "step": 4228
    },
    {
      "epoch": 0.9717371323529411,
      "grad_norm": 0.8024166822433472,
      "learning_rate": 8.952716503267973e-06,
      "loss": 0.052,
      "step": 4229
    },
    {
      "epoch": 0.9719669117647058,
      "grad_norm": 1.2229315042495728,
      "learning_rate": 8.952205882352943e-06,
      "loss": 0.0518,
      "step": 4230
    },
    {
      "epoch": 0.9721966911764706,
      "grad_norm": 0.8817944526672363,
      "learning_rate": 8.951695261437909e-06,
      "loss": 0.0802,
      "step": 4231
    },
    {
      "epoch": 0.9724264705882353,
      "grad_norm": 1.0214561223983765,
      "learning_rate": 8.951184640522877e-06,
      "loss": 0.0601,
      "step": 4232
    },
    {
      "epoch": 0.97265625,
      "grad_norm": 0.9299923777580261,
      "learning_rate": 8.950674019607843e-06,
      "loss": 0.0779,
      "step": 4233
    },
    {
      "epoch": 0.9728860294117647,
      "grad_norm": 1.0242085456848145,
      "learning_rate": 8.950163398692811e-06,
      "loss": 0.0846,
      "step": 4234
    },
    {
      "epoch": 0.9731158088235294,
      "grad_norm": 0.9833985567092896,
      "learning_rate": 8.949652777777779e-06,
      "loss": 0.0741,
      "step": 4235
    },
    {
      "epoch": 0.9733455882352942,
      "grad_norm": 0.8608165383338928,
      "learning_rate": 8.949142156862745e-06,
      "loss": 0.0497,
      "step": 4236
    },
    {
      "epoch": 0.9735753676470589,
      "grad_norm": 0.8621416687965393,
      "learning_rate": 8.948631535947713e-06,
      "loss": 0.0275,
      "step": 4237
    },
    {
      "epoch": 0.9738051470588235,
      "grad_norm": 1.124927043914795,
      "learning_rate": 8.94812091503268e-06,
      "loss": 0.1008,
      "step": 4238
    },
    {
      "epoch": 0.9740349264705882,
      "grad_norm": 0.9515196084976196,
      "learning_rate": 8.947610294117649e-06,
      "loss": 0.0625,
      "step": 4239
    },
    {
      "epoch": 0.9742647058823529,
      "grad_norm": 1.0036145448684692,
      "learning_rate": 8.947099673202615e-06,
      "loss": 0.0651,
      "step": 4240
    },
    {
      "epoch": 0.9744944852941176,
      "grad_norm": 1.0945508480072021,
      "learning_rate": 8.946589052287583e-06,
      "loss": 0.0928,
      "step": 4241
    },
    {
      "epoch": 0.9747242647058824,
      "grad_norm": 1.163550615310669,
      "learning_rate": 8.94607843137255e-06,
      "loss": 0.0755,
      "step": 4242
    },
    {
      "epoch": 0.9749540441176471,
      "grad_norm": 0.95521080493927,
      "learning_rate": 8.945567810457517e-06,
      "loss": 0.0809,
      "step": 4243
    },
    {
      "epoch": 0.9751838235294118,
      "grad_norm": 0.9569770097732544,
      "learning_rate": 8.945057189542485e-06,
      "loss": 0.0592,
      "step": 4244
    },
    {
      "epoch": 0.9754136029411765,
      "grad_norm": 1.2383532524108887,
      "learning_rate": 8.94454656862745e-06,
      "loss": 0.0894,
      "step": 4245
    },
    {
      "epoch": 0.9756433823529411,
      "grad_norm": 1.113795518875122,
      "learning_rate": 8.94403594771242e-06,
      "loss": 0.0778,
      "step": 4246
    },
    {
      "epoch": 0.9758731617647058,
      "grad_norm": 1.0192922353744507,
      "learning_rate": 8.943525326797386e-06,
      "loss": 0.0587,
      "step": 4247
    },
    {
      "epoch": 0.9761029411764706,
      "grad_norm": 0.8470777869224548,
      "learning_rate": 8.943014705882354e-06,
      "loss": 0.0475,
      "step": 4248
    },
    {
      "epoch": 0.9763327205882353,
      "grad_norm": 0.9490348100662231,
      "learning_rate": 8.94250408496732e-06,
      "loss": 0.0779,
      "step": 4249
    },
    {
      "epoch": 0.9765625,
      "grad_norm": 1.1152592897415161,
      "learning_rate": 8.941993464052288e-06,
      "loss": 0.0925,
      "step": 4250
    },
    {
      "epoch": 0.9767922794117647,
      "grad_norm": 0.8949683904647827,
      "learning_rate": 8.941482843137256e-06,
      "loss": 0.0853,
      "step": 4251
    },
    {
      "epoch": 0.9770220588235294,
      "grad_norm": 0.8697465658187866,
      "learning_rate": 8.940972222222222e-06,
      "loss": 0.0645,
      "step": 4252
    },
    {
      "epoch": 0.9772518382352942,
      "grad_norm": 1.0159906148910522,
      "learning_rate": 8.94046160130719e-06,
      "loss": 0.0427,
      "step": 4253
    },
    {
      "epoch": 0.9774816176470589,
      "grad_norm": 1.051917552947998,
      "learning_rate": 8.939950980392158e-06,
      "loss": 0.0667,
      "step": 4254
    },
    {
      "epoch": 0.9777113970588235,
      "grad_norm": 0.9185096025466919,
      "learning_rate": 8.939440359477126e-06,
      "loss": 0.0798,
      "step": 4255
    },
    {
      "epoch": 0.9779411764705882,
      "grad_norm": 0.9491533637046814,
      "learning_rate": 8.938929738562092e-06,
      "loss": 0.0572,
      "step": 4256
    },
    {
      "epoch": 0.9781709558823529,
      "grad_norm": 1.232101559638977,
      "learning_rate": 8.93841911764706e-06,
      "loss": 0.0931,
      "step": 4257
    },
    {
      "epoch": 0.9784007352941176,
      "grad_norm": 1.0761284828186035,
      "learning_rate": 8.937908496732028e-06,
      "loss": 0.048,
      "step": 4258
    },
    {
      "epoch": 0.9786305147058824,
      "grad_norm": 1.3531957864761353,
      "learning_rate": 8.937397875816994e-06,
      "loss": 0.0959,
      "step": 4259
    },
    {
      "epoch": 0.9788602941176471,
      "grad_norm": 0.8571974039077759,
      "learning_rate": 8.936887254901962e-06,
      "loss": 0.0806,
      "step": 4260
    },
    {
      "epoch": 0.9790900735294118,
      "grad_norm": 1.1429330110549927,
      "learning_rate": 8.936376633986928e-06,
      "loss": 0.0742,
      "step": 4261
    },
    {
      "epoch": 0.9793198529411765,
      "grad_norm": 0.8809235095977783,
      "learning_rate": 8.935866013071896e-06,
      "loss": 0.0614,
      "step": 4262
    },
    {
      "epoch": 0.9795496323529411,
      "grad_norm": 1.0714952945709229,
      "learning_rate": 8.935355392156864e-06,
      "loss": 0.0585,
      "step": 4263
    },
    {
      "epoch": 0.9797794117647058,
      "grad_norm": 0.8364285826683044,
      "learning_rate": 8.93484477124183e-06,
      "loss": 0.0601,
      "step": 4264
    },
    {
      "epoch": 0.9800091911764706,
      "grad_norm": 0.8406152129173279,
      "learning_rate": 8.934334150326798e-06,
      "loss": 0.0433,
      "step": 4265
    },
    {
      "epoch": 0.9802389705882353,
      "grad_norm": 1.3497905731201172,
      "learning_rate": 8.933823529411766e-06,
      "loss": 0.0796,
      "step": 4266
    },
    {
      "epoch": 0.98046875,
      "grad_norm": 1.0223898887634277,
      "learning_rate": 8.933312908496733e-06,
      "loss": 0.0644,
      "step": 4267
    },
    {
      "epoch": 0.9806985294117647,
      "grad_norm": 1.509519100189209,
      "learning_rate": 8.9328022875817e-06,
      "loss": 0.0662,
      "step": 4268
    },
    {
      "epoch": 0.9809283088235294,
      "grad_norm": 1.1232746839523315,
      "learning_rate": 8.932291666666668e-06,
      "loss": 0.0665,
      "step": 4269
    },
    {
      "epoch": 0.9811580882352942,
      "grad_norm": 0.8358004689216614,
      "learning_rate": 8.931781045751635e-06,
      "loss": 0.0666,
      "step": 4270
    },
    {
      "epoch": 0.9813878676470589,
      "grad_norm": 1.0733963251113892,
      "learning_rate": 8.931270424836602e-06,
      "loss": 0.0647,
      "step": 4271
    },
    {
      "epoch": 0.9816176470588235,
      "grad_norm": 1.1287634372711182,
      "learning_rate": 8.93075980392157e-06,
      "loss": 0.0637,
      "step": 4272
    },
    {
      "epoch": 0.9818474264705882,
      "grad_norm": 0.7570160031318665,
      "learning_rate": 8.930249183006536e-06,
      "loss": 0.051,
      "step": 4273
    },
    {
      "epoch": 0.9820772058823529,
      "grad_norm": 1.1907199621200562,
      "learning_rate": 8.929738562091505e-06,
      "loss": 0.0819,
      "step": 4274
    },
    {
      "epoch": 0.9823069852941176,
      "grad_norm": 0.8630119562149048,
      "learning_rate": 8.929227941176471e-06,
      "loss": 0.0558,
      "step": 4275
    },
    {
      "epoch": 0.9825367647058824,
      "grad_norm": 1.4641532897949219,
      "learning_rate": 8.928717320261439e-06,
      "loss": 0.1008,
      "step": 4276
    },
    {
      "epoch": 0.9827665441176471,
      "grad_norm": 1.062638282775879,
      "learning_rate": 8.928206699346405e-06,
      "loss": 0.0493,
      "step": 4277
    },
    {
      "epoch": 0.9829963235294118,
      "grad_norm": 1.2153998613357544,
      "learning_rate": 8.927696078431373e-06,
      "loss": 0.0666,
      "step": 4278
    },
    {
      "epoch": 0.9832261029411765,
      "grad_norm": 1.0815281867980957,
      "learning_rate": 8.927185457516341e-06,
      "loss": 0.0822,
      "step": 4279
    },
    {
      "epoch": 0.9834558823529411,
      "grad_norm": 0.8840076327323914,
      "learning_rate": 8.926674836601307e-06,
      "loss": 0.0596,
      "step": 4280
    },
    {
      "epoch": 0.9836856617647058,
      "grad_norm": 1.1580312252044678,
      "learning_rate": 8.926164215686275e-06,
      "loss": 0.0551,
      "step": 4281
    },
    {
      "epoch": 0.9839154411764706,
      "grad_norm": 1.2122783660888672,
      "learning_rate": 8.925653594771243e-06,
      "loss": 0.0673,
      "step": 4282
    },
    {
      "epoch": 0.9841452205882353,
      "grad_norm": 0.7835232615470886,
      "learning_rate": 8.92514297385621e-06,
      "loss": 0.0561,
      "step": 4283
    },
    {
      "epoch": 0.984375,
      "grad_norm": 0.8415451049804688,
      "learning_rate": 8.924632352941177e-06,
      "loss": 0.0603,
      "step": 4284
    },
    {
      "epoch": 0.9846047794117647,
      "grad_norm": 1.0586538314819336,
      "learning_rate": 8.924121732026145e-06,
      "loss": 0.0642,
      "step": 4285
    },
    {
      "epoch": 0.9848345588235294,
      "grad_norm": 1.1368037462234497,
      "learning_rate": 8.923611111111113e-06,
      "loss": 0.0705,
      "step": 4286
    },
    {
      "epoch": 0.9850643382352942,
      "grad_norm": 0.6741980314254761,
      "learning_rate": 8.923100490196079e-06,
      "loss": 0.0504,
      "step": 4287
    },
    {
      "epoch": 0.9852941176470589,
      "grad_norm": 0.8257363438606262,
      "learning_rate": 8.922589869281047e-06,
      "loss": 0.0457,
      "step": 4288
    },
    {
      "epoch": 0.9855238970588235,
      "grad_norm": 0.9024950861930847,
      "learning_rate": 8.922079248366013e-06,
      "loss": 0.0649,
      "step": 4289
    },
    {
      "epoch": 0.9857536764705882,
      "grad_norm": 0.8403106331825256,
      "learning_rate": 8.921568627450982e-06,
      "loss": 0.0637,
      "step": 4290
    },
    {
      "epoch": 0.9859834558823529,
      "grad_norm": 1.2526061534881592,
      "learning_rate": 8.921058006535949e-06,
      "loss": 0.1004,
      "step": 4291
    },
    {
      "epoch": 0.9862132352941176,
      "grad_norm": 1.0546387434005737,
      "learning_rate": 8.920547385620916e-06,
      "loss": 0.0763,
      "step": 4292
    },
    {
      "epoch": 0.9864430147058824,
      "grad_norm": 0.8295801877975464,
      "learning_rate": 8.920036764705883e-06,
      "loss": 0.0461,
      "step": 4293
    },
    {
      "epoch": 0.9866727941176471,
      "grad_norm": 0.8810415863990784,
      "learning_rate": 8.91952614379085e-06,
      "loss": 0.0488,
      "step": 4294
    },
    {
      "epoch": 0.9869025735294118,
      "grad_norm": 0.8492305874824524,
      "learning_rate": 8.919015522875818e-06,
      "loss": 0.0664,
      "step": 4295
    },
    {
      "epoch": 0.9871323529411765,
      "grad_norm": 0.8885992765426636,
      "learning_rate": 8.918504901960785e-06,
      "loss": 0.0407,
      "step": 4296
    },
    {
      "epoch": 0.9873621323529411,
      "grad_norm": 0.9314764142036438,
      "learning_rate": 8.917994281045752e-06,
      "loss": 0.0866,
      "step": 4297
    },
    {
      "epoch": 0.9875919117647058,
      "grad_norm": 0.9647538661956787,
      "learning_rate": 8.91748366013072e-06,
      "loss": 0.0509,
      "step": 4298
    },
    {
      "epoch": 0.9878216911764706,
      "grad_norm": 1.1267647743225098,
      "learning_rate": 8.916973039215686e-06,
      "loss": 0.0727,
      "step": 4299
    },
    {
      "epoch": 0.9880514705882353,
      "grad_norm": 1.0835726261138916,
      "learning_rate": 8.916462418300654e-06,
      "loss": 0.0554,
      "step": 4300
    },
    {
      "epoch": 0.98828125,
      "grad_norm": 1.0799647569656372,
      "learning_rate": 8.915951797385622e-06,
      "loss": 0.0724,
      "step": 4301
    },
    {
      "epoch": 0.9885110294117647,
      "grad_norm": 1.1233441829681396,
      "learning_rate": 8.91544117647059e-06,
      "loss": 0.1023,
      "step": 4302
    },
    {
      "epoch": 0.9887408088235294,
      "grad_norm": 1.0841290950775146,
      "learning_rate": 8.914930555555556e-06,
      "loss": 0.0684,
      "step": 4303
    },
    {
      "epoch": 0.9889705882352942,
      "grad_norm": 1.5590784549713135,
      "learning_rate": 8.914419934640524e-06,
      "loss": 0.1067,
      "step": 4304
    },
    {
      "epoch": 0.9892003676470589,
      "grad_norm": 0.9140962362289429,
      "learning_rate": 8.91390931372549e-06,
      "loss": 0.0602,
      "step": 4305
    },
    {
      "epoch": 0.9894301470588235,
      "grad_norm": 0.8790597915649414,
      "learning_rate": 8.913398692810458e-06,
      "loss": 0.0578,
      "step": 4306
    },
    {
      "epoch": 0.9896599264705882,
      "grad_norm": 0.9565037488937378,
      "learning_rate": 8.912888071895426e-06,
      "loss": 0.0431,
      "step": 4307
    },
    {
      "epoch": 0.9898897058823529,
      "grad_norm": 1.367881178855896,
      "learning_rate": 8.912377450980392e-06,
      "loss": 0.0846,
      "step": 4308
    },
    {
      "epoch": 0.9901194852941176,
      "grad_norm": 1.0097479820251465,
      "learning_rate": 8.91186683006536e-06,
      "loss": 0.0561,
      "step": 4309
    },
    {
      "epoch": 0.9903492647058824,
      "grad_norm": 0.8586291670799255,
      "learning_rate": 8.911356209150328e-06,
      "loss": 0.0412,
      "step": 4310
    },
    {
      "epoch": 0.9905790441176471,
      "grad_norm": 1.1598418951034546,
      "learning_rate": 8.910845588235296e-06,
      "loss": 0.0922,
      "step": 4311
    },
    {
      "epoch": 0.9908088235294118,
      "grad_norm": 1.014814019203186,
      "learning_rate": 8.910334967320262e-06,
      "loss": 0.0597,
      "step": 4312
    },
    {
      "epoch": 0.9910386029411765,
      "grad_norm": 1.4512056112289429,
      "learning_rate": 8.90982434640523e-06,
      "loss": 0.118,
      "step": 4313
    },
    {
      "epoch": 0.9912683823529411,
      "grad_norm": 0.9705371260643005,
      "learning_rate": 8.909313725490198e-06,
      "loss": 0.0842,
      "step": 4314
    },
    {
      "epoch": 0.9914981617647058,
      "grad_norm": 1.1110540628433228,
      "learning_rate": 8.908803104575164e-06,
      "loss": 0.0804,
      "step": 4315
    },
    {
      "epoch": 0.9917279411764706,
      "grad_norm": 0.8310099840164185,
      "learning_rate": 8.908292483660132e-06,
      "loss": 0.052,
      "step": 4316
    },
    {
      "epoch": 0.9919577205882353,
      "grad_norm": 1.1262052059173584,
      "learning_rate": 8.907781862745098e-06,
      "loss": 0.0691,
      "step": 4317
    },
    {
      "epoch": 0.9921875,
      "grad_norm": 1.0049861669540405,
      "learning_rate": 8.907271241830067e-06,
      "loss": 0.0647,
      "step": 4318
    },
    {
      "epoch": 0.9924172794117647,
      "grad_norm": 0.746179461479187,
      "learning_rate": 8.906760620915033e-06,
      "loss": 0.054,
      "step": 4319
    },
    {
      "epoch": 0.9926470588235294,
      "grad_norm": 1.0135754346847534,
      "learning_rate": 8.906250000000001e-06,
      "loss": 0.06,
      "step": 4320
    },
    {
      "epoch": 0.9928768382352942,
      "grad_norm": 0.9337589144706726,
      "learning_rate": 8.905739379084968e-06,
      "loss": 0.0663,
      "step": 4321
    },
    {
      "epoch": 0.9931066176470589,
      "grad_norm": 0.8451431393623352,
      "learning_rate": 8.905228758169935e-06,
      "loss": 0.0588,
      "step": 4322
    },
    {
      "epoch": 0.9933363970588235,
      "grad_norm": 0.9692853689193726,
      "learning_rate": 8.904718137254903e-06,
      "loss": 0.0724,
      "step": 4323
    },
    {
      "epoch": 0.9935661764705882,
      "grad_norm": 1.0137206315994263,
      "learning_rate": 8.90420751633987e-06,
      "loss": 0.0563,
      "step": 4324
    },
    {
      "epoch": 0.9937959558823529,
      "grad_norm": 1.2532954216003418,
      "learning_rate": 8.903696895424837e-06,
      "loss": 0.0805,
      "step": 4325
    },
    {
      "epoch": 0.9940257352941176,
      "grad_norm": 1.0097285509109497,
      "learning_rate": 8.903186274509803e-06,
      "loss": 0.0687,
      "step": 4326
    },
    {
      "epoch": 0.9942555147058824,
      "grad_norm": 0.9178627133369446,
      "learning_rate": 8.902675653594773e-06,
      "loss": 0.0604,
      "step": 4327
    },
    {
      "epoch": 0.9944852941176471,
      "grad_norm": 1.427428126335144,
      "learning_rate": 8.902165032679739e-06,
      "loss": 0.0822,
      "step": 4328
    },
    {
      "epoch": 0.9947150735294118,
      "grad_norm": 1.2520915269851685,
      "learning_rate": 8.901654411764707e-06,
      "loss": 0.0861,
      "step": 4329
    },
    {
      "epoch": 0.9949448529411765,
      "grad_norm": 0.9797918796539307,
      "learning_rate": 8.901143790849673e-06,
      "loss": 0.0773,
      "step": 4330
    },
    {
      "epoch": 0.9951746323529411,
      "grad_norm": 1.145998239517212,
      "learning_rate": 8.900633169934641e-06,
      "loss": 0.0848,
      "step": 4331
    },
    {
      "epoch": 0.9954044117647058,
      "grad_norm": 1.025386929512024,
      "learning_rate": 8.900122549019609e-06,
      "loss": 0.103,
      "step": 4332
    },
    {
      "epoch": 0.9956341911764706,
      "grad_norm": 0.9345531463623047,
      "learning_rate": 8.899611928104575e-06,
      "loss": 0.0779,
      "step": 4333
    },
    {
      "epoch": 0.9958639705882353,
      "grad_norm": 0.7565236687660217,
      "learning_rate": 8.899101307189543e-06,
      "loss": 0.0605,
      "step": 4334
    },
    {
      "epoch": 0.99609375,
      "grad_norm": 0.8434467911720276,
      "learning_rate": 8.89859068627451e-06,
      "loss": 0.0568,
      "step": 4335
    },
    {
      "epoch": 0.9963235294117647,
      "grad_norm": 1.0770660638809204,
      "learning_rate": 8.898080065359479e-06,
      "loss": 0.0456,
      "step": 4336
    },
    {
      "epoch": 0.9965533088235294,
      "grad_norm": 1.121018886566162,
      "learning_rate": 8.897569444444445e-06,
      "loss": 0.0672,
      "step": 4337
    },
    {
      "epoch": 0.9967830882352942,
      "grad_norm": 1.3723888397216797,
      "learning_rate": 8.897058823529413e-06,
      "loss": 0.0838,
      "step": 4338
    },
    {
      "epoch": 0.9970128676470589,
      "grad_norm": 0.9375700950622559,
      "learning_rate": 8.89654820261438e-06,
      "loss": 0.0628,
      "step": 4339
    },
    {
      "epoch": 0.9972426470588235,
      "grad_norm": 1.05080246925354,
      "learning_rate": 8.896037581699347e-06,
      "loss": 0.0557,
      "step": 4340
    },
    {
      "epoch": 0.9974724264705882,
      "grad_norm": 1.1320459842681885,
      "learning_rate": 8.895526960784315e-06,
      "loss": 0.0704,
      "step": 4341
    },
    {
      "epoch": 0.9977022058823529,
      "grad_norm": 1.069596767425537,
      "learning_rate": 8.89501633986928e-06,
      "loss": 0.0668,
      "step": 4342
    },
    {
      "epoch": 0.9979319852941176,
      "grad_norm": 1.8342963457107544,
      "learning_rate": 8.894505718954249e-06,
      "loss": 0.1148,
      "step": 4343
    },
    {
      "epoch": 0.9981617647058824,
      "grad_norm": 1.2225098609924316,
      "learning_rate": 8.893995098039216e-06,
      "loss": 0.0964,
      "step": 4344
    },
    {
      "epoch": 0.9983915441176471,
      "grad_norm": 1.0715175867080688,
      "learning_rate": 8.893484477124184e-06,
      "loss": 0.0696,
      "step": 4345
    },
    {
      "epoch": 0.9986213235294118,
      "grad_norm": 1.03408682346344,
      "learning_rate": 8.89297385620915e-06,
      "loss": 0.058,
      "step": 4346
    },
    {
      "epoch": 0.9988511029411765,
      "grad_norm": 1.1120179891586304,
      "learning_rate": 8.892463235294118e-06,
      "loss": 0.0793,
      "step": 4347
    },
    {
      "epoch": 0.9990808823529411,
      "grad_norm": 1.1283482313156128,
      "learning_rate": 8.891952614379086e-06,
      "loss": 0.0692,
      "step": 4348
    },
    {
      "epoch": 0.9993106617647058,
      "grad_norm": 0.918944776058197,
      "learning_rate": 8.891441993464052e-06,
      "loss": 0.0673,
      "step": 4349
    },
    {
      "epoch": 0.9995404411764706,
      "grad_norm": 1.3464348316192627,
      "learning_rate": 8.89093137254902e-06,
      "loss": 0.0811,
      "step": 4350
    },
    {
      "epoch": 0.9997702205882353,
      "grad_norm": 1.3460357189178467,
      "learning_rate": 8.890420751633988e-06,
      "loss": 0.0676,
      "step": 4351
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.0930063724517822,
      "learning_rate": 8.889910130718954e-06,
      "loss": 0.0635,
      "step": 4352
    },
    {
      "epoch": 1.0002297794117647,
      "grad_norm": 0.966655433177948,
      "learning_rate": 8.889399509803922e-06,
      "loss": 0.0591,
      "step": 4353
    },
    {
      "epoch": 1.0004595588235294,
      "grad_norm": 0.7413111329078674,
      "learning_rate": 8.888888888888888e-06,
      "loss": 0.06,
      "step": 4354
    },
    {
      "epoch": 1.0006893382352942,
      "grad_norm": 1.0406097173690796,
      "learning_rate": 8.888378267973858e-06,
      "loss": 0.0512,
      "step": 4355
    },
    {
      "epoch": 1.0009191176470589,
      "grad_norm": 0.8093470335006714,
      "learning_rate": 8.887867647058824e-06,
      "loss": 0.0714,
      "step": 4356
    },
    {
      "epoch": 1.0011488970588236,
      "grad_norm": 0.7661073803901672,
      "learning_rate": 8.887357026143792e-06,
      "loss": 0.0498,
      "step": 4357
    },
    {
      "epoch": 1.0013786764705883,
      "grad_norm": 0.8981318473815918,
      "learning_rate": 8.886846405228758e-06,
      "loss": 0.0578,
      "step": 4358
    },
    {
      "epoch": 1.001608455882353,
      "grad_norm": 1.4289108514785767,
      "learning_rate": 8.886335784313726e-06,
      "loss": 0.1103,
      "step": 4359
    },
    {
      "epoch": 1.0018382352941178,
      "grad_norm": 1.0492225885391235,
      "learning_rate": 8.885825163398694e-06,
      "loss": 0.0877,
      "step": 4360
    },
    {
      "epoch": 1.0020680147058822,
      "grad_norm": 0.9600569009780884,
      "learning_rate": 8.88531454248366e-06,
      "loss": 0.0619,
      "step": 4361
    },
    {
      "epoch": 1.002297794117647,
      "grad_norm": 1.5811233520507812,
      "learning_rate": 8.884803921568628e-06,
      "loss": 0.0699,
      "step": 4362
    },
    {
      "epoch": 1.0025275735294117,
      "grad_norm": 0.9857392311096191,
      "learning_rate": 8.884293300653596e-06,
      "loss": 0.0672,
      "step": 4363
    },
    {
      "epoch": 1.0027573529411764,
      "grad_norm": 1.4529722929000854,
      "learning_rate": 8.883782679738564e-06,
      "loss": 0.083,
      "step": 4364
    },
    {
      "epoch": 1.0029871323529411,
      "grad_norm": 1.1563714742660522,
      "learning_rate": 8.88327205882353e-06,
      "loss": 0.0511,
      "step": 4365
    },
    {
      "epoch": 1.0032169117647058,
      "grad_norm": 0.8685914278030396,
      "learning_rate": 8.882761437908498e-06,
      "loss": 0.0799,
      "step": 4366
    },
    {
      "epoch": 1.0034466911764706,
      "grad_norm": 1.246041178703308,
      "learning_rate": 8.882250816993465e-06,
      "loss": 0.0767,
      "step": 4367
    },
    {
      "epoch": 1.0036764705882353,
      "grad_norm": 0.9939393401145935,
      "learning_rate": 8.881740196078432e-06,
      "loss": 0.0502,
      "step": 4368
    },
    {
      "epoch": 1.00390625,
      "grad_norm": 0.9497681856155396,
      "learning_rate": 8.8812295751634e-06,
      "loss": 0.076,
      "step": 4369
    },
    {
      "epoch": 1.0041360294117647,
      "grad_norm": 0.965958833694458,
      "learning_rate": 8.880718954248366e-06,
      "loss": 0.0704,
      "step": 4370
    },
    {
      "epoch": 1.0043658088235294,
      "grad_norm": 1.076581358909607,
      "learning_rate": 8.880208333333335e-06,
      "loss": 0.0615,
      "step": 4371
    },
    {
      "epoch": 1.0045955882352942,
      "grad_norm": 0.9287131428718567,
      "learning_rate": 8.879697712418301e-06,
      "loss": 0.0647,
      "step": 4372
    },
    {
      "epoch": 1.0048253676470589,
      "grad_norm": 1.2772794961929321,
      "learning_rate": 8.87918709150327e-06,
      "loss": 0.1001,
      "step": 4373
    },
    {
      "epoch": 1.0050551470588236,
      "grad_norm": 0.8970334529876709,
      "learning_rate": 8.878676470588235e-06,
      "loss": 0.0764,
      "step": 4374
    },
    {
      "epoch": 1.0052849264705883,
      "grad_norm": 1.2727020978927612,
      "learning_rate": 8.878165849673203e-06,
      "loss": 0.0666,
      "step": 4375
    },
    {
      "epoch": 1.005514705882353,
      "grad_norm": 1.2098791599273682,
      "learning_rate": 8.877655228758171e-06,
      "loss": 0.0755,
      "step": 4376
    },
    {
      "epoch": 1.0057444852941178,
      "grad_norm": 0.6586190462112427,
      "learning_rate": 8.877144607843137e-06,
      "loss": 0.042,
      "step": 4377
    },
    {
      "epoch": 1.0059742647058822,
      "grad_norm": 0.7914232611656189,
      "learning_rate": 8.876633986928105e-06,
      "loss": 0.0412,
      "step": 4378
    },
    {
      "epoch": 1.006204044117647,
      "grad_norm": 1.1281828880310059,
      "learning_rate": 8.876123366013073e-06,
      "loss": 0.0923,
      "step": 4379
    },
    {
      "epoch": 1.0064338235294117,
      "grad_norm": 0.8908593058586121,
      "learning_rate": 8.87561274509804e-06,
      "loss": 0.0376,
      "step": 4380
    },
    {
      "epoch": 1.0066636029411764,
      "grad_norm": 1.108887791633606,
      "learning_rate": 8.875102124183007e-06,
      "loss": 0.0867,
      "step": 4381
    },
    {
      "epoch": 1.0068933823529411,
      "grad_norm": 0.8104047775268555,
      "learning_rate": 8.874591503267975e-06,
      "loss": 0.0479,
      "step": 4382
    },
    {
      "epoch": 1.0071231617647058,
      "grad_norm": 1.0858545303344727,
      "learning_rate": 8.874080882352943e-06,
      "loss": 0.0663,
      "step": 4383
    },
    {
      "epoch": 1.0073529411764706,
      "grad_norm": 1.0237045288085938,
      "learning_rate": 8.873570261437909e-06,
      "loss": 0.0721,
      "step": 4384
    },
    {
      "epoch": 1.0075827205882353,
      "grad_norm": 0.9022312164306641,
      "learning_rate": 8.873059640522877e-06,
      "loss": 0.0482,
      "step": 4385
    },
    {
      "epoch": 1.0078125,
      "grad_norm": 1.0040946006774902,
      "learning_rate": 8.872549019607843e-06,
      "loss": 0.0682,
      "step": 4386
    },
    {
      "epoch": 1.0080422794117647,
      "grad_norm": 1.2394522428512573,
      "learning_rate": 8.87203839869281e-06,
      "loss": 0.067,
      "step": 4387
    },
    {
      "epoch": 1.0082720588235294,
      "grad_norm": 0.888737142086029,
      "learning_rate": 8.871527777777779e-06,
      "loss": 0.0572,
      "step": 4388
    },
    {
      "epoch": 1.0085018382352942,
      "grad_norm": 0.9264905452728271,
      "learning_rate": 8.871017156862747e-06,
      "loss": 0.0521,
      "step": 4389
    },
    {
      "epoch": 1.0087316176470589,
      "grad_norm": 0.9679253101348877,
      "learning_rate": 8.870506535947713e-06,
      "loss": 0.0693,
      "step": 4390
    },
    {
      "epoch": 1.0089613970588236,
      "grad_norm": 0.7229941487312317,
      "learning_rate": 8.86999591503268e-06,
      "loss": 0.0319,
      "step": 4391
    },
    {
      "epoch": 1.0091911764705883,
      "grad_norm": 1.018053650856018,
      "learning_rate": 8.869485294117648e-06,
      "loss": 0.0449,
      "step": 4392
    },
    {
      "epoch": 1.009420955882353,
      "grad_norm": 1.2479068040847778,
      "learning_rate": 8.868974673202615e-06,
      "loss": 0.0745,
      "step": 4393
    },
    {
      "epoch": 1.0096507352941178,
      "grad_norm": 1.115807056427002,
      "learning_rate": 8.868464052287582e-06,
      "loss": 0.0792,
      "step": 4394
    },
    {
      "epoch": 1.0098805147058822,
      "grad_norm": 1.0775365829467773,
      "learning_rate": 8.86795343137255e-06,
      "loss": 0.067,
      "step": 4395
    },
    {
      "epoch": 1.010110294117647,
      "grad_norm": 1.2476518154144287,
      "learning_rate": 8.867442810457516e-06,
      "loss": 0.0844,
      "step": 4396
    },
    {
      "epoch": 1.0103400735294117,
      "grad_norm": 0.8639766573905945,
      "learning_rate": 8.866932189542484e-06,
      "loss": 0.0393,
      "step": 4397
    },
    {
      "epoch": 1.0105698529411764,
      "grad_norm": 0.9761286377906799,
      "learning_rate": 8.86642156862745e-06,
      "loss": 0.0589,
      "step": 4398
    },
    {
      "epoch": 1.0107996323529411,
      "grad_norm": 0.7454819083213806,
      "learning_rate": 8.86591094771242e-06,
      "loss": 0.0549,
      "step": 4399
    },
    {
      "epoch": 1.0110294117647058,
      "grad_norm": 1.0236514806747437,
      "learning_rate": 8.865400326797386e-06,
      "loss": 0.0563,
      "step": 4400
    },
    {
      "epoch": 1.0112591911764706,
      "grad_norm": 0.8601915240287781,
      "learning_rate": 8.864889705882354e-06,
      "loss": 0.053,
      "step": 4401
    },
    {
      "epoch": 1.0114889705882353,
      "grad_norm": 1.3658621311187744,
      "learning_rate": 8.86437908496732e-06,
      "loss": 0.0855,
      "step": 4402
    },
    {
      "epoch": 1.01171875,
      "grad_norm": 1.233508825302124,
      "learning_rate": 8.863868464052288e-06,
      "loss": 0.104,
      "step": 4403
    },
    {
      "epoch": 1.0119485294117647,
      "grad_norm": 0.8513776063919067,
      "learning_rate": 8.863357843137256e-06,
      "loss": 0.0503,
      "step": 4404
    },
    {
      "epoch": 1.0121783088235294,
      "grad_norm": 0.8432444930076599,
      "learning_rate": 8.862847222222222e-06,
      "loss": 0.0609,
      "step": 4405
    },
    {
      "epoch": 1.0124080882352942,
      "grad_norm": 0.9912291765213013,
      "learning_rate": 8.86233660130719e-06,
      "loss": 0.0461,
      "step": 4406
    },
    {
      "epoch": 1.0126378676470589,
      "grad_norm": 1.357818603515625,
      "learning_rate": 8.861825980392158e-06,
      "loss": 0.0895,
      "step": 4407
    },
    {
      "epoch": 1.0128676470588236,
      "grad_norm": 1.0274025201797485,
      "learning_rate": 8.861315359477126e-06,
      "loss": 0.0823,
      "step": 4408
    },
    {
      "epoch": 1.0130974264705883,
      "grad_norm": 0.9643676280975342,
      "learning_rate": 8.860804738562092e-06,
      "loss": 0.062,
      "step": 4409
    },
    {
      "epoch": 1.013327205882353,
      "grad_norm": 1.0120141506195068,
      "learning_rate": 8.86029411764706e-06,
      "loss": 0.0723,
      "step": 4410
    },
    {
      "epoch": 1.0135569852941178,
      "grad_norm": 0.9631692171096802,
      "learning_rate": 8.859783496732028e-06,
      "loss": 0.0711,
      "step": 4411
    },
    {
      "epoch": 1.0137867647058822,
      "grad_norm": 0.7872936725616455,
      "learning_rate": 8.859272875816994e-06,
      "loss": 0.0521,
      "step": 4412
    },
    {
      "epoch": 1.014016544117647,
      "grad_norm": 0.7317188382148743,
      "learning_rate": 8.858762254901962e-06,
      "loss": 0.05,
      "step": 4413
    },
    {
      "epoch": 1.0142463235294117,
      "grad_norm": 0.9227484464645386,
      "learning_rate": 8.858251633986928e-06,
      "loss": 0.0653,
      "step": 4414
    },
    {
      "epoch": 1.0144761029411764,
      "grad_norm": 1.206123948097229,
      "learning_rate": 8.857741013071897e-06,
      "loss": 0.0757,
      "step": 4415
    },
    {
      "epoch": 1.0147058823529411,
      "grad_norm": 1.1701948642730713,
      "learning_rate": 8.857230392156864e-06,
      "loss": 0.0775,
      "step": 4416
    },
    {
      "epoch": 1.0149356617647058,
      "grad_norm": 0.9754148125648499,
      "learning_rate": 8.856719771241831e-06,
      "loss": 0.0665,
      "step": 4417
    },
    {
      "epoch": 1.0151654411764706,
      "grad_norm": 0.9492758512496948,
      "learning_rate": 8.856209150326798e-06,
      "loss": 0.0515,
      "step": 4418
    },
    {
      "epoch": 1.0153952205882353,
      "grad_norm": 0.881619393825531,
      "learning_rate": 8.855698529411765e-06,
      "loss": 0.0632,
      "step": 4419
    },
    {
      "epoch": 1.015625,
      "grad_norm": 1.112733006477356,
      "learning_rate": 8.855187908496733e-06,
      "loss": 0.0725,
      "step": 4420
    },
    {
      "epoch": 1.0158547794117647,
      "grad_norm": 0.8885475993156433,
      "learning_rate": 8.8546772875817e-06,
      "loss": 0.069,
      "step": 4421
    },
    {
      "epoch": 1.0160845588235294,
      "grad_norm": 0.83661288022995,
      "learning_rate": 8.854166666666667e-06,
      "loss": 0.0494,
      "step": 4422
    },
    {
      "epoch": 1.0163143382352942,
      "grad_norm": 1.2064311504364014,
      "learning_rate": 8.853656045751635e-06,
      "loss": 0.0623,
      "step": 4423
    },
    {
      "epoch": 1.0165441176470589,
      "grad_norm": 1.0851807594299316,
      "learning_rate": 8.853145424836603e-06,
      "loss": 0.0615,
      "step": 4424
    },
    {
      "epoch": 1.0167738970588236,
      "grad_norm": 0.9575889706611633,
      "learning_rate": 8.85263480392157e-06,
      "loss": 0.0386,
      "step": 4425
    },
    {
      "epoch": 1.0170036764705883,
      "grad_norm": 0.9959151148796082,
      "learning_rate": 8.852124183006537e-06,
      "loss": 0.0866,
      "step": 4426
    },
    {
      "epoch": 1.017233455882353,
      "grad_norm": 1.6097426414489746,
      "learning_rate": 8.851613562091505e-06,
      "loss": 0.1086,
      "step": 4427
    },
    {
      "epoch": 1.0174632352941178,
      "grad_norm": 1.4905486106872559,
      "learning_rate": 8.851102941176471e-06,
      "loss": 0.0714,
      "step": 4428
    },
    {
      "epoch": 1.0176930147058822,
      "grad_norm": 0.9780706167221069,
      "learning_rate": 8.850592320261439e-06,
      "loss": 0.0576,
      "step": 4429
    },
    {
      "epoch": 1.017922794117647,
      "grad_norm": 1.0208122730255127,
      "learning_rate": 8.850081699346405e-06,
      "loss": 0.0559,
      "step": 4430
    },
    {
      "epoch": 1.0181525735294117,
      "grad_norm": 0.8416871428489685,
      "learning_rate": 8.849571078431373e-06,
      "loss": 0.0428,
      "step": 4431
    },
    {
      "epoch": 1.0183823529411764,
      "grad_norm": 1.1798795461654663,
      "learning_rate": 8.84906045751634e-06,
      "loss": 0.0778,
      "step": 4432
    },
    {
      "epoch": 1.0186121323529411,
      "grad_norm": 1.0538908243179321,
      "learning_rate": 8.848549836601307e-06,
      "loss": 0.068,
      "step": 4433
    },
    {
      "epoch": 1.0188419117647058,
      "grad_norm": 1.1200836896896362,
      "learning_rate": 8.848039215686275e-06,
      "loss": 0.0667,
      "step": 4434
    },
    {
      "epoch": 1.0190716911764706,
      "grad_norm": 1.2239466905593872,
      "learning_rate": 8.847528594771243e-06,
      "loss": 0.0711,
      "step": 4435
    },
    {
      "epoch": 1.0193014705882353,
      "grad_norm": 0.9308986067771912,
      "learning_rate": 8.84701797385621e-06,
      "loss": 0.0469,
      "step": 4436
    },
    {
      "epoch": 1.01953125,
      "grad_norm": 1.105467438697815,
      "learning_rate": 8.846507352941177e-06,
      "loss": 0.0445,
      "step": 4437
    },
    {
      "epoch": 1.0197610294117647,
      "grad_norm": 0.8410784006118774,
      "learning_rate": 8.845996732026145e-06,
      "loss": 0.0453,
      "step": 4438
    },
    {
      "epoch": 1.0199908088235294,
      "grad_norm": 1.29635751247406,
      "learning_rate": 8.845486111111112e-06,
      "loss": 0.0796,
      "step": 4439
    },
    {
      "epoch": 1.0202205882352942,
      "grad_norm": 0.9535244107246399,
      "learning_rate": 8.844975490196079e-06,
      "loss": 0.0566,
      "step": 4440
    },
    {
      "epoch": 1.0204503676470589,
      "grad_norm": 1.195976734161377,
      "learning_rate": 8.844464869281047e-06,
      "loss": 0.0718,
      "step": 4441
    },
    {
      "epoch": 1.0206801470588236,
      "grad_norm": 1.135288953781128,
      "learning_rate": 8.843954248366013e-06,
      "loss": 0.0552,
      "step": 4442
    },
    {
      "epoch": 1.0209099264705883,
      "grad_norm": 0.7779737710952759,
      "learning_rate": 8.843443627450982e-06,
      "loss": 0.0509,
      "step": 4443
    },
    {
      "epoch": 1.021139705882353,
      "grad_norm": 0.782602071762085,
      "learning_rate": 8.842933006535948e-06,
      "loss": 0.0645,
      "step": 4444
    },
    {
      "epoch": 1.0213694852941178,
      "grad_norm": 1.3229594230651855,
      "learning_rate": 8.842422385620916e-06,
      "loss": 0.0532,
      "step": 4445
    },
    {
      "epoch": 1.0215992647058822,
      "grad_norm": 0.8747340440750122,
      "learning_rate": 8.841911764705882e-06,
      "loss": 0.0446,
      "step": 4446
    },
    {
      "epoch": 1.021829044117647,
      "grad_norm": 0.7717258334159851,
      "learning_rate": 8.84140114379085e-06,
      "loss": 0.0422,
      "step": 4447
    },
    {
      "epoch": 1.0220588235294117,
      "grad_norm": 0.7992523312568665,
      "learning_rate": 8.840890522875818e-06,
      "loss": 0.0434,
      "step": 4448
    },
    {
      "epoch": 1.0222886029411764,
      "grad_norm": 1.1640087366104126,
      "learning_rate": 8.840379901960784e-06,
      "loss": 0.0701,
      "step": 4449
    },
    {
      "epoch": 1.0225183823529411,
      "grad_norm": 0.9542653560638428,
      "learning_rate": 8.839869281045752e-06,
      "loss": 0.0679,
      "step": 4450
    },
    {
      "epoch": 1.0227481617647058,
      "grad_norm": 0.9163973331451416,
      "learning_rate": 8.83935866013072e-06,
      "loss": 0.0509,
      "step": 4451
    },
    {
      "epoch": 1.0229779411764706,
      "grad_norm": 1.4088362455368042,
      "learning_rate": 8.838848039215688e-06,
      "loss": 0.0506,
      "step": 4452
    },
    {
      "epoch": 1.0232077205882353,
      "grad_norm": 1.2370744943618774,
      "learning_rate": 8.838337418300654e-06,
      "loss": 0.0722,
      "step": 4453
    },
    {
      "epoch": 1.0234375,
      "grad_norm": 0.8282006978988647,
      "learning_rate": 8.837826797385622e-06,
      "loss": 0.0588,
      "step": 4454
    },
    {
      "epoch": 1.0236672794117647,
      "grad_norm": 0.9720355868339539,
      "learning_rate": 8.83731617647059e-06,
      "loss": 0.0742,
      "step": 4455
    },
    {
      "epoch": 1.0238970588235294,
      "grad_norm": 0.9886345863342285,
      "learning_rate": 8.836805555555556e-06,
      "loss": 0.074,
      "step": 4456
    },
    {
      "epoch": 1.0241268382352942,
      "grad_norm": 1.1100735664367676,
      "learning_rate": 8.836294934640524e-06,
      "loss": 0.0702,
      "step": 4457
    },
    {
      "epoch": 1.0243566176470589,
      "grad_norm": 1.3720228672027588,
      "learning_rate": 8.83578431372549e-06,
      "loss": 0.0832,
      "step": 4458
    },
    {
      "epoch": 1.0245863970588236,
      "grad_norm": 0.9674742221832275,
      "learning_rate": 8.83527369281046e-06,
      "loss": 0.0589,
      "step": 4459
    },
    {
      "epoch": 1.0248161764705883,
      "grad_norm": 1.0074759721755981,
      "learning_rate": 8.834763071895426e-06,
      "loss": 0.0662,
      "step": 4460
    },
    {
      "epoch": 1.025045955882353,
      "grad_norm": 1.0900501012802124,
      "learning_rate": 8.834252450980394e-06,
      "loss": 0.0694,
      "step": 4461
    },
    {
      "epoch": 1.0252757352941178,
      "grad_norm": 0.8290461897850037,
      "learning_rate": 8.83374183006536e-06,
      "loss": 0.0549,
      "step": 4462
    },
    {
      "epoch": 1.0255055147058822,
      "grad_norm": 0.7799444198608398,
      "learning_rate": 8.833231209150328e-06,
      "loss": 0.0541,
      "step": 4463
    },
    {
      "epoch": 1.025735294117647,
      "grad_norm": 1.0254955291748047,
      "learning_rate": 8.832720588235295e-06,
      "loss": 0.0731,
      "step": 4464
    },
    {
      "epoch": 1.0259650735294117,
      "grad_norm": 0.7762070894241333,
      "learning_rate": 8.832209967320262e-06,
      "loss": 0.0486,
      "step": 4465
    },
    {
      "epoch": 1.0261948529411764,
      "grad_norm": 1.5954289436340332,
      "learning_rate": 8.83169934640523e-06,
      "loss": 0.0855,
      "step": 4466
    },
    {
      "epoch": 1.0264246323529411,
      "grad_norm": 1.2680200338363647,
      "learning_rate": 8.831188725490197e-06,
      "loss": 0.0665,
      "step": 4467
    },
    {
      "epoch": 1.0266544117647058,
      "grad_norm": 1.4877914190292358,
      "learning_rate": 8.830678104575165e-06,
      "loss": 0.0779,
      "step": 4468
    },
    {
      "epoch": 1.0268841911764706,
      "grad_norm": 1.1238834857940674,
      "learning_rate": 8.830167483660131e-06,
      "loss": 0.0653,
      "step": 4469
    },
    {
      "epoch": 1.0271139705882353,
      "grad_norm": 1.0201497077941895,
      "learning_rate": 8.8296568627451e-06,
      "loss": 0.0634,
      "step": 4470
    },
    {
      "epoch": 1.02734375,
      "grad_norm": 1.1425222158432007,
      "learning_rate": 8.829146241830067e-06,
      "loss": 0.0771,
      "step": 4471
    },
    {
      "epoch": 1.0275735294117647,
      "grad_norm": 0.8803380727767944,
      "learning_rate": 8.828635620915033e-06,
      "loss": 0.0479,
      "step": 4472
    },
    {
      "epoch": 1.0278033088235294,
      "grad_norm": 1.0468733310699463,
      "learning_rate": 8.828125000000001e-06,
      "loss": 0.0789,
      "step": 4473
    },
    {
      "epoch": 1.0280330882352942,
      "grad_norm": 1.1582480669021606,
      "learning_rate": 8.827614379084967e-06,
      "loss": 0.077,
      "step": 4474
    },
    {
      "epoch": 1.0282628676470589,
      "grad_norm": 0.9602417349815369,
      "learning_rate": 8.827103758169935e-06,
      "loss": 0.0562,
      "step": 4475
    },
    {
      "epoch": 1.0284926470588236,
      "grad_norm": 1.3106050491333008,
      "learning_rate": 8.826593137254903e-06,
      "loss": 0.0852,
      "step": 4476
    },
    {
      "epoch": 1.0287224264705883,
      "grad_norm": 1.360917329788208,
      "learning_rate": 8.82608251633987e-06,
      "loss": 0.0711,
      "step": 4477
    },
    {
      "epoch": 1.028952205882353,
      "grad_norm": 1.1339833736419678,
      "learning_rate": 8.825571895424837e-06,
      "loss": 0.0935,
      "step": 4478
    },
    {
      "epoch": 1.0291819852941178,
      "grad_norm": 1.0265499353408813,
      "learning_rate": 8.825061274509805e-06,
      "loss": 0.0544,
      "step": 4479
    },
    {
      "epoch": 1.0294117647058822,
      "grad_norm": 1.2809749841690063,
      "learning_rate": 8.824550653594773e-06,
      "loss": 0.0831,
      "step": 4480
    },
    {
      "epoch": 1.029641544117647,
      "grad_norm": 0.8547199964523315,
      "learning_rate": 8.824040032679739e-06,
      "loss": 0.0441,
      "step": 4481
    },
    {
      "epoch": 1.0298713235294117,
      "grad_norm": 1.1177784204483032,
      "learning_rate": 8.823529411764707e-06,
      "loss": 0.0576,
      "step": 4482
    },
    {
      "epoch": 1.0301011029411764,
      "grad_norm": 1.1928046941757202,
      "learning_rate": 8.823018790849673e-06,
      "loss": 0.0626,
      "step": 4483
    },
    {
      "epoch": 1.0303308823529411,
      "grad_norm": 0.9575067758560181,
      "learning_rate": 8.82250816993464e-06,
      "loss": 0.0492,
      "step": 4484
    },
    {
      "epoch": 1.0305606617647058,
      "grad_norm": 0.9654737114906311,
      "learning_rate": 8.821997549019609e-06,
      "loss": 0.0469,
      "step": 4485
    },
    {
      "epoch": 1.0307904411764706,
      "grad_norm": 1.0508366823196411,
      "learning_rate": 8.821486928104575e-06,
      "loss": 0.0809,
      "step": 4486
    },
    {
      "epoch": 1.0310202205882353,
      "grad_norm": 0.9762211441993713,
      "learning_rate": 8.820976307189543e-06,
      "loss": 0.0724,
      "step": 4487
    },
    {
      "epoch": 1.03125,
      "grad_norm": 1.17960786819458,
      "learning_rate": 8.82046568627451e-06,
      "loss": 0.0771,
      "step": 4488
    },
    {
      "epoch": 1.0314797794117647,
      "grad_norm": 1.04407799243927,
      "learning_rate": 8.819955065359478e-06,
      "loss": 0.0529,
      "step": 4489
    },
    {
      "epoch": 1.0317095588235294,
      "grad_norm": 0.9307532906532288,
      "learning_rate": 8.819444444444445e-06,
      "loss": 0.0797,
      "step": 4490
    },
    {
      "epoch": 1.0319393382352942,
      "grad_norm": 1.1754002571105957,
      "learning_rate": 8.818933823529412e-06,
      "loss": 0.0727,
      "step": 4491
    },
    {
      "epoch": 1.0321691176470589,
      "grad_norm": 1.209004282951355,
      "learning_rate": 8.81842320261438e-06,
      "loss": 0.0658,
      "step": 4492
    },
    {
      "epoch": 1.0323988970588236,
      "grad_norm": 1.1347095966339111,
      "learning_rate": 8.817912581699347e-06,
      "loss": 0.0796,
      "step": 4493
    },
    {
      "epoch": 1.0326286764705883,
      "grad_norm": 1.13937509059906,
      "learning_rate": 8.817401960784314e-06,
      "loss": 0.0482,
      "step": 4494
    },
    {
      "epoch": 1.032858455882353,
      "grad_norm": 0.8162972927093506,
      "learning_rate": 8.81689133986928e-06,
      "loss": 0.0462,
      "step": 4495
    },
    {
      "epoch": 1.0330882352941178,
      "grad_norm": 1.0041706562042236,
      "learning_rate": 8.81638071895425e-06,
      "loss": 0.047,
      "step": 4496
    },
    {
      "epoch": 1.0333180147058822,
      "grad_norm": 0.9464737772941589,
      "learning_rate": 8.815870098039216e-06,
      "loss": 0.0709,
      "step": 4497
    },
    {
      "epoch": 1.033547794117647,
      "grad_norm": 0.9023111462593079,
      "learning_rate": 8.815359477124184e-06,
      "loss": 0.0762,
      "step": 4498
    },
    {
      "epoch": 1.0337775735294117,
      "grad_norm": 1.146626353263855,
      "learning_rate": 8.81484885620915e-06,
      "loss": 0.0702,
      "step": 4499
    },
    {
      "epoch": 1.0340073529411764,
      "grad_norm": 1.327979564666748,
      "learning_rate": 8.814338235294118e-06,
      "loss": 0.0722,
      "step": 4500
    },
    {
      "epoch": 1.0340073529411764,
      "eval_loss": 0.06776697933673859,
      "eval_runtime": 2005.9197,
      "eval_samples_per_second": 4.44,
      "eval_steps_per_second": 2.22,
      "step": 4500
    },
    {
      "epoch": 1.0342371323529411,
      "grad_norm": 1.1929539442062378,
      "learning_rate": 8.813827614379086e-06,
      "loss": 0.0714,
      "step": 4501
    },
    {
      "epoch": 1.0344669117647058,
      "grad_norm": 1.0927585363388062,
      "learning_rate": 8.813316993464052e-06,
      "loss": 0.0645,
      "step": 4502
    },
    {
      "epoch": 1.0346966911764706,
      "grad_norm": 0.9662787914276123,
      "learning_rate": 8.81280637254902e-06,
      "loss": 0.0717,
      "step": 4503
    },
    {
      "epoch": 1.0349264705882353,
      "grad_norm": 0.8747052550315857,
      "learning_rate": 8.812295751633988e-06,
      "loss": 0.0503,
      "step": 4504
    },
    {
      "epoch": 1.03515625,
      "grad_norm": 0.9173612594604492,
      "learning_rate": 8.811785130718956e-06,
      "loss": 0.0547,
      "step": 4505
    },
    {
      "epoch": 1.0353860294117647,
      "grad_norm": 1.0665024518966675,
      "learning_rate": 8.811274509803922e-06,
      "loss": 0.049,
      "step": 4506
    },
    {
      "epoch": 1.0356158088235294,
      "grad_norm": 0.8079658150672913,
      "learning_rate": 8.81076388888889e-06,
      "loss": 0.0506,
      "step": 4507
    },
    {
      "epoch": 1.0358455882352942,
      "grad_norm": 0.8840283751487732,
      "learning_rate": 8.810253267973858e-06,
      "loss": 0.0567,
      "step": 4508
    },
    {
      "epoch": 1.0360753676470589,
      "grad_norm": 0.7544313073158264,
      "learning_rate": 8.809742647058824e-06,
      "loss": 0.0396,
      "step": 4509
    },
    {
      "epoch": 1.0363051470588236,
      "grad_norm": 0.8868700265884399,
      "learning_rate": 8.809232026143792e-06,
      "loss": 0.0491,
      "step": 4510
    },
    {
      "epoch": 1.0365349264705883,
      "grad_norm": 0.9138717651367188,
      "learning_rate": 8.808721405228758e-06,
      "loss": 0.0478,
      "step": 4511
    },
    {
      "epoch": 1.036764705882353,
      "grad_norm": 0.9738650918006897,
      "learning_rate": 8.808210784313727e-06,
      "loss": 0.0723,
      "step": 4512
    },
    {
      "epoch": 1.0369944852941178,
      "grad_norm": 1.0375311374664307,
      "learning_rate": 8.807700163398694e-06,
      "loss": 0.0549,
      "step": 4513
    },
    {
      "epoch": 1.0372242647058822,
      "grad_norm": 0.9241669774055481,
      "learning_rate": 8.807189542483661e-06,
      "loss": 0.0613,
      "step": 4514
    },
    {
      "epoch": 1.037454044117647,
      "grad_norm": 1.262746810913086,
      "learning_rate": 8.806678921568628e-06,
      "loss": 0.0819,
      "step": 4515
    },
    {
      "epoch": 1.0376838235294117,
      "grad_norm": 1.2832213640213013,
      "learning_rate": 8.806168300653595e-06,
      "loss": 0.0922,
      "step": 4516
    },
    {
      "epoch": 1.0379136029411764,
      "grad_norm": 0.9366174936294556,
      "learning_rate": 8.805657679738563e-06,
      "loss": 0.0662,
      "step": 4517
    },
    {
      "epoch": 1.0381433823529411,
      "grad_norm": 1.0660169124603271,
      "learning_rate": 8.80514705882353e-06,
      "loss": 0.1044,
      "step": 4518
    },
    {
      "epoch": 1.0383731617647058,
      "grad_norm": 1.0147249698638916,
      "learning_rate": 8.804636437908497e-06,
      "loss": 0.0793,
      "step": 4519
    },
    {
      "epoch": 1.0386029411764706,
      "grad_norm": 0.9112522006034851,
      "learning_rate": 8.804125816993465e-06,
      "loss": 0.0511,
      "step": 4520
    },
    {
      "epoch": 1.0388327205882353,
      "grad_norm": 0.8207451105117798,
      "learning_rate": 8.803615196078431e-06,
      "loss": 0.05,
      "step": 4521
    },
    {
      "epoch": 1.0390625,
      "grad_norm": 0.9814621806144714,
      "learning_rate": 8.8031045751634e-06,
      "loss": 0.0867,
      "step": 4522
    },
    {
      "epoch": 1.0392922794117647,
      "grad_norm": 0.9299907088279724,
      "learning_rate": 8.802593954248367e-06,
      "loss": 0.0701,
      "step": 4523
    },
    {
      "epoch": 1.0395220588235294,
      "grad_norm": 1.1929664611816406,
      "learning_rate": 8.802083333333335e-06,
      "loss": 0.0805,
      "step": 4524
    },
    {
      "epoch": 1.0397518382352942,
      "grad_norm": 1.1836800575256348,
      "learning_rate": 8.801572712418301e-06,
      "loss": 0.0567,
      "step": 4525
    },
    {
      "epoch": 1.0399816176470589,
      "grad_norm": 1.0999717712402344,
      "learning_rate": 8.801062091503269e-06,
      "loss": 0.091,
      "step": 4526
    },
    {
      "epoch": 1.0402113970588236,
      "grad_norm": 1.1156636476516724,
      "learning_rate": 8.800551470588235e-06,
      "loss": 0.0725,
      "step": 4527
    },
    {
      "epoch": 1.0404411764705883,
      "grad_norm": 0.7705660462379456,
      "learning_rate": 8.800040849673203e-06,
      "loss": 0.0818,
      "step": 4528
    },
    {
      "epoch": 1.040670955882353,
      "grad_norm": 1.0286625623703003,
      "learning_rate": 8.799530228758171e-06,
      "loss": 0.0712,
      "step": 4529
    },
    {
      "epoch": 1.0409007352941178,
      "grad_norm": 1.1007131338119507,
      "learning_rate": 8.799019607843137e-06,
      "loss": 0.0636,
      "step": 4530
    },
    {
      "epoch": 1.0411305147058822,
      "grad_norm": 0.8561234474182129,
      "learning_rate": 8.798508986928105e-06,
      "loss": 0.0576,
      "step": 4531
    },
    {
      "epoch": 1.041360294117647,
      "grad_norm": 1.1930791139602661,
      "learning_rate": 8.797998366013073e-06,
      "loss": 0.0705,
      "step": 4532
    },
    {
      "epoch": 1.0415900735294117,
      "grad_norm": 0.964225709438324,
      "learning_rate": 8.79748774509804e-06,
      "loss": 0.0519,
      "step": 4533
    },
    {
      "epoch": 1.0418198529411764,
      "grad_norm": 1.0311344861984253,
      "learning_rate": 8.796977124183007e-06,
      "loss": 0.0593,
      "step": 4534
    },
    {
      "epoch": 1.0420496323529411,
      "grad_norm": 0.9068081378936768,
      "learning_rate": 8.796466503267975e-06,
      "loss": 0.066,
      "step": 4535
    },
    {
      "epoch": 1.0422794117647058,
      "grad_norm": 1.0545494556427002,
      "learning_rate": 8.795955882352943e-06,
      "loss": 0.0661,
      "step": 4536
    },
    {
      "epoch": 1.0425091911764706,
      "grad_norm": 1.06419837474823,
      "learning_rate": 8.795445261437909e-06,
      "loss": 0.0541,
      "step": 4537
    },
    {
      "epoch": 1.0427389705882353,
      "grad_norm": 0.8563321232795715,
      "learning_rate": 8.794934640522877e-06,
      "loss": 0.0511,
      "step": 4538
    },
    {
      "epoch": 1.04296875,
      "grad_norm": 0.7898710370063782,
      "learning_rate": 8.794424019607843e-06,
      "loss": 0.0644,
      "step": 4539
    },
    {
      "epoch": 1.0431985294117647,
      "grad_norm": 0.8757835626602173,
      "learning_rate": 8.793913398692812e-06,
      "loss": 0.0607,
      "step": 4540
    },
    {
      "epoch": 1.0434283088235294,
      "grad_norm": 1.367430329322815,
      "learning_rate": 8.793402777777778e-06,
      "loss": 0.0766,
      "step": 4541
    },
    {
      "epoch": 1.0436580882352942,
      "grad_norm": 0.9199122786521912,
      "learning_rate": 8.792892156862746e-06,
      "loss": 0.0477,
      "step": 4542
    },
    {
      "epoch": 1.0438878676470589,
      "grad_norm": 1.0644261837005615,
      "learning_rate": 8.792381535947712e-06,
      "loss": 0.0683,
      "step": 4543
    },
    {
      "epoch": 1.0441176470588236,
      "grad_norm": 0.7326544523239136,
      "learning_rate": 8.79187091503268e-06,
      "loss": 0.0438,
      "step": 4544
    },
    {
      "epoch": 1.0443474264705883,
      "grad_norm": 0.9489081501960754,
      "learning_rate": 8.791360294117648e-06,
      "loss": 0.0661,
      "step": 4545
    },
    {
      "epoch": 1.044577205882353,
      "grad_norm": 1.03115975856781,
      "learning_rate": 8.790849673202614e-06,
      "loss": 0.0489,
      "step": 4546
    },
    {
      "epoch": 1.0448069852941178,
      "grad_norm": 0.8968547582626343,
      "learning_rate": 8.790339052287582e-06,
      "loss": 0.0689,
      "step": 4547
    },
    {
      "epoch": 1.0450367647058822,
      "grad_norm": 0.7578619718551636,
      "learning_rate": 8.78982843137255e-06,
      "loss": 0.0518,
      "step": 4548
    },
    {
      "epoch": 1.045266544117647,
      "grad_norm": 1.1484010219573975,
      "learning_rate": 8.789317810457518e-06,
      "loss": 0.0524,
      "step": 4549
    },
    {
      "epoch": 1.0454963235294117,
      "grad_norm": 1.002434253692627,
      "learning_rate": 8.788807189542484e-06,
      "loss": 0.0481,
      "step": 4550
    },
    {
      "epoch": 1.0457261029411764,
      "grad_norm": 1.6044437885284424,
      "learning_rate": 8.788296568627452e-06,
      "loss": 0.0876,
      "step": 4551
    },
    {
      "epoch": 1.0459558823529411,
      "grad_norm": 1.0287132263183594,
      "learning_rate": 8.78778594771242e-06,
      "loss": 0.0575,
      "step": 4552
    },
    {
      "epoch": 1.0461856617647058,
      "grad_norm": 1.4193410873413086,
      "learning_rate": 8.787275326797386e-06,
      "loss": 0.0837,
      "step": 4553
    },
    {
      "epoch": 1.0464154411764706,
      "grad_norm": 0.92726731300354,
      "learning_rate": 8.786764705882354e-06,
      "loss": 0.0513,
      "step": 4554
    },
    {
      "epoch": 1.0466452205882353,
      "grad_norm": 0.8994672894477844,
      "learning_rate": 8.78625408496732e-06,
      "loss": 0.0682,
      "step": 4555
    },
    {
      "epoch": 1.046875,
      "grad_norm": 1.2350486516952515,
      "learning_rate": 8.785743464052288e-06,
      "loss": 0.0738,
      "step": 4556
    },
    {
      "epoch": 1.0471047794117647,
      "grad_norm": 1.7278755903244019,
      "learning_rate": 8.785232843137256e-06,
      "loss": 0.0868,
      "step": 4557
    },
    {
      "epoch": 1.0473345588235294,
      "grad_norm": 1.0296516418457031,
      "learning_rate": 8.784722222222224e-06,
      "loss": 0.067,
      "step": 4558
    },
    {
      "epoch": 1.0475643382352942,
      "grad_norm": 1.2890146970748901,
      "learning_rate": 8.78421160130719e-06,
      "loss": 0.0873,
      "step": 4559
    },
    {
      "epoch": 1.0477941176470589,
      "grad_norm": 1.1899592876434326,
      "learning_rate": 8.783700980392158e-06,
      "loss": 0.068,
      "step": 4560
    },
    {
      "epoch": 1.0480238970588236,
      "grad_norm": 0.9111149907112122,
      "learning_rate": 8.783190359477126e-06,
      "loss": 0.0589,
      "step": 4561
    },
    {
      "epoch": 1.0482536764705883,
      "grad_norm": 0.8066484332084656,
      "learning_rate": 8.782679738562092e-06,
      "loss": 0.0442,
      "step": 4562
    },
    {
      "epoch": 1.048483455882353,
      "grad_norm": 1.0891597270965576,
      "learning_rate": 8.78216911764706e-06,
      "loss": 0.0414,
      "step": 4563
    },
    {
      "epoch": 1.0487132352941178,
      "grad_norm": 1.0964207649230957,
      "learning_rate": 8.781658496732027e-06,
      "loss": 0.0559,
      "step": 4564
    },
    {
      "epoch": 1.0489430147058822,
      "grad_norm": 0.9934712648391724,
      "learning_rate": 8.781147875816994e-06,
      "loss": 0.0466,
      "step": 4565
    },
    {
      "epoch": 1.049172794117647,
      "grad_norm": 1.0308398008346558,
      "learning_rate": 8.780637254901961e-06,
      "loss": 0.0644,
      "step": 4566
    },
    {
      "epoch": 1.0494025735294117,
      "grad_norm": 1.368356704711914,
      "learning_rate": 8.780126633986928e-06,
      "loss": 0.072,
      "step": 4567
    },
    {
      "epoch": 1.0496323529411764,
      "grad_norm": 1.4075069427490234,
      "learning_rate": 8.779616013071897e-06,
      "loss": 0.0888,
      "step": 4568
    },
    {
      "epoch": 1.0498621323529411,
      "grad_norm": 0.8999910354614258,
      "learning_rate": 8.779105392156863e-06,
      "loss": 0.0562,
      "step": 4569
    },
    {
      "epoch": 1.0500919117647058,
      "grad_norm": 0.7780546545982361,
      "learning_rate": 8.778594771241831e-06,
      "loss": 0.057,
      "step": 4570
    },
    {
      "epoch": 1.0503216911764706,
      "grad_norm": 1.001531720161438,
      "learning_rate": 8.778084150326797e-06,
      "loss": 0.059,
      "step": 4571
    },
    {
      "epoch": 1.0505514705882353,
      "grad_norm": 0.7128663063049316,
      "learning_rate": 8.777573529411765e-06,
      "loss": 0.0527,
      "step": 4572
    },
    {
      "epoch": 1.05078125,
      "grad_norm": 0.8697998523712158,
      "learning_rate": 8.777062908496733e-06,
      "loss": 0.0577,
      "step": 4573
    },
    {
      "epoch": 1.0510110294117647,
      "grad_norm": 0.913882851600647,
      "learning_rate": 8.7765522875817e-06,
      "loss": 0.0674,
      "step": 4574
    },
    {
      "epoch": 1.0512408088235294,
      "grad_norm": 1.0811854600906372,
      "learning_rate": 8.776041666666667e-06,
      "loss": 0.0583,
      "step": 4575
    },
    {
      "epoch": 1.0514705882352942,
      "grad_norm": 1.0542148351669312,
      "learning_rate": 8.775531045751635e-06,
      "loss": 0.0689,
      "step": 4576
    },
    {
      "epoch": 1.0517003676470589,
      "grad_norm": 0.9236987233161926,
      "learning_rate": 8.775020424836603e-06,
      "loss": 0.0616,
      "step": 4577
    },
    {
      "epoch": 1.0519301470588236,
      "grad_norm": 1.091016173362732,
      "learning_rate": 8.774509803921569e-06,
      "loss": 0.0544,
      "step": 4578
    },
    {
      "epoch": 1.0521599264705883,
      "grad_norm": 1.2274634838104248,
      "learning_rate": 8.773999183006537e-06,
      "loss": 0.0642,
      "step": 4579
    },
    {
      "epoch": 1.052389705882353,
      "grad_norm": 1.1240978240966797,
      "learning_rate": 8.773488562091505e-06,
      "loss": 0.0617,
      "step": 4580
    },
    {
      "epoch": 1.0526194852941178,
      "grad_norm": 0.9611729979515076,
      "learning_rate": 8.772977941176471e-06,
      "loss": 0.0613,
      "step": 4581
    },
    {
      "epoch": 1.0528492647058822,
      "grad_norm": 0.9513202905654907,
      "learning_rate": 8.772467320261439e-06,
      "loss": 0.0505,
      "step": 4582
    },
    {
      "epoch": 1.053079044117647,
      "grad_norm": 0.9845364689826965,
      "learning_rate": 8.771956699346405e-06,
      "loss": 0.0619,
      "step": 4583
    },
    {
      "epoch": 1.0533088235294117,
      "grad_norm": 1.256269931793213,
      "learning_rate": 8.771446078431374e-06,
      "loss": 0.0658,
      "step": 4584
    },
    {
      "epoch": 1.0535386029411764,
      "grad_norm": 1.1093432903289795,
      "learning_rate": 8.77093545751634e-06,
      "loss": 0.0613,
      "step": 4585
    },
    {
      "epoch": 1.0537683823529411,
      "grad_norm": 0.9800616502761841,
      "learning_rate": 8.770424836601308e-06,
      "loss": 0.0613,
      "step": 4586
    },
    {
      "epoch": 1.0539981617647058,
      "grad_norm": 0.9436262845993042,
      "learning_rate": 8.769914215686275e-06,
      "loss": 0.0607,
      "step": 4587
    },
    {
      "epoch": 1.0542279411764706,
      "grad_norm": 1.0592092275619507,
      "learning_rate": 8.769403594771243e-06,
      "loss": 0.0537,
      "step": 4588
    },
    {
      "epoch": 1.0544577205882353,
      "grad_norm": 1.2413181066513062,
      "learning_rate": 8.76889297385621e-06,
      "loss": 0.067,
      "step": 4589
    },
    {
      "epoch": 1.0546875,
      "grad_norm": 0.9392799139022827,
      "learning_rate": 8.768382352941177e-06,
      "loss": 0.0743,
      "step": 4590
    },
    {
      "epoch": 1.0549172794117647,
      "grad_norm": 0.8322019577026367,
      "learning_rate": 8.767871732026144e-06,
      "loss": 0.0354,
      "step": 4591
    },
    {
      "epoch": 1.0551470588235294,
      "grad_norm": 1.1787976026535034,
      "learning_rate": 8.767361111111112e-06,
      "loss": 0.0849,
      "step": 4592
    },
    {
      "epoch": 1.0553768382352942,
      "grad_norm": 1.0173734426498413,
      "learning_rate": 8.76685049019608e-06,
      "loss": 0.0708,
      "step": 4593
    },
    {
      "epoch": 1.0556066176470589,
      "grad_norm": 0.7689253687858582,
      "learning_rate": 8.766339869281046e-06,
      "loss": 0.0415,
      "step": 4594
    },
    {
      "epoch": 1.0558363970588236,
      "grad_norm": 1.105330228805542,
      "learning_rate": 8.765829248366014e-06,
      "loss": 0.0727,
      "step": 4595
    },
    {
      "epoch": 1.0560661764705883,
      "grad_norm": 1.251085877418518,
      "learning_rate": 8.765318627450982e-06,
      "loss": 0.0961,
      "step": 4596
    },
    {
      "epoch": 1.056295955882353,
      "grad_norm": 1.1119495630264282,
      "learning_rate": 8.764808006535948e-06,
      "loss": 0.052,
      "step": 4597
    },
    {
      "epoch": 1.0565257352941178,
      "grad_norm": 1.472786545753479,
      "learning_rate": 8.764297385620916e-06,
      "loss": 0.1077,
      "step": 4598
    },
    {
      "epoch": 1.0567555147058822,
      "grad_norm": 0.9364020228385925,
      "learning_rate": 8.763786764705882e-06,
      "loss": 0.0576,
      "step": 4599
    },
    {
      "epoch": 1.056985294117647,
      "grad_norm": 1.3193995952606201,
      "learning_rate": 8.76327614379085e-06,
      "loss": 0.0886,
      "step": 4600
    },
    {
      "epoch": 1.0572150735294117,
      "grad_norm": 0.822658121585846,
      "learning_rate": 8.762765522875818e-06,
      "loss": 0.0471,
      "step": 4601
    },
    {
      "epoch": 1.0574448529411764,
      "grad_norm": 0.898776650428772,
      "learning_rate": 8.762254901960786e-06,
      "loss": 0.0633,
      "step": 4602
    },
    {
      "epoch": 1.0576746323529411,
      "grad_norm": 1.1924066543579102,
      "learning_rate": 8.761744281045752e-06,
      "loss": 0.0674,
      "step": 4603
    },
    {
      "epoch": 1.0579044117647058,
      "grad_norm": 1.1528059244155884,
      "learning_rate": 8.76123366013072e-06,
      "loss": 0.0674,
      "step": 4604
    },
    {
      "epoch": 1.0581341911764706,
      "grad_norm": 1.1287521123886108,
      "learning_rate": 8.760723039215688e-06,
      "loss": 0.0581,
      "step": 4605
    },
    {
      "epoch": 1.0583639705882353,
      "grad_norm": 1.0279133319854736,
      "learning_rate": 8.760212418300654e-06,
      "loss": 0.0467,
      "step": 4606
    },
    {
      "epoch": 1.05859375,
      "grad_norm": 0.6379415392875671,
      "learning_rate": 8.759701797385622e-06,
      "loss": 0.0361,
      "step": 4607
    },
    {
      "epoch": 1.0588235294117647,
      "grad_norm": 1.117156744003296,
      "learning_rate": 8.75919117647059e-06,
      "loss": 0.0968,
      "step": 4608
    },
    {
      "epoch": 1.0590533088235294,
      "grad_norm": 1.1399012804031372,
      "learning_rate": 8.758680555555556e-06,
      "loss": 0.0423,
      "step": 4609
    },
    {
      "epoch": 1.0592830882352942,
      "grad_norm": 1.298694133758545,
      "learning_rate": 8.758169934640524e-06,
      "loss": 0.0778,
      "step": 4610
    },
    {
      "epoch": 1.0595128676470589,
      "grad_norm": 0.8720417022705078,
      "learning_rate": 8.75765931372549e-06,
      "loss": 0.0493,
      "step": 4611
    },
    {
      "epoch": 1.0597426470588236,
      "grad_norm": 1.0031611919403076,
      "learning_rate": 8.75714869281046e-06,
      "loss": 0.0563,
      "step": 4612
    },
    {
      "epoch": 1.0599724264705883,
      "grad_norm": 1.2615715265274048,
      "learning_rate": 8.756638071895426e-06,
      "loss": 0.0611,
      "step": 4613
    },
    {
      "epoch": 1.060202205882353,
      "grad_norm": 0.8161330223083496,
      "learning_rate": 8.756127450980393e-06,
      "loss": 0.0446,
      "step": 4614
    },
    {
      "epoch": 1.0604319852941178,
      "grad_norm": 1.671040654182434,
      "learning_rate": 8.75561683006536e-06,
      "loss": 0.1212,
      "step": 4615
    },
    {
      "epoch": 1.0606617647058822,
      "grad_norm": 0.8907183408737183,
      "learning_rate": 8.755106209150327e-06,
      "loss": 0.064,
      "step": 4616
    },
    {
      "epoch": 1.060891544117647,
      "grad_norm": 1.0431123971939087,
      "learning_rate": 8.754595588235295e-06,
      "loss": 0.0615,
      "step": 4617
    },
    {
      "epoch": 1.0611213235294117,
      "grad_norm": 1.0994340181350708,
      "learning_rate": 8.754084967320261e-06,
      "loss": 0.0786,
      "step": 4618
    },
    {
      "epoch": 1.0613511029411764,
      "grad_norm": 0.9982165098190308,
      "learning_rate": 8.75357434640523e-06,
      "loss": 0.0785,
      "step": 4619
    },
    {
      "epoch": 1.0615808823529411,
      "grad_norm": 0.6481784582138062,
      "learning_rate": 8.753063725490197e-06,
      "loss": 0.0351,
      "step": 4620
    },
    {
      "epoch": 1.0618106617647058,
      "grad_norm": 1.4198942184448242,
      "learning_rate": 8.752553104575165e-06,
      "loss": 0.081,
      "step": 4621
    },
    {
      "epoch": 1.0620404411764706,
      "grad_norm": 1.055434226989746,
      "learning_rate": 8.752042483660131e-06,
      "loss": 0.0541,
      "step": 4622
    },
    {
      "epoch": 1.0622702205882353,
      "grad_norm": 1.0332069396972656,
      "learning_rate": 8.751531862745099e-06,
      "loss": 0.0513,
      "step": 4623
    },
    {
      "epoch": 1.0625,
      "grad_norm": 0.8597769141197205,
      "learning_rate": 8.751021241830067e-06,
      "loss": 0.0316,
      "step": 4624
    },
    {
      "epoch": 1.0627297794117647,
      "grad_norm": 1.3069007396697998,
      "learning_rate": 8.750510620915033e-06,
      "loss": 0.0646,
      "step": 4625
    },
    {
      "epoch": 1.0629595588235294,
      "grad_norm": 0.6370428800582886,
      "learning_rate": 8.750000000000001e-06,
      "loss": 0.0382,
      "step": 4626
    },
    {
      "epoch": 1.0631893382352942,
      "grad_norm": 0.8942989110946655,
      "learning_rate": 8.749489379084967e-06,
      "loss": 0.0627,
      "step": 4627
    },
    {
      "epoch": 1.0634191176470589,
      "grad_norm": 1.1073269844055176,
      "learning_rate": 8.748978758169935e-06,
      "loss": 0.0563,
      "step": 4628
    },
    {
      "epoch": 1.0636488970588236,
      "grad_norm": 1.6446596384048462,
      "learning_rate": 8.748468137254903e-06,
      "loss": 0.079,
      "step": 4629
    },
    {
      "epoch": 1.0638786764705883,
      "grad_norm": 0.9181306958198547,
      "learning_rate": 8.74795751633987e-06,
      "loss": 0.0421,
      "step": 4630
    },
    {
      "epoch": 1.064108455882353,
      "grad_norm": 1.128774642944336,
      "learning_rate": 8.747446895424837e-06,
      "loss": 0.064,
      "step": 4631
    },
    {
      "epoch": 1.0643382352941178,
      "grad_norm": 1.0986207723617554,
      "learning_rate": 8.746936274509805e-06,
      "loss": 0.056,
      "step": 4632
    },
    {
      "epoch": 1.0645680147058822,
      "grad_norm": 1.0519853830337524,
      "learning_rate": 8.746425653594773e-06,
      "loss": 0.0484,
      "step": 4633
    },
    {
      "epoch": 1.064797794117647,
      "grad_norm": 1.0657224655151367,
      "learning_rate": 8.745915032679739e-06,
      "loss": 0.0739,
      "step": 4634
    },
    {
      "epoch": 1.0650275735294117,
      "grad_norm": 1.0979280471801758,
      "learning_rate": 8.745404411764707e-06,
      "loss": 0.0535,
      "step": 4635
    },
    {
      "epoch": 1.0652573529411764,
      "grad_norm": 0.9909829497337341,
      "learning_rate": 8.744893790849673e-06,
      "loss": 0.0719,
      "step": 4636
    },
    {
      "epoch": 1.0654871323529411,
      "grad_norm": 0.7857967615127563,
      "learning_rate": 8.744383169934642e-06,
      "loss": 0.043,
      "step": 4637
    },
    {
      "epoch": 1.0657169117647058,
      "grad_norm": 0.9769242405891418,
      "learning_rate": 8.743872549019608e-06,
      "loss": 0.0459,
      "step": 4638
    },
    {
      "epoch": 1.0659466911764706,
      "grad_norm": 1.1027055978775024,
      "learning_rate": 8.743361928104576e-06,
      "loss": 0.0783,
      "step": 4639
    },
    {
      "epoch": 1.0661764705882353,
      "grad_norm": 1.1253643035888672,
      "learning_rate": 8.742851307189543e-06,
      "loss": 0.0647,
      "step": 4640
    },
    {
      "epoch": 1.06640625,
      "grad_norm": 0.9817761778831482,
      "learning_rate": 8.74234068627451e-06,
      "loss": 0.0667,
      "step": 4641
    },
    {
      "epoch": 1.0666360294117647,
      "grad_norm": 0.6505690813064575,
      "learning_rate": 8.741830065359478e-06,
      "loss": 0.0472,
      "step": 4642
    },
    {
      "epoch": 1.0668658088235294,
      "grad_norm": 1.0463148355484009,
      "learning_rate": 8.741319444444444e-06,
      "loss": 0.0569,
      "step": 4643
    },
    {
      "epoch": 1.0670955882352942,
      "grad_norm": 1.2129980325698853,
      "learning_rate": 8.740808823529412e-06,
      "loss": 0.0829,
      "step": 4644
    },
    {
      "epoch": 1.0673253676470589,
      "grad_norm": 0.9035500884056091,
      "learning_rate": 8.74029820261438e-06,
      "loss": 0.0747,
      "step": 4645
    },
    {
      "epoch": 1.0675551470588236,
      "grad_norm": 1.0355474948883057,
      "learning_rate": 8.739787581699348e-06,
      "loss": 0.0631,
      "step": 4646
    },
    {
      "epoch": 1.0677849264705883,
      "grad_norm": 1.4221899509429932,
      "learning_rate": 8.739276960784314e-06,
      "loss": 0.0973,
      "step": 4647
    },
    {
      "epoch": 1.068014705882353,
      "grad_norm": 0.9389763474464417,
      "learning_rate": 8.738766339869282e-06,
      "loss": 0.0464,
      "step": 4648
    },
    {
      "epoch": 1.0682444852941178,
      "grad_norm": 0.7881381511688232,
      "learning_rate": 8.73825571895425e-06,
      "loss": 0.0484,
      "step": 4649
    },
    {
      "epoch": 1.0684742647058822,
      "grad_norm": 0.8167674541473389,
      "learning_rate": 8.737745098039216e-06,
      "loss": 0.0465,
      "step": 4650
    },
    {
      "epoch": 1.068704044117647,
      "grad_norm": 1.0840024948120117,
      "learning_rate": 8.737234477124184e-06,
      "loss": 0.1029,
      "step": 4651
    },
    {
      "epoch": 1.0689338235294117,
      "grad_norm": 0.8774582743644714,
      "learning_rate": 8.73672385620915e-06,
      "loss": 0.0474,
      "step": 4652
    },
    {
      "epoch": 1.0691636029411764,
      "grad_norm": 0.8644177913665771,
      "learning_rate": 8.736213235294118e-06,
      "loss": 0.0666,
      "step": 4653
    },
    {
      "epoch": 1.0693933823529411,
      "grad_norm": 1.1635136604309082,
      "learning_rate": 8.735702614379086e-06,
      "loss": 0.068,
      "step": 4654
    },
    {
      "epoch": 1.0696231617647058,
      "grad_norm": 0.9865533709526062,
      "learning_rate": 8.735191993464052e-06,
      "loss": 0.0914,
      "step": 4655
    },
    {
      "epoch": 1.0698529411764706,
      "grad_norm": 1.0316426753997803,
      "learning_rate": 8.73468137254902e-06,
      "loss": 0.1023,
      "step": 4656
    },
    {
      "epoch": 1.0700827205882353,
      "grad_norm": 1.0492579936981201,
      "learning_rate": 8.734170751633988e-06,
      "loss": 0.0669,
      "step": 4657
    },
    {
      "epoch": 1.0703125,
      "grad_norm": 0.8922836184501648,
      "learning_rate": 8.733660130718956e-06,
      "loss": 0.0625,
      "step": 4658
    },
    {
      "epoch": 1.0705422794117647,
      "grad_norm": 0.9014140963554382,
      "learning_rate": 8.733149509803922e-06,
      "loss": 0.0543,
      "step": 4659
    },
    {
      "epoch": 1.0707720588235294,
      "grad_norm": 0.656121015548706,
      "learning_rate": 8.73263888888889e-06,
      "loss": 0.0483,
      "step": 4660
    },
    {
      "epoch": 1.0710018382352942,
      "grad_norm": 1.0841940641403198,
      "learning_rate": 8.732128267973857e-06,
      "loss": 0.0656,
      "step": 4661
    },
    {
      "epoch": 1.0712316176470589,
      "grad_norm": 0.9791908860206604,
      "learning_rate": 8.731617647058824e-06,
      "loss": 0.0761,
      "step": 4662
    },
    {
      "epoch": 1.0714613970588236,
      "grad_norm": 0.9933257102966309,
      "learning_rate": 8.731107026143791e-06,
      "loss": 0.0744,
      "step": 4663
    },
    {
      "epoch": 1.0716911764705883,
      "grad_norm": 1.2545515298843384,
      "learning_rate": 8.730596405228758e-06,
      "loss": 0.0746,
      "step": 4664
    },
    {
      "epoch": 1.071920955882353,
      "grad_norm": 0.8793827295303345,
      "learning_rate": 8.730085784313727e-06,
      "loss": 0.0508,
      "step": 4665
    },
    {
      "epoch": 1.0721507352941178,
      "grad_norm": 0.9945793151855469,
      "learning_rate": 8.729575163398693e-06,
      "loss": 0.051,
      "step": 4666
    },
    {
      "epoch": 1.0723805147058822,
      "grad_norm": 1.4220213890075684,
      "learning_rate": 8.729064542483661e-06,
      "loss": 0.0886,
      "step": 4667
    },
    {
      "epoch": 1.072610294117647,
      "grad_norm": 1.027325987815857,
      "learning_rate": 8.728553921568627e-06,
      "loss": 0.0519,
      "step": 4668
    },
    {
      "epoch": 1.0728400735294117,
      "grad_norm": 0.9975763559341431,
      "learning_rate": 8.728043300653595e-06,
      "loss": 0.0467,
      "step": 4669
    },
    {
      "epoch": 1.0730698529411764,
      "grad_norm": 0.8905233144760132,
      "learning_rate": 8.727532679738563e-06,
      "loss": 0.0617,
      "step": 4670
    },
    {
      "epoch": 1.0732996323529411,
      "grad_norm": 1.2945916652679443,
      "learning_rate": 8.72702205882353e-06,
      "loss": 0.0941,
      "step": 4671
    },
    {
      "epoch": 1.0735294117647058,
      "grad_norm": 1.1142070293426514,
      "learning_rate": 8.726511437908497e-06,
      "loss": 0.0652,
      "step": 4672
    },
    {
      "epoch": 1.0737591911764706,
      "grad_norm": 0.9562289118766785,
      "learning_rate": 8.726000816993465e-06,
      "loss": 0.0639,
      "step": 4673
    },
    {
      "epoch": 1.0739889705882353,
      "grad_norm": 0.9174869656562805,
      "learning_rate": 8.725490196078433e-06,
      "loss": 0.0469,
      "step": 4674
    },
    {
      "epoch": 1.07421875,
      "grad_norm": 1.1657209396362305,
      "learning_rate": 8.724979575163399e-06,
      "loss": 0.0717,
      "step": 4675
    },
    {
      "epoch": 1.0744485294117647,
      "grad_norm": 1.001146912574768,
      "learning_rate": 8.724468954248367e-06,
      "loss": 0.0568,
      "step": 4676
    },
    {
      "epoch": 1.0746783088235294,
      "grad_norm": 0.9928449988365173,
      "learning_rate": 8.723958333333335e-06,
      "loss": 0.0519,
      "step": 4677
    },
    {
      "epoch": 1.0749080882352942,
      "grad_norm": 1.2908138036727905,
      "learning_rate": 8.723447712418301e-06,
      "loss": 0.0628,
      "step": 4678
    },
    {
      "epoch": 1.0751378676470589,
      "grad_norm": 0.814670979976654,
      "learning_rate": 8.722937091503269e-06,
      "loss": 0.0539,
      "step": 4679
    },
    {
      "epoch": 1.0753676470588236,
      "grad_norm": 1.3541697263717651,
      "learning_rate": 8.722426470588235e-06,
      "loss": 0.0837,
      "step": 4680
    },
    {
      "epoch": 1.0755974264705883,
      "grad_norm": 1.2585474252700806,
      "learning_rate": 8.721915849673205e-06,
      "loss": 0.0824,
      "step": 4681
    },
    {
      "epoch": 1.075827205882353,
      "grad_norm": 0.9202977418899536,
      "learning_rate": 8.72140522875817e-06,
      "loss": 0.0474,
      "step": 4682
    },
    {
      "epoch": 1.0760569852941178,
      "grad_norm": 2.363445281982422,
      "learning_rate": 8.720894607843139e-06,
      "loss": 0.0715,
      "step": 4683
    },
    {
      "epoch": 1.0762867647058822,
      "grad_norm": 1.2941572666168213,
      "learning_rate": 8.720383986928105e-06,
      "loss": 0.0745,
      "step": 4684
    },
    {
      "epoch": 1.076516544117647,
      "grad_norm": 0.9731177687644958,
      "learning_rate": 8.719873366013073e-06,
      "loss": 0.0639,
      "step": 4685
    },
    {
      "epoch": 1.0767463235294117,
      "grad_norm": 0.9731353521347046,
      "learning_rate": 8.71936274509804e-06,
      "loss": 0.0593,
      "step": 4686
    },
    {
      "epoch": 1.0769761029411764,
      "grad_norm": 0.7023850083351135,
      "learning_rate": 8.718852124183007e-06,
      "loss": 0.0497,
      "step": 4687
    },
    {
      "epoch": 1.0772058823529411,
      "grad_norm": 1.1961796283721924,
      "learning_rate": 8.718341503267974e-06,
      "loss": 0.0836,
      "step": 4688
    },
    {
      "epoch": 1.0774356617647058,
      "grad_norm": 0.9451584815979004,
      "learning_rate": 8.717830882352942e-06,
      "loss": 0.0637,
      "step": 4689
    },
    {
      "epoch": 1.0776654411764706,
      "grad_norm": 1.1031025648117065,
      "learning_rate": 8.717320261437908e-06,
      "loss": 0.0958,
      "step": 4690
    },
    {
      "epoch": 1.0778952205882353,
      "grad_norm": 0.9991150498390198,
      "learning_rate": 8.716809640522876e-06,
      "loss": 0.0718,
      "step": 4691
    },
    {
      "epoch": 1.078125,
      "grad_norm": 0.9865804314613342,
      "learning_rate": 8.716299019607844e-06,
      "loss": 0.0761,
      "step": 4692
    },
    {
      "epoch": 1.0783547794117647,
      "grad_norm": 0.8750415444374084,
      "learning_rate": 8.715788398692812e-06,
      "loss": 0.0425,
      "step": 4693
    },
    {
      "epoch": 1.0785845588235294,
      "grad_norm": 0.8134766221046448,
      "learning_rate": 8.715277777777778e-06,
      "loss": 0.056,
      "step": 4694
    },
    {
      "epoch": 1.0788143382352942,
      "grad_norm": 0.7134778499603271,
      "learning_rate": 8.714767156862746e-06,
      "loss": 0.0594,
      "step": 4695
    },
    {
      "epoch": 1.0790441176470589,
      "grad_norm": 0.8159541487693787,
      "learning_rate": 8.714256535947712e-06,
      "loss": 0.0605,
      "step": 4696
    },
    {
      "epoch": 1.0792738970588236,
      "grad_norm": 1.1118963956832886,
      "learning_rate": 8.71374591503268e-06,
      "loss": 0.0365,
      "step": 4697
    },
    {
      "epoch": 1.0795036764705883,
      "grad_norm": 1.2263885736465454,
      "learning_rate": 8.713235294117648e-06,
      "loss": 0.0838,
      "step": 4698
    },
    {
      "epoch": 1.079733455882353,
      "grad_norm": 1.0917891263961792,
      "learning_rate": 8.712724673202614e-06,
      "loss": 0.0652,
      "step": 4699
    },
    {
      "epoch": 1.0799632352941178,
      "grad_norm": 1.0901070833206177,
      "learning_rate": 8.712214052287582e-06,
      "loss": 0.084,
      "step": 4700
    },
    {
      "epoch": 1.0801930147058822,
      "grad_norm": 0.7756608128547668,
      "learning_rate": 8.71170343137255e-06,
      "loss": 0.0481,
      "step": 4701
    },
    {
      "epoch": 1.080422794117647,
      "grad_norm": 0.7303147315979004,
      "learning_rate": 8.711192810457518e-06,
      "loss": 0.0581,
      "step": 4702
    },
    {
      "epoch": 1.0806525735294117,
      "grad_norm": 0.882438063621521,
      "learning_rate": 8.710682189542484e-06,
      "loss": 0.0505,
      "step": 4703
    },
    {
      "epoch": 1.0808823529411764,
      "grad_norm": 0.7875636219978333,
      "learning_rate": 8.710171568627452e-06,
      "loss": 0.0377,
      "step": 4704
    },
    {
      "epoch": 1.0811121323529411,
      "grad_norm": 1.0284913778305054,
      "learning_rate": 8.70966094771242e-06,
      "loss": 0.064,
      "step": 4705
    },
    {
      "epoch": 1.0813419117647058,
      "grad_norm": 0.8421462178230286,
      "learning_rate": 8.709150326797386e-06,
      "loss": 0.0445,
      "step": 4706
    },
    {
      "epoch": 1.0815716911764706,
      "grad_norm": 0.7181189656257629,
      "learning_rate": 8.708639705882354e-06,
      "loss": 0.0412,
      "step": 4707
    },
    {
      "epoch": 1.0818014705882353,
      "grad_norm": 0.9799739718437195,
      "learning_rate": 8.70812908496732e-06,
      "loss": 0.0598,
      "step": 4708
    },
    {
      "epoch": 1.08203125,
      "grad_norm": 1.12575364112854,
      "learning_rate": 8.70761846405229e-06,
      "loss": 0.0649,
      "step": 4709
    },
    {
      "epoch": 1.0822610294117647,
      "grad_norm": 1.0171494483947754,
      "learning_rate": 8.707107843137256e-06,
      "loss": 0.0691,
      "step": 4710
    },
    {
      "epoch": 1.0824908088235294,
      "grad_norm": 1.199488639831543,
      "learning_rate": 8.706597222222223e-06,
      "loss": 0.0645,
      "step": 4711
    },
    {
      "epoch": 1.0827205882352942,
      "grad_norm": 0.794596791267395,
      "learning_rate": 8.70608660130719e-06,
      "loss": 0.0447,
      "step": 4712
    },
    {
      "epoch": 1.0829503676470589,
      "grad_norm": 1.1540119647979736,
      "learning_rate": 8.705575980392157e-06,
      "loss": 0.0704,
      "step": 4713
    },
    {
      "epoch": 1.0831801470588236,
      "grad_norm": 0.9770799875259399,
      "learning_rate": 8.705065359477125e-06,
      "loss": 0.0631,
      "step": 4714
    },
    {
      "epoch": 1.0834099264705883,
      "grad_norm": 1.3158849477767944,
      "learning_rate": 8.704554738562091e-06,
      "loss": 0.0643,
      "step": 4715
    },
    {
      "epoch": 1.083639705882353,
      "grad_norm": 0.955547034740448,
      "learning_rate": 8.70404411764706e-06,
      "loss": 0.0363,
      "step": 4716
    },
    {
      "epoch": 1.0838694852941178,
      "grad_norm": 0.8599031567573547,
      "learning_rate": 8.703533496732027e-06,
      "loss": 0.0547,
      "step": 4717
    },
    {
      "epoch": 1.0840992647058822,
      "grad_norm": 1.030407190322876,
      "learning_rate": 8.703022875816995e-06,
      "loss": 0.078,
      "step": 4718
    },
    {
      "epoch": 1.084329044117647,
      "grad_norm": 1.1943371295928955,
      "learning_rate": 8.702512254901961e-06,
      "loss": 0.0807,
      "step": 4719
    },
    {
      "epoch": 1.0845588235294117,
      "grad_norm": 1.1121337413787842,
      "learning_rate": 8.702001633986929e-06,
      "loss": 0.0731,
      "step": 4720
    },
    {
      "epoch": 1.0847886029411764,
      "grad_norm": 0.9372778534889221,
      "learning_rate": 8.701491013071897e-06,
      "loss": 0.0737,
      "step": 4721
    },
    {
      "epoch": 1.0850183823529411,
      "grad_norm": 1.2562257051467896,
      "learning_rate": 8.700980392156863e-06,
      "loss": 0.0561,
      "step": 4722
    },
    {
      "epoch": 1.0852481617647058,
      "grad_norm": 0.8787396550178528,
      "learning_rate": 8.700469771241831e-06,
      "loss": 0.0665,
      "step": 4723
    },
    {
      "epoch": 1.0854779411764706,
      "grad_norm": 1.0120285749435425,
      "learning_rate": 8.699959150326797e-06,
      "loss": 0.0737,
      "step": 4724
    },
    {
      "epoch": 1.0857077205882353,
      "grad_norm": 0.9899173378944397,
      "learning_rate": 8.699448529411767e-06,
      "loss": 0.0659,
      "step": 4725
    },
    {
      "epoch": 1.0859375,
      "grad_norm": 0.9123536944389343,
      "learning_rate": 8.698937908496733e-06,
      "loss": 0.0644,
      "step": 4726
    },
    {
      "epoch": 1.0861672794117647,
      "grad_norm": 0.6647239327430725,
      "learning_rate": 8.6984272875817e-06,
      "loss": 0.0466,
      "step": 4727
    },
    {
      "epoch": 1.0863970588235294,
      "grad_norm": 1.0787792205810547,
      "learning_rate": 8.697916666666667e-06,
      "loss": 0.0622,
      "step": 4728
    },
    {
      "epoch": 1.0866268382352942,
      "grad_norm": 1.055354356765747,
      "learning_rate": 8.697406045751635e-06,
      "loss": 0.0651,
      "step": 4729
    },
    {
      "epoch": 1.0868566176470589,
      "grad_norm": 1.214274287223816,
      "learning_rate": 8.696895424836603e-06,
      "loss": 0.068,
      "step": 4730
    },
    {
      "epoch": 1.0870863970588236,
      "grad_norm": 0.883031964302063,
      "learning_rate": 8.696384803921569e-06,
      "loss": 0.0589,
      "step": 4731
    },
    {
      "epoch": 1.0873161764705883,
      "grad_norm": 0.8883636593818665,
      "learning_rate": 8.695874183006537e-06,
      "loss": 0.043,
      "step": 4732
    },
    {
      "epoch": 1.087545955882353,
      "grad_norm": 0.8632996678352356,
      "learning_rate": 8.695363562091505e-06,
      "loss": 0.049,
      "step": 4733
    },
    {
      "epoch": 1.0877757352941178,
      "grad_norm": 1.0806493759155273,
      "learning_rate": 8.69485294117647e-06,
      "loss": 0.0638,
      "step": 4734
    },
    {
      "epoch": 1.0880055147058822,
      "grad_norm": 1.079132318496704,
      "learning_rate": 8.694342320261439e-06,
      "loss": 0.0664,
      "step": 4735
    },
    {
      "epoch": 1.088235294117647,
      "grad_norm": 0.9815346002578735,
      "learning_rate": 8.693831699346406e-06,
      "loss": 0.0554,
      "step": 4736
    },
    {
      "epoch": 1.0884650735294117,
      "grad_norm": 0.8881731629371643,
      "learning_rate": 8.693321078431374e-06,
      "loss": 0.0505,
      "step": 4737
    },
    {
      "epoch": 1.0886948529411764,
      "grad_norm": 0.7845578193664551,
      "learning_rate": 8.69281045751634e-06,
      "loss": 0.0572,
      "step": 4738
    },
    {
      "epoch": 1.0889246323529411,
      "grad_norm": 1.1220097541809082,
      "learning_rate": 8.692299836601308e-06,
      "loss": 0.066,
      "step": 4739
    },
    {
      "epoch": 1.0891544117647058,
      "grad_norm": 0.9203655123710632,
      "learning_rate": 8.691789215686274e-06,
      "loss": 0.049,
      "step": 4740
    },
    {
      "epoch": 1.0893841911764706,
      "grad_norm": 0.8853481411933899,
      "learning_rate": 8.691278594771242e-06,
      "loss": 0.0442,
      "step": 4741
    },
    {
      "epoch": 1.0896139705882353,
      "grad_norm": 0.9755937457084656,
      "learning_rate": 8.69076797385621e-06,
      "loss": 0.0767,
      "step": 4742
    },
    {
      "epoch": 1.08984375,
      "grad_norm": 0.9613938331604004,
      "learning_rate": 8.690257352941176e-06,
      "loss": 0.0557,
      "step": 4743
    },
    {
      "epoch": 1.0900735294117647,
      "grad_norm": 0.8246194124221802,
      "learning_rate": 8.689746732026144e-06,
      "loss": 0.0513,
      "step": 4744
    },
    {
      "epoch": 1.0903033088235294,
      "grad_norm": 0.9168875217437744,
      "learning_rate": 8.689236111111112e-06,
      "loss": 0.0579,
      "step": 4745
    },
    {
      "epoch": 1.0905330882352942,
      "grad_norm": 1.4449853897094727,
      "learning_rate": 8.68872549019608e-06,
      "loss": 0.1008,
      "step": 4746
    },
    {
      "epoch": 1.0907628676470589,
      "grad_norm": 0.818048357963562,
      "learning_rate": 8.688214869281046e-06,
      "loss": 0.0528,
      "step": 4747
    },
    {
      "epoch": 1.0909926470588236,
      "grad_norm": 1.014217495918274,
      "learning_rate": 8.687704248366014e-06,
      "loss": 0.0664,
      "step": 4748
    },
    {
      "epoch": 1.0912224264705883,
      "grad_norm": 0.941613495349884,
      "learning_rate": 8.687193627450982e-06,
      "loss": 0.0442,
      "step": 4749
    },
    {
      "epoch": 1.091452205882353,
      "grad_norm": 0.9010757803916931,
      "learning_rate": 8.686683006535948e-06,
      "loss": 0.0845,
      "step": 4750
    },
    {
      "epoch": 1.0916819852941178,
      "grad_norm": 1.0573114156723022,
      "learning_rate": 8.686172385620916e-06,
      "loss": 0.0545,
      "step": 4751
    },
    {
      "epoch": 1.0919117647058822,
      "grad_norm": 0.9194720387458801,
      "learning_rate": 8.685661764705882e-06,
      "loss": 0.0401,
      "step": 4752
    },
    {
      "epoch": 1.092141544117647,
      "grad_norm": 1.0091004371643066,
      "learning_rate": 8.685151143790852e-06,
      "loss": 0.0505,
      "step": 4753
    },
    {
      "epoch": 1.0923713235294117,
      "grad_norm": 0.745108425617218,
      "learning_rate": 8.684640522875818e-06,
      "loss": 0.0574,
      "step": 4754
    },
    {
      "epoch": 1.0926011029411764,
      "grad_norm": 0.9946304559707642,
      "learning_rate": 8.684129901960786e-06,
      "loss": 0.0471,
      "step": 4755
    },
    {
      "epoch": 1.0928308823529411,
      "grad_norm": 1.0360230207443237,
      "learning_rate": 8.683619281045752e-06,
      "loss": 0.0706,
      "step": 4756
    },
    {
      "epoch": 1.0930606617647058,
      "grad_norm": 1.2281668186187744,
      "learning_rate": 8.68310866013072e-06,
      "loss": 0.0776,
      "step": 4757
    },
    {
      "epoch": 1.0932904411764706,
      "grad_norm": 0.9855882525444031,
      "learning_rate": 8.682598039215687e-06,
      "loss": 0.0743,
      "step": 4758
    },
    {
      "epoch": 1.0935202205882353,
      "grad_norm": 1.135494351387024,
      "learning_rate": 8.682087418300654e-06,
      "loss": 0.067,
      "step": 4759
    },
    {
      "epoch": 1.09375,
      "grad_norm": 1.304644227027893,
      "learning_rate": 8.681576797385622e-06,
      "loss": 0.0664,
      "step": 4760
    },
    {
      "epoch": 1.0939797794117647,
      "grad_norm": 1.3432406187057495,
      "learning_rate": 8.68106617647059e-06,
      "loss": 0.0765,
      "step": 4761
    },
    {
      "epoch": 1.0942095588235294,
      "grad_norm": 1.0158885717391968,
      "learning_rate": 8.680555555555557e-06,
      "loss": 0.0619,
      "step": 4762
    },
    {
      "epoch": 1.0944393382352942,
      "grad_norm": 1.1645056009292603,
      "learning_rate": 8.680044934640523e-06,
      "loss": 0.0802,
      "step": 4763
    },
    {
      "epoch": 1.0946691176470589,
      "grad_norm": 0.8883683085441589,
      "learning_rate": 8.679534313725491e-06,
      "loss": 0.0437,
      "step": 4764
    },
    {
      "epoch": 1.0948988970588236,
      "grad_norm": 0.8946695327758789,
      "learning_rate": 8.679023692810459e-06,
      "loss": 0.0632,
      "step": 4765
    },
    {
      "epoch": 1.0951286764705883,
      "grad_norm": 0.9945675134658813,
      "learning_rate": 8.678513071895425e-06,
      "loss": 0.0474,
      "step": 4766
    },
    {
      "epoch": 1.095358455882353,
      "grad_norm": 1.0668169260025024,
      "learning_rate": 8.678002450980393e-06,
      "loss": 0.0679,
      "step": 4767
    },
    {
      "epoch": 1.0955882352941178,
      "grad_norm": 1.0540130138397217,
      "learning_rate": 8.67749183006536e-06,
      "loss": 0.0887,
      "step": 4768
    },
    {
      "epoch": 1.0958180147058822,
      "grad_norm": 0.836080014705658,
      "learning_rate": 8.676981209150329e-06,
      "loss": 0.0779,
      "step": 4769
    },
    {
      "epoch": 1.096047794117647,
      "grad_norm": 0.8662610650062561,
      "learning_rate": 8.676470588235295e-06,
      "loss": 0.0386,
      "step": 4770
    },
    {
      "epoch": 1.0962775735294117,
      "grad_norm": 0.8395565748214722,
      "learning_rate": 8.675959967320263e-06,
      "loss": 0.0413,
      "step": 4771
    },
    {
      "epoch": 1.0965073529411764,
      "grad_norm": 1.2123558521270752,
      "learning_rate": 8.675449346405229e-06,
      "loss": 0.0781,
      "step": 4772
    },
    {
      "epoch": 1.0967371323529411,
      "grad_norm": 0.9557933807373047,
      "learning_rate": 8.674938725490197e-06,
      "loss": 0.0543,
      "step": 4773
    },
    {
      "epoch": 1.0969669117647058,
      "grad_norm": 1.255912184715271,
      "learning_rate": 8.674428104575165e-06,
      "loss": 0.0729,
      "step": 4774
    },
    {
      "epoch": 1.0971966911764706,
      "grad_norm": 0.79082852602005,
      "learning_rate": 8.673917483660131e-06,
      "loss": 0.053,
      "step": 4775
    },
    {
      "epoch": 1.0974264705882353,
      "grad_norm": 0.7985560894012451,
      "learning_rate": 8.673406862745099e-06,
      "loss": 0.0371,
      "step": 4776
    },
    {
      "epoch": 1.09765625,
      "grad_norm": 1.2263946533203125,
      "learning_rate": 8.672896241830067e-06,
      "loss": 0.0683,
      "step": 4777
    },
    {
      "epoch": 1.0978860294117647,
      "grad_norm": 0.6137766242027283,
      "learning_rate": 8.672385620915033e-06,
      "loss": 0.0381,
      "step": 4778
    },
    {
      "epoch": 1.0981158088235294,
      "grad_norm": 1.227257490158081,
      "learning_rate": 8.671875e-06,
      "loss": 0.0848,
      "step": 4779
    },
    {
      "epoch": 1.0983455882352942,
      "grad_norm": 0.8263488411903381,
      "learning_rate": 8.671364379084969e-06,
      "loss": 0.0461,
      "step": 4780
    },
    {
      "epoch": 1.0985753676470589,
      "grad_norm": 1.159045696258545,
      "learning_rate": 8.670853758169935e-06,
      "loss": 0.0599,
      "step": 4781
    },
    {
      "epoch": 1.0988051470588236,
      "grad_norm": 0.7276983857154846,
      "learning_rate": 8.670343137254903e-06,
      "loss": 0.0293,
      "step": 4782
    },
    {
      "epoch": 1.0990349264705883,
      "grad_norm": 0.9689928889274597,
      "learning_rate": 8.66983251633987e-06,
      "loss": 0.0803,
      "step": 4783
    },
    {
      "epoch": 1.099264705882353,
      "grad_norm": 0.9434217810630798,
      "learning_rate": 8.669321895424837e-06,
      "loss": 0.0579,
      "step": 4784
    },
    {
      "epoch": 1.0994944852941178,
      "grad_norm": 0.8449588418006897,
      "learning_rate": 8.668811274509805e-06,
      "loss": 0.0525,
      "step": 4785
    },
    {
      "epoch": 1.0997242647058822,
      "grad_norm": 0.8489001393318176,
      "learning_rate": 8.668300653594772e-06,
      "loss": 0.0473,
      "step": 4786
    },
    {
      "epoch": 1.099954044117647,
      "grad_norm": 1.1753487586975098,
      "learning_rate": 8.667790032679739e-06,
      "loss": 0.099,
      "step": 4787
    },
    {
      "epoch": 1.1001838235294117,
      "grad_norm": 0.6899968981742859,
      "learning_rate": 8.667279411764706e-06,
      "loss": 0.0255,
      "step": 4788
    },
    {
      "epoch": 1.1004136029411764,
      "grad_norm": 1.0447431802749634,
      "learning_rate": 8.666768790849673e-06,
      "loss": 0.0656,
      "step": 4789
    },
    {
      "epoch": 1.1006433823529411,
      "grad_norm": 1.1877375841140747,
      "learning_rate": 8.666258169934642e-06,
      "loss": 0.0568,
      "step": 4790
    },
    {
      "epoch": 1.1008731617647058,
      "grad_norm": 1.7416468858718872,
      "learning_rate": 8.665747549019608e-06,
      "loss": 0.0482,
      "step": 4791
    },
    {
      "epoch": 1.1011029411764706,
      "grad_norm": 0.9563481211662292,
      "learning_rate": 8.665236928104576e-06,
      "loss": 0.0781,
      "step": 4792
    },
    {
      "epoch": 1.1013327205882353,
      "grad_norm": 1.137524127960205,
      "learning_rate": 8.664726307189542e-06,
      "loss": 0.0773,
      "step": 4793
    },
    {
      "epoch": 1.1015625,
      "grad_norm": 1.1683704853057861,
      "learning_rate": 8.66421568627451e-06,
      "loss": 0.0742,
      "step": 4794
    },
    {
      "epoch": 1.1017922794117647,
      "grad_norm": 1.162621259689331,
      "learning_rate": 8.663705065359478e-06,
      "loss": 0.0824,
      "step": 4795
    },
    {
      "epoch": 1.1020220588235294,
      "grad_norm": 1.1638447046279907,
      "learning_rate": 8.663194444444444e-06,
      "loss": 0.0705,
      "step": 4796
    },
    {
      "epoch": 1.1022518382352942,
      "grad_norm": 0.9808881282806396,
      "learning_rate": 8.662683823529412e-06,
      "loss": 0.0593,
      "step": 4797
    },
    {
      "epoch": 1.1024816176470589,
      "grad_norm": 1.0677844285964966,
      "learning_rate": 8.66217320261438e-06,
      "loss": 0.0627,
      "step": 4798
    },
    {
      "epoch": 1.1027113970588236,
      "grad_norm": 1.0587869882583618,
      "learning_rate": 8.661662581699348e-06,
      "loss": 0.0572,
      "step": 4799
    },
    {
      "epoch": 1.1029411764705883,
      "grad_norm": 0.9433493614196777,
      "learning_rate": 8.661151960784314e-06,
      "loss": 0.039,
      "step": 4800
    },
    {
      "epoch": 1.103170955882353,
      "grad_norm": 1.5350207090377808,
      "learning_rate": 8.660641339869282e-06,
      "loss": 0.0676,
      "step": 4801
    },
    {
      "epoch": 1.1034007352941178,
      "grad_norm": 0.9218637347221375,
      "learning_rate": 8.66013071895425e-06,
      "loss": 0.0451,
      "step": 4802
    },
    {
      "epoch": 1.1036305147058822,
      "grad_norm": 1.6086022853851318,
      "learning_rate": 8.659620098039216e-06,
      "loss": 0.0831,
      "step": 4803
    },
    {
      "epoch": 1.103860294117647,
      "grad_norm": 1.7555160522460938,
      "learning_rate": 8.659109477124184e-06,
      "loss": 0.0558,
      "step": 4804
    },
    {
      "epoch": 1.1040900735294117,
      "grad_norm": 0.995739221572876,
      "learning_rate": 8.65859885620915e-06,
      "loss": 0.0588,
      "step": 4805
    },
    {
      "epoch": 1.1043198529411764,
      "grad_norm": 1.2249594926834106,
      "learning_rate": 8.65808823529412e-06,
      "loss": 0.0609,
      "step": 4806
    },
    {
      "epoch": 1.1045496323529411,
      "grad_norm": 1.1428918838500977,
      "learning_rate": 8.657577614379086e-06,
      "loss": 0.0622,
      "step": 4807
    },
    {
      "epoch": 1.1047794117647058,
      "grad_norm": 1.1565300226211548,
      "learning_rate": 8.657066993464053e-06,
      "loss": 0.0468,
      "step": 4808
    },
    {
      "epoch": 1.1050091911764706,
      "grad_norm": 0.9520378112792969,
      "learning_rate": 8.65655637254902e-06,
      "loss": 0.0478,
      "step": 4809
    },
    {
      "epoch": 1.1052389705882353,
      "grad_norm": 1.2624726295471191,
      "learning_rate": 8.656045751633987e-06,
      "loss": 0.0849,
      "step": 4810
    },
    {
      "epoch": 1.10546875,
      "grad_norm": 1.4467531442642212,
      "learning_rate": 8.655535130718955e-06,
      "loss": 0.0842,
      "step": 4811
    },
    {
      "epoch": 1.1056985294117647,
      "grad_norm": 1.0319209098815918,
      "learning_rate": 8.655024509803922e-06,
      "loss": 0.0559,
      "step": 4812
    },
    {
      "epoch": 1.1059283088235294,
      "grad_norm": 1.1237199306488037,
      "learning_rate": 8.65451388888889e-06,
      "loss": 0.0705,
      "step": 4813
    },
    {
      "epoch": 1.1061580882352942,
      "grad_norm": 0.8325391411781311,
      "learning_rate": 8.654003267973857e-06,
      "loss": 0.0422,
      "step": 4814
    },
    {
      "epoch": 1.1063878676470589,
      "grad_norm": 1.0346612930297852,
      "learning_rate": 8.653492647058825e-06,
      "loss": 0.0523,
      "step": 4815
    },
    {
      "epoch": 1.1066176470588236,
      "grad_norm": 0.9647104144096375,
      "learning_rate": 8.652982026143791e-06,
      "loss": 0.064,
      "step": 4816
    },
    {
      "epoch": 1.1068474264705883,
      "grad_norm": 0.9004428386688232,
      "learning_rate": 8.652471405228759e-06,
      "loss": 0.0422,
      "step": 4817
    },
    {
      "epoch": 1.107077205882353,
      "grad_norm": 0.993910014629364,
      "learning_rate": 8.651960784313727e-06,
      "loss": 0.0599,
      "step": 4818
    },
    {
      "epoch": 1.1073069852941178,
      "grad_norm": 0.817750096321106,
      "learning_rate": 8.651450163398693e-06,
      "loss": 0.0469,
      "step": 4819
    },
    {
      "epoch": 1.1075367647058822,
      "grad_norm": 0.8954340219497681,
      "learning_rate": 8.650939542483661e-06,
      "loss": 0.045,
      "step": 4820
    },
    {
      "epoch": 1.107766544117647,
      "grad_norm": 2.0091960430145264,
      "learning_rate": 8.650428921568627e-06,
      "loss": 0.0587,
      "step": 4821
    },
    {
      "epoch": 1.1079963235294117,
      "grad_norm": 1.3967264890670776,
      "learning_rate": 8.649918300653595e-06,
      "loss": 0.0815,
      "step": 4822
    },
    {
      "epoch": 1.1082261029411764,
      "grad_norm": 0.8852723836898804,
      "learning_rate": 8.649407679738563e-06,
      "loss": 0.0858,
      "step": 4823
    },
    {
      "epoch": 1.1084558823529411,
      "grad_norm": 0.748125433921814,
      "learning_rate": 8.648897058823529e-06,
      "loss": 0.0423,
      "step": 4824
    },
    {
      "epoch": 1.1086856617647058,
      "grad_norm": 1.2746825218200684,
      "learning_rate": 8.648386437908497e-06,
      "loss": 0.0822,
      "step": 4825
    },
    {
      "epoch": 1.1089154411764706,
      "grad_norm": 1.3432718515396118,
      "learning_rate": 8.647875816993465e-06,
      "loss": 0.1012,
      "step": 4826
    },
    {
      "epoch": 1.1091452205882353,
      "grad_norm": 0.8686392307281494,
      "learning_rate": 8.647365196078433e-06,
      "loss": 0.0677,
      "step": 4827
    },
    {
      "epoch": 1.109375,
      "grad_norm": 0.9362311363220215,
      "learning_rate": 8.646854575163399e-06,
      "loss": 0.0493,
      "step": 4828
    },
    {
      "epoch": 1.1096047794117647,
      "grad_norm": 0.9431828856468201,
      "learning_rate": 8.646343954248367e-06,
      "loss": 0.0511,
      "step": 4829
    },
    {
      "epoch": 1.1098345588235294,
      "grad_norm": 1.5593304634094238,
      "learning_rate": 8.645833333333335e-06,
      "loss": 0.0706,
      "step": 4830
    },
    {
      "epoch": 1.1100643382352942,
      "grad_norm": 0.8881993889808655,
      "learning_rate": 8.6453227124183e-06,
      "loss": 0.0614,
      "step": 4831
    },
    {
      "epoch": 1.1102941176470589,
      "grad_norm": 0.9077906012535095,
      "learning_rate": 8.644812091503269e-06,
      "loss": 0.06,
      "step": 4832
    },
    {
      "epoch": 1.1105238970588236,
      "grad_norm": 0.957240641117096,
      "learning_rate": 8.644301470588235e-06,
      "loss": 0.032,
      "step": 4833
    },
    {
      "epoch": 1.1107536764705883,
      "grad_norm": 1.1764488220214844,
      "learning_rate": 8.643790849673204e-06,
      "loss": 0.0822,
      "step": 4834
    },
    {
      "epoch": 1.110983455882353,
      "grad_norm": 1.008093237876892,
      "learning_rate": 8.64328022875817e-06,
      "loss": 0.0376,
      "step": 4835
    },
    {
      "epoch": 1.1112132352941178,
      "grad_norm": 1.1863434314727783,
      "learning_rate": 8.642769607843138e-06,
      "loss": 0.0521,
      "step": 4836
    },
    {
      "epoch": 1.1114430147058822,
      "grad_norm": 1.0707979202270508,
      "learning_rate": 8.642258986928105e-06,
      "loss": 0.0539,
      "step": 4837
    },
    {
      "epoch": 1.111672794117647,
      "grad_norm": 1.0939245223999023,
      "learning_rate": 8.641748366013072e-06,
      "loss": 0.0779,
      "step": 4838
    },
    {
      "epoch": 1.1119025735294117,
      "grad_norm": 1.1002041101455688,
      "learning_rate": 8.64123774509804e-06,
      "loss": 0.0595,
      "step": 4839
    },
    {
      "epoch": 1.1121323529411764,
      "grad_norm": 1.1383674144744873,
      "learning_rate": 8.640727124183006e-06,
      "loss": 0.058,
      "step": 4840
    },
    {
      "epoch": 1.1123621323529411,
      "grad_norm": 0.9380960464477539,
      "learning_rate": 8.640216503267974e-06,
      "loss": 0.0527,
      "step": 4841
    },
    {
      "epoch": 1.1125919117647058,
      "grad_norm": 1.5307623147964478,
      "learning_rate": 8.639705882352942e-06,
      "loss": 0.0982,
      "step": 4842
    },
    {
      "epoch": 1.1128216911764706,
      "grad_norm": 0.9745119214057922,
      "learning_rate": 8.63919526143791e-06,
      "loss": 0.057,
      "step": 4843
    },
    {
      "epoch": 1.1130514705882353,
      "grad_norm": 1.0853328704833984,
      "learning_rate": 8.638684640522876e-06,
      "loss": 0.0744,
      "step": 4844
    },
    {
      "epoch": 1.11328125,
      "grad_norm": 1.001257300376892,
      "learning_rate": 8.638174019607844e-06,
      "loss": 0.0627,
      "step": 4845
    },
    {
      "epoch": 1.1135110294117647,
      "grad_norm": 1.2123119831085205,
      "learning_rate": 8.637663398692812e-06,
      "loss": 0.0708,
      "step": 4846
    },
    {
      "epoch": 1.1137408088235294,
      "grad_norm": 1.3691027164459229,
      "learning_rate": 8.637152777777778e-06,
      "loss": 0.098,
      "step": 4847
    },
    {
      "epoch": 1.1139705882352942,
      "grad_norm": 1.0741764307022095,
      "learning_rate": 8.636642156862746e-06,
      "loss": 0.0463,
      "step": 4848
    },
    {
      "epoch": 1.1142003676470589,
      "grad_norm": 0.704131543636322,
      "learning_rate": 8.636131535947712e-06,
      "loss": 0.0434,
      "step": 4849
    },
    {
      "epoch": 1.1144301470588236,
      "grad_norm": 1.0107464790344238,
      "learning_rate": 8.635620915032682e-06,
      "loss": 0.0651,
      "step": 4850
    },
    {
      "epoch": 1.1146599264705883,
      "grad_norm": 1.3437925577163696,
      "learning_rate": 8.635110294117648e-06,
      "loss": 0.0875,
      "step": 4851
    },
    {
      "epoch": 1.114889705882353,
      "grad_norm": 0.8409267663955688,
      "learning_rate": 8.634599673202616e-06,
      "loss": 0.0507,
      "step": 4852
    },
    {
      "epoch": 1.1151194852941178,
      "grad_norm": 0.8348152041435242,
      "learning_rate": 8.634089052287582e-06,
      "loss": 0.0617,
      "step": 4853
    },
    {
      "epoch": 1.1153492647058822,
      "grad_norm": 1.0799744129180908,
      "learning_rate": 8.63357843137255e-06,
      "loss": 0.0566,
      "step": 4854
    },
    {
      "epoch": 1.115579044117647,
      "grad_norm": 0.7842172980308533,
      "learning_rate": 8.633067810457518e-06,
      "loss": 0.0574,
      "step": 4855
    },
    {
      "epoch": 1.1158088235294117,
      "grad_norm": 1.2409971952438354,
      "learning_rate": 8.632557189542484e-06,
      "loss": 0.1074,
      "step": 4856
    },
    {
      "epoch": 1.1160386029411764,
      "grad_norm": 1.069899082183838,
      "learning_rate": 8.632046568627452e-06,
      "loss": 0.0656,
      "step": 4857
    },
    {
      "epoch": 1.1162683823529411,
      "grad_norm": 1.142785668373108,
      "learning_rate": 8.63153594771242e-06,
      "loss": 0.0667,
      "step": 4858
    },
    {
      "epoch": 1.1164981617647058,
      "grad_norm": 1.012861967086792,
      "learning_rate": 8.631025326797387e-06,
      "loss": 0.061,
      "step": 4859
    },
    {
      "epoch": 1.1167279411764706,
      "grad_norm": 0.9211075305938721,
      "learning_rate": 8.630514705882353e-06,
      "loss": 0.0517,
      "step": 4860
    },
    {
      "epoch": 1.1169577205882353,
      "grad_norm": 1.002379059791565,
      "learning_rate": 8.630004084967321e-06,
      "loss": 0.0584,
      "step": 4861
    },
    {
      "epoch": 1.1171875,
      "grad_norm": 1.4337512254714966,
      "learning_rate": 8.62949346405229e-06,
      "loss": 0.0818,
      "step": 4862
    },
    {
      "epoch": 1.1174172794117647,
      "grad_norm": 1.4476430416107178,
      "learning_rate": 8.628982843137255e-06,
      "loss": 0.0827,
      "step": 4863
    },
    {
      "epoch": 1.1176470588235294,
      "grad_norm": 0.7705293297767639,
      "learning_rate": 8.628472222222223e-06,
      "loss": 0.0457,
      "step": 4864
    },
    {
      "epoch": 1.1178768382352942,
      "grad_norm": 1.0896813869476318,
      "learning_rate": 8.62796160130719e-06,
      "loss": 0.0577,
      "step": 4865
    },
    {
      "epoch": 1.1181066176470589,
      "grad_norm": 1.0643914937973022,
      "learning_rate": 8.627450980392157e-06,
      "loss": 0.0608,
      "step": 4866
    },
    {
      "epoch": 1.1183363970588236,
      "grad_norm": 0.8543849587440491,
      "learning_rate": 8.626940359477125e-06,
      "loss": 0.0549,
      "step": 4867
    },
    {
      "epoch": 1.1185661764705883,
      "grad_norm": 0.956810474395752,
      "learning_rate": 8.626429738562091e-06,
      "loss": 0.0547,
      "step": 4868
    },
    {
      "epoch": 1.118795955882353,
      "grad_norm": 1.3904169797897339,
      "learning_rate": 8.625919117647059e-06,
      "loss": 0.0915,
      "step": 4869
    },
    {
      "epoch": 1.1190257352941178,
      "grad_norm": 1.1931750774383545,
      "learning_rate": 8.625408496732027e-06,
      "loss": 0.0906,
      "step": 4870
    },
    {
      "epoch": 1.1192555147058822,
      "grad_norm": 0.7568992376327515,
      "learning_rate": 8.624897875816995e-06,
      "loss": 0.057,
      "step": 4871
    },
    {
      "epoch": 1.119485294117647,
      "grad_norm": 1.1877045631408691,
      "learning_rate": 8.624387254901961e-06,
      "loss": 0.0432,
      "step": 4872
    },
    {
      "epoch": 1.1197150735294117,
      "grad_norm": 1.0613259077072144,
      "learning_rate": 8.623876633986929e-06,
      "loss": 0.0933,
      "step": 4873
    },
    {
      "epoch": 1.1199448529411764,
      "grad_norm": 1.1403517723083496,
      "learning_rate": 8.623366013071897e-06,
      "loss": 0.0618,
      "step": 4874
    },
    {
      "epoch": 1.1201746323529411,
      "grad_norm": 0.9842784404754639,
      "learning_rate": 8.622855392156863e-06,
      "loss": 0.0578,
      "step": 4875
    },
    {
      "epoch": 1.1204044117647058,
      "grad_norm": 0.8050422668457031,
      "learning_rate": 8.62234477124183e-06,
      "loss": 0.0621,
      "step": 4876
    },
    {
      "epoch": 1.1206341911764706,
      "grad_norm": 1.1014684438705444,
      "learning_rate": 8.621834150326797e-06,
      "loss": 0.0614,
      "step": 4877
    },
    {
      "epoch": 1.1208639705882353,
      "grad_norm": 0.6471498608589172,
      "learning_rate": 8.621323529411766e-06,
      "loss": 0.043,
      "step": 4878
    },
    {
      "epoch": 1.12109375,
      "grad_norm": 0.9722689986228943,
      "learning_rate": 8.620812908496733e-06,
      "loss": 0.0442,
      "step": 4879
    },
    {
      "epoch": 1.1213235294117647,
      "grad_norm": 0.832648515701294,
      "learning_rate": 8.6203022875817e-06,
      "loss": 0.0436,
      "step": 4880
    },
    {
      "epoch": 1.1215533088235294,
      "grad_norm": 1.0288008451461792,
      "learning_rate": 8.619791666666667e-06,
      "loss": 0.0849,
      "step": 4881
    },
    {
      "epoch": 1.1217830882352942,
      "grad_norm": 1.4066064357757568,
      "learning_rate": 8.619281045751635e-06,
      "loss": 0.0954,
      "step": 4882
    },
    {
      "epoch": 1.1220128676470589,
      "grad_norm": 1.014843463897705,
      "learning_rate": 8.618770424836602e-06,
      "loss": 0.0558,
      "step": 4883
    },
    {
      "epoch": 1.1222426470588236,
      "grad_norm": 1.0219897031784058,
      "learning_rate": 8.618259803921569e-06,
      "loss": 0.0808,
      "step": 4884
    },
    {
      "epoch": 1.1224724264705883,
      "grad_norm": 1.0048588514328003,
      "learning_rate": 8.617749183006536e-06,
      "loss": 0.0514,
      "step": 4885
    },
    {
      "epoch": 1.122702205882353,
      "grad_norm": 1.0555107593536377,
      "learning_rate": 8.617238562091504e-06,
      "loss": 0.0513,
      "step": 4886
    },
    {
      "epoch": 1.1229319852941178,
      "grad_norm": 1.0254310369491577,
      "learning_rate": 8.616727941176472e-06,
      "loss": 0.0665,
      "step": 4887
    },
    {
      "epoch": 1.1231617647058822,
      "grad_norm": 1.0635160207748413,
      "learning_rate": 8.616217320261438e-06,
      "loss": 0.0769,
      "step": 4888
    },
    {
      "epoch": 1.123391544117647,
      "grad_norm": 1.3591382503509521,
      "learning_rate": 8.615706699346406e-06,
      "loss": 0.0639,
      "step": 4889
    },
    {
      "epoch": 1.1236213235294117,
      "grad_norm": 0.7736520767211914,
      "learning_rate": 8.615196078431374e-06,
      "loss": 0.0588,
      "step": 4890
    },
    {
      "epoch": 1.1238511029411764,
      "grad_norm": 1.0372463464736938,
      "learning_rate": 8.61468545751634e-06,
      "loss": 0.0621,
      "step": 4891
    },
    {
      "epoch": 1.1240808823529411,
      "grad_norm": 1.2517365217208862,
      "learning_rate": 8.614174836601308e-06,
      "loss": 0.0848,
      "step": 4892
    },
    {
      "epoch": 1.1243106617647058,
      "grad_norm": 1.0635558366775513,
      "learning_rate": 8.613664215686274e-06,
      "loss": 0.0686,
      "step": 4893
    },
    {
      "epoch": 1.1245404411764706,
      "grad_norm": 1.1525375843048096,
      "learning_rate": 8.613153594771244e-06,
      "loss": 0.0805,
      "step": 4894
    },
    {
      "epoch": 1.1247702205882353,
      "grad_norm": 1.1736273765563965,
      "learning_rate": 8.61264297385621e-06,
      "loss": 0.0703,
      "step": 4895
    },
    {
      "epoch": 1.125,
      "grad_norm": 1.1660244464874268,
      "learning_rate": 8.612132352941178e-06,
      "loss": 0.0664,
      "step": 4896
    },
    {
      "epoch": 1.1252297794117647,
      "grad_norm": 1.2904590368270874,
      "learning_rate": 8.611621732026144e-06,
      "loss": 0.0713,
      "step": 4897
    },
    {
      "epoch": 1.1254595588235294,
      "grad_norm": 1.059393048286438,
      "learning_rate": 8.611111111111112e-06,
      "loss": 0.0591,
      "step": 4898
    },
    {
      "epoch": 1.1256893382352942,
      "grad_norm": 1.0075472593307495,
      "learning_rate": 8.61060049019608e-06,
      "loss": 0.0618,
      "step": 4899
    },
    {
      "epoch": 1.1259191176470589,
      "grad_norm": 0.8405537605285645,
      "learning_rate": 8.610089869281046e-06,
      "loss": 0.057,
      "step": 4900
    },
    {
      "epoch": 1.1261488970588236,
      "grad_norm": 0.8559356927871704,
      "learning_rate": 8.609579248366014e-06,
      "loss": 0.0489,
      "step": 4901
    },
    {
      "epoch": 1.1263786764705883,
      "grad_norm": 0.7585857510566711,
      "learning_rate": 8.609068627450982e-06,
      "loss": 0.0329,
      "step": 4902
    },
    {
      "epoch": 1.126608455882353,
      "grad_norm": 1.1893317699432373,
      "learning_rate": 8.60855800653595e-06,
      "loss": 0.0676,
      "step": 4903
    },
    {
      "epoch": 1.1268382352941178,
      "grad_norm": 0.8928747773170471,
      "learning_rate": 8.608047385620916e-06,
      "loss": 0.0748,
      "step": 4904
    },
    {
      "epoch": 1.1270680147058822,
      "grad_norm": 1.0925836563110352,
      "learning_rate": 8.607536764705884e-06,
      "loss": 0.0493,
      "step": 4905
    },
    {
      "epoch": 1.127297794117647,
      "grad_norm": 0.7569136023521423,
      "learning_rate": 8.607026143790851e-06,
      "loss": 0.0436,
      "step": 4906
    },
    {
      "epoch": 1.1275275735294117,
      "grad_norm": 0.8816277980804443,
      "learning_rate": 8.606515522875818e-06,
      "loss": 0.0511,
      "step": 4907
    },
    {
      "epoch": 1.1277573529411764,
      "grad_norm": 0.7945767045021057,
      "learning_rate": 8.606004901960785e-06,
      "loss": 0.0528,
      "step": 4908
    },
    {
      "epoch": 1.1279871323529411,
      "grad_norm": 0.9552664160728455,
      "learning_rate": 8.605494281045752e-06,
      "loss": 0.0596,
      "step": 4909
    },
    {
      "epoch": 1.1282169117647058,
      "grad_norm": 1.1644601821899414,
      "learning_rate": 8.60498366013072e-06,
      "loss": 0.075,
      "step": 4910
    },
    {
      "epoch": 1.1284466911764706,
      "grad_norm": 1.0072575807571411,
      "learning_rate": 8.604473039215687e-06,
      "loss": 0.0628,
      "step": 4911
    },
    {
      "epoch": 1.1286764705882353,
      "grad_norm": 1.1518170833587646,
      "learning_rate": 8.603962418300653e-06,
      "loss": 0.086,
      "step": 4912
    },
    {
      "epoch": 1.12890625,
      "grad_norm": 1.3600727319717407,
      "learning_rate": 8.603451797385621e-06,
      "loss": 0.0844,
      "step": 4913
    },
    {
      "epoch": 1.1291360294117647,
      "grad_norm": 0.7090926766395569,
      "learning_rate": 8.60294117647059e-06,
      "loss": 0.0316,
      "step": 4914
    },
    {
      "epoch": 1.1293658088235294,
      "grad_norm": 1.176786184310913,
      "learning_rate": 8.602430555555557e-06,
      "loss": 0.0574,
      "step": 4915
    },
    {
      "epoch": 1.1295955882352942,
      "grad_norm": 0.9428322911262512,
      "learning_rate": 8.601919934640523e-06,
      "loss": 0.0527,
      "step": 4916
    },
    {
      "epoch": 1.1298253676470589,
      "grad_norm": 1.369929552078247,
      "learning_rate": 8.601409313725491e-06,
      "loss": 0.075,
      "step": 4917
    },
    {
      "epoch": 1.1300551470588236,
      "grad_norm": 0.7824563980102539,
      "learning_rate": 8.600898692810459e-06,
      "loss": 0.0522,
      "step": 4918
    },
    {
      "epoch": 1.1302849264705883,
      "grad_norm": 0.8150124549865723,
      "learning_rate": 8.600388071895425e-06,
      "loss": 0.0493,
      "step": 4919
    },
    {
      "epoch": 1.130514705882353,
      "grad_norm": 0.7919121980667114,
      "learning_rate": 8.599877450980393e-06,
      "loss": 0.0325,
      "step": 4920
    },
    {
      "epoch": 1.1307444852941178,
      "grad_norm": 0.9576570391654968,
      "learning_rate": 8.599366830065359e-06,
      "loss": 0.0638,
      "step": 4921
    },
    {
      "epoch": 1.1309742647058822,
      "grad_norm": 1.3922628164291382,
      "learning_rate": 8.598856209150329e-06,
      "loss": 0.0875,
      "step": 4922
    },
    {
      "epoch": 1.131204044117647,
      "grad_norm": 1.0191148519515991,
      "learning_rate": 8.598345588235295e-06,
      "loss": 0.0622,
      "step": 4923
    },
    {
      "epoch": 1.1314338235294117,
      "grad_norm": 0.9277029633522034,
      "learning_rate": 8.597834967320263e-06,
      "loss": 0.0493,
      "step": 4924
    },
    {
      "epoch": 1.1316636029411764,
      "grad_norm": 1.0107994079589844,
      "learning_rate": 8.597324346405229e-06,
      "loss": 0.0653,
      "step": 4925
    },
    {
      "epoch": 1.1318933823529411,
      "grad_norm": 0.8557974100112915,
      "learning_rate": 8.596813725490197e-06,
      "loss": 0.0436,
      "step": 4926
    },
    {
      "epoch": 1.1321231617647058,
      "grad_norm": 1.5222054719924927,
      "learning_rate": 8.596303104575165e-06,
      "loss": 0.0517,
      "step": 4927
    },
    {
      "epoch": 1.1323529411764706,
      "grad_norm": 1.4281264543533325,
      "learning_rate": 8.59579248366013e-06,
      "loss": 0.0882,
      "step": 4928
    },
    {
      "epoch": 1.1325827205882353,
      "grad_norm": 0.9277659058570862,
      "learning_rate": 8.595281862745099e-06,
      "loss": 0.0616,
      "step": 4929
    },
    {
      "epoch": 1.1328125,
      "grad_norm": 0.9543910026550293,
      "learning_rate": 8.594771241830066e-06,
      "loss": 0.0495,
      "step": 4930
    },
    {
      "epoch": 1.1330422794117647,
      "grad_norm": 1.3185337781906128,
      "learning_rate": 8.594260620915034e-06,
      "loss": 0.0636,
      "step": 4931
    },
    {
      "epoch": 1.1332720588235294,
      "grad_norm": 1.018792748451233,
      "learning_rate": 8.59375e-06,
      "loss": 0.0584,
      "step": 4932
    },
    {
      "epoch": 1.1335018382352942,
      "grad_norm": 1.0281646251678467,
      "learning_rate": 8.593239379084968e-06,
      "loss": 0.0649,
      "step": 4933
    },
    {
      "epoch": 1.1337316176470589,
      "grad_norm": 0.7496516704559326,
      "learning_rate": 8.592728758169935e-06,
      "loss": 0.05,
      "step": 4934
    },
    {
      "epoch": 1.1339613970588236,
      "grad_norm": 1.019360065460205,
      "learning_rate": 8.592218137254902e-06,
      "loss": 0.0571,
      "step": 4935
    },
    {
      "epoch": 1.1341911764705883,
      "grad_norm": 0.8311962485313416,
      "learning_rate": 8.59170751633987e-06,
      "loss": 0.0456,
      "step": 4936
    },
    {
      "epoch": 1.134420955882353,
      "grad_norm": 0.857206404209137,
      "learning_rate": 8.591196895424836e-06,
      "loss": 0.0593,
      "step": 4937
    },
    {
      "epoch": 1.1346507352941178,
      "grad_norm": 0.7615887522697449,
      "learning_rate": 8.590686274509804e-06,
      "loss": 0.0495,
      "step": 4938
    },
    {
      "epoch": 1.1348805147058822,
      "grad_norm": 0.8778731822967529,
      "learning_rate": 8.590175653594772e-06,
      "loss": 0.0501,
      "step": 4939
    },
    {
      "epoch": 1.135110294117647,
      "grad_norm": 0.7748357057571411,
      "learning_rate": 8.58966503267974e-06,
      "loss": 0.0428,
      "step": 4940
    },
    {
      "epoch": 1.1353400735294117,
      "grad_norm": 1.1282294988632202,
      "learning_rate": 8.589154411764706e-06,
      "loss": 0.0606,
      "step": 4941
    },
    {
      "epoch": 1.1355698529411764,
      "grad_norm": 0.9644901156425476,
      "learning_rate": 8.588643790849674e-06,
      "loss": 0.0581,
      "step": 4942
    },
    {
      "epoch": 1.1357996323529411,
      "grad_norm": 0.6499791741371155,
      "learning_rate": 8.588133169934642e-06,
      "loss": 0.0411,
      "step": 4943
    },
    {
      "epoch": 1.1360294117647058,
      "grad_norm": 1.2073745727539062,
      "learning_rate": 8.587622549019608e-06,
      "loss": 0.0674,
      "step": 4944
    },
    {
      "epoch": 1.1362591911764706,
      "grad_norm": 1.066486120223999,
      "learning_rate": 8.587111928104576e-06,
      "loss": 0.0467,
      "step": 4945
    },
    {
      "epoch": 1.1364889705882353,
      "grad_norm": 0.7700693011283875,
      "learning_rate": 8.586601307189542e-06,
      "loss": 0.0666,
      "step": 4946
    },
    {
      "epoch": 1.13671875,
      "grad_norm": 1.2786598205566406,
      "learning_rate": 8.58609068627451e-06,
      "loss": 0.0679,
      "step": 4947
    },
    {
      "epoch": 1.1369485294117647,
      "grad_norm": 1.0548897981643677,
      "learning_rate": 8.585580065359478e-06,
      "loss": 0.0468,
      "step": 4948
    },
    {
      "epoch": 1.1371783088235294,
      "grad_norm": 0.7175614833831787,
      "learning_rate": 8.585069444444446e-06,
      "loss": 0.0419,
      "step": 4949
    },
    {
      "epoch": 1.1374080882352942,
      "grad_norm": 1.1060727834701538,
      "learning_rate": 8.584558823529412e-06,
      "loss": 0.0767,
      "step": 4950
    },
    {
      "epoch": 1.1376378676470589,
      "grad_norm": 0.6990663409233093,
      "learning_rate": 8.58404820261438e-06,
      "loss": 0.0597,
      "step": 4951
    },
    {
      "epoch": 1.1378676470588236,
      "grad_norm": 1.14718496799469,
      "learning_rate": 8.583537581699348e-06,
      "loss": 0.0694,
      "step": 4952
    },
    {
      "epoch": 1.1380974264705883,
      "grad_norm": 1.1584296226501465,
      "learning_rate": 8.583026960784314e-06,
      "loss": 0.0854,
      "step": 4953
    },
    {
      "epoch": 1.138327205882353,
      "grad_norm": 1.043346881866455,
      "learning_rate": 8.582516339869282e-06,
      "loss": 0.0415,
      "step": 4954
    },
    {
      "epoch": 1.1385569852941178,
      "grad_norm": 1.224047303199768,
      "learning_rate": 8.58200571895425e-06,
      "loss": 0.0537,
      "step": 4955
    },
    {
      "epoch": 1.1387867647058822,
      "grad_norm": 0.9354366064071655,
      "learning_rate": 8.581495098039216e-06,
      "loss": 0.0759,
      "step": 4956
    },
    {
      "epoch": 1.139016544117647,
      "grad_norm": 0.9288719892501831,
      "learning_rate": 8.580984477124184e-06,
      "loss": 0.0571,
      "step": 4957
    },
    {
      "epoch": 1.1392463235294117,
      "grad_norm": 0.7261491417884827,
      "learning_rate": 8.580473856209151e-06,
      "loss": 0.07,
      "step": 4958
    },
    {
      "epoch": 1.1394761029411764,
      "grad_norm": 0.7477611899375916,
      "learning_rate": 8.57996323529412e-06,
      "loss": 0.0398,
      "step": 4959
    },
    {
      "epoch": 1.1397058823529411,
      "grad_norm": 1.2890852689743042,
      "learning_rate": 8.579452614379085e-06,
      "loss": 0.0869,
      "step": 4960
    },
    {
      "epoch": 1.1399356617647058,
      "grad_norm": 1.0539032220840454,
      "learning_rate": 8.578941993464053e-06,
      "loss": 0.0449,
      "step": 4961
    },
    {
      "epoch": 1.1401654411764706,
      "grad_norm": 1.5887292623519897,
      "learning_rate": 8.57843137254902e-06,
      "loss": 0.1197,
      "step": 4962
    },
    {
      "epoch": 1.1403952205882353,
      "grad_norm": 0.9395488500595093,
      "learning_rate": 8.577920751633987e-06,
      "loss": 0.0593,
      "step": 4963
    },
    {
      "epoch": 1.140625,
      "grad_norm": 1.000117301940918,
      "learning_rate": 8.577410130718955e-06,
      "loss": 0.0444,
      "step": 4964
    },
    {
      "epoch": 1.1408547794117647,
      "grad_norm": 1.082263469696045,
      "learning_rate": 8.576899509803921e-06,
      "loss": 0.0675,
      "step": 4965
    },
    {
      "epoch": 1.1410845588235294,
      "grad_norm": 0.8497552275657654,
      "learning_rate": 8.57638888888889e-06,
      "loss": 0.0575,
      "step": 4966
    },
    {
      "epoch": 1.1413143382352942,
      "grad_norm": 0.9214847087860107,
      "learning_rate": 8.575878267973857e-06,
      "loss": 0.057,
      "step": 4967
    },
    {
      "epoch": 1.1415441176470589,
      "grad_norm": 1.1462559700012207,
      "learning_rate": 8.575367647058825e-06,
      "loss": 0.0708,
      "step": 4968
    },
    {
      "epoch": 1.1417738970588236,
      "grad_norm": 1.629429817199707,
      "learning_rate": 8.574857026143791e-06,
      "loss": 0.076,
      "step": 4969
    },
    {
      "epoch": 1.1420036764705883,
      "grad_norm": 1.057299256324768,
      "learning_rate": 8.574346405228759e-06,
      "loss": 0.0808,
      "step": 4970
    },
    {
      "epoch": 1.142233455882353,
      "grad_norm": 1.4748039245605469,
      "learning_rate": 8.573835784313727e-06,
      "loss": 0.0948,
      "step": 4971
    },
    {
      "epoch": 1.1424632352941178,
      "grad_norm": 1.1739637851715088,
      "learning_rate": 8.573325163398693e-06,
      "loss": 0.0776,
      "step": 4972
    },
    {
      "epoch": 1.1426930147058822,
      "grad_norm": 0.9596701860427856,
      "learning_rate": 8.57281454248366e-06,
      "loss": 0.0577,
      "step": 4973
    },
    {
      "epoch": 1.142922794117647,
      "grad_norm": 1.2691540718078613,
      "learning_rate": 8.572303921568627e-06,
      "loss": 0.0871,
      "step": 4974
    },
    {
      "epoch": 1.1431525735294117,
      "grad_norm": 1.5965347290039062,
      "learning_rate": 8.571793300653597e-06,
      "loss": 0.0419,
      "step": 4975
    },
    {
      "epoch": 1.1433823529411764,
      "grad_norm": 1.3364694118499756,
      "learning_rate": 8.571282679738563e-06,
      "loss": 0.0811,
      "step": 4976
    },
    {
      "epoch": 1.1436121323529411,
      "grad_norm": 0.8790987730026245,
      "learning_rate": 8.57077205882353e-06,
      "loss": 0.0598,
      "step": 4977
    },
    {
      "epoch": 1.1438419117647058,
      "grad_norm": 1.3076696395874023,
      "learning_rate": 8.570261437908497e-06,
      "loss": 0.0769,
      "step": 4978
    },
    {
      "epoch": 1.1440716911764706,
      "grad_norm": 0.7421815395355225,
      "learning_rate": 8.569750816993465e-06,
      "loss": 0.0639,
      "step": 4979
    },
    {
      "epoch": 1.1443014705882353,
      "grad_norm": 1.047407865524292,
      "learning_rate": 8.569240196078432e-06,
      "loss": 0.0751,
      "step": 4980
    },
    {
      "epoch": 1.14453125,
      "grad_norm": 0.8408602476119995,
      "learning_rate": 8.568729575163399e-06,
      "loss": 0.0652,
      "step": 4981
    },
    {
      "epoch": 1.1447610294117647,
      "grad_norm": 1.1692490577697754,
      "learning_rate": 8.568218954248366e-06,
      "loss": 0.0661,
      "step": 4982
    },
    {
      "epoch": 1.1449908088235294,
      "grad_norm": 1.1664624214172363,
      "learning_rate": 8.567708333333334e-06,
      "loss": 0.0695,
      "step": 4983
    },
    {
      "epoch": 1.1452205882352942,
      "grad_norm": 1.1699397563934326,
      "learning_rate": 8.567197712418302e-06,
      "loss": 0.0693,
      "step": 4984
    },
    {
      "epoch": 1.1454503676470589,
      "grad_norm": 1.09098219871521,
      "learning_rate": 8.566687091503268e-06,
      "loss": 0.0742,
      "step": 4985
    },
    {
      "epoch": 1.1456801470588236,
      "grad_norm": 1.266735553741455,
      "learning_rate": 8.566176470588236e-06,
      "loss": 0.065,
      "step": 4986
    },
    {
      "epoch": 1.1459099264705883,
      "grad_norm": 0.7551242709159851,
      "learning_rate": 8.565665849673204e-06,
      "loss": 0.0496,
      "step": 4987
    },
    {
      "epoch": 1.146139705882353,
      "grad_norm": 1.1509677171707153,
      "learning_rate": 8.56515522875817e-06,
      "loss": 0.0403,
      "step": 4988
    },
    {
      "epoch": 1.1463694852941178,
      "grad_norm": 1.96053147315979,
      "learning_rate": 8.564644607843138e-06,
      "loss": 0.0721,
      "step": 4989
    },
    {
      "epoch": 1.1465992647058822,
      "grad_norm": 0.9535947442054749,
      "learning_rate": 8.564133986928104e-06,
      "loss": 0.0663,
      "step": 4990
    },
    {
      "epoch": 1.146829044117647,
      "grad_norm": 0.6777032613754272,
      "learning_rate": 8.563623366013072e-06,
      "loss": 0.0433,
      "step": 4991
    },
    {
      "epoch": 1.1470588235294117,
      "grad_norm": 1.2401925325393677,
      "learning_rate": 8.56311274509804e-06,
      "loss": 0.0707,
      "step": 4992
    },
    {
      "epoch": 1.1472886029411764,
      "grad_norm": 0.9353168606758118,
      "learning_rate": 8.562602124183008e-06,
      "loss": 0.0558,
      "step": 4993
    },
    {
      "epoch": 1.1475183823529411,
      "grad_norm": 1.1490987539291382,
      "learning_rate": 8.562091503267974e-06,
      "loss": 0.0495,
      "step": 4994
    },
    {
      "epoch": 1.1477481617647058,
      "grad_norm": 0.9237252473831177,
      "learning_rate": 8.561580882352942e-06,
      "loss": 0.0354,
      "step": 4995
    },
    {
      "epoch": 1.1479779411764706,
      "grad_norm": 0.9172781705856323,
      "learning_rate": 8.56107026143791e-06,
      "loss": 0.0552,
      "step": 4996
    },
    {
      "epoch": 1.1482077205882353,
      "grad_norm": 1.4353395700454712,
      "learning_rate": 8.560559640522876e-06,
      "loss": 0.0679,
      "step": 4997
    },
    {
      "epoch": 1.1484375,
      "grad_norm": 1.4751296043395996,
      "learning_rate": 8.560049019607844e-06,
      "loss": 0.1037,
      "step": 4998
    },
    {
      "epoch": 1.1486672794117647,
      "grad_norm": 1.0256184339523315,
      "learning_rate": 8.559538398692812e-06,
      "loss": 0.0711,
      "step": 4999
    },
    {
      "epoch": 1.1488970588235294,
      "grad_norm": 1.6375665664672852,
      "learning_rate": 8.559027777777778e-06,
      "loss": 0.1062,
      "step": 5000
    },
    {
      "epoch": 1.1488970588235294,
      "eval_loss": 0.06338608264923096,
      "eval_runtime": 2006.6888,
      "eval_samples_per_second": 4.438,
      "eval_steps_per_second": 2.219,
      "step": 5000
    },
    {
      "epoch": 1.1491268382352942,
      "grad_norm": 0.877937912940979,
      "learning_rate": 8.558517156862746e-06,
      "loss": 0.0637,
      "step": 5001
    },
    {
      "epoch": 1.1493566176470589,
      "grad_norm": 1.606726884841919,
      "learning_rate": 8.558006535947712e-06,
      "loss": 0.0624,
      "step": 5002
    },
    {
      "epoch": 1.1495863970588236,
      "grad_norm": 1.144741415977478,
      "learning_rate": 8.557495915032681e-06,
      "loss": 0.057,
      "step": 5003
    },
    {
      "epoch": 1.1498161764705883,
      "grad_norm": 1.212692141532898,
      "learning_rate": 8.556985294117648e-06,
      "loss": 0.0722,
      "step": 5004
    },
    {
      "epoch": 1.150045955882353,
      "grad_norm": 1.2215049266815186,
      "learning_rate": 8.556474673202615e-06,
      "loss": 0.0778,
      "step": 5005
    },
    {
      "epoch": 1.1502757352941178,
      "grad_norm": 0.9542468786239624,
      "learning_rate": 8.555964052287582e-06,
      "loss": 0.0571,
      "step": 5006
    },
    {
      "epoch": 1.1505055147058822,
      "grad_norm": 0.978610634803772,
      "learning_rate": 8.55545343137255e-06,
      "loss": 0.0636,
      "step": 5007
    },
    {
      "epoch": 1.150735294117647,
      "grad_norm": 1.161508560180664,
      "learning_rate": 8.554942810457517e-06,
      "loss": 0.0591,
      "step": 5008
    },
    {
      "epoch": 1.1509650735294117,
      "grad_norm": 1.2647446393966675,
      "learning_rate": 8.554432189542483e-06,
      "loss": 0.0726,
      "step": 5009
    },
    {
      "epoch": 1.1511948529411764,
      "grad_norm": 0.9050741791725159,
      "learning_rate": 8.553921568627451e-06,
      "loss": 0.0507,
      "step": 5010
    },
    {
      "epoch": 1.1514246323529411,
      "grad_norm": 0.8760507106781006,
      "learning_rate": 8.55341094771242e-06,
      "loss": 0.0646,
      "step": 5011
    },
    {
      "epoch": 1.1516544117647058,
      "grad_norm": 0.9890621304512024,
      "learning_rate": 8.552900326797387e-06,
      "loss": 0.0593,
      "step": 5012
    },
    {
      "epoch": 1.1518841911764706,
      "grad_norm": 1.061265230178833,
      "learning_rate": 8.552389705882353e-06,
      "loss": 0.0461,
      "step": 5013
    },
    {
      "epoch": 1.1521139705882353,
      "grad_norm": 0.9348042607307434,
      "learning_rate": 8.551879084967321e-06,
      "loss": 0.0491,
      "step": 5014
    },
    {
      "epoch": 1.15234375,
      "grad_norm": 1.0311304330825806,
      "learning_rate": 8.551368464052289e-06,
      "loss": 0.052,
      "step": 5015
    },
    {
      "epoch": 1.1525735294117647,
      "grad_norm": 1.0323150157928467,
      "learning_rate": 8.550857843137255e-06,
      "loss": 0.0698,
      "step": 5016
    },
    {
      "epoch": 1.1528033088235294,
      "grad_norm": 0.9829591512680054,
      "learning_rate": 8.550347222222223e-06,
      "loss": 0.0735,
      "step": 5017
    },
    {
      "epoch": 1.1530330882352942,
      "grad_norm": 1.126142978668213,
      "learning_rate": 8.54983660130719e-06,
      "loss": 0.0486,
      "step": 5018
    },
    {
      "epoch": 1.1532628676470589,
      "grad_norm": 0.9955031275749207,
      "learning_rate": 8.549325980392159e-06,
      "loss": 0.0568,
      "step": 5019
    },
    {
      "epoch": 1.1534926470588236,
      "grad_norm": 0.9872186779975891,
      "learning_rate": 8.548815359477125e-06,
      "loss": 0.0644,
      "step": 5020
    },
    {
      "epoch": 1.1537224264705883,
      "grad_norm": 0.9308347702026367,
      "learning_rate": 8.548304738562093e-06,
      "loss": 0.0485,
      "step": 5021
    },
    {
      "epoch": 1.153952205882353,
      "grad_norm": 1.0036643743515015,
      "learning_rate": 8.547794117647059e-06,
      "loss": 0.0515,
      "step": 5022
    },
    {
      "epoch": 1.1541819852941178,
      "grad_norm": 0.8277802467346191,
      "learning_rate": 8.547283496732027e-06,
      "loss": 0.0513,
      "step": 5023
    },
    {
      "epoch": 1.1544117647058822,
      "grad_norm": 1.3022886514663696,
      "learning_rate": 8.546772875816995e-06,
      "loss": 0.0834,
      "step": 5024
    },
    {
      "epoch": 1.154641544117647,
      "grad_norm": 1.0686389207839966,
      "learning_rate": 8.54626225490196e-06,
      "loss": 0.0885,
      "step": 5025
    },
    {
      "epoch": 1.1548713235294117,
      "grad_norm": 0.7775384187698364,
      "learning_rate": 8.545751633986929e-06,
      "loss": 0.0435,
      "step": 5026
    },
    {
      "epoch": 1.1551011029411764,
      "grad_norm": 0.9482333660125732,
      "learning_rate": 8.545241013071897e-06,
      "loss": 0.0486,
      "step": 5027
    },
    {
      "epoch": 1.1553308823529411,
      "grad_norm": 1.0110368728637695,
      "learning_rate": 8.544730392156864e-06,
      "loss": 0.0674,
      "step": 5028
    },
    {
      "epoch": 1.1555606617647058,
      "grad_norm": 0.7091769576072693,
      "learning_rate": 8.54421977124183e-06,
      "loss": 0.0344,
      "step": 5029
    },
    {
      "epoch": 1.1557904411764706,
      "grad_norm": 1.1567683219909668,
      "learning_rate": 8.543709150326798e-06,
      "loss": 0.0626,
      "step": 5030
    },
    {
      "epoch": 1.1560202205882353,
      "grad_norm": 0.8628100156784058,
      "learning_rate": 8.543198529411766e-06,
      "loss": 0.0504,
      "step": 5031
    },
    {
      "epoch": 1.15625,
      "grad_norm": 0.8190057277679443,
      "learning_rate": 8.542687908496732e-06,
      "loss": 0.0333,
      "step": 5032
    },
    {
      "epoch": 1.1564797794117647,
      "grad_norm": 0.9229405522346497,
      "learning_rate": 8.5421772875817e-06,
      "loss": 0.0628,
      "step": 5033
    },
    {
      "epoch": 1.1567095588235294,
      "grad_norm": 1.2852492332458496,
      "learning_rate": 8.541666666666666e-06,
      "loss": 0.0393,
      "step": 5034
    },
    {
      "epoch": 1.1569393382352942,
      "grad_norm": 0.9749025702476501,
      "learning_rate": 8.541156045751634e-06,
      "loss": 0.0558,
      "step": 5035
    },
    {
      "epoch": 1.1571691176470589,
      "grad_norm": 0.931024432182312,
      "learning_rate": 8.540645424836602e-06,
      "loss": 0.0594,
      "step": 5036
    },
    {
      "epoch": 1.1573988970588236,
      "grad_norm": 0.9211572408676147,
      "learning_rate": 8.54013480392157e-06,
      "loss": 0.0476,
      "step": 5037
    },
    {
      "epoch": 1.1576286764705883,
      "grad_norm": 0.804316520690918,
      "learning_rate": 8.539624183006536e-06,
      "loss": 0.0448,
      "step": 5038
    },
    {
      "epoch": 1.157858455882353,
      "grad_norm": 0.9782978892326355,
      "learning_rate": 8.539113562091504e-06,
      "loss": 0.0574,
      "step": 5039
    },
    {
      "epoch": 1.1580882352941178,
      "grad_norm": 0.8135233521461487,
      "learning_rate": 8.538602941176472e-06,
      "loss": 0.0685,
      "step": 5040
    },
    {
      "epoch": 1.1583180147058822,
      "grad_norm": 1.0732663869857788,
      "learning_rate": 8.538092320261438e-06,
      "loss": 0.0731,
      "step": 5041
    },
    {
      "epoch": 1.158547794117647,
      "grad_norm": 1.1792041063308716,
      "learning_rate": 8.537581699346406e-06,
      "loss": 0.0703,
      "step": 5042
    },
    {
      "epoch": 1.1587775735294117,
      "grad_norm": 1.0383528470993042,
      "learning_rate": 8.537071078431374e-06,
      "loss": 0.0663,
      "step": 5043
    },
    {
      "epoch": 1.1590073529411764,
      "grad_norm": 0.9127098321914673,
      "learning_rate": 8.53656045751634e-06,
      "loss": 0.0549,
      "step": 5044
    },
    {
      "epoch": 1.1592371323529411,
      "grad_norm": 0.924834668636322,
      "learning_rate": 8.536049836601308e-06,
      "loss": 0.0456,
      "step": 5045
    },
    {
      "epoch": 1.1594669117647058,
      "grad_norm": 0.691079318523407,
      "learning_rate": 8.535539215686274e-06,
      "loss": 0.0423,
      "step": 5046
    },
    {
      "epoch": 1.1596966911764706,
      "grad_norm": 1.1045634746551514,
      "learning_rate": 8.535028594771244e-06,
      "loss": 0.0601,
      "step": 5047
    },
    {
      "epoch": 1.1599264705882353,
      "grad_norm": 1.1412709951400757,
      "learning_rate": 8.53451797385621e-06,
      "loss": 0.0782,
      "step": 5048
    },
    {
      "epoch": 1.16015625,
      "grad_norm": 0.9764377474784851,
      "learning_rate": 8.534007352941178e-06,
      "loss": 0.0839,
      "step": 5049
    },
    {
      "epoch": 1.1603860294117647,
      "grad_norm": 1.1142301559448242,
      "learning_rate": 8.533496732026144e-06,
      "loss": 0.0695,
      "step": 5050
    },
    {
      "epoch": 1.1606158088235294,
      "grad_norm": 0.9778106808662415,
      "learning_rate": 8.532986111111112e-06,
      "loss": 0.0559,
      "step": 5051
    },
    {
      "epoch": 1.1608455882352942,
      "grad_norm": 1.0111019611358643,
      "learning_rate": 8.53247549019608e-06,
      "loss": 0.0712,
      "step": 5052
    },
    {
      "epoch": 1.1610753676470589,
      "grad_norm": 0.8146319389343262,
      "learning_rate": 8.531964869281046e-06,
      "loss": 0.0448,
      "step": 5053
    },
    {
      "epoch": 1.1613051470588236,
      "grad_norm": 0.9437790513038635,
      "learning_rate": 8.531454248366014e-06,
      "loss": 0.0479,
      "step": 5054
    },
    {
      "epoch": 1.1615349264705883,
      "grad_norm": 1.3341871500015259,
      "learning_rate": 8.530943627450981e-06,
      "loss": 0.0689,
      "step": 5055
    },
    {
      "epoch": 1.161764705882353,
      "grad_norm": 1.2683446407318115,
      "learning_rate": 8.53043300653595e-06,
      "loss": 0.069,
      "step": 5056
    },
    {
      "epoch": 1.1619944852941178,
      "grad_norm": 0.9059492349624634,
      "learning_rate": 8.529922385620915e-06,
      "loss": 0.0492,
      "step": 5057
    },
    {
      "epoch": 1.1622242647058822,
      "grad_norm": 0.7990309596061707,
      "learning_rate": 8.529411764705883e-06,
      "loss": 0.0411,
      "step": 5058
    },
    {
      "epoch": 1.162454044117647,
      "grad_norm": 0.9452782273292542,
      "learning_rate": 8.528901143790851e-06,
      "loss": 0.0548,
      "step": 5059
    },
    {
      "epoch": 1.1626838235294117,
      "grad_norm": 1.1048719882965088,
      "learning_rate": 8.528390522875817e-06,
      "loss": 0.0624,
      "step": 5060
    },
    {
      "epoch": 1.1629136029411764,
      "grad_norm": 0.9340973496437073,
      "learning_rate": 8.527879901960785e-06,
      "loss": 0.073,
      "step": 5061
    },
    {
      "epoch": 1.1631433823529411,
      "grad_norm": 1.1264851093292236,
      "learning_rate": 8.527369281045751e-06,
      "loss": 0.0499,
      "step": 5062
    },
    {
      "epoch": 1.1633731617647058,
      "grad_norm": 1.5409331321716309,
      "learning_rate": 8.526858660130721e-06,
      "loss": 0.1236,
      "step": 5063
    },
    {
      "epoch": 1.1636029411764706,
      "grad_norm": 0.9043956995010376,
      "learning_rate": 8.526348039215687e-06,
      "loss": 0.0513,
      "step": 5064
    },
    {
      "epoch": 1.1638327205882353,
      "grad_norm": 0.7597026824951172,
      "learning_rate": 8.525837418300655e-06,
      "loss": 0.0279,
      "step": 5065
    },
    {
      "epoch": 1.1640625,
      "grad_norm": 0.9600053429603577,
      "learning_rate": 8.525326797385621e-06,
      "loss": 0.0469,
      "step": 5066
    },
    {
      "epoch": 1.1642922794117647,
      "grad_norm": 1.029209017753601,
      "learning_rate": 8.524816176470589e-06,
      "loss": 0.0512,
      "step": 5067
    },
    {
      "epoch": 1.1645220588235294,
      "grad_norm": 1.07747483253479,
      "learning_rate": 8.524305555555557e-06,
      "loss": 0.0623,
      "step": 5068
    },
    {
      "epoch": 1.1647518382352942,
      "grad_norm": 1.1535167694091797,
      "learning_rate": 8.523794934640523e-06,
      "loss": 0.0756,
      "step": 5069
    },
    {
      "epoch": 1.1649816176470589,
      "grad_norm": 1.3188332319259644,
      "learning_rate": 8.523284313725491e-06,
      "loss": 0.0629,
      "step": 5070
    },
    {
      "epoch": 1.1652113970588236,
      "grad_norm": 0.8154305219650269,
      "learning_rate": 8.522773692810459e-06,
      "loss": 0.0502,
      "step": 5071
    },
    {
      "epoch": 1.1654411764705883,
      "grad_norm": 0.8435623645782471,
      "learning_rate": 8.522263071895427e-06,
      "loss": 0.0454,
      "step": 5072
    },
    {
      "epoch": 1.165670955882353,
      "grad_norm": 1.377498984336853,
      "learning_rate": 8.521752450980393e-06,
      "loss": 0.069,
      "step": 5073
    },
    {
      "epoch": 1.1659007352941178,
      "grad_norm": 0.8436265587806702,
      "learning_rate": 8.52124183006536e-06,
      "loss": 0.0389,
      "step": 5074
    },
    {
      "epoch": 1.1661305147058822,
      "grad_norm": 0.8311052918434143,
      "learning_rate": 8.520731209150328e-06,
      "loss": 0.0434,
      "step": 5075
    },
    {
      "epoch": 1.166360294117647,
      "grad_norm": 0.7212398648262024,
      "learning_rate": 8.520220588235295e-06,
      "loss": 0.048,
      "step": 5076
    },
    {
      "epoch": 1.1665900735294117,
      "grad_norm": 1.4689552783966064,
      "learning_rate": 8.519709967320263e-06,
      "loss": 0.0967,
      "step": 5077
    },
    {
      "epoch": 1.1668198529411764,
      "grad_norm": 1.0385100841522217,
      "learning_rate": 8.519199346405229e-06,
      "loss": 0.0718,
      "step": 5078
    },
    {
      "epoch": 1.1670496323529411,
      "grad_norm": 1.2442688941955566,
      "learning_rate": 8.518688725490197e-06,
      "loss": 0.0639,
      "step": 5079
    },
    {
      "epoch": 1.1672794117647058,
      "grad_norm": 1.2307099103927612,
      "learning_rate": 8.518178104575164e-06,
      "loss": 0.0812,
      "step": 5080
    },
    {
      "epoch": 1.1675091911764706,
      "grad_norm": 1.9799124002456665,
      "learning_rate": 8.517667483660132e-06,
      "loss": 0.0768,
      "step": 5081
    },
    {
      "epoch": 1.1677389705882353,
      "grad_norm": 1.1685165166854858,
      "learning_rate": 8.517156862745098e-06,
      "loss": 0.0642,
      "step": 5082
    },
    {
      "epoch": 1.16796875,
      "grad_norm": 1.2273458242416382,
      "learning_rate": 8.516646241830066e-06,
      "loss": 0.0593,
      "step": 5083
    },
    {
      "epoch": 1.1681985294117647,
      "grad_norm": 1.086271047592163,
      "learning_rate": 8.516135620915034e-06,
      "loss": 0.0485,
      "step": 5084
    },
    {
      "epoch": 1.1684283088235294,
      "grad_norm": 1.0166473388671875,
      "learning_rate": 8.515625e-06,
      "loss": 0.0596,
      "step": 5085
    },
    {
      "epoch": 1.1686580882352942,
      "grad_norm": 0.7357574701309204,
      "learning_rate": 8.515114379084968e-06,
      "loss": 0.0455,
      "step": 5086
    },
    {
      "epoch": 1.1688878676470589,
      "grad_norm": 1.0551553964614868,
      "learning_rate": 8.514603758169934e-06,
      "loss": 0.0758,
      "step": 5087
    },
    {
      "epoch": 1.1691176470588236,
      "grad_norm": 1.0310910940170288,
      "learning_rate": 8.514093137254902e-06,
      "loss": 0.0731,
      "step": 5088
    },
    {
      "epoch": 1.1693474264705883,
      "grad_norm": 0.851474404335022,
      "learning_rate": 8.51358251633987e-06,
      "loss": 0.0657,
      "step": 5089
    },
    {
      "epoch": 1.169577205882353,
      "grad_norm": 0.9187263250350952,
      "learning_rate": 8.513071895424836e-06,
      "loss": 0.043,
      "step": 5090
    },
    {
      "epoch": 1.1698069852941178,
      "grad_norm": 1.5281200408935547,
      "learning_rate": 8.512561274509804e-06,
      "loss": 0.0783,
      "step": 5091
    },
    {
      "epoch": 1.1700367647058822,
      "grad_norm": 0.7239115238189697,
      "learning_rate": 8.512050653594772e-06,
      "loss": 0.0463,
      "step": 5092
    },
    {
      "epoch": 1.170266544117647,
      "grad_norm": 0.9467185735702515,
      "learning_rate": 8.51154003267974e-06,
      "loss": 0.0594,
      "step": 5093
    },
    {
      "epoch": 1.1704963235294117,
      "grad_norm": 1.0952244997024536,
      "learning_rate": 8.511029411764706e-06,
      "loss": 0.0635,
      "step": 5094
    },
    {
      "epoch": 1.1707261029411764,
      "grad_norm": 0.7596694231033325,
      "learning_rate": 8.510518790849674e-06,
      "loss": 0.0565,
      "step": 5095
    },
    {
      "epoch": 1.1709558823529411,
      "grad_norm": 1.7071036100387573,
      "learning_rate": 8.510008169934642e-06,
      "loss": 0.0589,
      "step": 5096
    },
    {
      "epoch": 1.1711856617647058,
      "grad_norm": 1.1832019090652466,
      "learning_rate": 8.509497549019608e-06,
      "loss": 0.0562,
      "step": 5097
    },
    {
      "epoch": 1.1714154411764706,
      "grad_norm": 1.0278711318969727,
      "learning_rate": 8.508986928104576e-06,
      "loss": 0.0501,
      "step": 5098
    },
    {
      "epoch": 1.1716452205882353,
      "grad_norm": 1.0082077980041504,
      "learning_rate": 8.508476307189542e-06,
      "loss": 0.0518,
      "step": 5099
    },
    {
      "epoch": 1.171875,
      "grad_norm": 1.6153031587600708,
      "learning_rate": 8.507965686274511e-06,
      "loss": 0.0893,
      "step": 5100
    },
    {
      "epoch": 1.1721047794117647,
      "grad_norm": 0.9262973070144653,
      "learning_rate": 8.507455065359478e-06,
      "loss": 0.0602,
      "step": 5101
    },
    {
      "epoch": 1.1723345588235294,
      "grad_norm": 0.9663214087486267,
      "learning_rate": 8.506944444444445e-06,
      "loss": 0.0679,
      "step": 5102
    },
    {
      "epoch": 1.1725643382352942,
      "grad_norm": 0.7869559526443481,
      "learning_rate": 8.506433823529412e-06,
      "loss": 0.0466,
      "step": 5103
    },
    {
      "epoch": 1.1727941176470589,
      "grad_norm": 1.336883306503296,
      "learning_rate": 8.50592320261438e-06,
      "loss": 0.0473,
      "step": 5104
    },
    {
      "epoch": 1.1730238970588236,
      "grad_norm": 0.9633088111877441,
      "learning_rate": 8.505412581699347e-06,
      "loss": 0.079,
      "step": 5105
    },
    {
      "epoch": 1.1732536764705883,
      "grad_norm": 0.7404106259346008,
      "learning_rate": 8.504901960784314e-06,
      "loss": 0.0403,
      "step": 5106
    },
    {
      "epoch": 1.173483455882353,
      "grad_norm": 1.032415509223938,
      "learning_rate": 8.504391339869281e-06,
      "loss": 0.0561,
      "step": 5107
    },
    {
      "epoch": 1.1737132352941178,
      "grad_norm": 1.5668929815292358,
      "learning_rate": 8.50388071895425e-06,
      "loss": 0.0853,
      "step": 5108
    },
    {
      "epoch": 1.1739430147058822,
      "grad_norm": 0.8558730483055115,
      "learning_rate": 8.503370098039217e-06,
      "loss": 0.0618,
      "step": 5109
    },
    {
      "epoch": 1.174172794117647,
      "grad_norm": 1.1816246509552002,
      "learning_rate": 8.502859477124183e-06,
      "loss": 0.0775,
      "step": 5110
    },
    {
      "epoch": 1.1744025735294117,
      "grad_norm": 0.7952532172203064,
      "learning_rate": 8.502348856209151e-06,
      "loss": 0.0388,
      "step": 5111
    },
    {
      "epoch": 1.1746323529411764,
      "grad_norm": 1.147051215171814,
      "learning_rate": 8.501838235294119e-06,
      "loss": 0.0665,
      "step": 5112
    },
    {
      "epoch": 1.1748621323529411,
      "grad_norm": 0.8658219575881958,
      "learning_rate": 8.501327614379085e-06,
      "loss": 0.0599,
      "step": 5113
    },
    {
      "epoch": 1.1750919117647058,
      "grad_norm": 0.9305670261383057,
      "learning_rate": 8.500816993464053e-06,
      "loss": 0.0582,
      "step": 5114
    },
    {
      "epoch": 1.1753216911764706,
      "grad_norm": 1.4568055868148804,
      "learning_rate": 8.50030637254902e-06,
      "loss": 0.0904,
      "step": 5115
    },
    {
      "epoch": 1.1755514705882353,
      "grad_norm": 1.5196259021759033,
      "learning_rate": 8.499795751633989e-06,
      "loss": 0.0484,
      "step": 5116
    },
    {
      "epoch": 1.17578125,
      "grad_norm": 0.8999620676040649,
      "learning_rate": 8.499285130718955e-06,
      "loss": 0.062,
      "step": 5117
    },
    {
      "epoch": 1.1760110294117647,
      "grad_norm": 1.5927666425704956,
      "learning_rate": 8.498774509803923e-06,
      "loss": 0.0802,
      "step": 5118
    },
    {
      "epoch": 1.1762408088235294,
      "grad_norm": 0.8582002520561218,
      "learning_rate": 8.498263888888889e-06,
      "loss": 0.0463,
      "step": 5119
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.8877240419387817,
      "learning_rate": 8.497753267973857e-06,
      "loss": 0.0441,
      "step": 5120
    },
    {
      "epoch": 1.1767003676470589,
      "grad_norm": 1.0463109016418457,
      "learning_rate": 8.497242647058825e-06,
      "loss": 0.0637,
      "step": 5121
    },
    {
      "epoch": 1.1769301470588236,
      "grad_norm": 1.6770637035369873,
      "learning_rate": 8.496732026143791e-06,
      "loss": 0.0739,
      "step": 5122
    },
    {
      "epoch": 1.1771599264705883,
      "grad_norm": 0.954988420009613,
      "learning_rate": 8.496221405228759e-06,
      "loss": 0.0544,
      "step": 5123
    },
    {
      "epoch": 1.177389705882353,
      "grad_norm": 0.9553117752075195,
      "learning_rate": 8.495710784313727e-06,
      "loss": 0.0633,
      "step": 5124
    },
    {
      "epoch": 1.1776194852941178,
      "grad_norm": 1.1954543590545654,
      "learning_rate": 8.495200163398693e-06,
      "loss": 0.0519,
      "step": 5125
    },
    {
      "epoch": 1.1778492647058822,
      "grad_norm": 2.1665117740631104,
      "learning_rate": 8.49468954248366e-06,
      "loss": 0.0733,
      "step": 5126
    },
    {
      "epoch": 1.178079044117647,
      "grad_norm": 0.8956093192100525,
      "learning_rate": 8.494178921568628e-06,
      "loss": 0.0526,
      "step": 5127
    },
    {
      "epoch": 1.1783088235294117,
      "grad_norm": 1.1379241943359375,
      "learning_rate": 8.493668300653596e-06,
      "loss": 0.0695,
      "step": 5128
    },
    {
      "epoch": 1.1785386029411764,
      "grad_norm": 1.4301942586898804,
      "learning_rate": 8.493157679738563e-06,
      "loss": 0.0749,
      "step": 5129
    },
    {
      "epoch": 1.1787683823529411,
      "grad_norm": 1.0023910999298096,
      "learning_rate": 8.49264705882353e-06,
      "loss": 0.0681,
      "step": 5130
    },
    {
      "epoch": 1.1789981617647058,
      "grad_norm": 0.8060925006866455,
      "learning_rate": 8.492136437908497e-06,
      "loss": 0.0637,
      "step": 5131
    },
    {
      "epoch": 1.1792279411764706,
      "grad_norm": 0.7185637354850769,
      "learning_rate": 8.491625816993464e-06,
      "loss": 0.0417,
      "step": 5132
    },
    {
      "epoch": 1.1794577205882353,
      "grad_norm": 1.1887562274932861,
      "learning_rate": 8.491115196078432e-06,
      "loss": 0.0804,
      "step": 5133
    },
    {
      "epoch": 1.1796875,
      "grad_norm": 1.0141857862472534,
      "learning_rate": 8.490604575163398e-06,
      "loss": 0.0527,
      "step": 5134
    },
    {
      "epoch": 1.1799172794117647,
      "grad_norm": 0.7553052306175232,
      "learning_rate": 8.490093954248366e-06,
      "loss": 0.0475,
      "step": 5135
    },
    {
      "epoch": 1.1801470588235294,
      "grad_norm": 0.9863646030426025,
      "learning_rate": 8.489583333333334e-06,
      "loss": 0.0649,
      "step": 5136
    },
    {
      "epoch": 1.1803768382352942,
      "grad_norm": 0.9354613423347473,
      "learning_rate": 8.489072712418302e-06,
      "loss": 0.0495,
      "step": 5137
    },
    {
      "epoch": 1.1806066176470589,
      "grad_norm": 1.1437379121780396,
      "learning_rate": 8.488562091503268e-06,
      "loss": 0.072,
      "step": 5138
    },
    {
      "epoch": 1.1808363970588236,
      "grad_norm": 0.9261099100112915,
      "learning_rate": 8.488051470588236e-06,
      "loss": 0.0359,
      "step": 5139
    },
    {
      "epoch": 1.1810661764705883,
      "grad_norm": 0.7700420618057251,
      "learning_rate": 8.487540849673204e-06,
      "loss": 0.0495,
      "step": 5140
    },
    {
      "epoch": 1.181295955882353,
      "grad_norm": 1.0399116277694702,
      "learning_rate": 8.48703022875817e-06,
      "loss": 0.0406,
      "step": 5141
    },
    {
      "epoch": 1.1815257352941178,
      "grad_norm": 0.8890382647514343,
      "learning_rate": 8.486519607843138e-06,
      "loss": 0.0501,
      "step": 5142
    },
    {
      "epoch": 1.1817555147058822,
      "grad_norm": 1.0289283990859985,
      "learning_rate": 8.486008986928104e-06,
      "loss": 0.0575,
      "step": 5143
    },
    {
      "epoch": 1.181985294117647,
      "grad_norm": 1.1100322008132935,
      "learning_rate": 8.485498366013074e-06,
      "loss": 0.0641,
      "step": 5144
    },
    {
      "epoch": 1.1822150735294117,
      "grad_norm": 1.0211800336837769,
      "learning_rate": 8.48498774509804e-06,
      "loss": 0.0462,
      "step": 5145
    },
    {
      "epoch": 1.1824448529411764,
      "grad_norm": 0.9127854108810425,
      "learning_rate": 8.484477124183008e-06,
      "loss": 0.0485,
      "step": 5146
    },
    {
      "epoch": 1.1826746323529411,
      "grad_norm": 1.104123830795288,
      "learning_rate": 8.483966503267974e-06,
      "loss": 0.082,
      "step": 5147
    },
    {
      "epoch": 1.1829044117647058,
      "grad_norm": 0.848395586013794,
      "learning_rate": 8.483455882352942e-06,
      "loss": 0.0501,
      "step": 5148
    },
    {
      "epoch": 1.1831341911764706,
      "grad_norm": 1.0372872352600098,
      "learning_rate": 8.48294526143791e-06,
      "loss": 0.0643,
      "step": 5149
    },
    {
      "epoch": 1.1833639705882353,
      "grad_norm": 0.9883529543876648,
      "learning_rate": 8.482434640522876e-06,
      "loss": 0.0572,
      "step": 5150
    },
    {
      "epoch": 1.18359375,
      "grad_norm": 1.090494155883789,
      "learning_rate": 8.481924019607844e-06,
      "loss": 0.0502,
      "step": 5151
    },
    {
      "epoch": 1.1838235294117647,
      "grad_norm": 1.466166377067566,
      "learning_rate": 8.481413398692811e-06,
      "loss": 0.0847,
      "step": 5152
    },
    {
      "epoch": 1.1840533088235294,
      "grad_norm": 1.0480448007583618,
      "learning_rate": 8.48090277777778e-06,
      "loss": 0.0593,
      "step": 5153
    },
    {
      "epoch": 1.1842830882352942,
      "grad_norm": 1.0791990756988525,
      "learning_rate": 8.480392156862745e-06,
      "loss": 0.0757,
      "step": 5154
    },
    {
      "epoch": 1.1845128676470589,
      "grad_norm": 0.9801294803619385,
      "learning_rate": 8.479881535947713e-06,
      "loss": 0.0502,
      "step": 5155
    },
    {
      "epoch": 1.1847426470588236,
      "grad_norm": 0.7198939919471741,
      "learning_rate": 8.479370915032681e-06,
      "loss": 0.0359,
      "step": 5156
    },
    {
      "epoch": 1.1849724264705883,
      "grad_norm": 0.8276723027229309,
      "learning_rate": 8.478860294117647e-06,
      "loss": 0.0553,
      "step": 5157
    },
    {
      "epoch": 1.185202205882353,
      "grad_norm": 1.0370997190475464,
      "learning_rate": 8.478349673202615e-06,
      "loss": 0.0641,
      "step": 5158
    },
    {
      "epoch": 1.1854319852941178,
      "grad_norm": 1.3864390850067139,
      "learning_rate": 8.477839052287581e-06,
      "loss": 0.0752,
      "step": 5159
    },
    {
      "epoch": 1.1856617647058822,
      "grad_norm": 1.6315561532974243,
      "learning_rate": 8.477328431372551e-06,
      "loss": 0.07,
      "step": 5160
    },
    {
      "epoch": 1.185891544117647,
      "grad_norm": 1.057797908782959,
      "learning_rate": 8.476817810457517e-06,
      "loss": 0.073,
      "step": 5161
    },
    {
      "epoch": 1.1861213235294117,
      "grad_norm": 1.0006259679794312,
      "learning_rate": 8.476307189542485e-06,
      "loss": 0.0432,
      "step": 5162
    },
    {
      "epoch": 1.1863511029411764,
      "grad_norm": 0.8296810984611511,
      "learning_rate": 8.475796568627451e-06,
      "loss": 0.0716,
      "step": 5163
    },
    {
      "epoch": 1.1865808823529411,
      "grad_norm": 1.285049557685852,
      "learning_rate": 8.475285947712419e-06,
      "loss": 0.0816,
      "step": 5164
    },
    {
      "epoch": 1.1868106617647058,
      "grad_norm": 0.9240694642066956,
      "learning_rate": 8.474775326797387e-06,
      "loss": 0.0551,
      "step": 5165
    },
    {
      "epoch": 1.1870404411764706,
      "grad_norm": 0.971973180770874,
      "learning_rate": 8.474264705882353e-06,
      "loss": 0.0646,
      "step": 5166
    },
    {
      "epoch": 1.1872702205882353,
      "grad_norm": 1.2655341625213623,
      "learning_rate": 8.473754084967321e-06,
      "loss": 0.0689,
      "step": 5167
    },
    {
      "epoch": 1.1875,
      "grad_norm": 1.3050786256790161,
      "learning_rate": 8.473243464052289e-06,
      "loss": 0.0571,
      "step": 5168
    },
    {
      "epoch": 1.1877297794117647,
      "grad_norm": 0.8583606481552124,
      "learning_rate": 8.472732843137255e-06,
      "loss": 0.0566,
      "step": 5169
    },
    {
      "epoch": 1.1879595588235294,
      "grad_norm": 0.9194011688232422,
      "learning_rate": 8.472222222222223e-06,
      "loss": 0.0652,
      "step": 5170
    },
    {
      "epoch": 1.1881893382352942,
      "grad_norm": 0.9557226300239563,
      "learning_rate": 8.47171160130719e-06,
      "loss": 0.0527,
      "step": 5171
    },
    {
      "epoch": 1.1884191176470589,
      "grad_norm": 0.8688868284225464,
      "learning_rate": 8.471200980392159e-06,
      "loss": 0.0552,
      "step": 5172
    },
    {
      "epoch": 1.1886488970588236,
      "grad_norm": 1.4911266565322876,
      "learning_rate": 8.470690359477125e-06,
      "loss": 0.068,
      "step": 5173
    },
    {
      "epoch": 1.1888786764705883,
      "grad_norm": 1.2958481311798096,
      "learning_rate": 8.470179738562093e-06,
      "loss": 0.0796,
      "step": 5174
    },
    {
      "epoch": 1.189108455882353,
      "grad_norm": 1.1604682207107544,
      "learning_rate": 8.469669117647059e-06,
      "loss": 0.0731,
      "step": 5175
    },
    {
      "epoch": 1.1893382352941178,
      "grad_norm": 0.8834221959114075,
      "learning_rate": 8.469158496732027e-06,
      "loss": 0.0534,
      "step": 5176
    },
    {
      "epoch": 1.1895680147058822,
      "grad_norm": 0.9098804593086243,
      "learning_rate": 8.468647875816994e-06,
      "loss": 0.0636,
      "step": 5177
    },
    {
      "epoch": 1.189797794117647,
      "grad_norm": 0.722793459892273,
      "learning_rate": 8.46813725490196e-06,
      "loss": 0.0442,
      "step": 5178
    },
    {
      "epoch": 1.1900275735294117,
      "grad_norm": 0.9608518481254578,
      "learning_rate": 8.467626633986928e-06,
      "loss": 0.0544,
      "step": 5179
    },
    {
      "epoch": 1.1902573529411764,
      "grad_norm": 0.6784331202507019,
      "learning_rate": 8.467116013071896e-06,
      "loss": 0.0377,
      "step": 5180
    },
    {
      "epoch": 1.1904871323529411,
      "grad_norm": 1.4640823602676392,
      "learning_rate": 8.466605392156864e-06,
      "loss": 0.0749,
      "step": 5181
    },
    {
      "epoch": 1.1907169117647058,
      "grad_norm": 1.0735993385314941,
      "learning_rate": 8.46609477124183e-06,
      "loss": 0.0781,
      "step": 5182
    },
    {
      "epoch": 1.1909466911764706,
      "grad_norm": 0.7832093834877014,
      "learning_rate": 8.465584150326798e-06,
      "loss": 0.0403,
      "step": 5183
    },
    {
      "epoch": 1.1911764705882353,
      "grad_norm": Infinity,
      "learning_rate": 8.465073529411766e-06,
      "loss": 0.0637,
      "step": 5184
    },
    {
      "epoch": 1.19140625,
      "grad_norm": 1.515289306640625,
      "learning_rate": 8.465073529411766e-06,
      "loss": 0.071,
      "step": 5185
    },
    {
      "epoch": 1.1916360294117647,
      "grad_norm": 1.1482902765274048,
      "learning_rate": 8.464562908496732e-06,
      "loss": 0.0528,
      "step": 5186
    },
    {
      "epoch": 1.1918658088235294,
      "grad_norm": 1.689730167388916,
      "learning_rate": 8.4640522875817e-06,
      "loss": 0.0603,
      "step": 5187
    },
    {
      "epoch": 1.1920955882352942,
      "grad_norm": 0.9381256103515625,
      "learning_rate": 8.463541666666666e-06,
      "loss": 0.0382,
      "step": 5188
    },
    {
      "epoch": 1.1923253676470589,
      "grad_norm": 0.9560023546218872,
      "learning_rate": 8.463031045751636e-06,
      "loss": 0.0529,
      "step": 5189
    },
    {
      "epoch": 1.1925551470588236,
      "grad_norm": 0.8340260982513428,
      "learning_rate": 8.462520424836602e-06,
      "loss": 0.0471,
      "step": 5190
    },
    {
      "epoch": 1.1927849264705883,
      "grad_norm": 1.0421726703643799,
      "learning_rate": 8.46200980392157e-06,
      "loss": 0.0614,
      "step": 5191
    },
    {
      "epoch": 1.193014705882353,
      "grad_norm": 0.9725045561790466,
      "learning_rate": 8.461499183006536e-06,
      "loss": 0.0626,
      "step": 5192
    },
    {
      "epoch": 1.1932444852941178,
      "grad_norm": 0.6960797905921936,
      "learning_rate": 8.460988562091504e-06,
      "loss": 0.048,
      "step": 5193
    },
    {
      "epoch": 1.1934742647058822,
      "grad_norm": 1.41270112991333,
      "learning_rate": 8.460477941176472e-06,
      "loss": 0.0651,
      "step": 5194
    },
    {
      "epoch": 1.193704044117647,
      "grad_norm": 0.8522070646286011,
      "learning_rate": 8.459967320261438e-06,
      "loss": 0.0555,
      "step": 5195
    },
    {
      "epoch": 1.1939338235294117,
      "grad_norm": 0.9725097417831421,
      "learning_rate": 8.459456699346406e-06,
      "loss": 0.0559,
      "step": 5196
    },
    {
      "epoch": 1.1941636029411764,
      "grad_norm": 1.272218942642212,
      "learning_rate": 8.458946078431374e-06,
      "loss": 0.0512,
      "step": 5197
    },
    {
      "epoch": 1.1943933823529411,
      "grad_norm": 1.2878491878509521,
      "learning_rate": 8.458435457516342e-06,
      "loss": 0.0725,
      "step": 5198
    },
    {
      "epoch": 1.1946231617647058,
      "grad_norm": 0.897486686706543,
      "learning_rate": 8.457924836601308e-06,
      "loss": 0.0432,
      "step": 5199
    },
    {
      "epoch": 1.1948529411764706,
      "grad_norm": 1.5066958665847778,
      "learning_rate": 8.457414215686276e-06,
      "loss": 0.0916,
      "step": 5200
    },
    {
      "epoch": 1.1950827205882353,
      "grad_norm": 0.9152999520301819,
      "learning_rate": 8.456903594771243e-06,
      "loss": 0.0634,
      "step": 5201
    },
    {
      "epoch": 1.1953125,
      "grad_norm": 1.0183219909667969,
      "learning_rate": 8.45639297385621e-06,
      "loss": 0.0671,
      "step": 5202
    },
    {
      "epoch": 1.1955422794117647,
      "grad_norm": 0.949550449848175,
      "learning_rate": 8.455882352941177e-06,
      "loss": 0.0582,
      "step": 5203
    },
    {
      "epoch": 1.1957720588235294,
      "grad_norm": 0.8736196756362915,
      "learning_rate": 8.455371732026144e-06,
      "loss": 0.0532,
      "step": 5204
    },
    {
      "epoch": 1.1960018382352942,
      "grad_norm": 0.965227484703064,
      "learning_rate": 8.454861111111111e-06,
      "loss": 0.0693,
      "step": 5205
    },
    {
      "epoch": 1.1962316176470589,
      "grad_norm": 0.864226222038269,
      "learning_rate": 8.45435049019608e-06,
      "loss": 0.0465,
      "step": 5206
    },
    {
      "epoch": 1.1964613970588236,
      "grad_norm": 0.8992193937301636,
      "learning_rate": 8.453839869281047e-06,
      "loss": 0.0454,
      "step": 5207
    },
    {
      "epoch": 1.1966911764705883,
      "grad_norm": 0.971651554107666,
      "learning_rate": 8.453329248366013e-06,
      "loss": 0.0841,
      "step": 5208
    },
    {
      "epoch": 1.196920955882353,
      "grad_norm": 0.9488126039505005,
      "learning_rate": 8.452818627450981e-06,
      "loss": 0.0591,
      "step": 5209
    },
    {
      "epoch": 1.1971507352941178,
      "grad_norm": 1.060879111289978,
      "learning_rate": 8.452308006535949e-06,
      "loss": 0.0757,
      "step": 5210
    },
    {
      "epoch": 1.1973805147058822,
      "grad_norm": 1.167655348777771,
      "learning_rate": 8.451797385620915e-06,
      "loss": 0.0764,
      "step": 5211
    },
    {
      "epoch": 1.197610294117647,
      "grad_norm": 1.258327603340149,
      "learning_rate": 8.451286764705883e-06,
      "loss": 0.0502,
      "step": 5212
    },
    {
      "epoch": 1.1978400735294117,
      "grad_norm": 0.9876556992530823,
      "learning_rate": 8.450776143790851e-06,
      "loss": 0.0617,
      "step": 5213
    },
    {
      "epoch": 1.1980698529411764,
      "grad_norm": 1.2570472955703735,
      "learning_rate": 8.450265522875817e-06,
      "loss": 0.052,
      "step": 5214
    },
    {
      "epoch": 1.1982996323529411,
      "grad_norm": 1.1303956508636475,
      "learning_rate": 8.449754901960785e-06,
      "loss": 0.0698,
      "step": 5215
    },
    {
      "epoch": 1.1985294117647058,
      "grad_norm": 0.8889284133911133,
      "learning_rate": 8.449244281045753e-06,
      "loss": 0.0773,
      "step": 5216
    },
    {
      "epoch": 1.1987591911764706,
      "grad_norm": 1.0184404850006104,
      "learning_rate": 8.44873366013072e-06,
      "loss": 0.0545,
      "step": 5217
    },
    {
      "epoch": 1.1989889705882353,
      "grad_norm": 1.0930253267288208,
      "learning_rate": 8.448223039215687e-06,
      "loss": 0.0866,
      "step": 5218
    },
    {
      "epoch": 1.19921875,
      "grad_norm": 1.1246272325515747,
      "learning_rate": 8.447712418300655e-06,
      "loss": 0.0572,
      "step": 5219
    },
    {
      "epoch": 1.1994485294117647,
      "grad_norm": 1.0734481811523438,
      "learning_rate": 8.447201797385621e-06,
      "loss": 0.0693,
      "step": 5220
    },
    {
      "epoch": 1.1996783088235294,
      "grad_norm": 1.095699429512024,
      "learning_rate": 8.446691176470589e-06,
      "loss": 0.0528,
      "step": 5221
    },
    {
      "epoch": 1.1999080882352942,
      "grad_norm": 0.8307574987411499,
      "learning_rate": 8.446180555555557e-06,
      "loss": 0.0504,
      "step": 5222
    },
    {
      "epoch": 1.2001378676470589,
      "grad_norm": 1.2067509889602661,
      "learning_rate": 8.445669934640523e-06,
      "loss": 0.0744,
      "step": 5223
    },
    {
      "epoch": 1.2003676470588236,
      "grad_norm": 1.397782802581787,
      "learning_rate": 8.44515931372549e-06,
      "loss": 0.069,
      "step": 5224
    },
    {
      "epoch": 1.2005974264705883,
      "grad_norm": 1.0029644966125488,
      "learning_rate": 8.444648692810459e-06,
      "loss": 0.0512,
      "step": 5225
    },
    {
      "epoch": 1.200827205882353,
      "grad_norm": 1.1916855573654175,
      "learning_rate": 8.444138071895426e-06,
      "loss": 0.0615,
      "step": 5226
    },
    {
      "epoch": 1.2010569852941178,
      "grad_norm": 1.3549643754959106,
      "learning_rate": 8.443627450980393e-06,
      "loss": 0.0459,
      "step": 5227
    },
    {
      "epoch": 1.2012867647058822,
      "grad_norm": 1.1198301315307617,
      "learning_rate": 8.44311683006536e-06,
      "loss": 0.062,
      "step": 5228
    },
    {
      "epoch": 1.201516544117647,
      "grad_norm": 0.8963428735733032,
      "learning_rate": 8.442606209150328e-06,
      "loss": 0.0479,
      "step": 5229
    },
    {
      "epoch": 1.2017463235294117,
      "grad_norm": 0.8780734539031982,
      "learning_rate": 8.442095588235294e-06,
      "loss": 0.0508,
      "step": 5230
    },
    {
      "epoch": 1.2019761029411764,
      "grad_norm": 0.7091946005821228,
      "learning_rate": 8.441584967320262e-06,
      "loss": 0.0447,
      "step": 5231
    },
    {
      "epoch": 1.2022058823529411,
      "grad_norm": 0.9637253880500793,
      "learning_rate": 8.441074346405228e-06,
      "loss": 0.0827,
      "step": 5232
    },
    {
      "epoch": 1.2024356617647058,
      "grad_norm": 1.5444825887680054,
      "learning_rate": 8.440563725490198e-06,
      "loss": 0.0463,
      "step": 5233
    },
    {
      "epoch": 1.2026654411764706,
      "grad_norm": 1.3444464206695557,
      "learning_rate": 8.440053104575164e-06,
      "loss": 0.0434,
      "step": 5234
    },
    {
      "epoch": 1.2028952205882353,
      "grad_norm": 1.1441911458969116,
      "learning_rate": 8.439542483660132e-06,
      "loss": 0.0562,
      "step": 5235
    },
    {
      "epoch": 1.203125,
      "grad_norm": 1.0317611694335938,
      "learning_rate": 8.439031862745098e-06,
      "loss": 0.0469,
      "step": 5236
    },
    {
      "epoch": 1.2033547794117647,
      "grad_norm": 0.8032298684120178,
      "learning_rate": 8.438521241830066e-06,
      "loss": 0.0402,
      "step": 5237
    },
    {
      "epoch": 1.2035845588235294,
      "grad_norm": 0.9140773415565491,
      "learning_rate": 8.438010620915034e-06,
      "loss": 0.0599,
      "step": 5238
    },
    {
      "epoch": 1.2038143382352942,
      "grad_norm": 1.0292272567749023,
      "learning_rate": 8.4375e-06,
      "loss": 0.0605,
      "step": 5239
    },
    {
      "epoch": 1.2040441176470589,
      "grad_norm": 0.9331533312797546,
      "learning_rate": 8.436989379084968e-06,
      "loss": 0.0471,
      "step": 5240
    },
    {
      "epoch": 1.2042738970588236,
      "grad_norm": 1.1193130016326904,
      "learning_rate": 8.436478758169934e-06,
      "loss": 0.0599,
      "step": 5241
    },
    {
      "epoch": 1.2045036764705883,
      "grad_norm": 0.9802576899528503,
      "learning_rate": 8.435968137254904e-06,
      "loss": 0.0635,
      "step": 5242
    },
    {
      "epoch": 1.204733455882353,
      "grad_norm": 1.054541826248169,
      "learning_rate": 8.43545751633987e-06,
      "loss": 0.054,
      "step": 5243
    },
    {
      "epoch": 1.2049632352941178,
      "grad_norm": 0.9297784566879272,
      "learning_rate": 8.434946895424838e-06,
      "loss": 0.0513,
      "step": 5244
    },
    {
      "epoch": 1.2051930147058822,
      "grad_norm": 1.2181932926177979,
      "learning_rate": 8.434436274509804e-06,
      "loss": 0.0644,
      "step": 5245
    },
    {
      "epoch": 1.205422794117647,
      "grad_norm": 0.8478121161460876,
      "learning_rate": 8.433925653594772e-06,
      "loss": 0.045,
      "step": 5246
    },
    {
      "epoch": 1.2056525735294117,
      "grad_norm": 0.7454155683517456,
      "learning_rate": 8.43341503267974e-06,
      "loss": 0.0422,
      "step": 5247
    },
    {
      "epoch": 1.2058823529411764,
      "grad_norm": 1.0777102708816528,
      "learning_rate": 8.432904411764706e-06,
      "loss": 0.0688,
      "step": 5248
    },
    {
      "epoch": 1.2061121323529411,
      "grad_norm": 1.0709291696548462,
      "learning_rate": 8.432393790849674e-06,
      "loss": 0.0701,
      "step": 5249
    },
    {
      "epoch": 1.2063419117647058,
      "grad_norm": 1.0447518825531006,
      "learning_rate": 8.431883169934642e-06,
      "loss": 0.0467,
      "step": 5250
    },
    {
      "epoch": 1.2065716911764706,
      "grad_norm": 1.1861697435379028,
      "learning_rate": 8.43137254901961e-06,
      "loss": 0.0701,
      "step": 5251
    },
    {
      "epoch": 1.2068014705882353,
      "grad_norm": 1.179492712020874,
      "learning_rate": 8.430861928104576e-06,
      "loss": 0.0457,
      "step": 5252
    },
    {
      "epoch": 1.20703125,
      "grad_norm": 1.347253441810608,
      "learning_rate": 8.430351307189543e-06,
      "loss": 0.1189,
      "step": 5253
    },
    {
      "epoch": 1.2072610294117647,
      "grad_norm": 1.0328341722488403,
      "learning_rate": 8.429840686274511e-06,
      "loss": 0.0532,
      "step": 5254
    },
    {
      "epoch": 1.2074908088235294,
      "grad_norm": 1.2207615375518799,
      "learning_rate": 8.429330065359477e-06,
      "loss": 0.0927,
      "step": 5255
    },
    {
      "epoch": 1.2077205882352942,
      "grad_norm": 1.2732504606246948,
      "learning_rate": 8.428819444444445e-06,
      "loss": 0.0741,
      "step": 5256
    },
    {
      "epoch": 1.2079503676470589,
      "grad_norm": 1.2180030345916748,
      "learning_rate": 8.428308823529411e-06,
      "loss": 0.08,
      "step": 5257
    },
    {
      "epoch": 1.2081801470588236,
      "grad_norm": 0.960983157157898,
      "learning_rate": 8.42779820261438e-06,
      "loss": 0.0645,
      "step": 5258
    },
    {
      "epoch": 1.2084099264705883,
      "grad_norm": 1.1142650842666626,
      "learning_rate": 8.427287581699347e-06,
      "loss": 0.0619,
      "step": 5259
    },
    {
      "epoch": 1.208639705882353,
      "grad_norm": 0.8706014156341553,
      "learning_rate": 8.426776960784313e-06,
      "loss": 0.065,
      "step": 5260
    },
    {
      "epoch": 1.2088694852941178,
      "grad_norm": 1.314498782157898,
      "learning_rate": 8.426266339869281e-06,
      "loss": 0.0882,
      "step": 5261
    },
    {
      "epoch": 1.2090992647058822,
      "grad_norm": 0.9442898631095886,
      "learning_rate": 8.425755718954249e-06,
      "loss": 0.0568,
      "step": 5262
    },
    {
      "epoch": 1.209329044117647,
      "grad_norm": 0.6833471059799194,
      "learning_rate": 8.425245098039217e-06,
      "loss": 0.0385,
      "step": 5263
    },
    {
      "epoch": 1.2095588235294117,
      "grad_norm": 1.7331640720367432,
      "learning_rate": 8.424734477124183e-06,
      "loss": 0.0504,
      "step": 5264
    },
    {
      "epoch": 1.2097886029411764,
      "grad_norm": 0.8186814785003662,
      "learning_rate": 8.424223856209151e-06,
      "loss": 0.0329,
      "step": 5265
    },
    {
      "epoch": 1.2100183823529411,
      "grad_norm": 0.9246839880943298,
      "learning_rate": 8.423713235294119e-06,
      "loss": 0.0527,
      "step": 5266
    },
    {
      "epoch": 1.2102481617647058,
      "grad_norm": 0.8883638381958008,
      "learning_rate": 8.423202614379085e-06,
      "loss": 0.0485,
      "step": 5267
    },
    {
      "epoch": 1.2104779411764706,
      "grad_norm": 0.8950587511062622,
      "learning_rate": 8.422691993464053e-06,
      "loss": 0.0501,
      "step": 5268
    },
    {
      "epoch": 1.2107077205882353,
      "grad_norm": 0.7351599931716919,
      "learning_rate": 8.422181372549019e-06,
      "loss": 0.0394,
      "step": 5269
    },
    {
      "epoch": 1.2109375,
      "grad_norm": 1.1578892469406128,
      "learning_rate": 8.421670751633989e-06,
      "loss": 0.0538,
      "step": 5270
    },
    {
      "epoch": 1.2111672794117647,
      "grad_norm": 0.9503077268600464,
      "learning_rate": 8.421160130718955e-06,
      "loss": 0.0654,
      "step": 5271
    },
    {
      "epoch": 1.2113970588235294,
      "grad_norm": 0.9314395189285278,
      "learning_rate": 8.420649509803923e-06,
      "loss": 0.0572,
      "step": 5272
    },
    {
      "epoch": 1.2116268382352942,
      "grad_norm": 0.8236650824546814,
      "learning_rate": 8.420138888888889e-06,
      "loss": 0.0421,
      "step": 5273
    },
    {
      "epoch": 1.2118566176470589,
      "grad_norm": 1.006575107574463,
      "learning_rate": 8.419628267973857e-06,
      "loss": 0.0657,
      "step": 5274
    },
    {
      "epoch": 1.2120863970588236,
      "grad_norm": 0.7063899636268616,
      "learning_rate": 8.419117647058824e-06,
      "loss": 0.0479,
      "step": 5275
    },
    {
      "epoch": 1.2123161764705883,
      "grad_norm": 1.2403713464736938,
      "learning_rate": 8.41860702614379e-06,
      "loss": 0.0706,
      "step": 5276
    },
    {
      "epoch": 1.212545955882353,
      "grad_norm": 0.8256124258041382,
      "learning_rate": 8.418096405228759e-06,
      "loss": 0.0461,
      "step": 5277
    },
    {
      "epoch": 1.2127757352941178,
      "grad_norm": 1.1362282037734985,
      "learning_rate": 8.417585784313726e-06,
      "loss": 0.059,
      "step": 5278
    },
    {
      "epoch": 1.2130055147058822,
      "grad_norm": 0.8662128448486328,
      "learning_rate": 8.417075163398694e-06,
      "loss": 0.046,
      "step": 5279
    },
    {
      "epoch": 1.213235294117647,
      "grad_norm": 0.916571855545044,
      "learning_rate": 8.41656454248366e-06,
      "loss": 0.0516,
      "step": 5280
    },
    {
      "epoch": 1.2134650735294117,
      "grad_norm": 0.8897146582603455,
      "learning_rate": 8.416053921568628e-06,
      "loss": 0.044,
      "step": 5281
    },
    {
      "epoch": 1.2136948529411764,
      "grad_norm": 0.9786273241043091,
      "learning_rate": 8.415543300653596e-06,
      "loss": 0.0583,
      "step": 5282
    },
    {
      "epoch": 1.2139246323529411,
      "grad_norm": 0.978715717792511,
      "learning_rate": 8.415032679738562e-06,
      "loss": 0.0692,
      "step": 5283
    },
    {
      "epoch": 1.2141544117647058,
      "grad_norm": 1.3050336837768555,
      "learning_rate": 8.41452205882353e-06,
      "loss": 0.1124,
      "step": 5284
    },
    {
      "epoch": 1.2143841911764706,
      "grad_norm": 1.2308403253555298,
      "learning_rate": 8.414011437908496e-06,
      "loss": 0.0665,
      "step": 5285
    },
    {
      "epoch": 1.2146139705882353,
      "grad_norm": 1.1588594913482666,
      "learning_rate": 8.413500816993466e-06,
      "loss": 0.048,
      "step": 5286
    },
    {
      "epoch": 1.21484375,
      "grad_norm": 1.6012743711471558,
      "learning_rate": 8.412990196078432e-06,
      "loss": 0.0634,
      "step": 5287
    },
    {
      "epoch": 1.2150735294117647,
      "grad_norm": 1.3078280687332153,
      "learning_rate": 8.4124795751634e-06,
      "loss": 0.0698,
      "step": 5288
    },
    {
      "epoch": 1.2153033088235294,
      "grad_norm": 0.9940172433853149,
      "learning_rate": 8.411968954248366e-06,
      "loss": 0.0526,
      "step": 5289
    },
    {
      "epoch": 1.2155330882352942,
      "grad_norm": 1.2340128421783447,
      "learning_rate": 8.411458333333334e-06,
      "loss": 0.075,
      "step": 5290
    },
    {
      "epoch": 1.2157628676470589,
      "grad_norm": 1.8713535070419312,
      "learning_rate": 8.410947712418302e-06,
      "loss": 0.0971,
      "step": 5291
    },
    {
      "epoch": 1.2159926470588236,
      "grad_norm": 1.169553518295288,
      "learning_rate": 8.410437091503268e-06,
      "loss": 0.0596,
      "step": 5292
    },
    {
      "epoch": 1.2162224264705883,
      "grad_norm": 0.9432427287101746,
      "learning_rate": 8.409926470588236e-06,
      "loss": 0.0431,
      "step": 5293
    },
    {
      "epoch": 1.216452205882353,
      "grad_norm": 1.467525601387024,
      "learning_rate": 8.409415849673204e-06,
      "loss": 0.0915,
      "step": 5294
    },
    {
      "epoch": 1.2166819852941178,
      "grad_norm": 1.089414119720459,
      "learning_rate": 8.408905228758172e-06,
      "loss": 0.0727,
      "step": 5295
    },
    {
      "epoch": 1.2169117647058822,
      "grad_norm": 0.9874406456947327,
      "learning_rate": 8.408394607843138e-06,
      "loss": 0.0599,
      "step": 5296
    },
    {
      "epoch": 1.217141544117647,
      "grad_norm": 1.119248390197754,
      "learning_rate": 8.407883986928106e-06,
      "loss": 0.0676,
      "step": 5297
    },
    {
      "epoch": 1.2173713235294117,
      "grad_norm": 1.0414668321609497,
      "learning_rate": 8.407373366013073e-06,
      "loss": 0.0703,
      "step": 5298
    },
    {
      "epoch": 1.2176011029411764,
      "grad_norm": 1.1072081327438354,
      "learning_rate": 8.40686274509804e-06,
      "loss": 0.0682,
      "step": 5299
    },
    {
      "epoch": 1.2178308823529411,
      "grad_norm": 1.0409269332885742,
      "learning_rate": 8.406352124183007e-06,
      "loss": 0.0687,
      "step": 5300
    },
    {
      "epoch": 1.2180606617647058,
      "grad_norm": 1.037343144416809,
      "learning_rate": 8.405841503267974e-06,
      "loss": 0.0879,
      "step": 5301
    },
    {
      "epoch": 1.2182904411764706,
      "grad_norm": 0.882701575756073,
      "learning_rate": 8.405330882352941e-06,
      "loss": 0.0621,
      "step": 5302
    },
    {
      "epoch": 1.2185202205882353,
      "grad_norm": 0.8636729717254639,
      "learning_rate": 8.40482026143791e-06,
      "loss": 0.0502,
      "step": 5303
    },
    {
      "epoch": 1.21875,
      "grad_norm": 0.9836220145225525,
      "learning_rate": 8.404309640522876e-06,
      "loss": 0.0487,
      "step": 5304
    },
    {
      "epoch": 1.2189797794117647,
      "grad_norm": 1.0095868110656738,
      "learning_rate": 8.403799019607843e-06,
      "loss": 0.0614,
      "step": 5305
    },
    {
      "epoch": 1.2192095588235294,
      "grad_norm": 1.051451563835144,
      "learning_rate": 8.403288398692811e-06,
      "loss": 0.047,
      "step": 5306
    },
    {
      "epoch": 1.2194393382352942,
      "grad_norm": 1.179416537284851,
      "learning_rate": 8.402777777777779e-06,
      "loss": 0.0584,
      "step": 5307
    },
    {
      "epoch": 1.2196691176470589,
      "grad_norm": 0.7085995078086853,
      "learning_rate": 8.402267156862745e-06,
      "loss": 0.0399,
      "step": 5308
    },
    {
      "epoch": 1.2198988970588236,
      "grad_norm": 1.1613541841506958,
      "learning_rate": 8.401756535947713e-06,
      "loss": 0.0601,
      "step": 5309
    },
    {
      "epoch": 1.2201286764705883,
      "grad_norm": 1.060241460800171,
      "learning_rate": 8.401245915032681e-06,
      "loss": 0.0854,
      "step": 5310
    },
    {
      "epoch": 1.220358455882353,
      "grad_norm": 0.9256029725074768,
      "learning_rate": 8.400735294117647e-06,
      "loss": 0.0866,
      "step": 5311
    },
    {
      "epoch": 1.2205882352941178,
      "grad_norm": 1.1381537914276123,
      "learning_rate": 8.400224673202615e-06,
      "loss": 0.0917,
      "step": 5312
    },
    {
      "epoch": 1.2208180147058822,
      "grad_norm": 0.9121050238609314,
      "learning_rate": 8.399714052287581e-06,
      "loss": 0.0652,
      "step": 5313
    },
    {
      "epoch": 1.221047794117647,
      "grad_norm": 1.0238388776779175,
      "learning_rate": 8.39920343137255e-06,
      "loss": 0.046,
      "step": 5314
    },
    {
      "epoch": 1.2212775735294117,
      "grad_norm": 1.2678414583206177,
      "learning_rate": 8.398692810457517e-06,
      "loss": 0.0787,
      "step": 5315
    },
    {
      "epoch": 1.2215073529411764,
      "grad_norm": 1.0518920421600342,
      "learning_rate": 8.398182189542485e-06,
      "loss": 0.0603,
      "step": 5316
    },
    {
      "epoch": 1.2217371323529411,
      "grad_norm": 0.8549949526786804,
      "learning_rate": 8.397671568627451e-06,
      "loss": 0.0566,
      "step": 5317
    },
    {
      "epoch": 1.2219669117647058,
      "grad_norm": 0.8819466233253479,
      "learning_rate": 8.397160947712419e-06,
      "loss": 0.0471,
      "step": 5318
    },
    {
      "epoch": 1.2221966911764706,
      "grad_norm": 1.4360297918319702,
      "learning_rate": 8.396650326797387e-06,
      "loss": 0.0504,
      "step": 5319
    },
    {
      "epoch": 1.2224264705882353,
      "grad_norm": 0.9958934783935547,
      "learning_rate": 8.396139705882353e-06,
      "loss": 0.0743,
      "step": 5320
    },
    {
      "epoch": 1.22265625,
      "grad_norm": 0.947110652923584,
      "learning_rate": 8.39562908496732e-06,
      "loss": 0.0504,
      "step": 5321
    },
    {
      "epoch": 1.2228860294117647,
      "grad_norm": 1.043315052986145,
      "learning_rate": 8.395118464052289e-06,
      "loss": 0.0463,
      "step": 5322
    },
    {
      "epoch": 1.2231158088235294,
      "grad_norm": 1.4091315269470215,
      "learning_rate": 8.394607843137256e-06,
      "loss": 0.0972,
      "step": 5323
    },
    {
      "epoch": 1.2233455882352942,
      "grad_norm": 0.9751595854759216,
      "learning_rate": 8.394097222222223e-06,
      "loss": 0.0422,
      "step": 5324
    },
    {
      "epoch": 1.2235753676470589,
      "grad_norm": 1.0597553253173828,
      "learning_rate": 8.39358660130719e-06,
      "loss": 0.0918,
      "step": 5325
    },
    {
      "epoch": 1.2238051470588236,
      "grad_norm": 1.1639783382415771,
      "learning_rate": 8.393075980392158e-06,
      "loss": 0.0723,
      "step": 5326
    },
    {
      "epoch": 1.2240349264705883,
      "grad_norm": 0.987109363079071,
      "learning_rate": 8.392565359477124e-06,
      "loss": 0.0643,
      "step": 5327
    },
    {
      "epoch": 1.224264705882353,
      "grad_norm": 0.8751055002212524,
      "learning_rate": 8.392054738562092e-06,
      "loss": 0.0477,
      "step": 5328
    },
    {
      "epoch": 1.2244944852941178,
      "grad_norm": 1.2906668186187744,
      "learning_rate": 8.391544117647059e-06,
      "loss": 0.0585,
      "step": 5329
    },
    {
      "epoch": 1.2247242647058822,
      "grad_norm": 1.1225721836090088,
      "learning_rate": 8.391033496732028e-06,
      "loss": 0.0597,
      "step": 5330
    },
    {
      "epoch": 1.224954044117647,
      "grad_norm": 0.972359836101532,
      "learning_rate": 8.390522875816994e-06,
      "loss": 0.0542,
      "step": 5331
    },
    {
      "epoch": 1.2251838235294117,
      "grad_norm": 1.026458978652954,
      "learning_rate": 8.390012254901962e-06,
      "loss": 0.0522,
      "step": 5332
    },
    {
      "epoch": 1.2254136029411764,
      "grad_norm": 0.9223120808601379,
      "learning_rate": 8.389501633986928e-06,
      "loss": 0.0467,
      "step": 5333
    },
    {
      "epoch": 1.2256433823529411,
      "grad_norm": 0.9202178716659546,
      "learning_rate": 8.388991013071896e-06,
      "loss": 0.0509,
      "step": 5334
    },
    {
      "epoch": 1.2258731617647058,
      "grad_norm": 1.1638320684432983,
      "learning_rate": 8.388480392156864e-06,
      "loss": 0.061,
      "step": 5335
    },
    {
      "epoch": 1.2261029411764706,
      "grad_norm": 1.2439519166946411,
      "learning_rate": 8.38796977124183e-06,
      "loss": 0.0597,
      "step": 5336
    },
    {
      "epoch": 1.2263327205882353,
      "grad_norm": 1.0840039253234863,
      "learning_rate": 8.387459150326798e-06,
      "loss": 0.0632,
      "step": 5337
    },
    {
      "epoch": 1.2265625,
      "grad_norm": 0.8480579257011414,
      "learning_rate": 8.386948529411766e-06,
      "loss": 0.051,
      "step": 5338
    },
    {
      "epoch": 1.2267922794117647,
      "grad_norm": 1.0134398937225342,
      "learning_rate": 8.386437908496734e-06,
      "loss": 0.0654,
      "step": 5339
    },
    {
      "epoch": 1.2270220588235294,
      "grad_norm": 0.8527788519859314,
      "learning_rate": 8.3859272875817e-06,
      "loss": 0.0592,
      "step": 5340
    },
    {
      "epoch": 1.2272518382352942,
      "grad_norm": 1.1398210525512695,
      "learning_rate": 8.385416666666668e-06,
      "loss": 0.0486,
      "step": 5341
    },
    {
      "epoch": 1.2274816176470589,
      "grad_norm": 1.1429725885391235,
      "learning_rate": 8.384906045751636e-06,
      "loss": 0.0719,
      "step": 5342
    },
    {
      "epoch": 1.2277113970588236,
      "grad_norm": 0.7698283195495605,
      "learning_rate": 8.384395424836602e-06,
      "loss": 0.0512,
      "step": 5343
    },
    {
      "epoch": 1.2279411764705883,
      "grad_norm": 0.8022776246070862,
      "learning_rate": 8.38388480392157e-06,
      "loss": 0.0452,
      "step": 5344
    },
    {
      "epoch": 1.228170955882353,
      "grad_norm": 0.6829028129577637,
      "learning_rate": 8.383374183006536e-06,
      "loss": 0.0369,
      "step": 5345
    },
    {
      "epoch": 1.2284007352941178,
      "grad_norm": 1.365517020225525,
      "learning_rate": 8.382863562091504e-06,
      "loss": 0.0795,
      "step": 5346
    },
    {
      "epoch": 1.2286305147058822,
      "grad_norm": 0.9722822308540344,
      "learning_rate": 8.382352941176472e-06,
      "loss": 0.0389,
      "step": 5347
    },
    {
      "epoch": 1.228860294117647,
      "grad_norm": 1.3091669082641602,
      "learning_rate": 8.381842320261438e-06,
      "loss": 0.0511,
      "step": 5348
    },
    {
      "epoch": 1.2290900735294117,
      "grad_norm": 0.8600248694419861,
      "learning_rate": 8.381331699346406e-06,
      "loss": 0.0388,
      "step": 5349
    },
    {
      "epoch": 1.2293198529411764,
      "grad_norm": 0.8404338359832764,
      "learning_rate": 8.380821078431373e-06,
      "loss": 0.058,
      "step": 5350
    },
    {
      "epoch": 1.2295496323529411,
      "grad_norm": 1.0895898342132568,
      "learning_rate": 8.380310457516341e-06,
      "loss": 0.0543,
      "step": 5351
    },
    {
      "epoch": 1.2297794117647058,
      "grad_norm": 0.8948624134063721,
      "learning_rate": 8.379799836601307e-06,
      "loss": 0.0449,
      "step": 5352
    },
    {
      "epoch": 1.2300091911764706,
      "grad_norm": 1.1500489711761475,
      "learning_rate": 8.379289215686275e-06,
      "loss": 0.0654,
      "step": 5353
    },
    {
      "epoch": 1.2302389705882353,
      "grad_norm": 1.4066693782806396,
      "learning_rate": 8.378778594771243e-06,
      "loss": 0.0553,
      "step": 5354
    },
    {
      "epoch": 1.23046875,
      "grad_norm": 1.1184568405151367,
      "learning_rate": 8.37826797385621e-06,
      "loss": 0.0543,
      "step": 5355
    },
    {
      "epoch": 1.2306985294117647,
      "grad_norm": 0.9519301652908325,
      "learning_rate": 8.377757352941177e-06,
      "loss": 0.0465,
      "step": 5356
    },
    {
      "epoch": 1.2309283088235294,
      "grad_norm": 1.191672682762146,
      "learning_rate": 8.377246732026143e-06,
      "loss": 0.0577,
      "step": 5357
    },
    {
      "epoch": 1.2311580882352942,
      "grad_norm": 1.3056484460830688,
      "learning_rate": 8.376736111111113e-06,
      "loss": 0.0694,
      "step": 5358
    },
    {
      "epoch": 1.2313878676470589,
      "grad_norm": 1.0391168594360352,
      "learning_rate": 8.376225490196079e-06,
      "loss": 0.0563,
      "step": 5359
    },
    {
      "epoch": 1.2316176470588236,
      "grad_norm": 0.9083147644996643,
      "learning_rate": 8.375714869281047e-06,
      "loss": 0.0457,
      "step": 5360
    },
    {
      "epoch": 1.2318474264705883,
      "grad_norm": 1.3041146993637085,
      "learning_rate": 8.375204248366013e-06,
      "loss": 0.0674,
      "step": 5361
    },
    {
      "epoch": 1.232077205882353,
      "grad_norm": 1.2171140909194946,
      "learning_rate": 8.374693627450981e-06,
      "loss": 0.0651,
      "step": 5362
    },
    {
      "epoch": 1.2323069852941178,
      "grad_norm": 0.9863019585609436,
      "learning_rate": 8.374183006535949e-06,
      "loss": 0.0355,
      "step": 5363
    },
    {
      "epoch": 1.2325367647058822,
      "grad_norm": 1.1996827125549316,
      "learning_rate": 8.373672385620915e-06,
      "loss": 0.0603,
      "step": 5364
    },
    {
      "epoch": 1.232766544117647,
      "grad_norm": 1.5219782590866089,
      "learning_rate": 8.373161764705883e-06,
      "loss": 0.0892,
      "step": 5365
    },
    {
      "epoch": 1.2329963235294117,
      "grad_norm": 0.8844683766365051,
      "learning_rate": 8.37265114379085e-06,
      "loss": 0.045,
      "step": 5366
    },
    {
      "epoch": 1.2332261029411764,
      "grad_norm": 0.7485707998275757,
      "learning_rate": 8.372140522875819e-06,
      "loss": 0.0347,
      "step": 5367
    },
    {
      "epoch": 1.2334558823529411,
      "grad_norm": 1.065524697303772,
      "learning_rate": 8.371629901960785e-06,
      "loss": 0.0496,
      "step": 5368
    },
    {
      "epoch": 1.2336856617647058,
      "grad_norm": 0.8308142423629761,
      "learning_rate": 8.371119281045753e-06,
      "loss": 0.0445,
      "step": 5369
    },
    {
      "epoch": 1.2339154411764706,
      "grad_norm": 1.6245440244674683,
      "learning_rate": 8.37060866013072e-06,
      "loss": 0.0598,
      "step": 5370
    },
    {
      "epoch": 1.2341452205882353,
      "grad_norm": 0.9318326711654663,
      "learning_rate": 8.370098039215687e-06,
      "loss": 0.0481,
      "step": 5371
    },
    {
      "epoch": 1.234375,
      "grad_norm": 0.8317280411720276,
      "learning_rate": 8.369587418300655e-06,
      "loss": 0.0475,
      "step": 5372
    },
    {
      "epoch": 1.2346047794117647,
      "grad_norm": 0.9510294198989868,
      "learning_rate": 8.36907679738562e-06,
      "loss": 0.0508,
      "step": 5373
    },
    {
      "epoch": 1.2348345588235294,
      "grad_norm": 1.0212712287902832,
      "learning_rate": 8.36856617647059e-06,
      "loss": 0.0623,
      "step": 5374
    },
    {
      "epoch": 1.2350643382352942,
      "grad_norm": 1.5575385093688965,
      "learning_rate": 8.368055555555556e-06,
      "loss": 0.0851,
      "step": 5375
    },
    {
      "epoch": 1.2352941176470589,
      "grad_norm": 1.374340534210205,
      "learning_rate": 8.367544934640524e-06,
      "loss": 0.1079,
      "step": 5376
    },
    {
      "epoch": 1.2355238970588236,
      "grad_norm": 0.9978815317153931,
      "learning_rate": 8.36703431372549e-06,
      "loss": 0.0612,
      "step": 5377
    },
    {
      "epoch": 1.2357536764705883,
      "grad_norm": 0.8608317375183105,
      "learning_rate": 8.366523692810458e-06,
      "loss": 0.0448,
      "step": 5378
    },
    {
      "epoch": 1.235983455882353,
      "grad_norm": 1.0105763673782349,
      "learning_rate": 8.366013071895426e-06,
      "loss": 0.0681,
      "step": 5379
    },
    {
      "epoch": 1.2362132352941178,
      "grad_norm": 0.8998084664344788,
      "learning_rate": 8.365502450980392e-06,
      "loss": 0.0466,
      "step": 5380
    },
    {
      "epoch": 1.2364430147058822,
      "grad_norm": 0.9201269745826721,
      "learning_rate": 8.36499183006536e-06,
      "loss": 0.0494,
      "step": 5381
    },
    {
      "epoch": 1.236672794117647,
      "grad_norm": 0.7987924218177795,
      "learning_rate": 8.364481209150328e-06,
      "loss": 0.052,
      "step": 5382
    },
    {
      "epoch": 1.2369025735294117,
      "grad_norm": 0.9325418472290039,
      "learning_rate": 8.363970588235294e-06,
      "loss": 0.0471,
      "step": 5383
    },
    {
      "epoch": 1.2371323529411764,
      "grad_norm": 1.319209098815918,
      "learning_rate": 8.363459967320262e-06,
      "loss": 0.0674,
      "step": 5384
    },
    {
      "epoch": 1.2373621323529411,
      "grad_norm": 1.2550073862075806,
      "learning_rate": 8.36294934640523e-06,
      "loss": 0.0744,
      "step": 5385
    },
    {
      "epoch": 1.2375919117647058,
      "grad_norm": 1.355686068534851,
      "learning_rate": 8.362438725490198e-06,
      "loss": 0.0652,
      "step": 5386
    },
    {
      "epoch": 1.2378216911764706,
      "grad_norm": 1.0759985446929932,
      "learning_rate": 8.361928104575164e-06,
      "loss": 0.0539,
      "step": 5387
    },
    {
      "epoch": 1.2380514705882353,
      "grad_norm": 0.8795827627182007,
      "learning_rate": 8.361417483660132e-06,
      "loss": 0.0657,
      "step": 5388
    },
    {
      "epoch": 1.23828125,
      "grad_norm": 1.2042773962020874,
      "learning_rate": 8.360906862745098e-06,
      "loss": 0.0558,
      "step": 5389
    },
    {
      "epoch": 1.2385110294117647,
      "grad_norm": 0.6883388757705688,
      "learning_rate": 8.360396241830066e-06,
      "loss": 0.0374,
      "step": 5390
    },
    {
      "epoch": 1.2387408088235294,
      "grad_norm": 1.182383418083191,
      "learning_rate": 8.359885620915034e-06,
      "loss": 0.0765,
      "step": 5391
    },
    {
      "epoch": 1.2389705882352942,
      "grad_norm": 1.0152469873428345,
      "learning_rate": 8.359375e-06,
      "loss": 0.0608,
      "step": 5392
    },
    {
      "epoch": 1.2392003676470589,
      "grad_norm": 0.8504361510276794,
      "learning_rate": 8.358864379084968e-06,
      "loss": 0.0444,
      "step": 5393
    },
    {
      "epoch": 1.2394301470588236,
      "grad_norm": 1.1062852144241333,
      "learning_rate": 8.358353758169934e-06,
      "loss": 0.0624,
      "step": 5394
    },
    {
      "epoch": 1.2396599264705883,
      "grad_norm": 1.539885401725769,
      "learning_rate": 8.357843137254903e-06,
      "loss": 0.0719,
      "step": 5395
    },
    {
      "epoch": 1.239889705882353,
      "grad_norm": 0.96727454662323,
      "learning_rate": 8.35733251633987e-06,
      "loss": 0.0692,
      "step": 5396
    },
    {
      "epoch": 1.2401194852941178,
      "grad_norm": 1.2625144720077515,
      "learning_rate": 8.356821895424838e-06,
      "loss": 0.0669,
      "step": 5397
    },
    {
      "epoch": 1.2403492647058822,
      "grad_norm": 1.9488389492034912,
      "learning_rate": 8.356311274509804e-06,
      "loss": 0.0675,
      "step": 5398
    },
    {
      "epoch": 1.240579044117647,
      "grad_norm": 0.8339208960533142,
      "learning_rate": 8.355800653594772e-06,
      "loss": 0.0505,
      "step": 5399
    },
    {
      "epoch": 1.2408088235294117,
      "grad_norm": 1.0657706260681152,
      "learning_rate": 8.35529003267974e-06,
      "loss": 0.0669,
      "step": 5400
    },
    {
      "epoch": 1.2410386029411764,
      "grad_norm": 0.9175934195518494,
      "learning_rate": 8.354779411764706e-06,
      "loss": 0.0618,
      "step": 5401
    },
    {
      "epoch": 1.2412683823529411,
      "grad_norm": 1.4122834205627441,
      "learning_rate": 8.354268790849673e-06,
      "loss": 0.0622,
      "step": 5402
    },
    {
      "epoch": 1.2414981617647058,
      "grad_norm": 1.4008868932724,
      "learning_rate": 8.353758169934641e-06,
      "loss": 0.0848,
      "step": 5403
    },
    {
      "epoch": 1.2417279411764706,
      "grad_norm": 0.8550761342048645,
      "learning_rate": 8.35324754901961e-06,
      "loss": 0.0549,
      "step": 5404
    },
    {
      "epoch": 1.2419577205882353,
      "grad_norm": 1.1441154479980469,
      "learning_rate": 8.352736928104575e-06,
      "loss": 0.0625,
      "step": 5405
    },
    {
      "epoch": 1.2421875,
      "grad_norm": 0.956355631351471,
      "learning_rate": 8.352226307189543e-06,
      "loss": 0.0574,
      "step": 5406
    },
    {
      "epoch": 1.2424172794117647,
      "grad_norm": 1.2912405729293823,
      "learning_rate": 8.351715686274511e-06,
      "loss": 0.054,
      "step": 5407
    },
    {
      "epoch": 1.2426470588235294,
      "grad_norm": 1.2417583465576172,
      "learning_rate": 8.351205065359477e-06,
      "loss": 0.0639,
      "step": 5408
    },
    {
      "epoch": 1.2428768382352942,
      "grad_norm": 1.4368013143539429,
      "learning_rate": 8.350694444444445e-06,
      "loss": 0.0759,
      "step": 5409
    },
    {
      "epoch": 1.2431066176470589,
      "grad_norm": 1.572834849357605,
      "learning_rate": 8.350183823529411e-06,
      "loss": 0.071,
      "step": 5410
    },
    {
      "epoch": 1.2433363970588236,
      "grad_norm": 1.1645889282226562,
      "learning_rate": 8.34967320261438e-06,
      "loss": 0.0474,
      "step": 5411
    },
    {
      "epoch": 1.2435661764705883,
      "grad_norm": 0.8621048927307129,
      "learning_rate": 8.349162581699347e-06,
      "loss": 0.0491,
      "step": 5412
    },
    {
      "epoch": 1.243795955882353,
      "grad_norm": 1.3464058637619019,
      "learning_rate": 8.348651960784315e-06,
      "loss": 0.0916,
      "step": 5413
    },
    {
      "epoch": 1.2440257352941178,
      "grad_norm": 0.8920472264289856,
      "learning_rate": 8.348141339869281e-06,
      "loss": 0.0561,
      "step": 5414
    },
    {
      "epoch": 1.2442555147058822,
      "grad_norm": 0.7814822793006897,
      "learning_rate": 8.347630718954249e-06,
      "loss": 0.0519,
      "step": 5415
    },
    {
      "epoch": 1.244485294117647,
      "grad_norm": 1.0330030918121338,
      "learning_rate": 8.347120098039217e-06,
      "loss": 0.0575,
      "step": 5416
    },
    {
      "epoch": 1.2447150735294117,
      "grad_norm": 1.1158015727996826,
      "learning_rate": 8.346609477124183e-06,
      "loss": 0.0508,
      "step": 5417
    },
    {
      "epoch": 1.2449448529411764,
      "grad_norm": 1.138074517250061,
      "learning_rate": 8.34609885620915e-06,
      "loss": 0.0462,
      "step": 5418
    },
    {
      "epoch": 1.2451746323529411,
      "grad_norm": 1.2846238613128662,
      "learning_rate": 8.345588235294119e-06,
      "loss": 0.0939,
      "step": 5419
    },
    {
      "epoch": 1.2454044117647058,
      "grad_norm": 1.1896001100540161,
      "learning_rate": 8.345077614379086e-06,
      "loss": 0.0782,
      "step": 5420
    },
    {
      "epoch": 1.2456341911764706,
      "grad_norm": 0.8418260216712952,
      "learning_rate": 8.344566993464053e-06,
      "loss": 0.0616,
      "step": 5421
    },
    {
      "epoch": 1.2458639705882353,
      "grad_norm": 0.8415136933326721,
      "learning_rate": 8.34405637254902e-06,
      "loss": 0.0491,
      "step": 5422
    },
    {
      "epoch": 1.24609375,
      "grad_norm": 0.7882595658302307,
      "learning_rate": 8.343545751633988e-06,
      "loss": 0.0505,
      "step": 5423
    },
    {
      "epoch": 1.2463235294117647,
      "grad_norm": 0.8267008066177368,
      "learning_rate": 8.343035130718955e-06,
      "loss": 0.059,
      "step": 5424
    },
    {
      "epoch": 1.2465533088235294,
      "grad_norm": 0.7913567423820496,
      "learning_rate": 8.342524509803922e-06,
      "loss": 0.0546,
      "step": 5425
    },
    {
      "epoch": 1.2467830882352942,
      "grad_norm": 1.186858892440796,
      "learning_rate": 8.342013888888889e-06,
      "loss": 0.0705,
      "step": 5426
    },
    {
      "epoch": 1.2470128676470589,
      "grad_norm": 0.5815172791481018,
      "learning_rate": 8.341503267973856e-06,
      "loss": 0.0449,
      "step": 5427
    },
    {
      "epoch": 1.2472426470588236,
      "grad_norm": 1.4479018449783325,
      "learning_rate": 8.340992647058824e-06,
      "loss": 0.0805,
      "step": 5428
    },
    {
      "epoch": 1.2474724264705883,
      "grad_norm": 0.904220461845398,
      "learning_rate": 8.340482026143792e-06,
      "loss": 0.0594,
      "step": 5429
    },
    {
      "epoch": 1.247702205882353,
      "grad_norm": 0.77634197473526,
      "learning_rate": 8.339971405228758e-06,
      "loss": 0.0606,
      "step": 5430
    },
    {
      "epoch": 1.2479319852941178,
      "grad_norm": 0.625765323638916,
      "learning_rate": 8.339460784313726e-06,
      "loss": 0.0295,
      "step": 5431
    },
    {
      "epoch": 1.2481617647058822,
      "grad_norm": 0.7604110836982727,
      "learning_rate": 8.338950163398694e-06,
      "loss": 0.0456,
      "step": 5432
    },
    {
      "epoch": 1.248391544117647,
      "grad_norm": 0.9193677306175232,
      "learning_rate": 8.33843954248366e-06,
      "loss": 0.0605,
      "step": 5433
    },
    {
      "epoch": 1.2486213235294117,
      "grad_norm": 0.8776956796646118,
      "learning_rate": 8.337928921568628e-06,
      "loss": 0.0722,
      "step": 5434
    },
    {
      "epoch": 1.2488511029411764,
      "grad_norm": 0.9293628931045532,
      "learning_rate": 8.337418300653596e-06,
      "loss": 0.0445,
      "step": 5435
    },
    {
      "epoch": 1.2490808823529411,
      "grad_norm": 0.8317693471908569,
      "learning_rate": 8.336907679738562e-06,
      "loss": 0.0572,
      "step": 5436
    },
    {
      "epoch": 1.2493106617647058,
      "grad_norm": 0.9105677008628845,
      "learning_rate": 8.33639705882353e-06,
      "loss": 0.0712,
      "step": 5437
    },
    {
      "epoch": 1.2495404411764706,
      "grad_norm": 0.9945307970046997,
      "learning_rate": 8.335886437908496e-06,
      "loss": 0.0864,
      "step": 5438
    },
    {
      "epoch": 1.2497702205882353,
      "grad_norm": 0.9591724276542664,
      "learning_rate": 8.335375816993466e-06,
      "loss": 0.0629,
      "step": 5439
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.8903993964195251,
      "learning_rate": 8.334865196078432e-06,
      "loss": 0.048,
      "step": 5440
    },
    {
      "epoch": 1.2502297794117647,
      "grad_norm": 0.8927763104438782,
      "learning_rate": 8.3343545751634e-06,
      "loss": 0.0657,
      "step": 5441
    },
    {
      "epoch": 1.2504595588235294,
      "grad_norm": 0.9929916858673096,
      "learning_rate": 8.333843954248366e-06,
      "loss": 0.046,
      "step": 5442
    },
    {
      "epoch": 1.2506893382352942,
      "grad_norm": 1.0429364442825317,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.0466,
      "step": 5443
    },
    {
      "epoch": 1.2509191176470589,
      "grad_norm": 0.8662568926811218,
      "learning_rate": 8.332822712418302e-06,
      "loss": 0.061,
      "step": 5444
    },
    {
      "epoch": 1.2511488970588236,
      "grad_norm": 0.7485557794570923,
      "learning_rate": 8.332312091503268e-06,
      "loss": 0.0444,
      "step": 5445
    },
    {
      "epoch": 1.2513786764705883,
      "grad_norm": 0.9205586314201355,
      "learning_rate": 8.331801470588236e-06,
      "loss": 0.0502,
      "step": 5446
    },
    {
      "epoch": 1.2516084558823528,
      "grad_norm": 0.7891215682029724,
      "learning_rate": 8.331290849673203e-06,
      "loss": 0.0603,
      "step": 5447
    },
    {
      "epoch": 1.2518382352941178,
      "grad_norm": 1.2598459720611572,
      "learning_rate": 8.330780228758171e-06,
      "loss": 0.07,
      "step": 5448
    },
    {
      "epoch": 1.2520680147058822,
      "grad_norm": 1.2175320386886597,
      "learning_rate": 8.330269607843138e-06,
      "loss": 0.0621,
      "step": 5449
    },
    {
      "epoch": 1.2522977941176472,
      "grad_norm": 0.8124158978462219,
      "learning_rate": 8.329758986928105e-06,
      "loss": 0.0323,
      "step": 5450
    },
    {
      "epoch": 1.2525275735294117,
      "grad_norm": 0.7809890508651733,
      "learning_rate": 8.329248366013073e-06,
      "loss": 0.0458,
      "step": 5451
    },
    {
      "epoch": 1.2527573529411764,
      "grad_norm": 1.1103471517562866,
      "learning_rate": 8.32873774509804e-06,
      "loss": 0.0601,
      "step": 5452
    },
    {
      "epoch": 1.2529871323529411,
      "grad_norm": 0.6643596887588501,
      "learning_rate": 8.328227124183007e-06,
      "loss": 0.0333,
      "step": 5453
    },
    {
      "epoch": 1.2532169117647058,
      "grad_norm": 1.2238432168960571,
      "learning_rate": 8.327716503267973e-06,
      "loss": 0.0471,
      "step": 5454
    },
    {
      "epoch": 1.2534466911764706,
      "grad_norm": 0.8527769446372986,
      "learning_rate": 8.327205882352943e-06,
      "loss": 0.0579,
      "step": 5455
    },
    {
      "epoch": 1.2536764705882353,
      "grad_norm": 1.0334837436676025,
      "learning_rate": 8.32669526143791e-06,
      "loss": 0.0671,
      "step": 5456
    },
    {
      "epoch": 1.25390625,
      "grad_norm": 0.9664987325668335,
      "learning_rate": 8.326184640522877e-06,
      "loss": 0.0499,
      "step": 5457
    },
    {
      "epoch": 1.2541360294117647,
      "grad_norm": 0.9542083740234375,
      "learning_rate": 8.325674019607843e-06,
      "loss": 0.0536,
      "step": 5458
    },
    {
      "epoch": 1.2543658088235294,
      "grad_norm": 1.0113036632537842,
      "learning_rate": 8.325163398692811e-06,
      "loss": 0.0548,
      "step": 5459
    },
    {
      "epoch": 1.2545955882352942,
      "grad_norm": 1.0635170936584473,
      "learning_rate": 8.324652777777779e-06,
      "loss": 0.0575,
      "step": 5460
    },
    {
      "epoch": 1.2548253676470589,
      "grad_norm": 1.3179607391357422,
      "learning_rate": 8.324142156862745e-06,
      "loss": 0.0712,
      "step": 5461
    },
    {
      "epoch": 1.2550551470588236,
      "grad_norm": 0.7994022965431213,
      "learning_rate": 8.323631535947713e-06,
      "loss": 0.0409,
      "step": 5462
    },
    {
      "epoch": 1.2552849264705883,
      "grad_norm": 1.020156741142273,
      "learning_rate": 8.32312091503268e-06,
      "loss": 0.0614,
      "step": 5463
    },
    {
      "epoch": 1.2555147058823528,
      "grad_norm": 0.8211786150932312,
      "learning_rate": 8.322610294117649e-06,
      "loss": 0.0532,
      "step": 5464
    },
    {
      "epoch": 1.2557444852941178,
      "grad_norm": 0.9926808476448059,
      "learning_rate": 8.322099673202615e-06,
      "loss": 0.0424,
      "step": 5465
    },
    {
      "epoch": 1.2559742647058822,
      "grad_norm": 0.935015082359314,
      "learning_rate": 8.321589052287583e-06,
      "loss": 0.0687,
      "step": 5466
    },
    {
      "epoch": 1.2562040441176472,
      "grad_norm": 1.0063056945800781,
      "learning_rate": 8.32107843137255e-06,
      "loss": 0.0482,
      "step": 5467
    },
    {
      "epoch": 1.2564338235294117,
      "grad_norm": 0.9572075605392456,
      "learning_rate": 8.320567810457517e-06,
      "loss": 0.0614,
      "step": 5468
    },
    {
      "epoch": 1.2566636029411764,
      "grad_norm": 0.8602311611175537,
      "learning_rate": 8.320057189542485e-06,
      "loss": 0.0358,
      "step": 5469
    },
    {
      "epoch": 1.2568933823529411,
      "grad_norm": 1.1992970705032349,
      "learning_rate": 8.31954656862745e-06,
      "loss": 0.0768,
      "step": 5470
    },
    {
      "epoch": 1.2571231617647058,
      "grad_norm": 1.5111385583877563,
      "learning_rate": 8.319035947712419e-06,
      "loss": 0.073,
      "step": 5471
    },
    {
      "epoch": 1.2573529411764706,
      "grad_norm": 1.0956709384918213,
      "learning_rate": 8.318525326797386e-06,
      "loss": 0.058,
      "step": 5472
    },
    {
      "epoch": 1.2575827205882353,
      "grad_norm": 1.2806057929992676,
      "learning_rate": 8.318014705882354e-06,
      "loss": 0.0913,
      "step": 5473
    },
    {
      "epoch": 1.2578125,
      "grad_norm": 1.0877758264541626,
      "learning_rate": 8.31750408496732e-06,
      "loss": 0.058,
      "step": 5474
    },
    {
      "epoch": 1.2580422794117647,
      "grad_norm": 0.7971125841140747,
      "learning_rate": 8.316993464052288e-06,
      "loss": 0.0575,
      "step": 5475
    },
    {
      "epoch": 1.2582720588235294,
      "grad_norm": 0.7979409694671631,
      "learning_rate": 8.316482843137256e-06,
      "loss": 0.0481,
      "step": 5476
    },
    {
      "epoch": 1.2585018382352942,
      "grad_norm": 0.9384111166000366,
      "learning_rate": 8.315972222222222e-06,
      "loss": 0.0811,
      "step": 5477
    },
    {
      "epoch": 1.2587316176470589,
      "grad_norm": 0.8829684257507324,
      "learning_rate": 8.31546160130719e-06,
      "loss": 0.0517,
      "step": 5478
    },
    {
      "epoch": 1.2589613970588236,
      "grad_norm": 0.8194715976715088,
      "learning_rate": 8.314950980392158e-06,
      "loss": 0.051,
      "step": 5479
    },
    {
      "epoch": 1.2591911764705883,
      "grad_norm": 1.0007693767547607,
      "learning_rate": 8.314440359477124e-06,
      "loss": 0.0599,
      "step": 5480
    },
    {
      "epoch": 1.2594209558823528,
      "grad_norm": 0.9781516790390015,
      "learning_rate": 8.313929738562092e-06,
      "loss": 0.0568,
      "step": 5481
    },
    {
      "epoch": 1.2596507352941178,
      "grad_norm": 1.1477580070495605,
      "learning_rate": 8.313419117647058e-06,
      "loss": 0.0678,
      "step": 5482
    },
    {
      "epoch": 1.2598805147058822,
      "grad_norm": 0.8639614582061768,
      "learning_rate": 8.312908496732028e-06,
      "loss": 0.0426,
      "step": 5483
    },
    {
      "epoch": 1.2601102941176472,
      "grad_norm": 1.2297712564468384,
      "learning_rate": 8.312397875816994e-06,
      "loss": 0.0651,
      "step": 5484
    },
    {
      "epoch": 1.2603400735294117,
      "grad_norm": 0.9940739274024963,
      "learning_rate": 8.311887254901962e-06,
      "loss": 0.0683,
      "step": 5485
    },
    {
      "epoch": 1.2605698529411764,
      "grad_norm": 0.932184636592865,
      "learning_rate": 8.311376633986928e-06,
      "loss": 0.0345,
      "step": 5486
    },
    {
      "epoch": 1.2607996323529411,
      "grad_norm": 1.1984152793884277,
      "learning_rate": 8.310866013071896e-06,
      "loss": 0.0751,
      "step": 5487
    },
    {
      "epoch": 1.2610294117647058,
      "grad_norm": 1.447188138961792,
      "learning_rate": 8.310355392156864e-06,
      "loss": 0.0544,
      "step": 5488
    },
    {
      "epoch": 1.2612591911764706,
      "grad_norm": 0.8830509781837463,
      "learning_rate": 8.30984477124183e-06,
      "loss": 0.0442,
      "step": 5489
    },
    {
      "epoch": 1.2614889705882353,
      "grad_norm": 1.0616086721420288,
      "learning_rate": 8.309334150326798e-06,
      "loss": 0.0442,
      "step": 5490
    },
    {
      "epoch": 1.26171875,
      "grad_norm": 0.8811937570571899,
      "learning_rate": 8.308823529411766e-06,
      "loss": 0.0546,
      "step": 5491
    },
    {
      "epoch": 1.2619485294117647,
      "grad_norm": 1.077125906944275,
      "learning_rate": 8.308312908496734e-06,
      "loss": 0.0721,
      "step": 5492
    },
    {
      "epoch": 1.2621783088235294,
      "grad_norm": 1.5038886070251465,
      "learning_rate": 8.3078022875817e-06,
      "loss": 0.066,
      "step": 5493
    },
    {
      "epoch": 1.2624080882352942,
      "grad_norm": 1.1235363483428955,
      "learning_rate": 8.307291666666668e-06,
      "loss": 0.0767,
      "step": 5494
    },
    {
      "epoch": 1.2626378676470589,
      "grad_norm": 1.1163585186004639,
      "learning_rate": 8.306781045751635e-06,
      "loss": 0.065,
      "step": 5495
    },
    {
      "epoch": 1.2628676470588236,
      "grad_norm": 0.981596827507019,
      "learning_rate": 8.306270424836602e-06,
      "loss": 0.0565,
      "step": 5496
    },
    {
      "epoch": 1.2630974264705883,
      "grad_norm": 1.2021886110305786,
      "learning_rate": 8.30575980392157e-06,
      "loss": 0.0637,
      "step": 5497
    },
    {
      "epoch": 1.2633272058823528,
      "grad_norm": 0.9573962092399597,
      "learning_rate": 8.305249183006536e-06,
      "loss": 0.043,
      "step": 5498
    },
    {
      "epoch": 1.2635569852941178,
      "grad_norm": 0.6900440454483032,
      "learning_rate": 8.304738562091505e-06,
      "loss": 0.0368,
      "step": 5499
    },
    {
      "epoch": 1.2637867647058822,
      "grad_norm": 1.0109866857528687,
      "learning_rate": 8.304227941176471e-06,
      "loss": 0.0491,
      "step": 5500
    },
    {
      "epoch": 1.2637867647058822,
      "eval_loss": 0.060115914791822433,
      "eval_runtime": 2006.4067,
      "eval_samples_per_second": 4.439,
      "eval_steps_per_second": 2.219,
      "step": 5500
    },
    {
      "epoch": 1.2640165441176472,
      "grad_norm": 1.0876808166503906,
      "learning_rate": 8.30371732026144e-06,
      "loss": 0.0565,
      "step": 5501
    },
    {
      "epoch": 1.2642463235294117,
      "grad_norm": 0.8307931423187256,
      "learning_rate": 8.303206699346405e-06,
      "loss": 0.048,
      "step": 5502
    },
    {
      "epoch": 1.2644761029411764,
      "grad_norm": 1.144940733909607,
      "learning_rate": 8.302696078431373e-06,
      "loss": 0.0454,
      "step": 5503
    },
    {
      "epoch": 1.2647058823529411,
      "grad_norm": 0.9851170778274536,
      "learning_rate": 8.302185457516341e-06,
      "loss": 0.0659,
      "step": 5504
    },
    {
      "epoch": 1.2649356617647058,
      "grad_norm": 1.3046444654464722,
      "learning_rate": 8.301674836601307e-06,
      "loss": 0.0358,
      "step": 5505
    },
    {
      "epoch": 1.2651654411764706,
      "grad_norm": 0.8407983183860779,
      "learning_rate": 8.301164215686275e-06,
      "loss": 0.0627,
      "step": 5506
    },
    {
      "epoch": 1.2653952205882353,
      "grad_norm": 1.0858975648880005,
      "learning_rate": 8.300653594771243e-06,
      "loss": 0.0804,
      "step": 5507
    },
    {
      "epoch": 1.265625,
      "grad_norm": 0.9406096935272217,
      "learning_rate": 8.30014297385621e-06,
      "loss": 0.0621,
      "step": 5508
    },
    {
      "epoch": 1.2658547794117647,
      "grad_norm": 0.9314063787460327,
      "learning_rate": 8.299632352941177e-06,
      "loss": 0.0515,
      "step": 5509
    },
    {
      "epoch": 1.2660845588235294,
      "grad_norm": 0.9900391101837158,
      "learning_rate": 8.299121732026145e-06,
      "loss": 0.0728,
      "step": 5510
    },
    {
      "epoch": 1.2663143382352942,
      "grad_norm": 0.9121538996696472,
      "learning_rate": 8.298611111111113e-06,
      "loss": 0.0437,
      "step": 5511
    },
    {
      "epoch": 1.2665441176470589,
      "grad_norm": 0.7616338729858398,
      "learning_rate": 8.298100490196079e-06,
      "loss": 0.0483,
      "step": 5512
    },
    {
      "epoch": 1.2667738970588236,
      "grad_norm": 1.0058802366256714,
      "learning_rate": 8.297589869281047e-06,
      "loss": 0.0587,
      "step": 5513
    },
    {
      "epoch": 1.2670036764705883,
      "grad_norm": 1.0361098051071167,
      "learning_rate": 8.297079248366013e-06,
      "loss": 0.0458,
      "step": 5514
    },
    {
      "epoch": 1.2672334558823528,
      "grad_norm": 0.9967970252037048,
      "learning_rate": 8.29656862745098e-06,
      "loss": 0.08,
      "step": 5515
    },
    {
      "epoch": 1.2674632352941178,
      "grad_norm": 0.8182576894760132,
      "learning_rate": 8.296058006535949e-06,
      "loss": 0.0322,
      "step": 5516
    },
    {
      "epoch": 1.2676930147058822,
      "grad_norm": 1.2958954572677612,
      "learning_rate": 8.295547385620915e-06,
      "loss": 0.0515,
      "step": 5517
    },
    {
      "epoch": 1.2679227941176472,
      "grad_norm": 1.0771733522415161,
      "learning_rate": 8.295036764705883e-06,
      "loss": 0.0461,
      "step": 5518
    },
    {
      "epoch": 1.2681525735294117,
      "grad_norm": 1.159594178199768,
      "learning_rate": 8.29452614379085e-06,
      "loss": 0.0651,
      "step": 5519
    },
    {
      "epoch": 1.2683823529411764,
      "grad_norm": 1.221522331237793,
      "learning_rate": 8.294015522875818e-06,
      "loss": 0.0747,
      "step": 5520
    },
    {
      "epoch": 1.2686121323529411,
      "grad_norm": 1.4998587369918823,
      "learning_rate": 8.293504901960785e-06,
      "loss": 0.0681,
      "step": 5521
    },
    {
      "epoch": 1.2688419117647058,
      "grad_norm": 1.2526386976242065,
      "learning_rate": 8.292994281045752e-06,
      "loss": 0.0811,
      "step": 5522
    },
    {
      "epoch": 1.2690716911764706,
      "grad_norm": 0.8644089102745056,
      "learning_rate": 8.29248366013072e-06,
      "loss": 0.048,
      "step": 5523
    },
    {
      "epoch": 1.2693014705882353,
      "grad_norm": 0.8799616694450378,
      "learning_rate": 8.291973039215686e-06,
      "loss": 0.0579,
      "step": 5524
    },
    {
      "epoch": 1.26953125,
      "grad_norm": 0.8387293219566345,
      "learning_rate": 8.291462418300654e-06,
      "loss": 0.0445,
      "step": 5525
    },
    {
      "epoch": 1.2697610294117647,
      "grad_norm": 0.8759766817092896,
      "learning_rate": 8.29095179738562e-06,
      "loss": 0.0527,
      "step": 5526
    },
    {
      "epoch": 1.2699908088235294,
      "grad_norm": 1.04412841796875,
      "learning_rate": 8.29044117647059e-06,
      "loss": 0.0717,
      "step": 5527
    },
    {
      "epoch": 1.2702205882352942,
      "grad_norm": 1.1955019235610962,
      "learning_rate": 8.289930555555556e-06,
      "loss": 0.0589,
      "step": 5528
    },
    {
      "epoch": 1.2704503676470589,
      "grad_norm": 1.0092109441757202,
      "learning_rate": 8.289419934640524e-06,
      "loss": 0.0553,
      "step": 5529
    },
    {
      "epoch": 1.2706801470588236,
      "grad_norm": 0.9998576045036316,
      "learning_rate": 8.28890931372549e-06,
      "loss": 0.0758,
      "step": 5530
    },
    {
      "epoch": 1.2709099264705883,
      "grad_norm": 0.9204878807067871,
      "learning_rate": 8.288398692810458e-06,
      "loss": 0.0566,
      "step": 5531
    },
    {
      "epoch": 1.2711397058823528,
      "grad_norm": 0.8175994157791138,
      "learning_rate": 8.287888071895426e-06,
      "loss": 0.0474,
      "step": 5532
    },
    {
      "epoch": 1.2713694852941178,
      "grad_norm": 1.342394471168518,
      "learning_rate": 8.287377450980392e-06,
      "loss": 0.0996,
      "step": 5533
    },
    {
      "epoch": 1.2715992647058822,
      "grad_norm": 1.221171498298645,
      "learning_rate": 8.28686683006536e-06,
      "loss": 0.0803,
      "step": 5534
    },
    {
      "epoch": 1.2718290441176472,
      "grad_norm": 1.3221288919448853,
      "learning_rate": 8.286356209150328e-06,
      "loss": 0.0712,
      "step": 5535
    },
    {
      "epoch": 1.2720588235294117,
      "grad_norm": 1.0842589139938354,
      "learning_rate": 8.285845588235296e-06,
      "loss": 0.0486,
      "step": 5536
    },
    {
      "epoch": 1.2722886029411764,
      "grad_norm": 0.8254469633102417,
      "learning_rate": 8.285334967320262e-06,
      "loss": 0.0378,
      "step": 5537
    },
    {
      "epoch": 1.2725183823529411,
      "grad_norm": 1.2532234191894531,
      "learning_rate": 8.28482434640523e-06,
      "loss": 0.0692,
      "step": 5538
    },
    {
      "epoch": 1.2727481617647058,
      "grad_norm": 0.9130845665931702,
      "learning_rate": 8.284313725490198e-06,
      "loss": 0.0418,
      "step": 5539
    },
    {
      "epoch": 1.2729779411764706,
      "grad_norm": 0.8679417967796326,
      "learning_rate": 8.283803104575164e-06,
      "loss": 0.0509,
      "step": 5540
    },
    {
      "epoch": 1.2732077205882353,
      "grad_norm": 1.1095070838928223,
      "learning_rate": 8.283292483660132e-06,
      "loss": 0.0773,
      "step": 5541
    },
    {
      "epoch": 1.2734375,
      "grad_norm": 0.9155223369598389,
      "learning_rate": 8.282781862745098e-06,
      "loss": 0.0495,
      "step": 5542
    },
    {
      "epoch": 1.2736672794117647,
      "grad_norm": 1.154286503791809,
      "learning_rate": 8.282271241830067e-06,
      "loss": 0.0556,
      "step": 5543
    },
    {
      "epoch": 1.2738970588235294,
      "grad_norm": 0.9822933673858643,
      "learning_rate": 8.281760620915034e-06,
      "loss": 0.0654,
      "step": 5544
    },
    {
      "epoch": 1.2741268382352942,
      "grad_norm": 0.7559580206871033,
      "learning_rate": 8.281250000000001e-06,
      "loss": 0.049,
      "step": 5545
    },
    {
      "epoch": 1.2743566176470589,
      "grad_norm": 1.316130518913269,
      "learning_rate": 8.280739379084968e-06,
      "loss": 0.0682,
      "step": 5546
    },
    {
      "epoch": 1.2745863970588236,
      "grad_norm": 1.3491840362548828,
      "learning_rate": 8.280228758169935e-06,
      "loss": 0.0719,
      "step": 5547
    },
    {
      "epoch": 1.2748161764705883,
      "grad_norm": 1.0614421367645264,
      "learning_rate": 8.279718137254903e-06,
      "loss": 0.0692,
      "step": 5548
    },
    {
      "epoch": 1.2750459558823528,
      "grad_norm": 0.8259748220443726,
      "learning_rate": 8.27920751633987e-06,
      "loss": 0.0531,
      "step": 5549
    },
    {
      "epoch": 1.2752757352941178,
      "grad_norm": 0.9059112668037415,
      "learning_rate": 8.278696895424837e-06,
      "loss": 0.0377,
      "step": 5550
    },
    {
      "epoch": 1.2755055147058822,
      "grad_norm": 0.8968021273612976,
      "learning_rate": 8.278186274509803e-06,
      "loss": 0.0484,
      "step": 5551
    },
    {
      "epoch": 1.2757352941176472,
      "grad_norm": 1.012190580368042,
      "learning_rate": 8.277675653594773e-06,
      "loss": 0.0592,
      "step": 5552
    },
    {
      "epoch": 1.2759650735294117,
      "grad_norm": 1.0533208847045898,
      "learning_rate": 8.27716503267974e-06,
      "loss": 0.0545,
      "step": 5553
    },
    {
      "epoch": 1.2761948529411764,
      "grad_norm": 1.4882086515426636,
      "learning_rate": 8.276654411764707e-06,
      "loss": 0.0704,
      "step": 5554
    },
    {
      "epoch": 1.2764246323529411,
      "grad_norm": 1.3386262655258179,
      "learning_rate": 8.276143790849673e-06,
      "loss": 0.0421,
      "step": 5555
    },
    {
      "epoch": 1.2766544117647058,
      "grad_norm": 1.1126564741134644,
      "learning_rate": 8.275633169934641e-06,
      "loss": 0.0524,
      "step": 5556
    },
    {
      "epoch": 1.2768841911764706,
      "grad_norm": 0.8904847502708435,
      "learning_rate": 8.275122549019609e-06,
      "loss": 0.0502,
      "step": 5557
    },
    {
      "epoch": 1.2771139705882353,
      "grad_norm": 1.331325650215149,
      "learning_rate": 8.274611928104575e-06,
      "loss": 0.0713,
      "step": 5558
    },
    {
      "epoch": 1.27734375,
      "grad_norm": 1.1884576082229614,
      "learning_rate": 8.274101307189543e-06,
      "loss": 0.0719,
      "step": 5559
    },
    {
      "epoch": 1.2775735294117647,
      "grad_norm": 1.2792677879333496,
      "learning_rate": 8.27359068627451e-06,
      "loss": 0.0692,
      "step": 5560
    },
    {
      "epoch": 1.2778033088235294,
      "grad_norm": 1.2346630096435547,
      "learning_rate": 8.273080065359477e-06,
      "loss": 0.0694,
      "step": 5561
    },
    {
      "epoch": 1.2780330882352942,
      "grad_norm": 1.2466838359832764,
      "learning_rate": 8.272569444444445e-06,
      "loss": 0.0821,
      "step": 5562
    },
    {
      "epoch": 1.2782628676470589,
      "grad_norm": 1.0096940994262695,
      "learning_rate": 8.272058823529413e-06,
      "loss": 0.0509,
      "step": 5563
    },
    {
      "epoch": 1.2784926470588236,
      "grad_norm": 0.9402315616607666,
      "learning_rate": 8.27154820261438e-06,
      "loss": 0.0563,
      "step": 5564
    },
    {
      "epoch": 1.2787224264705883,
      "grad_norm": 1.166222095489502,
      "learning_rate": 8.271037581699347e-06,
      "loss": 0.0744,
      "step": 5565
    },
    {
      "epoch": 1.2789522058823528,
      "grad_norm": 0.9089626669883728,
      "learning_rate": 8.270526960784315e-06,
      "loss": 0.0399,
      "step": 5566
    },
    {
      "epoch": 1.2791819852941178,
      "grad_norm": 1.0077275037765503,
      "learning_rate": 8.27001633986928e-06,
      "loss": 0.055,
      "step": 5567
    },
    {
      "epoch": 1.2794117647058822,
      "grad_norm": 1.3269463777542114,
      "learning_rate": 8.269505718954249e-06,
      "loss": 0.1059,
      "step": 5568
    },
    {
      "epoch": 1.2796415441176472,
      "grad_norm": 0.8809722661972046,
      "learning_rate": 8.268995098039217e-06,
      "loss": 0.0615,
      "step": 5569
    },
    {
      "epoch": 1.2798713235294117,
      "grad_norm": 0.9991351366043091,
      "learning_rate": 8.268484477124183e-06,
      "loss": 0.0572,
      "step": 5570
    },
    {
      "epoch": 1.2801011029411764,
      "grad_norm": 1.252949595451355,
      "learning_rate": 8.26797385620915e-06,
      "loss": 0.0608,
      "step": 5571
    },
    {
      "epoch": 1.2803308823529411,
      "grad_norm": 0.919221818447113,
      "learning_rate": 8.267463235294118e-06,
      "loss": 0.0539,
      "step": 5572
    },
    {
      "epoch": 1.2805606617647058,
      "grad_norm": 1.1095856428146362,
      "learning_rate": 8.266952614379086e-06,
      "loss": 0.0522,
      "step": 5573
    },
    {
      "epoch": 1.2807904411764706,
      "grad_norm": 1.5056718587875366,
      "learning_rate": 8.266441993464052e-06,
      "loss": 0.0641,
      "step": 5574
    },
    {
      "epoch": 1.2810202205882353,
      "grad_norm": 0.9263812899589539,
      "learning_rate": 8.26593137254902e-06,
      "loss": 0.0588,
      "step": 5575
    },
    {
      "epoch": 1.28125,
      "grad_norm": 0.714939296245575,
      "learning_rate": 8.265420751633988e-06,
      "loss": 0.0364,
      "step": 5576
    },
    {
      "epoch": 1.2814797794117647,
      "grad_norm": 0.9474254250526428,
      "learning_rate": 8.264910130718954e-06,
      "loss": 0.0759,
      "step": 5577
    },
    {
      "epoch": 1.2817095588235294,
      "grad_norm": 0.989260196685791,
      "learning_rate": 8.264399509803922e-06,
      "loss": 0.056,
      "step": 5578
    },
    {
      "epoch": 1.2819393382352942,
      "grad_norm": 1.266710877418518,
      "learning_rate": 8.263888888888888e-06,
      "loss": 0.0746,
      "step": 5579
    },
    {
      "epoch": 1.2821691176470589,
      "grad_norm": 1.6678529977798462,
      "learning_rate": 8.263378267973858e-06,
      "loss": 0.0803,
      "step": 5580
    },
    {
      "epoch": 1.2823988970588236,
      "grad_norm": 1.2210506200790405,
      "learning_rate": 8.262867647058824e-06,
      "loss": 0.0931,
      "step": 5581
    },
    {
      "epoch": 1.2826286764705883,
      "grad_norm": 0.9592497944831848,
      "learning_rate": 8.262357026143792e-06,
      "loss": 0.0397,
      "step": 5582
    },
    {
      "epoch": 1.2828584558823528,
      "grad_norm": 1.3109347820281982,
      "learning_rate": 8.261846405228758e-06,
      "loss": 0.0436,
      "step": 5583
    },
    {
      "epoch": 1.2830882352941178,
      "grad_norm": 0.8305762410163879,
      "learning_rate": 8.261335784313726e-06,
      "loss": 0.049,
      "step": 5584
    },
    {
      "epoch": 1.2833180147058822,
      "grad_norm": 0.8676819205284119,
      "learning_rate": 8.260825163398694e-06,
      "loss": 0.0442,
      "step": 5585
    },
    {
      "epoch": 1.2835477941176472,
      "grad_norm": 1.0439574718475342,
      "learning_rate": 8.26031454248366e-06,
      "loss": 0.0712,
      "step": 5586
    },
    {
      "epoch": 1.2837775735294117,
      "grad_norm": 1.195888638496399,
      "learning_rate": 8.259803921568628e-06,
      "loss": 0.0543,
      "step": 5587
    },
    {
      "epoch": 1.2840073529411764,
      "grad_norm": 0.8820357322692871,
      "learning_rate": 8.259293300653596e-06,
      "loss": 0.0377,
      "step": 5588
    },
    {
      "epoch": 1.2842371323529411,
      "grad_norm": 0.8863652348518372,
      "learning_rate": 8.258782679738564e-06,
      "loss": 0.0646,
      "step": 5589
    },
    {
      "epoch": 1.2844669117647058,
      "grad_norm": 1.0813876390457153,
      "learning_rate": 8.25827205882353e-06,
      "loss": 0.0496,
      "step": 5590
    },
    {
      "epoch": 1.2846966911764706,
      "grad_norm": 1.2686160802841187,
      "learning_rate": 8.257761437908498e-06,
      "loss": 0.0986,
      "step": 5591
    },
    {
      "epoch": 1.2849264705882353,
      "grad_norm": 1.1837838888168335,
      "learning_rate": 8.257250816993465e-06,
      "loss": 0.0826,
      "step": 5592
    },
    {
      "epoch": 1.28515625,
      "grad_norm": 0.8439675569534302,
      "learning_rate": 8.256740196078432e-06,
      "loss": 0.0631,
      "step": 5593
    },
    {
      "epoch": 1.2853860294117647,
      "grad_norm": 1.3795591592788696,
      "learning_rate": 8.2562295751634e-06,
      "loss": 0.0735,
      "step": 5594
    },
    {
      "epoch": 1.2856158088235294,
      "grad_norm": 0.8896167874336243,
      "learning_rate": 8.255718954248366e-06,
      "loss": 0.0701,
      "step": 5595
    },
    {
      "epoch": 1.2858455882352942,
      "grad_norm": 0.9544236660003662,
      "learning_rate": 8.255208333333335e-06,
      "loss": 0.0509,
      "step": 5596
    },
    {
      "epoch": 1.2860753676470589,
      "grad_norm": 0.8889822363853455,
      "learning_rate": 8.254697712418301e-06,
      "loss": 0.0629,
      "step": 5597
    },
    {
      "epoch": 1.2863051470588236,
      "grad_norm": 1.134687900543213,
      "learning_rate": 8.25418709150327e-06,
      "loss": 0.0652,
      "step": 5598
    },
    {
      "epoch": 1.2865349264705883,
      "grad_norm": 1.0539346933364868,
      "learning_rate": 8.253676470588235e-06,
      "loss": 0.0631,
      "step": 5599
    },
    {
      "epoch": 1.2867647058823528,
      "grad_norm": 0.7728341817855835,
      "learning_rate": 8.253165849673203e-06,
      "loss": 0.0338,
      "step": 5600
    },
    {
      "epoch": 1.2869944852941178,
      "grad_norm": 1.0279829502105713,
      "learning_rate": 8.252655228758171e-06,
      "loss": 0.0515,
      "step": 5601
    },
    {
      "epoch": 1.2872242647058822,
      "grad_norm": 1.0964986085891724,
      "learning_rate": 8.252144607843137e-06,
      "loss": 0.0609,
      "step": 5602
    },
    {
      "epoch": 1.2874540441176472,
      "grad_norm": 1.0062919855117798,
      "learning_rate": 8.251633986928105e-06,
      "loss": 0.0464,
      "step": 5603
    },
    {
      "epoch": 1.2876838235294117,
      "grad_norm": 1.3185619115829468,
      "learning_rate": 8.251123366013073e-06,
      "loss": 0.0824,
      "step": 5604
    },
    {
      "epoch": 1.2879136029411764,
      "grad_norm": 1.1161597967147827,
      "learning_rate": 8.25061274509804e-06,
      "loss": 0.059,
      "step": 5605
    },
    {
      "epoch": 1.2881433823529411,
      "grad_norm": 1.0503736734390259,
      "learning_rate": 8.250102124183007e-06,
      "loss": 0.0617,
      "step": 5606
    },
    {
      "epoch": 1.2883731617647058,
      "grad_norm": 1.2180529832839966,
      "learning_rate": 8.249591503267975e-06,
      "loss": 0.0753,
      "step": 5607
    },
    {
      "epoch": 1.2886029411764706,
      "grad_norm": 0.6546729803085327,
      "learning_rate": 8.249080882352943e-06,
      "loss": 0.0374,
      "step": 5608
    },
    {
      "epoch": 1.2888327205882353,
      "grad_norm": 1.1201589107513428,
      "learning_rate": 8.248570261437909e-06,
      "loss": 0.0399,
      "step": 5609
    },
    {
      "epoch": 1.2890625,
      "grad_norm": 1.4634371995925903,
      "learning_rate": 8.248059640522877e-06,
      "loss": 0.0649,
      "step": 5610
    },
    {
      "epoch": 1.2892922794117647,
      "grad_norm": 1.2703160047531128,
      "learning_rate": 8.247549019607843e-06,
      "loss": 0.06,
      "step": 5611
    },
    {
      "epoch": 1.2895220588235294,
      "grad_norm": 0.9713066816329956,
      "learning_rate": 8.24703839869281e-06,
      "loss": 0.0587,
      "step": 5612
    },
    {
      "epoch": 1.2897518382352942,
      "grad_norm": 1.1401113271713257,
      "learning_rate": 8.246527777777779e-06,
      "loss": 0.0939,
      "step": 5613
    },
    {
      "epoch": 1.2899816176470589,
      "grad_norm": 0.847531259059906,
      "learning_rate": 8.246017156862745e-06,
      "loss": 0.0583,
      "step": 5614
    },
    {
      "epoch": 1.2902113970588236,
      "grad_norm": 0.774965763092041,
      "learning_rate": 8.245506535947713e-06,
      "loss": 0.0522,
      "step": 5615
    },
    {
      "epoch": 1.2904411764705883,
      "grad_norm": 0.7605330944061279,
      "learning_rate": 8.24499591503268e-06,
      "loss": 0.0479,
      "step": 5616
    },
    {
      "epoch": 1.2906709558823528,
      "grad_norm": 0.8236187696456909,
      "learning_rate": 8.244485294117648e-06,
      "loss": 0.0512,
      "step": 5617
    },
    {
      "epoch": 1.2909007352941178,
      "grad_norm": 0.9670412540435791,
      "learning_rate": 8.243974673202615e-06,
      "loss": 0.0775,
      "step": 5618
    },
    {
      "epoch": 1.2911305147058822,
      "grad_norm": 1.0905520915985107,
      "learning_rate": 8.243464052287582e-06,
      "loss": 0.0738,
      "step": 5619
    },
    {
      "epoch": 1.2913602941176472,
      "grad_norm": 1.0167360305786133,
      "learning_rate": 8.24295343137255e-06,
      "loss": 0.0369,
      "step": 5620
    },
    {
      "epoch": 1.2915900735294117,
      "grad_norm": 1.0782793760299683,
      "learning_rate": 8.242442810457517e-06,
      "loss": 0.0468,
      "step": 5621
    },
    {
      "epoch": 1.2918198529411764,
      "grad_norm": 1.204373836517334,
      "learning_rate": 8.241932189542484e-06,
      "loss": 0.0863,
      "step": 5622
    },
    {
      "epoch": 1.2920496323529411,
      "grad_norm": 0.6511719226837158,
      "learning_rate": 8.24142156862745e-06,
      "loss": 0.0451,
      "step": 5623
    },
    {
      "epoch": 1.2922794117647058,
      "grad_norm": 0.8521256446838379,
      "learning_rate": 8.24091094771242e-06,
      "loss": 0.0617,
      "step": 5624
    },
    {
      "epoch": 1.2925091911764706,
      "grad_norm": 0.9457350969314575,
      "learning_rate": 8.240400326797386e-06,
      "loss": 0.0646,
      "step": 5625
    },
    {
      "epoch": 1.2927389705882353,
      "grad_norm": 1.3154149055480957,
      "learning_rate": 8.239889705882354e-06,
      "loss": 0.0651,
      "step": 5626
    },
    {
      "epoch": 1.29296875,
      "grad_norm": 1.030495524406433,
      "learning_rate": 8.23937908496732e-06,
      "loss": 0.0536,
      "step": 5627
    },
    {
      "epoch": 1.2931985294117647,
      "grad_norm": 0.7877017855644226,
      "learning_rate": 8.238868464052288e-06,
      "loss": 0.0442,
      "step": 5628
    },
    {
      "epoch": 1.2934283088235294,
      "grad_norm": 1.2369993925094604,
      "learning_rate": 8.238357843137256e-06,
      "loss": 0.0673,
      "step": 5629
    },
    {
      "epoch": 1.2936580882352942,
      "grad_norm": 0.9359005093574524,
      "learning_rate": 8.237847222222222e-06,
      "loss": 0.0621,
      "step": 5630
    },
    {
      "epoch": 1.2938878676470589,
      "grad_norm": 0.9736737012863159,
      "learning_rate": 8.23733660130719e-06,
      "loss": 0.0573,
      "step": 5631
    },
    {
      "epoch": 1.2941176470588236,
      "grad_norm": 0.7709298729896545,
      "learning_rate": 8.236825980392158e-06,
      "loss": 0.0774,
      "step": 5632
    },
    {
      "epoch": 1.2943474264705883,
      "grad_norm": 1.358296513557434,
      "learning_rate": 8.236315359477126e-06,
      "loss": 0.0901,
      "step": 5633
    },
    {
      "epoch": 1.2945772058823528,
      "grad_norm": 1.0590366125106812,
      "learning_rate": 8.235804738562092e-06,
      "loss": 0.0482,
      "step": 5634
    },
    {
      "epoch": 1.2948069852941178,
      "grad_norm": 1.2324590682983398,
      "learning_rate": 8.23529411764706e-06,
      "loss": 0.0713,
      "step": 5635
    },
    {
      "epoch": 1.2950367647058822,
      "grad_norm": 0.967950701713562,
      "learning_rate": 8.234783496732028e-06,
      "loss": 0.0454,
      "step": 5636
    },
    {
      "epoch": 1.2952665441176472,
      "grad_norm": 1.1174836158752441,
      "learning_rate": 8.234272875816994e-06,
      "loss": 0.0903,
      "step": 5637
    },
    {
      "epoch": 1.2954963235294117,
      "grad_norm": 1.542839765548706,
      "learning_rate": 8.233762254901962e-06,
      "loss": 0.0664,
      "step": 5638
    },
    {
      "epoch": 1.2957261029411764,
      "grad_norm": 1.0521734952926636,
      "learning_rate": 8.233251633986928e-06,
      "loss": 0.0488,
      "step": 5639
    },
    {
      "epoch": 1.2959558823529411,
      "grad_norm": 0.9069632887840271,
      "learning_rate": 8.232741013071896e-06,
      "loss": 0.0399,
      "step": 5640
    },
    {
      "epoch": 1.2961856617647058,
      "grad_norm": 1.6584160327911377,
      "learning_rate": 8.232230392156864e-06,
      "loss": 0.0658,
      "step": 5641
    },
    {
      "epoch": 1.2964154411764706,
      "grad_norm": 1.296517252922058,
      "learning_rate": 8.231719771241831e-06,
      "loss": 0.0795,
      "step": 5642
    },
    {
      "epoch": 1.2966452205882353,
      "grad_norm": 0.8908182382583618,
      "learning_rate": 8.231209150326798e-06,
      "loss": 0.0786,
      "step": 5643
    },
    {
      "epoch": 1.296875,
      "grad_norm": 1.0380384922027588,
      "learning_rate": 8.230698529411765e-06,
      "loss": 0.0507,
      "step": 5644
    },
    {
      "epoch": 1.2971047794117647,
      "grad_norm": 1.0001221895217896,
      "learning_rate": 8.230187908496733e-06,
      "loss": 0.0585,
      "step": 5645
    },
    {
      "epoch": 1.2973345588235294,
      "grad_norm": 1.3315539360046387,
      "learning_rate": 8.2296772875817e-06,
      "loss": 0.0478,
      "step": 5646
    },
    {
      "epoch": 1.2975643382352942,
      "grad_norm": 1.4587147235870361,
      "learning_rate": 8.229166666666667e-06,
      "loss": 0.0914,
      "step": 5647
    },
    {
      "epoch": 1.2977941176470589,
      "grad_norm": 0.9617758393287659,
      "learning_rate": 8.228656045751635e-06,
      "loss": 0.0512,
      "step": 5648
    },
    {
      "epoch": 1.2980238970588236,
      "grad_norm": 1.1604759693145752,
      "learning_rate": 8.228145424836601e-06,
      "loss": 0.0682,
      "step": 5649
    },
    {
      "epoch": 1.2982536764705883,
      "grad_norm": 1.0032120943069458,
      "learning_rate": 8.22763480392157e-06,
      "loss": 0.0455,
      "step": 5650
    },
    {
      "epoch": 1.2984834558823528,
      "grad_norm": 0.9516404867172241,
      "learning_rate": 8.227124183006535e-06,
      "loss": 0.0659,
      "step": 5651
    },
    {
      "epoch": 1.2987132352941178,
      "grad_norm": 1.292273759841919,
      "learning_rate": 8.226613562091505e-06,
      "loss": 0.0542,
      "step": 5652
    },
    {
      "epoch": 1.2989430147058822,
      "grad_norm": 0.7901824116706848,
      "learning_rate": 8.226102941176471e-06,
      "loss": 0.0315,
      "step": 5653
    },
    {
      "epoch": 1.2991727941176472,
      "grad_norm": 0.8508911728858948,
      "learning_rate": 8.225592320261439e-06,
      "loss": 0.0429,
      "step": 5654
    },
    {
      "epoch": 1.2994025735294117,
      "grad_norm": 0.9542148113250732,
      "learning_rate": 8.225081699346405e-06,
      "loss": 0.069,
      "step": 5655
    },
    {
      "epoch": 1.2996323529411764,
      "grad_norm": 0.7717152833938599,
      "learning_rate": 8.224571078431373e-06,
      "loss": 0.038,
      "step": 5656
    },
    {
      "epoch": 1.2998621323529411,
      "grad_norm": 0.7532967329025269,
      "learning_rate": 8.224060457516341e-06,
      "loss": 0.0383,
      "step": 5657
    },
    {
      "epoch": 1.3000919117647058,
      "grad_norm": 1.262915849685669,
      "learning_rate": 8.223549836601307e-06,
      "loss": 0.0773,
      "step": 5658
    },
    {
      "epoch": 1.3003216911764706,
      "grad_norm": 0.8432262539863586,
      "learning_rate": 8.223039215686275e-06,
      "loss": 0.0596,
      "step": 5659
    },
    {
      "epoch": 1.3005514705882353,
      "grad_norm": 0.7147992849349976,
      "learning_rate": 8.222528594771243e-06,
      "loss": 0.0439,
      "step": 5660
    },
    {
      "epoch": 1.30078125,
      "grad_norm": 1.3137162923812866,
      "learning_rate": 8.22201797385621e-06,
      "loss": 0.0754,
      "step": 5661
    },
    {
      "epoch": 1.3010110294117647,
      "grad_norm": 1.1306496858596802,
      "learning_rate": 8.221507352941177e-06,
      "loss": 0.0626,
      "step": 5662
    },
    {
      "epoch": 1.3012408088235294,
      "grad_norm": 0.9981966018676758,
      "learning_rate": 8.220996732026145e-06,
      "loss": 0.068,
      "step": 5663
    },
    {
      "epoch": 1.3014705882352942,
      "grad_norm": 0.8542904853820801,
      "learning_rate": 8.220486111111113e-06,
      "loss": 0.0616,
      "step": 5664
    },
    {
      "epoch": 1.3017003676470589,
      "grad_norm": 0.9173860549926758,
      "learning_rate": 8.219975490196079e-06,
      "loss": 0.0439,
      "step": 5665
    },
    {
      "epoch": 1.3019301470588236,
      "grad_norm": 1.406200647354126,
      "learning_rate": 8.219464869281047e-06,
      "loss": 0.075,
      "step": 5666
    },
    {
      "epoch": 1.3021599264705883,
      "grad_norm": 1.501395583152771,
      "learning_rate": 8.218954248366013e-06,
      "loss": 0.0583,
      "step": 5667
    },
    {
      "epoch": 1.3023897058823528,
      "grad_norm": 1.0727081298828125,
      "learning_rate": 8.218443627450982e-06,
      "loss": 0.0576,
      "step": 5668
    },
    {
      "epoch": 1.3026194852941178,
      "grad_norm": 0.8615714907646179,
      "learning_rate": 8.217933006535948e-06,
      "loss": 0.0537,
      "step": 5669
    },
    {
      "epoch": 1.3028492647058822,
      "grad_norm": 1.009352684020996,
      "learning_rate": 8.217422385620916e-06,
      "loss": 0.0511,
      "step": 5670
    },
    {
      "epoch": 1.3030790441176472,
      "grad_norm": 0.9867951273918152,
      "learning_rate": 8.216911764705882e-06,
      "loss": 0.0476,
      "step": 5671
    },
    {
      "epoch": 1.3033088235294117,
      "grad_norm": 0.8526186943054199,
      "learning_rate": 8.21640114379085e-06,
      "loss": 0.0292,
      "step": 5672
    },
    {
      "epoch": 1.3035386029411764,
      "grad_norm": 1.0255601406097412,
      "learning_rate": 8.215890522875818e-06,
      "loss": 0.0709,
      "step": 5673
    },
    {
      "epoch": 1.3037683823529411,
      "grad_norm": 0.7967903017997742,
      "learning_rate": 8.215379901960784e-06,
      "loss": 0.0505,
      "step": 5674
    },
    {
      "epoch": 1.3039981617647058,
      "grad_norm": 0.7489582896232605,
      "learning_rate": 8.214869281045752e-06,
      "loss": 0.052,
      "step": 5675
    },
    {
      "epoch": 1.3042279411764706,
      "grad_norm": 0.7059158086776733,
      "learning_rate": 8.21435866013072e-06,
      "loss": 0.0384,
      "step": 5676
    },
    {
      "epoch": 1.3044577205882353,
      "grad_norm": 1.3449362516403198,
      "learning_rate": 8.213848039215688e-06,
      "loss": 0.0775,
      "step": 5677
    },
    {
      "epoch": 1.3046875,
      "grad_norm": 0.9941747784614563,
      "learning_rate": 8.213337418300654e-06,
      "loss": 0.0526,
      "step": 5678
    },
    {
      "epoch": 1.3049172794117647,
      "grad_norm": 0.8137081861495972,
      "learning_rate": 8.212826797385622e-06,
      "loss": 0.0588,
      "step": 5679
    },
    {
      "epoch": 1.3051470588235294,
      "grad_norm": 1.1876599788665771,
      "learning_rate": 8.21231617647059e-06,
      "loss": 0.0722,
      "step": 5680
    },
    {
      "epoch": 1.3053768382352942,
      "grad_norm": 0.7993106245994568,
      "learning_rate": 8.211805555555556e-06,
      "loss": 0.0531,
      "step": 5681
    },
    {
      "epoch": 1.3056066176470589,
      "grad_norm": 1.159312129020691,
      "learning_rate": 8.211294934640524e-06,
      "loss": 0.0593,
      "step": 5682
    },
    {
      "epoch": 1.3058363970588236,
      "grad_norm": 1.0041691064834595,
      "learning_rate": 8.21078431372549e-06,
      "loss": 0.0614,
      "step": 5683
    },
    {
      "epoch": 1.3060661764705883,
      "grad_norm": 0.797968864440918,
      "learning_rate": 8.210273692810458e-06,
      "loss": 0.0433,
      "step": 5684
    },
    {
      "epoch": 1.3062959558823528,
      "grad_norm": 0.9619544148445129,
      "learning_rate": 8.209763071895426e-06,
      "loss": 0.0554,
      "step": 5685
    },
    {
      "epoch": 1.3065257352941178,
      "grad_norm": 0.9708620309829712,
      "learning_rate": 8.209252450980394e-06,
      "loss": 0.0406,
      "step": 5686
    },
    {
      "epoch": 1.3067555147058822,
      "grad_norm": 0.909702479839325,
      "learning_rate": 8.20874183006536e-06,
      "loss": 0.0445,
      "step": 5687
    },
    {
      "epoch": 1.3069852941176472,
      "grad_norm": 0.8063732981681824,
      "learning_rate": 8.208231209150328e-06,
      "loss": 0.0636,
      "step": 5688
    },
    {
      "epoch": 1.3072150735294117,
      "grad_norm": 1.031772255897522,
      "learning_rate": 8.207720588235296e-06,
      "loss": 0.0736,
      "step": 5689
    },
    {
      "epoch": 1.3074448529411764,
      "grad_norm": 1.183221697807312,
      "learning_rate": 8.207209967320262e-06,
      "loss": 0.0519,
      "step": 5690
    },
    {
      "epoch": 1.3076746323529411,
      "grad_norm": 1.1467317342758179,
      "learning_rate": 8.20669934640523e-06,
      "loss": 0.0626,
      "step": 5691
    },
    {
      "epoch": 1.3079044117647058,
      "grad_norm": 1.0998055934906006,
      "learning_rate": 8.206188725490197e-06,
      "loss": 0.0629,
      "step": 5692
    },
    {
      "epoch": 1.3081341911764706,
      "grad_norm": 1.0516082048416138,
      "learning_rate": 8.205678104575164e-06,
      "loss": 0.0661,
      "step": 5693
    },
    {
      "epoch": 1.3083639705882353,
      "grad_norm": 1.261647343635559,
      "learning_rate": 8.205167483660131e-06,
      "loss": 0.076,
      "step": 5694
    },
    {
      "epoch": 1.30859375,
      "grad_norm": 0.8563327789306641,
      "learning_rate": 8.204656862745098e-06,
      "loss": 0.042,
      "step": 5695
    },
    {
      "epoch": 1.3088235294117647,
      "grad_norm": 1.3930450677871704,
      "learning_rate": 8.204146241830067e-06,
      "loss": 0.0773,
      "step": 5696
    },
    {
      "epoch": 1.3090533088235294,
      "grad_norm": 0.7641754746437073,
      "learning_rate": 8.203635620915033e-06,
      "loss": 0.0439,
      "step": 5697
    },
    {
      "epoch": 1.3092830882352942,
      "grad_norm": 0.9777988195419312,
      "learning_rate": 8.203125000000001e-06,
      "loss": 0.0488,
      "step": 5698
    },
    {
      "epoch": 1.3095128676470589,
      "grad_norm": 0.8019568920135498,
      "learning_rate": 8.202614379084967e-06,
      "loss": 0.0466,
      "step": 5699
    },
    {
      "epoch": 1.3097426470588236,
      "grad_norm": 1.1162794828414917,
      "learning_rate": 8.202103758169935e-06,
      "loss": 0.0582,
      "step": 5700
    },
    {
      "epoch": 1.3099724264705883,
      "grad_norm": 0.6400005221366882,
      "learning_rate": 8.201593137254903e-06,
      "loss": 0.0407,
      "step": 5701
    },
    {
      "epoch": 1.3102022058823528,
      "grad_norm": 0.7073257565498352,
      "learning_rate": 8.20108251633987e-06,
      "loss": 0.0517,
      "step": 5702
    },
    {
      "epoch": 1.3104319852941178,
      "grad_norm": 0.9392056465148926,
      "learning_rate": 8.200571895424837e-06,
      "loss": 0.0608,
      "step": 5703
    },
    {
      "epoch": 1.3106617647058822,
      "grad_norm": 0.6977471709251404,
      "learning_rate": 8.200061274509803e-06,
      "loss": 0.0443,
      "step": 5704
    },
    {
      "epoch": 1.3108915441176472,
      "grad_norm": 0.8684768080711365,
      "learning_rate": 8.199550653594773e-06,
      "loss": 0.0553,
      "step": 5705
    },
    {
      "epoch": 1.3111213235294117,
      "grad_norm": 1.1248093843460083,
      "learning_rate": 8.199040032679739e-06,
      "loss": 0.0613,
      "step": 5706
    },
    {
      "epoch": 1.3113511029411764,
      "grad_norm": 0.9032496809959412,
      "learning_rate": 8.198529411764707e-06,
      "loss": 0.0597,
      "step": 5707
    },
    {
      "epoch": 1.3115808823529411,
      "grad_norm": 1.2181371450424194,
      "learning_rate": 8.198018790849673e-06,
      "loss": 0.0798,
      "step": 5708
    },
    {
      "epoch": 1.3118106617647058,
      "grad_norm": 0.673816442489624,
      "learning_rate": 8.197508169934641e-06,
      "loss": 0.028,
      "step": 5709
    },
    {
      "epoch": 1.3120404411764706,
      "grad_norm": 0.9424536824226379,
      "learning_rate": 8.196997549019609e-06,
      "loss": 0.0746,
      "step": 5710
    },
    {
      "epoch": 1.3122702205882353,
      "grad_norm": 1.026293396949768,
      "learning_rate": 8.196486928104575e-06,
      "loss": 0.0635,
      "step": 5711
    },
    {
      "epoch": 1.3125,
      "grad_norm": 1.1354840993881226,
      "learning_rate": 8.195976307189543e-06,
      "loss": 0.0346,
      "step": 5712
    },
    {
      "epoch": 1.3127297794117647,
      "grad_norm": 0.9818638563156128,
      "learning_rate": 8.19546568627451e-06,
      "loss": 0.083,
      "step": 5713
    },
    {
      "epoch": 1.3129595588235294,
      "grad_norm": 0.864832878112793,
      "learning_rate": 8.194955065359479e-06,
      "loss": 0.0369,
      "step": 5714
    },
    {
      "epoch": 1.3131893382352942,
      "grad_norm": 0.8272003531455994,
      "learning_rate": 8.194444444444445e-06,
      "loss": 0.0571,
      "step": 5715
    },
    {
      "epoch": 1.3134191176470589,
      "grad_norm": 0.9807893633842468,
      "learning_rate": 8.193933823529413e-06,
      "loss": 0.0443,
      "step": 5716
    },
    {
      "epoch": 1.3136488970588236,
      "grad_norm": 0.7177765369415283,
      "learning_rate": 8.19342320261438e-06,
      "loss": 0.0385,
      "step": 5717
    },
    {
      "epoch": 1.3138786764705883,
      "grad_norm": 0.9184114933013916,
      "learning_rate": 8.192912581699347e-06,
      "loss": 0.0444,
      "step": 5718
    },
    {
      "epoch": 1.3141084558823528,
      "grad_norm": 0.8245805501937866,
      "learning_rate": 8.192401960784314e-06,
      "loss": 0.0574,
      "step": 5719
    },
    {
      "epoch": 1.3143382352941178,
      "grad_norm": 0.815019965171814,
      "learning_rate": 8.19189133986928e-06,
      "loss": 0.0642,
      "step": 5720
    },
    {
      "epoch": 1.3145680147058822,
      "grad_norm": 1.143540859222412,
      "learning_rate": 8.19138071895425e-06,
      "loss": 0.0803,
      "step": 5721
    },
    {
      "epoch": 1.3147977941176472,
      "grad_norm": 0.8633673191070557,
      "learning_rate": 8.190870098039216e-06,
      "loss": 0.0488,
      "step": 5722
    },
    {
      "epoch": 1.3150275735294117,
      "grad_norm": 1.3799399137496948,
      "learning_rate": 8.190359477124184e-06,
      "loss": 0.1382,
      "step": 5723
    },
    {
      "epoch": 1.3152573529411764,
      "grad_norm": 0.8275538086891174,
      "learning_rate": 8.18984885620915e-06,
      "loss": 0.0548,
      "step": 5724
    },
    {
      "epoch": 1.3154871323529411,
      "grad_norm": 0.8993952870368958,
      "learning_rate": 8.189338235294118e-06,
      "loss": 0.0536,
      "step": 5725
    },
    {
      "epoch": 1.3157169117647058,
      "grad_norm": 0.819538414478302,
      "learning_rate": 8.188827614379086e-06,
      "loss": 0.0392,
      "step": 5726
    },
    {
      "epoch": 1.3159466911764706,
      "grad_norm": 1.2458715438842773,
      "learning_rate": 8.188316993464052e-06,
      "loss": 0.0702,
      "step": 5727
    },
    {
      "epoch": 1.3161764705882353,
      "grad_norm": 1.134264588356018,
      "learning_rate": 8.18780637254902e-06,
      "loss": 0.0602,
      "step": 5728
    },
    {
      "epoch": 1.31640625,
      "grad_norm": 1.0828319787979126,
      "learning_rate": 8.187295751633988e-06,
      "loss": 0.0699,
      "step": 5729
    },
    {
      "epoch": 1.3166360294117647,
      "grad_norm": 0.8565201759338379,
      "learning_rate": 8.186785130718956e-06,
      "loss": 0.0493,
      "step": 5730
    },
    {
      "epoch": 1.3168658088235294,
      "grad_norm": 0.8074900507926941,
      "learning_rate": 8.186274509803922e-06,
      "loss": 0.0371,
      "step": 5731
    },
    {
      "epoch": 1.3170955882352942,
      "grad_norm": 1.172269582748413,
      "learning_rate": 8.18576388888889e-06,
      "loss": 0.0572,
      "step": 5732
    },
    {
      "epoch": 1.3173253676470589,
      "grad_norm": 1.0688556432724,
      "learning_rate": 8.185253267973858e-06,
      "loss": 0.0824,
      "step": 5733
    },
    {
      "epoch": 1.3175551470588236,
      "grad_norm": 0.9705619812011719,
      "learning_rate": 8.184742647058824e-06,
      "loss": 0.0398,
      "step": 5734
    },
    {
      "epoch": 1.3177849264705883,
      "grad_norm": 0.7672690749168396,
      "learning_rate": 8.184232026143792e-06,
      "loss": 0.0389,
      "step": 5735
    },
    {
      "epoch": 1.3180147058823528,
      "grad_norm": 0.7870618104934692,
      "learning_rate": 8.183721405228758e-06,
      "loss": 0.0331,
      "step": 5736
    },
    {
      "epoch": 1.3182444852941178,
      "grad_norm": 1.0719914436340332,
      "learning_rate": 8.183210784313726e-06,
      "loss": 0.0422,
      "step": 5737
    },
    {
      "epoch": 1.3184742647058822,
      "grad_norm": 1.0665072202682495,
      "learning_rate": 8.182700163398694e-06,
      "loss": 0.0577,
      "step": 5738
    },
    {
      "epoch": 1.3187040441176472,
      "grad_norm": 0.9168238639831543,
      "learning_rate": 8.18218954248366e-06,
      "loss": 0.0473,
      "step": 5739
    },
    {
      "epoch": 1.3189338235294117,
      "grad_norm": 0.9700258374214172,
      "learning_rate": 8.181678921568628e-06,
      "loss": 0.0471,
      "step": 5740
    },
    {
      "epoch": 1.3191636029411764,
      "grad_norm": 0.9561551213264465,
      "learning_rate": 8.181168300653596e-06,
      "loss": 0.0646,
      "step": 5741
    },
    {
      "epoch": 1.3193933823529411,
      "grad_norm": 0.8913062810897827,
      "learning_rate": 8.180657679738563e-06,
      "loss": 0.0587,
      "step": 5742
    },
    {
      "epoch": 1.3196231617647058,
      "grad_norm": 0.9140807390213013,
      "learning_rate": 8.18014705882353e-06,
      "loss": 0.0658,
      "step": 5743
    },
    {
      "epoch": 1.3198529411764706,
      "grad_norm": 0.8455119729042053,
      "learning_rate": 8.179636437908497e-06,
      "loss": 0.0588,
      "step": 5744
    },
    {
      "epoch": 1.3200827205882353,
      "grad_norm": 0.8881927132606506,
      "learning_rate": 8.179125816993465e-06,
      "loss": 0.0498,
      "step": 5745
    },
    {
      "epoch": 1.3203125,
      "grad_norm": 1.0318405628204346,
      "learning_rate": 8.178615196078431e-06,
      "loss": 0.0479,
      "step": 5746
    },
    {
      "epoch": 1.3205422794117647,
      "grad_norm": 0.7330264449119568,
      "learning_rate": 8.1781045751634e-06,
      "loss": 0.0415,
      "step": 5747
    },
    {
      "epoch": 1.3207720588235294,
      "grad_norm": 1.0780383348464966,
      "learning_rate": 8.177593954248365e-06,
      "loss": 0.0624,
      "step": 5748
    },
    {
      "epoch": 1.3210018382352942,
      "grad_norm": 0.8585669994354248,
      "learning_rate": 8.177083333333335e-06,
      "loss": 0.0481,
      "step": 5749
    },
    {
      "epoch": 1.3212316176470589,
      "grad_norm": 1.1354173421859741,
      "learning_rate": 8.176572712418301e-06,
      "loss": 0.0553,
      "step": 5750
    },
    {
      "epoch": 1.3214613970588236,
      "grad_norm": 1.0462721586227417,
      "learning_rate": 8.176062091503269e-06,
      "loss": 0.0554,
      "step": 5751
    },
    {
      "epoch": 1.3216911764705883,
      "grad_norm": 1.2945623397827148,
      "learning_rate": 8.175551470588235e-06,
      "loss": 0.0648,
      "step": 5752
    },
    {
      "epoch": 1.3219209558823528,
      "grad_norm": 0.8806427121162415,
      "learning_rate": 8.175040849673203e-06,
      "loss": 0.0435,
      "step": 5753
    },
    {
      "epoch": 1.3221507352941178,
      "grad_norm": 1.2179217338562012,
      "learning_rate": 8.174530228758171e-06,
      "loss": 0.0515,
      "step": 5754
    },
    {
      "epoch": 1.3223805147058822,
      "grad_norm": 0.809651792049408,
      "learning_rate": 8.174019607843137e-06,
      "loss": 0.0519,
      "step": 5755
    },
    {
      "epoch": 1.3226102941176472,
      "grad_norm": 1.7423845529556274,
      "learning_rate": 8.173508986928105e-06,
      "loss": 0.089,
      "step": 5756
    },
    {
      "epoch": 1.3228400735294117,
      "grad_norm": 0.989510178565979,
      "learning_rate": 8.172998366013073e-06,
      "loss": 0.0424,
      "step": 5757
    },
    {
      "epoch": 1.3230698529411764,
      "grad_norm": 1.2176272869110107,
      "learning_rate": 8.17248774509804e-06,
      "loss": 0.0723,
      "step": 5758
    },
    {
      "epoch": 1.3232996323529411,
      "grad_norm": 1.1300146579742432,
      "learning_rate": 8.171977124183007e-06,
      "loss": 0.0611,
      "step": 5759
    },
    {
      "epoch": 1.3235294117647058,
      "grad_norm": 0.8062114715576172,
      "learning_rate": 8.171466503267975e-06,
      "loss": 0.0571,
      "step": 5760
    },
    {
      "epoch": 1.3237591911764706,
      "grad_norm": 0.9294091463088989,
      "learning_rate": 8.170955882352943e-06,
      "loss": 0.0474,
      "step": 5761
    },
    {
      "epoch": 1.3239889705882353,
      "grad_norm": 1.0706678628921509,
      "learning_rate": 8.170445261437909e-06,
      "loss": 0.0656,
      "step": 5762
    },
    {
      "epoch": 1.32421875,
      "grad_norm": 1.0083056688308716,
      "learning_rate": 8.169934640522877e-06,
      "loss": 0.0479,
      "step": 5763
    },
    {
      "epoch": 1.3244485294117647,
      "grad_norm": 0.7741666436195374,
      "learning_rate": 8.169424019607843e-06,
      "loss": 0.0574,
      "step": 5764
    },
    {
      "epoch": 1.3246783088235294,
      "grad_norm": 1.1314610242843628,
      "learning_rate": 8.168913398692812e-06,
      "loss": 0.0604,
      "step": 5765
    },
    {
      "epoch": 1.3249080882352942,
      "grad_norm": 1.054320216178894,
      "learning_rate": 8.168402777777778e-06,
      "loss": 0.0597,
      "step": 5766
    },
    {
      "epoch": 1.3251378676470589,
      "grad_norm": 0.9495782256126404,
      "learning_rate": 8.167892156862746e-06,
      "loss": 0.0642,
      "step": 5767
    },
    {
      "epoch": 1.3253676470588236,
      "grad_norm": 1.0878316164016724,
      "learning_rate": 8.167381535947713e-06,
      "loss": 0.0553,
      "step": 5768
    },
    {
      "epoch": 1.3255974264705883,
      "grad_norm": 1.0869383811950684,
      "learning_rate": 8.16687091503268e-06,
      "loss": 0.0875,
      "step": 5769
    },
    {
      "epoch": 1.3258272058823528,
      "grad_norm": 1.204099178314209,
      "learning_rate": 8.166360294117648e-06,
      "loss": 0.0692,
      "step": 5770
    },
    {
      "epoch": 1.3260569852941178,
      "grad_norm": 1.0512466430664062,
      "learning_rate": 8.165849673202614e-06,
      "loss": 0.0699,
      "step": 5771
    },
    {
      "epoch": 1.3262867647058822,
      "grad_norm": 1.0217599868774414,
      "learning_rate": 8.165339052287582e-06,
      "loss": 0.0741,
      "step": 5772
    },
    {
      "epoch": 1.3265165441176472,
      "grad_norm": 0.9587542414665222,
      "learning_rate": 8.16482843137255e-06,
      "loss": 0.0419,
      "step": 5773
    },
    {
      "epoch": 1.3267463235294117,
      "grad_norm": 1.6854894161224365,
      "learning_rate": 8.164317810457516e-06,
      "loss": 0.1016,
      "step": 5774
    },
    {
      "epoch": 1.3269761029411764,
      "grad_norm": 0.919781506061554,
      "learning_rate": 8.163807189542484e-06,
      "loss": 0.0503,
      "step": 5775
    },
    {
      "epoch": 1.3272058823529411,
      "grad_norm": 1.300905704498291,
      "learning_rate": 8.163296568627452e-06,
      "loss": 0.0516,
      "step": 5776
    },
    {
      "epoch": 1.3274356617647058,
      "grad_norm": 1.0121406316757202,
      "learning_rate": 8.16278594771242e-06,
      "loss": 0.0735,
      "step": 5777
    },
    {
      "epoch": 1.3276654411764706,
      "grad_norm": 1.167015790939331,
      "learning_rate": 8.162275326797386e-06,
      "loss": 0.051,
      "step": 5778
    },
    {
      "epoch": 1.3278952205882353,
      "grad_norm": 0.9308843016624451,
      "learning_rate": 8.161764705882354e-06,
      "loss": 0.0421,
      "step": 5779
    },
    {
      "epoch": 1.328125,
      "grad_norm": 1.2093331813812256,
      "learning_rate": 8.16125408496732e-06,
      "loss": 0.0693,
      "step": 5780
    },
    {
      "epoch": 1.3283547794117647,
      "grad_norm": 0.9490796327590942,
      "learning_rate": 8.160743464052288e-06,
      "loss": 0.0604,
      "step": 5781
    },
    {
      "epoch": 1.3285845588235294,
      "grad_norm": 0.8528600931167603,
      "learning_rate": 8.160232843137256e-06,
      "loss": 0.0524,
      "step": 5782
    },
    {
      "epoch": 1.3288143382352942,
      "grad_norm": 1.1266289949417114,
      "learning_rate": 8.159722222222222e-06,
      "loss": 0.0932,
      "step": 5783
    },
    {
      "epoch": 1.3290441176470589,
      "grad_norm": 1.036328673362732,
      "learning_rate": 8.15921160130719e-06,
      "loss": 0.0637,
      "step": 5784
    },
    {
      "epoch": 1.3292738970588236,
      "grad_norm": 1.0821560621261597,
      "learning_rate": 8.158700980392158e-06,
      "loss": 0.054,
      "step": 5785
    },
    {
      "epoch": 1.3295036764705883,
      "grad_norm": 1.3851007223129272,
      "learning_rate": 8.158190359477126e-06,
      "loss": 0.0539,
      "step": 5786
    },
    {
      "epoch": 1.3297334558823528,
      "grad_norm": 1.0696252584457397,
      "learning_rate": 8.157679738562092e-06,
      "loss": 0.0616,
      "step": 5787
    },
    {
      "epoch": 1.3299632352941178,
      "grad_norm": 0.9587259888648987,
      "learning_rate": 8.15716911764706e-06,
      "loss": 0.0429,
      "step": 5788
    },
    {
      "epoch": 1.3301930147058822,
      "grad_norm": 1.0538467168807983,
      "learning_rate": 8.156658496732027e-06,
      "loss": 0.0608,
      "step": 5789
    },
    {
      "epoch": 1.3304227941176472,
      "grad_norm": 0.912360668182373,
      "learning_rate": 8.156147875816994e-06,
      "loss": 0.0556,
      "step": 5790
    },
    {
      "epoch": 1.3306525735294117,
      "grad_norm": 0.8371794819831848,
      "learning_rate": 8.155637254901961e-06,
      "loss": 0.0372,
      "step": 5791
    },
    {
      "epoch": 1.3308823529411764,
      "grad_norm": 0.6588547229766846,
      "learning_rate": 8.155126633986928e-06,
      "loss": 0.0392,
      "step": 5792
    },
    {
      "epoch": 1.3311121323529411,
      "grad_norm": 0.8581386804580688,
      "learning_rate": 8.154616013071897e-06,
      "loss": 0.0375,
      "step": 5793
    },
    {
      "epoch": 1.3313419117647058,
      "grad_norm": 1.056643009185791,
      "learning_rate": 8.154105392156863e-06,
      "loss": 0.0506,
      "step": 5794
    },
    {
      "epoch": 1.3315716911764706,
      "grad_norm": 0.9268002510070801,
      "learning_rate": 8.153594771241831e-06,
      "loss": 0.0426,
      "step": 5795
    },
    {
      "epoch": 1.3318014705882353,
      "grad_norm": 1.1809123754501343,
      "learning_rate": 8.153084150326797e-06,
      "loss": 0.0666,
      "step": 5796
    },
    {
      "epoch": 1.33203125,
      "grad_norm": 0.7856206297874451,
      "learning_rate": 8.152573529411765e-06,
      "loss": 0.0348,
      "step": 5797
    },
    {
      "epoch": 1.3322610294117647,
      "grad_norm": 1.2104535102844238,
      "learning_rate": 8.152062908496733e-06,
      "loss": 0.085,
      "step": 5798
    },
    {
      "epoch": 1.3324908088235294,
      "grad_norm": 0.9395245909690857,
      "learning_rate": 8.1515522875817e-06,
      "loss": 0.0367,
      "step": 5799
    },
    {
      "epoch": 1.3327205882352942,
      "grad_norm": 1.1575337648391724,
      "learning_rate": 8.151041666666667e-06,
      "loss": 0.0979,
      "step": 5800
    },
    {
      "epoch": 1.3329503676470589,
      "grad_norm": 0.9024525880813599,
      "learning_rate": 8.150531045751635e-06,
      "loss": 0.0441,
      "step": 5801
    },
    {
      "epoch": 1.3331801470588236,
      "grad_norm": 1.4924966096878052,
      "learning_rate": 8.150020424836603e-06,
      "loss": 0.0787,
      "step": 5802
    },
    {
      "epoch": 1.3334099264705883,
      "grad_norm": 0.9591372013092041,
      "learning_rate": 8.149509803921569e-06,
      "loss": 0.0594,
      "step": 5803
    },
    {
      "epoch": 1.3336397058823528,
      "grad_norm": 1.3065303564071655,
      "learning_rate": 8.148999183006537e-06,
      "loss": 0.09,
      "step": 5804
    },
    {
      "epoch": 1.3338694852941178,
      "grad_norm": 1.2259584665298462,
      "learning_rate": 8.148488562091505e-06,
      "loss": 0.0781,
      "step": 5805
    },
    {
      "epoch": 1.3340992647058822,
      "grad_norm": 0.9553059339523315,
      "learning_rate": 8.147977941176471e-06,
      "loss": 0.0565,
      "step": 5806
    },
    {
      "epoch": 1.3343290441176472,
      "grad_norm": 0.8833152651786804,
      "learning_rate": 8.147467320261439e-06,
      "loss": 0.0575,
      "step": 5807
    },
    {
      "epoch": 1.3345588235294117,
      "grad_norm": 1.1202936172485352,
      "learning_rate": 8.146956699346405e-06,
      "loss": 0.068,
      "step": 5808
    },
    {
      "epoch": 1.3347886029411764,
      "grad_norm": 1.110783576965332,
      "learning_rate": 8.146446078431375e-06,
      "loss": 0.0677,
      "step": 5809
    },
    {
      "epoch": 1.3350183823529411,
      "grad_norm": 1.1772594451904297,
      "learning_rate": 8.14593545751634e-06,
      "loss": 0.0524,
      "step": 5810
    },
    {
      "epoch": 1.3352481617647058,
      "grad_norm": 1.2455946207046509,
      "learning_rate": 8.145424836601309e-06,
      "loss": 0.0606,
      "step": 5811
    },
    {
      "epoch": 1.3354779411764706,
      "grad_norm": 0.8996854424476624,
      "learning_rate": 8.144914215686275e-06,
      "loss": 0.0475,
      "step": 5812
    },
    {
      "epoch": 1.3357077205882353,
      "grad_norm": 1.1202614307403564,
      "learning_rate": 8.144403594771243e-06,
      "loss": 0.0612,
      "step": 5813
    },
    {
      "epoch": 1.3359375,
      "grad_norm": 0.9306919574737549,
      "learning_rate": 8.14389297385621e-06,
      "loss": 0.0466,
      "step": 5814
    },
    {
      "epoch": 1.3361672794117647,
      "grad_norm": 0.8148300647735596,
      "learning_rate": 8.143382352941177e-06,
      "loss": 0.031,
      "step": 5815
    },
    {
      "epoch": 1.3363970588235294,
      "grad_norm": 0.7975063920021057,
      "learning_rate": 8.142871732026144e-06,
      "loss": 0.0448,
      "step": 5816
    },
    {
      "epoch": 1.3366268382352942,
      "grad_norm": 1.1211931705474854,
      "learning_rate": 8.142361111111112e-06,
      "loss": 0.0497,
      "step": 5817
    },
    {
      "epoch": 1.3368566176470589,
      "grad_norm": 0.9853481650352478,
      "learning_rate": 8.141850490196078e-06,
      "loss": 0.0727,
      "step": 5818
    },
    {
      "epoch": 1.3370863970588236,
      "grad_norm": 0.9415632486343384,
      "learning_rate": 8.141339869281046e-06,
      "loss": 0.057,
      "step": 5819
    },
    {
      "epoch": 1.3373161764705883,
      "grad_norm": 0.9240140914916992,
      "learning_rate": 8.140829248366014e-06,
      "loss": 0.0667,
      "step": 5820
    },
    {
      "epoch": 1.3375459558823528,
      "grad_norm": 1.3188432455062866,
      "learning_rate": 8.140318627450982e-06,
      "loss": 0.0638,
      "step": 5821
    },
    {
      "epoch": 1.3377757352941178,
      "grad_norm": 0.9210699200630188,
      "learning_rate": 8.139808006535948e-06,
      "loss": 0.0604,
      "step": 5822
    },
    {
      "epoch": 1.3380055147058822,
      "grad_norm": 0.9716751575469971,
      "learning_rate": 8.139297385620916e-06,
      "loss": 0.0745,
      "step": 5823
    },
    {
      "epoch": 1.3382352941176472,
      "grad_norm": 1.0309453010559082,
      "learning_rate": 8.138786764705882e-06,
      "loss": 0.0584,
      "step": 5824
    },
    {
      "epoch": 1.3384650735294117,
      "grad_norm": 1.2934974431991577,
      "learning_rate": 8.13827614379085e-06,
      "loss": 0.0732,
      "step": 5825
    },
    {
      "epoch": 1.3386948529411764,
      "grad_norm": 0.8592711091041565,
      "learning_rate": 8.137765522875818e-06,
      "loss": 0.0371,
      "step": 5826
    },
    {
      "epoch": 1.3389246323529411,
      "grad_norm": 0.9086926579475403,
      "learning_rate": 8.137254901960784e-06,
      "loss": 0.0507,
      "step": 5827
    },
    {
      "epoch": 1.3391544117647058,
      "grad_norm": 0.8519256711006165,
      "learning_rate": 8.136744281045752e-06,
      "loss": 0.0418,
      "step": 5828
    },
    {
      "epoch": 1.3393841911764706,
      "grad_norm": 1.0968297719955444,
      "learning_rate": 8.13623366013072e-06,
      "loss": 0.0549,
      "step": 5829
    },
    {
      "epoch": 1.3396139705882353,
      "grad_norm": 1.243903398513794,
      "learning_rate": 8.135723039215688e-06,
      "loss": 0.0847,
      "step": 5830
    },
    {
      "epoch": 1.33984375,
      "grad_norm": 1.1776949167251587,
      "learning_rate": 8.135212418300654e-06,
      "loss": 0.0627,
      "step": 5831
    },
    {
      "epoch": 1.3400735294117647,
      "grad_norm": 1.1391841173171997,
      "learning_rate": 8.134701797385622e-06,
      "loss": 0.0703,
      "step": 5832
    },
    {
      "epoch": 1.3403033088235294,
      "grad_norm": 0.9524810910224915,
      "learning_rate": 8.13419117647059e-06,
      "loss": 0.0649,
      "step": 5833
    },
    {
      "epoch": 1.3405330882352942,
      "grad_norm": 0.7454007267951965,
      "learning_rate": 8.133680555555556e-06,
      "loss": 0.0554,
      "step": 5834
    },
    {
      "epoch": 1.3407628676470589,
      "grad_norm": 1.1718418598175049,
      "learning_rate": 8.133169934640524e-06,
      "loss": 0.0563,
      "step": 5835
    },
    {
      "epoch": 1.3409926470588236,
      "grad_norm": 1.2215871810913086,
      "learning_rate": 8.13265931372549e-06,
      "loss": 0.0703,
      "step": 5836
    },
    {
      "epoch": 1.3412224264705883,
      "grad_norm": 1.0474177598953247,
      "learning_rate": 8.13214869281046e-06,
      "loss": 0.0508,
      "step": 5837
    },
    {
      "epoch": 1.3414522058823528,
      "grad_norm": 1.0156505107879639,
      "learning_rate": 8.131638071895426e-06,
      "loss": 0.0547,
      "step": 5838
    },
    {
      "epoch": 1.3416819852941178,
      "grad_norm": 1.1803346872329712,
      "learning_rate": 8.131127450980393e-06,
      "loss": 0.0647,
      "step": 5839
    },
    {
      "epoch": 1.3419117647058822,
      "grad_norm": 1.1326171159744263,
      "learning_rate": 8.13061683006536e-06,
      "loss": 0.0554,
      "step": 5840
    },
    {
      "epoch": 1.3421415441176472,
      "grad_norm": 1.1196922063827515,
      "learning_rate": 8.130106209150327e-06,
      "loss": 0.0601,
      "step": 5841
    },
    {
      "epoch": 1.3423713235294117,
      "grad_norm": 0.9624509811401367,
      "learning_rate": 8.129595588235295e-06,
      "loss": 0.0536,
      "step": 5842
    },
    {
      "epoch": 1.3426011029411764,
      "grad_norm": 0.9873436093330383,
      "learning_rate": 8.129084967320261e-06,
      "loss": 0.06,
      "step": 5843
    },
    {
      "epoch": 1.3428308823529411,
      "grad_norm": 0.7846643328666687,
      "learning_rate": 8.12857434640523e-06,
      "loss": 0.0441,
      "step": 5844
    },
    {
      "epoch": 1.3430606617647058,
      "grad_norm": 0.970921516418457,
      "learning_rate": 8.128063725490197e-06,
      "loss": 0.0477,
      "step": 5845
    },
    {
      "epoch": 1.3432904411764706,
      "grad_norm": 0.8305209279060364,
      "learning_rate": 8.127553104575165e-06,
      "loss": 0.0433,
      "step": 5846
    },
    {
      "epoch": 1.3435202205882353,
      "grad_norm": 0.7927488684654236,
      "learning_rate": 8.127042483660131e-06,
      "loss": 0.0534,
      "step": 5847
    },
    {
      "epoch": 1.34375,
      "grad_norm": 0.8818791508674622,
      "learning_rate": 8.126531862745099e-06,
      "loss": 0.0598,
      "step": 5848
    },
    {
      "epoch": 1.3439797794117647,
      "grad_norm": 1.1971060037612915,
      "learning_rate": 8.126021241830067e-06,
      "loss": 0.0865,
      "step": 5849
    },
    {
      "epoch": 1.3442095588235294,
      "grad_norm": 0.704558789730072,
      "learning_rate": 8.125510620915033e-06,
      "loss": 0.0381,
      "step": 5850
    },
    {
      "epoch": 1.3444393382352942,
      "grad_norm": 0.9840313792228699,
      "learning_rate": 8.125000000000001e-06,
      "loss": 0.0421,
      "step": 5851
    },
    {
      "epoch": 1.3446691176470589,
      "grad_norm": 1.0603382587432861,
      "learning_rate": 8.124489379084967e-06,
      "loss": 0.05,
      "step": 5852
    },
    {
      "epoch": 1.3448988970588236,
      "grad_norm": 0.7679744362831116,
      "learning_rate": 8.123978758169935e-06,
      "loss": 0.042,
      "step": 5853
    },
    {
      "epoch": 1.3451286764705883,
      "grad_norm": 0.8267859220504761,
      "learning_rate": 8.123468137254903e-06,
      "loss": 0.0662,
      "step": 5854
    },
    {
      "epoch": 1.3453584558823528,
      "grad_norm": 1.0216683149337769,
      "learning_rate": 8.12295751633987e-06,
      "loss": 0.0658,
      "step": 5855
    },
    {
      "epoch": 1.3455882352941178,
      "grad_norm": 1.0197514295578003,
      "learning_rate": 8.122446895424837e-06,
      "loss": 0.0767,
      "step": 5856
    },
    {
      "epoch": 1.3458180147058822,
      "grad_norm": 0.8895261883735657,
      "learning_rate": 8.121936274509805e-06,
      "loss": 0.0554,
      "step": 5857
    },
    {
      "epoch": 1.3460477941176472,
      "grad_norm": 1.0669753551483154,
      "learning_rate": 8.121425653594773e-06,
      "loss": 0.072,
      "step": 5858
    },
    {
      "epoch": 1.3462775735294117,
      "grad_norm": 1.409058928489685,
      "learning_rate": 8.120915032679739e-06,
      "loss": 0.0809,
      "step": 5859
    },
    {
      "epoch": 1.3465073529411764,
      "grad_norm": 1.2358520030975342,
      "learning_rate": 8.120404411764707e-06,
      "loss": 0.0458,
      "step": 5860
    },
    {
      "epoch": 1.3467371323529411,
      "grad_norm": 1.1257582902908325,
      "learning_rate": 8.119893790849673e-06,
      "loss": 0.0538,
      "step": 5861
    },
    {
      "epoch": 1.3469669117647058,
      "grad_norm": 0.8213693499565125,
      "learning_rate": 8.11938316993464e-06,
      "loss": 0.0512,
      "step": 5862
    },
    {
      "epoch": 1.3471966911764706,
      "grad_norm": 1.288761019706726,
      "learning_rate": 8.118872549019609e-06,
      "loss": 0.0715,
      "step": 5863
    },
    {
      "epoch": 1.3474264705882353,
      "grad_norm": 0.8077571392059326,
      "learning_rate": 8.118361928104576e-06,
      "loss": 0.042,
      "step": 5864
    },
    {
      "epoch": 1.34765625,
      "grad_norm": 0.8902309536933899,
      "learning_rate": 8.117851307189543e-06,
      "loss": 0.0493,
      "step": 5865
    },
    {
      "epoch": 1.3478860294117647,
      "grad_norm": 0.7660389542579651,
      "learning_rate": 8.11734068627451e-06,
      "loss": 0.0472,
      "step": 5866
    },
    {
      "epoch": 1.3481158088235294,
      "grad_norm": 1.1915940046310425,
      "learning_rate": 8.116830065359478e-06,
      "loss": 0.0859,
      "step": 5867
    },
    {
      "epoch": 1.3483455882352942,
      "grad_norm": 1.4049403667449951,
      "learning_rate": 8.116319444444444e-06,
      "loss": 0.066,
      "step": 5868
    },
    {
      "epoch": 1.3485753676470589,
      "grad_norm": 1.4403915405273438,
      "learning_rate": 8.115808823529412e-06,
      "loss": 0.077,
      "step": 5869
    },
    {
      "epoch": 1.3488051470588236,
      "grad_norm": 1.2044181823730469,
      "learning_rate": 8.11529820261438e-06,
      "loss": 0.0632,
      "step": 5870
    },
    {
      "epoch": 1.3490349264705883,
      "grad_norm": 1.0051511526107788,
      "learning_rate": 8.114787581699346e-06,
      "loss": 0.0565,
      "step": 5871
    },
    {
      "epoch": 1.3492647058823528,
      "grad_norm": 1.4168199300765991,
      "learning_rate": 8.114276960784314e-06,
      "loss": 0.0739,
      "step": 5872
    },
    {
      "epoch": 1.3494944852941178,
      "grad_norm": 0.7648177742958069,
      "learning_rate": 8.11376633986928e-06,
      "loss": 0.0322,
      "step": 5873
    },
    {
      "epoch": 1.3497242647058822,
      "grad_norm": 1.1006273031234741,
      "learning_rate": 8.11325571895425e-06,
      "loss": 0.0487,
      "step": 5874
    },
    {
      "epoch": 1.3499540441176472,
      "grad_norm": 1.000988245010376,
      "learning_rate": 8.112745098039216e-06,
      "loss": 0.0688,
      "step": 5875
    },
    {
      "epoch": 1.3501838235294117,
      "grad_norm": 1.00645112991333,
      "learning_rate": 8.112234477124184e-06,
      "loss": 0.0521,
      "step": 5876
    },
    {
      "epoch": 1.3504136029411764,
      "grad_norm": 0.880844235420227,
      "learning_rate": 8.11172385620915e-06,
      "loss": 0.0429,
      "step": 5877
    },
    {
      "epoch": 1.3506433823529411,
      "grad_norm": 0.8538093566894531,
      "learning_rate": 8.111213235294118e-06,
      "loss": 0.0428,
      "step": 5878
    },
    {
      "epoch": 1.3508731617647058,
      "grad_norm": 1.0469759702682495,
      "learning_rate": 8.110702614379086e-06,
      "loss": 0.0555,
      "step": 5879
    },
    {
      "epoch": 1.3511029411764706,
      "grad_norm": 0.8483723402023315,
      "learning_rate": 8.110191993464052e-06,
      "loss": 0.0469,
      "step": 5880
    },
    {
      "epoch": 1.3513327205882353,
      "grad_norm": 1.1447594165802002,
      "learning_rate": 8.10968137254902e-06,
      "loss": 0.0718,
      "step": 5881
    },
    {
      "epoch": 1.3515625,
      "grad_norm": 1.2188787460327148,
      "learning_rate": 8.109170751633988e-06,
      "loss": 0.0894,
      "step": 5882
    },
    {
      "epoch": 1.3517922794117647,
      "grad_norm": 1.2458221912384033,
      "learning_rate": 8.108660130718956e-06,
      "loss": 0.0602,
      "step": 5883
    },
    {
      "epoch": 1.3520220588235294,
      "grad_norm": 1.3321418762207031,
      "learning_rate": 8.108149509803922e-06,
      "loss": 0.0775,
      "step": 5884
    },
    {
      "epoch": 1.3522518382352942,
      "grad_norm": 1.188923716545105,
      "learning_rate": 8.10763888888889e-06,
      "loss": 0.0603,
      "step": 5885
    },
    {
      "epoch": 1.3524816176470589,
      "grad_norm": 1.0602201223373413,
      "learning_rate": 8.107128267973857e-06,
      "loss": 0.0482,
      "step": 5886
    },
    {
      "epoch": 1.3527113970588236,
      "grad_norm": 1.0429571866989136,
      "learning_rate": 8.106617647058824e-06,
      "loss": 0.0567,
      "step": 5887
    },
    {
      "epoch": 1.3529411764705883,
      "grad_norm": 1.3816699981689453,
      "learning_rate": 8.106107026143792e-06,
      "loss": 0.0871,
      "step": 5888
    },
    {
      "epoch": 1.3531709558823528,
      "grad_norm": 1.3174500465393066,
      "learning_rate": 8.105596405228758e-06,
      "loss": 0.0563,
      "step": 5889
    },
    {
      "epoch": 1.3534007352941178,
      "grad_norm": 0.8401392698287964,
      "learning_rate": 8.105085784313727e-06,
      "loss": 0.0484,
      "step": 5890
    },
    {
      "epoch": 1.3536305147058822,
      "grad_norm": 1.0465222597122192,
      "learning_rate": 8.104575163398693e-06,
      "loss": 0.045,
      "step": 5891
    },
    {
      "epoch": 1.3538602941176472,
      "grad_norm": 0.8916327953338623,
      "learning_rate": 8.104064542483661e-06,
      "loss": 0.0374,
      "step": 5892
    },
    {
      "epoch": 1.3540900735294117,
      "grad_norm": 1.1657391786575317,
      "learning_rate": 8.103553921568627e-06,
      "loss": 0.0506,
      "step": 5893
    },
    {
      "epoch": 1.3543198529411764,
      "grad_norm": 1.1786860227584839,
      "learning_rate": 8.103043300653595e-06,
      "loss": 0.0702,
      "step": 5894
    },
    {
      "epoch": 1.3545496323529411,
      "grad_norm": 0.8471489548683167,
      "learning_rate": 8.102532679738563e-06,
      "loss": 0.0487,
      "step": 5895
    },
    {
      "epoch": 1.3547794117647058,
      "grad_norm": 1.7087539434432983,
      "learning_rate": 8.10202205882353e-06,
      "loss": 0.0895,
      "step": 5896
    },
    {
      "epoch": 1.3550091911764706,
      "grad_norm": 0.90855872631073,
      "learning_rate": 8.101511437908497e-06,
      "loss": 0.063,
      "step": 5897
    },
    {
      "epoch": 1.3552389705882353,
      "grad_norm": 0.9641386866569519,
      "learning_rate": 8.101000816993465e-06,
      "loss": 0.0551,
      "step": 5898
    },
    {
      "epoch": 1.35546875,
      "grad_norm": 0.7716016173362732,
      "learning_rate": 8.100490196078433e-06,
      "loss": 0.0521,
      "step": 5899
    },
    {
      "epoch": 1.3556985294117647,
      "grad_norm": 0.9051292538642883,
      "learning_rate": 8.099979575163399e-06,
      "loss": 0.0561,
      "step": 5900
    },
    {
      "epoch": 1.3559283088235294,
      "grad_norm": 1.2131999731063843,
      "learning_rate": 8.099468954248367e-06,
      "loss": 0.0453,
      "step": 5901
    },
    {
      "epoch": 1.3561580882352942,
      "grad_norm": 0.9843114018440247,
      "learning_rate": 8.098958333333335e-06,
      "loss": 0.0773,
      "step": 5902
    },
    {
      "epoch": 1.3563878676470589,
      "grad_norm": 1.3067086935043335,
      "learning_rate": 8.098447712418301e-06,
      "loss": 0.0625,
      "step": 5903
    },
    {
      "epoch": 1.3566176470588236,
      "grad_norm": 0.7467355728149414,
      "learning_rate": 8.097937091503269e-06,
      "loss": 0.0338,
      "step": 5904
    },
    {
      "epoch": 1.3568474264705883,
      "grad_norm": 1.3345985412597656,
      "learning_rate": 8.097426470588235e-06,
      "loss": 0.1085,
      "step": 5905
    },
    {
      "epoch": 1.3570772058823528,
      "grad_norm": 0.8282892107963562,
      "learning_rate": 8.096915849673203e-06,
      "loss": 0.0482,
      "step": 5906
    },
    {
      "epoch": 1.3573069852941178,
      "grad_norm": 0.9546921849250793,
      "learning_rate": 8.09640522875817e-06,
      "loss": 0.0469,
      "step": 5907
    },
    {
      "epoch": 1.3575367647058822,
      "grad_norm": 0.9336264729499817,
      "learning_rate": 8.095894607843137e-06,
      "loss": 0.0417,
      "step": 5908
    },
    {
      "epoch": 1.3577665441176472,
      "grad_norm": 0.6501656770706177,
      "learning_rate": 8.095383986928105e-06,
      "loss": 0.0342,
      "step": 5909
    },
    {
      "epoch": 1.3579963235294117,
      "grad_norm": 1.060434103012085,
      "learning_rate": 8.094873366013073e-06,
      "loss": 0.0601,
      "step": 5910
    },
    {
      "epoch": 1.3582261029411764,
      "grad_norm": 1.4261854887008667,
      "learning_rate": 8.09436274509804e-06,
      "loss": 0.0769,
      "step": 5911
    },
    {
      "epoch": 1.3584558823529411,
      "grad_norm": 1.2431070804595947,
      "learning_rate": 8.093852124183007e-06,
      "loss": 0.0595,
      "step": 5912
    },
    {
      "epoch": 1.3586856617647058,
      "grad_norm": 0.8104653358459473,
      "learning_rate": 8.093341503267975e-06,
      "loss": 0.0453,
      "step": 5913
    },
    {
      "epoch": 1.3589154411764706,
      "grad_norm": 0.6502682566642761,
      "learning_rate": 8.092830882352942e-06,
      "loss": 0.0371,
      "step": 5914
    },
    {
      "epoch": 1.3591452205882353,
      "grad_norm": 0.8822188973426819,
      "learning_rate": 8.092320261437909e-06,
      "loss": 0.0528,
      "step": 5915
    },
    {
      "epoch": 1.359375,
      "grad_norm": 0.9440693855285645,
      "learning_rate": 8.091809640522876e-06,
      "loss": 0.0457,
      "step": 5916
    },
    {
      "epoch": 1.3596047794117647,
      "grad_norm": 1.037157654762268,
      "learning_rate": 8.091299019607843e-06,
      "loss": 0.0432,
      "step": 5917
    },
    {
      "epoch": 1.3598345588235294,
      "grad_norm": 0.9961280226707458,
      "learning_rate": 8.090788398692812e-06,
      "loss": 0.0575,
      "step": 5918
    },
    {
      "epoch": 1.3600643382352942,
      "grad_norm": 0.6676139831542969,
      "learning_rate": 8.090277777777778e-06,
      "loss": 0.033,
      "step": 5919
    },
    {
      "epoch": 1.3602941176470589,
      "grad_norm": 0.7852984666824341,
      "learning_rate": 8.089767156862746e-06,
      "loss": 0.0374,
      "step": 5920
    },
    {
      "epoch": 1.3605238970588236,
      "grad_norm": 1.2006514072418213,
      "learning_rate": 8.089256535947712e-06,
      "loss": 0.06,
      "step": 5921
    },
    {
      "epoch": 1.3607536764705883,
      "grad_norm": 1.0226218700408936,
      "learning_rate": 8.08874591503268e-06,
      "loss": 0.0531,
      "step": 5922
    },
    {
      "epoch": 1.3609834558823528,
      "grad_norm": 1.085922360420227,
      "learning_rate": 8.088235294117648e-06,
      "loss": 0.0639,
      "step": 5923
    },
    {
      "epoch": 1.3612132352941178,
      "grad_norm": 1.8557991981506348,
      "learning_rate": 8.087724673202614e-06,
      "loss": 0.0588,
      "step": 5924
    },
    {
      "epoch": 1.3614430147058822,
      "grad_norm": 1.1429905891418457,
      "learning_rate": 8.087214052287582e-06,
      "loss": 0.0555,
      "step": 5925
    },
    {
      "epoch": 1.3616727941176472,
      "grad_norm": 0.9012619853019714,
      "learning_rate": 8.08670343137255e-06,
      "loss": 0.0409,
      "step": 5926
    },
    {
      "epoch": 1.3619025735294117,
      "grad_norm": 1.0422550439834595,
      "learning_rate": 8.086192810457518e-06,
      "loss": 0.0641,
      "step": 5927
    },
    {
      "epoch": 1.3621323529411764,
      "grad_norm": 1.085712194442749,
      "learning_rate": 8.085682189542484e-06,
      "loss": 0.0702,
      "step": 5928
    },
    {
      "epoch": 1.3623621323529411,
      "grad_norm": 1.0103334188461304,
      "learning_rate": 8.085171568627452e-06,
      "loss": 0.0499,
      "step": 5929
    },
    {
      "epoch": 1.3625919117647058,
      "grad_norm": 0.7189214825630188,
      "learning_rate": 8.08466094771242e-06,
      "loss": 0.0382,
      "step": 5930
    },
    {
      "epoch": 1.3628216911764706,
      "grad_norm": 0.7463595867156982,
      "learning_rate": 8.084150326797386e-06,
      "loss": 0.0324,
      "step": 5931
    },
    {
      "epoch": 1.3630514705882353,
      "grad_norm": 0.9906479716300964,
      "learning_rate": 8.083639705882354e-06,
      "loss": 0.0622,
      "step": 5932
    },
    {
      "epoch": 1.36328125,
      "grad_norm": 0.8766941428184509,
      "learning_rate": 8.08312908496732e-06,
      "loss": 0.0451,
      "step": 5933
    },
    {
      "epoch": 1.3635110294117647,
      "grad_norm": 0.8050983548164368,
      "learning_rate": 8.08261846405229e-06,
      "loss": 0.0345,
      "step": 5934
    },
    {
      "epoch": 1.3637408088235294,
      "grad_norm": 1.0096811056137085,
      "learning_rate": 8.082107843137256e-06,
      "loss": 0.0513,
      "step": 5935
    },
    {
      "epoch": 1.3639705882352942,
      "grad_norm": 0.9652645587921143,
      "learning_rate": 8.081597222222223e-06,
      "loss": 0.0401,
      "step": 5936
    },
    {
      "epoch": 1.3642003676470589,
      "grad_norm": 1.114250898361206,
      "learning_rate": 8.08108660130719e-06,
      "loss": 0.0689,
      "step": 5937
    },
    {
      "epoch": 1.3644301470588236,
      "grad_norm": 0.8883191347122192,
      "learning_rate": 8.080575980392157e-06,
      "loss": 0.043,
      "step": 5938
    },
    {
      "epoch": 1.3646599264705883,
      "grad_norm": 1.3704700469970703,
      "learning_rate": 8.080065359477125e-06,
      "loss": 0.0752,
      "step": 5939
    },
    {
      "epoch": 1.3648897058823528,
      "grad_norm": 1.2245184183120728,
      "learning_rate": 8.079554738562092e-06,
      "loss": 0.0606,
      "step": 5940
    },
    {
      "epoch": 1.3651194852941178,
      "grad_norm": 0.7614895701408386,
      "learning_rate": 8.07904411764706e-06,
      "loss": 0.043,
      "step": 5941
    },
    {
      "epoch": 1.3653492647058822,
      "grad_norm": 0.7619786262512207,
      "learning_rate": 8.078533496732027e-06,
      "loss": 0.0392,
      "step": 5942
    },
    {
      "epoch": 1.3655790441176472,
      "grad_norm": 1.3989505767822266,
      "learning_rate": 8.078022875816995e-06,
      "loss": 0.058,
      "step": 5943
    },
    {
      "epoch": 1.3658088235294117,
      "grad_norm": 1.3155282735824585,
      "learning_rate": 8.077512254901961e-06,
      "loss": 0.0581,
      "step": 5944
    },
    {
      "epoch": 1.3660386029411764,
      "grad_norm": 1.0043621063232422,
      "learning_rate": 8.077001633986929e-06,
      "loss": 0.0354,
      "step": 5945
    },
    {
      "epoch": 1.3662683823529411,
      "grad_norm": 0.9854039549827576,
      "learning_rate": 8.076491013071897e-06,
      "loss": 0.051,
      "step": 5946
    },
    {
      "epoch": 1.3664981617647058,
      "grad_norm": 0.9242138862609863,
      "learning_rate": 8.075980392156863e-06,
      "loss": 0.0393,
      "step": 5947
    },
    {
      "epoch": 1.3667279411764706,
      "grad_norm": 1.5238239765167236,
      "learning_rate": 8.075469771241831e-06,
      "loss": 0.0451,
      "step": 5948
    },
    {
      "epoch": 1.3669577205882353,
      "grad_norm": 1.2654505968093872,
      "learning_rate": 8.074959150326797e-06,
      "loss": 0.079,
      "step": 5949
    },
    {
      "epoch": 1.3671875,
      "grad_norm": 1.0119603872299194,
      "learning_rate": 8.074448529411765e-06,
      "loss": 0.0501,
      "step": 5950
    },
    {
      "epoch": 1.3674172794117647,
      "grad_norm": 1.049680233001709,
      "learning_rate": 8.073937908496733e-06,
      "loss": 0.0679,
      "step": 5951
    },
    {
      "epoch": 1.3676470588235294,
      "grad_norm": 1.6001023054122925,
      "learning_rate": 8.073427287581699e-06,
      "loss": 0.0589,
      "step": 5952
    },
    {
      "epoch": 1.3678768382352942,
      "grad_norm": 1.1341423988342285,
      "learning_rate": 8.072916666666667e-06,
      "loss": 0.0557,
      "step": 5953
    },
    {
      "epoch": 1.3681066176470589,
      "grad_norm": 1.3245810270309448,
      "learning_rate": 8.072406045751635e-06,
      "loss": 0.0625,
      "step": 5954
    },
    {
      "epoch": 1.3683363970588236,
      "grad_norm": 1.0767878293991089,
      "learning_rate": 8.071895424836603e-06,
      "loss": 0.0619,
      "step": 5955
    },
    {
      "epoch": 1.3685661764705883,
      "grad_norm": 1.5051213502883911,
      "learning_rate": 8.071384803921569e-06,
      "loss": 0.0431,
      "step": 5956
    },
    {
      "epoch": 1.3687959558823528,
      "grad_norm": 0.9473899602890015,
      "learning_rate": 8.070874183006537e-06,
      "loss": 0.0644,
      "step": 5957
    },
    {
      "epoch": 1.3690257352941178,
      "grad_norm": 1.4765491485595703,
      "learning_rate": 8.070363562091505e-06,
      "loss": 0.059,
      "step": 5958
    },
    {
      "epoch": 1.3692555147058822,
      "grad_norm": 1.4555143117904663,
      "learning_rate": 8.06985294117647e-06,
      "loss": 0.0682,
      "step": 5959
    },
    {
      "epoch": 1.3694852941176472,
      "grad_norm": 1.105502963066101,
      "learning_rate": 8.069342320261439e-06,
      "loss": 0.0496,
      "step": 5960
    },
    {
      "epoch": 1.3697150735294117,
      "grad_norm": 0.9609530568122864,
      "learning_rate": 8.068831699346405e-06,
      "loss": 0.0285,
      "step": 5961
    },
    {
      "epoch": 1.3699448529411764,
      "grad_norm": 1.1482049226760864,
      "learning_rate": 8.068321078431374e-06,
      "loss": 0.0771,
      "step": 5962
    },
    {
      "epoch": 1.3701746323529411,
      "grad_norm": 1.269270896911621,
      "learning_rate": 8.06781045751634e-06,
      "loss": 0.0411,
      "step": 5963
    },
    {
      "epoch": 1.3704044117647058,
      "grad_norm": 1.08721923828125,
      "learning_rate": 8.067299836601308e-06,
      "loss": 0.0718,
      "step": 5964
    },
    {
      "epoch": 1.3706341911764706,
      "grad_norm": 1.0644071102142334,
      "learning_rate": 8.066789215686275e-06,
      "loss": 0.0487,
      "step": 5965
    },
    {
      "epoch": 1.3708639705882353,
      "grad_norm": 0.6915030479431152,
      "learning_rate": 8.066278594771242e-06,
      "loss": 0.029,
      "step": 5966
    },
    {
      "epoch": 1.37109375,
      "grad_norm": 1.3064912557601929,
      "learning_rate": 8.06576797385621e-06,
      "loss": 0.0484,
      "step": 5967
    },
    {
      "epoch": 1.3713235294117647,
      "grad_norm": 1.0284302234649658,
      "learning_rate": 8.065257352941176e-06,
      "loss": 0.0668,
      "step": 5968
    },
    {
      "epoch": 1.3715533088235294,
      "grad_norm": 1.1558696031570435,
      "learning_rate": 8.064746732026144e-06,
      "loss": 0.048,
      "step": 5969
    },
    {
      "epoch": 1.3717830882352942,
      "grad_norm": 1.2374627590179443,
      "learning_rate": 8.064236111111112e-06,
      "loss": 0.0545,
      "step": 5970
    },
    {
      "epoch": 1.3720128676470589,
      "grad_norm": 1.1766701936721802,
      "learning_rate": 8.06372549019608e-06,
      "loss": 0.0797,
      "step": 5971
    },
    {
      "epoch": 1.3722426470588236,
      "grad_norm": 1.127554178237915,
      "learning_rate": 8.063214869281046e-06,
      "loss": 0.0708,
      "step": 5972
    },
    {
      "epoch": 1.3724724264705883,
      "grad_norm": 0.9264485836029053,
      "learning_rate": 8.062704248366014e-06,
      "loss": 0.0631,
      "step": 5973
    },
    {
      "epoch": 1.3727022058823528,
      "grad_norm": 0.9043793082237244,
      "learning_rate": 8.062193627450982e-06,
      "loss": 0.0477,
      "step": 5974
    },
    {
      "epoch": 1.3729319852941178,
      "grad_norm": 1.017830729484558,
      "learning_rate": 8.061683006535948e-06,
      "loss": 0.0577,
      "step": 5975
    },
    {
      "epoch": 1.3731617647058822,
      "grad_norm": 1.0212739706039429,
      "learning_rate": 8.061172385620916e-06,
      "loss": 0.037,
      "step": 5976
    },
    {
      "epoch": 1.3733915441176472,
      "grad_norm": 1.5583652257919312,
      "learning_rate": 8.060661764705882e-06,
      "loss": 0.0623,
      "step": 5977
    },
    {
      "epoch": 1.3736213235294117,
      "grad_norm": 0.6396930813789368,
      "learning_rate": 8.060151143790852e-06,
      "loss": 0.0334,
      "step": 5978
    },
    {
      "epoch": 1.3738511029411764,
      "grad_norm": 0.9905781149864197,
      "learning_rate": 8.059640522875818e-06,
      "loss": 0.0551,
      "step": 5979
    },
    {
      "epoch": 1.3740808823529411,
      "grad_norm": 1.1114941835403442,
      "learning_rate": 8.059129901960786e-06,
      "loss": 0.0706,
      "step": 5980
    },
    {
      "epoch": 1.3743106617647058,
      "grad_norm": 0.6984883546829224,
      "learning_rate": 8.058619281045752e-06,
      "loss": 0.031,
      "step": 5981
    },
    {
      "epoch": 1.3745404411764706,
      "grad_norm": 0.7928017377853394,
      "learning_rate": 8.05810866013072e-06,
      "loss": 0.0371,
      "step": 5982
    },
    {
      "epoch": 1.3747702205882353,
      "grad_norm": 0.9095627069473267,
      "learning_rate": 8.057598039215688e-06,
      "loss": 0.0497,
      "step": 5983
    },
    {
      "epoch": 1.375,
      "grad_norm": 0.7717878818511963,
      "learning_rate": 8.057087418300654e-06,
      "loss": 0.046,
      "step": 5984
    },
    {
      "epoch": 1.3752297794117647,
      "grad_norm": 1.111768364906311,
      "learning_rate": 8.056576797385622e-06,
      "loss": 0.0549,
      "step": 5985
    },
    {
      "epoch": 1.3754595588235294,
      "grad_norm": 1.3818223476409912,
      "learning_rate": 8.05606617647059e-06,
      "loss": 0.0672,
      "step": 5986
    },
    {
      "epoch": 1.3756893382352942,
      "grad_norm": 0.9014572501182556,
      "learning_rate": 8.055555555555557e-06,
      "loss": 0.0436,
      "step": 5987
    },
    {
      "epoch": 1.3759191176470589,
      "grad_norm": 1.2585231065750122,
      "learning_rate": 8.055044934640523e-06,
      "loss": 0.0691,
      "step": 5988
    },
    {
      "epoch": 1.3761488970588236,
      "grad_norm": 1.2874609231948853,
      "learning_rate": 8.054534313725491e-06,
      "loss": 0.0438,
      "step": 5989
    },
    {
      "epoch": 1.3763786764705883,
      "grad_norm": 1.1269924640655518,
      "learning_rate": 8.05402369281046e-06,
      "loss": 0.0663,
      "step": 5990
    },
    {
      "epoch": 1.3766084558823528,
      "grad_norm": 0.9582284688949585,
      "learning_rate": 8.053513071895425e-06,
      "loss": 0.0455,
      "step": 5991
    },
    {
      "epoch": 1.3768382352941178,
      "grad_norm": 1.062166452407837,
      "learning_rate": 8.053002450980393e-06,
      "loss": 0.0512,
      "step": 5992
    },
    {
      "epoch": 1.3770680147058822,
      "grad_norm": 0.7782558798789978,
      "learning_rate": 8.05249183006536e-06,
      "loss": 0.0497,
      "step": 5993
    },
    {
      "epoch": 1.3772977941176472,
      "grad_norm": 1.0873169898986816,
      "learning_rate": 8.051981209150327e-06,
      "loss": 0.0519,
      "step": 5994
    },
    {
      "epoch": 1.3775275735294117,
      "grad_norm": 0.6732833981513977,
      "learning_rate": 8.051470588235295e-06,
      "loss": 0.0367,
      "step": 5995
    },
    {
      "epoch": 1.3777573529411764,
      "grad_norm": 0.8971937298774719,
      "learning_rate": 8.050959967320261e-06,
      "loss": 0.0529,
      "step": 5996
    },
    {
      "epoch": 1.3779871323529411,
      "grad_norm": 1.3591221570968628,
      "learning_rate": 8.050449346405229e-06,
      "loss": 0.0776,
      "step": 5997
    },
    {
      "epoch": 1.3782169117647058,
      "grad_norm": 1.0300227403640747,
      "learning_rate": 8.049938725490197e-06,
      "loss": 0.052,
      "step": 5998
    },
    {
      "epoch": 1.3784466911764706,
      "grad_norm": 1.0048775672912598,
      "learning_rate": 8.049428104575165e-06,
      "loss": 0.0446,
      "step": 5999
    },
    {
      "epoch": 1.3786764705882353,
      "grad_norm": 0.9107226729393005,
      "learning_rate": 8.048917483660131e-06,
      "loss": 0.0437,
      "step": 6000
    },
    {
      "epoch": 1.3786764705882353,
      "eval_loss": 0.05765882879495621,
      "eval_runtime": 2006.941,
      "eval_samples_per_second": 4.438,
      "eval_steps_per_second": 2.219,
      "step": 6000
    },
    {
      "epoch": 1.37890625,
      "grad_norm": 0.9175412058830261,
      "learning_rate": 8.048406862745099e-06,
      "loss": 0.0461,
      "step": 6001
    },
    {
      "epoch": 1.3791360294117647,
      "grad_norm": 0.7923177480697632,
      "learning_rate": 8.047896241830067e-06,
      "loss": 0.041,
      "step": 6002
    },
    {
      "epoch": 1.3793658088235294,
      "grad_norm": 0.9754728078842163,
      "learning_rate": 8.047385620915033e-06,
      "loss": 0.0435,
      "step": 6003
    },
    {
      "epoch": 1.3795955882352942,
      "grad_norm": 1.034556269645691,
      "learning_rate": 8.046875e-06,
      "loss": 0.0454,
      "step": 6004
    },
    {
      "epoch": 1.3798253676470589,
      "grad_norm": 1.1213586330413818,
      "learning_rate": 8.046364379084967e-06,
      "loss": 0.054,
      "step": 6005
    },
    {
      "epoch": 1.3800551470588236,
      "grad_norm": 0.8858481049537659,
      "learning_rate": 8.045853758169935e-06,
      "loss": 0.0575,
      "step": 6006
    },
    {
      "epoch": 1.3802849264705883,
      "grad_norm": 1.3557449579238892,
      "learning_rate": 8.045343137254903e-06,
      "loss": 0.0798,
      "step": 6007
    },
    {
      "epoch": 1.3805147058823528,
      "grad_norm": 1.0052273273468018,
      "learning_rate": 8.04483251633987e-06,
      "loss": 0.072,
      "step": 6008
    },
    {
      "epoch": 1.3807444852941178,
      "grad_norm": 1.2552870512008667,
      "learning_rate": 8.044321895424837e-06,
      "loss": 0.073,
      "step": 6009
    },
    {
      "epoch": 1.3809742647058822,
      "grad_norm": 1.124609112739563,
      "learning_rate": 8.043811274509805e-06,
      "loss": 0.0599,
      "step": 6010
    },
    {
      "epoch": 1.3812040441176472,
      "grad_norm": 0.9156126976013184,
      "learning_rate": 8.043300653594772e-06,
      "loss": 0.0369,
      "step": 6011
    },
    {
      "epoch": 1.3814338235294117,
      "grad_norm": 1.0782994031906128,
      "learning_rate": 8.042790032679739e-06,
      "loss": 0.0635,
      "step": 6012
    },
    {
      "epoch": 1.3816636029411764,
      "grad_norm": 1.0474189519882202,
      "learning_rate": 8.042279411764706e-06,
      "loss": 0.0498,
      "step": 6013
    },
    {
      "epoch": 1.3818933823529411,
      "grad_norm": 0.7516082525253296,
      "learning_rate": 8.041768790849673e-06,
      "loss": 0.0331,
      "step": 6014
    },
    {
      "epoch": 1.3821231617647058,
      "grad_norm": 0.8951866626739502,
      "learning_rate": 8.041258169934642e-06,
      "loss": 0.0589,
      "step": 6015
    },
    {
      "epoch": 1.3823529411764706,
      "grad_norm": 1.471539855003357,
      "learning_rate": 8.040747549019608e-06,
      "loss": 0.0684,
      "step": 6016
    },
    {
      "epoch": 1.3825827205882353,
      "grad_norm": 1.240301489830017,
      "learning_rate": 8.040236928104576e-06,
      "loss": 0.1053,
      "step": 6017
    },
    {
      "epoch": 1.3828125,
      "grad_norm": 1.0299888849258423,
      "learning_rate": 8.039726307189542e-06,
      "loss": 0.0643,
      "step": 6018
    },
    {
      "epoch": 1.3830422794117647,
      "grad_norm": 1.2149170637130737,
      "learning_rate": 8.03921568627451e-06,
      "loss": 0.0562,
      "step": 6019
    },
    {
      "epoch": 1.3832720588235294,
      "grad_norm": 1.126164436340332,
      "learning_rate": 8.038705065359478e-06,
      "loss": 0.0568,
      "step": 6020
    },
    {
      "epoch": 1.3835018382352942,
      "grad_norm": 0.6512829065322876,
      "learning_rate": 8.038194444444444e-06,
      "loss": 0.0314,
      "step": 6021
    },
    {
      "epoch": 1.3837316176470589,
      "grad_norm": 1.0872641801834106,
      "learning_rate": 8.037683823529412e-06,
      "loss": 0.0546,
      "step": 6022
    },
    {
      "epoch": 1.3839613970588236,
      "grad_norm": 1.5080032348632812,
      "learning_rate": 8.03717320261438e-06,
      "loss": 0.0597,
      "step": 6023
    },
    {
      "epoch": 1.3841911764705883,
      "grad_norm": 1.2784101963043213,
      "learning_rate": 8.036662581699348e-06,
      "loss": 0.0621,
      "step": 6024
    },
    {
      "epoch": 1.3844209558823528,
      "grad_norm": 1.0062487125396729,
      "learning_rate": 8.036151960784314e-06,
      "loss": 0.0695,
      "step": 6025
    },
    {
      "epoch": 1.3846507352941178,
      "grad_norm": 1.08814537525177,
      "learning_rate": 8.035641339869282e-06,
      "loss": 0.0699,
      "step": 6026
    },
    {
      "epoch": 1.3848805147058822,
      "grad_norm": 1.11967134475708,
      "learning_rate": 8.03513071895425e-06,
      "loss": 0.0864,
      "step": 6027
    },
    {
      "epoch": 1.3851102941176472,
      "grad_norm": 1.0689128637313843,
      "learning_rate": 8.034620098039216e-06,
      "loss": 0.0499,
      "step": 6028
    },
    {
      "epoch": 1.3853400735294117,
      "grad_norm": 1.034156322479248,
      "learning_rate": 8.034109477124184e-06,
      "loss": 0.0644,
      "step": 6029
    },
    {
      "epoch": 1.3855698529411764,
      "grad_norm": 0.7467935085296631,
      "learning_rate": 8.03359885620915e-06,
      "loss": 0.0325,
      "step": 6030
    },
    {
      "epoch": 1.3857996323529411,
      "grad_norm": 0.7411980032920837,
      "learning_rate": 8.033088235294118e-06,
      "loss": 0.0389,
      "step": 6031
    },
    {
      "epoch": 1.3860294117647058,
      "grad_norm": 0.9705550074577332,
      "learning_rate": 8.032577614379086e-06,
      "loss": 0.0494,
      "step": 6032
    },
    {
      "epoch": 1.3862591911764706,
      "grad_norm": 1.1701335906982422,
      "learning_rate": 8.032066993464054e-06,
      "loss": 0.0533,
      "step": 6033
    },
    {
      "epoch": 1.3864889705882353,
      "grad_norm": 1.3684731721878052,
      "learning_rate": 8.03155637254902e-06,
      "loss": 0.0656,
      "step": 6034
    },
    {
      "epoch": 1.38671875,
      "grad_norm": 1.1053047180175781,
      "learning_rate": 8.031045751633988e-06,
      "loss": 0.0878,
      "step": 6035
    },
    {
      "epoch": 1.3869485294117647,
      "grad_norm": 0.9961099028587341,
      "learning_rate": 8.030535130718955e-06,
      "loss": 0.0632,
      "step": 6036
    },
    {
      "epoch": 1.3871783088235294,
      "grad_norm": 1.19306218624115,
      "learning_rate": 8.030024509803922e-06,
      "loss": 0.07,
      "step": 6037
    },
    {
      "epoch": 1.3874080882352942,
      "grad_norm": 0.9387311935424805,
      "learning_rate": 8.02951388888889e-06,
      "loss": 0.0651,
      "step": 6038
    },
    {
      "epoch": 1.3876378676470589,
      "grad_norm": 1.0413613319396973,
      "learning_rate": 8.029003267973857e-06,
      "loss": 0.0376,
      "step": 6039
    },
    {
      "epoch": 1.3878676470588236,
      "grad_norm": 1.0105862617492676,
      "learning_rate": 8.028492647058823e-06,
      "loss": 0.0732,
      "step": 6040
    },
    {
      "epoch": 1.3880974264705883,
      "grad_norm": 0.7847157716751099,
      "learning_rate": 8.027982026143791e-06,
      "loss": 0.0403,
      "step": 6041
    },
    {
      "epoch": 1.3883272058823528,
      "grad_norm": 1.1070345640182495,
      "learning_rate": 8.02747140522876e-06,
      "loss": 0.0461,
      "step": 6042
    },
    {
      "epoch": 1.3885569852941178,
      "grad_norm": 0.9395822882652283,
      "learning_rate": 8.026960784313727e-06,
      "loss": 0.0516,
      "step": 6043
    },
    {
      "epoch": 1.3887867647058822,
      "grad_norm": 0.8291127681732178,
      "learning_rate": 8.026450163398693e-06,
      "loss": 0.0387,
      "step": 6044
    },
    {
      "epoch": 1.3890165441176472,
      "grad_norm": 1.158065676689148,
      "learning_rate": 8.025939542483661e-06,
      "loss": 0.0658,
      "step": 6045
    },
    {
      "epoch": 1.3892463235294117,
      "grad_norm": 1.0445412397384644,
      "learning_rate": 8.025428921568627e-06,
      "loss": 0.07,
      "step": 6046
    },
    {
      "epoch": 1.3894761029411764,
      "grad_norm": 0.9384790658950806,
      "learning_rate": 8.024918300653595e-06,
      "loss": 0.0529,
      "step": 6047
    },
    {
      "epoch": 1.3897058823529411,
      "grad_norm": 1.1239248514175415,
      "learning_rate": 8.024407679738563e-06,
      "loss": 0.0638,
      "step": 6048
    },
    {
      "epoch": 1.3899356617647058,
      "grad_norm": 0.961127519607544,
      "learning_rate": 8.023897058823529e-06,
      "loss": 0.055,
      "step": 6049
    },
    {
      "epoch": 1.3901654411764706,
      "grad_norm": 1.1402266025543213,
      "learning_rate": 8.023386437908497e-06,
      "loss": 0.0455,
      "step": 6050
    },
    {
      "epoch": 1.3903952205882353,
      "grad_norm": 1.1569534540176392,
      "learning_rate": 8.022875816993465e-06,
      "loss": 0.0502,
      "step": 6051
    },
    {
      "epoch": 1.390625,
      "grad_norm": 0.6110913753509521,
      "learning_rate": 8.022365196078433e-06,
      "loss": 0.0331,
      "step": 6052
    },
    {
      "epoch": 1.3908547794117647,
      "grad_norm": 1.0277793407440186,
      "learning_rate": 8.021854575163399e-06,
      "loss": 0.0559,
      "step": 6053
    },
    {
      "epoch": 1.3910845588235294,
      "grad_norm": 1.4792656898498535,
      "learning_rate": 8.021343954248367e-06,
      "loss": 0.0398,
      "step": 6054
    },
    {
      "epoch": 1.3913143382352942,
      "grad_norm": 1.0169442892074585,
      "learning_rate": 8.020833333333335e-06,
      "loss": 0.046,
      "step": 6055
    },
    {
      "epoch": 1.3915441176470589,
      "grad_norm": 1.1603813171386719,
      "learning_rate": 8.0203227124183e-06,
      "loss": 0.0519,
      "step": 6056
    },
    {
      "epoch": 1.3917738970588236,
      "grad_norm": 0.823023796081543,
      "learning_rate": 8.019812091503269e-06,
      "loss": 0.0449,
      "step": 6057
    },
    {
      "epoch": 1.3920036764705883,
      "grad_norm": 1.2864819765090942,
      "learning_rate": 8.019301470588235e-06,
      "loss": 0.0488,
      "step": 6058
    },
    {
      "epoch": 1.3922334558823528,
      "grad_norm": 1.0329753160476685,
      "learning_rate": 8.018790849673204e-06,
      "loss": 0.0452,
      "step": 6059
    },
    {
      "epoch": 1.3924632352941178,
      "grad_norm": 0.8892098665237427,
      "learning_rate": 8.01828022875817e-06,
      "loss": 0.0554,
      "step": 6060
    },
    {
      "epoch": 1.3926930147058822,
      "grad_norm": 1.0577731132507324,
      "learning_rate": 8.017769607843138e-06,
      "loss": 0.0543,
      "step": 6061
    },
    {
      "epoch": 1.3929227941176472,
      "grad_norm": 1.0274039506912231,
      "learning_rate": 8.017258986928105e-06,
      "loss": 0.0569,
      "step": 6062
    },
    {
      "epoch": 1.3931525735294117,
      "grad_norm": 0.8139849901199341,
      "learning_rate": 8.016748366013072e-06,
      "loss": 0.0483,
      "step": 6063
    },
    {
      "epoch": 1.3933823529411764,
      "grad_norm": 1.196702003479004,
      "learning_rate": 8.01623774509804e-06,
      "loss": 0.0641,
      "step": 6064
    },
    {
      "epoch": 1.3936121323529411,
      "grad_norm": 1.4159212112426758,
      "learning_rate": 8.015727124183006e-06,
      "loss": 0.0549,
      "step": 6065
    },
    {
      "epoch": 1.3938419117647058,
      "grad_norm": 1.3009997606277466,
      "learning_rate": 8.015216503267974e-06,
      "loss": 0.081,
      "step": 6066
    },
    {
      "epoch": 1.3940716911764706,
      "grad_norm": 1.6165105104446411,
      "learning_rate": 8.014705882352942e-06,
      "loss": 0.0617,
      "step": 6067
    },
    {
      "epoch": 1.3943014705882353,
      "grad_norm": 1.3197304010391235,
      "learning_rate": 8.01419526143791e-06,
      "loss": 0.0789,
      "step": 6068
    },
    {
      "epoch": 1.39453125,
      "grad_norm": 1.6967618465423584,
      "learning_rate": 8.013684640522876e-06,
      "loss": 0.0653,
      "step": 6069
    },
    {
      "epoch": 1.3947610294117647,
      "grad_norm": 1.151919960975647,
      "learning_rate": 8.013174019607844e-06,
      "loss": 0.0449,
      "step": 6070
    },
    {
      "epoch": 1.3949908088235294,
      "grad_norm": 1.0537989139556885,
      "learning_rate": 8.012663398692812e-06,
      "loss": 0.0406,
      "step": 6071
    },
    {
      "epoch": 1.3952205882352942,
      "grad_norm": 0.9602381587028503,
      "learning_rate": 8.012152777777778e-06,
      "loss": 0.0498,
      "step": 6072
    },
    {
      "epoch": 1.3954503676470589,
      "grad_norm": 1.0850930213928223,
      "learning_rate": 8.011642156862746e-06,
      "loss": 0.0762,
      "step": 6073
    },
    {
      "epoch": 1.3956801470588236,
      "grad_norm": 0.9161167740821838,
      "learning_rate": 8.011131535947712e-06,
      "loss": 0.0448,
      "step": 6074
    },
    {
      "epoch": 1.3959099264705883,
      "grad_norm": 0.9882158637046814,
      "learning_rate": 8.01062091503268e-06,
      "loss": 0.0326,
      "step": 6075
    },
    {
      "epoch": 1.3961397058823528,
      "grad_norm": 0.8558812141418457,
      "learning_rate": 8.010110294117648e-06,
      "loss": 0.0518,
      "step": 6076
    },
    {
      "epoch": 1.3963694852941178,
      "grad_norm": 1.0580730438232422,
      "learning_rate": 8.009599673202616e-06,
      "loss": 0.0647,
      "step": 6077
    },
    {
      "epoch": 1.3965992647058822,
      "grad_norm": 1.114715576171875,
      "learning_rate": 8.009089052287582e-06,
      "loss": 0.057,
      "step": 6078
    },
    {
      "epoch": 1.3968290441176472,
      "grad_norm": 0.933617889881134,
      "learning_rate": 8.00857843137255e-06,
      "loss": 0.0627,
      "step": 6079
    },
    {
      "epoch": 1.3970588235294117,
      "grad_norm": 0.9008366465568542,
      "learning_rate": 8.008067810457518e-06,
      "loss": 0.0385,
      "step": 6080
    },
    {
      "epoch": 1.3972886029411764,
      "grad_norm": 1.2149804830551147,
      "learning_rate": 8.007557189542484e-06,
      "loss": 0.0593,
      "step": 6081
    },
    {
      "epoch": 1.3975183823529411,
      "grad_norm": 0.7684044241905212,
      "learning_rate": 8.007046568627452e-06,
      "loss": 0.0381,
      "step": 6082
    },
    {
      "epoch": 1.3977481617647058,
      "grad_norm": 1.0459717512130737,
      "learning_rate": 8.00653594771242e-06,
      "loss": 0.062,
      "step": 6083
    },
    {
      "epoch": 1.3979779411764706,
      "grad_norm": 1.2002307176589966,
      "learning_rate": 8.006025326797386e-06,
      "loss": 0.0571,
      "step": 6084
    },
    {
      "epoch": 1.3982077205882353,
      "grad_norm": 1.3568284511566162,
      "learning_rate": 8.005514705882354e-06,
      "loss": 0.0861,
      "step": 6085
    },
    {
      "epoch": 1.3984375,
      "grad_norm": 1.1405516862869263,
      "learning_rate": 8.00500408496732e-06,
      "loss": 0.0589,
      "step": 6086
    },
    {
      "epoch": 1.3986672794117647,
      "grad_norm": 1.413293480873108,
      "learning_rate": 8.00449346405229e-06,
      "loss": 0.0789,
      "step": 6087
    },
    {
      "epoch": 1.3988970588235294,
      "grad_norm": 1.3722602128982544,
      "learning_rate": 8.003982843137255e-06,
      "loss": 0.0648,
      "step": 6088
    },
    {
      "epoch": 1.3991268382352942,
      "grad_norm": 0.7576543688774109,
      "learning_rate": 8.003472222222223e-06,
      "loss": 0.0485,
      "step": 6089
    },
    {
      "epoch": 1.3993566176470589,
      "grad_norm": 0.8987245559692383,
      "learning_rate": 8.00296160130719e-06,
      "loss": 0.0568,
      "step": 6090
    },
    {
      "epoch": 1.3995863970588236,
      "grad_norm": 1.2227729558944702,
      "learning_rate": 8.002450980392157e-06,
      "loss": 0.0604,
      "step": 6091
    },
    {
      "epoch": 1.3998161764705883,
      "grad_norm": 0.9058377146720886,
      "learning_rate": 8.001940359477125e-06,
      "loss": 0.0594,
      "step": 6092
    },
    {
      "epoch": 1.4000459558823528,
      "grad_norm": 1.306552529335022,
      "learning_rate": 8.001429738562091e-06,
      "loss": 0.0585,
      "step": 6093
    },
    {
      "epoch": 1.4002757352941178,
      "grad_norm": 1.050847053527832,
      "learning_rate": 8.00091911764706e-06,
      "loss": 0.0537,
      "step": 6094
    },
    {
      "epoch": 1.4005055147058822,
      "grad_norm": 1.0347365140914917,
      "learning_rate": 8.000408496732027e-06,
      "loss": 0.0638,
      "step": 6095
    },
    {
      "epoch": 1.4007352941176472,
      "grad_norm": 1.1205172538757324,
      "learning_rate": 7.999897875816995e-06,
      "loss": 0.0819,
      "step": 6096
    },
    {
      "epoch": 1.4009650735294117,
      "grad_norm": 1.0315935611724854,
      "learning_rate": 7.999387254901961e-06,
      "loss": 0.0616,
      "step": 6097
    },
    {
      "epoch": 1.4011948529411764,
      "grad_norm": 0.975177526473999,
      "learning_rate": 7.998876633986929e-06,
      "loss": 0.0511,
      "step": 6098
    },
    {
      "epoch": 1.4014246323529411,
      "grad_norm": 1.0447466373443604,
      "learning_rate": 7.998366013071897e-06,
      "loss": 0.049,
      "step": 6099
    },
    {
      "epoch": 1.4016544117647058,
      "grad_norm": 1.0165379047393799,
      "learning_rate": 7.997855392156863e-06,
      "loss": 0.0677,
      "step": 6100
    },
    {
      "epoch": 1.4018841911764706,
      "grad_norm": 1.1347532272338867,
      "learning_rate": 7.99734477124183e-06,
      "loss": 0.0601,
      "step": 6101
    },
    {
      "epoch": 1.4021139705882353,
      "grad_norm": 1.0183391571044922,
      "learning_rate": 7.996834150326797e-06,
      "loss": 0.058,
      "step": 6102
    },
    {
      "epoch": 1.40234375,
      "grad_norm": 0.8186258673667908,
      "learning_rate": 7.996323529411767e-06,
      "loss": 0.0483,
      "step": 6103
    },
    {
      "epoch": 1.4025735294117647,
      "grad_norm": 0.9069463610649109,
      "learning_rate": 7.995812908496733e-06,
      "loss": 0.0335,
      "step": 6104
    },
    {
      "epoch": 1.4028033088235294,
      "grad_norm": 0.9860986471176147,
      "learning_rate": 7.9953022875817e-06,
      "loss": 0.0473,
      "step": 6105
    },
    {
      "epoch": 1.4030330882352942,
      "grad_norm": 0.9893572330474854,
      "learning_rate": 7.994791666666667e-06,
      "loss": 0.0514,
      "step": 6106
    },
    {
      "epoch": 1.4032628676470589,
      "grad_norm": 0.848787784576416,
      "learning_rate": 7.994281045751635e-06,
      "loss": 0.0472,
      "step": 6107
    },
    {
      "epoch": 1.4034926470588236,
      "grad_norm": 1.0276468992233276,
      "learning_rate": 7.993770424836602e-06,
      "loss": 0.0608,
      "step": 6108
    },
    {
      "epoch": 1.4037224264705883,
      "grad_norm": 1.5373607873916626,
      "learning_rate": 7.993259803921569e-06,
      "loss": 0.0887,
      "step": 6109
    },
    {
      "epoch": 1.4039522058823528,
      "grad_norm": 1.1363439559936523,
      "learning_rate": 7.992749183006536e-06,
      "loss": 0.0659,
      "step": 6110
    },
    {
      "epoch": 1.4041819852941178,
      "grad_norm": 1.1299865245819092,
      "learning_rate": 7.992238562091504e-06,
      "loss": 0.053,
      "step": 6111
    },
    {
      "epoch": 1.4044117647058822,
      "grad_norm": 1.3424383401870728,
      "learning_rate": 7.991727941176472e-06,
      "loss": 0.0645,
      "step": 6112
    },
    {
      "epoch": 1.4046415441176472,
      "grad_norm": 1.2551122903823853,
      "learning_rate": 7.991217320261438e-06,
      "loss": 0.0642,
      "step": 6113
    },
    {
      "epoch": 1.4048713235294117,
      "grad_norm": 0.8740954399108887,
      "learning_rate": 7.990706699346406e-06,
      "loss": 0.0458,
      "step": 6114
    },
    {
      "epoch": 1.4051011029411764,
      "grad_norm": 0.955481767654419,
      "learning_rate": 7.990196078431374e-06,
      "loss": 0.0435,
      "step": 6115
    },
    {
      "epoch": 1.4053308823529411,
      "grad_norm": 1.0241326093673706,
      "learning_rate": 7.98968545751634e-06,
      "loss": 0.0673,
      "step": 6116
    },
    {
      "epoch": 1.4055606617647058,
      "grad_norm": 1.022398829460144,
      "learning_rate": 7.989174836601308e-06,
      "loss": 0.068,
      "step": 6117
    },
    {
      "epoch": 1.4057904411764706,
      "grad_norm": 0.8901472687721252,
      "learning_rate": 7.988664215686274e-06,
      "loss": 0.0361,
      "step": 6118
    },
    {
      "epoch": 1.4060202205882353,
      "grad_norm": 0.9466453790664673,
      "learning_rate": 7.988153594771242e-06,
      "loss": 0.0643,
      "step": 6119
    },
    {
      "epoch": 1.40625,
      "grad_norm": 1.025836706161499,
      "learning_rate": 7.98764297385621e-06,
      "loss": 0.0535,
      "step": 6120
    },
    {
      "epoch": 1.4064797794117647,
      "grad_norm": 1.2736762762069702,
      "learning_rate": 7.987132352941178e-06,
      "loss": 0.0835,
      "step": 6121
    },
    {
      "epoch": 1.4067095588235294,
      "grad_norm": 0.9953371286392212,
      "learning_rate": 7.986621732026144e-06,
      "loss": 0.0583,
      "step": 6122
    },
    {
      "epoch": 1.4069393382352942,
      "grad_norm": 0.9762313365936279,
      "learning_rate": 7.986111111111112e-06,
      "loss": 0.0518,
      "step": 6123
    },
    {
      "epoch": 1.4071691176470589,
      "grad_norm": 0.9911258220672607,
      "learning_rate": 7.98560049019608e-06,
      "loss": 0.0597,
      "step": 6124
    },
    {
      "epoch": 1.4073988970588236,
      "grad_norm": 0.7473325729370117,
      "learning_rate": 7.985089869281046e-06,
      "loss": 0.0391,
      "step": 6125
    },
    {
      "epoch": 1.4076286764705883,
      "grad_norm": 1.1744786500930786,
      "learning_rate": 7.984579248366014e-06,
      "loss": 0.0428,
      "step": 6126
    },
    {
      "epoch": 1.4078584558823528,
      "grad_norm": 0.8860964179039001,
      "learning_rate": 7.984068627450982e-06,
      "loss": 0.0643,
      "step": 6127
    },
    {
      "epoch": 1.4080882352941178,
      "grad_norm": 1.3386870622634888,
      "learning_rate": 7.983558006535948e-06,
      "loss": 0.0758,
      "step": 6128
    },
    {
      "epoch": 1.4083180147058822,
      "grad_norm": 1.155457854270935,
      "learning_rate": 7.983047385620916e-06,
      "loss": 0.0401,
      "step": 6129
    },
    {
      "epoch": 1.4085477941176472,
      "grad_norm": 1.7448183298110962,
      "learning_rate": 7.982536764705882e-06,
      "loss": 0.064,
      "step": 6130
    },
    {
      "epoch": 1.4087775735294117,
      "grad_norm": 1.1207008361816406,
      "learning_rate": 7.982026143790851e-06,
      "loss": 0.08,
      "step": 6131
    },
    {
      "epoch": 1.4090073529411764,
      "grad_norm": 1.0546081066131592,
      "learning_rate": 7.981515522875818e-06,
      "loss": 0.0553,
      "step": 6132
    },
    {
      "epoch": 1.4092371323529411,
      "grad_norm": 1.0060268640518188,
      "learning_rate": 7.981004901960785e-06,
      "loss": 0.048,
      "step": 6133
    },
    {
      "epoch": 1.4094669117647058,
      "grad_norm": 1.2142751216888428,
      "learning_rate": 7.980494281045752e-06,
      "loss": 0.0488,
      "step": 6134
    },
    {
      "epoch": 1.4096966911764706,
      "grad_norm": 0.9053586721420288,
      "learning_rate": 7.97998366013072e-06,
      "loss": 0.0356,
      "step": 6135
    },
    {
      "epoch": 1.4099264705882353,
      "grad_norm": 0.7961640954017639,
      "learning_rate": 7.979473039215687e-06,
      "loss": 0.0443,
      "step": 6136
    },
    {
      "epoch": 1.41015625,
      "grad_norm": 1.2333766222000122,
      "learning_rate": 7.978962418300654e-06,
      "loss": 0.0528,
      "step": 6137
    },
    {
      "epoch": 1.4103860294117647,
      "grad_norm": 0.9822935461997986,
      "learning_rate": 7.978451797385621e-06,
      "loss": 0.0561,
      "step": 6138
    },
    {
      "epoch": 1.4106158088235294,
      "grad_norm": 0.9127673506736755,
      "learning_rate": 7.97794117647059e-06,
      "loss": 0.0633,
      "step": 6139
    },
    {
      "epoch": 1.4108455882352942,
      "grad_norm": 0.8160656094551086,
      "learning_rate": 7.977430555555557e-06,
      "loss": 0.0421,
      "step": 6140
    },
    {
      "epoch": 1.4110753676470589,
      "grad_norm": 0.8537883758544922,
      "learning_rate": 7.976919934640523e-06,
      "loss": 0.0483,
      "step": 6141
    },
    {
      "epoch": 1.4113051470588236,
      "grad_norm": 0.9756208658218384,
      "learning_rate": 7.976409313725491e-06,
      "loss": 0.0522,
      "step": 6142
    },
    {
      "epoch": 1.4115349264705883,
      "grad_norm": 1.1000272035598755,
      "learning_rate": 7.975898692810459e-06,
      "loss": 0.0667,
      "step": 6143
    },
    {
      "epoch": 1.4117647058823528,
      "grad_norm": 0.9295001029968262,
      "learning_rate": 7.975388071895425e-06,
      "loss": 0.0538,
      "step": 6144
    },
    {
      "epoch": 1.4119944852941178,
      "grad_norm": 1.1296067237854004,
      "learning_rate": 7.974877450980393e-06,
      "loss": 0.0594,
      "step": 6145
    },
    {
      "epoch": 1.4122242647058822,
      "grad_norm": 0.8112357258796692,
      "learning_rate": 7.97436683006536e-06,
      "loss": 0.0396,
      "step": 6146
    },
    {
      "epoch": 1.4124540441176472,
      "grad_norm": 1.3808194398880005,
      "learning_rate": 7.973856209150329e-06,
      "loss": 0.0743,
      "step": 6147
    },
    {
      "epoch": 1.4126838235294117,
      "grad_norm": 0.9940678477287292,
      "learning_rate": 7.973345588235295e-06,
      "loss": 0.0471,
      "step": 6148
    },
    {
      "epoch": 1.4129136029411764,
      "grad_norm": 1.2153489589691162,
      "learning_rate": 7.972834967320263e-06,
      "loss": 0.0764,
      "step": 6149
    },
    {
      "epoch": 1.4131433823529411,
      "grad_norm": 1.1942613124847412,
      "learning_rate": 7.972324346405229e-06,
      "loss": 0.0854,
      "step": 6150
    },
    {
      "epoch": 1.4133731617647058,
      "grad_norm": 1.3430614471435547,
      "learning_rate": 7.971813725490197e-06,
      "loss": 0.0773,
      "step": 6151
    },
    {
      "epoch": 1.4136029411764706,
      "grad_norm": 1.1608318090438843,
      "learning_rate": 7.971303104575165e-06,
      "loss": 0.0623,
      "step": 6152
    },
    {
      "epoch": 1.4138327205882353,
      "grad_norm": 0.7691502571105957,
      "learning_rate": 7.97079248366013e-06,
      "loss": 0.0605,
      "step": 6153
    },
    {
      "epoch": 1.4140625,
      "grad_norm": 1.0343111753463745,
      "learning_rate": 7.970281862745099e-06,
      "loss": 0.0488,
      "step": 6154
    },
    {
      "epoch": 1.4142922794117647,
      "grad_norm": 1.0691149234771729,
      "learning_rate": 7.969771241830067e-06,
      "loss": 0.0546,
      "step": 6155
    },
    {
      "epoch": 1.4145220588235294,
      "grad_norm": 1.040274739265442,
      "learning_rate": 7.969260620915034e-06,
      "loss": 0.0664,
      "step": 6156
    },
    {
      "epoch": 1.4147518382352942,
      "grad_norm": 0.9276405572891235,
      "learning_rate": 7.96875e-06,
      "loss": 0.066,
      "step": 6157
    },
    {
      "epoch": 1.4149816176470589,
      "grad_norm": 0.9527352452278137,
      "learning_rate": 7.968239379084968e-06,
      "loss": 0.0631,
      "step": 6158
    },
    {
      "epoch": 1.4152113970588236,
      "grad_norm": 0.8955987095832825,
      "learning_rate": 7.967728758169935e-06,
      "loss": 0.0492,
      "step": 6159
    },
    {
      "epoch": 1.4154411764705883,
      "grad_norm": 1.016423225402832,
      "learning_rate": 7.967218137254902e-06,
      "loss": 0.0552,
      "step": 6160
    },
    {
      "epoch": 1.4156709558823528,
      "grad_norm": 1.1150094270706177,
      "learning_rate": 7.96670751633987e-06,
      "loss": 0.0632,
      "step": 6161
    },
    {
      "epoch": 1.4159007352941178,
      "grad_norm": 0.9854437708854675,
      "learning_rate": 7.966196895424836e-06,
      "loss": 0.0517,
      "step": 6162
    },
    {
      "epoch": 1.4161305147058822,
      "grad_norm": 1.091766119003296,
      "learning_rate": 7.965686274509804e-06,
      "loss": 0.0736,
      "step": 6163
    },
    {
      "epoch": 1.4163602941176472,
      "grad_norm": 1.2455780506134033,
      "learning_rate": 7.965175653594772e-06,
      "loss": 0.091,
      "step": 6164
    },
    {
      "epoch": 1.4165900735294117,
      "grad_norm": 0.8516889214515686,
      "learning_rate": 7.964665032679738e-06,
      "loss": 0.0557,
      "step": 6165
    },
    {
      "epoch": 1.4168198529411764,
      "grad_norm": 1.072805643081665,
      "learning_rate": 7.964154411764706e-06,
      "loss": 0.0505,
      "step": 6166
    },
    {
      "epoch": 1.4170496323529411,
      "grad_norm": 0.944865882396698,
      "learning_rate": 7.963643790849674e-06,
      "loss": 0.0586,
      "step": 6167
    },
    {
      "epoch": 1.4172794117647058,
      "grad_norm": 1.182064175605774,
      "learning_rate": 7.963133169934642e-06,
      "loss": 0.063,
      "step": 6168
    },
    {
      "epoch": 1.4175091911764706,
      "grad_norm": 0.9167961478233337,
      "learning_rate": 7.962622549019608e-06,
      "loss": 0.0431,
      "step": 6169
    },
    {
      "epoch": 1.4177389705882353,
      "grad_norm": 0.8133429288864136,
      "learning_rate": 7.962111928104576e-06,
      "loss": 0.0517,
      "step": 6170
    },
    {
      "epoch": 1.41796875,
      "grad_norm": 1.364175796508789,
      "learning_rate": 7.961601307189542e-06,
      "loss": 0.0845,
      "step": 6171
    },
    {
      "epoch": 1.4181985294117647,
      "grad_norm": 0.9484821557998657,
      "learning_rate": 7.96109068627451e-06,
      "loss": 0.0648,
      "step": 6172
    },
    {
      "epoch": 1.4184283088235294,
      "grad_norm": 0.7951012849807739,
      "learning_rate": 7.960580065359478e-06,
      "loss": 0.0515,
      "step": 6173
    },
    {
      "epoch": 1.4186580882352942,
      "grad_norm": 0.9803653359413147,
      "learning_rate": 7.960069444444444e-06,
      "loss": 0.0567,
      "step": 6174
    },
    {
      "epoch": 1.4188878676470589,
      "grad_norm": 0.8944997787475586,
      "learning_rate": 7.959558823529412e-06,
      "loss": 0.0527,
      "step": 6175
    },
    {
      "epoch": 1.4191176470588236,
      "grad_norm": 0.9054487347602844,
      "learning_rate": 7.95904820261438e-06,
      "loss": 0.0501,
      "step": 6176
    },
    {
      "epoch": 1.4193474264705883,
      "grad_norm": 1.3181142807006836,
      "learning_rate": 7.958537581699348e-06,
      "loss": 0.0857,
      "step": 6177
    },
    {
      "epoch": 1.4195772058823528,
      "grad_norm": 0.8634085059165955,
      "learning_rate": 7.958026960784314e-06,
      "loss": 0.043,
      "step": 6178
    },
    {
      "epoch": 1.4198069852941178,
      "grad_norm": 1.0483543872833252,
      "learning_rate": 7.957516339869282e-06,
      "loss": 0.0502,
      "step": 6179
    },
    {
      "epoch": 1.4200367647058822,
      "grad_norm": 0.618080735206604,
      "learning_rate": 7.95700571895425e-06,
      "loss": 0.0313,
      "step": 6180
    },
    {
      "epoch": 1.4202665441176472,
      "grad_norm": 0.9165984988212585,
      "learning_rate": 7.956495098039216e-06,
      "loss": 0.0527,
      "step": 6181
    },
    {
      "epoch": 1.4204963235294117,
      "grad_norm": 1.1836514472961426,
      "learning_rate": 7.955984477124184e-06,
      "loss": 0.087,
      "step": 6182
    },
    {
      "epoch": 1.4207261029411764,
      "grad_norm": 0.9704207181930542,
      "learning_rate": 7.95547385620915e-06,
      "loss": 0.0385,
      "step": 6183
    },
    {
      "epoch": 1.4209558823529411,
      "grad_norm": 1.033408761024475,
      "learning_rate": 7.95496323529412e-06,
      "loss": 0.0545,
      "step": 6184
    },
    {
      "epoch": 1.4211856617647058,
      "grad_norm": 0.9346590042114258,
      "learning_rate": 7.954452614379085e-06,
      "loss": 0.0504,
      "step": 6185
    },
    {
      "epoch": 1.4214154411764706,
      "grad_norm": 0.8915621638298035,
      "learning_rate": 7.953941993464053e-06,
      "loss": 0.0396,
      "step": 6186
    },
    {
      "epoch": 1.4216452205882353,
      "grad_norm": 0.9837179183959961,
      "learning_rate": 7.95343137254902e-06,
      "loss": 0.0862,
      "step": 6187
    },
    {
      "epoch": 1.421875,
      "grad_norm": 0.6854446530342102,
      "learning_rate": 7.952920751633987e-06,
      "loss": 0.0464,
      "step": 6188
    },
    {
      "epoch": 1.4221047794117647,
      "grad_norm": 0.912471354007721,
      "learning_rate": 7.952410130718955e-06,
      "loss": 0.0713,
      "step": 6189
    },
    {
      "epoch": 1.4223345588235294,
      "grad_norm": 0.8177663087844849,
      "learning_rate": 7.951899509803921e-06,
      "loss": 0.0578,
      "step": 6190
    },
    {
      "epoch": 1.4225643382352942,
      "grad_norm": 1.2036877870559692,
      "learning_rate": 7.95138888888889e-06,
      "loss": 0.0859,
      "step": 6191
    },
    {
      "epoch": 1.4227941176470589,
      "grad_norm": 0.88011234998703,
      "learning_rate": 7.950878267973857e-06,
      "loss": 0.0443,
      "step": 6192
    },
    {
      "epoch": 1.4230238970588236,
      "grad_norm": 0.8293410539627075,
      "learning_rate": 7.950367647058825e-06,
      "loss": 0.0333,
      "step": 6193
    },
    {
      "epoch": 1.4232536764705883,
      "grad_norm": 0.6477762460708618,
      "learning_rate": 7.949857026143791e-06,
      "loss": 0.0384,
      "step": 6194
    },
    {
      "epoch": 1.4234834558823528,
      "grad_norm": 0.9315987825393677,
      "learning_rate": 7.949346405228759e-06,
      "loss": 0.0537,
      "step": 6195
    },
    {
      "epoch": 1.4237132352941178,
      "grad_norm": 0.9418668746948242,
      "learning_rate": 7.948835784313727e-06,
      "loss": 0.0534,
      "step": 6196
    },
    {
      "epoch": 1.4239430147058822,
      "grad_norm": 0.8228068351745605,
      "learning_rate": 7.948325163398693e-06,
      "loss": 0.0319,
      "step": 6197
    },
    {
      "epoch": 1.4241727941176472,
      "grad_norm": 1.1094954013824463,
      "learning_rate": 7.947814542483661e-06,
      "loss": 0.0648,
      "step": 6198
    },
    {
      "epoch": 1.4244025735294117,
      "grad_norm": 0.7019129991531372,
      "learning_rate": 7.947303921568627e-06,
      "loss": 0.0331,
      "step": 6199
    },
    {
      "epoch": 1.4246323529411764,
      "grad_norm": 1.0909862518310547,
      "learning_rate": 7.946793300653597e-06,
      "loss": 0.0538,
      "step": 6200
    },
    {
      "epoch": 1.4248621323529411,
      "grad_norm": 1.1983251571655273,
      "learning_rate": 7.946282679738563e-06,
      "loss": 0.0686,
      "step": 6201
    },
    {
      "epoch": 1.4250919117647058,
      "grad_norm": 0.9900366067886353,
      "learning_rate": 7.94577205882353e-06,
      "loss": 0.0527,
      "step": 6202
    },
    {
      "epoch": 1.4253216911764706,
      "grad_norm": 0.9408114552497864,
      "learning_rate": 7.945261437908497e-06,
      "loss": 0.0573,
      "step": 6203
    },
    {
      "epoch": 1.4255514705882353,
      "grad_norm": 0.7964820861816406,
      "learning_rate": 7.944750816993465e-06,
      "loss": 0.0456,
      "step": 6204
    },
    {
      "epoch": 1.42578125,
      "grad_norm": 0.914663553237915,
      "learning_rate": 7.944240196078433e-06,
      "loss": 0.0493,
      "step": 6205
    },
    {
      "epoch": 1.4260110294117647,
      "grad_norm": 1.0198181867599487,
      "learning_rate": 7.943729575163399e-06,
      "loss": 0.0558,
      "step": 6206
    },
    {
      "epoch": 1.4262408088235294,
      "grad_norm": 1.0995619297027588,
      "learning_rate": 7.943218954248367e-06,
      "loss": 0.0497,
      "step": 6207
    },
    {
      "epoch": 1.4264705882352942,
      "grad_norm": 0.8003379702568054,
      "learning_rate": 7.942708333333334e-06,
      "loss": 0.042,
      "step": 6208
    },
    {
      "epoch": 1.4267003676470589,
      "grad_norm": 0.9858264327049255,
      "learning_rate": 7.9421977124183e-06,
      "loss": 0.0524,
      "step": 6209
    },
    {
      "epoch": 1.4269301470588236,
      "grad_norm": 1.0566242933273315,
      "learning_rate": 7.941687091503268e-06,
      "loss": 0.0538,
      "step": 6210
    },
    {
      "epoch": 1.4271599264705883,
      "grad_norm": 0.791680097579956,
      "learning_rate": 7.941176470588236e-06,
      "loss": 0.0484,
      "step": 6211
    },
    {
      "epoch": 1.4273897058823528,
      "grad_norm": 0.9677392840385437,
      "learning_rate": 7.940665849673204e-06,
      "loss": 0.0397,
      "step": 6212
    },
    {
      "epoch": 1.4276194852941178,
      "grad_norm": 0.7089889645576477,
      "learning_rate": 7.94015522875817e-06,
      "loss": 0.0298,
      "step": 6213
    },
    {
      "epoch": 1.4278492647058822,
      "grad_norm": 0.9565509557723999,
      "learning_rate": 7.939644607843138e-06,
      "loss": 0.0583,
      "step": 6214
    },
    {
      "epoch": 1.4280790441176472,
      "grad_norm": 1.1499857902526855,
      "learning_rate": 7.939133986928104e-06,
      "loss": 0.083,
      "step": 6215
    },
    {
      "epoch": 1.4283088235294117,
      "grad_norm": 1.0579215288162231,
      "learning_rate": 7.938623366013072e-06,
      "loss": 0.0537,
      "step": 6216
    },
    {
      "epoch": 1.4285386029411764,
      "grad_norm": 1.8564399480819702,
      "learning_rate": 7.93811274509804e-06,
      "loss": 0.0756,
      "step": 6217
    },
    {
      "epoch": 1.4287683823529411,
      "grad_norm": 1.1500025987625122,
      "learning_rate": 7.937602124183006e-06,
      "loss": 0.0738,
      "step": 6218
    },
    {
      "epoch": 1.4289981617647058,
      "grad_norm": 0.9583339691162109,
      "learning_rate": 7.937091503267974e-06,
      "loss": 0.0549,
      "step": 6219
    },
    {
      "epoch": 1.4292279411764706,
      "grad_norm": 1.0830589532852173,
      "learning_rate": 7.936580882352942e-06,
      "loss": 0.0451,
      "step": 6220
    },
    {
      "epoch": 1.4294577205882353,
      "grad_norm": 1.0290521383285522,
      "learning_rate": 7.93607026143791e-06,
      "loss": 0.0568,
      "step": 6221
    },
    {
      "epoch": 1.4296875,
      "grad_norm": 0.8696067333221436,
      "learning_rate": 7.935559640522876e-06,
      "loss": 0.0454,
      "step": 6222
    },
    {
      "epoch": 1.4299172794117647,
      "grad_norm": 0.8824373483657837,
      "learning_rate": 7.935049019607844e-06,
      "loss": 0.0593,
      "step": 6223
    },
    {
      "epoch": 1.4301470588235294,
      "grad_norm": 1.000799298286438,
      "learning_rate": 7.934538398692812e-06,
      "loss": 0.0397,
      "step": 6224
    },
    {
      "epoch": 1.4303768382352942,
      "grad_norm": 0.9021177887916565,
      "learning_rate": 7.934027777777778e-06,
      "loss": 0.0378,
      "step": 6225
    },
    {
      "epoch": 1.4306066176470589,
      "grad_norm": 0.950994074344635,
      "learning_rate": 7.933517156862746e-06,
      "loss": 0.0469,
      "step": 6226
    },
    {
      "epoch": 1.4308363970588236,
      "grad_norm": 0.8014588356018066,
      "learning_rate": 7.933006535947712e-06,
      "loss": 0.035,
      "step": 6227
    },
    {
      "epoch": 1.4310661764705883,
      "grad_norm": 1.1338388919830322,
      "learning_rate": 7.932495915032681e-06,
      "loss": 0.0669,
      "step": 6228
    },
    {
      "epoch": 1.4312959558823528,
      "grad_norm": 1.1132307052612305,
      "learning_rate": 7.931985294117648e-06,
      "loss": 0.0463,
      "step": 6229
    },
    {
      "epoch": 1.4315257352941178,
      "grad_norm": 0.938064694404602,
      "learning_rate": 7.931474673202615e-06,
      "loss": 0.0434,
      "step": 6230
    },
    {
      "epoch": 1.4317555147058822,
      "grad_norm": 0.9170260429382324,
      "learning_rate": 7.930964052287582e-06,
      "loss": 0.0608,
      "step": 6231
    },
    {
      "epoch": 1.4319852941176472,
      "grad_norm": 1.1228530406951904,
      "learning_rate": 7.93045343137255e-06,
      "loss": 0.0638,
      "step": 6232
    },
    {
      "epoch": 1.4322150735294117,
      "grad_norm": 0.9575996398925781,
      "learning_rate": 7.929942810457517e-06,
      "loss": 0.0699,
      "step": 6233
    },
    {
      "epoch": 1.4324448529411764,
      "grad_norm": 1.0508174896240234,
      "learning_rate": 7.929432189542484e-06,
      "loss": 0.0466,
      "step": 6234
    },
    {
      "epoch": 1.4326746323529411,
      "grad_norm": 0.9720118641853333,
      "learning_rate": 7.928921568627451e-06,
      "loss": 0.0682,
      "step": 6235
    },
    {
      "epoch": 1.4329044117647058,
      "grad_norm": 1.1726224422454834,
      "learning_rate": 7.92841094771242e-06,
      "loss": 0.0558,
      "step": 6236
    },
    {
      "epoch": 1.4331341911764706,
      "grad_norm": 0.9871147274971008,
      "learning_rate": 7.927900326797387e-06,
      "loss": 0.0422,
      "step": 6237
    },
    {
      "epoch": 1.4333639705882353,
      "grad_norm": 1.1881426572799683,
      "learning_rate": 7.927389705882353e-06,
      "loss": 0.0626,
      "step": 6238
    },
    {
      "epoch": 1.43359375,
      "grad_norm": 1.1622523069381714,
      "learning_rate": 7.926879084967321e-06,
      "loss": 0.0709,
      "step": 6239
    },
    {
      "epoch": 1.4338235294117647,
      "grad_norm": 1.3619427680969238,
      "learning_rate": 7.926368464052289e-06,
      "loss": 0.0573,
      "step": 6240
    },
    {
      "epoch": 1.4340533088235294,
      "grad_norm": 1.0639517307281494,
      "learning_rate": 7.925857843137255e-06,
      "loss": 0.0711,
      "step": 6241
    },
    {
      "epoch": 1.4342830882352942,
      "grad_norm": 1.009057641029358,
      "learning_rate": 7.925347222222223e-06,
      "loss": 0.06,
      "step": 6242
    },
    {
      "epoch": 1.4345128676470589,
      "grad_norm": 0.9535403251647949,
      "learning_rate": 7.92483660130719e-06,
      "loss": 0.0643,
      "step": 6243
    },
    {
      "epoch": 1.4347426470588236,
      "grad_norm": 0.8650022149085999,
      "learning_rate": 7.924325980392159e-06,
      "loss": 0.055,
      "step": 6244
    },
    {
      "epoch": 1.4349724264705883,
      "grad_norm": 0.8136130571365356,
      "learning_rate": 7.923815359477125e-06,
      "loss": 0.038,
      "step": 6245
    },
    {
      "epoch": 1.4352022058823528,
      "grad_norm": 0.9636768698692322,
      "learning_rate": 7.923304738562093e-06,
      "loss": 0.0459,
      "step": 6246
    },
    {
      "epoch": 1.4354319852941178,
      "grad_norm": 0.9352861642837524,
      "learning_rate": 7.922794117647059e-06,
      "loss": 0.0532,
      "step": 6247
    },
    {
      "epoch": 1.4356617647058822,
      "grad_norm": 0.9365167617797852,
      "learning_rate": 7.922283496732027e-06,
      "loss": 0.0517,
      "step": 6248
    },
    {
      "epoch": 1.4358915441176472,
      "grad_norm": 1.070193886756897,
      "learning_rate": 7.921772875816995e-06,
      "loss": 0.0431,
      "step": 6249
    },
    {
      "epoch": 1.4361213235294117,
      "grad_norm": 0.8924593329429626,
      "learning_rate": 7.921262254901961e-06,
      "loss": 0.0443,
      "step": 6250
    },
    {
      "epoch": 1.4363511029411764,
      "grad_norm": 1.2382839918136597,
      "learning_rate": 7.920751633986929e-06,
      "loss": 0.066,
      "step": 6251
    },
    {
      "epoch": 1.4365808823529411,
      "grad_norm": 0.9633728861808777,
      "learning_rate": 7.920241013071897e-06,
      "loss": 0.0522,
      "step": 6252
    },
    {
      "epoch": 1.4368106617647058,
      "grad_norm": 0.8902563452720642,
      "learning_rate": 7.919730392156863e-06,
      "loss": 0.0462,
      "step": 6253
    },
    {
      "epoch": 1.4370404411764706,
      "grad_norm": 1.0408141613006592,
      "learning_rate": 7.91921977124183e-06,
      "loss": 0.0837,
      "step": 6254
    },
    {
      "epoch": 1.4372702205882353,
      "grad_norm": 0.6602401733398438,
      "learning_rate": 7.918709150326798e-06,
      "loss": 0.0342,
      "step": 6255
    },
    {
      "epoch": 1.4375,
      "grad_norm": 0.8092976212501526,
      "learning_rate": 7.918198529411766e-06,
      "loss": 0.0417,
      "step": 6256
    },
    {
      "epoch": 1.4377297794117647,
      "grad_norm": 0.7177600860595703,
      "learning_rate": 7.917687908496733e-06,
      "loss": 0.0381,
      "step": 6257
    },
    {
      "epoch": 1.4379595588235294,
      "grad_norm": 0.8773946762084961,
      "learning_rate": 7.9171772875817e-06,
      "loss": 0.0523,
      "step": 6258
    },
    {
      "epoch": 1.4381893382352942,
      "grad_norm": 0.915405809879303,
      "learning_rate": 7.916666666666667e-06,
      "loss": 0.037,
      "step": 6259
    },
    {
      "epoch": 1.4384191176470589,
      "grad_norm": 1.1783020496368408,
      "learning_rate": 7.916156045751634e-06,
      "loss": 0.0837,
      "step": 6260
    },
    {
      "epoch": 1.4386488970588236,
      "grad_norm": 1.394041895866394,
      "learning_rate": 7.915645424836602e-06,
      "loss": 0.0771,
      "step": 6261
    },
    {
      "epoch": 1.4388786764705883,
      "grad_norm": 1.0833418369293213,
      "learning_rate": 7.915134803921568e-06,
      "loss": 0.0649,
      "step": 6262
    },
    {
      "epoch": 1.4391084558823528,
      "grad_norm": 0.8422902226448059,
      "learning_rate": 7.914624183006536e-06,
      "loss": 0.0414,
      "step": 6263
    },
    {
      "epoch": 1.4393382352941178,
      "grad_norm": 0.7756847739219666,
      "learning_rate": 7.914113562091504e-06,
      "loss": 0.0311,
      "step": 6264
    },
    {
      "epoch": 1.4395680147058822,
      "grad_norm": 1.020420789718628,
      "learning_rate": 7.913602941176472e-06,
      "loss": 0.0543,
      "step": 6265
    },
    {
      "epoch": 1.4397977941176472,
      "grad_norm": 1.038846492767334,
      "learning_rate": 7.913092320261438e-06,
      "loss": 0.053,
      "step": 6266
    },
    {
      "epoch": 1.4400275735294117,
      "grad_norm": 0.8798322677612305,
      "learning_rate": 7.912581699346406e-06,
      "loss": 0.052,
      "step": 6267
    },
    {
      "epoch": 1.4402573529411764,
      "grad_norm": 1.2923353910446167,
      "learning_rate": 7.912071078431374e-06,
      "loss": 0.0657,
      "step": 6268
    },
    {
      "epoch": 1.4404871323529411,
      "grad_norm": 1.0806138515472412,
      "learning_rate": 7.91156045751634e-06,
      "loss": 0.0597,
      "step": 6269
    },
    {
      "epoch": 1.4407169117647058,
      "grad_norm": 0.7358821034431458,
      "learning_rate": 7.911049836601308e-06,
      "loss": 0.029,
      "step": 6270
    },
    {
      "epoch": 1.4409466911764706,
      "grad_norm": 1.1977194547653198,
      "learning_rate": 7.910539215686274e-06,
      "loss": 0.0521,
      "step": 6271
    },
    {
      "epoch": 1.4411764705882353,
      "grad_norm": 0.9367465376853943,
      "learning_rate": 7.910028594771244e-06,
      "loss": 0.0465,
      "step": 6272
    },
    {
      "epoch": 1.44140625,
      "grad_norm": 1.0693349838256836,
      "learning_rate": 7.90951797385621e-06,
      "loss": 0.0507,
      "step": 6273
    },
    {
      "epoch": 1.4416360294117647,
      "grad_norm": 1.0918772220611572,
      "learning_rate": 7.909007352941178e-06,
      "loss": 0.0561,
      "step": 6274
    },
    {
      "epoch": 1.4418658088235294,
      "grad_norm": 1.011775016784668,
      "learning_rate": 7.908496732026144e-06,
      "loss": 0.0601,
      "step": 6275
    },
    {
      "epoch": 1.4420955882352942,
      "grad_norm": 0.7587373852729797,
      "learning_rate": 7.907986111111112e-06,
      "loss": 0.034,
      "step": 6276
    },
    {
      "epoch": 1.4423253676470589,
      "grad_norm": 1.626974105834961,
      "learning_rate": 7.90747549019608e-06,
      "loss": 0.08,
      "step": 6277
    },
    {
      "epoch": 1.4425551470588236,
      "grad_norm": 1.028048038482666,
      "learning_rate": 7.906964869281046e-06,
      "loss": 0.0673,
      "step": 6278
    },
    {
      "epoch": 1.4427849264705883,
      "grad_norm": 0.8618031144142151,
      "learning_rate": 7.906454248366014e-06,
      "loss": 0.0494,
      "step": 6279
    },
    {
      "epoch": 1.4430147058823528,
      "grad_norm": 0.9366048574447632,
      "learning_rate": 7.905943627450981e-06,
      "loss": 0.0413,
      "step": 6280
    },
    {
      "epoch": 1.4432444852941178,
      "grad_norm": 0.8551138043403625,
      "learning_rate": 7.90543300653595e-06,
      "loss": 0.037,
      "step": 6281
    },
    {
      "epoch": 1.4434742647058822,
      "grad_norm": 1.4061025381088257,
      "learning_rate": 7.904922385620915e-06,
      "loss": 0.0744,
      "step": 6282
    },
    {
      "epoch": 1.4437040441176472,
      "grad_norm": 1.3818491697311401,
      "learning_rate": 7.904411764705883e-06,
      "loss": 0.0703,
      "step": 6283
    },
    {
      "epoch": 1.4439338235294117,
      "grad_norm": 1.015305519104004,
      "learning_rate": 7.903901143790851e-06,
      "loss": 0.0581,
      "step": 6284
    },
    {
      "epoch": 1.4441636029411764,
      "grad_norm": 0.9106593132019043,
      "learning_rate": 7.903390522875817e-06,
      "loss": 0.0545,
      "step": 6285
    },
    {
      "epoch": 1.4443933823529411,
      "grad_norm": 1.32683527469635,
      "learning_rate": 7.902879901960785e-06,
      "loss": 0.0833,
      "step": 6286
    },
    {
      "epoch": 1.4446231617647058,
      "grad_norm": 0.7476949095726013,
      "learning_rate": 7.902369281045751e-06,
      "loss": 0.0358,
      "step": 6287
    },
    {
      "epoch": 1.4448529411764706,
      "grad_norm": 1.1990299224853516,
      "learning_rate": 7.90185866013072e-06,
      "loss": 0.0607,
      "step": 6288
    },
    {
      "epoch": 1.4450827205882353,
      "grad_norm": 0.9357889890670776,
      "learning_rate": 7.901348039215687e-06,
      "loss": 0.0492,
      "step": 6289
    },
    {
      "epoch": 1.4453125,
      "grad_norm": 0.9143350124359131,
      "learning_rate": 7.900837418300655e-06,
      "loss": 0.0336,
      "step": 6290
    },
    {
      "epoch": 1.4455422794117647,
      "grad_norm": 0.9531632661819458,
      "learning_rate": 7.900326797385621e-06,
      "loss": 0.059,
      "step": 6291
    },
    {
      "epoch": 1.4457720588235294,
      "grad_norm": 1.12437903881073,
      "learning_rate": 7.899816176470589e-06,
      "loss": 0.0543,
      "step": 6292
    },
    {
      "epoch": 1.4460018382352942,
      "grad_norm": 0.6573699712753296,
      "learning_rate": 7.899305555555557e-06,
      "loss": 0.0276,
      "step": 6293
    },
    {
      "epoch": 1.4462316176470589,
      "grad_norm": 1.0252357721328735,
      "learning_rate": 7.898794934640523e-06,
      "loss": 0.0342,
      "step": 6294
    },
    {
      "epoch": 1.4464613970588236,
      "grad_norm": 0.8264367580413818,
      "learning_rate": 7.898284313725491e-06,
      "loss": 0.0383,
      "step": 6295
    },
    {
      "epoch": 1.4466911764705883,
      "grad_norm": 1.1081286668777466,
      "learning_rate": 7.897773692810459e-06,
      "loss": 0.0582,
      "step": 6296
    },
    {
      "epoch": 1.4469209558823528,
      "grad_norm": 1.341465950012207,
      "learning_rate": 7.897263071895425e-06,
      "loss": 0.0754,
      "step": 6297
    },
    {
      "epoch": 1.4471507352941178,
      "grad_norm": 1.1122939586639404,
      "learning_rate": 7.896752450980393e-06,
      "loss": 0.0671,
      "step": 6298
    },
    {
      "epoch": 1.4473805147058822,
      "grad_norm": 1.0920079946517944,
      "learning_rate": 7.89624183006536e-06,
      "loss": 0.0696,
      "step": 6299
    },
    {
      "epoch": 1.4476102941176472,
      "grad_norm": 0.8453416228294373,
      "learning_rate": 7.895731209150329e-06,
      "loss": 0.0364,
      "step": 6300
    },
    {
      "epoch": 1.4478400735294117,
      "grad_norm": 0.8708427548408508,
      "learning_rate": 7.895220588235295e-06,
      "loss": 0.0448,
      "step": 6301
    },
    {
      "epoch": 1.4480698529411764,
      "grad_norm": 1.0255396366119385,
      "learning_rate": 7.894709967320263e-06,
      "loss": 0.0601,
      "step": 6302
    },
    {
      "epoch": 1.4482996323529411,
      "grad_norm": 1.1149592399597168,
      "learning_rate": 7.894199346405229e-06,
      "loss": 0.0698,
      "step": 6303
    },
    {
      "epoch": 1.4485294117647058,
      "grad_norm": 0.7470523715019226,
      "learning_rate": 7.893688725490197e-06,
      "loss": 0.0445,
      "step": 6304
    },
    {
      "epoch": 1.4487591911764706,
      "grad_norm": 0.7823300957679749,
      "learning_rate": 7.893178104575164e-06,
      "loss": 0.0365,
      "step": 6305
    },
    {
      "epoch": 1.4489889705882353,
      "grad_norm": 1.0670628547668457,
      "learning_rate": 7.89266748366013e-06,
      "loss": 0.0479,
      "step": 6306
    },
    {
      "epoch": 1.44921875,
      "grad_norm": 1.2032839059829712,
      "learning_rate": 7.892156862745098e-06,
      "loss": 0.0523,
      "step": 6307
    },
    {
      "epoch": 1.4494485294117647,
      "grad_norm": 0.8074012398719788,
      "learning_rate": 7.891646241830066e-06,
      "loss": 0.0452,
      "step": 6308
    },
    {
      "epoch": 1.4496783088235294,
      "grad_norm": 0.7059067487716675,
      "learning_rate": 7.891135620915034e-06,
      "loss": 0.0351,
      "step": 6309
    },
    {
      "epoch": 1.4499080882352942,
      "grad_norm": 0.8994014859199524,
      "learning_rate": 7.890625e-06,
      "loss": 0.0333,
      "step": 6310
    },
    {
      "epoch": 1.4501378676470589,
      "grad_norm": 1.123387336730957,
      "learning_rate": 7.890114379084968e-06,
      "loss": 0.0589,
      "step": 6311
    },
    {
      "epoch": 1.4503676470588236,
      "grad_norm": 1.1495753526687622,
      "learning_rate": 7.889603758169934e-06,
      "loss": 0.0794,
      "step": 6312
    },
    {
      "epoch": 1.4505974264705883,
      "grad_norm": 1.070952296257019,
      "learning_rate": 7.889093137254902e-06,
      "loss": 0.06,
      "step": 6313
    },
    {
      "epoch": 1.4508272058823528,
      "grad_norm": 1.0346400737762451,
      "learning_rate": 7.88858251633987e-06,
      "loss": 0.0592,
      "step": 6314
    },
    {
      "epoch": 1.4510569852941178,
      "grad_norm": 1.1924946308135986,
      "learning_rate": 7.888071895424836e-06,
      "loss": 0.0772,
      "step": 6315
    },
    {
      "epoch": 1.4512867647058822,
      "grad_norm": 1.1645121574401855,
      "learning_rate": 7.887561274509804e-06,
      "loss": 0.073,
      "step": 6316
    },
    {
      "epoch": 1.4515165441176472,
      "grad_norm": 1.4393856525421143,
      "learning_rate": 7.887050653594772e-06,
      "loss": 0.0694,
      "step": 6317
    },
    {
      "epoch": 1.4517463235294117,
      "grad_norm": 0.9098635911941528,
      "learning_rate": 7.88654003267974e-06,
      "loss": 0.0498,
      "step": 6318
    },
    {
      "epoch": 1.4519761029411764,
      "grad_norm": 0.7928972840309143,
      "learning_rate": 7.886029411764706e-06,
      "loss": 0.04,
      "step": 6319
    },
    {
      "epoch": 1.4522058823529411,
      "grad_norm": 0.6074284315109253,
      "learning_rate": 7.885518790849674e-06,
      "loss": 0.0273,
      "step": 6320
    },
    {
      "epoch": 1.4524356617647058,
      "grad_norm": 0.9907103776931763,
      "learning_rate": 7.885008169934642e-06,
      "loss": 0.0492,
      "step": 6321
    },
    {
      "epoch": 1.4526654411764706,
      "grad_norm": 1.14108145236969,
      "learning_rate": 7.884497549019608e-06,
      "loss": 0.0462,
      "step": 6322
    },
    {
      "epoch": 1.4528952205882353,
      "grad_norm": 1.105757474899292,
      "learning_rate": 7.883986928104576e-06,
      "loss": 0.0682,
      "step": 6323
    },
    {
      "epoch": 1.453125,
      "grad_norm": 0.8798851370811462,
      "learning_rate": 7.883476307189542e-06,
      "loss": 0.0524,
      "step": 6324
    },
    {
      "epoch": 1.4533547794117647,
      "grad_norm": 1.151865839958191,
      "learning_rate": 7.882965686274512e-06,
      "loss": 0.0635,
      "step": 6325
    },
    {
      "epoch": 1.4535845588235294,
      "grad_norm": 0.6933898329734802,
      "learning_rate": 7.882455065359478e-06,
      "loss": 0.0332,
      "step": 6326
    },
    {
      "epoch": 1.4538143382352942,
      "grad_norm": 0.977269172668457,
      "learning_rate": 7.881944444444446e-06,
      "loss": 0.0415,
      "step": 6327
    },
    {
      "epoch": 1.4540441176470589,
      "grad_norm": 0.9315793514251709,
      "learning_rate": 7.881433823529412e-06,
      "loss": 0.061,
      "step": 6328
    },
    {
      "epoch": 1.4542738970588236,
      "grad_norm": 0.8255866765975952,
      "learning_rate": 7.88092320261438e-06,
      "loss": 0.0485,
      "step": 6329
    },
    {
      "epoch": 1.4545036764705883,
      "grad_norm": 0.8399408459663391,
      "learning_rate": 7.880412581699347e-06,
      "loss": 0.0536,
      "step": 6330
    },
    {
      "epoch": 1.4547334558823528,
      "grad_norm": 1.6150779724121094,
      "learning_rate": 7.879901960784314e-06,
      "loss": 0.0602,
      "step": 6331
    },
    {
      "epoch": 1.4549632352941178,
      "grad_norm": 1.2289702892303467,
      "learning_rate": 7.879391339869281e-06,
      "loss": 0.0454,
      "step": 6332
    },
    {
      "epoch": 1.4551930147058822,
      "grad_norm": 0.9745705723762512,
      "learning_rate": 7.87888071895425e-06,
      "loss": 0.0612,
      "step": 6333
    },
    {
      "epoch": 1.4554227941176472,
      "grad_norm": 1.1490061283111572,
      "learning_rate": 7.878370098039217e-06,
      "loss": 0.0552,
      "step": 6334
    },
    {
      "epoch": 1.4556525735294117,
      "grad_norm": 0.9620895981788635,
      "learning_rate": 7.877859477124183e-06,
      "loss": 0.0538,
      "step": 6335
    },
    {
      "epoch": 1.4558823529411764,
      "grad_norm": 0.964086651802063,
      "learning_rate": 7.877348856209151e-06,
      "loss": 0.0372,
      "step": 6336
    },
    {
      "epoch": 1.4561121323529411,
      "grad_norm": 1.0268346071243286,
      "learning_rate": 7.876838235294119e-06,
      "loss": 0.0498,
      "step": 6337
    },
    {
      "epoch": 1.4563419117647058,
      "grad_norm": 0.7493466734886169,
      "learning_rate": 7.876327614379085e-06,
      "loss": 0.0464,
      "step": 6338
    },
    {
      "epoch": 1.4565716911764706,
      "grad_norm": 0.9566900730133057,
      "learning_rate": 7.875816993464053e-06,
      "loss": 0.0569,
      "step": 6339
    },
    {
      "epoch": 1.4568014705882353,
      "grad_norm": 0.896138072013855,
      "learning_rate": 7.87530637254902e-06,
      "loss": 0.0371,
      "step": 6340
    },
    {
      "epoch": 1.45703125,
      "grad_norm": 0.9309949278831482,
      "learning_rate": 7.874795751633987e-06,
      "loss": 0.0503,
      "step": 6341
    },
    {
      "epoch": 1.4572610294117647,
      "grad_norm": 0.9479097127914429,
      "learning_rate": 7.874285130718955e-06,
      "loss": 0.0523,
      "step": 6342
    },
    {
      "epoch": 1.4574908088235294,
      "grad_norm": 1.3034876585006714,
      "learning_rate": 7.873774509803921e-06,
      "loss": 0.0838,
      "step": 6343
    },
    {
      "epoch": 1.4577205882352942,
      "grad_norm": 1.447247862815857,
      "learning_rate": 7.873263888888889e-06,
      "loss": 0.0968,
      "step": 6344
    },
    {
      "epoch": 1.4579503676470589,
      "grad_norm": 1.093895673751831,
      "learning_rate": 7.872753267973857e-06,
      "loss": 0.0554,
      "step": 6345
    },
    {
      "epoch": 1.4581801470588236,
      "grad_norm": 1.0720603466033936,
      "learning_rate": 7.872242647058825e-06,
      "loss": 0.0469,
      "step": 6346
    },
    {
      "epoch": 1.4584099264705883,
      "grad_norm": 0.9763343334197998,
      "learning_rate": 7.871732026143791e-06,
      "loss": 0.0574,
      "step": 6347
    },
    {
      "epoch": 1.4586397058823528,
      "grad_norm": 1.0716352462768555,
      "learning_rate": 7.871221405228759e-06,
      "loss": 0.0531,
      "step": 6348
    },
    {
      "epoch": 1.4588694852941178,
      "grad_norm": 1.0952664613723755,
      "learning_rate": 7.870710784313727e-06,
      "loss": 0.0592,
      "step": 6349
    },
    {
      "epoch": 1.4590992647058822,
      "grad_norm": 1.1751008033752441,
      "learning_rate": 7.870200163398693e-06,
      "loss": 0.0743,
      "step": 6350
    },
    {
      "epoch": 1.4593290441176472,
      "grad_norm": 0.894929826259613,
      "learning_rate": 7.86968954248366e-06,
      "loss": 0.0548,
      "step": 6351
    },
    {
      "epoch": 1.4595588235294117,
      "grad_norm": 0.9412246942520142,
      "learning_rate": 7.869178921568627e-06,
      "loss": 0.0668,
      "step": 6352
    },
    {
      "epoch": 1.4597886029411764,
      "grad_norm": 0.8492391109466553,
      "learning_rate": 7.868668300653596e-06,
      "loss": 0.0646,
      "step": 6353
    },
    {
      "epoch": 1.4600183823529411,
      "grad_norm": 1.0670503377914429,
      "learning_rate": 7.868157679738563e-06,
      "loss": 0.0636,
      "step": 6354
    },
    {
      "epoch": 1.4602481617647058,
      "grad_norm": 0.6459722518920898,
      "learning_rate": 7.86764705882353e-06,
      "loss": 0.0395,
      "step": 6355
    },
    {
      "epoch": 1.4604779411764706,
      "grad_norm": 1.113874912261963,
      "learning_rate": 7.867136437908497e-06,
      "loss": 0.0405,
      "step": 6356
    },
    {
      "epoch": 1.4607077205882353,
      "grad_norm": 0.9591019749641418,
      "learning_rate": 7.866625816993464e-06,
      "loss": 0.0585,
      "step": 6357
    },
    {
      "epoch": 1.4609375,
      "grad_norm": 1.2624433040618896,
      "learning_rate": 7.866115196078432e-06,
      "loss": 0.0838,
      "step": 6358
    },
    {
      "epoch": 1.4611672794117647,
      "grad_norm": 0.7059236764907837,
      "learning_rate": 7.865604575163398e-06,
      "loss": 0.0433,
      "step": 6359
    },
    {
      "epoch": 1.4613970588235294,
      "grad_norm": 0.8648111820220947,
      "learning_rate": 7.865093954248366e-06,
      "loss": 0.0484,
      "step": 6360
    },
    {
      "epoch": 1.4616268382352942,
      "grad_norm": 0.8575788140296936,
      "learning_rate": 7.864583333333334e-06,
      "loss": 0.0624,
      "step": 6361
    },
    {
      "epoch": 1.4618566176470589,
      "grad_norm": 1.0753856897354126,
      "learning_rate": 7.864072712418302e-06,
      "loss": 0.0871,
      "step": 6362
    },
    {
      "epoch": 1.4620863970588236,
      "grad_norm": 0.7955297231674194,
      "learning_rate": 7.863562091503268e-06,
      "loss": 0.0463,
      "step": 6363
    },
    {
      "epoch": 1.4623161764705883,
      "grad_norm": 1.0304367542266846,
      "learning_rate": 7.863051470588236e-06,
      "loss": 0.0644,
      "step": 6364
    },
    {
      "epoch": 1.4625459558823528,
      "grad_norm": 1.0152876377105713,
      "learning_rate": 7.862540849673204e-06,
      "loss": 0.0284,
      "step": 6365
    },
    {
      "epoch": 1.4627757352941178,
      "grad_norm": 1.4984298944473267,
      "learning_rate": 7.86203022875817e-06,
      "loss": 0.0713,
      "step": 6366
    },
    {
      "epoch": 1.4630055147058822,
      "grad_norm": 1.1140960454940796,
      "learning_rate": 7.861519607843138e-06,
      "loss": 0.0498,
      "step": 6367
    },
    {
      "epoch": 1.4632352941176472,
      "grad_norm": 0.7863084077835083,
      "learning_rate": 7.861008986928104e-06,
      "loss": 0.0492,
      "step": 6368
    },
    {
      "epoch": 1.4634650735294117,
      "grad_norm": 1.236700177192688,
      "learning_rate": 7.860498366013074e-06,
      "loss": 0.0956,
      "step": 6369
    },
    {
      "epoch": 1.4636948529411764,
      "grad_norm": 1.1253563165664673,
      "learning_rate": 7.85998774509804e-06,
      "loss": 0.0298,
      "step": 6370
    },
    {
      "epoch": 1.4639246323529411,
      "grad_norm": 1.2108300924301147,
      "learning_rate": 7.859477124183008e-06,
      "loss": 0.0582,
      "step": 6371
    },
    {
      "epoch": 1.4641544117647058,
      "grad_norm": 0.9893460273742676,
      "learning_rate": 7.858966503267974e-06,
      "loss": 0.0525,
      "step": 6372
    },
    {
      "epoch": 1.4643841911764706,
      "grad_norm": 0.9463093280792236,
      "learning_rate": 7.858455882352942e-06,
      "loss": 0.0493,
      "step": 6373
    },
    {
      "epoch": 1.4646139705882353,
      "grad_norm": 1.235465168952942,
      "learning_rate": 7.85794526143791e-06,
      "loss": 0.049,
      "step": 6374
    },
    {
      "epoch": 1.46484375,
      "grad_norm": 0.9807336330413818,
      "learning_rate": 7.857434640522876e-06,
      "loss": 0.0563,
      "step": 6375
    },
    {
      "epoch": 1.4650735294117647,
      "grad_norm": 1.075200080871582,
      "learning_rate": 7.856924019607844e-06,
      "loss": 0.079,
      "step": 6376
    },
    {
      "epoch": 1.4653033088235294,
      "grad_norm": 0.8241007328033447,
      "learning_rate": 7.856413398692812e-06,
      "loss": 0.0372,
      "step": 6377
    },
    {
      "epoch": 1.4655330882352942,
      "grad_norm": 0.8253700733184814,
      "learning_rate": 7.85590277777778e-06,
      "loss": 0.0501,
      "step": 6378
    },
    {
      "epoch": 1.4657628676470589,
      "grad_norm": 0.9663196206092834,
      "learning_rate": 7.855392156862746e-06,
      "loss": 0.0574,
      "step": 6379
    },
    {
      "epoch": 1.4659926470588236,
      "grad_norm": 1.4777344465255737,
      "learning_rate": 7.854881535947713e-06,
      "loss": 0.0745,
      "step": 6380
    },
    {
      "epoch": 1.4662224264705883,
      "grad_norm": 0.9608175754547119,
      "learning_rate": 7.854370915032681e-06,
      "loss": 0.0842,
      "step": 6381
    },
    {
      "epoch": 1.4664522058823528,
      "grad_norm": 0.7694533467292786,
      "learning_rate": 7.853860294117647e-06,
      "loss": 0.0485,
      "step": 6382
    },
    {
      "epoch": 1.4666819852941178,
      "grad_norm": 0.9280301332473755,
      "learning_rate": 7.853349673202615e-06,
      "loss": 0.0568,
      "step": 6383
    },
    {
      "epoch": 1.4669117647058822,
      "grad_norm": 1.740107536315918,
      "learning_rate": 7.852839052287581e-06,
      "loss": 0.0625,
      "step": 6384
    },
    {
      "epoch": 1.4671415441176472,
      "grad_norm": 1.1034005880355835,
      "learning_rate": 7.85232843137255e-06,
      "loss": 0.0523,
      "step": 6385
    },
    {
      "epoch": 1.4673713235294117,
      "grad_norm": 1.1158514022827148,
      "learning_rate": 7.851817810457517e-06,
      "loss": 0.0507,
      "step": 6386
    },
    {
      "epoch": 1.4676011029411764,
      "grad_norm": 0.7505072355270386,
      "learning_rate": 7.851307189542483e-06,
      "loss": 0.0386,
      "step": 6387
    },
    {
      "epoch": 1.4678308823529411,
      "grad_norm": 1.1503312587738037,
      "learning_rate": 7.850796568627451e-06,
      "loss": 0.0885,
      "step": 6388
    },
    {
      "epoch": 1.4680606617647058,
      "grad_norm": 0.946819007396698,
      "learning_rate": 7.850285947712419e-06,
      "loss": 0.0476,
      "step": 6389
    },
    {
      "epoch": 1.4682904411764706,
      "grad_norm": 0.9763893485069275,
      "learning_rate": 7.849775326797387e-06,
      "loss": 0.0394,
      "step": 6390
    },
    {
      "epoch": 1.4685202205882353,
      "grad_norm": 0.9375332593917847,
      "learning_rate": 7.849264705882353e-06,
      "loss": 0.0657,
      "step": 6391
    },
    {
      "epoch": 1.46875,
      "grad_norm": 0.8686690926551819,
      "learning_rate": 7.848754084967321e-06,
      "loss": 0.0516,
      "step": 6392
    },
    {
      "epoch": 1.4689797794117647,
      "grad_norm": 0.9776542782783508,
      "learning_rate": 7.848243464052289e-06,
      "loss": 0.0314,
      "step": 6393
    },
    {
      "epoch": 1.4692095588235294,
      "grad_norm": 0.8164966106414795,
      "learning_rate": 7.847732843137255e-06,
      "loss": 0.0493,
      "step": 6394
    },
    {
      "epoch": 1.4694393382352942,
      "grad_norm": 0.8951462507247925,
      "learning_rate": 7.847222222222223e-06,
      "loss": 0.0459,
      "step": 6395
    },
    {
      "epoch": 1.4696691176470589,
      "grad_norm": 1.0163644552230835,
      "learning_rate": 7.846711601307189e-06,
      "loss": 0.0583,
      "step": 6396
    },
    {
      "epoch": 1.4698988970588236,
      "grad_norm": 0.7513478398323059,
      "learning_rate": 7.846200980392159e-06,
      "loss": 0.0365,
      "step": 6397
    },
    {
      "epoch": 1.4701286764705883,
      "grad_norm": 0.6148846745491028,
      "learning_rate": 7.845690359477125e-06,
      "loss": 0.0272,
      "step": 6398
    },
    {
      "epoch": 1.4703584558823528,
      "grad_norm": 0.9409078359603882,
      "learning_rate": 7.845179738562093e-06,
      "loss": 0.0495,
      "step": 6399
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 0.8668289184570312,
      "learning_rate": 7.844669117647059e-06,
      "loss": 0.0473,
      "step": 6400
    },
    {
      "epoch": 1.4708180147058822,
      "grad_norm": 0.6399638652801514,
      "learning_rate": 7.844158496732027e-06,
      "loss": 0.0329,
      "step": 6401
    },
    {
      "epoch": 1.4710477941176472,
      "grad_norm": 1.1106324195861816,
      "learning_rate": 7.843647875816994e-06,
      "loss": 0.0535,
      "step": 6402
    },
    {
      "epoch": 1.4712775735294117,
      "grad_norm": 1.003489375114441,
      "learning_rate": 7.84313725490196e-06,
      "loss": 0.0429,
      "step": 6403
    },
    {
      "epoch": 1.4715073529411764,
      "grad_norm": 0.7737960815429688,
      "learning_rate": 7.842626633986929e-06,
      "loss": 0.0401,
      "step": 6404
    },
    {
      "epoch": 1.4717371323529411,
      "grad_norm": 1.426065444946289,
      "learning_rate": 7.842116013071896e-06,
      "loss": 0.0497,
      "step": 6405
    },
    {
      "epoch": 1.4719669117647058,
      "grad_norm": 1.0693902969360352,
      "learning_rate": 7.841605392156864e-06,
      "loss": 0.0549,
      "step": 6406
    },
    {
      "epoch": 1.4721966911764706,
      "grad_norm": 1.010547399520874,
      "learning_rate": 7.84109477124183e-06,
      "loss": 0.0538,
      "step": 6407
    },
    {
      "epoch": 1.4724264705882353,
      "grad_norm": 0.773040235042572,
      "learning_rate": 7.840584150326798e-06,
      "loss": 0.0473,
      "step": 6408
    },
    {
      "epoch": 1.47265625,
      "grad_norm": 1.045767068862915,
      "learning_rate": 7.840073529411766e-06,
      "loss": 0.0376,
      "step": 6409
    },
    {
      "epoch": 1.4728860294117647,
      "grad_norm": 0.8292550444602966,
      "learning_rate": 7.839562908496732e-06,
      "loss": 0.0566,
      "step": 6410
    },
    {
      "epoch": 1.4731158088235294,
      "grad_norm": 1.158619999885559,
      "learning_rate": 7.8390522875817e-06,
      "loss": 0.0635,
      "step": 6411
    },
    {
      "epoch": 1.4733455882352942,
      "grad_norm": 0.6612192392349243,
      "learning_rate": 7.838541666666666e-06,
      "loss": 0.0403,
      "step": 6412
    },
    {
      "epoch": 1.4735753676470589,
      "grad_norm": 0.7350105047225952,
      "learning_rate": 7.838031045751636e-06,
      "loss": 0.0438,
      "step": 6413
    },
    {
      "epoch": 1.4738051470588236,
      "grad_norm": 0.832412838935852,
      "learning_rate": 7.837520424836602e-06,
      "loss": 0.053,
      "step": 6414
    },
    {
      "epoch": 1.4740349264705883,
      "grad_norm": 0.961638867855072,
      "learning_rate": 7.83700980392157e-06,
      "loss": 0.0446,
      "step": 6415
    },
    {
      "epoch": 1.4742647058823528,
      "grad_norm": 1.3392975330352783,
      "learning_rate": 7.836499183006536e-06,
      "loss": 0.0866,
      "step": 6416
    },
    {
      "epoch": 1.4744944852941178,
      "grad_norm": 0.7103127241134644,
      "learning_rate": 7.835988562091504e-06,
      "loss": 0.024,
      "step": 6417
    },
    {
      "epoch": 1.4747242647058822,
      "grad_norm": 0.7495531439781189,
      "learning_rate": 7.835477941176472e-06,
      "loss": 0.0484,
      "step": 6418
    },
    {
      "epoch": 1.4749540441176472,
      "grad_norm": 1.004841685295105,
      "learning_rate": 7.834967320261438e-06,
      "loss": 0.0469,
      "step": 6419
    },
    {
      "epoch": 1.4751838235294117,
      "grad_norm": 1.4249025583267212,
      "learning_rate": 7.834456699346406e-06,
      "loss": 0.068,
      "step": 6420
    },
    {
      "epoch": 1.4754136029411764,
      "grad_norm": 0.7838460803031921,
      "learning_rate": 7.833946078431374e-06,
      "loss": 0.0339,
      "step": 6421
    },
    {
      "epoch": 1.4756433823529411,
      "grad_norm": 0.9437946081161499,
      "learning_rate": 7.833435457516342e-06,
      "loss": 0.0454,
      "step": 6422
    },
    {
      "epoch": 1.4758731617647058,
      "grad_norm": 1.1325873136520386,
      "learning_rate": 7.832924836601308e-06,
      "loss": 0.0687,
      "step": 6423
    },
    {
      "epoch": 1.4761029411764706,
      "grad_norm": 0.6875683069229126,
      "learning_rate": 7.832414215686276e-06,
      "loss": 0.0313,
      "step": 6424
    },
    {
      "epoch": 1.4763327205882353,
      "grad_norm": 1.0265355110168457,
      "learning_rate": 7.831903594771243e-06,
      "loss": 0.0591,
      "step": 6425
    },
    {
      "epoch": 1.4765625,
      "grad_norm": 0.9775548577308655,
      "learning_rate": 7.83139297385621e-06,
      "loss": 0.0549,
      "step": 6426
    },
    {
      "epoch": 1.4767922794117647,
      "grad_norm": 0.708223819732666,
      "learning_rate": 7.830882352941177e-06,
      "loss": 0.0323,
      "step": 6427
    },
    {
      "epoch": 1.4770220588235294,
      "grad_norm": 0.8201897740364075,
      "learning_rate": 7.830371732026144e-06,
      "loss": 0.0397,
      "step": 6428
    },
    {
      "epoch": 1.4772518382352942,
      "grad_norm": 1.2746286392211914,
      "learning_rate": 7.829861111111112e-06,
      "loss": 0.0587,
      "step": 6429
    },
    {
      "epoch": 1.4774816176470589,
      "grad_norm": 1.16505765914917,
      "learning_rate": 7.82935049019608e-06,
      "loss": 0.0631,
      "step": 6430
    },
    {
      "epoch": 1.4777113970588236,
      "grad_norm": 1.1202728748321533,
      "learning_rate": 7.828839869281046e-06,
      "loss": 0.0591,
      "step": 6431
    },
    {
      "epoch": 1.4779411764705883,
      "grad_norm": 0.7804827094078064,
      "learning_rate": 7.828329248366013e-06,
      "loss": 0.0317,
      "step": 6432
    },
    {
      "epoch": 1.4781709558823528,
      "grad_norm": 0.7987069487571716,
      "learning_rate": 7.827818627450981e-06,
      "loss": 0.0543,
      "step": 6433
    },
    {
      "epoch": 1.4784007352941178,
      "grad_norm": 1.247166395187378,
      "learning_rate": 7.827308006535949e-06,
      "loss": 0.068,
      "step": 6434
    },
    {
      "epoch": 1.4786305147058822,
      "grad_norm": 0.9069110751152039,
      "learning_rate": 7.826797385620915e-06,
      "loss": 0.0399,
      "step": 6435
    },
    {
      "epoch": 1.4788602941176472,
      "grad_norm": 0.8144444823265076,
      "learning_rate": 7.826286764705883e-06,
      "loss": 0.0424,
      "step": 6436
    },
    {
      "epoch": 1.4790900735294117,
      "grad_norm": 0.9047074317932129,
      "learning_rate": 7.825776143790851e-06,
      "loss": 0.0313,
      "step": 6437
    },
    {
      "epoch": 1.4793198529411764,
      "grad_norm": 1.292531967163086,
      "learning_rate": 7.825265522875817e-06,
      "loss": 0.0735,
      "step": 6438
    },
    {
      "epoch": 1.4795496323529411,
      "grad_norm": 1.113826870918274,
      "learning_rate": 7.824754901960785e-06,
      "loss": 0.0725,
      "step": 6439
    },
    {
      "epoch": 1.4797794117647058,
      "grad_norm": 0.709823727607727,
      "learning_rate": 7.824244281045751e-06,
      "loss": 0.0474,
      "step": 6440
    },
    {
      "epoch": 1.4800091911764706,
      "grad_norm": 1.1412107944488525,
      "learning_rate": 7.82373366013072e-06,
      "loss": 0.0644,
      "step": 6441
    },
    {
      "epoch": 1.4802389705882353,
      "grad_norm": 1.02627432346344,
      "learning_rate": 7.823223039215687e-06,
      "loss": 0.055,
      "step": 6442
    },
    {
      "epoch": 1.48046875,
      "grad_norm": 1.1123127937316895,
      "learning_rate": 7.822712418300655e-06,
      "loss": 0.063,
      "step": 6443
    },
    {
      "epoch": 1.4806985294117647,
      "grad_norm": 0.9573191404342651,
      "learning_rate": 7.822201797385621e-06,
      "loss": 0.0577,
      "step": 6444
    },
    {
      "epoch": 1.4809283088235294,
      "grad_norm": 0.848170816898346,
      "learning_rate": 7.821691176470589e-06,
      "loss": 0.0473,
      "step": 6445
    },
    {
      "epoch": 1.4811580882352942,
      "grad_norm": 0.7241586446762085,
      "learning_rate": 7.821180555555557e-06,
      "loss": 0.0358,
      "step": 6446
    },
    {
      "epoch": 1.4813878676470589,
      "grad_norm": 0.8991147875785828,
      "learning_rate": 7.820669934640523e-06,
      "loss": 0.051,
      "step": 6447
    },
    {
      "epoch": 1.4816176470588236,
      "grad_norm": 0.897760808467865,
      "learning_rate": 7.82015931372549e-06,
      "loss": 0.042,
      "step": 6448
    },
    {
      "epoch": 1.4818474264705883,
      "grad_norm": 1.2233418226242065,
      "learning_rate": 7.819648692810459e-06,
      "loss": 0.0725,
      "step": 6449
    },
    {
      "epoch": 1.4820772058823528,
      "grad_norm": 1.2287025451660156,
      "learning_rate": 7.819138071895426e-06,
      "loss": 0.0884,
      "step": 6450
    },
    {
      "epoch": 1.4823069852941178,
      "grad_norm": 1.0568851232528687,
      "learning_rate": 7.818627450980393e-06,
      "loss": 0.0743,
      "step": 6451
    },
    {
      "epoch": 1.4825367647058822,
      "grad_norm": 0.9383900761604309,
      "learning_rate": 7.81811683006536e-06,
      "loss": 0.065,
      "step": 6452
    },
    {
      "epoch": 1.4827665441176472,
      "grad_norm": 0.9739488363265991,
      "learning_rate": 7.817606209150328e-06,
      "loss": 0.0378,
      "step": 6453
    },
    {
      "epoch": 1.4829963235294117,
      "grad_norm": 0.9658697843551636,
      "learning_rate": 7.817095588235294e-06,
      "loss": 0.0513,
      "step": 6454
    },
    {
      "epoch": 1.4832261029411764,
      "grad_norm": 1.0829354524612427,
      "learning_rate": 7.816584967320262e-06,
      "loss": 0.0609,
      "step": 6455
    },
    {
      "epoch": 1.4834558823529411,
      "grad_norm": 0.6556525230407715,
      "learning_rate": 7.816074346405229e-06,
      "loss": 0.0372,
      "step": 6456
    },
    {
      "epoch": 1.4836856617647058,
      "grad_norm": 0.8386197686195374,
      "learning_rate": 7.815563725490198e-06,
      "loss": 0.0377,
      "step": 6457
    },
    {
      "epoch": 1.4839154411764706,
      "grad_norm": 0.8819687962532043,
      "learning_rate": 7.815053104575164e-06,
      "loss": 0.0611,
      "step": 6458
    },
    {
      "epoch": 1.4841452205882353,
      "grad_norm": 0.9167044162750244,
      "learning_rate": 7.814542483660132e-06,
      "loss": 0.0561,
      "step": 6459
    },
    {
      "epoch": 1.484375,
      "grad_norm": 1.139086365699768,
      "learning_rate": 7.814031862745098e-06,
      "loss": 0.0465,
      "step": 6460
    },
    {
      "epoch": 1.4846047794117647,
      "grad_norm": 0.8572360873222351,
      "learning_rate": 7.813521241830066e-06,
      "loss": 0.051,
      "step": 6461
    },
    {
      "epoch": 1.4848345588235294,
      "grad_norm": 0.9385597705841064,
      "learning_rate": 7.813010620915034e-06,
      "loss": 0.0468,
      "step": 6462
    },
    {
      "epoch": 1.4850643382352942,
      "grad_norm": 0.9893963932991028,
      "learning_rate": 7.8125e-06,
      "loss": 0.067,
      "step": 6463
    },
    {
      "epoch": 1.4852941176470589,
      "grad_norm": 1.0580931901931763,
      "learning_rate": 7.811989379084968e-06,
      "loss": 0.0567,
      "step": 6464
    },
    {
      "epoch": 1.4855238970588236,
      "grad_norm": 0.8532238602638245,
      "learning_rate": 7.811478758169934e-06,
      "loss": 0.0528,
      "step": 6465
    },
    {
      "epoch": 1.4857536764705883,
      "grad_norm": 1.357293725013733,
      "learning_rate": 7.810968137254902e-06,
      "loss": 0.055,
      "step": 6466
    },
    {
      "epoch": 1.4859834558823528,
      "grad_norm": 1.1748063564300537,
      "learning_rate": 7.81045751633987e-06,
      "loss": 0.0703,
      "step": 6467
    },
    {
      "epoch": 1.4862132352941178,
      "grad_norm": 0.885113537311554,
      "learning_rate": 7.809946895424838e-06,
      "loss": 0.0481,
      "step": 6468
    },
    {
      "epoch": 1.4864430147058822,
      "grad_norm": 0.9219642877578735,
      "learning_rate": 7.809436274509804e-06,
      "loss": 0.0414,
      "step": 6469
    },
    {
      "epoch": 1.4866727941176472,
      "grad_norm": 1.1070387363433838,
      "learning_rate": 7.808925653594772e-06,
      "loss": 0.0449,
      "step": 6470
    },
    {
      "epoch": 1.4869025735294117,
      "grad_norm": 1.1776683330535889,
      "learning_rate": 7.80841503267974e-06,
      "loss": 0.0417,
      "step": 6471
    },
    {
      "epoch": 1.4871323529411764,
      "grad_norm": 1.2276620864868164,
      "learning_rate": 7.807904411764706e-06,
      "loss": 0.0449,
      "step": 6472
    },
    {
      "epoch": 1.4873621323529411,
      "grad_norm": 1.0040594339370728,
      "learning_rate": 7.807393790849674e-06,
      "loss": 0.0481,
      "step": 6473
    },
    {
      "epoch": 1.4875919117647058,
      "grad_norm": 0.8504416942596436,
      "learning_rate": 7.806883169934642e-06,
      "loss": 0.0331,
      "step": 6474
    },
    {
      "epoch": 1.4878216911764706,
      "grad_norm": 1.0487021207809448,
      "learning_rate": 7.806372549019608e-06,
      "loss": 0.0665,
      "step": 6475
    },
    {
      "epoch": 1.4880514705882353,
      "grad_norm": 1.0004955530166626,
      "learning_rate": 7.805861928104576e-06,
      "loss": 0.0546,
      "step": 6476
    },
    {
      "epoch": 1.48828125,
      "grad_norm": 1.2001252174377441,
      "learning_rate": 7.805351307189542e-06,
      "loss": 0.0554,
      "step": 6477
    },
    {
      "epoch": 1.4885110294117647,
      "grad_norm": 1.2237780094146729,
      "learning_rate": 7.804840686274511e-06,
      "loss": 0.0602,
      "step": 6478
    },
    {
      "epoch": 1.4887408088235294,
      "grad_norm": 1.6634422540664673,
      "learning_rate": 7.804330065359477e-06,
      "loss": 0.0787,
      "step": 6479
    },
    {
      "epoch": 1.4889705882352942,
      "grad_norm": 0.9681897759437561,
      "learning_rate": 7.803819444444445e-06,
      "loss": 0.0425,
      "step": 6480
    },
    {
      "epoch": 1.4892003676470589,
      "grad_norm": 1.313685655593872,
      "learning_rate": 7.803308823529412e-06,
      "loss": 0.0654,
      "step": 6481
    },
    {
      "epoch": 1.4894301470588236,
      "grad_norm": 1.1746410131454468,
      "learning_rate": 7.80279820261438e-06,
      "loss": 0.0628,
      "step": 6482
    },
    {
      "epoch": 1.4896599264705883,
      "grad_norm": 0.7271222472190857,
      "learning_rate": 7.802287581699347e-06,
      "loss": 0.0471,
      "step": 6483
    },
    {
      "epoch": 1.4898897058823528,
      "grad_norm": 0.9497649669647217,
      "learning_rate": 7.801776960784313e-06,
      "loss": 0.0483,
      "step": 6484
    },
    {
      "epoch": 1.4901194852941178,
      "grad_norm": 0.9549027681350708,
      "learning_rate": 7.801266339869281e-06,
      "loss": 0.053,
      "step": 6485
    },
    {
      "epoch": 1.4903492647058822,
      "grad_norm": 1.3578317165374756,
      "learning_rate": 7.800755718954249e-06,
      "loss": 0.0668,
      "step": 6486
    },
    {
      "epoch": 1.4905790441176472,
      "grad_norm": 0.9429627060890198,
      "learning_rate": 7.800245098039217e-06,
      "loss": 0.0472,
      "step": 6487
    },
    {
      "epoch": 1.4908088235294117,
      "grad_norm": 1.0299962759017944,
      "learning_rate": 7.799734477124183e-06,
      "loss": 0.0518,
      "step": 6488
    },
    {
      "epoch": 1.4910386029411764,
      "grad_norm": 1.3552441596984863,
      "learning_rate": 7.799223856209151e-06,
      "loss": 0.0931,
      "step": 6489
    },
    {
      "epoch": 1.4912683823529411,
      "grad_norm": 0.9304878115653992,
      "learning_rate": 7.798713235294119e-06,
      "loss": 0.0452,
      "step": 6490
    },
    {
      "epoch": 1.4914981617647058,
      "grad_norm": 1.1394903659820557,
      "learning_rate": 7.798202614379085e-06,
      "loss": 0.0717,
      "step": 6491
    },
    {
      "epoch": 1.4917279411764706,
      "grad_norm": 1.156165361404419,
      "learning_rate": 7.797691993464053e-06,
      "loss": 0.0543,
      "step": 6492
    },
    {
      "epoch": 1.4919577205882353,
      "grad_norm": 1.1276655197143555,
      "learning_rate": 7.797181372549019e-06,
      "loss": 0.0622,
      "step": 6493
    },
    {
      "epoch": 1.4921875,
      "grad_norm": 1.0332896709442139,
      "learning_rate": 7.796670751633989e-06,
      "loss": 0.0412,
      "step": 6494
    },
    {
      "epoch": 1.4924172794117647,
      "grad_norm": 0.9274666905403137,
      "learning_rate": 7.796160130718955e-06,
      "loss": 0.0316,
      "step": 6495
    },
    {
      "epoch": 1.4926470588235294,
      "grad_norm": 0.920767605304718,
      "learning_rate": 7.795649509803923e-06,
      "loss": 0.0419,
      "step": 6496
    },
    {
      "epoch": 1.4928768382352942,
      "grad_norm": 1.0480341911315918,
      "learning_rate": 7.795138888888889e-06,
      "loss": 0.0508,
      "step": 6497
    },
    {
      "epoch": 1.4931066176470589,
      "grad_norm": 0.8093505501747131,
      "learning_rate": 7.794628267973857e-06,
      "loss": 0.0623,
      "step": 6498
    },
    {
      "epoch": 1.4933363970588236,
      "grad_norm": 0.9679032564163208,
      "learning_rate": 7.794117647058825e-06,
      "loss": 0.0452,
      "step": 6499
    },
    {
      "epoch": 1.4935661764705883,
      "grad_norm": 0.8220877647399902,
      "learning_rate": 7.79360702614379e-06,
      "loss": 0.0355,
      "step": 6500
    },
    {
      "epoch": 1.4935661764705883,
      "eval_loss": 0.05609430372714996,
      "eval_runtime": 2006.8568,
      "eval_samples_per_second": 4.438,
      "eval_steps_per_second": 2.219,
      "step": 6500
    },
    {
      "epoch": 1.4937959558823528,
      "grad_norm": 0.9813589453697205,
      "learning_rate": 7.793096405228759e-06,
      "loss": 0.0575,
      "step": 6501
    },
    {
      "epoch": 1.4940257352941178,
      "grad_norm": 1.0085707902908325,
      "learning_rate": 7.792585784313726e-06,
      "loss": 0.0545,
      "step": 6502
    },
    {
      "epoch": 1.4942555147058822,
      "grad_norm": 0.675527811050415,
      "learning_rate": 7.792075163398694e-06,
      "loss": 0.0348,
      "step": 6503
    },
    {
      "epoch": 1.4944852941176472,
      "grad_norm": 1.0754679441452026,
      "learning_rate": 7.79156454248366e-06,
      "loss": 0.0493,
      "step": 6504
    },
    {
      "epoch": 1.4947150735294117,
      "grad_norm": 0.9469352960586548,
      "learning_rate": 7.791053921568628e-06,
      "loss": 0.0594,
      "step": 6505
    },
    {
      "epoch": 1.4949448529411764,
      "grad_norm": 1.0254325866699219,
      "learning_rate": 7.790543300653596e-06,
      "loss": 0.0577,
      "step": 6506
    },
    {
      "epoch": 1.4951746323529411,
      "grad_norm": 0.8705206513404846,
      "learning_rate": 7.790032679738562e-06,
      "loss": 0.057,
      "step": 6507
    },
    {
      "epoch": 1.4954044117647058,
      "grad_norm": 0.9357109069824219,
      "learning_rate": 7.78952205882353e-06,
      "loss": 0.0547,
      "step": 6508
    },
    {
      "epoch": 1.4956341911764706,
      "grad_norm": 1.0893023014068604,
      "learning_rate": 7.789011437908496e-06,
      "loss": 0.0638,
      "step": 6509
    },
    {
      "epoch": 1.4958639705882353,
      "grad_norm": 0.904614269733429,
      "learning_rate": 7.788500816993464e-06,
      "loss": 0.061,
      "step": 6510
    },
    {
      "epoch": 1.49609375,
      "grad_norm": 1.1246229410171509,
      "learning_rate": 7.787990196078432e-06,
      "loss": 0.0389,
      "step": 6511
    },
    {
      "epoch": 1.4963235294117647,
      "grad_norm": 0.8533387780189514,
      "learning_rate": 7.7874795751634e-06,
      "loss": 0.0462,
      "step": 6512
    },
    {
      "epoch": 1.4965533088235294,
      "grad_norm": 0.9483259916305542,
      "learning_rate": 7.786968954248366e-06,
      "loss": 0.0469,
      "step": 6513
    },
    {
      "epoch": 1.4967830882352942,
      "grad_norm": 0.7086667418479919,
      "learning_rate": 7.786458333333334e-06,
      "loss": 0.0413,
      "step": 6514
    },
    {
      "epoch": 1.4970128676470589,
      "grad_norm": 1.2441048622131348,
      "learning_rate": 7.785947712418302e-06,
      "loss": 0.064,
      "step": 6515
    },
    {
      "epoch": 1.4972426470588236,
      "grad_norm": 0.9740139842033386,
      "learning_rate": 7.785437091503268e-06,
      "loss": 0.0505,
      "step": 6516
    },
    {
      "epoch": 1.4974724264705883,
      "grad_norm": 0.6680572628974915,
      "learning_rate": 7.784926470588236e-06,
      "loss": 0.0287,
      "step": 6517
    },
    {
      "epoch": 1.4977022058823528,
      "grad_norm": 1.0955569744110107,
      "learning_rate": 7.784415849673204e-06,
      "loss": 0.0449,
      "step": 6518
    },
    {
      "epoch": 1.4979319852941178,
      "grad_norm": 0.7291507124900818,
      "learning_rate": 7.78390522875817e-06,
      "loss": 0.0428,
      "step": 6519
    },
    {
      "epoch": 1.4981617647058822,
      "grad_norm": 0.8050753474235535,
      "learning_rate": 7.783394607843138e-06,
      "loss": 0.0426,
      "step": 6520
    },
    {
      "epoch": 1.4983915441176472,
      "grad_norm": 1.0539270639419556,
      "learning_rate": 7.782883986928104e-06,
      "loss": 0.0505,
      "step": 6521
    },
    {
      "epoch": 1.4986213235294117,
      "grad_norm": 1.1031721830368042,
      "learning_rate": 7.782373366013073e-06,
      "loss": 0.0841,
      "step": 6522
    },
    {
      "epoch": 1.4988511029411764,
      "grad_norm": 1.215699315071106,
      "learning_rate": 7.78186274509804e-06,
      "loss": 0.068,
      "step": 6523
    },
    {
      "epoch": 1.4990808823529411,
      "grad_norm": 0.9591643214225769,
      "learning_rate": 7.781352124183008e-06,
      "loss": 0.0525,
      "step": 6524
    },
    {
      "epoch": 1.4993106617647058,
      "grad_norm": 1.064293384552002,
      "learning_rate": 7.780841503267974e-06,
      "loss": 0.0622,
      "step": 6525
    },
    {
      "epoch": 1.4995404411764706,
      "grad_norm": 0.722164511680603,
      "learning_rate": 7.780330882352942e-06,
      "loss": 0.025,
      "step": 6526
    },
    {
      "epoch": 1.4997702205882353,
      "grad_norm": 0.9495472311973572,
      "learning_rate": 7.77982026143791e-06,
      "loss": 0.0477,
      "step": 6527
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.0025107860565186,
      "learning_rate": 7.779309640522876e-06,
      "loss": 0.0448,
      "step": 6528
    },
    {
      "epoch": 1.5002297794117647,
      "grad_norm": 1.1374317407608032,
      "learning_rate": 7.778799019607843e-06,
      "loss": 0.0619,
      "step": 6529
    },
    {
      "epoch": 1.5004595588235294,
      "grad_norm": 0.8158241510391235,
      "learning_rate": 7.778288398692811e-06,
      "loss": 0.037,
      "step": 6530
    },
    {
      "epoch": 1.5006893382352942,
      "grad_norm": 1.2398858070373535,
      "learning_rate": 7.77777777777778e-06,
      "loss": 0.09,
      "step": 6531
    },
    {
      "epoch": 1.5009191176470589,
      "grad_norm": 0.8921772837638855,
      "learning_rate": 7.777267156862745e-06,
      "loss": 0.0534,
      "step": 6532
    },
    {
      "epoch": 1.5011488970588234,
      "grad_norm": 0.9586107134819031,
      "learning_rate": 7.776756535947713e-06,
      "loss": 0.0501,
      "step": 6533
    },
    {
      "epoch": 1.5013786764705883,
      "grad_norm": 1.1404664516448975,
      "learning_rate": 7.776245915032681e-06,
      "loss": 0.0549,
      "step": 6534
    },
    {
      "epoch": 1.5016084558823528,
      "grad_norm": 0.7499105930328369,
      "learning_rate": 7.775735294117647e-06,
      "loss": 0.0318,
      "step": 6535
    },
    {
      "epoch": 1.5018382352941178,
      "grad_norm": 0.9246577024459839,
      "learning_rate": 7.775224673202615e-06,
      "loss": 0.0503,
      "step": 6536
    },
    {
      "epoch": 1.5020680147058822,
      "grad_norm": 1.0638011693954468,
      "learning_rate": 7.774714052287581e-06,
      "loss": 0.0423,
      "step": 6537
    },
    {
      "epoch": 1.5022977941176472,
      "grad_norm": 1.396447777748108,
      "learning_rate": 7.77420343137255e-06,
      "loss": 0.0571,
      "step": 6538
    },
    {
      "epoch": 1.5025275735294117,
      "grad_norm": 0.7716256976127625,
      "learning_rate": 7.773692810457517e-06,
      "loss": 0.0422,
      "step": 6539
    },
    {
      "epoch": 1.5027573529411766,
      "grad_norm": 1.1813946962356567,
      "learning_rate": 7.773182189542485e-06,
      "loss": 0.062,
      "step": 6540
    },
    {
      "epoch": 1.5029871323529411,
      "grad_norm": 0.9404716491699219,
      "learning_rate": 7.772671568627451e-06,
      "loss": 0.0409,
      "step": 6541
    },
    {
      "epoch": 1.5032169117647058,
      "grad_norm": 0.7989182472229004,
      "learning_rate": 7.772160947712419e-06,
      "loss": 0.0483,
      "step": 6542
    },
    {
      "epoch": 1.5034466911764706,
      "grad_norm": 0.7811952829360962,
      "learning_rate": 7.771650326797387e-06,
      "loss": 0.0536,
      "step": 6543
    },
    {
      "epoch": 1.5036764705882353,
      "grad_norm": 1.1576428413391113,
      "learning_rate": 7.771139705882353e-06,
      "loss": 0.0499,
      "step": 6544
    },
    {
      "epoch": 1.50390625,
      "grad_norm": 0.9600609540939331,
      "learning_rate": 7.77062908496732e-06,
      "loss": 0.0452,
      "step": 6545
    },
    {
      "epoch": 1.5041360294117647,
      "grad_norm": 1.0559836626052856,
      "learning_rate": 7.770118464052289e-06,
      "loss": 0.073,
      "step": 6546
    },
    {
      "epoch": 1.5043658088235294,
      "grad_norm": 1.1743084192276,
      "learning_rate": 7.769607843137256e-06,
      "loss": 0.054,
      "step": 6547
    },
    {
      "epoch": 1.5045955882352942,
      "grad_norm": 0.8630574941635132,
      "learning_rate": 7.769097222222223e-06,
      "loss": 0.0626,
      "step": 6548
    },
    {
      "epoch": 1.5048253676470589,
      "grad_norm": 0.8026570081710815,
      "learning_rate": 7.76858660130719e-06,
      "loss": 0.0353,
      "step": 6549
    },
    {
      "epoch": 1.5050551470588234,
      "grad_norm": 0.8325416445732117,
      "learning_rate": 7.768075980392158e-06,
      "loss": 0.0501,
      "step": 6550
    },
    {
      "epoch": 1.5052849264705883,
      "grad_norm": 1.0989896059036255,
      "learning_rate": 7.767565359477125e-06,
      "loss": 0.0595,
      "step": 6551
    },
    {
      "epoch": 1.5055147058823528,
      "grad_norm": 0.9196155071258545,
      "learning_rate": 7.767054738562092e-06,
      "loss": 0.0489,
      "step": 6552
    },
    {
      "epoch": 1.5057444852941178,
      "grad_norm": 1.012545108795166,
      "learning_rate": 7.766544117647059e-06,
      "loss": 0.0758,
      "step": 6553
    },
    {
      "epoch": 1.5059742647058822,
      "grad_norm": 0.7597029209136963,
      "learning_rate": 7.766033496732026e-06,
      "loss": 0.0355,
      "step": 6554
    },
    {
      "epoch": 1.5062040441176472,
      "grad_norm": 0.8333032727241516,
      "learning_rate": 7.765522875816994e-06,
      "loss": 0.0506,
      "step": 6555
    },
    {
      "epoch": 1.5064338235294117,
      "grad_norm": 0.9915854334831238,
      "learning_rate": 7.765012254901962e-06,
      "loss": 0.0479,
      "step": 6556
    },
    {
      "epoch": 1.5066636029411766,
      "grad_norm": 0.6792030334472656,
      "learning_rate": 7.764501633986928e-06,
      "loss": 0.0321,
      "step": 6557
    },
    {
      "epoch": 1.5068933823529411,
      "grad_norm": 0.8436339497566223,
      "learning_rate": 7.763991013071896e-06,
      "loss": 0.0435,
      "step": 6558
    },
    {
      "epoch": 1.5071231617647058,
      "grad_norm": 0.766106128692627,
      "learning_rate": 7.763480392156864e-06,
      "loss": 0.0287,
      "step": 6559
    },
    {
      "epoch": 1.5073529411764706,
      "grad_norm": 0.8132251501083374,
      "learning_rate": 7.76296977124183e-06,
      "loss": 0.0538,
      "step": 6560
    },
    {
      "epoch": 1.5075827205882353,
      "grad_norm": 1.109288215637207,
      "learning_rate": 7.762459150326798e-06,
      "loss": 0.0765,
      "step": 6561
    },
    {
      "epoch": 1.5078125,
      "grad_norm": 1.071728229522705,
      "learning_rate": 7.761948529411766e-06,
      "loss": 0.055,
      "step": 6562
    },
    {
      "epoch": 1.5080422794117647,
      "grad_norm": 0.8514068722724915,
      "learning_rate": 7.761437908496732e-06,
      "loss": 0.0524,
      "step": 6563
    },
    {
      "epoch": 1.5082720588235294,
      "grad_norm": 0.8764206171035767,
      "learning_rate": 7.7609272875817e-06,
      "loss": 0.0626,
      "step": 6564
    },
    {
      "epoch": 1.5085018382352942,
      "grad_norm": 1.004258155822754,
      "learning_rate": 7.760416666666666e-06,
      "loss": 0.0513,
      "step": 6565
    },
    {
      "epoch": 1.5087316176470589,
      "grad_norm": 1.0458886623382568,
      "learning_rate": 7.759906045751636e-06,
      "loss": 0.0402,
      "step": 6566
    },
    {
      "epoch": 1.5089613970588234,
      "grad_norm": 0.8394950032234192,
      "learning_rate": 7.759395424836602e-06,
      "loss": 0.049,
      "step": 6567
    },
    {
      "epoch": 1.5091911764705883,
      "grad_norm": 0.8468424677848816,
      "learning_rate": 7.75888480392157e-06,
      "loss": 0.0389,
      "step": 6568
    },
    {
      "epoch": 1.5094209558823528,
      "grad_norm": 1.2783547639846802,
      "learning_rate": 7.758374183006536e-06,
      "loss": 0.0455,
      "step": 6569
    },
    {
      "epoch": 1.5096507352941178,
      "grad_norm": 1.1049718856811523,
      "learning_rate": 7.757863562091504e-06,
      "loss": 0.0603,
      "step": 6570
    },
    {
      "epoch": 1.5098805147058822,
      "grad_norm": 0.9540225863456726,
      "learning_rate": 7.757352941176472e-06,
      "loss": 0.0592,
      "step": 6571
    },
    {
      "epoch": 1.5101102941176472,
      "grad_norm": 0.86772620677948,
      "learning_rate": 7.756842320261438e-06,
      "loss": 0.0529,
      "step": 6572
    },
    {
      "epoch": 1.5103400735294117,
      "grad_norm": 1.1696667671203613,
      "learning_rate": 7.756331699346406e-06,
      "loss": 0.0651,
      "step": 6573
    },
    {
      "epoch": 1.5105698529411766,
      "grad_norm": 0.8690199851989746,
      "learning_rate": 7.755821078431373e-06,
      "loss": 0.0481,
      "step": 6574
    },
    {
      "epoch": 1.5107996323529411,
      "grad_norm": 1.0788875818252563,
      "learning_rate": 7.755310457516341e-06,
      "loss": 0.0686,
      "step": 6575
    },
    {
      "epoch": 1.5110294117647058,
      "grad_norm": 1.0499906539916992,
      "learning_rate": 7.754799836601308e-06,
      "loss": 0.0669,
      "step": 6576
    },
    {
      "epoch": 1.5112591911764706,
      "grad_norm": 1.206872582435608,
      "learning_rate": 7.754289215686275e-06,
      "loss": 0.0632,
      "step": 6577
    },
    {
      "epoch": 1.5114889705882353,
      "grad_norm": 1.5471183061599731,
      "learning_rate": 7.753778594771243e-06,
      "loss": 0.0407,
      "step": 6578
    },
    {
      "epoch": 1.51171875,
      "grad_norm": 1.2207039594650269,
      "learning_rate": 7.75326797385621e-06,
      "loss": 0.0585,
      "step": 6579
    },
    {
      "epoch": 1.5119485294117647,
      "grad_norm": 1.0807000398635864,
      "learning_rate": 7.752757352941177e-06,
      "loss": 0.0748,
      "step": 6580
    },
    {
      "epoch": 1.5121783088235294,
      "grad_norm": 1.2409733533859253,
      "learning_rate": 7.752246732026143e-06,
      "loss": 0.0513,
      "step": 6581
    },
    {
      "epoch": 1.5124080882352942,
      "grad_norm": 0.9760687351226807,
      "learning_rate": 7.751736111111113e-06,
      "loss": 0.0397,
      "step": 6582
    },
    {
      "epoch": 1.5126378676470589,
      "grad_norm": 0.7710651159286499,
      "learning_rate": 7.75122549019608e-06,
      "loss": 0.0453,
      "step": 6583
    },
    {
      "epoch": 1.5128676470588234,
      "grad_norm": 1.1680161952972412,
      "learning_rate": 7.750714869281047e-06,
      "loss": 0.0523,
      "step": 6584
    },
    {
      "epoch": 1.5130974264705883,
      "grad_norm": 1.1559725999832153,
      "learning_rate": 7.750204248366013e-06,
      "loss": 0.0913,
      "step": 6585
    },
    {
      "epoch": 1.5133272058823528,
      "grad_norm": 0.689556360244751,
      "learning_rate": 7.749693627450981e-06,
      "loss": 0.0403,
      "step": 6586
    },
    {
      "epoch": 1.5135569852941178,
      "grad_norm": 1.1808757781982422,
      "learning_rate": 7.749183006535949e-06,
      "loss": 0.0539,
      "step": 6587
    },
    {
      "epoch": 1.5137867647058822,
      "grad_norm": 1.1464520692825317,
      "learning_rate": 7.748672385620915e-06,
      "loss": 0.0878,
      "step": 6588
    },
    {
      "epoch": 1.5140165441176472,
      "grad_norm": 1.1677597761154175,
      "learning_rate": 7.748161764705883e-06,
      "loss": 0.0506,
      "step": 6589
    },
    {
      "epoch": 1.5142463235294117,
      "grad_norm": 0.840573251247406,
      "learning_rate": 7.74765114379085e-06,
      "loss": 0.0345,
      "step": 6590
    },
    {
      "epoch": 1.5144761029411766,
      "grad_norm": 0.8815380930900574,
      "learning_rate": 7.747140522875819e-06,
      "loss": 0.035,
      "step": 6591
    },
    {
      "epoch": 1.5147058823529411,
      "grad_norm": 0.901721179485321,
      "learning_rate": 7.746629901960785e-06,
      "loss": 0.0349,
      "step": 6592
    },
    {
      "epoch": 1.5149356617647058,
      "grad_norm": 1.8198492527008057,
      "learning_rate": 7.746119281045753e-06,
      "loss": 0.0885,
      "step": 6593
    },
    {
      "epoch": 1.5151654411764706,
      "grad_norm": 0.8058521747589111,
      "learning_rate": 7.74560866013072e-06,
      "loss": 0.0381,
      "step": 6594
    },
    {
      "epoch": 1.5153952205882353,
      "grad_norm": 0.944382905960083,
      "learning_rate": 7.745098039215687e-06,
      "loss": 0.0511,
      "step": 6595
    },
    {
      "epoch": 1.515625,
      "grad_norm": 0.9005346894264221,
      "learning_rate": 7.744587418300655e-06,
      "loss": 0.0694,
      "step": 6596
    },
    {
      "epoch": 1.5158547794117647,
      "grad_norm": 1.521242380142212,
      "learning_rate": 7.74407679738562e-06,
      "loss": 0.0713,
      "step": 6597
    },
    {
      "epoch": 1.5160845588235294,
      "grad_norm": 1.183200716972351,
      "learning_rate": 7.743566176470589e-06,
      "loss": 0.0678,
      "step": 6598
    },
    {
      "epoch": 1.5163143382352942,
      "grad_norm": 0.7516158819198608,
      "learning_rate": 7.743055555555556e-06,
      "loss": 0.0464,
      "step": 6599
    },
    {
      "epoch": 1.5165441176470589,
      "grad_norm": 1.0444718599319458,
      "learning_rate": 7.742544934640523e-06,
      "loss": 0.0754,
      "step": 6600
    },
    {
      "epoch": 1.5167738970588234,
      "grad_norm": 1.0822287797927856,
      "learning_rate": 7.74203431372549e-06,
      "loss": 0.0514,
      "step": 6601
    },
    {
      "epoch": 1.5170036764705883,
      "grad_norm": 0.9229525327682495,
      "learning_rate": 7.741523692810458e-06,
      "loss": 0.0565,
      "step": 6602
    },
    {
      "epoch": 1.5172334558823528,
      "grad_norm": 1.2974404096603394,
      "learning_rate": 7.741013071895426e-06,
      "loss": 0.0916,
      "step": 6603
    },
    {
      "epoch": 1.5174632352941178,
      "grad_norm": 0.8371955752372742,
      "learning_rate": 7.740502450980392e-06,
      "loss": 0.04,
      "step": 6604
    },
    {
      "epoch": 1.5176930147058822,
      "grad_norm": 0.8104105591773987,
      "learning_rate": 7.73999183006536e-06,
      "loss": 0.04,
      "step": 6605
    },
    {
      "epoch": 1.5179227941176472,
      "grad_norm": 1.2899668216705322,
      "learning_rate": 7.739481209150328e-06,
      "loss": 0.0652,
      "step": 6606
    },
    {
      "epoch": 1.5181525735294117,
      "grad_norm": 1.0972776412963867,
      "learning_rate": 7.738970588235294e-06,
      "loss": 0.047,
      "step": 6607
    },
    {
      "epoch": 1.5183823529411766,
      "grad_norm": 0.7170390486717224,
      "learning_rate": 7.738459967320262e-06,
      "loss": 0.0386,
      "step": 6608
    },
    {
      "epoch": 1.5186121323529411,
      "grad_norm": 0.6705034375190735,
      "learning_rate": 7.737949346405228e-06,
      "loss": 0.0314,
      "step": 6609
    },
    {
      "epoch": 1.5188419117647058,
      "grad_norm": 0.8130797147750854,
      "learning_rate": 7.737438725490198e-06,
      "loss": 0.0392,
      "step": 6610
    },
    {
      "epoch": 1.5190716911764706,
      "grad_norm": 0.9668751955032349,
      "learning_rate": 7.736928104575164e-06,
      "loss": 0.0412,
      "step": 6611
    },
    {
      "epoch": 1.5193014705882353,
      "grad_norm": 0.8240538239479065,
      "learning_rate": 7.736417483660132e-06,
      "loss": 0.0427,
      "step": 6612
    },
    {
      "epoch": 1.51953125,
      "grad_norm": 0.8169352412223816,
      "learning_rate": 7.735906862745098e-06,
      "loss": 0.044,
      "step": 6613
    },
    {
      "epoch": 1.5197610294117647,
      "grad_norm": 0.9639437198638916,
      "learning_rate": 7.735396241830066e-06,
      "loss": 0.0587,
      "step": 6614
    },
    {
      "epoch": 1.5199908088235294,
      "grad_norm": 0.9285750985145569,
      "learning_rate": 7.734885620915034e-06,
      "loss": 0.0659,
      "step": 6615
    },
    {
      "epoch": 1.5202205882352942,
      "grad_norm": 0.8200640678405762,
      "learning_rate": 7.734375e-06,
      "loss": 0.0301,
      "step": 6616
    },
    {
      "epoch": 1.5204503676470589,
      "grad_norm": 1.0624157190322876,
      "learning_rate": 7.733864379084968e-06,
      "loss": 0.0469,
      "step": 6617
    },
    {
      "epoch": 1.5206801470588234,
      "grad_norm": 0.9939982295036316,
      "learning_rate": 7.733353758169934e-06,
      "loss": 0.0741,
      "step": 6618
    },
    {
      "epoch": 1.5209099264705883,
      "grad_norm": 1.0715035200119019,
      "learning_rate": 7.732843137254904e-06,
      "loss": 0.0607,
      "step": 6619
    },
    {
      "epoch": 1.5211397058823528,
      "grad_norm": 0.6773148775100708,
      "learning_rate": 7.73233251633987e-06,
      "loss": 0.0262,
      "step": 6620
    },
    {
      "epoch": 1.5213694852941178,
      "grad_norm": 0.8403142094612122,
      "learning_rate": 7.731821895424838e-06,
      "loss": 0.0464,
      "step": 6621
    },
    {
      "epoch": 1.5215992647058822,
      "grad_norm": 1.1441274881362915,
      "learning_rate": 7.731311274509804e-06,
      "loss": 0.0648,
      "step": 6622
    },
    {
      "epoch": 1.5218290441176472,
      "grad_norm": 1.0765647888183594,
      "learning_rate": 7.730800653594772e-06,
      "loss": 0.0448,
      "step": 6623
    },
    {
      "epoch": 1.5220588235294117,
      "grad_norm": 0.7263810634613037,
      "learning_rate": 7.73029003267974e-06,
      "loss": 0.0339,
      "step": 6624
    },
    {
      "epoch": 1.5222886029411766,
      "grad_norm": 1.541559100151062,
      "learning_rate": 7.729779411764706e-06,
      "loss": 0.0945,
      "step": 6625
    },
    {
      "epoch": 1.5225183823529411,
      "grad_norm": 1.0076251029968262,
      "learning_rate": 7.729268790849673e-06,
      "loss": 0.047,
      "step": 6626
    },
    {
      "epoch": 1.5227481617647058,
      "grad_norm": 0.9226166009902954,
      "learning_rate": 7.728758169934641e-06,
      "loss": 0.0531,
      "step": 6627
    },
    {
      "epoch": 1.5229779411764706,
      "grad_norm": 0.9584299921989441,
      "learning_rate": 7.72824754901961e-06,
      "loss": 0.0606,
      "step": 6628
    },
    {
      "epoch": 1.5232077205882353,
      "grad_norm": 0.9331048727035522,
      "learning_rate": 7.727736928104575e-06,
      "loss": 0.0413,
      "step": 6629
    },
    {
      "epoch": 1.5234375,
      "grad_norm": 0.8429694771766663,
      "learning_rate": 7.727226307189543e-06,
      "loss": 0.0538,
      "step": 6630
    },
    {
      "epoch": 1.5236672794117647,
      "grad_norm": 0.9407874345779419,
      "learning_rate": 7.726715686274511e-06,
      "loss": 0.0492,
      "step": 6631
    },
    {
      "epoch": 1.5238970588235294,
      "grad_norm": 0.9769358038902283,
      "learning_rate": 7.726205065359477e-06,
      "loss": 0.0431,
      "step": 6632
    },
    {
      "epoch": 1.5241268382352942,
      "grad_norm": 0.7307093143463135,
      "learning_rate": 7.725694444444445e-06,
      "loss": 0.0455,
      "step": 6633
    },
    {
      "epoch": 1.5243566176470589,
      "grad_norm": 0.9768769145011902,
      "learning_rate": 7.725183823529411e-06,
      "loss": 0.0626,
      "step": 6634
    },
    {
      "epoch": 1.5245863970588234,
      "grad_norm": 1.3403809070587158,
      "learning_rate": 7.724673202614381e-06,
      "loss": 0.0779,
      "step": 6635
    },
    {
      "epoch": 1.5248161764705883,
      "grad_norm": 1.0329416990280151,
      "learning_rate": 7.724162581699347e-06,
      "loss": 0.062,
      "step": 6636
    },
    {
      "epoch": 1.5250459558823528,
      "grad_norm": 0.8094732761383057,
      "learning_rate": 7.723651960784315e-06,
      "loss": 0.0381,
      "step": 6637
    },
    {
      "epoch": 1.5252757352941178,
      "grad_norm": 0.7975447773933411,
      "learning_rate": 7.723141339869281e-06,
      "loss": 0.0503,
      "step": 6638
    },
    {
      "epoch": 1.5255055147058822,
      "grad_norm": 1.1492935419082642,
      "learning_rate": 7.722630718954249e-06,
      "loss": 0.049,
      "step": 6639
    },
    {
      "epoch": 1.5257352941176472,
      "grad_norm": 0.9847894906997681,
      "learning_rate": 7.722120098039217e-06,
      "loss": 0.0262,
      "step": 6640
    },
    {
      "epoch": 1.5259650735294117,
      "grad_norm": 0.8458878993988037,
      "learning_rate": 7.721609477124183e-06,
      "loss": 0.0503,
      "step": 6641
    },
    {
      "epoch": 1.5261948529411766,
      "grad_norm": 1.1099364757537842,
      "learning_rate": 7.72109885620915e-06,
      "loss": 0.0496,
      "step": 6642
    },
    {
      "epoch": 1.5264246323529411,
      "grad_norm": 1.1678588390350342,
      "learning_rate": 7.720588235294119e-06,
      "loss": 0.067,
      "step": 6643
    },
    {
      "epoch": 1.5266544117647058,
      "grad_norm": 1.06315279006958,
      "learning_rate": 7.720077614379085e-06,
      "loss": 0.0461,
      "step": 6644
    },
    {
      "epoch": 1.5268841911764706,
      "grad_norm": 0.8294855356216431,
      "learning_rate": 7.719566993464053e-06,
      "loss": 0.0356,
      "step": 6645
    },
    {
      "epoch": 1.5271139705882353,
      "grad_norm": 1.1713236570358276,
      "learning_rate": 7.71905637254902e-06,
      "loss": 0.0577,
      "step": 6646
    },
    {
      "epoch": 1.52734375,
      "grad_norm": 0.9296988248825073,
      "learning_rate": 7.718545751633988e-06,
      "loss": 0.0447,
      "step": 6647
    },
    {
      "epoch": 1.5275735294117647,
      "grad_norm": 1.3261672258377075,
      "learning_rate": 7.718035130718955e-06,
      "loss": 0.0664,
      "step": 6648
    },
    {
      "epoch": 1.5278033088235294,
      "grad_norm": 0.8847270011901855,
      "learning_rate": 7.717524509803922e-06,
      "loss": 0.0443,
      "step": 6649
    },
    {
      "epoch": 1.5280330882352942,
      "grad_norm": 0.7068527340888977,
      "learning_rate": 7.717013888888889e-06,
      "loss": 0.0356,
      "step": 6650
    },
    {
      "epoch": 1.5282628676470589,
      "grad_norm": 0.9381087422370911,
      "learning_rate": 7.716503267973856e-06,
      "loss": 0.0684,
      "step": 6651
    },
    {
      "epoch": 1.5284926470588234,
      "grad_norm": 1.010360836982727,
      "learning_rate": 7.715992647058824e-06,
      "loss": 0.0707,
      "step": 6652
    },
    {
      "epoch": 1.5287224264705883,
      "grad_norm": 0.8489272594451904,
      "learning_rate": 7.71548202614379e-06,
      "loss": 0.0458,
      "step": 6653
    },
    {
      "epoch": 1.5289522058823528,
      "grad_norm": 1.237491250038147,
      "learning_rate": 7.714971405228758e-06,
      "loss": 0.056,
      "step": 6654
    },
    {
      "epoch": 1.5291819852941178,
      "grad_norm": 0.902021586894989,
      "learning_rate": 7.714460784313726e-06,
      "loss": 0.0543,
      "step": 6655
    },
    {
      "epoch": 1.5294117647058822,
      "grad_norm": 1.3052024841308594,
      "learning_rate": 7.713950163398694e-06,
      "loss": 0.0945,
      "step": 6656
    },
    {
      "epoch": 1.5296415441176472,
      "grad_norm": 1.0788224935531616,
      "learning_rate": 7.71343954248366e-06,
      "loss": 0.0686,
      "step": 6657
    },
    {
      "epoch": 1.5298713235294117,
      "grad_norm": 1.0095890760421753,
      "learning_rate": 7.712928921568628e-06,
      "loss": 0.0568,
      "step": 6658
    },
    {
      "epoch": 1.5301011029411766,
      "grad_norm": 1.3511080741882324,
      "learning_rate": 7.712418300653596e-06,
      "loss": 0.0534,
      "step": 6659
    },
    {
      "epoch": 1.5303308823529411,
      "grad_norm": 0.677399218082428,
      "learning_rate": 7.711907679738562e-06,
      "loss": 0.0246,
      "step": 6660
    },
    {
      "epoch": 1.5305606617647058,
      "grad_norm": 0.8445106744766235,
      "learning_rate": 7.71139705882353e-06,
      "loss": 0.0598,
      "step": 6661
    },
    {
      "epoch": 1.5307904411764706,
      "grad_norm": 0.8730255961418152,
      "learning_rate": 7.710886437908496e-06,
      "loss": 0.0589,
      "step": 6662
    },
    {
      "epoch": 1.5310202205882353,
      "grad_norm": 1.1781927347183228,
      "learning_rate": 7.710375816993466e-06,
      "loss": 0.0582,
      "step": 6663
    },
    {
      "epoch": 1.53125,
      "grad_norm": 1.003748893737793,
      "learning_rate": 7.709865196078432e-06,
      "loss": 0.0487,
      "step": 6664
    },
    {
      "epoch": 1.5314797794117647,
      "grad_norm": 0.8085577487945557,
      "learning_rate": 7.7093545751634e-06,
      "loss": 0.0598,
      "step": 6665
    },
    {
      "epoch": 1.5317095588235294,
      "grad_norm": 1.0068012475967407,
      "learning_rate": 7.708843954248366e-06,
      "loss": 0.0421,
      "step": 6666
    },
    {
      "epoch": 1.5319393382352942,
      "grad_norm": 0.8231573104858398,
      "learning_rate": 7.708333333333334e-06,
      "loss": 0.0545,
      "step": 6667
    },
    {
      "epoch": 1.5321691176470589,
      "grad_norm": 0.72372967004776,
      "learning_rate": 7.707822712418302e-06,
      "loss": 0.0471,
      "step": 6668
    },
    {
      "epoch": 1.5323988970588234,
      "grad_norm": 0.9798576831817627,
      "learning_rate": 7.707312091503268e-06,
      "loss": 0.0507,
      "step": 6669
    },
    {
      "epoch": 1.5326286764705883,
      "grad_norm": 0.5394936203956604,
      "learning_rate": 7.706801470588236e-06,
      "loss": 0.0194,
      "step": 6670
    },
    {
      "epoch": 1.5328584558823528,
      "grad_norm": 1.142822504043579,
      "learning_rate": 7.706290849673204e-06,
      "loss": 0.0652,
      "step": 6671
    },
    {
      "epoch": 1.5330882352941178,
      "grad_norm": 1.0142860412597656,
      "learning_rate": 7.705780228758171e-06,
      "loss": 0.0636,
      "step": 6672
    },
    {
      "epoch": 1.5333180147058822,
      "grad_norm": 0.8173115849494934,
      "learning_rate": 7.705269607843138e-06,
      "loss": 0.0422,
      "step": 6673
    },
    {
      "epoch": 1.5335477941176472,
      "grad_norm": 0.9848554730415344,
      "learning_rate": 7.704758986928105e-06,
      "loss": 0.048,
      "step": 6674
    },
    {
      "epoch": 1.5337775735294117,
      "grad_norm": 0.9291277527809143,
      "learning_rate": 7.704248366013073e-06,
      "loss": 0.0499,
      "step": 6675
    },
    {
      "epoch": 1.5340073529411766,
      "grad_norm": 1.0174510478973389,
      "learning_rate": 7.70373774509804e-06,
      "loss": 0.0533,
      "step": 6676
    },
    {
      "epoch": 1.5342371323529411,
      "grad_norm": 0.8767009377479553,
      "learning_rate": 7.703227124183007e-06,
      "loss": 0.0562,
      "step": 6677
    },
    {
      "epoch": 1.5344669117647058,
      "grad_norm": 1.0044443607330322,
      "learning_rate": 7.702716503267973e-06,
      "loss": 0.0512,
      "step": 6678
    },
    {
      "epoch": 1.5346966911764706,
      "grad_norm": 1.3946768045425415,
      "learning_rate": 7.702205882352943e-06,
      "loss": 0.0824,
      "step": 6679
    },
    {
      "epoch": 1.5349264705882353,
      "grad_norm": 1.3062435388565063,
      "learning_rate": 7.70169526143791e-06,
      "loss": 0.081,
      "step": 6680
    },
    {
      "epoch": 1.53515625,
      "grad_norm": 1.0567843914031982,
      "learning_rate": 7.701184640522877e-06,
      "loss": 0.0694,
      "step": 6681
    },
    {
      "epoch": 1.5353860294117647,
      "grad_norm": 0.8174958825111389,
      "learning_rate": 7.700674019607843e-06,
      "loss": 0.0426,
      "step": 6682
    },
    {
      "epoch": 1.5356158088235294,
      "grad_norm": 0.7682020664215088,
      "learning_rate": 7.700163398692811e-06,
      "loss": 0.0334,
      "step": 6683
    },
    {
      "epoch": 1.5358455882352942,
      "grad_norm": 0.8458746671676636,
      "learning_rate": 7.699652777777779e-06,
      "loss": 0.0443,
      "step": 6684
    },
    {
      "epoch": 1.5360753676470589,
      "grad_norm": 1.1876029968261719,
      "learning_rate": 7.699142156862745e-06,
      "loss": 0.0578,
      "step": 6685
    },
    {
      "epoch": 1.5363051470588234,
      "grad_norm": 1.0340133905410767,
      "learning_rate": 7.698631535947713e-06,
      "loss": 0.0506,
      "step": 6686
    },
    {
      "epoch": 1.5365349264705883,
      "grad_norm": 0.620223343372345,
      "learning_rate": 7.698120915032681e-06,
      "loss": 0.0331,
      "step": 6687
    },
    {
      "epoch": 1.5367647058823528,
      "grad_norm": 1.730737566947937,
      "learning_rate": 7.697610294117647e-06,
      "loss": 0.0839,
      "step": 6688
    },
    {
      "epoch": 1.5369944852941178,
      "grad_norm": 1.13594651222229,
      "learning_rate": 7.697099673202615e-06,
      "loss": 0.0659,
      "step": 6689
    },
    {
      "epoch": 1.5372242647058822,
      "grad_norm": 0.9041357636451721,
      "learning_rate": 7.696589052287583e-06,
      "loss": 0.0526,
      "step": 6690
    },
    {
      "epoch": 1.5374540441176472,
      "grad_norm": 1.2341583967208862,
      "learning_rate": 7.69607843137255e-06,
      "loss": 0.0543,
      "step": 6691
    },
    {
      "epoch": 1.5376838235294117,
      "grad_norm": 1.0264590978622437,
      "learning_rate": 7.695567810457517e-06,
      "loss": 0.0668,
      "step": 6692
    },
    {
      "epoch": 1.5379136029411766,
      "grad_norm": 1.1005747318267822,
      "learning_rate": 7.695057189542485e-06,
      "loss": 0.0703,
      "step": 6693
    },
    {
      "epoch": 1.5381433823529411,
      "grad_norm": 0.8332914113998413,
      "learning_rate": 7.69454656862745e-06,
      "loss": 0.0442,
      "step": 6694
    },
    {
      "epoch": 1.5383731617647058,
      "grad_norm": 0.8622604608535767,
      "learning_rate": 7.694035947712419e-06,
      "loss": 0.0445,
      "step": 6695
    },
    {
      "epoch": 1.5386029411764706,
      "grad_norm": 0.7874455451965332,
      "learning_rate": 7.693525326797387e-06,
      "loss": 0.0506,
      "step": 6696
    },
    {
      "epoch": 1.5388327205882353,
      "grad_norm": 0.842719316482544,
      "learning_rate": 7.693014705882353e-06,
      "loss": 0.0368,
      "step": 6697
    },
    {
      "epoch": 1.5390625,
      "grad_norm": 1.0628358125686646,
      "learning_rate": 7.69250408496732e-06,
      "loss": 0.0543,
      "step": 6698
    },
    {
      "epoch": 1.5392922794117647,
      "grad_norm": 0.8734999895095825,
      "learning_rate": 7.691993464052288e-06,
      "loss": 0.0714,
      "step": 6699
    },
    {
      "epoch": 1.5395220588235294,
      "grad_norm": 0.684781551361084,
      "learning_rate": 7.691482843137256e-06,
      "loss": 0.029,
      "step": 6700
    },
    {
      "epoch": 1.5397518382352942,
      "grad_norm": 0.6924408078193665,
      "learning_rate": 7.690972222222222e-06,
      "loss": 0.045,
      "step": 6701
    },
    {
      "epoch": 1.5399816176470589,
      "grad_norm": 1.0714956521987915,
      "learning_rate": 7.69046160130719e-06,
      "loss": 0.0789,
      "step": 6702
    },
    {
      "epoch": 1.5402113970588234,
      "grad_norm": 1.029855728149414,
      "learning_rate": 7.689950980392158e-06,
      "loss": 0.0436,
      "step": 6703
    },
    {
      "epoch": 1.5404411764705883,
      "grad_norm": 0.9446178674697876,
      "learning_rate": 7.689440359477124e-06,
      "loss": 0.0513,
      "step": 6704
    },
    {
      "epoch": 1.5406709558823528,
      "grad_norm": 0.9221891760826111,
      "learning_rate": 7.688929738562092e-06,
      "loss": 0.0585,
      "step": 6705
    },
    {
      "epoch": 1.5409007352941178,
      "grad_norm": 1.1187223196029663,
      "learning_rate": 7.688419117647058e-06,
      "loss": 0.0545,
      "step": 6706
    },
    {
      "epoch": 1.5411305147058822,
      "grad_norm": 0.871554970741272,
      "learning_rate": 7.687908496732028e-06,
      "loss": 0.0482,
      "step": 6707
    },
    {
      "epoch": 1.5413602941176472,
      "grad_norm": 0.9236243367195129,
      "learning_rate": 7.687397875816994e-06,
      "loss": 0.0526,
      "step": 6708
    },
    {
      "epoch": 1.5415900735294117,
      "grad_norm": 1.1189117431640625,
      "learning_rate": 7.686887254901962e-06,
      "loss": 0.0673,
      "step": 6709
    },
    {
      "epoch": 1.5418198529411766,
      "grad_norm": 1.399898886680603,
      "learning_rate": 7.686376633986928e-06,
      "loss": 0.0794,
      "step": 6710
    },
    {
      "epoch": 1.5420496323529411,
      "grad_norm": 1.1450666189193726,
      "learning_rate": 7.685866013071896e-06,
      "loss": 0.0452,
      "step": 6711
    },
    {
      "epoch": 1.5422794117647058,
      "grad_norm": 1.122506856918335,
      "learning_rate": 7.685355392156864e-06,
      "loss": 0.0746,
      "step": 6712
    },
    {
      "epoch": 1.5425091911764706,
      "grad_norm": 0.9156018495559692,
      "learning_rate": 7.68484477124183e-06,
      "loss": 0.035,
      "step": 6713
    },
    {
      "epoch": 1.5427389705882353,
      "grad_norm": 1.1345837116241455,
      "learning_rate": 7.684334150326798e-06,
      "loss": 0.06,
      "step": 6714
    },
    {
      "epoch": 1.54296875,
      "grad_norm": 1.208953619003296,
      "learning_rate": 7.683823529411766e-06,
      "loss": 0.0587,
      "step": 6715
    },
    {
      "epoch": 1.5431985294117647,
      "grad_norm": 1.0949803590774536,
      "learning_rate": 7.683312908496734e-06,
      "loss": 0.0628,
      "step": 6716
    },
    {
      "epoch": 1.5434283088235294,
      "grad_norm": 0.9945415258407593,
      "learning_rate": 7.6828022875817e-06,
      "loss": 0.0701,
      "step": 6717
    },
    {
      "epoch": 1.5436580882352942,
      "grad_norm": 0.7759305834770203,
      "learning_rate": 7.682291666666668e-06,
      "loss": 0.029,
      "step": 6718
    },
    {
      "epoch": 1.5438878676470589,
      "grad_norm": 1.0878480672836304,
      "learning_rate": 7.681781045751635e-06,
      "loss": 0.0544,
      "step": 6719
    },
    {
      "epoch": 1.5441176470588234,
      "grad_norm": 0.7989565134048462,
      "learning_rate": 7.681270424836602e-06,
      "loss": 0.0533,
      "step": 6720
    },
    {
      "epoch": 1.5443474264705883,
      "grad_norm": 0.9813329577445984,
      "learning_rate": 7.68075980392157e-06,
      "loss": 0.0409,
      "step": 6721
    },
    {
      "epoch": 1.5445772058823528,
      "grad_norm": 0.9082150459289551,
      "learning_rate": 7.680249183006536e-06,
      "loss": 0.0461,
      "step": 6722
    },
    {
      "epoch": 1.5448069852941178,
      "grad_norm": 0.9665578007698059,
      "learning_rate": 7.679738562091504e-06,
      "loss": 0.0578,
      "step": 6723
    },
    {
      "epoch": 1.5450367647058822,
      "grad_norm": 1.1646372079849243,
      "learning_rate": 7.679227941176471e-06,
      "loss": 0.0493,
      "step": 6724
    },
    {
      "epoch": 1.5452665441176472,
      "grad_norm": 1.0896613597869873,
      "learning_rate": 7.67871732026144e-06,
      "loss": 0.0528,
      "step": 6725
    },
    {
      "epoch": 1.5454963235294117,
      "grad_norm": 1.0489206314086914,
      "learning_rate": 7.678206699346405e-06,
      "loss": 0.0739,
      "step": 6726
    },
    {
      "epoch": 1.5457261029411766,
      "grad_norm": 0.8488592505455017,
      "learning_rate": 7.677696078431373e-06,
      "loss": 0.0552,
      "step": 6727
    },
    {
      "epoch": 1.5459558823529411,
      "grad_norm": 1.0696518421173096,
      "learning_rate": 7.677185457516341e-06,
      "loss": 0.0627,
      "step": 6728
    },
    {
      "epoch": 1.5461856617647058,
      "grad_norm": 1.5497794151306152,
      "learning_rate": 7.676674836601307e-06,
      "loss": 0.0752,
      "step": 6729
    },
    {
      "epoch": 1.5464154411764706,
      "grad_norm": 0.8609288930892944,
      "learning_rate": 7.676164215686275e-06,
      "loss": 0.0482,
      "step": 6730
    },
    {
      "epoch": 1.5466452205882353,
      "grad_norm": 0.9407086968421936,
      "learning_rate": 7.675653594771243e-06,
      "loss": 0.0493,
      "step": 6731
    },
    {
      "epoch": 1.546875,
      "grad_norm": 1.2731943130493164,
      "learning_rate": 7.67514297385621e-06,
      "loss": 0.0546,
      "step": 6732
    },
    {
      "epoch": 1.5471047794117647,
      "grad_norm": 1.2545716762542725,
      "learning_rate": 7.674632352941177e-06,
      "loss": 0.0894,
      "step": 6733
    },
    {
      "epoch": 1.5473345588235294,
      "grad_norm": 0.9420164227485657,
      "learning_rate": 7.674121732026143e-06,
      "loss": 0.0439,
      "step": 6734
    },
    {
      "epoch": 1.5475643382352942,
      "grad_norm": 1.1772942543029785,
      "learning_rate": 7.673611111111113e-06,
      "loss": 0.0595,
      "step": 6735
    },
    {
      "epoch": 1.5477941176470589,
      "grad_norm": 0.8434514403343201,
      "learning_rate": 7.673100490196079e-06,
      "loss": 0.0367,
      "step": 6736
    },
    {
      "epoch": 1.5480238970588234,
      "grad_norm": 0.9888663291931152,
      "learning_rate": 7.672589869281047e-06,
      "loss": 0.0578,
      "step": 6737
    },
    {
      "epoch": 1.5482536764705883,
      "grad_norm": 1.3533896207809448,
      "learning_rate": 7.672079248366013e-06,
      "loss": 0.0701,
      "step": 6738
    },
    {
      "epoch": 1.5484834558823528,
      "grad_norm": 0.7943785786628723,
      "learning_rate": 7.671568627450981e-06,
      "loss": 0.048,
      "step": 6739
    },
    {
      "epoch": 1.5487132352941178,
      "grad_norm": 0.7028502225875854,
      "learning_rate": 7.671058006535949e-06,
      "loss": 0.0397,
      "step": 6740
    },
    {
      "epoch": 1.5489430147058822,
      "grad_norm": 1.290207862854004,
      "learning_rate": 7.670547385620915e-06,
      "loss": 0.0483,
      "step": 6741
    },
    {
      "epoch": 1.5491727941176472,
      "grad_norm": 0.9223098158836365,
      "learning_rate": 7.670036764705883e-06,
      "loss": 0.0447,
      "step": 6742
    },
    {
      "epoch": 1.5494025735294117,
      "grad_norm": 1.0154221057891846,
      "learning_rate": 7.66952614379085e-06,
      "loss": 0.0644,
      "step": 6743
    },
    {
      "epoch": 1.5496323529411766,
      "grad_norm": 1.134132742881775,
      "learning_rate": 7.669015522875818e-06,
      "loss": 0.0626,
      "step": 6744
    },
    {
      "epoch": 1.5498621323529411,
      "grad_norm": 0.9013347029685974,
      "learning_rate": 7.668504901960785e-06,
      "loss": 0.0351,
      "step": 6745
    },
    {
      "epoch": 1.5500919117647058,
      "grad_norm": 0.9770370721817017,
      "learning_rate": 7.667994281045752e-06,
      "loss": 0.0595,
      "step": 6746
    },
    {
      "epoch": 1.5503216911764706,
      "grad_norm": 0.8411121964454651,
      "learning_rate": 7.66748366013072e-06,
      "loss": 0.0427,
      "step": 6747
    },
    {
      "epoch": 1.5505514705882353,
      "grad_norm": 0.7390224933624268,
      "learning_rate": 7.666973039215687e-06,
      "loss": 0.0463,
      "step": 6748
    },
    {
      "epoch": 1.55078125,
      "grad_norm": 1.0160185098648071,
      "learning_rate": 7.666462418300654e-06,
      "loss": 0.0627,
      "step": 6749
    },
    {
      "epoch": 1.5510110294117647,
      "grad_norm": 1.3540608882904053,
      "learning_rate": 7.66595179738562e-06,
      "loss": 0.0882,
      "step": 6750
    },
    {
      "epoch": 1.5512408088235294,
      "grad_norm": 0.9134427309036255,
      "learning_rate": 7.66544117647059e-06,
      "loss": 0.0405,
      "step": 6751
    },
    {
      "epoch": 1.5514705882352942,
      "grad_norm": 0.8150134682655334,
      "learning_rate": 7.664930555555556e-06,
      "loss": 0.0487,
      "step": 6752
    },
    {
      "epoch": 1.5517003676470589,
      "grad_norm": 1.058331847190857,
      "learning_rate": 7.664419934640524e-06,
      "loss": 0.0613,
      "step": 6753
    },
    {
      "epoch": 1.5519301470588234,
      "grad_norm": 1.0306789875030518,
      "learning_rate": 7.66390931372549e-06,
      "loss": 0.0419,
      "step": 6754
    },
    {
      "epoch": 1.5521599264705883,
      "grad_norm": 0.7795455455780029,
      "learning_rate": 7.663398692810458e-06,
      "loss": 0.0468,
      "step": 6755
    },
    {
      "epoch": 1.5523897058823528,
      "grad_norm": 1.190096378326416,
      "learning_rate": 7.662888071895426e-06,
      "loss": 0.0336,
      "step": 6756
    },
    {
      "epoch": 1.5526194852941178,
      "grad_norm": 0.9159348011016846,
      "learning_rate": 7.662377450980392e-06,
      "loss": 0.0652,
      "step": 6757
    },
    {
      "epoch": 1.5528492647058822,
      "grad_norm": 0.8131785988807678,
      "learning_rate": 7.66186683006536e-06,
      "loss": 0.0421,
      "step": 6758
    },
    {
      "epoch": 1.5530790441176472,
      "grad_norm": 0.9659311175346375,
      "learning_rate": 7.661356209150328e-06,
      "loss": 0.0402,
      "step": 6759
    },
    {
      "epoch": 1.5533088235294117,
      "grad_norm": 1.0705598592758179,
      "learning_rate": 7.660845588235296e-06,
      "loss": 0.0558,
      "step": 6760
    },
    {
      "epoch": 1.5535386029411766,
      "grad_norm": 1.123732328414917,
      "learning_rate": 7.660334967320262e-06,
      "loss": 0.0638,
      "step": 6761
    },
    {
      "epoch": 1.5537683823529411,
      "grad_norm": 1.0053600072860718,
      "learning_rate": 7.65982434640523e-06,
      "loss": 0.0532,
      "step": 6762
    },
    {
      "epoch": 1.5539981617647058,
      "grad_norm": 0.9991192817687988,
      "learning_rate": 7.659313725490198e-06,
      "loss": 0.047,
      "step": 6763
    },
    {
      "epoch": 1.5542279411764706,
      "grad_norm": 1.0452245473861694,
      "learning_rate": 7.658803104575164e-06,
      "loss": 0.0605,
      "step": 6764
    },
    {
      "epoch": 1.5544577205882353,
      "grad_norm": 1.229514241218567,
      "learning_rate": 7.658292483660132e-06,
      "loss": 0.0773,
      "step": 6765
    },
    {
      "epoch": 1.5546875,
      "grad_norm": 0.9346538782119751,
      "learning_rate": 7.657781862745098e-06,
      "loss": 0.0442,
      "step": 6766
    },
    {
      "epoch": 1.5549172794117647,
      "grad_norm": 0.8669765591621399,
      "learning_rate": 7.657271241830066e-06,
      "loss": 0.0454,
      "step": 6767
    },
    {
      "epoch": 1.5551470588235294,
      "grad_norm": 0.6418064832687378,
      "learning_rate": 7.656760620915034e-06,
      "loss": 0.0308,
      "step": 6768
    },
    {
      "epoch": 1.5553768382352942,
      "grad_norm": 0.8872600197792053,
      "learning_rate": 7.656250000000001e-06,
      "loss": 0.0496,
      "step": 6769
    },
    {
      "epoch": 1.5556066176470589,
      "grad_norm": 1.121281385421753,
      "learning_rate": 7.655739379084968e-06,
      "loss": 0.0411,
      "step": 6770
    },
    {
      "epoch": 1.5558363970588234,
      "grad_norm": 0.8313247561454773,
      "learning_rate": 7.655228758169935e-06,
      "loss": 0.046,
      "step": 6771
    },
    {
      "epoch": 1.5560661764705883,
      "grad_norm": 0.8894957900047302,
      "learning_rate": 7.654718137254903e-06,
      "loss": 0.0525,
      "step": 6772
    },
    {
      "epoch": 1.5562959558823528,
      "grad_norm": 1.0634337663650513,
      "learning_rate": 7.65420751633987e-06,
      "loss": 0.0378,
      "step": 6773
    },
    {
      "epoch": 1.5565257352941178,
      "grad_norm": 0.9450495839118958,
      "learning_rate": 7.653696895424837e-06,
      "loss": 0.046,
      "step": 6774
    },
    {
      "epoch": 1.5567555147058822,
      "grad_norm": 1.0509089231491089,
      "learning_rate": 7.653186274509804e-06,
      "loss": 0.0591,
      "step": 6775
    },
    {
      "epoch": 1.5569852941176472,
      "grad_norm": 0.7342014312744141,
      "learning_rate": 7.652675653594771e-06,
      "loss": 0.0359,
      "step": 6776
    },
    {
      "epoch": 1.5572150735294117,
      "grad_norm": 0.9405680894851685,
      "learning_rate": 7.65216503267974e-06,
      "loss": 0.048,
      "step": 6777
    },
    {
      "epoch": 1.5574448529411766,
      "grad_norm": 1.1332380771636963,
      "learning_rate": 7.651654411764705e-06,
      "loss": 0.0689,
      "step": 6778
    },
    {
      "epoch": 1.5576746323529411,
      "grad_norm": 1.0319976806640625,
      "learning_rate": 7.651143790849673e-06,
      "loss": 0.0393,
      "step": 6779
    },
    {
      "epoch": 1.5579044117647058,
      "grad_norm": 1.1170649528503418,
      "learning_rate": 7.650633169934641e-06,
      "loss": 0.0603,
      "step": 6780
    },
    {
      "epoch": 1.5581341911764706,
      "grad_norm": 0.946576714515686,
      "learning_rate": 7.650122549019609e-06,
      "loss": 0.036,
      "step": 6781
    },
    {
      "epoch": 1.5583639705882353,
      "grad_norm": 0.8716623783111572,
      "learning_rate": 7.649611928104575e-06,
      "loss": 0.0426,
      "step": 6782
    },
    {
      "epoch": 1.55859375,
      "grad_norm": 1.2315101623535156,
      "learning_rate": 7.649101307189543e-06,
      "loss": 0.0648,
      "step": 6783
    },
    {
      "epoch": 1.5588235294117647,
      "grad_norm": 1.1032286882400513,
      "learning_rate": 7.648590686274511e-06,
      "loss": 0.0462,
      "step": 6784
    },
    {
      "epoch": 1.5590533088235294,
      "grad_norm": 0.8370468020439148,
      "learning_rate": 7.648080065359477e-06,
      "loss": 0.0437,
      "step": 6785
    },
    {
      "epoch": 1.5592830882352942,
      "grad_norm": 1.2639511823654175,
      "learning_rate": 7.647569444444445e-06,
      "loss": 0.0555,
      "step": 6786
    },
    {
      "epoch": 1.5595128676470589,
      "grad_norm": 0.945314884185791,
      "learning_rate": 7.647058823529411e-06,
      "loss": 0.056,
      "step": 6787
    },
    {
      "epoch": 1.5597426470588234,
      "grad_norm": 1.167769193649292,
      "learning_rate": 7.64654820261438e-06,
      "loss": 0.0837,
      "step": 6788
    },
    {
      "epoch": 1.5599724264705883,
      "grad_norm": 1.103988528251648,
      "learning_rate": 7.646037581699347e-06,
      "loss": 0.0756,
      "step": 6789
    },
    {
      "epoch": 1.5602022058823528,
      "grad_norm": 1.139095425605774,
      "learning_rate": 7.645526960784315e-06,
      "loss": 0.058,
      "step": 6790
    },
    {
      "epoch": 1.5604319852941178,
      "grad_norm": 1.1221400499343872,
      "learning_rate": 7.64501633986928e-06,
      "loss": 0.0635,
      "step": 6791
    },
    {
      "epoch": 1.5606617647058822,
      "grad_norm": 0.9952465891838074,
      "learning_rate": 7.644505718954249e-06,
      "loss": 0.0558,
      "step": 6792
    },
    {
      "epoch": 1.5608915441176472,
      "grad_norm": 1.1397743225097656,
      "learning_rate": 7.643995098039217e-06,
      "loss": 0.0559,
      "step": 6793
    },
    {
      "epoch": 1.5611213235294117,
      "grad_norm": 0.9886330366134644,
      "learning_rate": 7.643484477124183e-06,
      "loss": 0.0638,
      "step": 6794
    },
    {
      "epoch": 1.5613511029411766,
      "grad_norm": 1.0046348571777344,
      "learning_rate": 7.64297385620915e-06,
      "loss": 0.0519,
      "step": 6795
    },
    {
      "epoch": 1.5615808823529411,
      "grad_norm": 1.192435383796692,
      "learning_rate": 7.642463235294118e-06,
      "loss": 0.0867,
      "step": 6796
    },
    {
      "epoch": 1.5618106617647058,
      "grad_norm": 0.7215957045555115,
      "learning_rate": 7.641952614379086e-06,
      "loss": 0.0445,
      "step": 6797
    },
    {
      "epoch": 1.5620404411764706,
      "grad_norm": 0.7911680936813354,
      "learning_rate": 7.641441993464052e-06,
      "loss": 0.037,
      "step": 6798
    },
    {
      "epoch": 1.5622702205882353,
      "grad_norm": 0.8732672929763794,
      "learning_rate": 7.64093137254902e-06,
      "loss": 0.0377,
      "step": 6799
    },
    {
      "epoch": 1.5625,
      "grad_norm": 0.9954968094825745,
      "learning_rate": 7.640420751633988e-06,
      "loss": 0.0801,
      "step": 6800
    },
    {
      "epoch": 1.5627297794117647,
      "grad_norm": 0.8255581855773926,
      "learning_rate": 7.639910130718954e-06,
      "loss": 0.0484,
      "step": 6801
    },
    {
      "epoch": 1.5629595588235294,
      "grad_norm": 0.8320571780204773,
      "learning_rate": 7.639399509803922e-06,
      "loss": 0.0451,
      "step": 6802
    },
    {
      "epoch": 1.5631893382352942,
      "grad_norm": 0.852640688419342,
      "learning_rate": 7.638888888888888e-06,
      "loss": 0.0577,
      "step": 6803
    },
    {
      "epoch": 1.5634191176470589,
      "grad_norm": 0.6594849228858948,
      "learning_rate": 7.638378267973858e-06,
      "loss": 0.044,
      "step": 6804
    },
    {
      "epoch": 1.5636488970588234,
      "grad_norm": 1.183972954750061,
      "learning_rate": 7.637867647058824e-06,
      "loss": 0.0702,
      "step": 6805
    },
    {
      "epoch": 1.5638786764705883,
      "grad_norm": 0.742970883846283,
      "learning_rate": 7.637357026143792e-06,
      "loss": 0.0415,
      "step": 6806
    },
    {
      "epoch": 1.5641084558823528,
      "grad_norm": 1.1302998065948486,
      "learning_rate": 7.636846405228758e-06,
      "loss": 0.0522,
      "step": 6807
    },
    {
      "epoch": 1.5643382352941178,
      "grad_norm": 2.3618738651275635,
      "learning_rate": 7.636335784313726e-06,
      "loss": 0.0775,
      "step": 6808
    },
    {
      "epoch": 1.5645680147058822,
      "grad_norm": 1.1447855234146118,
      "learning_rate": 7.635825163398694e-06,
      "loss": 0.062,
      "step": 6809
    },
    {
      "epoch": 1.5647977941176472,
      "grad_norm": 1.258117437362671,
      "learning_rate": 7.63531454248366e-06,
      "loss": 0.083,
      "step": 6810
    },
    {
      "epoch": 1.5650275735294117,
      "grad_norm": 0.906810462474823,
      "learning_rate": 7.634803921568628e-06,
      "loss": 0.0498,
      "step": 6811
    },
    {
      "epoch": 1.5652573529411766,
      "grad_norm": 0.790740966796875,
      "learning_rate": 7.634293300653596e-06,
      "loss": 0.0335,
      "step": 6812
    },
    {
      "epoch": 1.5654871323529411,
      "grad_norm": 1.006916880607605,
      "learning_rate": 7.633782679738564e-06,
      "loss": 0.05,
      "step": 6813
    },
    {
      "epoch": 1.5657169117647058,
      "grad_norm": 0.982570469379425,
      "learning_rate": 7.63327205882353e-06,
      "loss": 0.0446,
      "step": 6814
    },
    {
      "epoch": 1.5659466911764706,
      "grad_norm": 1.1928222179412842,
      "learning_rate": 7.632761437908498e-06,
      "loss": 0.0729,
      "step": 6815
    },
    {
      "epoch": 1.5661764705882353,
      "grad_norm": 1.0552875995635986,
      "learning_rate": 7.632250816993466e-06,
      "loss": 0.048,
      "step": 6816
    },
    {
      "epoch": 1.56640625,
      "grad_norm": 1.2872837781906128,
      "learning_rate": 7.631740196078432e-06,
      "loss": 0.0639,
      "step": 6817
    },
    {
      "epoch": 1.5666360294117647,
      "grad_norm": 1.1798416376113892,
      "learning_rate": 7.6312295751634e-06,
      "loss": 0.0683,
      "step": 6818
    },
    {
      "epoch": 1.5668658088235294,
      "grad_norm": 0.9073562026023865,
      "learning_rate": 7.630718954248366e-06,
      "loss": 0.0504,
      "step": 6819
    },
    {
      "epoch": 1.5670955882352942,
      "grad_norm": Infinity,
      "learning_rate": 7.630208333333334e-06,
      "loss": 0.0515,
      "step": 6820
    },
    {
      "epoch": 1.5673253676470589,
      "grad_norm": 1.0351476669311523,
      "learning_rate": 7.630208333333334e-06,
      "loss": 0.0552,
      "step": 6821
    },
    {
      "epoch": 1.5675551470588234,
      "grad_norm": 0.9978584051132202,
      "learning_rate": 7.629697712418301e-06,
      "loss": 0.049,
      "step": 6822
    },
    {
      "epoch": 1.5677849264705883,
      "grad_norm": 1.409554123878479,
      "learning_rate": 7.6291870915032685e-06,
      "loss": 0.0549,
      "step": 6823
    },
    {
      "epoch": 1.5680147058823528,
      "grad_norm": 0.9142181873321533,
      "learning_rate": 7.6286764705882355e-06,
      "loss": 0.0349,
      "step": 6824
    },
    {
      "epoch": 1.5682444852941178,
      "grad_norm": 0.979442298412323,
      "learning_rate": 7.628165849673203e-06,
      "loss": 0.0713,
      "step": 6825
    },
    {
      "epoch": 1.5684742647058822,
      "grad_norm": 0.8094565272331238,
      "learning_rate": 7.62765522875817e-06,
      "loss": 0.0399,
      "step": 6826
    },
    {
      "epoch": 1.5687040441176472,
      "grad_norm": 1.0570340156555176,
      "learning_rate": 7.627144607843137e-06,
      "loss": 0.061,
      "step": 6827
    },
    {
      "epoch": 1.5689338235294117,
      "grad_norm": 1.0148812532424927,
      "learning_rate": 7.626633986928104e-06,
      "loss": 0.0483,
      "step": 6828
    },
    {
      "epoch": 1.5691636029411766,
      "grad_norm": 1.1237903833389282,
      "learning_rate": 7.626123366013073e-06,
      "loss": 0.0589,
      "step": 6829
    },
    {
      "epoch": 1.5693933823529411,
      "grad_norm": 1.2160991430282593,
      "learning_rate": 7.62561274509804e-06,
      "loss": 0.0689,
      "step": 6830
    },
    {
      "epoch": 1.5696231617647058,
      "grad_norm": 0.8068747520446777,
      "learning_rate": 7.625102124183007e-06,
      "loss": 0.0503,
      "step": 6831
    },
    {
      "epoch": 1.5698529411764706,
      "grad_norm": 1.0179725885391235,
      "learning_rate": 7.624591503267974e-06,
      "loss": 0.0557,
      "step": 6832
    },
    {
      "epoch": 1.5700827205882353,
      "grad_norm": 1.3854900598526,
      "learning_rate": 7.624080882352942e-06,
      "loss": 0.064,
      "step": 6833
    },
    {
      "epoch": 1.5703125,
      "grad_norm": 1.0374442338943481,
      "learning_rate": 7.623570261437909e-06,
      "loss": 0.0436,
      "step": 6834
    },
    {
      "epoch": 1.5705422794117647,
      "grad_norm": 0.8090835213661194,
      "learning_rate": 7.623059640522876e-06,
      "loss": 0.0459,
      "step": 6835
    },
    {
      "epoch": 1.5707720588235294,
      "grad_norm": 1.4675993919372559,
      "learning_rate": 7.622549019607843e-06,
      "loss": 0.071,
      "step": 6836
    },
    {
      "epoch": 1.5710018382352942,
      "grad_norm": 1.0737459659576416,
      "learning_rate": 7.622038398692812e-06,
      "loss": 0.0474,
      "step": 6837
    },
    {
      "epoch": 1.5712316176470589,
      "grad_norm": 1.4662681818008423,
      "learning_rate": 7.621527777777779e-06,
      "loss": 0.0733,
      "step": 6838
    },
    {
      "epoch": 1.5714613970588234,
      "grad_norm": 1.1100990772247314,
      "learning_rate": 7.621017156862746e-06,
      "loss": 0.0533,
      "step": 6839
    },
    {
      "epoch": 1.5716911764705883,
      "grad_norm": 1.0339165925979614,
      "learning_rate": 7.620506535947713e-06,
      "loss": 0.0642,
      "step": 6840
    },
    {
      "epoch": 1.5719209558823528,
      "grad_norm": 1.3123772144317627,
      "learning_rate": 7.619995915032681e-06,
      "loss": 0.0567,
      "step": 6841
    },
    {
      "epoch": 1.5721507352941178,
      "grad_norm": 1.5527966022491455,
      "learning_rate": 7.619485294117648e-06,
      "loss": 0.0534,
      "step": 6842
    },
    {
      "epoch": 1.5723805147058822,
      "grad_norm": 0.9089232087135315,
      "learning_rate": 7.618974673202615e-06,
      "loss": 0.0515,
      "step": 6843
    },
    {
      "epoch": 1.5726102941176472,
      "grad_norm": 1.1662760972976685,
      "learning_rate": 7.618464052287582e-06,
      "loss": 0.0648,
      "step": 6844
    },
    {
      "epoch": 1.5728400735294117,
      "grad_norm": 1.53403902053833,
      "learning_rate": 7.61795343137255e-06,
      "loss": 0.0313,
      "step": 6845
    },
    {
      "epoch": 1.5730698529411766,
      "grad_norm": 0.9187486171722412,
      "learning_rate": 7.617442810457517e-06,
      "loss": 0.0417,
      "step": 6846
    },
    {
      "epoch": 1.5732996323529411,
      "grad_norm": 0.7360102534294128,
      "learning_rate": 7.6169321895424844e-06,
      "loss": 0.0343,
      "step": 6847
    },
    {
      "epoch": 1.5735294117647058,
      "grad_norm": 1.1874027252197266,
      "learning_rate": 7.6164215686274514e-06,
      "loss": 0.076,
      "step": 6848
    },
    {
      "epoch": 1.5737591911764706,
      "grad_norm": 0.9690613150596619,
      "learning_rate": 7.615910947712419e-06,
      "loss": 0.0737,
      "step": 6849
    },
    {
      "epoch": 1.5739889705882353,
      "grad_norm": 1.02813720703125,
      "learning_rate": 7.615400326797386e-06,
      "loss": 0.0559,
      "step": 6850
    },
    {
      "epoch": 1.57421875,
      "grad_norm": 0.986400842666626,
      "learning_rate": 7.614889705882353e-06,
      "loss": 0.0688,
      "step": 6851
    },
    {
      "epoch": 1.5744485294117647,
      "grad_norm": 0.9892082810401917,
      "learning_rate": 7.61437908496732e-06,
      "loss": 0.044,
      "step": 6852
    },
    {
      "epoch": 1.5746783088235294,
      "grad_norm": 1.2443161010742188,
      "learning_rate": 7.613868464052289e-06,
      "loss": 0.0601,
      "step": 6853
    },
    {
      "epoch": 1.5749080882352942,
      "grad_norm": 0.9983398914337158,
      "learning_rate": 7.613357843137256e-06,
      "loss": 0.0541,
      "step": 6854
    },
    {
      "epoch": 1.5751378676470589,
      "grad_norm": 0.8092626929283142,
      "learning_rate": 7.612847222222223e-06,
      "loss": 0.0505,
      "step": 6855
    },
    {
      "epoch": 1.5753676470588234,
      "grad_norm": 0.8674086332321167,
      "learning_rate": 7.61233660130719e-06,
      "loss": 0.039,
      "step": 6856
    },
    {
      "epoch": 1.5755974264705883,
      "grad_norm": 0.8756463527679443,
      "learning_rate": 7.611825980392158e-06,
      "loss": 0.0375,
      "step": 6857
    },
    {
      "epoch": 1.5758272058823528,
      "grad_norm": 1.044585943222046,
      "learning_rate": 7.611315359477125e-06,
      "loss": 0.0486,
      "step": 6858
    },
    {
      "epoch": 1.5760569852941178,
      "grad_norm": 0.7565881013870239,
      "learning_rate": 7.610804738562092e-06,
      "loss": 0.0333,
      "step": 6859
    },
    {
      "epoch": 1.5762867647058822,
      "grad_norm": 0.7905341386795044,
      "learning_rate": 7.610294117647059e-06,
      "loss": 0.0515,
      "step": 6860
    },
    {
      "epoch": 1.5765165441176472,
      "grad_norm": 1.0095603466033936,
      "learning_rate": 7.609783496732027e-06,
      "loss": 0.0701,
      "step": 6861
    },
    {
      "epoch": 1.5767463235294117,
      "grad_norm": 0.9537962675094604,
      "learning_rate": 7.609272875816994e-06,
      "loss": 0.0516,
      "step": 6862
    },
    {
      "epoch": 1.5769761029411766,
      "grad_norm": 0.8552049398422241,
      "learning_rate": 7.608762254901961e-06,
      "loss": 0.0386,
      "step": 6863
    },
    {
      "epoch": 1.5772058823529411,
      "grad_norm": 1.354781150817871,
      "learning_rate": 7.608251633986929e-06,
      "loss": 0.0523,
      "step": 6864
    },
    {
      "epoch": 1.5774356617647058,
      "grad_norm": 1.145981788635254,
      "learning_rate": 7.607741013071897e-06,
      "loss": 0.0679,
      "step": 6865
    },
    {
      "epoch": 1.5776654411764706,
      "grad_norm": 0.8634904026985168,
      "learning_rate": 7.607230392156864e-06,
      "loss": 0.0437,
      "step": 6866
    },
    {
      "epoch": 1.5778952205882353,
      "grad_norm": 0.8215947151184082,
      "learning_rate": 7.606719771241831e-06,
      "loss": 0.0469,
      "step": 6867
    },
    {
      "epoch": 1.578125,
      "grad_norm": 0.7317178249359131,
      "learning_rate": 7.606209150326798e-06,
      "loss": 0.0517,
      "step": 6868
    },
    {
      "epoch": 1.5783547794117647,
      "grad_norm": 0.7368294596672058,
      "learning_rate": 7.6056985294117655e-06,
      "loss": 0.0266,
      "step": 6869
    },
    {
      "epoch": 1.5785845588235294,
      "grad_norm": 1.1638559103012085,
      "learning_rate": 7.6051879084967325e-06,
      "loss": 0.067,
      "step": 6870
    },
    {
      "epoch": 1.5788143382352942,
      "grad_norm": 1.3490939140319824,
      "learning_rate": 7.6046772875816996e-06,
      "loss": 0.071,
      "step": 6871
    },
    {
      "epoch": 1.5790441176470589,
      "grad_norm": 0.9636398553848267,
      "learning_rate": 7.6041666666666666e-06,
      "loss": 0.0434,
      "step": 6872
    },
    {
      "epoch": 1.5792738970588234,
      "grad_norm": 0.6154902577400208,
      "learning_rate": 7.603656045751635e-06,
      "loss": 0.0269,
      "step": 6873
    },
    {
      "epoch": 1.5795036764705883,
      "grad_norm": 1.0841866731643677,
      "learning_rate": 7.603145424836602e-06,
      "loss": 0.0605,
      "step": 6874
    },
    {
      "epoch": 1.5797334558823528,
      "grad_norm": 0.7917435169219971,
      "learning_rate": 7.602634803921569e-06,
      "loss": 0.0333,
      "step": 6875
    },
    {
      "epoch": 1.5799632352941178,
      "grad_norm": 0.9641841650009155,
      "learning_rate": 7.602124183006536e-06,
      "loss": 0.0387,
      "step": 6876
    },
    {
      "epoch": 1.5801930147058822,
      "grad_norm": 0.8563966155052185,
      "learning_rate": 7.601613562091504e-06,
      "loss": 0.0461,
      "step": 6877
    },
    {
      "epoch": 1.5804227941176472,
      "grad_norm": 1.3020657300949097,
      "learning_rate": 7.601102941176471e-06,
      "loss": 0.0831,
      "step": 6878
    },
    {
      "epoch": 1.5806525735294117,
      "grad_norm": 0.905938982963562,
      "learning_rate": 7.600592320261438e-06,
      "loss": 0.0427,
      "step": 6879
    },
    {
      "epoch": 1.5808823529411766,
      "grad_norm": 1.154538631439209,
      "learning_rate": 7.600081699346405e-06,
      "loss": 0.0634,
      "step": 6880
    },
    {
      "epoch": 1.5811121323529411,
      "grad_norm": 1.0874053239822388,
      "learning_rate": 7.599571078431374e-06,
      "loss": 0.044,
      "step": 6881
    },
    {
      "epoch": 1.5813419117647058,
      "grad_norm": 1.016608476638794,
      "learning_rate": 7.599060457516341e-06,
      "loss": 0.0674,
      "step": 6882
    },
    {
      "epoch": 1.5815716911764706,
      "grad_norm": 1.021172285079956,
      "learning_rate": 7.598549836601308e-06,
      "loss": 0.0516,
      "step": 6883
    },
    {
      "epoch": 1.5818014705882353,
      "grad_norm": 0.9656842350959778,
      "learning_rate": 7.598039215686275e-06,
      "loss": 0.0536,
      "step": 6884
    },
    {
      "epoch": 1.58203125,
      "grad_norm": 0.8822866678237915,
      "learning_rate": 7.597528594771243e-06,
      "loss": 0.0427,
      "step": 6885
    },
    {
      "epoch": 1.5822610294117647,
      "grad_norm": 0.6205453276634216,
      "learning_rate": 7.59701797385621e-06,
      "loss": 0.0292,
      "step": 6886
    },
    {
      "epoch": 1.5824908088235294,
      "grad_norm": 0.807144045829773,
      "learning_rate": 7.596507352941177e-06,
      "loss": 0.0486,
      "step": 6887
    },
    {
      "epoch": 1.5827205882352942,
      "grad_norm": 1.12942373752594,
      "learning_rate": 7.595996732026144e-06,
      "loss": 0.0504,
      "step": 6888
    },
    {
      "epoch": 1.5829503676470589,
      "grad_norm": 0.9915522933006287,
      "learning_rate": 7.595486111111113e-06,
      "loss": 0.0611,
      "step": 6889
    },
    {
      "epoch": 1.5831801470588234,
      "grad_norm": 0.8379088640213013,
      "learning_rate": 7.59497549019608e-06,
      "loss": 0.0455,
      "step": 6890
    },
    {
      "epoch": 1.5834099264705883,
      "grad_norm": 0.7042135000228882,
      "learning_rate": 7.594464869281047e-06,
      "loss": 0.0609,
      "step": 6891
    },
    {
      "epoch": 1.5836397058823528,
      "grad_norm": 0.8966536521911621,
      "learning_rate": 7.593954248366014e-06,
      "loss": 0.0447,
      "step": 6892
    },
    {
      "epoch": 1.5838694852941178,
      "grad_norm": 0.9626122117042542,
      "learning_rate": 7.5934436274509815e-06,
      "loss": 0.0456,
      "step": 6893
    },
    {
      "epoch": 1.5840992647058822,
      "grad_norm": 0.8850401043891907,
      "learning_rate": 7.5929330065359485e-06,
      "loss": 0.0469,
      "step": 6894
    },
    {
      "epoch": 1.5843290441176472,
      "grad_norm": 1.059617519378662,
      "learning_rate": 7.5924223856209155e-06,
      "loss": 0.0479,
      "step": 6895
    },
    {
      "epoch": 1.5845588235294117,
      "grad_norm": 0.6056736707687378,
      "learning_rate": 7.5919117647058825e-06,
      "loss": 0.0294,
      "step": 6896
    },
    {
      "epoch": 1.5847886029411766,
      "grad_norm": 1.270546317100525,
      "learning_rate": 7.59140114379085e-06,
      "loss": 0.0715,
      "step": 6897
    },
    {
      "epoch": 1.5850183823529411,
      "grad_norm": 1.102594017982483,
      "learning_rate": 7.590890522875818e-06,
      "loss": 0.0503,
      "step": 6898
    },
    {
      "epoch": 1.5852481617647058,
      "grad_norm": 1.1464476585388184,
      "learning_rate": 7.590379901960785e-06,
      "loss": 0.0622,
      "step": 6899
    },
    {
      "epoch": 1.5854779411764706,
      "grad_norm": 1.0547795295715332,
      "learning_rate": 7.589869281045752e-06,
      "loss": 0.0663,
      "step": 6900
    },
    {
      "epoch": 1.5857077205882353,
      "grad_norm": 0.8112781047821045,
      "learning_rate": 7.58935866013072e-06,
      "loss": 0.0339,
      "step": 6901
    },
    {
      "epoch": 1.5859375,
      "grad_norm": 0.879004955291748,
      "learning_rate": 7.588848039215687e-06,
      "loss": 0.0506,
      "step": 6902
    },
    {
      "epoch": 1.5861672794117647,
      "grad_norm": 1.0057289600372314,
      "learning_rate": 7.588337418300654e-06,
      "loss": 0.052,
      "step": 6903
    },
    {
      "epoch": 1.5863970588235294,
      "grad_norm": 0.8557227253913879,
      "learning_rate": 7.587826797385621e-06,
      "loss": 0.0398,
      "step": 6904
    },
    {
      "epoch": 1.5866268382352942,
      "grad_norm": 1.004601001739502,
      "learning_rate": 7.587316176470589e-06,
      "loss": 0.056,
      "step": 6905
    },
    {
      "epoch": 1.5868566176470589,
      "grad_norm": 0.9396798610687256,
      "learning_rate": 7.586805555555556e-06,
      "loss": 0.0495,
      "step": 6906
    },
    {
      "epoch": 1.5870863970588234,
      "grad_norm": 1.1303390264511108,
      "learning_rate": 7.586294934640523e-06,
      "loss": 0.0496,
      "step": 6907
    },
    {
      "epoch": 1.5873161764705883,
      "grad_norm": 1.001176357269287,
      "learning_rate": 7.58578431372549e-06,
      "loss": 0.0407,
      "step": 6908
    },
    {
      "epoch": 1.5875459558823528,
      "grad_norm": 0.8278520107269287,
      "learning_rate": 7.585273692810459e-06,
      "loss": 0.0486,
      "step": 6909
    },
    {
      "epoch": 1.5877757352941178,
      "grad_norm": 1.027696132659912,
      "learning_rate": 7.584763071895426e-06,
      "loss": 0.0613,
      "step": 6910
    },
    {
      "epoch": 1.5880055147058822,
      "grad_norm": 1.4252405166625977,
      "learning_rate": 7.584252450980393e-06,
      "loss": 0.0912,
      "step": 6911
    },
    {
      "epoch": 1.5882352941176472,
      "grad_norm": 1.2163017988204956,
      "learning_rate": 7.58374183006536e-06,
      "loss": 0.0776,
      "step": 6912
    },
    {
      "epoch": 1.5884650735294117,
      "grad_norm": 1.1924946308135986,
      "learning_rate": 7.583231209150328e-06,
      "loss": 0.0401,
      "step": 6913
    },
    {
      "epoch": 1.5886948529411766,
      "grad_norm": 0.9793579578399658,
      "learning_rate": 7.582720588235295e-06,
      "loss": 0.0371,
      "step": 6914
    },
    {
      "epoch": 1.5889246323529411,
      "grad_norm": 1.145342469215393,
      "learning_rate": 7.582209967320262e-06,
      "loss": 0.1,
      "step": 6915
    },
    {
      "epoch": 1.5891544117647058,
      "grad_norm": 1.0748395919799805,
      "learning_rate": 7.581699346405229e-06,
      "loss": 0.069,
      "step": 6916
    },
    {
      "epoch": 1.5893841911764706,
      "grad_norm": 0.9705548286437988,
      "learning_rate": 7.5811887254901975e-06,
      "loss": 0.043,
      "step": 6917
    },
    {
      "epoch": 1.5896139705882353,
      "grad_norm": 0.8050817847251892,
      "learning_rate": 7.5806781045751645e-06,
      "loss": 0.0346,
      "step": 6918
    },
    {
      "epoch": 1.58984375,
      "grad_norm": 0.98273766040802,
      "learning_rate": 7.5801674836601315e-06,
      "loss": 0.0507,
      "step": 6919
    },
    {
      "epoch": 1.5900735294117647,
      "grad_norm": 1.116592288017273,
      "learning_rate": 7.5796568627450985e-06,
      "loss": 0.0612,
      "step": 6920
    },
    {
      "epoch": 1.5903033088235294,
      "grad_norm": 0.8641849160194397,
      "learning_rate": 7.579146241830066e-06,
      "loss": 0.0461,
      "step": 6921
    },
    {
      "epoch": 1.5905330882352942,
      "grad_norm": 0.7198327779769897,
      "learning_rate": 7.578635620915033e-06,
      "loss": 0.0285,
      "step": 6922
    },
    {
      "epoch": 1.5907628676470589,
      "grad_norm": 0.915193498134613,
      "learning_rate": 7.578125e-06,
      "loss": 0.0406,
      "step": 6923
    },
    {
      "epoch": 1.5909926470588234,
      "grad_norm": 1.2298555374145508,
      "learning_rate": 7.577614379084967e-06,
      "loss": 0.0487,
      "step": 6924
    },
    {
      "epoch": 1.5912224264705883,
      "grad_norm": 1.017518162727356,
      "learning_rate": 7.5771037581699344e-06,
      "loss": 0.0529,
      "step": 6925
    },
    {
      "epoch": 1.5914522058823528,
      "grad_norm": 0.9545729756355286,
      "learning_rate": 7.576593137254903e-06,
      "loss": 0.0446,
      "step": 6926
    },
    {
      "epoch": 1.5916819852941178,
      "grad_norm": 0.8857683539390564,
      "learning_rate": 7.57608251633987e-06,
      "loss": 0.0369,
      "step": 6927
    },
    {
      "epoch": 1.5919117647058822,
      "grad_norm": 0.9566115140914917,
      "learning_rate": 7.575571895424837e-06,
      "loss": 0.0578,
      "step": 6928
    },
    {
      "epoch": 1.5921415441176472,
      "grad_norm": 1.0996956825256348,
      "learning_rate": 7.575061274509804e-06,
      "loss": 0.0612,
      "step": 6929
    },
    {
      "epoch": 1.5923713235294117,
      "grad_norm": 0.8799504041671753,
      "learning_rate": 7.574550653594772e-06,
      "loss": 0.0366,
      "step": 6930
    },
    {
      "epoch": 1.5926011029411766,
      "grad_norm": 0.8573440909385681,
      "learning_rate": 7.574040032679739e-06,
      "loss": 0.0474,
      "step": 6931
    },
    {
      "epoch": 1.5928308823529411,
      "grad_norm": 0.8782527446746826,
      "learning_rate": 7.573529411764706e-06,
      "loss": 0.0457,
      "step": 6932
    },
    {
      "epoch": 1.5930606617647058,
      "grad_norm": 1.1932579278945923,
      "learning_rate": 7.573018790849673e-06,
      "loss": 0.0541,
      "step": 6933
    },
    {
      "epoch": 1.5932904411764706,
      "grad_norm": 1.0309768915176392,
      "learning_rate": 7.572508169934642e-06,
      "loss": 0.0584,
      "step": 6934
    },
    {
      "epoch": 1.5935202205882353,
      "grad_norm": 0.9937846064567566,
      "learning_rate": 7.571997549019609e-06,
      "loss": 0.0635,
      "step": 6935
    },
    {
      "epoch": 1.59375,
      "grad_norm": 1.4301166534423828,
      "learning_rate": 7.571486928104576e-06,
      "loss": 0.0714,
      "step": 6936
    },
    {
      "epoch": 1.5939797794117647,
      "grad_norm": 1.0030486583709717,
      "learning_rate": 7.570976307189543e-06,
      "loss": 0.0575,
      "step": 6937
    },
    {
      "epoch": 1.5942095588235294,
      "grad_norm": 1.0627574920654297,
      "learning_rate": 7.570465686274511e-06,
      "loss": 0.0529,
      "step": 6938
    },
    {
      "epoch": 1.5944393382352942,
      "grad_norm": 1.0902312994003296,
      "learning_rate": 7.569955065359478e-06,
      "loss": 0.0792,
      "step": 6939
    },
    {
      "epoch": 1.5946691176470589,
      "grad_norm": 0.9323742985725403,
      "learning_rate": 7.569444444444445e-06,
      "loss": 0.058,
      "step": 6940
    },
    {
      "epoch": 1.5948988970588234,
      "grad_norm": 0.7924221754074097,
      "learning_rate": 7.568933823529412e-06,
      "loss": 0.0379,
      "step": 6941
    },
    {
      "epoch": 1.5951286764705883,
      "grad_norm": 0.9965634346008301,
      "learning_rate": 7.56842320261438e-06,
      "loss": 0.062,
      "step": 6942
    },
    {
      "epoch": 1.5953584558823528,
      "grad_norm": 1.2596837282180786,
      "learning_rate": 7.5679125816993475e-06,
      "loss": 0.0855,
      "step": 6943
    },
    {
      "epoch": 1.5955882352941178,
      "grad_norm": 1.139750361442566,
      "learning_rate": 7.5674019607843145e-06,
      "loss": 0.0549,
      "step": 6944
    },
    {
      "epoch": 1.5958180147058822,
      "grad_norm": 1.0371090173721313,
      "learning_rate": 7.5668913398692815e-06,
      "loss": 0.0508,
      "step": 6945
    },
    {
      "epoch": 1.5960477941176472,
      "grad_norm": 0.9436221718788147,
      "learning_rate": 7.566380718954249e-06,
      "loss": 0.053,
      "step": 6946
    },
    {
      "epoch": 1.5962775735294117,
      "grad_norm": 1.3506076335906982,
      "learning_rate": 7.565870098039216e-06,
      "loss": 0.0665,
      "step": 6947
    },
    {
      "epoch": 1.5965073529411766,
      "grad_norm": 0.7320722937583923,
      "learning_rate": 7.565359477124183e-06,
      "loss": 0.0345,
      "step": 6948
    },
    {
      "epoch": 1.5967371323529411,
      "grad_norm": 0.973122239112854,
      "learning_rate": 7.56484885620915e-06,
      "loss": 0.0633,
      "step": 6949
    },
    {
      "epoch": 1.5969669117647058,
      "grad_norm": 1.0715736150741577,
      "learning_rate": 7.564338235294118e-06,
      "loss": 0.0478,
      "step": 6950
    },
    {
      "epoch": 1.5971966911764706,
      "grad_norm": 1.3153645992279053,
      "learning_rate": 7.563827614379085e-06,
      "loss": 0.066,
      "step": 6951
    },
    {
      "epoch": 1.5974264705882353,
      "grad_norm": 0.9612939953804016,
      "learning_rate": 7.563316993464052e-06,
      "loss": 0.0833,
      "step": 6952
    },
    {
      "epoch": 1.59765625,
      "grad_norm": 0.7947341203689575,
      "learning_rate": 7.56280637254902e-06,
      "loss": 0.0394,
      "step": 6953
    },
    {
      "epoch": 1.5978860294117647,
      "grad_norm": 0.9702943563461304,
      "learning_rate": 7.562295751633988e-06,
      "loss": 0.0475,
      "step": 6954
    },
    {
      "epoch": 1.5981158088235294,
      "grad_norm": 0.7965152859687805,
      "learning_rate": 7.561785130718955e-06,
      "loss": 0.0374,
      "step": 6955
    },
    {
      "epoch": 1.5983455882352942,
      "grad_norm": 0.8373791575431824,
      "learning_rate": 7.561274509803922e-06,
      "loss": 0.0445,
      "step": 6956
    },
    {
      "epoch": 1.5985753676470589,
      "grad_norm": 1.1608927249908447,
      "learning_rate": 7.560763888888889e-06,
      "loss": 0.0659,
      "step": 6957
    },
    {
      "epoch": 1.5988051470588234,
      "grad_norm": 0.9816305041313171,
      "learning_rate": 7.560253267973857e-06,
      "loss": 0.0526,
      "step": 6958
    },
    {
      "epoch": 1.5990349264705883,
      "grad_norm": 0.9092716574668884,
      "learning_rate": 7.559742647058824e-06,
      "loss": 0.0662,
      "step": 6959
    },
    {
      "epoch": 1.5992647058823528,
      "grad_norm": 0.9180654883384705,
      "learning_rate": 7.559232026143791e-06,
      "loss": 0.043,
      "step": 6960
    },
    {
      "epoch": 1.5994944852941178,
      "grad_norm": 0.9287266731262207,
      "learning_rate": 7.558721405228758e-06,
      "loss": 0.0427,
      "step": 6961
    },
    {
      "epoch": 1.5997242647058822,
      "grad_norm": 1.0692843198776245,
      "learning_rate": 7.558210784313727e-06,
      "loss": 0.0521,
      "step": 6962
    },
    {
      "epoch": 1.5999540441176472,
      "grad_norm": 1.0117501020431519,
      "learning_rate": 7.557700163398694e-06,
      "loss": 0.0909,
      "step": 6963
    },
    {
      "epoch": 1.6001838235294117,
      "grad_norm": 1.0995713472366333,
      "learning_rate": 7.557189542483661e-06,
      "loss": 0.0669,
      "step": 6964
    },
    {
      "epoch": 1.6004136029411766,
      "grad_norm": 0.8730868697166443,
      "learning_rate": 7.556678921568628e-06,
      "loss": 0.0505,
      "step": 6965
    },
    {
      "epoch": 1.6006433823529411,
      "grad_norm": 0.940613329410553,
      "learning_rate": 7.5561683006535956e-06,
      "loss": 0.0455,
      "step": 6966
    },
    {
      "epoch": 1.6008731617647058,
      "grad_norm": 0.8443150520324707,
      "learning_rate": 7.555657679738563e-06,
      "loss": 0.0556,
      "step": 6967
    },
    {
      "epoch": 1.6011029411764706,
      "grad_norm": 1.1119294166564941,
      "learning_rate": 7.55514705882353e-06,
      "loss": 0.0756,
      "step": 6968
    },
    {
      "epoch": 1.6013327205882353,
      "grad_norm": 0.948977530002594,
      "learning_rate": 7.554636437908497e-06,
      "loss": 0.0514,
      "step": 6969
    },
    {
      "epoch": 1.6015625,
      "grad_norm": 0.7975934743881226,
      "learning_rate": 7.554125816993465e-06,
      "loss": 0.0527,
      "step": 6970
    },
    {
      "epoch": 1.6017922794117647,
      "grad_norm": 0.874339759349823,
      "learning_rate": 7.553615196078432e-06,
      "loss": 0.0529,
      "step": 6971
    },
    {
      "epoch": 1.6020220588235294,
      "grad_norm": 0.907854437828064,
      "learning_rate": 7.553104575163399e-06,
      "loss": 0.0521,
      "step": 6972
    },
    {
      "epoch": 1.6022518382352942,
      "grad_norm": 0.9079843163490295,
      "learning_rate": 7.552593954248366e-06,
      "loss": 0.0355,
      "step": 6973
    },
    {
      "epoch": 1.6024816176470589,
      "grad_norm": 1.1281887292861938,
      "learning_rate": 7.552083333333334e-06,
      "loss": 0.0516,
      "step": 6974
    },
    {
      "epoch": 1.6027113970588234,
      "grad_norm": 0.7156484127044678,
      "learning_rate": 7.551572712418301e-06,
      "loss": 0.0381,
      "step": 6975
    },
    {
      "epoch": 1.6029411764705883,
      "grad_norm": 1.408984899520874,
      "learning_rate": 7.551062091503268e-06,
      "loss": 0.0763,
      "step": 6976
    },
    {
      "epoch": 1.6031709558823528,
      "grad_norm": 1.0925953388214111,
      "learning_rate": 7.550551470588235e-06,
      "loss": 0.052,
      "step": 6977
    },
    {
      "epoch": 1.6034007352941178,
      "grad_norm": 1.3685882091522217,
      "learning_rate": 7.550040849673204e-06,
      "loss": 0.0653,
      "step": 6978
    },
    {
      "epoch": 1.6036305147058822,
      "grad_norm": 0.8148818612098694,
      "learning_rate": 7.549530228758171e-06,
      "loss": 0.0596,
      "step": 6979
    },
    {
      "epoch": 1.6038602941176472,
      "grad_norm": 0.7768646478652954,
      "learning_rate": 7.549019607843138e-06,
      "loss": 0.0398,
      "step": 6980
    },
    {
      "epoch": 1.6040900735294117,
      "grad_norm": 0.7521107196807861,
      "learning_rate": 7.548508986928105e-06,
      "loss": 0.0471,
      "step": 6981
    },
    {
      "epoch": 1.6043198529411766,
      "grad_norm": 1.5478241443634033,
      "learning_rate": 7.547998366013073e-06,
      "loss": 0.0754,
      "step": 6982
    },
    {
      "epoch": 1.6045496323529411,
      "grad_norm": 0.9479008913040161,
      "learning_rate": 7.54748774509804e-06,
      "loss": 0.07,
      "step": 6983
    },
    {
      "epoch": 1.6047794117647058,
      "grad_norm": 0.7852954864501953,
      "learning_rate": 7.546977124183007e-06,
      "loss": 0.0471,
      "step": 6984
    },
    {
      "epoch": 1.6050091911764706,
      "grad_norm": 0.7240858674049377,
      "learning_rate": 7.546466503267974e-06,
      "loss": 0.034,
      "step": 6985
    },
    {
      "epoch": 1.6052389705882353,
      "grad_norm": 1.1317329406738281,
      "learning_rate": 7.545955882352942e-06,
      "loss": 0.0549,
      "step": 6986
    },
    {
      "epoch": 1.60546875,
      "grad_norm": 1.2115726470947266,
      "learning_rate": 7.54544526143791e-06,
      "loss": 0.035,
      "step": 6987
    },
    {
      "epoch": 1.6056985294117647,
      "grad_norm": 1.0342350006103516,
      "learning_rate": 7.544934640522877e-06,
      "loss": 0.0418,
      "step": 6988
    },
    {
      "epoch": 1.6059283088235294,
      "grad_norm": 0.8573274612426758,
      "learning_rate": 7.544424019607844e-06,
      "loss": 0.0461,
      "step": 6989
    },
    {
      "epoch": 1.6061580882352942,
      "grad_norm": 1.119268536567688,
      "learning_rate": 7.5439133986928115e-06,
      "loss": 0.0475,
      "step": 6990
    },
    {
      "epoch": 1.6063878676470589,
      "grad_norm": 0.9262155294418335,
      "learning_rate": 7.5434027777777786e-06,
      "loss": 0.0615,
      "step": 6991
    },
    {
      "epoch": 1.6066176470588234,
      "grad_norm": 1.0567201375961304,
      "learning_rate": 7.5428921568627456e-06,
      "loss": 0.0515,
      "step": 6992
    },
    {
      "epoch": 1.6068474264705883,
      "grad_norm": 0.6794977188110352,
      "learning_rate": 7.542381535947713e-06,
      "loss": 0.0342,
      "step": 6993
    },
    {
      "epoch": 1.6070772058823528,
      "grad_norm": 0.9065657258033752,
      "learning_rate": 7.5418709150326804e-06,
      "loss": 0.0383,
      "step": 6994
    },
    {
      "epoch": 1.6073069852941178,
      "grad_norm": 0.9778034687042236,
      "learning_rate": 7.5413602941176475e-06,
      "loss": 0.0467,
      "step": 6995
    },
    {
      "epoch": 1.6075367647058822,
      "grad_norm": 1.4558907747268677,
      "learning_rate": 7.5408496732026145e-06,
      "loss": 0.0738,
      "step": 6996
    },
    {
      "epoch": 1.6077665441176472,
      "grad_norm": 0.7926267385482788,
      "learning_rate": 7.5403390522875815e-06,
      "loss": 0.0423,
      "step": 6997
    },
    {
      "epoch": 1.6079963235294117,
      "grad_norm": 0.9105469584465027,
      "learning_rate": 7.53982843137255e-06,
      "loss": 0.0662,
      "step": 6998
    },
    {
      "epoch": 1.6082261029411766,
      "grad_norm": 1.1087443828582764,
      "learning_rate": 7.539317810457517e-06,
      "loss": 0.0483,
      "step": 6999
    },
    {
      "epoch": 1.6084558823529411,
      "grad_norm": 1.0003830194473267,
      "learning_rate": 7.538807189542484e-06,
      "loss": 0.0462,
      "step": 7000
    },
    {
      "epoch": 1.6084558823529411,
      "eval_loss": 0.05421709269285202,
      "eval_runtime": 2007.0288,
      "eval_samples_per_second": 4.437,
      "eval_steps_per_second": 2.219,
      "step": 7000
    },
    {
      "epoch": 1.6086856617647058,
      "grad_norm": 0.9837307333946228,
      "learning_rate": 7.538296568627451e-06,
      "loss": 0.044,
      "step": 7001
    },
    {
      "epoch": 1.6089154411764706,
      "grad_norm": 0.9432645440101624,
      "learning_rate": 7.537785947712419e-06,
      "loss": 0.0481,
      "step": 7002
    },
    {
      "epoch": 1.6091452205882353,
      "grad_norm": 0.8109549283981323,
      "learning_rate": 7.537275326797386e-06,
      "loss": 0.0441,
      "step": 7003
    },
    {
      "epoch": 1.609375,
      "grad_norm": 0.872508704662323,
      "learning_rate": 7.536764705882353e-06,
      "loss": 0.0329,
      "step": 7004
    },
    {
      "epoch": 1.6096047794117647,
      "grad_norm": 0.8253514170646667,
      "learning_rate": 7.53625408496732e-06,
      "loss": 0.0392,
      "step": 7005
    },
    {
      "epoch": 1.6098345588235294,
      "grad_norm": 1.2004913091659546,
      "learning_rate": 7.535743464052289e-06,
      "loss": 0.0609,
      "step": 7006
    },
    {
      "epoch": 1.6100643382352942,
      "grad_norm": 0.8118731379508972,
      "learning_rate": 7.535232843137256e-06,
      "loss": 0.0526,
      "step": 7007
    },
    {
      "epoch": 1.6102941176470589,
      "grad_norm": 0.9276928305625916,
      "learning_rate": 7.534722222222223e-06,
      "loss": 0.0549,
      "step": 7008
    },
    {
      "epoch": 1.6105238970588234,
      "grad_norm": 1.1780955791473389,
      "learning_rate": 7.53421160130719e-06,
      "loss": 0.0627,
      "step": 7009
    },
    {
      "epoch": 1.6107536764705883,
      "grad_norm": 1.308785319328308,
      "learning_rate": 7.533700980392158e-06,
      "loss": 0.0725,
      "step": 7010
    },
    {
      "epoch": 1.6109834558823528,
      "grad_norm": 0.9068495631217957,
      "learning_rate": 7.533190359477125e-06,
      "loss": 0.0635,
      "step": 7011
    },
    {
      "epoch": 1.6112132352941178,
      "grad_norm": 1.0988402366638184,
      "learning_rate": 7.532679738562092e-06,
      "loss": 0.0621,
      "step": 7012
    },
    {
      "epoch": 1.6114430147058822,
      "grad_norm": 0.9271923899650574,
      "learning_rate": 7.532169117647059e-06,
      "loss": 0.0484,
      "step": 7013
    },
    {
      "epoch": 1.6116727941176472,
      "grad_norm": 0.8992437124252319,
      "learning_rate": 7.5316584967320275e-06,
      "loss": 0.059,
      "step": 7014
    },
    {
      "epoch": 1.6119025735294117,
      "grad_norm": 1.1757264137268066,
      "learning_rate": 7.5311478758169945e-06,
      "loss": 0.0691,
      "step": 7015
    },
    {
      "epoch": 1.6121323529411766,
      "grad_norm": 1.1746023893356323,
      "learning_rate": 7.5306372549019615e-06,
      "loss": 0.0685,
      "step": 7016
    },
    {
      "epoch": 1.6123621323529411,
      "grad_norm": 1.1269334554672241,
      "learning_rate": 7.5301266339869286e-06,
      "loss": 0.0524,
      "step": 7017
    },
    {
      "epoch": 1.6125919117647058,
      "grad_norm": 1.2019513845443726,
      "learning_rate": 7.529616013071896e-06,
      "loss": 0.0549,
      "step": 7018
    },
    {
      "epoch": 1.6128216911764706,
      "grad_norm": 0.8503869771957397,
      "learning_rate": 7.5291053921568634e-06,
      "loss": 0.0398,
      "step": 7019
    },
    {
      "epoch": 1.6130514705882353,
      "grad_norm": 2.08370041847229,
      "learning_rate": 7.5285947712418304e-06,
      "loss": 0.0559,
      "step": 7020
    },
    {
      "epoch": 1.61328125,
      "grad_norm": 1.109687328338623,
      "learning_rate": 7.5280841503267975e-06,
      "loss": 0.0546,
      "step": 7021
    },
    {
      "epoch": 1.6135110294117647,
      "grad_norm": 1.518298864364624,
      "learning_rate": 7.527573529411766e-06,
      "loss": 0.0642,
      "step": 7022
    },
    {
      "epoch": 1.6137408088235294,
      "grad_norm": 0.9974137544631958,
      "learning_rate": 7.527062908496733e-06,
      "loss": 0.0567,
      "step": 7023
    },
    {
      "epoch": 1.6139705882352942,
      "grad_norm": 0.9007770419120789,
      "learning_rate": 7.5265522875817e-06,
      "loss": 0.0384,
      "step": 7024
    },
    {
      "epoch": 1.6142003676470589,
      "grad_norm": 1.0226545333862305,
      "learning_rate": 7.526041666666667e-06,
      "loss": 0.0558,
      "step": 7025
    },
    {
      "epoch": 1.6144301470588234,
      "grad_norm": 0.9934772253036499,
      "learning_rate": 7.525531045751635e-06,
      "loss": 0.0393,
      "step": 7026
    },
    {
      "epoch": 1.6146599264705883,
      "grad_norm": 0.9507131576538086,
      "learning_rate": 7.525020424836602e-06,
      "loss": 0.0531,
      "step": 7027
    },
    {
      "epoch": 1.6148897058823528,
      "grad_norm": 1.0044759511947632,
      "learning_rate": 7.524509803921569e-06,
      "loss": 0.0507,
      "step": 7028
    },
    {
      "epoch": 1.6151194852941178,
      "grad_norm": 0.7946985363960266,
      "learning_rate": 7.523999183006536e-06,
      "loss": 0.041,
      "step": 7029
    },
    {
      "epoch": 1.6153492647058822,
      "grad_norm": 0.719365656375885,
      "learning_rate": 7.523488562091504e-06,
      "loss": 0.043,
      "step": 7030
    },
    {
      "epoch": 1.6155790441176472,
      "grad_norm": 0.9047904014587402,
      "learning_rate": 7.522977941176471e-06,
      "loss": 0.0511,
      "step": 7031
    },
    {
      "epoch": 1.6158088235294117,
      "grad_norm": 1.1422419548034668,
      "learning_rate": 7.522467320261439e-06,
      "loss": 0.0587,
      "step": 7032
    },
    {
      "epoch": 1.6160386029411766,
      "grad_norm": 0.87293541431427,
      "learning_rate": 7.521956699346406e-06,
      "loss": 0.0632,
      "step": 7033
    },
    {
      "epoch": 1.6162683823529411,
      "grad_norm": 0.8634620308876038,
      "learning_rate": 7.521446078431374e-06,
      "loss": 0.0522,
      "step": 7034
    },
    {
      "epoch": 1.6164981617647058,
      "grad_norm": 1.6158348321914673,
      "learning_rate": 7.520935457516341e-06,
      "loss": 0.0741,
      "step": 7035
    },
    {
      "epoch": 1.6167279411764706,
      "grad_norm": 1.0454005002975464,
      "learning_rate": 7.520424836601308e-06,
      "loss": 0.0638,
      "step": 7036
    },
    {
      "epoch": 1.6169577205882353,
      "grad_norm": 1.242770791053772,
      "learning_rate": 7.519914215686275e-06,
      "loss": 0.0745,
      "step": 7037
    },
    {
      "epoch": 1.6171875,
      "grad_norm": 1.0077999830245972,
      "learning_rate": 7.519403594771243e-06,
      "loss": 0.0453,
      "step": 7038
    },
    {
      "epoch": 1.6174172794117647,
      "grad_norm": 0.86885005235672,
      "learning_rate": 7.51889297385621e-06,
      "loss": 0.0463,
      "step": 7039
    },
    {
      "epoch": 1.6176470588235294,
      "grad_norm": 0.6383349895477295,
      "learning_rate": 7.518382352941177e-06,
      "loss": 0.0349,
      "step": 7040
    },
    {
      "epoch": 1.6178768382352942,
      "grad_norm": 0.7746887803077698,
      "learning_rate": 7.517871732026144e-06,
      "loss": 0.0426,
      "step": 7041
    },
    {
      "epoch": 1.6181066176470589,
      "grad_norm": 1.0903464555740356,
      "learning_rate": 7.517361111111112e-06,
      "loss": 0.0366,
      "step": 7042
    },
    {
      "epoch": 1.6183363970588234,
      "grad_norm": 0.8190584778785706,
      "learning_rate": 7.516850490196079e-06,
      "loss": 0.0394,
      "step": 7043
    },
    {
      "epoch": 1.6185661764705883,
      "grad_norm": 1.3424458503723145,
      "learning_rate": 7.516339869281046e-06,
      "loss": 0.0574,
      "step": 7044
    },
    {
      "epoch": 1.6187959558823528,
      "grad_norm": 1.05008864402771,
      "learning_rate": 7.5158292483660134e-06,
      "loss": 0.0614,
      "step": 7045
    },
    {
      "epoch": 1.6190257352941178,
      "grad_norm": 1.3607805967330933,
      "learning_rate": 7.515318627450981e-06,
      "loss": 0.0563,
      "step": 7046
    },
    {
      "epoch": 1.6192555147058822,
      "grad_norm": 0.7338768243789673,
      "learning_rate": 7.514808006535948e-06,
      "loss": 0.0384,
      "step": 7047
    },
    {
      "epoch": 1.6194852941176472,
      "grad_norm": 0.9151403307914734,
      "learning_rate": 7.514297385620915e-06,
      "loss": 0.0539,
      "step": 7048
    },
    {
      "epoch": 1.6197150735294117,
      "grad_norm": 0.7322831153869629,
      "learning_rate": 7.513786764705882e-06,
      "loss": 0.0432,
      "step": 7049
    },
    {
      "epoch": 1.6199448529411766,
      "grad_norm": 0.7920088768005371,
      "learning_rate": 7.513276143790851e-06,
      "loss": 0.0394,
      "step": 7050
    },
    {
      "epoch": 1.6201746323529411,
      "grad_norm": 1.1296404600143433,
      "learning_rate": 7.512765522875818e-06,
      "loss": 0.0775,
      "step": 7051
    },
    {
      "epoch": 1.6204044117647058,
      "grad_norm": 1.0761785507202148,
      "learning_rate": 7.512254901960785e-06,
      "loss": 0.0662,
      "step": 7052
    },
    {
      "epoch": 1.6206341911764706,
      "grad_norm": 1.0287293195724487,
      "learning_rate": 7.511744281045752e-06,
      "loss": 0.0575,
      "step": 7053
    },
    {
      "epoch": 1.6208639705882353,
      "grad_norm": 1.255523920059204,
      "learning_rate": 7.51123366013072e-06,
      "loss": 0.0674,
      "step": 7054
    },
    {
      "epoch": 1.62109375,
      "grad_norm": 0.7311147451400757,
      "learning_rate": 7.510723039215687e-06,
      "loss": 0.0471,
      "step": 7055
    },
    {
      "epoch": 1.6213235294117647,
      "grad_norm": 0.9018911123275757,
      "learning_rate": 7.510212418300654e-06,
      "loss": 0.0501,
      "step": 7056
    },
    {
      "epoch": 1.6215533088235294,
      "grad_norm": 1.1117252111434937,
      "learning_rate": 7.509701797385621e-06,
      "loss": 0.0598,
      "step": 7057
    },
    {
      "epoch": 1.6217830882352942,
      "grad_norm": 1.2148734331130981,
      "learning_rate": 7.50919117647059e-06,
      "loss": 0.0842,
      "step": 7058
    },
    {
      "epoch": 1.6220128676470589,
      "grad_norm": 1.0187411308288574,
      "learning_rate": 7.508680555555557e-06,
      "loss": 0.0517,
      "step": 7059
    },
    {
      "epoch": 1.6222426470588234,
      "grad_norm": 0.9061815738677979,
      "learning_rate": 7.508169934640524e-06,
      "loss": 0.0232,
      "step": 7060
    },
    {
      "epoch": 1.6224724264705883,
      "grad_norm": 0.8924764394760132,
      "learning_rate": 7.507659313725491e-06,
      "loss": 0.0454,
      "step": 7061
    },
    {
      "epoch": 1.6227022058823528,
      "grad_norm": 0.94504714012146,
      "learning_rate": 7.507148692810459e-06,
      "loss": 0.0664,
      "step": 7062
    },
    {
      "epoch": 1.6229319852941178,
      "grad_norm": 1.280638337135315,
      "learning_rate": 7.506638071895426e-06,
      "loss": 0.0708,
      "step": 7063
    },
    {
      "epoch": 1.6231617647058822,
      "grad_norm": 0.8626599311828613,
      "learning_rate": 7.506127450980393e-06,
      "loss": 0.0491,
      "step": 7064
    },
    {
      "epoch": 1.6233915441176472,
      "grad_norm": 0.8231148719787598,
      "learning_rate": 7.50561683006536e-06,
      "loss": 0.0416,
      "step": 7065
    },
    {
      "epoch": 1.6236213235294117,
      "grad_norm": 0.8719547986984253,
      "learning_rate": 7.505106209150328e-06,
      "loss": 0.0471,
      "step": 7066
    },
    {
      "epoch": 1.6238511029411766,
      "grad_norm": 1.172239065170288,
      "learning_rate": 7.504595588235295e-06,
      "loss": 0.0524,
      "step": 7067
    },
    {
      "epoch": 1.6240808823529411,
      "grad_norm": 0.9049739837646484,
      "learning_rate": 7.504084967320262e-06,
      "loss": 0.0485,
      "step": 7068
    },
    {
      "epoch": 1.6243106617647058,
      "grad_norm": 1.7554683685302734,
      "learning_rate": 7.503574346405229e-06,
      "loss": 0.0516,
      "step": 7069
    },
    {
      "epoch": 1.6245404411764706,
      "grad_norm": 0.8692963123321533,
      "learning_rate": 7.503063725490197e-06,
      "loss": 0.0579,
      "step": 7070
    },
    {
      "epoch": 1.6247702205882353,
      "grad_norm": 0.7472479939460754,
      "learning_rate": 7.502553104575164e-06,
      "loss": 0.035,
      "step": 7071
    },
    {
      "epoch": 1.625,
      "grad_norm": 0.9958519339561462,
      "learning_rate": 7.502042483660131e-06,
      "loss": 0.0503,
      "step": 7072
    },
    {
      "epoch": 1.6252297794117647,
      "grad_norm": 1.076151967048645,
      "learning_rate": 7.501531862745098e-06,
      "loss": 0.0435,
      "step": 7073
    },
    {
      "epoch": 1.6254595588235294,
      "grad_norm": 0.9054632782936096,
      "learning_rate": 7.501021241830066e-06,
      "loss": 0.0409,
      "step": 7074
    },
    {
      "epoch": 1.6256893382352942,
      "grad_norm": 0.9748734831809998,
      "learning_rate": 7.500510620915033e-06,
      "loss": 0.0439,
      "step": 7075
    },
    {
      "epoch": 1.6259191176470589,
      "grad_norm": 1.7029857635498047,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.0767,
      "step": 7076
    },
    {
      "epoch": 1.6261488970588234,
      "grad_norm": 0.8229531645774841,
      "learning_rate": 7.499489379084968e-06,
      "loss": 0.0359,
      "step": 7077
    },
    {
      "epoch": 1.6263786764705883,
      "grad_norm": 1.3591073751449585,
      "learning_rate": 7.498978758169935e-06,
      "loss": 0.0754,
      "step": 7078
    },
    {
      "epoch": 1.6266084558823528,
      "grad_norm": 0.9565660953521729,
      "learning_rate": 7.498468137254903e-06,
      "loss": 0.0598,
      "step": 7079
    },
    {
      "epoch": 1.6268382352941178,
      "grad_norm": 1.0190021991729736,
      "learning_rate": 7.49795751633987e-06,
      "loss": 0.0513,
      "step": 7080
    },
    {
      "epoch": 1.6270680147058822,
      "grad_norm": 0.8963648080825806,
      "learning_rate": 7.497446895424837e-06,
      "loss": 0.0481,
      "step": 7081
    },
    {
      "epoch": 1.6272977941176472,
      "grad_norm": 0.7820241451263428,
      "learning_rate": 7.496936274509804e-06,
      "loss": 0.0569,
      "step": 7082
    },
    {
      "epoch": 1.6275275735294117,
      "grad_norm": 1.0124448537826538,
      "learning_rate": 7.496425653594772e-06,
      "loss": 0.0427,
      "step": 7083
    },
    {
      "epoch": 1.6277573529411766,
      "grad_norm": 0.931753396987915,
      "learning_rate": 7.495915032679739e-06,
      "loss": 0.0487,
      "step": 7084
    },
    {
      "epoch": 1.6279871323529411,
      "grad_norm": 0.9095787405967712,
      "learning_rate": 7.495404411764706e-06,
      "loss": 0.0384,
      "step": 7085
    },
    {
      "epoch": 1.6282169117647058,
      "grad_norm": 0.831349790096283,
      "learning_rate": 7.494893790849673e-06,
      "loss": 0.0501,
      "step": 7086
    },
    {
      "epoch": 1.6284466911764706,
      "grad_norm": 0.7994632124900818,
      "learning_rate": 7.494383169934642e-06,
      "loss": 0.0547,
      "step": 7087
    },
    {
      "epoch": 1.6286764705882353,
      "grad_norm": 1.2048290967941284,
      "learning_rate": 7.493872549019609e-06,
      "loss": 0.0632,
      "step": 7088
    },
    {
      "epoch": 1.62890625,
      "grad_norm": 1.0110305547714233,
      "learning_rate": 7.493361928104576e-06,
      "loss": 0.0552,
      "step": 7089
    },
    {
      "epoch": 1.6291360294117647,
      "grad_norm": 0.9939294457435608,
      "learning_rate": 7.492851307189543e-06,
      "loss": 0.0517,
      "step": 7090
    },
    {
      "epoch": 1.6293658088235294,
      "grad_norm": 0.9849757552146912,
      "learning_rate": 7.4923406862745105e-06,
      "loss": 0.0619,
      "step": 7091
    },
    {
      "epoch": 1.6295955882352942,
      "grad_norm": 0.8507536053657532,
      "learning_rate": 7.4918300653594775e-06,
      "loss": 0.0464,
      "step": 7092
    },
    {
      "epoch": 1.6298253676470589,
      "grad_norm": 1.0148375034332275,
      "learning_rate": 7.4913194444444445e-06,
      "loss": 0.0676,
      "step": 7093
    },
    {
      "epoch": 1.6300551470588234,
      "grad_norm": 0.982515811920166,
      "learning_rate": 7.4908088235294115e-06,
      "loss": 0.0416,
      "step": 7094
    },
    {
      "epoch": 1.6302849264705883,
      "grad_norm": 1.0256606340408325,
      "learning_rate": 7.49029820261438e-06,
      "loss": 0.052,
      "step": 7095
    },
    {
      "epoch": 1.6305147058823528,
      "grad_norm": 1.092763066291809,
      "learning_rate": 7.489787581699347e-06,
      "loss": 0.0731,
      "step": 7096
    },
    {
      "epoch": 1.6307444852941178,
      "grad_norm": 0.7259964942932129,
      "learning_rate": 7.489276960784314e-06,
      "loss": 0.0318,
      "step": 7097
    },
    {
      "epoch": 1.6309742647058822,
      "grad_norm": 0.8281014561653137,
      "learning_rate": 7.488766339869281e-06,
      "loss": 0.0507,
      "step": 7098
    },
    {
      "epoch": 1.6312040441176472,
      "grad_norm": 1.341300129890442,
      "learning_rate": 7.488255718954249e-06,
      "loss": 0.0447,
      "step": 7099
    },
    {
      "epoch": 1.6314338235294117,
      "grad_norm": 1.006483793258667,
      "learning_rate": 7.487745098039216e-06,
      "loss": 0.0687,
      "step": 7100
    },
    {
      "epoch": 1.6316636029411766,
      "grad_norm": 0.9350300431251526,
      "learning_rate": 7.487234477124183e-06,
      "loss": 0.0627,
      "step": 7101
    },
    {
      "epoch": 1.6318933823529411,
      "grad_norm": 0.9647813439369202,
      "learning_rate": 7.48672385620915e-06,
      "loss": 0.0438,
      "step": 7102
    },
    {
      "epoch": 1.6321231617647058,
      "grad_norm": 0.980631411075592,
      "learning_rate": 7.486213235294119e-06,
      "loss": 0.0427,
      "step": 7103
    },
    {
      "epoch": 1.6323529411764706,
      "grad_norm": 1.0189515352249146,
      "learning_rate": 7.485702614379086e-06,
      "loss": 0.038,
      "step": 7104
    },
    {
      "epoch": 1.6325827205882353,
      "grad_norm": 2.097661018371582,
      "learning_rate": 7.485191993464053e-06,
      "loss": 0.058,
      "step": 7105
    },
    {
      "epoch": 1.6328125,
      "grad_norm": 1.2215235233306885,
      "learning_rate": 7.48468137254902e-06,
      "loss": 0.047,
      "step": 7106
    },
    {
      "epoch": 1.6330422794117647,
      "grad_norm": 0.8337616324424744,
      "learning_rate": 7.484170751633988e-06,
      "loss": 0.0408,
      "step": 7107
    },
    {
      "epoch": 1.6332720588235294,
      "grad_norm": 1.0348246097564697,
      "learning_rate": 7.483660130718955e-06,
      "loss": 0.0367,
      "step": 7108
    },
    {
      "epoch": 1.6335018382352942,
      "grad_norm": 0.7395915985107422,
      "learning_rate": 7.483149509803922e-06,
      "loss": 0.047,
      "step": 7109
    },
    {
      "epoch": 1.6337316176470589,
      "grad_norm": 1.0578186511993408,
      "learning_rate": 7.482638888888889e-06,
      "loss": 0.0452,
      "step": 7110
    },
    {
      "epoch": 1.6339613970588234,
      "grad_norm": 1.0861256122589111,
      "learning_rate": 7.4821282679738576e-06,
      "loss": 0.0659,
      "step": 7111
    },
    {
      "epoch": 1.6341911764705883,
      "grad_norm": 0.9301193356513977,
      "learning_rate": 7.4816176470588246e-06,
      "loss": 0.077,
      "step": 7112
    },
    {
      "epoch": 1.6344209558823528,
      "grad_norm": 1.0561330318450928,
      "learning_rate": 7.481107026143792e-06,
      "loss": 0.0625,
      "step": 7113
    },
    {
      "epoch": 1.6346507352941178,
      "grad_norm": 0.820872962474823,
      "learning_rate": 7.480596405228759e-06,
      "loss": 0.0463,
      "step": 7114
    },
    {
      "epoch": 1.6348805147058822,
      "grad_norm": 0.8890419602394104,
      "learning_rate": 7.4800857843137265e-06,
      "loss": 0.0507,
      "step": 7115
    },
    {
      "epoch": 1.6351102941176472,
      "grad_norm": 0.7880190014839172,
      "learning_rate": 7.4795751633986935e-06,
      "loss": 0.0581,
      "step": 7116
    },
    {
      "epoch": 1.6353400735294117,
      "grad_norm": 0.7983672618865967,
      "learning_rate": 7.4790645424836605e-06,
      "loss": 0.0435,
      "step": 7117
    },
    {
      "epoch": 1.6355698529411766,
      "grad_norm": 1.133458137512207,
      "learning_rate": 7.4785539215686275e-06,
      "loss": 0.0745,
      "step": 7118
    },
    {
      "epoch": 1.6357996323529411,
      "grad_norm": 1.2045081853866577,
      "learning_rate": 7.478043300653595e-06,
      "loss": 0.0736,
      "step": 7119
    },
    {
      "epoch": 1.6360294117647058,
      "grad_norm": 0.8945708870887756,
      "learning_rate": 7.477532679738562e-06,
      "loss": 0.042,
      "step": 7120
    },
    {
      "epoch": 1.6362591911764706,
      "grad_norm": 1.1218780279159546,
      "learning_rate": 7.47702205882353e-06,
      "loss": 0.0602,
      "step": 7121
    },
    {
      "epoch": 1.6364889705882353,
      "grad_norm": 1.1050493717193604,
      "learning_rate": 7.476511437908497e-06,
      "loss": 0.0396,
      "step": 7122
    },
    {
      "epoch": 1.63671875,
      "grad_norm": 1.0018019676208496,
      "learning_rate": 7.476000816993465e-06,
      "loss": 0.0545,
      "step": 7123
    },
    {
      "epoch": 1.6369485294117647,
      "grad_norm": 0.8720995783805847,
      "learning_rate": 7.475490196078432e-06,
      "loss": 0.0507,
      "step": 7124
    },
    {
      "epoch": 1.6371783088235294,
      "grad_norm": 1.5487107038497925,
      "learning_rate": 7.474979575163399e-06,
      "loss": 0.0626,
      "step": 7125
    },
    {
      "epoch": 1.6374080882352942,
      "grad_norm": 1.4190245866775513,
      "learning_rate": 7.474468954248366e-06,
      "loss": 0.0574,
      "step": 7126
    },
    {
      "epoch": 1.6376378676470589,
      "grad_norm": 0.9666112661361694,
      "learning_rate": 7.473958333333334e-06,
      "loss": 0.0455,
      "step": 7127
    },
    {
      "epoch": 1.6378676470588234,
      "grad_norm": 1.274001121520996,
      "learning_rate": 7.473447712418301e-06,
      "loss": 0.0791,
      "step": 7128
    },
    {
      "epoch": 1.6380974264705883,
      "grad_norm": 0.8376349210739136,
      "learning_rate": 7.472937091503268e-06,
      "loss": 0.0397,
      "step": 7129
    },
    {
      "epoch": 1.6383272058823528,
      "grad_norm": 1.0632017850875854,
      "learning_rate": 7.472426470588235e-06,
      "loss": 0.0565,
      "step": 7130
    },
    {
      "epoch": 1.6385569852941178,
      "grad_norm": 0.9135625958442688,
      "learning_rate": 7.471915849673204e-06,
      "loss": 0.0396,
      "step": 7131
    },
    {
      "epoch": 1.6387867647058822,
      "grad_norm": 0.8541156649589539,
      "learning_rate": 7.471405228758171e-06,
      "loss": 0.0392,
      "step": 7132
    },
    {
      "epoch": 1.6390165441176472,
      "grad_norm": 0.9846698045730591,
      "learning_rate": 7.470894607843138e-06,
      "loss": 0.0385,
      "step": 7133
    },
    {
      "epoch": 1.6392463235294117,
      "grad_norm": 1.157945990562439,
      "learning_rate": 7.470383986928105e-06,
      "loss": 0.0425,
      "step": 7134
    },
    {
      "epoch": 1.6394761029411766,
      "grad_norm": 0.8714731335639954,
      "learning_rate": 7.469873366013073e-06,
      "loss": 0.0435,
      "step": 7135
    },
    {
      "epoch": 1.6397058823529411,
      "grad_norm": 1.0318862199783325,
      "learning_rate": 7.46936274509804e-06,
      "loss": 0.0623,
      "step": 7136
    },
    {
      "epoch": 1.6399356617647058,
      "grad_norm": 1.1405301094055176,
      "learning_rate": 7.468852124183007e-06,
      "loss": 0.0616,
      "step": 7137
    },
    {
      "epoch": 1.6401654411764706,
      "grad_norm": 0.9693700075149536,
      "learning_rate": 7.468341503267974e-06,
      "loss": 0.0437,
      "step": 7138
    },
    {
      "epoch": 1.6403952205882353,
      "grad_norm": 0.7069770693778992,
      "learning_rate": 7.4678308823529424e-06,
      "loss": 0.0299,
      "step": 7139
    },
    {
      "epoch": 1.640625,
      "grad_norm": 1.0369024276733398,
      "learning_rate": 7.4673202614379094e-06,
      "loss": 0.045,
      "step": 7140
    },
    {
      "epoch": 1.6408547794117647,
      "grad_norm": 0.6972011923789978,
      "learning_rate": 7.4668096405228765e-06,
      "loss": 0.0488,
      "step": 7141
    },
    {
      "epoch": 1.6410845588235294,
      "grad_norm": 1.1520243883132935,
      "learning_rate": 7.4662990196078435e-06,
      "loss": 0.0608,
      "step": 7142
    },
    {
      "epoch": 1.6413143382352942,
      "grad_norm": 0.6569042801856995,
      "learning_rate": 7.465788398692811e-06,
      "loss": 0.0445,
      "step": 7143
    },
    {
      "epoch": 1.6415441176470589,
      "grad_norm": 0.8185638785362244,
      "learning_rate": 7.465277777777778e-06,
      "loss": 0.0363,
      "step": 7144
    },
    {
      "epoch": 1.6417738970588234,
      "grad_norm": 1.0701661109924316,
      "learning_rate": 7.464767156862745e-06,
      "loss": 0.053,
      "step": 7145
    },
    {
      "epoch": 1.6420036764705883,
      "grad_norm": 0.8766448497772217,
      "learning_rate": 7.464256535947712e-06,
      "loss": 0.0474,
      "step": 7146
    },
    {
      "epoch": 1.6422334558823528,
      "grad_norm": 0.9029402136802673,
      "learning_rate": 7.463745915032681e-06,
      "loss": 0.058,
      "step": 7147
    },
    {
      "epoch": 1.6424632352941178,
      "grad_norm": 1.4640620946884155,
      "learning_rate": 7.463235294117648e-06,
      "loss": 0.0731,
      "step": 7148
    },
    {
      "epoch": 1.6426930147058822,
      "grad_norm": 0.9713053107261658,
      "learning_rate": 7.462724673202615e-06,
      "loss": 0.0529,
      "step": 7149
    },
    {
      "epoch": 1.6429227941176472,
      "grad_norm": 0.7364745736122131,
      "learning_rate": 7.462214052287582e-06,
      "loss": 0.0429,
      "step": 7150
    },
    {
      "epoch": 1.6431525735294117,
      "grad_norm": 0.8882071375846863,
      "learning_rate": 7.46170343137255e-06,
      "loss": 0.0555,
      "step": 7151
    },
    {
      "epoch": 1.6433823529411766,
      "grad_norm": 0.9232355952262878,
      "learning_rate": 7.461192810457517e-06,
      "loss": 0.0471,
      "step": 7152
    },
    {
      "epoch": 1.6436121323529411,
      "grad_norm": 1.1239908933639526,
      "learning_rate": 7.460682189542484e-06,
      "loss": 0.062,
      "step": 7153
    },
    {
      "epoch": 1.6438419117647058,
      "grad_norm": 0.848597526550293,
      "learning_rate": 7.460171568627451e-06,
      "loss": 0.0442,
      "step": 7154
    },
    {
      "epoch": 1.6440716911764706,
      "grad_norm": 0.8483386039733887,
      "learning_rate": 7.45966094771242e-06,
      "loss": 0.0422,
      "step": 7155
    },
    {
      "epoch": 1.6443014705882353,
      "grad_norm": 1.163754940032959,
      "learning_rate": 7.459150326797387e-06,
      "loss": 0.075,
      "step": 7156
    },
    {
      "epoch": 1.64453125,
      "grad_norm": 1.063288927078247,
      "learning_rate": 7.458639705882354e-06,
      "loss": 0.0657,
      "step": 7157
    },
    {
      "epoch": 1.6447610294117647,
      "grad_norm": 1.203945517539978,
      "learning_rate": 7.458129084967321e-06,
      "loss": 0.0619,
      "step": 7158
    },
    {
      "epoch": 1.6449908088235294,
      "grad_norm": 1.0161935091018677,
      "learning_rate": 7.457618464052289e-06,
      "loss": 0.0434,
      "step": 7159
    },
    {
      "epoch": 1.6452205882352942,
      "grad_norm": 0.8367565274238586,
      "learning_rate": 7.457107843137256e-06,
      "loss": 0.0474,
      "step": 7160
    },
    {
      "epoch": 1.6454503676470589,
      "grad_norm": 0.9361141324043274,
      "learning_rate": 7.456597222222223e-06,
      "loss": 0.0527,
      "step": 7161
    },
    {
      "epoch": 1.6456801470588234,
      "grad_norm": 1.092543125152588,
      "learning_rate": 7.45608660130719e-06,
      "loss": 0.0541,
      "step": 7162
    },
    {
      "epoch": 1.6459099264705883,
      "grad_norm": 1.0719056129455566,
      "learning_rate": 7.4555759803921576e-06,
      "loss": 0.0662,
      "step": 7163
    },
    {
      "epoch": 1.6461397058823528,
      "grad_norm": 0.7326327562332153,
      "learning_rate": 7.4550653594771246e-06,
      "loss": 0.0445,
      "step": 7164
    },
    {
      "epoch": 1.6463694852941178,
      "grad_norm": 1.0372313261032104,
      "learning_rate": 7.454554738562092e-06,
      "loss": 0.0469,
      "step": 7165
    },
    {
      "epoch": 1.6465992647058822,
      "grad_norm": 1.228910207748413,
      "learning_rate": 7.4540441176470594e-06,
      "loss": 0.0547,
      "step": 7166
    },
    {
      "epoch": 1.6468290441176472,
      "grad_norm": 1.1318962574005127,
      "learning_rate": 7.453533496732027e-06,
      "loss": 0.0478,
      "step": 7167
    },
    {
      "epoch": 1.6470588235294117,
      "grad_norm": 0.8773608803749084,
      "learning_rate": 7.453022875816994e-06,
      "loss": 0.0493,
      "step": 7168
    },
    {
      "epoch": 1.6472886029411766,
      "grad_norm": 1.211228370666504,
      "learning_rate": 7.452512254901961e-06,
      "loss": 0.0664,
      "step": 7169
    },
    {
      "epoch": 1.6475183823529411,
      "grad_norm": 1.1418160200119019,
      "learning_rate": 7.452001633986928e-06,
      "loss": 0.04,
      "step": 7170
    },
    {
      "epoch": 1.6477481617647058,
      "grad_norm": 1.248387098312378,
      "learning_rate": 7.451491013071896e-06,
      "loss": 0.0572,
      "step": 7171
    },
    {
      "epoch": 1.6479779411764706,
      "grad_norm": 0.7012444138526917,
      "learning_rate": 7.450980392156863e-06,
      "loss": 0.0319,
      "step": 7172
    },
    {
      "epoch": 1.6482077205882353,
      "grad_norm": 1.4136855602264404,
      "learning_rate": 7.45046977124183e-06,
      "loss": 0.0568,
      "step": 7173
    },
    {
      "epoch": 1.6484375,
      "grad_norm": 2.3591229915618896,
      "learning_rate": 7.449959150326797e-06,
      "loss": 0.0563,
      "step": 7174
    },
    {
      "epoch": 1.6486672794117647,
      "grad_norm": 1.5511394739151,
      "learning_rate": 7.449448529411766e-06,
      "loss": 0.0352,
      "step": 7175
    },
    {
      "epoch": 1.6488970588235294,
      "grad_norm": 1.3002370595932007,
      "learning_rate": 7.448937908496733e-06,
      "loss": 0.06,
      "step": 7176
    },
    {
      "epoch": 1.6491268382352942,
      "grad_norm": 1.5017775297164917,
      "learning_rate": 7.4484272875817e-06,
      "loss": 0.065,
      "step": 7177
    },
    {
      "epoch": 1.6493566176470589,
      "grad_norm": 1.1903471946716309,
      "learning_rate": 7.447916666666667e-06,
      "loss": 0.0518,
      "step": 7178
    },
    {
      "epoch": 1.6495863970588234,
      "grad_norm": 1.342401146888733,
      "learning_rate": 7.447406045751635e-06,
      "loss": 0.0423,
      "step": 7179
    },
    {
      "epoch": 1.6498161764705883,
      "grad_norm": 0.9740415215492249,
      "learning_rate": 7.446895424836602e-06,
      "loss": 0.0386,
      "step": 7180
    },
    {
      "epoch": 1.6500459558823528,
      "grad_norm": 1.3000134229660034,
      "learning_rate": 7.446384803921569e-06,
      "loss": 0.0676,
      "step": 7181
    },
    {
      "epoch": 1.6502757352941178,
      "grad_norm": 1.155604362487793,
      "learning_rate": 7.445874183006536e-06,
      "loss": 0.0783,
      "step": 7182
    },
    {
      "epoch": 1.6505055147058822,
      "grad_norm": 0.9553642868995667,
      "learning_rate": 7.445363562091505e-06,
      "loss": 0.0366,
      "step": 7183
    },
    {
      "epoch": 1.6507352941176472,
      "grad_norm": 0.9785450100898743,
      "learning_rate": 7.444852941176472e-06,
      "loss": 0.0684,
      "step": 7184
    },
    {
      "epoch": 1.6509650735294117,
      "grad_norm": 0.7574827671051025,
      "learning_rate": 7.444342320261439e-06,
      "loss": 0.0345,
      "step": 7185
    },
    {
      "epoch": 1.6511948529411766,
      "grad_norm": 1.1188251972198486,
      "learning_rate": 7.443831699346406e-06,
      "loss": 0.0618,
      "step": 7186
    },
    {
      "epoch": 1.6514246323529411,
      "grad_norm": 0.8504073619842529,
      "learning_rate": 7.4433210784313735e-06,
      "loss": 0.034,
      "step": 7187
    },
    {
      "epoch": 1.6516544117647058,
      "grad_norm": 0.913442850112915,
      "learning_rate": 7.4428104575163405e-06,
      "loss": 0.0397,
      "step": 7188
    },
    {
      "epoch": 1.6518841911764706,
      "grad_norm": 0.8425947427749634,
      "learning_rate": 7.4422998366013075e-06,
      "loss": 0.0315,
      "step": 7189
    },
    {
      "epoch": 1.6521139705882353,
      "grad_norm": 0.8977214694023132,
      "learning_rate": 7.4417892156862746e-06,
      "loss": 0.0441,
      "step": 7190
    },
    {
      "epoch": 1.65234375,
      "grad_norm": 0.9268311262130737,
      "learning_rate": 7.441278594771243e-06,
      "loss": 0.0483,
      "step": 7191
    },
    {
      "epoch": 1.6525735294117647,
      "grad_norm": 1.3224153518676758,
      "learning_rate": 7.44076797385621e-06,
      "loss": 0.0561,
      "step": 7192
    },
    {
      "epoch": 1.6528033088235294,
      "grad_norm": 0.9191179871559143,
      "learning_rate": 7.440257352941177e-06,
      "loss": 0.0346,
      "step": 7193
    },
    {
      "epoch": 1.6530330882352942,
      "grad_norm": 0.8943940997123718,
      "learning_rate": 7.439746732026144e-06,
      "loss": 0.0436,
      "step": 7194
    },
    {
      "epoch": 1.6532628676470589,
      "grad_norm": 1.042180061340332,
      "learning_rate": 7.439236111111112e-06,
      "loss": 0.0728,
      "step": 7195
    },
    {
      "epoch": 1.6534926470588234,
      "grad_norm": 1.11123788356781,
      "learning_rate": 7.438725490196079e-06,
      "loss": 0.0428,
      "step": 7196
    },
    {
      "epoch": 1.6537224264705883,
      "grad_norm": 1.165970802307129,
      "learning_rate": 7.438214869281046e-06,
      "loss": 0.055,
      "step": 7197
    },
    {
      "epoch": 1.6539522058823528,
      "grad_norm": 0.7818160653114319,
      "learning_rate": 7.437704248366013e-06,
      "loss": 0.0561,
      "step": 7198
    },
    {
      "epoch": 1.6541819852941178,
      "grad_norm": 1.0460976362228394,
      "learning_rate": 7.437193627450981e-06,
      "loss": 0.0386,
      "step": 7199
    },
    {
      "epoch": 1.6544117647058822,
      "grad_norm": 0.9902185797691345,
      "learning_rate": 7.436683006535949e-06,
      "loss": 0.0572,
      "step": 7200
    },
    {
      "epoch": 1.6546415441176472,
      "grad_norm": 0.7296541333198547,
      "learning_rate": 7.436172385620916e-06,
      "loss": 0.0301,
      "step": 7201
    },
    {
      "epoch": 1.6548713235294117,
      "grad_norm": 0.9979668259620667,
      "learning_rate": 7.435661764705883e-06,
      "loss": 0.0488,
      "step": 7202
    },
    {
      "epoch": 1.6551011029411766,
      "grad_norm": 0.9051721096038818,
      "learning_rate": 7.435151143790851e-06,
      "loss": 0.0481,
      "step": 7203
    },
    {
      "epoch": 1.6553308823529411,
      "grad_norm": 1.0254859924316406,
      "learning_rate": 7.434640522875818e-06,
      "loss": 0.0596,
      "step": 7204
    },
    {
      "epoch": 1.6555606617647058,
      "grad_norm": 1.3174346685409546,
      "learning_rate": 7.434129901960785e-06,
      "loss": 0.0434,
      "step": 7205
    },
    {
      "epoch": 1.6557904411764706,
      "grad_norm": 1.1189472675323486,
      "learning_rate": 7.433619281045752e-06,
      "loss": 0.059,
      "step": 7206
    },
    {
      "epoch": 1.6560202205882353,
      "grad_norm": 1.0875365734100342,
      "learning_rate": 7.43310866013072e-06,
      "loss": 0.0593,
      "step": 7207
    },
    {
      "epoch": 1.65625,
      "grad_norm": 0.9435676336288452,
      "learning_rate": 7.432598039215687e-06,
      "loss": 0.0479,
      "step": 7208
    },
    {
      "epoch": 1.6564797794117647,
      "grad_norm": 1.0183937549591064,
      "learning_rate": 7.432087418300654e-06,
      "loss": 0.0609,
      "step": 7209
    },
    {
      "epoch": 1.6567095588235294,
      "grad_norm": 1.3641841411590576,
      "learning_rate": 7.431576797385622e-06,
      "loss": 0.0569,
      "step": 7210
    },
    {
      "epoch": 1.6569393382352942,
      "grad_norm": 0.932165265083313,
      "learning_rate": 7.4310661764705895e-06,
      "loss": 0.0349,
      "step": 7211
    },
    {
      "epoch": 1.6571691176470589,
      "grad_norm": 0.8793110847473145,
      "learning_rate": 7.4305555555555565e-06,
      "loss": 0.0462,
      "step": 7212
    },
    {
      "epoch": 1.6573988970588234,
      "grad_norm": 0.7877129316329956,
      "learning_rate": 7.4300449346405235e-06,
      "loss": 0.0366,
      "step": 7213
    },
    {
      "epoch": 1.6576286764705883,
      "grad_norm": 1.145989179611206,
      "learning_rate": 7.4295343137254905e-06,
      "loss": 0.0539,
      "step": 7214
    },
    {
      "epoch": 1.6578584558823528,
      "grad_norm": 0.6930442452430725,
      "learning_rate": 7.429023692810458e-06,
      "loss": 0.0472,
      "step": 7215
    },
    {
      "epoch": 1.6580882352941178,
      "grad_norm": 0.9504573345184326,
      "learning_rate": 7.428513071895425e-06,
      "loss": 0.0496,
      "step": 7216
    },
    {
      "epoch": 1.6583180147058822,
      "grad_norm": 0.9894861578941345,
      "learning_rate": 7.4280024509803924e-06,
      "loss": 0.0639,
      "step": 7217
    },
    {
      "epoch": 1.6585477941176472,
      "grad_norm": 0.8975134491920471,
      "learning_rate": 7.4274918300653594e-06,
      "loss": 0.0529,
      "step": 7218
    },
    {
      "epoch": 1.6587775735294117,
      "grad_norm": 1.1939083337783813,
      "learning_rate": 7.426981209150328e-06,
      "loss": 0.0544,
      "step": 7219
    },
    {
      "epoch": 1.6590073529411766,
      "grad_norm": 1.0536103248596191,
      "learning_rate": 7.426470588235295e-06,
      "loss": 0.0544,
      "step": 7220
    },
    {
      "epoch": 1.6592371323529411,
      "grad_norm": 0.9693669676780701,
      "learning_rate": 7.425959967320262e-06,
      "loss": 0.0418,
      "step": 7221
    },
    {
      "epoch": 1.6594669117647058,
      "grad_norm": 1.1322766542434692,
      "learning_rate": 7.425449346405229e-06,
      "loss": 0.0771,
      "step": 7222
    },
    {
      "epoch": 1.6596966911764706,
      "grad_norm": 1.2534189224243164,
      "learning_rate": 7.424938725490197e-06,
      "loss": 0.0594,
      "step": 7223
    },
    {
      "epoch": 1.6599264705882353,
      "grad_norm": 0.8196059465408325,
      "learning_rate": 7.424428104575164e-06,
      "loss": 0.0345,
      "step": 7224
    },
    {
      "epoch": 1.66015625,
      "grad_norm": 0.9663465619087219,
      "learning_rate": 7.423917483660131e-06,
      "loss": 0.0651,
      "step": 7225
    },
    {
      "epoch": 1.6603860294117647,
      "grad_norm": 0.8319359421730042,
      "learning_rate": 7.423406862745098e-06,
      "loss": 0.0629,
      "step": 7226
    },
    {
      "epoch": 1.6606158088235294,
      "grad_norm": 0.925728440284729,
      "learning_rate": 7.422896241830067e-06,
      "loss": 0.04,
      "step": 7227
    },
    {
      "epoch": 1.6608455882352942,
      "grad_norm": 0.7678847312927246,
      "learning_rate": 7.422385620915034e-06,
      "loss": 0.0493,
      "step": 7228
    },
    {
      "epoch": 1.6610753676470589,
      "grad_norm": 0.9413117170333862,
      "learning_rate": 7.421875000000001e-06,
      "loss": 0.0497,
      "step": 7229
    },
    {
      "epoch": 1.6613051470588234,
      "grad_norm": 0.8930475115776062,
      "learning_rate": 7.421364379084968e-06,
      "loss": 0.0437,
      "step": 7230
    },
    {
      "epoch": 1.6615349264705883,
      "grad_norm": 1.2567496299743652,
      "learning_rate": 7.420853758169935e-06,
      "loss": 0.0612,
      "step": 7231
    },
    {
      "epoch": 1.6617647058823528,
      "grad_norm": 0.8962423801422119,
      "learning_rate": 7.420343137254903e-06,
      "loss": 0.0433,
      "step": 7232
    },
    {
      "epoch": 1.6619944852941178,
      "grad_norm": 0.7108138203620911,
      "learning_rate": 7.41983251633987e-06,
      "loss": 0.0404,
      "step": 7233
    },
    {
      "epoch": 1.6622242647058822,
      "grad_norm": 1.0995699167251587,
      "learning_rate": 7.419321895424837e-06,
      "loss": 0.0522,
      "step": 7234
    },
    {
      "epoch": 1.6624540441176472,
      "grad_norm": 0.8935214877128601,
      "learning_rate": 7.418811274509804e-06,
      "loss": 0.0498,
      "step": 7235
    },
    {
      "epoch": 1.6626838235294117,
      "grad_norm": 1.5476000308990479,
      "learning_rate": 7.4183006535947725e-06,
      "loss": 0.0845,
      "step": 7236
    },
    {
      "epoch": 1.6629136029411766,
      "grad_norm": 0.7638055682182312,
      "learning_rate": 7.4177900326797395e-06,
      "loss": 0.0394,
      "step": 7237
    },
    {
      "epoch": 1.6631433823529411,
      "grad_norm": 1.03594172000885,
      "learning_rate": 7.4172794117647065e-06,
      "loss": 0.0498,
      "step": 7238
    },
    {
      "epoch": 1.6633731617647058,
      "grad_norm": 0.9416860342025757,
      "learning_rate": 7.4167687908496735e-06,
      "loss": 0.0443,
      "step": 7239
    },
    {
      "epoch": 1.6636029411764706,
      "grad_norm": 1.2916797399520874,
      "learning_rate": 7.416258169934641e-06,
      "loss": 0.0431,
      "step": 7240
    },
    {
      "epoch": 1.6638327205882353,
      "grad_norm": 0.7889881134033203,
      "learning_rate": 7.415747549019608e-06,
      "loss": 0.0447,
      "step": 7241
    },
    {
      "epoch": 1.6640625,
      "grad_norm": 1.0272282361984253,
      "learning_rate": 7.415236928104575e-06,
      "loss": 0.0569,
      "step": 7242
    },
    {
      "epoch": 1.6642922794117647,
      "grad_norm": 1.1426504850387573,
      "learning_rate": 7.414726307189542e-06,
      "loss": 0.049,
      "step": 7243
    },
    {
      "epoch": 1.6645220588235294,
      "grad_norm": 1.0675930976867676,
      "learning_rate": 7.414215686274511e-06,
      "loss": 0.0644,
      "step": 7244
    },
    {
      "epoch": 1.6647518382352942,
      "grad_norm": 0.8362182974815369,
      "learning_rate": 7.413705065359478e-06,
      "loss": 0.036,
      "step": 7245
    },
    {
      "epoch": 1.6649816176470589,
      "grad_norm": 0.7290246486663818,
      "learning_rate": 7.413194444444445e-06,
      "loss": 0.0466,
      "step": 7246
    },
    {
      "epoch": 1.6652113970588234,
      "grad_norm": 0.708821177482605,
      "learning_rate": 7.412683823529412e-06,
      "loss": 0.0368,
      "step": 7247
    },
    {
      "epoch": 1.6654411764705883,
      "grad_norm": 0.7528430223464966,
      "learning_rate": 7.41217320261438e-06,
      "loss": 0.0338,
      "step": 7248
    },
    {
      "epoch": 1.6656709558823528,
      "grad_norm": 0.7232195138931274,
      "learning_rate": 7.411662581699347e-06,
      "loss": 0.0364,
      "step": 7249
    },
    {
      "epoch": 1.6659007352941178,
      "grad_norm": 0.777758777141571,
      "learning_rate": 7.411151960784314e-06,
      "loss": 0.0406,
      "step": 7250
    },
    {
      "epoch": 1.6661305147058822,
      "grad_norm": 1.2300198078155518,
      "learning_rate": 7.410641339869281e-06,
      "loss": 0.0661,
      "step": 7251
    },
    {
      "epoch": 1.6663602941176472,
      "grad_norm": 1.118265151977539,
      "learning_rate": 7.410130718954249e-06,
      "loss": 0.0587,
      "step": 7252
    },
    {
      "epoch": 1.6665900735294117,
      "grad_norm": 1.0815247297286987,
      "learning_rate": 7.409620098039216e-06,
      "loss": 0.0371,
      "step": 7253
    },
    {
      "epoch": 1.6668198529411766,
      "grad_norm": 0.9207535982131958,
      "learning_rate": 7.409109477124183e-06,
      "loss": 0.0293,
      "step": 7254
    },
    {
      "epoch": 1.6670496323529411,
      "grad_norm": 0.9492781162261963,
      "learning_rate": 7.408598856209151e-06,
      "loss": 0.0509,
      "step": 7255
    },
    {
      "epoch": 1.6672794117647058,
      "grad_norm": 0.8277990221977234,
      "learning_rate": 7.408088235294119e-06,
      "loss": 0.0434,
      "step": 7256
    },
    {
      "epoch": 1.6675091911764706,
      "grad_norm": 1.4011150598526,
      "learning_rate": 7.407577614379086e-06,
      "loss": 0.0662,
      "step": 7257
    },
    {
      "epoch": 1.6677389705882353,
      "grad_norm": 0.8757917881011963,
      "learning_rate": 7.407066993464053e-06,
      "loss": 0.0289,
      "step": 7258
    },
    {
      "epoch": 1.66796875,
      "grad_norm": 1.060553789138794,
      "learning_rate": 7.40655637254902e-06,
      "loss": 0.0745,
      "step": 7259
    },
    {
      "epoch": 1.6681985294117647,
      "grad_norm": 0.8691768646240234,
      "learning_rate": 7.406045751633988e-06,
      "loss": 0.0439,
      "step": 7260
    },
    {
      "epoch": 1.6684283088235294,
      "grad_norm": 1.3378937244415283,
      "learning_rate": 7.405535130718955e-06,
      "loss": 0.0722,
      "step": 7261
    },
    {
      "epoch": 1.6686580882352942,
      "grad_norm": 0.6054219603538513,
      "learning_rate": 7.405024509803922e-06,
      "loss": 0.0348,
      "step": 7262
    },
    {
      "epoch": 1.6688878676470589,
      "grad_norm": 1.0173004865646362,
      "learning_rate": 7.404513888888889e-06,
      "loss": 0.0364,
      "step": 7263
    },
    {
      "epoch": 1.6691176470588234,
      "grad_norm": 0.8446502685546875,
      "learning_rate": 7.404003267973857e-06,
      "loss": 0.046,
      "step": 7264
    },
    {
      "epoch": 1.6693474264705883,
      "grad_norm": 0.8225648999214172,
      "learning_rate": 7.403492647058824e-06,
      "loss": 0.0372,
      "step": 7265
    },
    {
      "epoch": 1.6695772058823528,
      "grad_norm": 1.154702067375183,
      "learning_rate": 7.402982026143791e-06,
      "loss": 0.0577,
      "step": 7266
    },
    {
      "epoch": 1.6698069852941178,
      "grad_norm": 1.711139440536499,
      "learning_rate": 7.402471405228758e-06,
      "loss": 0.0786,
      "step": 7267
    },
    {
      "epoch": 1.6700367647058822,
      "grad_norm": 0.8477457761764526,
      "learning_rate": 7.401960784313726e-06,
      "loss": 0.0483,
      "step": 7268
    },
    {
      "epoch": 1.6702665441176472,
      "grad_norm": 1.2129185199737549,
      "learning_rate": 7.401450163398693e-06,
      "loss": 0.0762,
      "step": 7269
    },
    {
      "epoch": 1.6704963235294117,
      "grad_norm": 0.8504355549812317,
      "learning_rate": 7.40093954248366e-06,
      "loss": 0.0466,
      "step": 7270
    },
    {
      "epoch": 1.6707261029411766,
      "grad_norm": 0.9099990725517273,
      "learning_rate": 7.400428921568627e-06,
      "loss": 0.0433,
      "step": 7271
    },
    {
      "epoch": 1.6709558823529411,
      "grad_norm": 1.1183183193206787,
      "learning_rate": 7.399918300653596e-06,
      "loss": 0.0548,
      "step": 7272
    },
    {
      "epoch": 1.6711856617647058,
      "grad_norm": 1.0453872680664062,
      "learning_rate": 7.399407679738563e-06,
      "loss": 0.0534,
      "step": 7273
    },
    {
      "epoch": 1.6714154411764706,
      "grad_norm": 0.8678248524665833,
      "learning_rate": 7.39889705882353e-06,
      "loss": 0.0311,
      "step": 7274
    },
    {
      "epoch": 1.6716452205882353,
      "grad_norm": 0.8897497057914734,
      "learning_rate": 7.398386437908497e-06,
      "loss": 0.0652,
      "step": 7275
    },
    {
      "epoch": 1.671875,
      "grad_norm": 0.9684755206108093,
      "learning_rate": 7.397875816993465e-06,
      "loss": 0.0591,
      "step": 7276
    },
    {
      "epoch": 1.6721047794117647,
      "grad_norm": 1.1444772481918335,
      "learning_rate": 7.397365196078432e-06,
      "loss": 0.0655,
      "step": 7277
    },
    {
      "epoch": 1.6723345588235294,
      "grad_norm": 0.912815511226654,
      "learning_rate": 7.396854575163399e-06,
      "loss": 0.0435,
      "step": 7278
    },
    {
      "epoch": 1.6725643382352942,
      "grad_norm": 0.8715385794639587,
      "learning_rate": 7.396343954248366e-06,
      "loss": 0.0449,
      "step": 7279
    },
    {
      "epoch": 1.6727941176470589,
      "grad_norm": 0.9000577926635742,
      "learning_rate": 7.395833333333335e-06,
      "loss": 0.0461,
      "step": 7280
    },
    {
      "epoch": 1.6730238970588234,
      "grad_norm": 1.3619320392608643,
      "learning_rate": 7.395322712418302e-06,
      "loss": 0.0433,
      "step": 7281
    },
    {
      "epoch": 1.6732536764705883,
      "grad_norm": 1.1142497062683105,
      "learning_rate": 7.394812091503269e-06,
      "loss": 0.0643,
      "step": 7282
    },
    {
      "epoch": 1.6734834558823528,
      "grad_norm": 0.912446916103363,
      "learning_rate": 7.394301470588236e-06,
      "loss": 0.0545,
      "step": 7283
    },
    {
      "epoch": 1.6737132352941178,
      "grad_norm": 1.0644831657409668,
      "learning_rate": 7.3937908496732036e-06,
      "loss": 0.0593,
      "step": 7284
    },
    {
      "epoch": 1.6739430147058822,
      "grad_norm": 0.9811405539512634,
      "learning_rate": 7.393280228758171e-06,
      "loss": 0.0656,
      "step": 7285
    },
    {
      "epoch": 1.6741727941176472,
      "grad_norm": 0.8233802318572998,
      "learning_rate": 7.392769607843138e-06,
      "loss": 0.0444,
      "step": 7286
    },
    {
      "epoch": 1.6744025735294117,
      "grad_norm": 1.0359910726547241,
      "learning_rate": 7.392258986928105e-06,
      "loss": 0.0588,
      "step": 7287
    },
    {
      "epoch": 1.6746323529411766,
      "grad_norm": 1.1370943784713745,
      "learning_rate": 7.3917483660130725e-06,
      "loss": 0.0775,
      "step": 7288
    },
    {
      "epoch": 1.6748621323529411,
      "grad_norm": 1.3078949451446533,
      "learning_rate": 7.39123774509804e-06,
      "loss": 0.086,
      "step": 7289
    },
    {
      "epoch": 1.6750919117647058,
      "grad_norm": 1.1030504703521729,
      "learning_rate": 7.390727124183007e-06,
      "loss": 0.0677,
      "step": 7290
    },
    {
      "epoch": 1.6753216911764706,
      "grad_norm": 1.0793887376785278,
      "learning_rate": 7.390216503267974e-06,
      "loss": 0.0573,
      "step": 7291
    },
    {
      "epoch": 1.6755514705882353,
      "grad_norm": 1.5672800540924072,
      "learning_rate": 7.389705882352942e-06,
      "loss": 0.0707,
      "step": 7292
    },
    {
      "epoch": 1.67578125,
      "grad_norm": 0.9227120280265808,
      "learning_rate": 7.389195261437909e-06,
      "loss": 0.0433,
      "step": 7293
    },
    {
      "epoch": 1.6760110294117647,
      "grad_norm": 1.0147128105163574,
      "learning_rate": 7.388684640522876e-06,
      "loss": 0.0719,
      "step": 7294
    },
    {
      "epoch": 1.6762408088235294,
      "grad_norm": 1.1070520877838135,
      "learning_rate": 7.388174019607843e-06,
      "loss": 0.0565,
      "step": 7295
    },
    {
      "epoch": 1.6764705882352942,
      "grad_norm": 0.8569696545600891,
      "learning_rate": 7.387663398692811e-06,
      "loss": 0.0551,
      "step": 7296
    },
    {
      "epoch": 1.6767003676470589,
      "grad_norm": 1.1022205352783203,
      "learning_rate": 7.387152777777778e-06,
      "loss": 0.0477,
      "step": 7297
    },
    {
      "epoch": 1.6769301470588234,
      "grad_norm": 0.7123774886131287,
      "learning_rate": 7.386642156862745e-06,
      "loss": 0.0394,
      "step": 7298
    },
    {
      "epoch": 1.6771599264705883,
      "grad_norm": 1.0829963684082031,
      "learning_rate": 7.386131535947712e-06,
      "loss": 0.0642,
      "step": 7299
    },
    {
      "epoch": 1.6773897058823528,
      "grad_norm": 0.9294435977935791,
      "learning_rate": 7.385620915032681e-06,
      "loss": 0.0716,
      "step": 7300
    },
    {
      "epoch": 1.6776194852941178,
      "grad_norm": 0.6726383566856384,
      "learning_rate": 7.385110294117648e-06,
      "loss": 0.0296,
      "step": 7301
    },
    {
      "epoch": 1.6778492647058822,
      "grad_norm": 0.9993745684623718,
      "learning_rate": 7.384599673202615e-06,
      "loss": 0.0415,
      "step": 7302
    },
    {
      "epoch": 1.6780790441176472,
      "grad_norm": 0.9284443855285645,
      "learning_rate": 7.384089052287582e-06,
      "loss": 0.0368,
      "step": 7303
    },
    {
      "epoch": 1.6783088235294117,
      "grad_norm": 0.7702632546424866,
      "learning_rate": 7.38357843137255e-06,
      "loss": 0.0347,
      "step": 7304
    },
    {
      "epoch": 1.6785386029411766,
      "grad_norm": 0.8515964150428772,
      "learning_rate": 7.383067810457517e-06,
      "loss": 0.0469,
      "step": 7305
    },
    {
      "epoch": 1.6787683823529411,
      "grad_norm": 0.7959223389625549,
      "learning_rate": 7.382557189542484e-06,
      "loss": 0.0414,
      "step": 7306
    },
    {
      "epoch": 1.6789981617647058,
      "grad_norm": 0.841873288154602,
      "learning_rate": 7.382046568627451e-06,
      "loss": 0.0383,
      "step": 7307
    },
    {
      "epoch": 1.6792279411764706,
      "grad_norm": 1.0755294561386108,
      "learning_rate": 7.3815359477124195e-06,
      "loss": 0.0537,
      "step": 7308
    },
    {
      "epoch": 1.6794577205882353,
      "grad_norm": 1.2799667119979858,
      "learning_rate": 7.3810253267973866e-06,
      "loss": 0.0706,
      "step": 7309
    },
    {
      "epoch": 1.6796875,
      "grad_norm": 1.0763047933578491,
      "learning_rate": 7.3805147058823536e-06,
      "loss": 0.0604,
      "step": 7310
    },
    {
      "epoch": 1.6799172794117647,
      "grad_norm": 1.3805785179138184,
      "learning_rate": 7.380004084967321e-06,
      "loss": 0.0527,
      "step": 7311
    },
    {
      "epoch": 1.6801470588235294,
      "grad_norm": 0.8925898671150208,
      "learning_rate": 7.3794934640522884e-06,
      "loss": 0.0421,
      "step": 7312
    },
    {
      "epoch": 1.6803768382352942,
      "grad_norm": 0.8014616966247559,
      "learning_rate": 7.3789828431372555e-06,
      "loss": 0.0395,
      "step": 7313
    },
    {
      "epoch": 1.6806066176470589,
      "grad_norm": 1.2549781799316406,
      "learning_rate": 7.3784722222222225e-06,
      "loss": 0.0446,
      "step": 7314
    },
    {
      "epoch": 1.6808363970588234,
      "grad_norm": 1.0575634241104126,
      "learning_rate": 7.3779616013071895e-06,
      "loss": 0.0559,
      "step": 7315
    },
    {
      "epoch": 1.6810661764705883,
      "grad_norm": 1.0682389736175537,
      "learning_rate": 7.377450980392158e-06,
      "loss": 0.0493,
      "step": 7316
    },
    {
      "epoch": 1.6812959558823528,
      "grad_norm": 0.9199323654174805,
      "learning_rate": 7.376940359477125e-06,
      "loss": 0.041,
      "step": 7317
    },
    {
      "epoch": 1.6815257352941178,
      "grad_norm": 1.0346267223358154,
      "learning_rate": 7.376429738562092e-06,
      "loss": 0.0641,
      "step": 7318
    },
    {
      "epoch": 1.6817555147058822,
      "grad_norm": 1.1969714164733887,
      "learning_rate": 7.375919117647059e-06,
      "loss": 0.0483,
      "step": 7319
    },
    {
      "epoch": 1.6819852941176472,
      "grad_norm": 1.554194450378418,
      "learning_rate": 7.375408496732027e-06,
      "loss": 0.0798,
      "step": 7320
    },
    {
      "epoch": 1.6822150735294117,
      "grad_norm": 0.8734791874885559,
      "learning_rate": 7.374897875816994e-06,
      "loss": 0.0547,
      "step": 7321
    },
    {
      "epoch": 1.6824448529411766,
      "grad_norm": 0.6211214661598206,
      "learning_rate": 7.374387254901961e-06,
      "loss": 0.037,
      "step": 7322
    },
    {
      "epoch": 1.6826746323529411,
      "grad_norm": 1.072542667388916,
      "learning_rate": 7.373876633986928e-06,
      "loss": 0.0451,
      "step": 7323
    },
    {
      "epoch": 1.6829044117647058,
      "grad_norm": 0.7486291527748108,
      "learning_rate": 7.373366013071897e-06,
      "loss": 0.0347,
      "step": 7324
    },
    {
      "epoch": 1.6831341911764706,
      "grad_norm": 1.2079424858093262,
      "learning_rate": 7.372855392156864e-06,
      "loss": 0.0489,
      "step": 7325
    },
    {
      "epoch": 1.6833639705882353,
      "grad_norm": 1.451317310333252,
      "learning_rate": 7.372344771241831e-06,
      "loss": 0.0516,
      "step": 7326
    },
    {
      "epoch": 1.68359375,
      "grad_norm": 1.209183931350708,
      "learning_rate": 7.371834150326798e-06,
      "loss": 0.067,
      "step": 7327
    },
    {
      "epoch": 1.6838235294117647,
      "grad_norm": 0.8950216174125671,
      "learning_rate": 7.371323529411766e-06,
      "loss": 0.0415,
      "step": 7328
    },
    {
      "epoch": 1.6840533088235294,
      "grad_norm": 1.3988746404647827,
      "learning_rate": 7.370812908496733e-06,
      "loss": 0.0624,
      "step": 7329
    },
    {
      "epoch": 1.6842830882352942,
      "grad_norm": 1.3423457145690918,
      "learning_rate": 7.3703022875817e-06,
      "loss": 0.0721,
      "step": 7330
    },
    {
      "epoch": 1.6845128676470589,
      "grad_norm": 0.829654335975647,
      "learning_rate": 7.369791666666667e-06,
      "loss": 0.0332,
      "step": 7331
    },
    {
      "epoch": 1.6847426470588234,
      "grad_norm": 1.110986351966858,
      "learning_rate": 7.369281045751635e-06,
      "loss": 0.0677,
      "step": 7332
    },
    {
      "epoch": 1.6849724264705883,
      "grad_norm": 1.2769767045974731,
      "learning_rate": 7.3687704248366025e-06,
      "loss": 0.0638,
      "step": 7333
    },
    {
      "epoch": 1.6852022058823528,
      "grad_norm": 1.0131841897964478,
      "learning_rate": 7.3682598039215695e-06,
      "loss": 0.0385,
      "step": 7334
    },
    {
      "epoch": 1.6854319852941178,
      "grad_norm": 1.1037756204605103,
      "learning_rate": 7.3677491830065365e-06,
      "loss": 0.0818,
      "step": 7335
    },
    {
      "epoch": 1.6856617647058822,
      "grad_norm": 1.1107591390609741,
      "learning_rate": 7.367238562091504e-06,
      "loss": 0.0685,
      "step": 7336
    },
    {
      "epoch": 1.6858915441176472,
      "grad_norm": 0.8783521056175232,
      "learning_rate": 7.3667279411764714e-06,
      "loss": 0.0346,
      "step": 7337
    },
    {
      "epoch": 1.6861213235294117,
      "grad_norm": 1.0196503400802612,
      "learning_rate": 7.3662173202614384e-06,
      "loss": 0.0424,
      "step": 7338
    },
    {
      "epoch": 1.6863511029411766,
      "grad_norm": 1.0009876489639282,
      "learning_rate": 7.3657066993464055e-06,
      "loss": 0.0468,
      "step": 7339
    },
    {
      "epoch": 1.6865808823529411,
      "grad_norm": 1.0789518356323242,
      "learning_rate": 7.365196078431373e-06,
      "loss": 0.0548,
      "step": 7340
    },
    {
      "epoch": 1.6868106617647058,
      "grad_norm": 1.1157174110412598,
      "learning_rate": 7.36468545751634e-06,
      "loss": 0.0608,
      "step": 7341
    },
    {
      "epoch": 1.6870404411764706,
      "grad_norm": 0.8196958899497986,
      "learning_rate": 7.364174836601307e-06,
      "loss": 0.04,
      "step": 7342
    },
    {
      "epoch": 1.6872702205882353,
      "grad_norm": 0.9563405513763428,
      "learning_rate": 7.363664215686274e-06,
      "loss": 0.0372,
      "step": 7343
    },
    {
      "epoch": 1.6875,
      "grad_norm": 0.8065855503082275,
      "learning_rate": 7.363153594771243e-06,
      "loss": 0.0438,
      "step": 7344
    },
    {
      "epoch": 1.6877297794117647,
      "grad_norm": 1.0611015558242798,
      "learning_rate": 7.36264297385621e-06,
      "loss": 0.0414,
      "step": 7345
    },
    {
      "epoch": 1.6879595588235294,
      "grad_norm": 0.9454070925712585,
      "learning_rate": 7.362132352941177e-06,
      "loss": 0.0623,
      "step": 7346
    },
    {
      "epoch": 1.6881893382352942,
      "grad_norm": 0.882378876209259,
      "learning_rate": 7.361621732026144e-06,
      "loss": 0.0274,
      "step": 7347
    },
    {
      "epoch": 1.6884191176470589,
      "grad_norm": 1.133313536643982,
      "learning_rate": 7.361111111111112e-06,
      "loss": 0.0781,
      "step": 7348
    },
    {
      "epoch": 1.6886488970588234,
      "grad_norm": 1.0078957080841064,
      "learning_rate": 7.360600490196079e-06,
      "loss": 0.0514,
      "step": 7349
    },
    {
      "epoch": 1.6888786764705883,
      "grad_norm": 1.0514445304870605,
      "learning_rate": 7.360089869281046e-06,
      "loss": 0.0449,
      "step": 7350
    },
    {
      "epoch": 1.6891084558823528,
      "grad_norm": 1.348636269569397,
      "learning_rate": 7.359579248366013e-06,
      "loss": 0.0532,
      "step": 7351
    },
    {
      "epoch": 1.6893382352941178,
      "grad_norm": 0.8853526711463928,
      "learning_rate": 7.359068627450982e-06,
      "loss": 0.0493,
      "step": 7352
    },
    {
      "epoch": 1.6895680147058822,
      "grad_norm": 1.3842318058013916,
      "learning_rate": 7.358558006535949e-06,
      "loss": 0.0372,
      "step": 7353
    },
    {
      "epoch": 1.6897977941176472,
      "grad_norm": 0.8621653318405151,
      "learning_rate": 7.358047385620916e-06,
      "loss": 0.0627,
      "step": 7354
    },
    {
      "epoch": 1.6900275735294117,
      "grad_norm": 1.2746943235397339,
      "learning_rate": 7.357536764705883e-06,
      "loss": 0.049,
      "step": 7355
    },
    {
      "epoch": 1.6902573529411766,
      "grad_norm": 0.7398579120635986,
      "learning_rate": 7.357026143790851e-06,
      "loss": 0.0407,
      "step": 7356
    },
    {
      "epoch": 1.6904871323529411,
      "grad_norm": 0.8050734996795654,
      "learning_rate": 7.356515522875818e-06,
      "loss": 0.0367,
      "step": 7357
    },
    {
      "epoch": 1.6907169117647058,
      "grad_norm": 1.4932386875152588,
      "learning_rate": 7.356004901960785e-06,
      "loss": 0.0634,
      "step": 7358
    },
    {
      "epoch": 1.6909466911764706,
      "grad_norm": 0.8475468754768372,
      "learning_rate": 7.355494281045752e-06,
      "loss": 0.0367,
      "step": 7359
    },
    {
      "epoch": 1.6911764705882353,
      "grad_norm": 1.056644082069397,
      "learning_rate": 7.35498366013072e-06,
      "loss": 0.0696,
      "step": 7360
    },
    {
      "epoch": 1.69140625,
      "grad_norm": 0.8529180288314819,
      "learning_rate": 7.354473039215687e-06,
      "loss": 0.0578,
      "step": 7361
    },
    {
      "epoch": 1.6916360294117647,
      "grad_norm": 1.349078893661499,
      "learning_rate": 7.353962418300654e-06,
      "loss": 0.0307,
      "step": 7362
    },
    {
      "epoch": 1.6918658088235294,
      "grad_norm": 0.7547674179077148,
      "learning_rate": 7.3534517973856214e-06,
      "loss": 0.0478,
      "step": 7363
    },
    {
      "epoch": 1.6920955882352942,
      "grad_norm": 1.1480873823165894,
      "learning_rate": 7.352941176470589e-06,
      "loss": 0.048,
      "step": 7364
    },
    {
      "epoch": 1.6923253676470589,
      "grad_norm": 0.9373793601989746,
      "learning_rate": 7.352430555555556e-06,
      "loss": 0.0457,
      "step": 7365
    },
    {
      "epoch": 1.6925551470588234,
      "grad_norm": 0.9615263342857361,
      "learning_rate": 7.351919934640523e-06,
      "loss": 0.0646,
      "step": 7366
    },
    {
      "epoch": 1.6927849264705883,
      "grad_norm": 1.328796148300171,
      "learning_rate": 7.35140931372549e-06,
      "loss": 0.058,
      "step": 7367
    },
    {
      "epoch": 1.6930147058823528,
      "grad_norm": 0.9357184171676636,
      "learning_rate": 7.350898692810459e-06,
      "loss": 0.0613,
      "step": 7368
    },
    {
      "epoch": 1.6932444852941178,
      "grad_norm": 1.0849494934082031,
      "learning_rate": 7.350388071895426e-06,
      "loss": 0.0435,
      "step": 7369
    },
    {
      "epoch": 1.6934742647058822,
      "grad_norm": 0.9091491103172302,
      "learning_rate": 7.349877450980393e-06,
      "loss": 0.036,
      "step": 7370
    },
    {
      "epoch": 1.6937040441176472,
      "grad_norm": 1.0995968580245972,
      "learning_rate": 7.34936683006536e-06,
      "loss": 0.0696,
      "step": 7371
    },
    {
      "epoch": 1.6939338235294117,
      "grad_norm": 1.1306926012039185,
      "learning_rate": 7.348856209150328e-06,
      "loss": 0.0512,
      "step": 7372
    },
    {
      "epoch": 1.6941636029411766,
      "grad_norm": 1.3661137819290161,
      "learning_rate": 7.348345588235295e-06,
      "loss": 0.0561,
      "step": 7373
    },
    {
      "epoch": 1.6943933823529411,
      "grad_norm": 0.8662569522857666,
      "learning_rate": 7.347834967320262e-06,
      "loss": 0.054,
      "step": 7374
    },
    {
      "epoch": 1.6946231617647058,
      "grad_norm": 0.9155802726745605,
      "learning_rate": 7.347324346405229e-06,
      "loss": 0.0322,
      "step": 7375
    },
    {
      "epoch": 1.6948529411764706,
      "grad_norm": 0.7830137014389038,
      "learning_rate": 7.346813725490197e-06,
      "loss": 0.0422,
      "step": 7376
    },
    {
      "epoch": 1.6950827205882353,
      "grad_norm": 1.2071588039398193,
      "learning_rate": 7.346303104575164e-06,
      "loss": 0.0611,
      "step": 7377
    },
    {
      "epoch": 1.6953125,
      "grad_norm": 1.9918876886367798,
      "learning_rate": 7.345792483660132e-06,
      "loss": 0.0479,
      "step": 7378
    },
    {
      "epoch": 1.6955422794117647,
      "grad_norm": 0.7120947241783142,
      "learning_rate": 7.345281862745099e-06,
      "loss": 0.0355,
      "step": 7379
    },
    {
      "epoch": 1.6957720588235294,
      "grad_norm": 0.7519875764846802,
      "learning_rate": 7.344771241830067e-06,
      "loss": 0.0424,
      "step": 7380
    },
    {
      "epoch": 1.6960018382352942,
      "grad_norm": 0.974489152431488,
      "learning_rate": 7.344260620915034e-06,
      "loss": 0.0532,
      "step": 7381
    },
    {
      "epoch": 1.6962316176470589,
      "grad_norm": 0.8402367830276489,
      "learning_rate": 7.343750000000001e-06,
      "loss": 0.0375,
      "step": 7382
    },
    {
      "epoch": 1.6964613970588234,
      "grad_norm": 0.6925159096717834,
      "learning_rate": 7.343239379084968e-06,
      "loss": 0.0393,
      "step": 7383
    },
    {
      "epoch": 1.6966911764705883,
      "grad_norm": 0.9347259402275085,
      "learning_rate": 7.342728758169935e-06,
      "loss": 0.0592,
      "step": 7384
    },
    {
      "epoch": 1.6969209558823528,
      "grad_norm": 1.000120997428894,
      "learning_rate": 7.3422181372549025e-06,
      "loss": 0.0363,
      "step": 7385
    },
    {
      "epoch": 1.6971507352941178,
      "grad_norm": 0.8447869420051575,
      "learning_rate": 7.3417075163398695e-06,
      "loss": 0.0397,
      "step": 7386
    },
    {
      "epoch": 1.6973805147058822,
      "grad_norm": 0.8522914052009583,
      "learning_rate": 7.3411968954248365e-06,
      "loss": 0.0462,
      "step": 7387
    },
    {
      "epoch": 1.6976102941176472,
      "grad_norm": 0.8755853176116943,
      "learning_rate": 7.3406862745098036e-06,
      "loss": 0.0355,
      "step": 7388
    },
    {
      "epoch": 1.6978400735294117,
      "grad_norm": 1.3014912605285645,
      "learning_rate": 7.340175653594772e-06,
      "loss": 0.0622,
      "step": 7389
    },
    {
      "epoch": 1.6980698529411766,
      "grad_norm": 0.9214984774589539,
      "learning_rate": 7.339665032679739e-06,
      "loss": 0.0419,
      "step": 7390
    },
    {
      "epoch": 1.6982996323529411,
      "grad_norm": 0.7230817079544067,
      "learning_rate": 7.339154411764706e-06,
      "loss": 0.0347,
      "step": 7391
    },
    {
      "epoch": 1.6985294117647058,
      "grad_norm": 0.549678385257721,
      "learning_rate": 7.338643790849673e-06,
      "loss": 0.0241,
      "step": 7392
    },
    {
      "epoch": 1.6987591911764706,
      "grad_norm": 0.6979926824569702,
      "learning_rate": 7.338133169934641e-06,
      "loss": 0.0359,
      "step": 7393
    },
    {
      "epoch": 1.6989889705882353,
      "grad_norm": 1.0720131397247314,
      "learning_rate": 7.337622549019608e-06,
      "loss": 0.0895,
      "step": 7394
    },
    {
      "epoch": 1.69921875,
      "grad_norm": 1.0648235082626343,
      "learning_rate": 7.337111928104575e-06,
      "loss": 0.0551,
      "step": 7395
    },
    {
      "epoch": 1.6994485294117647,
      "grad_norm": 0.9944271445274353,
      "learning_rate": 7.336601307189542e-06,
      "loss": 0.0577,
      "step": 7396
    },
    {
      "epoch": 1.6996783088235294,
      "grad_norm": 1.0455846786499023,
      "learning_rate": 7.336090686274511e-06,
      "loss": 0.0401,
      "step": 7397
    },
    {
      "epoch": 1.6999080882352942,
      "grad_norm": 0.7717852592468262,
      "learning_rate": 7.335580065359478e-06,
      "loss": 0.0306,
      "step": 7398
    },
    {
      "epoch": 1.7001378676470589,
      "grad_norm": 0.792873740196228,
      "learning_rate": 7.335069444444445e-06,
      "loss": 0.0304,
      "step": 7399
    },
    {
      "epoch": 1.7003676470588234,
      "grad_norm": 0.9941306710243225,
      "learning_rate": 7.334558823529412e-06,
      "loss": 0.0486,
      "step": 7400
    },
    {
      "epoch": 1.7005974264705883,
      "grad_norm": 0.7383791208267212,
      "learning_rate": 7.33404820261438e-06,
      "loss": 0.0379,
      "step": 7401
    },
    {
      "epoch": 1.7008272058823528,
      "grad_norm": 1.0218335390090942,
      "learning_rate": 7.333537581699347e-06,
      "loss": 0.049,
      "step": 7402
    },
    {
      "epoch": 1.7010569852941178,
      "grad_norm": 1.2184029817581177,
      "learning_rate": 7.333026960784314e-06,
      "loss": 0.0579,
      "step": 7403
    },
    {
      "epoch": 1.7012867647058822,
      "grad_norm": 1.0389575958251953,
      "learning_rate": 7.332516339869281e-06,
      "loss": 0.0582,
      "step": 7404
    },
    {
      "epoch": 1.7015165441176472,
      "grad_norm": 0.7268310189247131,
      "learning_rate": 7.33200571895425e-06,
      "loss": 0.0336,
      "step": 7405
    },
    {
      "epoch": 1.7017463235294117,
      "grad_norm": 1.4640276432037354,
      "learning_rate": 7.331495098039217e-06,
      "loss": 0.0594,
      "step": 7406
    },
    {
      "epoch": 1.7019761029411766,
      "grad_norm": 0.9522733092308044,
      "learning_rate": 7.330984477124184e-06,
      "loss": 0.0528,
      "step": 7407
    },
    {
      "epoch": 1.7022058823529411,
      "grad_norm": 2.062225103378296,
      "learning_rate": 7.330473856209151e-06,
      "loss": 0.0323,
      "step": 7408
    },
    {
      "epoch": 1.7024356617647058,
      "grad_norm": 0.8895070552825928,
      "learning_rate": 7.3299632352941185e-06,
      "loss": 0.05,
      "step": 7409
    },
    {
      "epoch": 1.7026654411764706,
      "grad_norm": 0.674773097038269,
      "learning_rate": 7.3294526143790855e-06,
      "loss": 0.0332,
      "step": 7410
    },
    {
      "epoch": 1.7028952205882353,
      "grad_norm": 0.8320770263671875,
      "learning_rate": 7.3289419934640525e-06,
      "loss": 0.0415,
      "step": 7411
    },
    {
      "epoch": 1.703125,
      "grad_norm": 0.9022142887115479,
      "learning_rate": 7.3284313725490195e-06,
      "loss": 0.0415,
      "step": 7412
    },
    {
      "epoch": 1.7033547794117647,
      "grad_norm": 0.9062889218330383,
      "learning_rate": 7.327920751633988e-06,
      "loss": 0.0408,
      "step": 7413
    },
    {
      "epoch": 1.7035845588235294,
      "grad_norm": 0.7949333786964417,
      "learning_rate": 7.327410130718955e-06,
      "loss": 0.0371,
      "step": 7414
    },
    {
      "epoch": 1.7038143382352942,
      "grad_norm": 1.3413606882095337,
      "learning_rate": 7.326899509803922e-06,
      "loss": 0.0519,
      "step": 7415
    },
    {
      "epoch": 1.7040441176470589,
      "grad_norm": 0.9991059303283691,
      "learning_rate": 7.326388888888889e-06,
      "loss": 0.0426,
      "step": 7416
    },
    {
      "epoch": 1.7042738970588234,
      "grad_norm": 1.2216954231262207,
      "learning_rate": 7.325878267973857e-06,
      "loss": 0.0703,
      "step": 7417
    },
    {
      "epoch": 1.7045036764705883,
      "grad_norm": 0.8452598452568054,
      "learning_rate": 7.325367647058824e-06,
      "loss": 0.0392,
      "step": 7418
    },
    {
      "epoch": 1.7047334558823528,
      "grad_norm": 0.9978864192962646,
      "learning_rate": 7.324857026143791e-06,
      "loss": 0.0461,
      "step": 7419
    },
    {
      "epoch": 1.7049632352941178,
      "grad_norm": 0.7209768891334534,
      "learning_rate": 7.324346405228758e-06,
      "loss": 0.027,
      "step": 7420
    },
    {
      "epoch": 1.7051930147058822,
      "grad_norm": 1.1362299919128418,
      "learning_rate": 7.323835784313726e-06,
      "loss": 0.0646,
      "step": 7421
    },
    {
      "epoch": 1.7054227941176472,
      "grad_norm": 1.0858960151672363,
      "learning_rate": 7.323325163398693e-06,
      "loss": 0.0579,
      "step": 7422
    },
    {
      "epoch": 1.7056525735294117,
      "grad_norm": 0.8034440279006958,
      "learning_rate": 7.322814542483661e-06,
      "loss": 0.0509,
      "step": 7423
    },
    {
      "epoch": 1.7058823529411766,
      "grad_norm": 0.9807114005088806,
      "learning_rate": 7.322303921568628e-06,
      "loss": 0.0513,
      "step": 7424
    },
    {
      "epoch": 1.7061121323529411,
      "grad_norm": 0.8777427077293396,
      "learning_rate": 7.321793300653596e-06,
      "loss": 0.047,
      "step": 7425
    },
    {
      "epoch": 1.7063419117647058,
      "grad_norm": 0.9873197674751282,
      "learning_rate": 7.321282679738563e-06,
      "loss": 0.04,
      "step": 7426
    },
    {
      "epoch": 1.7065716911764706,
      "grad_norm": 1.0394312143325806,
      "learning_rate": 7.32077205882353e-06,
      "loss": 0.0546,
      "step": 7427
    },
    {
      "epoch": 1.7068014705882353,
      "grad_norm": 0.8721330761909485,
      "learning_rate": 7.320261437908497e-06,
      "loss": 0.0441,
      "step": 7428
    },
    {
      "epoch": 1.70703125,
      "grad_norm": 0.7307785749435425,
      "learning_rate": 7.319750816993465e-06,
      "loss": 0.045,
      "step": 7429
    },
    {
      "epoch": 1.7072610294117647,
      "grad_norm": 1.1866388320922852,
      "learning_rate": 7.319240196078432e-06,
      "loss": 0.0515,
      "step": 7430
    },
    {
      "epoch": 1.7074908088235294,
      "grad_norm": 1.187018632888794,
      "learning_rate": 7.318729575163399e-06,
      "loss": 0.0432,
      "step": 7431
    },
    {
      "epoch": 1.7077205882352942,
      "grad_norm": 1.0497183799743652,
      "learning_rate": 7.318218954248366e-06,
      "loss": 0.0617,
      "step": 7432
    },
    {
      "epoch": 1.7079503676470589,
      "grad_norm": 0.7279519438743591,
      "learning_rate": 7.3177083333333345e-06,
      "loss": 0.04,
      "step": 7433
    },
    {
      "epoch": 1.7081801470588234,
      "grad_norm": 1.810632586479187,
      "learning_rate": 7.3171977124183015e-06,
      "loss": 0.1066,
      "step": 7434
    },
    {
      "epoch": 1.7084099264705883,
      "grad_norm": 1.0110385417938232,
      "learning_rate": 7.3166870915032685e-06,
      "loss": 0.0404,
      "step": 7435
    },
    {
      "epoch": 1.7086397058823528,
      "grad_norm": 0.9421480298042297,
      "learning_rate": 7.3161764705882355e-06,
      "loss": 0.0467,
      "step": 7436
    },
    {
      "epoch": 1.7088694852941178,
      "grad_norm": 1.2035692930221558,
      "learning_rate": 7.315665849673203e-06,
      "loss": 0.062,
      "step": 7437
    },
    {
      "epoch": 1.7090992647058822,
      "grad_norm": 0.9895634055137634,
      "learning_rate": 7.31515522875817e-06,
      "loss": 0.0449,
      "step": 7438
    },
    {
      "epoch": 1.7093290441176472,
      "grad_norm": 0.9354061484336853,
      "learning_rate": 7.314644607843137e-06,
      "loss": 0.0471,
      "step": 7439
    },
    {
      "epoch": 1.7095588235294117,
      "grad_norm": 0.7704294323921204,
      "learning_rate": 7.314133986928104e-06,
      "loss": 0.0319,
      "step": 7440
    },
    {
      "epoch": 1.7097886029411766,
      "grad_norm": 1.0078341960906982,
      "learning_rate": 7.313623366013073e-06,
      "loss": 0.0626,
      "step": 7441
    },
    {
      "epoch": 1.7100183823529411,
      "grad_norm": 1.0256048440933228,
      "learning_rate": 7.31311274509804e-06,
      "loss": 0.045,
      "step": 7442
    },
    {
      "epoch": 1.7102481617647058,
      "grad_norm": 0.9621282815933228,
      "learning_rate": 7.312602124183007e-06,
      "loss": 0.0408,
      "step": 7443
    },
    {
      "epoch": 1.7104779411764706,
      "grad_norm": 1.5219398736953735,
      "learning_rate": 7.312091503267974e-06,
      "loss": 0.0767,
      "step": 7444
    },
    {
      "epoch": 1.7107077205882353,
      "grad_norm": 1.024414300918579,
      "learning_rate": 7.311580882352942e-06,
      "loss": 0.0481,
      "step": 7445
    },
    {
      "epoch": 1.7109375,
      "grad_norm": 1.0476949214935303,
      "learning_rate": 7.311070261437909e-06,
      "loss": 0.054,
      "step": 7446
    },
    {
      "epoch": 1.7111672794117647,
      "grad_norm": 0.9988511800765991,
      "learning_rate": 7.310559640522876e-06,
      "loss": 0.0434,
      "step": 7447
    },
    {
      "epoch": 1.7113970588235294,
      "grad_norm": 0.9660044312477112,
      "learning_rate": 7.310049019607843e-06,
      "loss": 0.0454,
      "step": 7448
    },
    {
      "epoch": 1.7116268382352942,
      "grad_norm": 1.1475664377212524,
      "learning_rate": 7.309538398692812e-06,
      "loss": 0.059,
      "step": 7449
    },
    {
      "epoch": 1.7118566176470589,
      "grad_norm": 1.1079901456832886,
      "learning_rate": 7.309027777777779e-06,
      "loss": 0.0523,
      "step": 7450
    },
    {
      "epoch": 1.7120863970588234,
      "grad_norm": 0.9215530157089233,
      "learning_rate": 7.308517156862746e-06,
      "loss": 0.0587,
      "step": 7451
    },
    {
      "epoch": 1.7123161764705883,
      "grad_norm": 0.7705537676811218,
      "learning_rate": 7.308006535947713e-06,
      "loss": 0.0318,
      "step": 7452
    },
    {
      "epoch": 1.7125459558823528,
      "grad_norm": 1.0245598554611206,
      "learning_rate": 7.307495915032681e-06,
      "loss": 0.0511,
      "step": 7453
    },
    {
      "epoch": 1.7127757352941178,
      "grad_norm": 0.7546987533569336,
      "learning_rate": 7.306985294117648e-06,
      "loss": 0.0288,
      "step": 7454
    },
    {
      "epoch": 1.7130055147058822,
      "grad_norm": 0.9993058443069458,
      "learning_rate": 7.306474673202615e-06,
      "loss": 0.0309,
      "step": 7455
    },
    {
      "epoch": 1.7132352941176472,
      "grad_norm": 1.0544393062591553,
      "learning_rate": 7.305964052287582e-06,
      "loss": 0.0481,
      "step": 7456
    },
    {
      "epoch": 1.7134650735294117,
      "grad_norm": 0.8159510493278503,
      "learning_rate": 7.3054534313725504e-06,
      "loss": 0.0273,
      "step": 7457
    },
    {
      "epoch": 1.7136948529411766,
      "grad_norm": 0.9738371968269348,
      "learning_rate": 7.3049428104575174e-06,
      "loss": 0.0428,
      "step": 7458
    },
    {
      "epoch": 1.7139246323529411,
      "grad_norm": 0.9708107709884644,
      "learning_rate": 7.3044321895424845e-06,
      "loss": 0.0633,
      "step": 7459
    },
    {
      "epoch": 1.7141544117647058,
      "grad_norm": 1.0538002252578735,
      "learning_rate": 7.3039215686274515e-06,
      "loss": 0.0423,
      "step": 7460
    },
    {
      "epoch": 1.7143841911764706,
      "grad_norm": 0.6617613434791565,
      "learning_rate": 7.303410947712419e-06,
      "loss": 0.0262,
      "step": 7461
    },
    {
      "epoch": 1.7146139705882353,
      "grad_norm": 0.9796750545501709,
      "learning_rate": 7.302900326797386e-06,
      "loss": 0.0326,
      "step": 7462
    },
    {
      "epoch": 1.71484375,
      "grad_norm": 0.9215663075447083,
      "learning_rate": 7.302389705882353e-06,
      "loss": 0.0467,
      "step": 7463
    },
    {
      "epoch": 1.7150735294117647,
      "grad_norm": 0.7248759269714355,
      "learning_rate": 7.30187908496732e-06,
      "loss": 0.0269,
      "step": 7464
    },
    {
      "epoch": 1.7153033088235294,
      "grad_norm": 0.955220103263855,
      "learning_rate": 7.301368464052288e-06,
      "loss": 0.039,
      "step": 7465
    },
    {
      "epoch": 1.7155330882352942,
      "grad_norm": 1.084511160850525,
      "learning_rate": 7.300857843137255e-06,
      "loss": 0.0609,
      "step": 7466
    },
    {
      "epoch": 1.7157628676470589,
      "grad_norm": 0.8024485111236572,
      "learning_rate": 7.300347222222223e-06,
      "loss": 0.0454,
      "step": 7467
    },
    {
      "epoch": 1.7159926470588234,
      "grad_norm": 1.782222867012024,
      "learning_rate": 7.29983660130719e-06,
      "loss": 0.0822,
      "step": 7468
    },
    {
      "epoch": 1.7162224264705883,
      "grad_norm": 1.6452383995056152,
      "learning_rate": 7.299325980392158e-06,
      "loss": 0.0755,
      "step": 7469
    },
    {
      "epoch": 1.7164522058823528,
      "grad_norm": 0.882926881313324,
      "learning_rate": 7.298815359477125e-06,
      "loss": 0.0448,
      "step": 7470
    },
    {
      "epoch": 1.7166819852941178,
      "grad_norm": 0.9541612267494202,
      "learning_rate": 7.298304738562092e-06,
      "loss": 0.0639,
      "step": 7471
    },
    {
      "epoch": 1.7169117647058822,
      "grad_norm": 1.2482966184616089,
      "learning_rate": 7.297794117647059e-06,
      "loss": 0.0532,
      "step": 7472
    },
    {
      "epoch": 1.7171415441176472,
      "grad_norm": 0.9906070232391357,
      "learning_rate": 7.297283496732027e-06,
      "loss": 0.0577,
      "step": 7473
    },
    {
      "epoch": 1.7173713235294117,
      "grad_norm": 1.1104745864868164,
      "learning_rate": 7.296772875816994e-06,
      "loss": 0.0612,
      "step": 7474
    },
    {
      "epoch": 1.7176011029411766,
      "grad_norm": 1.0148054361343384,
      "learning_rate": 7.296262254901961e-06,
      "loss": 0.0441,
      "step": 7475
    },
    {
      "epoch": 1.7178308823529411,
      "grad_norm": 1.1598228216171265,
      "learning_rate": 7.295751633986928e-06,
      "loss": 0.0626,
      "step": 7476
    },
    {
      "epoch": 1.7180606617647058,
      "grad_norm": 0.9410905241966248,
      "learning_rate": 7.295241013071897e-06,
      "loss": 0.0376,
      "step": 7477
    },
    {
      "epoch": 1.7182904411764706,
      "grad_norm": 0.7202880382537842,
      "learning_rate": 7.294730392156864e-06,
      "loss": 0.0327,
      "step": 7478
    },
    {
      "epoch": 1.7185202205882353,
      "grad_norm": 0.9459569454193115,
      "learning_rate": 7.294219771241831e-06,
      "loss": 0.0548,
      "step": 7479
    },
    {
      "epoch": 1.71875,
      "grad_norm": 1.1536281108856201,
      "learning_rate": 7.293709150326798e-06,
      "loss": 0.071,
      "step": 7480
    },
    {
      "epoch": 1.7189797794117647,
      "grad_norm": 1.0951701402664185,
      "learning_rate": 7.2931985294117655e-06,
      "loss": 0.0521,
      "step": 7481
    },
    {
      "epoch": 1.7192095588235294,
      "grad_norm": 0.9751788377761841,
      "learning_rate": 7.2926879084967326e-06,
      "loss": 0.0667,
      "step": 7482
    },
    {
      "epoch": 1.7194393382352942,
      "grad_norm": 1.0610837936401367,
      "learning_rate": 7.2921772875817e-06,
      "loss": 0.0501,
      "step": 7483
    },
    {
      "epoch": 1.7196691176470589,
      "grad_norm": 1.223612904548645,
      "learning_rate": 7.291666666666667e-06,
      "loss": 0.046,
      "step": 7484
    },
    {
      "epoch": 1.7198988970588234,
      "grad_norm": 0.8364991545677185,
      "learning_rate": 7.291156045751635e-06,
      "loss": 0.0503,
      "step": 7485
    },
    {
      "epoch": 1.7201286764705883,
      "grad_norm": 1.2291618585586548,
      "learning_rate": 7.290645424836602e-06,
      "loss": 0.0794,
      "step": 7486
    },
    {
      "epoch": 1.7203584558823528,
      "grad_norm": 0.9361007213592529,
      "learning_rate": 7.290134803921569e-06,
      "loss": 0.0605,
      "step": 7487
    },
    {
      "epoch": 1.7205882352941178,
      "grad_norm": 0.7100756764411926,
      "learning_rate": 7.289624183006536e-06,
      "loss": 0.0312,
      "step": 7488
    },
    {
      "epoch": 1.7208180147058822,
      "grad_norm": 1.8538092374801636,
      "learning_rate": 7.289113562091504e-06,
      "loss": 0.03,
      "step": 7489
    },
    {
      "epoch": 1.7210477941176472,
      "grad_norm": 0.8211644887924194,
      "learning_rate": 7.288602941176471e-06,
      "loss": 0.0353,
      "step": 7490
    },
    {
      "epoch": 1.7212775735294117,
      "grad_norm": 1.156340479850769,
      "learning_rate": 7.288092320261438e-06,
      "loss": 0.0606,
      "step": 7491
    },
    {
      "epoch": 1.7215073529411766,
      "grad_norm": 0.6924964189529419,
      "learning_rate": 7.287581699346405e-06,
      "loss": 0.0426,
      "step": 7492
    },
    {
      "epoch": 1.7217371323529411,
      "grad_norm": 0.9281263947486877,
      "learning_rate": 7.287071078431374e-06,
      "loss": 0.0442,
      "step": 7493
    },
    {
      "epoch": 1.7219669117647058,
      "grad_norm": 0.8723336458206177,
      "learning_rate": 7.286560457516341e-06,
      "loss": 0.0451,
      "step": 7494
    },
    {
      "epoch": 1.7221966911764706,
      "grad_norm": 0.9615016579627991,
      "learning_rate": 7.286049836601308e-06,
      "loss": 0.0371,
      "step": 7495
    },
    {
      "epoch": 1.7224264705882353,
      "grad_norm": 0.9497315287590027,
      "learning_rate": 7.285539215686275e-06,
      "loss": 0.0525,
      "step": 7496
    },
    {
      "epoch": 1.72265625,
      "grad_norm": 0.9389328956604004,
      "learning_rate": 7.285028594771243e-06,
      "loss": 0.0517,
      "step": 7497
    },
    {
      "epoch": 1.7228860294117647,
      "grad_norm": 1.032463788986206,
      "learning_rate": 7.28451797385621e-06,
      "loss": 0.0492,
      "step": 7498
    },
    {
      "epoch": 1.7231158088235294,
      "grad_norm": 1.2286648750305176,
      "learning_rate": 7.284007352941177e-06,
      "loss": 0.0543,
      "step": 7499
    },
    {
      "epoch": 1.7233455882352942,
      "grad_norm": 1.03581964969635,
      "learning_rate": 7.283496732026144e-06,
      "loss": 0.0394,
      "step": 7500
    },
    {
      "epoch": 1.7233455882352942,
      "eval_loss": 0.05231141299009323,
      "eval_runtime": 2007.1972,
      "eval_samples_per_second": 4.437,
      "eval_steps_per_second": 2.219,
      "step": 7500
    },
    {
      "epoch": 1.7235753676470589,
      "grad_norm": 0.9676276445388794,
      "learning_rate": 7.282986111111113e-06,
      "loss": 0.039,
      "step": 7501
    },
    {
      "epoch": 1.7238051470588234,
      "grad_norm": 0.961736798286438,
      "learning_rate": 7.28247549019608e-06,
      "loss": 0.0426,
      "step": 7502
    },
    {
      "epoch": 1.7240349264705883,
      "grad_norm": 1.1830854415893555,
      "learning_rate": 7.281964869281047e-06,
      "loss": 0.0543,
      "step": 7503
    },
    {
      "epoch": 1.7242647058823528,
      "grad_norm": 1.549003005027771,
      "learning_rate": 7.281454248366014e-06,
      "loss": 0.0516,
      "step": 7504
    },
    {
      "epoch": 1.7244944852941178,
      "grad_norm": 1.1559727191925049,
      "learning_rate": 7.2809436274509815e-06,
      "loss": 0.0625,
      "step": 7505
    },
    {
      "epoch": 1.7247242647058822,
      "grad_norm": 0.9949100017547607,
      "learning_rate": 7.2804330065359485e-06,
      "loss": 0.0472,
      "step": 7506
    },
    {
      "epoch": 1.7249540441176472,
      "grad_norm": 1.2305302619934082,
      "learning_rate": 7.2799223856209155e-06,
      "loss": 0.0682,
      "step": 7507
    },
    {
      "epoch": 1.7251838235294117,
      "grad_norm": 0.9760327339172363,
      "learning_rate": 7.2794117647058826e-06,
      "loss": 0.0288,
      "step": 7508
    },
    {
      "epoch": 1.7254136029411766,
      "grad_norm": 0.7273533940315247,
      "learning_rate": 7.2789011437908504e-06,
      "loss": 0.0382,
      "step": 7509
    },
    {
      "epoch": 1.7256433823529411,
      "grad_norm": 0.8692241311073303,
      "learning_rate": 7.2783905228758174e-06,
      "loss": 0.052,
      "step": 7510
    },
    {
      "epoch": 1.7258731617647058,
      "grad_norm": 0.6823932528495789,
      "learning_rate": 7.2778799019607845e-06,
      "loss": 0.04,
      "step": 7511
    },
    {
      "epoch": 1.7261029411764706,
      "grad_norm": 1.4838449954986572,
      "learning_rate": 7.277369281045752e-06,
      "loss": 0.0686,
      "step": 7512
    },
    {
      "epoch": 1.7263327205882353,
      "grad_norm": 0.9667273759841919,
      "learning_rate": 7.27685866013072e-06,
      "loss": 0.0528,
      "step": 7513
    },
    {
      "epoch": 1.7265625,
      "grad_norm": 1.179256558418274,
      "learning_rate": 7.276348039215687e-06,
      "loss": 0.0593,
      "step": 7514
    },
    {
      "epoch": 1.7267922794117647,
      "grad_norm": 1.118925929069519,
      "learning_rate": 7.275837418300654e-06,
      "loss": 0.0505,
      "step": 7515
    },
    {
      "epoch": 1.7270220588235294,
      "grad_norm": 1.116050124168396,
      "learning_rate": 7.275326797385621e-06,
      "loss": 0.0569,
      "step": 7516
    },
    {
      "epoch": 1.7272518382352942,
      "grad_norm": 0.8198732137680054,
      "learning_rate": 7.274816176470589e-06,
      "loss": 0.0561,
      "step": 7517
    },
    {
      "epoch": 1.7274816176470589,
      "grad_norm": 0.8527036309242249,
      "learning_rate": 7.274305555555556e-06,
      "loss": 0.0354,
      "step": 7518
    },
    {
      "epoch": 1.7277113970588234,
      "grad_norm": 0.8172510862350464,
      "learning_rate": 7.273794934640523e-06,
      "loss": 0.0396,
      "step": 7519
    },
    {
      "epoch": 1.7279411764705883,
      "grad_norm": 0.8326176404953003,
      "learning_rate": 7.27328431372549e-06,
      "loss": 0.0257,
      "step": 7520
    },
    {
      "epoch": 1.7281709558823528,
      "grad_norm": 0.9557434320449829,
      "learning_rate": 7.272773692810459e-06,
      "loss": 0.0517,
      "step": 7521
    },
    {
      "epoch": 1.7284007352941178,
      "grad_norm": 1.239830732345581,
      "learning_rate": 7.272263071895426e-06,
      "loss": 0.0587,
      "step": 7522
    },
    {
      "epoch": 1.7286305147058822,
      "grad_norm": 1.089174747467041,
      "learning_rate": 7.271752450980393e-06,
      "loss": 0.0556,
      "step": 7523
    },
    {
      "epoch": 1.7288602941176472,
      "grad_norm": 0.6560631394386292,
      "learning_rate": 7.27124183006536e-06,
      "loss": 0.0347,
      "step": 7524
    },
    {
      "epoch": 1.7290900735294117,
      "grad_norm": 0.8550841212272644,
      "learning_rate": 7.270731209150328e-06,
      "loss": 0.0543,
      "step": 7525
    },
    {
      "epoch": 1.7293198529411766,
      "grad_norm": 0.7834793925285339,
      "learning_rate": 7.270220588235295e-06,
      "loss": 0.0482,
      "step": 7526
    },
    {
      "epoch": 1.7295496323529411,
      "grad_norm": 1.128113865852356,
      "learning_rate": 7.269709967320262e-06,
      "loss": 0.0673,
      "step": 7527
    },
    {
      "epoch": 1.7297794117647058,
      "grad_norm": 1.1892009973526,
      "learning_rate": 7.269199346405229e-06,
      "loss": 0.0496,
      "step": 7528
    },
    {
      "epoch": 1.7300091911764706,
      "grad_norm": 0.846511721611023,
      "learning_rate": 7.2686887254901975e-06,
      "loss": 0.0338,
      "step": 7529
    },
    {
      "epoch": 1.7302389705882353,
      "grad_norm": 1.0446478128433228,
      "learning_rate": 7.2681781045751645e-06,
      "loss": 0.055,
      "step": 7530
    },
    {
      "epoch": 1.73046875,
      "grad_norm": 0.9090134501457214,
      "learning_rate": 7.2676674836601315e-06,
      "loss": 0.0448,
      "step": 7531
    },
    {
      "epoch": 1.7306985294117647,
      "grad_norm": 0.9758188724517822,
      "learning_rate": 7.2671568627450985e-06,
      "loss": 0.0465,
      "step": 7532
    },
    {
      "epoch": 1.7309283088235294,
      "grad_norm": 1.0612599849700928,
      "learning_rate": 7.266646241830066e-06,
      "loss": 0.056,
      "step": 7533
    },
    {
      "epoch": 1.7311580882352942,
      "grad_norm": 1.425958275794983,
      "learning_rate": 7.266135620915033e-06,
      "loss": 0.0555,
      "step": 7534
    },
    {
      "epoch": 1.7313878676470589,
      "grad_norm": 1.1211755275726318,
      "learning_rate": 7.265625e-06,
      "loss": 0.0538,
      "step": 7535
    },
    {
      "epoch": 1.7316176470588234,
      "grad_norm": 1.6789391040802002,
      "learning_rate": 7.2651143790849674e-06,
      "loss": 0.0659,
      "step": 7536
    },
    {
      "epoch": 1.7318474264705883,
      "grad_norm": 0.8258817195892334,
      "learning_rate": 7.2646037581699345e-06,
      "loss": 0.0524,
      "step": 7537
    },
    {
      "epoch": 1.7320772058823528,
      "grad_norm": 0.7676895260810852,
      "learning_rate": 7.264093137254903e-06,
      "loss": 0.0246,
      "step": 7538
    },
    {
      "epoch": 1.7323069852941178,
      "grad_norm": 1.0257874727249146,
      "learning_rate": 7.26358251633987e-06,
      "loss": 0.0468,
      "step": 7539
    },
    {
      "epoch": 1.7325367647058822,
      "grad_norm": 0.937702476978302,
      "learning_rate": 7.263071895424837e-06,
      "loss": 0.0531,
      "step": 7540
    },
    {
      "epoch": 1.7327665441176472,
      "grad_norm": 1.1526039838790894,
      "learning_rate": 7.262561274509804e-06,
      "loss": 0.07,
      "step": 7541
    },
    {
      "epoch": 1.7329963235294117,
      "grad_norm": 0.7990901470184326,
      "learning_rate": 7.262050653594772e-06,
      "loss": 0.0471,
      "step": 7542
    },
    {
      "epoch": 1.7332261029411766,
      "grad_norm": 0.6655641198158264,
      "learning_rate": 7.261540032679739e-06,
      "loss": 0.0313,
      "step": 7543
    },
    {
      "epoch": 1.7334558823529411,
      "grad_norm": 1.0622146129608154,
      "learning_rate": 7.261029411764706e-06,
      "loss": 0.047,
      "step": 7544
    },
    {
      "epoch": 1.7336856617647058,
      "grad_norm": 1.0169650316238403,
      "learning_rate": 7.260518790849673e-06,
      "loss": 0.048,
      "step": 7545
    },
    {
      "epoch": 1.7339154411764706,
      "grad_norm": 1.0390448570251465,
      "learning_rate": 7.260008169934642e-06,
      "loss": 0.0426,
      "step": 7546
    },
    {
      "epoch": 1.7341452205882353,
      "grad_norm": 0.8462247848510742,
      "learning_rate": 7.259497549019609e-06,
      "loss": 0.0377,
      "step": 7547
    },
    {
      "epoch": 1.734375,
      "grad_norm": 0.8004112243652344,
      "learning_rate": 7.258986928104576e-06,
      "loss": 0.0427,
      "step": 7548
    },
    {
      "epoch": 1.7346047794117647,
      "grad_norm": 1.2679595947265625,
      "learning_rate": 7.258476307189543e-06,
      "loss": 0.0607,
      "step": 7549
    },
    {
      "epoch": 1.7348345588235294,
      "grad_norm": 0.7869248986244202,
      "learning_rate": 7.257965686274511e-06,
      "loss": 0.0441,
      "step": 7550
    },
    {
      "epoch": 1.7350643382352942,
      "grad_norm": 1.263742446899414,
      "learning_rate": 7.257455065359478e-06,
      "loss": 0.0442,
      "step": 7551
    },
    {
      "epoch": 1.7352941176470589,
      "grad_norm": 0.84471595287323,
      "learning_rate": 7.256944444444445e-06,
      "loss": 0.0382,
      "step": 7552
    },
    {
      "epoch": 1.7355238970588234,
      "grad_norm": 1.076266884803772,
      "learning_rate": 7.256433823529412e-06,
      "loss": 0.0405,
      "step": 7553
    },
    {
      "epoch": 1.7357536764705883,
      "grad_norm": 0.9518455862998962,
      "learning_rate": 7.25592320261438e-06,
      "loss": 0.0565,
      "step": 7554
    },
    {
      "epoch": 1.7359834558823528,
      "grad_norm": 0.9199830293655396,
      "learning_rate": 7.255412581699347e-06,
      "loss": 0.0375,
      "step": 7555
    },
    {
      "epoch": 1.7362132352941178,
      "grad_norm": 0.6201345920562744,
      "learning_rate": 7.2549019607843145e-06,
      "loss": 0.0247,
      "step": 7556
    },
    {
      "epoch": 1.7364430147058822,
      "grad_norm": 1.1996080875396729,
      "learning_rate": 7.2543913398692815e-06,
      "loss": 0.0649,
      "step": 7557
    },
    {
      "epoch": 1.7366727941176472,
      "grad_norm": 1.3532871007919312,
      "learning_rate": 7.253880718954249e-06,
      "loss": 0.0906,
      "step": 7558
    },
    {
      "epoch": 1.7369025735294117,
      "grad_norm": 2.3624634742736816,
      "learning_rate": 7.253370098039216e-06,
      "loss": 0.0303,
      "step": 7559
    },
    {
      "epoch": 1.7371323529411766,
      "grad_norm": 1.230912208557129,
      "learning_rate": 7.252859477124183e-06,
      "loss": 0.05,
      "step": 7560
    },
    {
      "epoch": 1.7373621323529411,
      "grad_norm": 1.1777292490005493,
      "learning_rate": 7.25234885620915e-06,
      "loss": 0.0588,
      "step": 7561
    },
    {
      "epoch": 1.7375919117647058,
      "grad_norm": 0.9781641960144043,
      "learning_rate": 7.251838235294118e-06,
      "loss": 0.0354,
      "step": 7562
    },
    {
      "epoch": 1.7378216911764706,
      "grad_norm": 1.1128361225128174,
      "learning_rate": 7.251327614379085e-06,
      "loss": 0.0718,
      "step": 7563
    },
    {
      "epoch": 1.7380514705882353,
      "grad_norm": 0.7615147829055786,
      "learning_rate": 7.250816993464052e-06,
      "loss": 0.0235,
      "step": 7564
    },
    {
      "epoch": 1.73828125,
      "grad_norm": 1.0771772861480713,
      "learning_rate": 7.250306372549019e-06,
      "loss": 0.0504,
      "step": 7565
    },
    {
      "epoch": 1.7385110294117647,
      "grad_norm": 1.136704444885254,
      "learning_rate": 7.249795751633988e-06,
      "loss": 0.0761,
      "step": 7566
    },
    {
      "epoch": 1.7387408088235294,
      "grad_norm": 0.9992595314979553,
      "learning_rate": 7.249285130718955e-06,
      "loss": 0.0436,
      "step": 7567
    },
    {
      "epoch": 1.7389705882352942,
      "grad_norm": 0.670329749584198,
      "learning_rate": 7.248774509803922e-06,
      "loss": 0.0315,
      "step": 7568
    },
    {
      "epoch": 1.7392003676470589,
      "grad_norm": 0.9546461701393127,
      "learning_rate": 7.248263888888889e-06,
      "loss": 0.0461,
      "step": 7569
    },
    {
      "epoch": 1.7394301470588234,
      "grad_norm": 1.087765097618103,
      "learning_rate": 7.247753267973857e-06,
      "loss": 0.0598,
      "step": 7570
    },
    {
      "epoch": 1.7396599264705883,
      "grad_norm": 0.7988792061805725,
      "learning_rate": 7.247242647058824e-06,
      "loss": 0.0408,
      "step": 7571
    },
    {
      "epoch": 1.7398897058823528,
      "grad_norm": 1.0176395177841187,
      "learning_rate": 7.246732026143791e-06,
      "loss": 0.044,
      "step": 7572
    },
    {
      "epoch": 1.7401194852941178,
      "grad_norm": 1.4839887619018555,
      "learning_rate": 7.246221405228758e-06,
      "loss": 0.0449,
      "step": 7573
    },
    {
      "epoch": 1.7403492647058822,
      "grad_norm": 1.0988045930862427,
      "learning_rate": 7.245710784313727e-06,
      "loss": 0.0507,
      "step": 7574
    },
    {
      "epoch": 1.7405790441176472,
      "grad_norm": 1.359381079673767,
      "learning_rate": 7.245200163398694e-06,
      "loss": 0.0495,
      "step": 7575
    },
    {
      "epoch": 1.7408088235294117,
      "grad_norm": 1.0111037492752075,
      "learning_rate": 7.244689542483661e-06,
      "loss": 0.052,
      "step": 7576
    },
    {
      "epoch": 1.7410386029411766,
      "grad_norm": 0.7619055509567261,
      "learning_rate": 7.244178921568628e-06,
      "loss": 0.0546,
      "step": 7577
    },
    {
      "epoch": 1.7412683823529411,
      "grad_norm": 1.134434700012207,
      "learning_rate": 7.243668300653596e-06,
      "loss": 0.0504,
      "step": 7578
    },
    {
      "epoch": 1.7414981617647058,
      "grad_norm": 0.9632502794265747,
      "learning_rate": 7.243157679738563e-06,
      "loss": 0.0392,
      "step": 7579
    },
    {
      "epoch": 1.7417279411764706,
      "grad_norm": 0.9995555877685547,
      "learning_rate": 7.24264705882353e-06,
      "loss": 0.0446,
      "step": 7580
    },
    {
      "epoch": 1.7419577205882353,
      "grad_norm": 1.3249822854995728,
      "learning_rate": 7.242136437908497e-06,
      "loss": 0.0717,
      "step": 7581
    },
    {
      "epoch": 1.7421875,
      "grad_norm": 1.2324570417404175,
      "learning_rate": 7.241625816993465e-06,
      "loss": 0.0461,
      "step": 7582
    },
    {
      "epoch": 1.7424172794117647,
      "grad_norm": 1.344618558883667,
      "learning_rate": 7.241115196078432e-06,
      "loss": 0.0735,
      "step": 7583
    },
    {
      "epoch": 1.7426470588235294,
      "grad_norm": 1.2544362545013428,
      "learning_rate": 7.240604575163399e-06,
      "loss": 0.0598,
      "step": 7584
    },
    {
      "epoch": 1.7428768382352942,
      "grad_norm": 1.204868197441101,
      "learning_rate": 7.240093954248366e-06,
      "loss": 0.0636,
      "step": 7585
    },
    {
      "epoch": 1.7431066176470589,
      "grad_norm": 0.8433390855789185,
      "learning_rate": 7.239583333333334e-06,
      "loss": 0.042,
      "step": 7586
    },
    {
      "epoch": 1.7433363970588234,
      "grad_norm": 1.0417252779006958,
      "learning_rate": 7.239072712418301e-06,
      "loss": 0.0419,
      "step": 7587
    },
    {
      "epoch": 1.7435661764705883,
      "grad_norm": 0.8527122735977173,
      "learning_rate": 7.238562091503268e-06,
      "loss": 0.0587,
      "step": 7588
    },
    {
      "epoch": 1.7437959558823528,
      "grad_norm": 1.1929606199264526,
      "learning_rate": 7.238051470588235e-06,
      "loss": 0.0578,
      "step": 7589
    },
    {
      "epoch": 1.7440257352941178,
      "grad_norm": 0.8328105211257935,
      "learning_rate": 7.237540849673204e-06,
      "loss": 0.0542,
      "step": 7590
    },
    {
      "epoch": 1.7442555147058822,
      "grad_norm": 1.211456537246704,
      "learning_rate": 7.237030228758171e-06,
      "loss": 0.0589,
      "step": 7591
    },
    {
      "epoch": 1.7444852941176472,
      "grad_norm": 0.9781612753868103,
      "learning_rate": 7.236519607843138e-06,
      "loss": 0.0663,
      "step": 7592
    },
    {
      "epoch": 1.7447150735294117,
      "grad_norm": 0.9334914684295654,
      "learning_rate": 7.236008986928105e-06,
      "loss": 0.0652,
      "step": 7593
    },
    {
      "epoch": 1.7449448529411766,
      "grad_norm": 1.0371135473251343,
      "learning_rate": 7.235498366013073e-06,
      "loss": 0.0611,
      "step": 7594
    },
    {
      "epoch": 1.7451746323529411,
      "grad_norm": 1.0337148904800415,
      "learning_rate": 7.23498774509804e-06,
      "loss": 0.0375,
      "step": 7595
    },
    {
      "epoch": 1.7454044117647058,
      "grad_norm": 0.8804577589035034,
      "learning_rate": 7.234477124183007e-06,
      "loss": 0.0595,
      "step": 7596
    },
    {
      "epoch": 1.7456341911764706,
      "grad_norm": 0.9926454424858093,
      "learning_rate": 7.233966503267974e-06,
      "loss": 0.0462,
      "step": 7597
    },
    {
      "epoch": 1.7458639705882353,
      "grad_norm": 1.3532524108886719,
      "learning_rate": 7.233455882352942e-06,
      "loss": 0.0609,
      "step": 7598
    },
    {
      "epoch": 1.74609375,
      "grad_norm": 0.8864729404449463,
      "learning_rate": 7.232945261437909e-06,
      "loss": 0.0455,
      "step": 7599
    },
    {
      "epoch": 1.7463235294117647,
      "grad_norm": 1.6709798574447632,
      "learning_rate": 7.232434640522876e-06,
      "loss": 0.0554,
      "step": 7600
    },
    {
      "epoch": 1.7465533088235294,
      "grad_norm": 1.2852425575256348,
      "learning_rate": 7.231924019607844e-06,
      "loss": 0.0498,
      "step": 7601
    },
    {
      "epoch": 1.7467830882352942,
      "grad_norm": 0.982149064540863,
      "learning_rate": 7.2314133986928116e-06,
      "loss": 0.0681,
      "step": 7602
    },
    {
      "epoch": 1.7470128676470589,
      "grad_norm": 1.039892554283142,
      "learning_rate": 7.230902777777779e-06,
      "loss": 0.0612,
      "step": 7603
    },
    {
      "epoch": 1.7472426470588234,
      "grad_norm": 1.0161044597625732,
      "learning_rate": 7.230392156862746e-06,
      "loss": 0.0567,
      "step": 7604
    },
    {
      "epoch": 1.7474724264705883,
      "grad_norm": 0.8531635999679565,
      "learning_rate": 7.229881535947713e-06,
      "loss": 0.0311,
      "step": 7605
    },
    {
      "epoch": 1.7477022058823528,
      "grad_norm": 0.6770161986351013,
      "learning_rate": 7.2293709150326805e-06,
      "loss": 0.0322,
      "step": 7606
    },
    {
      "epoch": 1.7479319852941178,
      "grad_norm": 1.082568883895874,
      "learning_rate": 7.2288602941176475e-06,
      "loss": 0.0495,
      "step": 7607
    },
    {
      "epoch": 1.7481617647058822,
      "grad_norm": 0.9775773286819458,
      "learning_rate": 7.2283496732026145e-06,
      "loss": 0.0537,
      "step": 7608
    },
    {
      "epoch": 1.7483915441176472,
      "grad_norm": 1.480108618736267,
      "learning_rate": 7.2278390522875815e-06,
      "loss": 0.0448,
      "step": 7609
    },
    {
      "epoch": 1.7486213235294117,
      "grad_norm": 0.6979289650917053,
      "learning_rate": 7.22732843137255e-06,
      "loss": 0.0435,
      "step": 7610
    },
    {
      "epoch": 1.7488511029411766,
      "grad_norm": 0.8164833188056946,
      "learning_rate": 7.226817810457517e-06,
      "loss": 0.0495,
      "step": 7611
    },
    {
      "epoch": 1.7490808823529411,
      "grad_norm": 0.9409163594245911,
      "learning_rate": 7.226307189542484e-06,
      "loss": 0.0364,
      "step": 7612
    },
    {
      "epoch": 1.7493106617647058,
      "grad_norm": 1.2133046388626099,
      "learning_rate": 7.225796568627451e-06,
      "loss": 0.0483,
      "step": 7613
    },
    {
      "epoch": 1.7495404411764706,
      "grad_norm": 0.9390961527824402,
      "learning_rate": 7.225285947712419e-06,
      "loss": 0.0342,
      "step": 7614
    },
    {
      "epoch": 1.7497702205882353,
      "grad_norm": 0.8574036359786987,
      "learning_rate": 7.224775326797386e-06,
      "loss": 0.0495,
      "step": 7615
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.7890883684158325,
      "learning_rate": 7.224264705882353e-06,
      "loss": 0.0425,
      "step": 7616
    },
    {
      "epoch": 1.7502297794117647,
      "grad_norm": 1.0134857892990112,
      "learning_rate": 7.22375408496732e-06,
      "loss": 0.056,
      "step": 7617
    },
    {
      "epoch": 1.7504595588235294,
      "grad_norm": 0.9376396536827087,
      "learning_rate": 7.223243464052289e-06,
      "loss": 0.0381,
      "step": 7618
    },
    {
      "epoch": 1.7506893382352942,
      "grad_norm": 1.2065736055374146,
      "learning_rate": 7.222732843137256e-06,
      "loss": 0.0696,
      "step": 7619
    },
    {
      "epoch": 1.7509191176470589,
      "grad_norm": 1.0648270845413208,
      "learning_rate": 7.222222222222223e-06,
      "loss": 0.05,
      "step": 7620
    },
    {
      "epoch": 1.7511488970588234,
      "grad_norm": 1.085931420326233,
      "learning_rate": 7.22171160130719e-06,
      "loss": 0.0488,
      "step": 7621
    },
    {
      "epoch": 1.7513786764705883,
      "grad_norm": 0.8665562272071838,
      "learning_rate": 7.221200980392158e-06,
      "loss": 0.0585,
      "step": 7622
    },
    {
      "epoch": 1.7516084558823528,
      "grad_norm": 0.6385238170623779,
      "learning_rate": 7.220690359477125e-06,
      "loss": 0.0368,
      "step": 7623
    },
    {
      "epoch": 1.7518382352941178,
      "grad_norm": 0.9125567078590393,
      "learning_rate": 7.220179738562092e-06,
      "loss": 0.0556,
      "step": 7624
    },
    {
      "epoch": 1.7520680147058822,
      "grad_norm": 1.2365952730178833,
      "learning_rate": 7.219669117647059e-06,
      "loss": 0.048,
      "step": 7625
    },
    {
      "epoch": 1.7522977941176472,
      "grad_norm": 2.0489182472229004,
      "learning_rate": 7.2191584967320275e-06,
      "loss": 0.057,
      "step": 7626
    },
    {
      "epoch": 1.7525275735294117,
      "grad_norm": 0.7058895826339722,
      "learning_rate": 7.2186478758169945e-06,
      "loss": 0.0398,
      "step": 7627
    },
    {
      "epoch": 1.7527573529411766,
      "grad_norm": 0.8261375427246094,
      "learning_rate": 7.2181372549019616e-06,
      "loss": 0.0365,
      "step": 7628
    },
    {
      "epoch": 1.7529871323529411,
      "grad_norm": 1.3063344955444336,
      "learning_rate": 7.217626633986929e-06,
      "loss": 0.0605,
      "step": 7629
    },
    {
      "epoch": 1.7532169117647058,
      "grad_norm": 1.0540522336959839,
      "learning_rate": 7.2171160130718964e-06,
      "loss": 0.0682,
      "step": 7630
    },
    {
      "epoch": 1.7534466911764706,
      "grad_norm": 0.7142875790596008,
      "learning_rate": 7.2166053921568635e-06,
      "loss": 0.0325,
      "step": 7631
    },
    {
      "epoch": 1.7536764705882353,
      "grad_norm": 0.8154528141021729,
      "learning_rate": 7.2160947712418305e-06,
      "loss": 0.0448,
      "step": 7632
    },
    {
      "epoch": 1.75390625,
      "grad_norm": 1.0838505029678345,
      "learning_rate": 7.2155841503267975e-06,
      "loss": 0.0295,
      "step": 7633
    },
    {
      "epoch": 1.7541360294117647,
      "grad_norm": 1.31330144405365,
      "learning_rate": 7.215073529411765e-06,
      "loss": 0.0583,
      "step": 7634
    },
    {
      "epoch": 1.7543658088235294,
      "grad_norm": 0.8758246898651123,
      "learning_rate": 7.214562908496733e-06,
      "loss": 0.0511,
      "step": 7635
    },
    {
      "epoch": 1.7545955882352942,
      "grad_norm": 0.9537434577941895,
      "learning_rate": 7.2140522875817e-06,
      "loss": 0.0292,
      "step": 7636
    },
    {
      "epoch": 1.7548253676470589,
      "grad_norm": 0.7594738006591797,
      "learning_rate": 7.213541666666667e-06,
      "loss": 0.0321,
      "step": 7637
    },
    {
      "epoch": 1.7550551470588234,
      "grad_norm": 1.153271198272705,
      "learning_rate": 7.213031045751635e-06,
      "loss": 0.0531,
      "step": 7638
    },
    {
      "epoch": 1.7552849264705883,
      "grad_norm": 1.1993621587753296,
      "learning_rate": 7.212520424836602e-06,
      "loss": 0.054,
      "step": 7639
    },
    {
      "epoch": 1.7555147058823528,
      "grad_norm": 0.8929604291915894,
      "learning_rate": 7.212009803921569e-06,
      "loss": 0.0368,
      "step": 7640
    },
    {
      "epoch": 1.7557444852941178,
      "grad_norm": 1.424939513206482,
      "learning_rate": 7.211499183006536e-06,
      "loss": 0.0707,
      "step": 7641
    },
    {
      "epoch": 1.7559742647058822,
      "grad_norm": 1.239047646522522,
      "learning_rate": 7.210988562091504e-06,
      "loss": 0.0594,
      "step": 7642
    },
    {
      "epoch": 1.7562040441176472,
      "grad_norm": 0.9116916656494141,
      "learning_rate": 7.210477941176471e-06,
      "loss": 0.0376,
      "step": 7643
    },
    {
      "epoch": 1.7564338235294117,
      "grad_norm": 1.032727837562561,
      "learning_rate": 7.209967320261438e-06,
      "loss": 0.0526,
      "step": 7644
    },
    {
      "epoch": 1.7566636029411766,
      "grad_norm": 0.7078801989555359,
      "learning_rate": 7.209456699346405e-06,
      "loss": 0.0282,
      "step": 7645
    },
    {
      "epoch": 1.7568933823529411,
      "grad_norm": 1.289717435836792,
      "learning_rate": 7.208946078431374e-06,
      "loss": 0.0372,
      "step": 7646
    },
    {
      "epoch": 1.7571231617647058,
      "grad_norm": 1.030068039894104,
      "learning_rate": 7.208435457516341e-06,
      "loss": 0.0473,
      "step": 7647
    },
    {
      "epoch": 1.7573529411764706,
      "grad_norm": 0.7561917901039124,
      "learning_rate": 7.207924836601308e-06,
      "loss": 0.0261,
      "step": 7648
    },
    {
      "epoch": 1.7575827205882353,
      "grad_norm": 0.85179203748703,
      "learning_rate": 7.207414215686275e-06,
      "loss": 0.0441,
      "step": 7649
    },
    {
      "epoch": 1.7578125,
      "grad_norm": 0.78482586145401,
      "learning_rate": 7.206903594771243e-06,
      "loss": 0.0392,
      "step": 7650
    },
    {
      "epoch": 1.7580422794117647,
      "grad_norm": 0.7495129108428955,
      "learning_rate": 7.20639297385621e-06,
      "loss": 0.0457,
      "step": 7651
    },
    {
      "epoch": 1.7582720588235294,
      "grad_norm": 0.8885306715965271,
      "learning_rate": 7.205882352941177e-06,
      "loss": 0.0643,
      "step": 7652
    },
    {
      "epoch": 1.7585018382352942,
      "grad_norm": 0.7579072117805481,
      "learning_rate": 7.205371732026144e-06,
      "loss": 0.0211,
      "step": 7653
    },
    {
      "epoch": 1.7587316176470589,
      "grad_norm": 0.8182072043418884,
      "learning_rate": 7.204861111111112e-06,
      "loss": 0.0468,
      "step": 7654
    },
    {
      "epoch": 1.7589613970588234,
      "grad_norm": 0.8438873291015625,
      "learning_rate": 7.2043504901960794e-06,
      "loss": 0.0351,
      "step": 7655
    },
    {
      "epoch": 1.7591911764705883,
      "grad_norm": 0.9847033619880676,
      "learning_rate": 7.2038398692810464e-06,
      "loss": 0.0508,
      "step": 7656
    },
    {
      "epoch": 1.7594209558823528,
      "grad_norm": 1.05756676197052,
      "learning_rate": 7.2033292483660135e-06,
      "loss": 0.0726,
      "step": 7657
    },
    {
      "epoch": 1.7596507352941178,
      "grad_norm": 1.2704970836639404,
      "learning_rate": 7.202818627450981e-06,
      "loss": 0.0682,
      "step": 7658
    },
    {
      "epoch": 1.7598805147058822,
      "grad_norm": 1.0095924139022827,
      "learning_rate": 7.202308006535948e-06,
      "loss": 0.0448,
      "step": 7659
    },
    {
      "epoch": 1.7601102941176472,
      "grad_norm": 0.8330880999565125,
      "learning_rate": 7.201797385620915e-06,
      "loss": 0.0416,
      "step": 7660
    },
    {
      "epoch": 1.7603400735294117,
      "grad_norm": 1.6457613706588745,
      "learning_rate": 7.201286764705882e-06,
      "loss": 0.1157,
      "step": 7661
    },
    {
      "epoch": 1.7605698529411766,
      "grad_norm": 1.2686303853988647,
      "learning_rate": 7.200776143790851e-06,
      "loss": 0.0654,
      "step": 7662
    },
    {
      "epoch": 1.7607996323529411,
      "grad_norm": 1.2907943725585938,
      "learning_rate": 7.200265522875818e-06,
      "loss": 0.0598,
      "step": 7663
    },
    {
      "epoch": 1.7610294117647058,
      "grad_norm": 0.972283661365509,
      "learning_rate": 7.199754901960785e-06,
      "loss": 0.046,
      "step": 7664
    },
    {
      "epoch": 1.7612591911764706,
      "grad_norm": 1.0217258930206299,
      "learning_rate": 7.199244281045752e-06,
      "loss": 0.0569,
      "step": 7665
    },
    {
      "epoch": 1.7614889705882353,
      "grad_norm": 0.9390968680381775,
      "learning_rate": 7.19873366013072e-06,
      "loss": 0.0518,
      "step": 7666
    },
    {
      "epoch": 1.76171875,
      "grad_norm": 1.1560094356536865,
      "learning_rate": 7.198223039215687e-06,
      "loss": 0.037,
      "step": 7667
    },
    {
      "epoch": 1.7619485294117647,
      "grad_norm": 0.858981192111969,
      "learning_rate": 7.197712418300654e-06,
      "loss": 0.0439,
      "step": 7668
    },
    {
      "epoch": 1.7621783088235294,
      "grad_norm": 1.1573430299758911,
      "learning_rate": 7.197201797385621e-06,
      "loss": 0.0607,
      "step": 7669
    },
    {
      "epoch": 1.7624080882352942,
      "grad_norm": 0.8435673713684082,
      "learning_rate": 7.19669117647059e-06,
      "loss": 0.0385,
      "step": 7670
    },
    {
      "epoch": 1.7626378676470589,
      "grad_norm": 0.7904473543167114,
      "learning_rate": 7.196180555555557e-06,
      "loss": 0.028,
      "step": 7671
    },
    {
      "epoch": 1.7628676470588234,
      "grad_norm": 0.8811760544776917,
      "learning_rate": 7.195669934640524e-06,
      "loss": 0.0421,
      "step": 7672
    },
    {
      "epoch": 1.7630974264705883,
      "grad_norm": 1.1996713876724243,
      "learning_rate": 7.195159313725491e-06,
      "loss": 0.0454,
      "step": 7673
    },
    {
      "epoch": 1.7633272058823528,
      "grad_norm": 1.2734131813049316,
      "learning_rate": 7.194648692810459e-06,
      "loss": 0.0723,
      "step": 7674
    },
    {
      "epoch": 1.7635569852941178,
      "grad_norm": 0.8387269973754883,
      "learning_rate": 7.194138071895426e-06,
      "loss": 0.0411,
      "step": 7675
    },
    {
      "epoch": 1.7637867647058822,
      "grad_norm": 0.8606172800064087,
      "learning_rate": 7.193627450980393e-06,
      "loss": 0.0547,
      "step": 7676
    },
    {
      "epoch": 1.7640165441176472,
      "grad_norm": 0.8546661138534546,
      "learning_rate": 7.19311683006536e-06,
      "loss": 0.0505,
      "step": 7677
    },
    {
      "epoch": 1.7642463235294117,
      "grad_norm": 0.7043157815933228,
      "learning_rate": 7.1926062091503275e-06,
      "loss": 0.0364,
      "step": 7678
    },
    {
      "epoch": 1.7644761029411766,
      "grad_norm": 1.0703349113464355,
      "learning_rate": 7.1920955882352945e-06,
      "loss": 0.0399,
      "step": 7679
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 1.241443395614624,
      "learning_rate": 7.191584967320262e-06,
      "loss": 0.0581,
      "step": 7680
    },
    {
      "epoch": 1.7649356617647058,
      "grad_norm": 0.9316357970237732,
      "learning_rate": 7.191074346405229e-06,
      "loss": 0.0375,
      "step": 7681
    },
    {
      "epoch": 1.7651654411764706,
      "grad_norm": 0.9466485977172852,
      "learning_rate": 7.190563725490197e-06,
      "loss": 0.0544,
      "step": 7682
    },
    {
      "epoch": 1.7653952205882353,
      "grad_norm": 1.8746296167373657,
      "learning_rate": 7.190053104575164e-06,
      "loss": 0.0941,
      "step": 7683
    },
    {
      "epoch": 1.765625,
      "grad_norm": 1.0997904539108276,
      "learning_rate": 7.189542483660131e-06,
      "loss": 0.0662,
      "step": 7684
    },
    {
      "epoch": 1.7658547794117647,
      "grad_norm": 1.0280550718307495,
      "learning_rate": 7.189031862745098e-06,
      "loss": 0.0648,
      "step": 7685
    },
    {
      "epoch": 1.7660845588235294,
      "grad_norm": 1.1250633001327515,
      "learning_rate": 7.188521241830066e-06,
      "loss": 0.0426,
      "step": 7686
    },
    {
      "epoch": 1.7663143382352942,
      "grad_norm": 0.9377355575561523,
      "learning_rate": 7.188010620915033e-06,
      "loss": 0.0507,
      "step": 7687
    },
    {
      "epoch": 1.7665441176470589,
      "grad_norm": 1.1543210744857788,
      "learning_rate": 7.1875e-06,
      "loss": 0.0654,
      "step": 7688
    },
    {
      "epoch": 1.7667738970588234,
      "grad_norm": 0.8816686272621155,
      "learning_rate": 7.186989379084967e-06,
      "loss": 0.0473,
      "step": 7689
    },
    {
      "epoch": 1.7670036764705883,
      "grad_norm": 0.9656385183334351,
      "learning_rate": 7.186478758169935e-06,
      "loss": 0.0804,
      "step": 7690
    },
    {
      "epoch": 1.7672334558823528,
      "grad_norm": 1.015868902206421,
      "learning_rate": 7.185968137254903e-06,
      "loss": 0.0619,
      "step": 7691
    },
    {
      "epoch": 1.7674632352941178,
      "grad_norm": 0.777873694896698,
      "learning_rate": 7.18545751633987e-06,
      "loss": 0.05,
      "step": 7692
    },
    {
      "epoch": 1.7676930147058822,
      "grad_norm": 1.1111699342727661,
      "learning_rate": 7.184946895424837e-06,
      "loss": 0.0593,
      "step": 7693
    },
    {
      "epoch": 1.7679227941176472,
      "grad_norm": 0.9352443218231201,
      "learning_rate": 7.184436274509804e-06,
      "loss": 0.0544,
      "step": 7694
    },
    {
      "epoch": 1.7681525735294117,
      "grad_norm": 0.7932369112968445,
      "learning_rate": 7.183925653594772e-06,
      "loss": 0.0382,
      "step": 7695
    },
    {
      "epoch": 1.7683823529411766,
      "grad_norm": 0.760334312915802,
      "learning_rate": 7.183415032679739e-06,
      "loss": 0.0414,
      "step": 7696
    },
    {
      "epoch": 1.7686121323529411,
      "grad_norm": 0.6394522190093994,
      "learning_rate": 7.182904411764706e-06,
      "loss": 0.0316,
      "step": 7697
    },
    {
      "epoch": 1.7688419117647058,
      "grad_norm": 0.949331521987915,
      "learning_rate": 7.182393790849673e-06,
      "loss": 0.0591,
      "step": 7698
    },
    {
      "epoch": 1.7690716911764706,
      "grad_norm": 1.0038801431655884,
      "learning_rate": 7.181883169934642e-06,
      "loss": 0.0579,
      "step": 7699
    },
    {
      "epoch": 1.7693014705882353,
      "grad_norm": 0.7497400045394897,
      "learning_rate": 7.181372549019609e-06,
      "loss": 0.031,
      "step": 7700
    },
    {
      "epoch": 1.76953125,
      "grad_norm": 1.102298617362976,
      "learning_rate": 7.180861928104576e-06,
      "loss": 0.0571,
      "step": 7701
    },
    {
      "epoch": 1.7697610294117647,
      "grad_norm": 1.0526784658432007,
      "learning_rate": 7.180351307189543e-06,
      "loss": 0.0394,
      "step": 7702
    },
    {
      "epoch": 1.7699908088235294,
      "grad_norm": 1.020776391029358,
      "learning_rate": 7.1798406862745105e-06,
      "loss": 0.0616,
      "step": 7703
    },
    {
      "epoch": 1.7702205882352942,
      "grad_norm": 0.982244074344635,
      "learning_rate": 7.1793300653594775e-06,
      "loss": 0.0534,
      "step": 7704
    },
    {
      "epoch": 1.7704503676470589,
      "grad_norm": 1.0625627040863037,
      "learning_rate": 7.1788194444444445e-06,
      "loss": 0.045,
      "step": 7705
    },
    {
      "epoch": 1.7706801470588234,
      "grad_norm": 1.0654079914093018,
      "learning_rate": 7.1783088235294116e-06,
      "loss": 0.0509,
      "step": 7706
    },
    {
      "epoch": 1.7709099264705883,
      "grad_norm": 0.8457215428352356,
      "learning_rate": 7.17779820261438e-06,
      "loss": 0.0451,
      "step": 7707
    },
    {
      "epoch": 1.7711397058823528,
      "grad_norm": 0.9705923795700073,
      "learning_rate": 7.177287581699347e-06,
      "loss": 0.0546,
      "step": 7708
    },
    {
      "epoch": 1.7713694852941178,
      "grad_norm": 1.2827521562576294,
      "learning_rate": 7.176776960784314e-06,
      "loss": 0.0552,
      "step": 7709
    },
    {
      "epoch": 1.7715992647058822,
      "grad_norm": 1.0011399984359741,
      "learning_rate": 7.176266339869281e-06,
      "loss": 0.0533,
      "step": 7710
    },
    {
      "epoch": 1.7718290441176472,
      "grad_norm": 0.6914457082748413,
      "learning_rate": 7.175755718954249e-06,
      "loss": 0.0313,
      "step": 7711
    },
    {
      "epoch": 1.7720588235294117,
      "grad_norm": 1.0358588695526123,
      "learning_rate": 7.175245098039216e-06,
      "loss": 0.0586,
      "step": 7712
    },
    {
      "epoch": 1.7722886029411766,
      "grad_norm": 1.2432068586349487,
      "learning_rate": 7.174734477124183e-06,
      "loss": 0.0529,
      "step": 7713
    },
    {
      "epoch": 1.7725183823529411,
      "grad_norm": 0.7438497543334961,
      "learning_rate": 7.17422385620915e-06,
      "loss": 0.0305,
      "step": 7714
    },
    {
      "epoch": 1.7727481617647058,
      "grad_norm": 1.0531307458877563,
      "learning_rate": 7.173713235294119e-06,
      "loss": 0.0683,
      "step": 7715
    },
    {
      "epoch": 1.7729779411764706,
      "grad_norm": 0.8592110872268677,
      "learning_rate": 7.173202614379086e-06,
      "loss": 0.0275,
      "step": 7716
    },
    {
      "epoch": 1.7732077205882353,
      "grad_norm": 1.1873337030410767,
      "learning_rate": 7.172691993464053e-06,
      "loss": 0.0655,
      "step": 7717
    },
    {
      "epoch": 1.7734375,
      "grad_norm": 1.0257513523101807,
      "learning_rate": 7.17218137254902e-06,
      "loss": 0.0503,
      "step": 7718
    },
    {
      "epoch": 1.7736672794117647,
      "grad_norm": 0.9599060416221619,
      "learning_rate": 7.171670751633988e-06,
      "loss": 0.0494,
      "step": 7719
    },
    {
      "epoch": 1.7738970588235294,
      "grad_norm": 1.0142841339111328,
      "learning_rate": 7.171160130718955e-06,
      "loss": 0.0467,
      "step": 7720
    },
    {
      "epoch": 1.7741268382352942,
      "grad_norm": 0.8238081932067871,
      "learning_rate": 7.170649509803922e-06,
      "loss": 0.0409,
      "step": 7721
    },
    {
      "epoch": 1.7743566176470589,
      "grad_norm": 1.2714102268218994,
      "learning_rate": 7.170138888888889e-06,
      "loss": 0.0575,
      "step": 7722
    },
    {
      "epoch": 1.7745863970588234,
      "grad_norm": 1.3791791200637817,
      "learning_rate": 7.169628267973857e-06,
      "loss": 0.0721,
      "step": 7723
    },
    {
      "epoch": 1.7748161764705883,
      "grad_norm": 0.9913248419761658,
      "learning_rate": 7.169117647058825e-06,
      "loss": 0.0471,
      "step": 7724
    },
    {
      "epoch": 1.7750459558823528,
      "grad_norm": 1.00581955909729,
      "learning_rate": 7.168607026143792e-06,
      "loss": 0.063,
      "step": 7725
    },
    {
      "epoch": 1.7752757352941178,
      "grad_norm": 0.8835724592208862,
      "learning_rate": 7.168096405228759e-06,
      "loss": 0.0498,
      "step": 7726
    },
    {
      "epoch": 1.7755055147058822,
      "grad_norm": 0.7958309650421143,
      "learning_rate": 7.1675857843137265e-06,
      "loss": 0.0281,
      "step": 7727
    },
    {
      "epoch": 1.7757352941176472,
      "grad_norm": 0.8620578646659851,
      "learning_rate": 7.1670751633986935e-06,
      "loss": 0.0334,
      "step": 7728
    },
    {
      "epoch": 1.7759650735294117,
      "grad_norm": 0.8478532433509827,
      "learning_rate": 7.1665645424836605e-06,
      "loss": 0.0529,
      "step": 7729
    },
    {
      "epoch": 1.7761948529411766,
      "grad_norm": 0.7014369368553162,
      "learning_rate": 7.1660539215686275e-06,
      "loss": 0.0298,
      "step": 7730
    },
    {
      "epoch": 1.7764246323529411,
      "grad_norm": 1.1190682649612427,
      "learning_rate": 7.165543300653595e-06,
      "loss": 0.0545,
      "step": 7731
    },
    {
      "epoch": 1.7766544117647058,
      "grad_norm": 0.9317271709442139,
      "learning_rate": 7.165032679738562e-06,
      "loss": 0.0599,
      "step": 7732
    },
    {
      "epoch": 1.7768841911764706,
      "grad_norm": 0.7741075158119202,
      "learning_rate": 7.164522058823529e-06,
      "loss": 0.0362,
      "step": 7733
    },
    {
      "epoch": 1.7771139705882353,
      "grad_norm": 0.8745845556259155,
      "learning_rate": 7.1640114379084964e-06,
      "loss": 0.0468,
      "step": 7734
    },
    {
      "epoch": 1.77734375,
      "grad_norm": 1.1878316402435303,
      "learning_rate": 7.163500816993465e-06,
      "loss": 0.0474,
      "step": 7735
    },
    {
      "epoch": 1.7775735294117647,
      "grad_norm": 1.6203627586364746,
      "learning_rate": 7.162990196078432e-06,
      "loss": 0.0924,
      "step": 7736
    },
    {
      "epoch": 1.7778033088235294,
      "grad_norm": 0.9094342589378357,
      "learning_rate": 7.162479575163399e-06,
      "loss": 0.0404,
      "step": 7737
    },
    {
      "epoch": 1.7780330882352942,
      "grad_norm": 1.036146879196167,
      "learning_rate": 7.161968954248366e-06,
      "loss": 0.0614,
      "step": 7738
    },
    {
      "epoch": 1.7782628676470589,
      "grad_norm": 0.941139280796051,
      "learning_rate": 7.161458333333334e-06,
      "loss": 0.0636,
      "step": 7739
    },
    {
      "epoch": 1.7784926470588234,
      "grad_norm": 1.044334888458252,
      "learning_rate": 7.160947712418301e-06,
      "loss": 0.0425,
      "step": 7740
    },
    {
      "epoch": 1.7787224264705883,
      "grad_norm": 0.7414402365684509,
      "learning_rate": 7.160437091503268e-06,
      "loss": 0.05,
      "step": 7741
    },
    {
      "epoch": 1.7789522058823528,
      "grad_norm": 0.962084174156189,
      "learning_rate": 7.159926470588235e-06,
      "loss": 0.056,
      "step": 7742
    },
    {
      "epoch": 1.7791819852941178,
      "grad_norm": 0.921519935131073,
      "learning_rate": 7.159415849673204e-06,
      "loss": 0.0549,
      "step": 7743
    },
    {
      "epoch": 1.7794117647058822,
      "grad_norm": 1.0198774337768555,
      "learning_rate": 7.158905228758171e-06,
      "loss": 0.0445,
      "step": 7744
    },
    {
      "epoch": 1.7796415441176472,
      "grad_norm": 0.7886320352554321,
      "learning_rate": 7.158394607843138e-06,
      "loss": 0.0292,
      "step": 7745
    },
    {
      "epoch": 1.7798713235294117,
      "grad_norm": 0.7427645325660706,
      "learning_rate": 7.157883986928105e-06,
      "loss": 0.0329,
      "step": 7746
    },
    {
      "epoch": 1.7801011029411766,
      "grad_norm": 0.9959806799888611,
      "learning_rate": 7.157373366013073e-06,
      "loss": 0.0548,
      "step": 7747
    },
    {
      "epoch": 1.7803308823529411,
      "grad_norm": 0.7600579857826233,
      "learning_rate": 7.15686274509804e-06,
      "loss": 0.0351,
      "step": 7748
    },
    {
      "epoch": 1.7805606617647058,
      "grad_norm": 1.084686279296875,
      "learning_rate": 7.156352124183007e-06,
      "loss": 0.0723,
      "step": 7749
    },
    {
      "epoch": 1.7807904411764706,
      "grad_norm": 1.0533586740493774,
      "learning_rate": 7.155841503267974e-06,
      "loss": 0.0679,
      "step": 7750
    },
    {
      "epoch": 1.7810202205882353,
      "grad_norm": 0.8275071382522583,
      "learning_rate": 7.1553308823529425e-06,
      "loss": 0.0478,
      "step": 7751
    },
    {
      "epoch": 1.78125,
      "grad_norm": 1.091576099395752,
      "learning_rate": 7.1548202614379095e-06,
      "loss": 0.0607,
      "step": 7752
    },
    {
      "epoch": 1.7814797794117647,
      "grad_norm": 0.7938101887702942,
      "learning_rate": 7.1543096405228765e-06,
      "loss": 0.0419,
      "step": 7753
    },
    {
      "epoch": 1.7817095588235294,
      "grad_norm": 1.1065208911895752,
      "learning_rate": 7.1537990196078435e-06,
      "loss": 0.068,
      "step": 7754
    },
    {
      "epoch": 1.7819393382352942,
      "grad_norm": 0.7626087665557861,
      "learning_rate": 7.153288398692811e-06,
      "loss": 0.0374,
      "step": 7755
    },
    {
      "epoch": 1.7821691176470589,
      "grad_norm": 0.8813987970352173,
      "learning_rate": 7.152777777777778e-06,
      "loss": 0.0493,
      "step": 7756
    },
    {
      "epoch": 1.7823988970588234,
      "grad_norm": 1.176042079925537,
      "learning_rate": 7.152267156862745e-06,
      "loss": 0.0493,
      "step": 7757
    },
    {
      "epoch": 1.7826286764705883,
      "grad_norm": 0.9646445512771606,
      "learning_rate": 7.151756535947712e-06,
      "loss": 0.0334,
      "step": 7758
    },
    {
      "epoch": 1.7828584558823528,
      "grad_norm": 0.6145473122596741,
      "learning_rate": 7.151245915032681e-06,
      "loss": 0.0216,
      "step": 7759
    },
    {
      "epoch": 1.7830882352941178,
      "grad_norm": 1.0056856870651245,
      "learning_rate": 7.150735294117648e-06,
      "loss": 0.0444,
      "step": 7760
    },
    {
      "epoch": 1.7833180147058822,
      "grad_norm": 0.8722636699676514,
      "learning_rate": 7.150224673202615e-06,
      "loss": 0.0426,
      "step": 7761
    },
    {
      "epoch": 1.7835477941176472,
      "grad_norm": 1.0875954627990723,
      "learning_rate": 7.149714052287582e-06,
      "loss": 0.0557,
      "step": 7762
    },
    {
      "epoch": 1.7837775735294117,
      "grad_norm": 0.8761281371116638,
      "learning_rate": 7.14920343137255e-06,
      "loss": 0.0356,
      "step": 7763
    },
    {
      "epoch": 1.7840073529411766,
      "grad_norm": 0.6258316040039062,
      "learning_rate": 7.148692810457517e-06,
      "loss": 0.0324,
      "step": 7764
    },
    {
      "epoch": 1.7842371323529411,
      "grad_norm": 0.7974312901496887,
      "learning_rate": 7.148182189542484e-06,
      "loss": 0.0291,
      "step": 7765
    },
    {
      "epoch": 1.7844669117647058,
      "grad_norm": 0.8191975355148315,
      "learning_rate": 7.147671568627451e-06,
      "loss": 0.0338,
      "step": 7766
    },
    {
      "epoch": 1.7846966911764706,
      "grad_norm": 1.0598065853118896,
      "learning_rate": 7.147160947712419e-06,
      "loss": 0.0501,
      "step": 7767
    },
    {
      "epoch": 1.7849264705882353,
      "grad_norm": 0.9200680255889893,
      "learning_rate": 7.146650326797386e-06,
      "loss": 0.0365,
      "step": 7768
    },
    {
      "epoch": 1.78515625,
      "grad_norm": 0.861033022403717,
      "learning_rate": 7.146139705882354e-06,
      "loss": 0.0322,
      "step": 7769
    },
    {
      "epoch": 1.7853860294117647,
      "grad_norm": 1.0799202919006348,
      "learning_rate": 7.145629084967321e-06,
      "loss": 0.0624,
      "step": 7770
    },
    {
      "epoch": 1.7856158088235294,
      "grad_norm": 0.9916108846664429,
      "learning_rate": 7.145118464052289e-06,
      "loss": 0.0508,
      "step": 7771
    },
    {
      "epoch": 1.7858455882352942,
      "grad_norm": 1.0098621845245361,
      "learning_rate": 7.144607843137256e-06,
      "loss": 0.0662,
      "step": 7772
    },
    {
      "epoch": 1.7860753676470589,
      "grad_norm": 1.1220245361328125,
      "learning_rate": 7.144097222222223e-06,
      "loss": 0.0673,
      "step": 7773
    },
    {
      "epoch": 1.7863051470588234,
      "grad_norm": 1.5657275915145874,
      "learning_rate": 7.14358660130719e-06,
      "loss": 0.0907,
      "step": 7774
    },
    {
      "epoch": 1.7865349264705883,
      "grad_norm": 1.210028052330017,
      "learning_rate": 7.143075980392158e-06,
      "loss": 0.0555,
      "step": 7775
    },
    {
      "epoch": 1.7867647058823528,
      "grad_norm": 1.3486026525497437,
      "learning_rate": 7.142565359477125e-06,
      "loss": 0.0272,
      "step": 7776
    },
    {
      "epoch": 1.7869944852941178,
      "grad_norm": 1.4247167110443115,
      "learning_rate": 7.142054738562092e-06,
      "loss": 0.0564,
      "step": 7777
    },
    {
      "epoch": 1.7872242647058822,
      "grad_norm": 1.1972546577453613,
      "learning_rate": 7.141544117647059e-06,
      "loss": 0.0815,
      "step": 7778
    },
    {
      "epoch": 1.7874540441176472,
      "grad_norm": 0.9832121133804321,
      "learning_rate": 7.141033496732027e-06,
      "loss": 0.0528,
      "step": 7779
    },
    {
      "epoch": 1.7876838235294117,
      "grad_norm": 0.8132758736610413,
      "learning_rate": 7.140522875816994e-06,
      "loss": 0.0392,
      "step": 7780
    },
    {
      "epoch": 1.7879136029411766,
      "grad_norm": 0.9183322787284851,
      "learning_rate": 7.140012254901961e-06,
      "loss": 0.0393,
      "step": 7781
    },
    {
      "epoch": 1.7881433823529411,
      "grad_norm": 1.1052950620651245,
      "learning_rate": 7.139501633986928e-06,
      "loss": 0.0674,
      "step": 7782
    },
    {
      "epoch": 1.7883731617647058,
      "grad_norm": 0.814241886138916,
      "learning_rate": 7.138991013071896e-06,
      "loss": 0.042,
      "step": 7783
    },
    {
      "epoch": 1.7886029411764706,
      "grad_norm": 0.9707024693489075,
      "learning_rate": 7.138480392156863e-06,
      "loss": 0.0478,
      "step": 7784
    },
    {
      "epoch": 1.7888327205882353,
      "grad_norm": 0.8984359502792358,
      "learning_rate": 7.13796977124183e-06,
      "loss": 0.038,
      "step": 7785
    },
    {
      "epoch": 1.7890625,
      "grad_norm": 0.8138474225997925,
      "learning_rate": 7.137459150326797e-06,
      "loss": 0.0415,
      "step": 7786
    },
    {
      "epoch": 1.7892922794117647,
      "grad_norm": 1.0547447204589844,
      "learning_rate": 7.136948529411766e-06,
      "loss": 0.0419,
      "step": 7787
    },
    {
      "epoch": 1.7895220588235294,
      "grad_norm": 0.7994338274002075,
      "learning_rate": 7.136437908496733e-06,
      "loss": 0.0506,
      "step": 7788
    },
    {
      "epoch": 1.7897518382352942,
      "grad_norm": 0.9947036504745483,
      "learning_rate": 7.1359272875817e-06,
      "loss": 0.0417,
      "step": 7789
    },
    {
      "epoch": 1.7899816176470589,
      "grad_norm": 1.089334487915039,
      "learning_rate": 7.135416666666667e-06,
      "loss": 0.0682,
      "step": 7790
    },
    {
      "epoch": 1.7902113970588234,
      "grad_norm": 0.7244269847869873,
      "learning_rate": 7.134906045751635e-06,
      "loss": 0.0298,
      "step": 7791
    },
    {
      "epoch": 1.7904411764705883,
      "grad_norm": 0.935478150844574,
      "learning_rate": 7.134395424836602e-06,
      "loss": 0.0389,
      "step": 7792
    },
    {
      "epoch": 1.7906709558823528,
      "grad_norm": 0.9374473690986633,
      "learning_rate": 7.133884803921569e-06,
      "loss": 0.0443,
      "step": 7793
    },
    {
      "epoch": 1.7909007352941178,
      "grad_norm": 0.9568042159080505,
      "learning_rate": 7.133374183006536e-06,
      "loss": 0.0583,
      "step": 7794
    },
    {
      "epoch": 1.7911305147058822,
      "grad_norm": 1.184629201889038,
      "learning_rate": 7.132863562091505e-06,
      "loss": 0.0472,
      "step": 7795
    },
    {
      "epoch": 1.7913602941176472,
      "grad_norm": 1.2555997371673584,
      "learning_rate": 7.132352941176472e-06,
      "loss": 0.0608,
      "step": 7796
    },
    {
      "epoch": 1.7915900735294117,
      "grad_norm": 1.0806924104690552,
      "learning_rate": 7.131842320261439e-06,
      "loss": 0.047,
      "step": 7797
    },
    {
      "epoch": 1.7918198529411766,
      "grad_norm": 0.8355313539505005,
      "learning_rate": 7.131331699346406e-06,
      "loss": 0.0494,
      "step": 7798
    },
    {
      "epoch": 1.7920496323529411,
      "grad_norm": 1.165972113609314,
      "learning_rate": 7.1308210784313735e-06,
      "loss": 0.0567,
      "step": 7799
    },
    {
      "epoch": 1.7922794117647058,
      "grad_norm": 0.712540328502655,
      "learning_rate": 7.1303104575163406e-06,
      "loss": 0.0303,
      "step": 7800
    },
    {
      "epoch": 1.7925091911764706,
      "grad_norm": 1.1858136653900146,
      "learning_rate": 7.129799836601308e-06,
      "loss": 0.0961,
      "step": 7801
    },
    {
      "epoch": 1.7927389705882353,
      "grad_norm": 1.129026174545288,
      "learning_rate": 7.129289215686275e-06,
      "loss": 0.0451,
      "step": 7802
    },
    {
      "epoch": 1.79296875,
      "grad_norm": 1.1793075799942017,
      "learning_rate": 7.128778594771243e-06,
      "loss": 0.0518,
      "step": 7803
    },
    {
      "epoch": 1.7931985294117647,
      "grad_norm": 1.0141862630844116,
      "learning_rate": 7.12826797385621e-06,
      "loss": 0.0492,
      "step": 7804
    },
    {
      "epoch": 1.7934283088235294,
      "grad_norm": 1.296906590461731,
      "learning_rate": 7.127757352941177e-06,
      "loss": 0.0561,
      "step": 7805
    },
    {
      "epoch": 1.7936580882352942,
      "grad_norm": 1.124981164932251,
      "learning_rate": 7.127246732026144e-06,
      "loss": 0.0481,
      "step": 7806
    },
    {
      "epoch": 1.7938878676470589,
      "grad_norm": 1.2939400672912598,
      "learning_rate": 7.126736111111112e-06,
      "loss": 0.0382,
      "step": 7807
    },
    {
      "epoch": 1.7941176470588234,
      "grad_norm": 0.7246227264404297,
      "learning_rate": 7.126225490196079e-06,
      "loss": 0.0424,
      "step": 7808
    },
    {
      "epoch": 1.7943474264705883,
      "grad_norm": 0.8587157130241394,
      "learning_rate": 7.125714869281046e-06,
      "loss": 0.0443,
      "step": 7809
    },
    {
      "epoch": 1.7945772058823528,
      "grad_norm": 0.6857939958572388,
      "learning_rate": 7.125204248366013e-06,
      "loss": 0.0421,
      "step": 7810
    },
    {
      "epoch": 1.7948069852941178,
      "grad_norm": 1.7166513204574585,
      "learning_rate": 7.124693627450981e-06,
      "loss": 0.0847,
      "step": 7811
    },
    {
      "epoch": 1.7950367647058822,
      "grad_norm": 1.675364375114441,
      "learning_rate": 7.124183006535948e-06,
      "loss": 0.048,
      "step": 7812
    },
    {
      "epoch": 1.7952665441176472,
      "grad_norm": 0.9333266615867615,
      "learning_rate": 7.123672385620916e-06,
      "loss": 0.0442,
      "step": 7813
    },
    {
      "epoch": 1.7954963235294117,
      "grad_norm": 1.1535680294036865,
      "learning_rate": 7.123161764705883e-06,
      "loss": 0.0435,
      "step": 7814
    },
    {
      "epoch": 1.7957261029411766,
      "grad_norm": 1.187035083770752,
      "learning_rate": 7.122651143790851e-06,
      "loss": 0.0621,
      "step": 7815
    },
    {
      "epoch": 1.7959558823529411,
      "grad_norm": 0.932051420211792,
      "learning_rate": 7.122140522875818e-06,
      "loss": 0.043,
      "step": 7816
    },
    {
      "epoch": 1.7961856617647058,
      "grad_norm": 0.8139937520027161,
      "learning_rate": 7.121629901960785e-06,
      "loss": 0.0436,
      "step": 7817
    },
    {
      "epoch": 1.7964154411764706,
      "grad_norm": 1.1951755285263062,
      "learning_rate": 7.121119281045752e-06,
      "loss": 0.0562,
      "step": 7818
    },
    {
      "epoch": 1.7966452205882353,
      "grad_norm": 1.1600319147109985,
      "learning_rate": 7.12060866013072e-06,
      "loss": 0.0562,
      "step": 7819
    },
    {
      "epoch": 1.796875,
      "grad_norm": 0.8072810173034668,
      "learning_rate": 7.120098039215687e-06,
      "loss": 0.0336,
      "step": 7820
    },
    {
      "epoch": 1.7971047794117647,
      "grad_norm": 1.2374281883239746,
      "learning_rate": 7.119587418300654e-06,
      "loss": 0.0477,
      "step": 7821
    },
    {
      "epoch": 1.7973345588235294,
      "grad_norm": 0.8425322771072388,
      "learning_rate": 7.119076797385621e-06,
      "loss": 0.0385,
      "step": 7822
    },
    {
      "epoch": 1.7975643382352942,
      "grad_norm": 0.7727473378181458,
      "learning_rate": 7.1185661764705895e-06,
      "loss": 0.0337,
      "step": 7823
    },
    {
      "epoch": 1.7977941176470589,
      "grad_norm": 0.8857457041740417,
      "learning_rate": 7.1180555555555565e-06,
      "loss": 0.0336,
      "step": 7824
    },
    {
      "epoch": 1.7980238970588234,
      "grad_norm": 0.9426084756851196,
      "learning_rate": 7.1175449346405235e-06,
      "loss": 0.0408,
      "step": 7825
    },
    {
      "epoch": 1.7982536764705883,
      "grad_norm": 0.7488963007926941,
      "learning_rate": 7.1170343137254906e-06,
      "loss": 0.0374,
      "step": 7826
    },
    {
      "epoch": 1.7984834558823528,
      "grad_norm": 1.1479684114456177,
      "learning_rate": 7.116523692810458e-06,
      "loss": 0.0633,
      "step": 7827
    },
    {
      "epoch": 1.7987132352941178,
      "grad_norm": 0.8074613809585571,
      "learning_rate": 7.1160130718954254e-06,
      "loss": 0.0349,
      "step": 7828
    },
    {
      "epoch": 1.7989430147058822,
      "grad_norm": 0.8650639057159424,
      "learning_rate": 7.1155024509803925e-06,
      "loss": 0.0616,
      "step": 7829
    },
    {
      "epoch": 1.7991727941176472,
      "grad_norm": 0.9409290552139282,
      "learning_rate": 7.1149918300653595e-06,
      "loss": 0.0399,
      "step": 7830
    },
    {
      "epoch": 1.7994025735294117,
      "grad_norm": 0.6877807378768921,
      "learning_rate": 7.114481209150328e-06,
      "loss": 0.0351,
      "step": 7831
    },
    {
      "epoch": 1.7996323529411766,
      "grad_norm": 0.9936816096305847,
      "learning_rate": 7.113970588235295e-06,
      "loss": 0.0437,
      "step": 7832
    },
    {
      "epoch": 1.7998621323529411,
      "grad_norm": 1.1297657489776611,
      "learning_rate": 7.113459967320262e-06,
      "loss": 0.0783,
      "step": 7833
    },
    {
      "epoch": 1.8000919117647058,
      "grad_norm": 1.1138323545455933,
      "learning_rate": 7.112949346405229e-06,
      "loss": 0.0493,
      "step": 7834
    },
    {
      "epoch": 1.8003216911764706,
      "grad_norm": 0.8695763349533081,
      "learning_rate": 7.112438725490197e-06,
      "loss": 0.0551,
      "step": 7835
    },
    {
      "epoch": 1.8005514705882353,
      "grad_norm": 1.0815351009368896,
      "learning_rate": 7.111928104575164e-06,
      "loss": 0.0437,
      "step": 7836
    },
    {
      "epoch": 1.80078125,
      "grad_norm": 0.9085426330566406,
      "learning_rate": 7.111417483660131e-06,
      "loss": 0.0434,
      "step": 7837
    },
    {
      "epoch": 1.8010110294117647,
      "grad_norm": 0.776340663433075,
      "learning_rate": 7.110906862745098e-06,
      "loss": 0.0323,
      "step": 7838
    },
    {
      "epoch": 1.8012408088235294,
      "grad_norm": 0.697097659111023,
      "learning_rate": 7.110396241830067e-06,
      "loss": 0.0313,
      "step": 7839
    },
    {
      "epoch": 1.8014705882352942,
      "grad_norm": 1.0273829698562622,
      "learning_rate": 7.109885620915034e-06,
      "loss": 0.0507,
      "step": 7840
    },
    {
      "epoch": 1.8017003676470589,
      "grad_norm": 1.0040419101715088,
      "learning_rate": 7.109375000000001e-06,
      "loss": 0.037,
      "step": 7841
    },
    {
      "epoch": 1.8019301470588234,
      "grad_norm": 1.0743175745010376,
      "learning_rate": 7.108864379084968e-06,
      "loss": 0.0551,
      "step": 7842
    },
    {
      "epoch": 1.8021599264705883,
      "grad_norm": 1.1034843921661377,
      "learning_rate": 7.108353758169935e-06,
      "loss": 0.0653,
      "step": 7843
    },
    {
      "epoch": 1.8023897058823528,
      "grad_norm": 0.7857028245925903,
      "learning_rate": 7.107843137254903e-06,
      "loss": 0.0342,
      "step": 7844
    },
    {
      "epoch": 1.8026194852941178,
      "grad_norm": 1.0653923749923706,
      "learning_rate": 7.10733251633987e-06,
      "loss": 0.0497,
      "step": 7845
    },
    {
      "epoch": 1.8028492647058822,
      "grad_norm": 0.9194818139076233,
      "learning_rate": 7.106821895424837e-06,
      "loss": 0.0565,
      "step": 7846
    },
    {
      "epoch": 1.8030790441176472,
      "grad_norm": 0.8711870312690735,
      "learning_rate": 7.106311274509804e-06,
      "loss": 0.0388,
      "step": 7847
    },
    {
      "epoch": 1.8033088235294117,
      "grad_norm": 1.673590064048767,
      "learning_rate": 7.1058006535947725e-06,
      "loss": 0.0457,
      "step": 7848
    },
    {
      "epoch": 1.8035386029411766,
      "grad_norm": 1.3016210794448853,
      "learning_rate": 7.1052900326797395e-06,
      "loss": 0.0624,
      "step": 7849
    },
    {
      "epoch": 1.8037683823529411,
      "grad_norm": 0.7760111689567566,
      "learning_rate": 7.1047794117647065e-06,
      "loss": 0.0357,
      "step": 7850
    },
    {
      "epoch": 1.8039981617647058,
      "grad_norm": 0.9272550344467163,
      "learning_rate": 7.1042687908496735e-06,
      "loss": 0.0581,
      "step": 7851
    },
    {
      "epoch": 1.8042279411764706,
      "grad_norm": 0.887884795665741,
      "learning_rate": 7.103758169934641e-06,
      "loss": 0.0414,
      "step": 7852
    },
    {
      "epoch": 1.8044577205882353,
      "grad_norm": 0.8564218282699585,
      "learning_rate": 7.103247549019608e-06,
      "loss": 0.0575,
      "step": 7853
    },
    {
      "epoch": 1.8046875,
      "grad_norm": 0.8270029425621033,
      "learning_rate": 7.1027369281045754e-06,
      "loss": 0.0457,
      "step": 7854
    },
    {
      "epoch": 1.8049172794117647,
      "grad_norm": 1.0794775485992432,
      "learning_rate": 7.1022263071895424e-06,
      "loss": 0.0687,
      "step": 7855
    },
    {
      "epoch": 1.8051470588235294,
      "grad_norm": 1.3789528608322144,
      "learning_rate": 7.10171568627451e-06,
      "loss": 0.0411,
      "step": 7856
    },
    {
      "epoch": 1.8053768382352942,
      "grad_norm": 1.196990728378296,
      "learning_rate": 7.101205065359477e-06,
      "loss": 0.0801,
      "step": 7857
    },
    {
      "epoch": 1.8056066176470589,
      "grad_norm": 1.2498703002929688,
      "learning_rate": 7.100694444444445e-06,
      "loss": 0.0549,
      "step": 7858
    },
    {
      "epoch": 1.8058363970588234,
      "grad_norm": 0.9427563548088074,
      "learning_rate": 7.100183823529412e-06,
      "loss": 0.0463,
      "step": 7859
    },
    {
      "epoch": 1.8060661764705883,
      "grad_norm": 1.054302453994751,
      "learning_rate": 7.09967320261438e-06,
      "loss": 0.0624,
      "step": 7860
    },
    {
      "epoch": 1.8062959558823528,
      "grad_norm": 1.1069738864898682,
      "learning_rate": 7.099162581699347e-06,
      "loss": 0.0449,
      "step": 7861
    },
    {
      "epoch": 1.8065257352941178,
      "grad_norm": 1.13373863697052,
      "learning_rate": 7.098651960784314e-06,
      "loss": 0.064,
      "step": 7862
    },
    {
      "epoch": 1.8067555147058822,
      "grad_norm": 1.0898160934448242,
      "learning_rate": 7.098141339869281e-06,
      "loss": 0.0758,
      "step": 7863
    },
    {
      "epoch": 1.8069852941176472,
      "grad_norm": 0.7484109401702881,
      "learning_rate": 7.097630718954249e-06,
      "loss": 0.0458,
      "step": 7864
    },
    {
      "epoch": 1.8072150735294117,
      "grad_norm": 1.1193305253982544,
      "learning_rate": 7.097120098039216e-06,
      "loss": 0.0537,
      "step": 7865
    },
    {
      "epoch": 1.8074448529411766,
      "grad_norm": 0.97928786277771,
      "learning_rate": 7.096609477124183e-06,
      "loss": 0.0403,
      "step": 7866
    },
    {
      "epoch": 1.8076746323529411,
      "grad_norm": 1.1999906301498413,
      "learning_rate": 7.09609885620915e-06,
      "loss": 0.0751,
      "step": 7867
    },
    {
      "epoch": 1.8079044117647058,
      "grad_norm": 0.7799103260040283,
      "learning_rate": 7.095588235294119e-06,
      "loss": 0.0429,
      "step": 7868
    },
    {
      "epoch": 1.8081341911764706,
      "grad_norm": 1.4805737733840942,
      "learning_rate": 7.095077614379086e-06,
      "loss": 0.0604,
      "step": 7869
    },
    {
      "epoch": 1.8083639705882353,
      "grad_norm": 0.8644415736198425,
      "learning_rate": 7.094566993464053e-06,
      "loss": 0.0421,
      "step": 7870
    },
    {
      "epoch": 1.80859375,
      "grad_norm": 1.1035676002502441,
      "learning_rate": 7.09405637254902e-06,
      "loss": 0.0675,
      "step": 7871
    },
    {
      "epoch": 1.8088235294117647,
      "grad_norm": 1.091506838798523,
      "learning_rate": 7.093545751633988e-06,
      "loss": 0.0574,
      "step": 7872
    },
    {
      "epoch": 1.8090533088235294,
      "grad_norm": 0.7227972745895386,
      "learning_rate": 7.093035130718955e-06,
      "loss": 0.033,
      "step": 7873
    },
    {
      "epoch": 1.8092830882352942,
      "grad_norm": 0.9392993450164795,
      "learning_rate": 7.092524509803922e-06,
      "loss": 0.0532,
      "step": 7874
    },
    {
      "epoch": 1.8095128676470589,
      "grad_norm": 0.9826112389564514,
      "learning_rate": 7.092013888888889e-06,
      "loss": 0.0437,
      "step": 7875
    },
    {
      "epoch": 1.8097426470588234,
      "grad_norm": 0.8082938194274902,
      "learning_rate": 7.091503267973857e-06,
      "loss": 0.0483,
      "step": 7876
    },
    {
      "epoch": 1.8099724264705883,
      "grad_norm": 0.798675000667572,
      "learning_rate": 7.090992647058824e-06,
      "loss": 0.045,
      "step": 7877
    },
    {
      "epoch": 1.8102022058823528,
      "grad_norm": 1.062991738319397,
      "learning_rate": 7.090482026143791e-06,
      "loss": 0.062,
      "step": 7878
    },
    {
      "epoch": 1.8104319852941178,
      "grad_norm": 0.8358790278434753,
      "learning_rate": 7.089971405228758e-06,
      "loss": 0.0425,
      "step": 7879
    },
    {
      "epoch": 1.8106617647058822,
      "grad_norm": 0.9684926867485046,
      "learning_rate": 7.089460784313726e-06,
      "loss": 0.067,
      "step": 7880
    },
    {
      "epoch": 1.8108915441176472,
      "grad_norm": 0.9522390365600586,
      "learning_rate": 7.088950163398693e-06,
      "loss": 0.0454,
      "step": 7881
    },
    {
      "epoch": 1.8111213235294117,
      "grad_norm": 1.2851762771606445,
      "learning_rate": 7.08843954248366e-06,
      "loss": 0.0601,
      "step": 7882
    },
    {
      "epoch": 1.8113511029411766,
      "grad_norm": 1.0395514965057373,
      "learning_rate": 7.087928921568627e-06,
      "loss": 0.0407,
      "step": 7883
    },
    {
      "epoch": 1.8115808823529411,
      "grad_norm": 0.9869536757469177,
      "learning_rate": 7.087418300653596e-06,
      "loss": 0.057,
      "step": 7884
    },
    {
      "epoch": 1.8118106617647058,
      "grad_norm": 0.9734342694282532,
      "learning_rate": 7.086907679738563e-06,
      "loss": 0.0601,
      "step": 7885
    },
    {
      "epoch": 1.8120404411764706,
      "grad_norm": 0.9715226888656616,
      "learning_rate": 7.08639705882353e-06,
      "loss": 0.0541,
      "step": 7886
    },
    {
      "epoch": 1.8122702205882353,
      "grad_norm": 0.6929190754890442,
      "learning_rate": 7.085886437908497e-06,
      "loss": 0.0323,
      "step": 7887
    },
    {
      "epoch": 1.8125,
      "grad_norm": 1.028682827949524,
      "learning_rate": 7.085375816993465e-06,
      "loss": 0.0481,
      "step": 7888
    },
    {
      "epoch": 1.8127297794117647,
      "grad_norm": 1.012434720993042,
      "learning_rate": 7.084865196078432e-06,
      "loss": 0.0669,
      "step": 7889
    },
    {
      "epoch": 1.8129595588235294,
      "grad_norm": 1.1196297407150269,
      "learning_rate": 7.084354575163399e-06,
      "loss": 0.0938,
      "step": 7890
    },
    {
      "epoch": 1.8131893382352942,
      "grad_norm": 0.8417966365814209,
      "learning_rate": 7.083843954248366e-06,
      "loss": 0.0395,
      "step": 7891
    },
    {
      "epoch": 1.8134191176470589,
      "grad_norm": 0.8123343586921692,
      "learning_rate": 7.083333333333335e-06,
      "loss": 0.0513,
      "step": 7892
    },
    {
      "epoch": 1.8136488970588234,
      "grad_norm": 1.005386471748352,
      "learning_rate": 7.082822712418302e-06,
      "loss": 0.0475,
      "step": 7893
    },
    {
      "epoch": 1.8138786764705883,
      "grad_norm": 0.9069700837135315,
      "learning_rate": 7.082312091503269e-06,
      "loss": 0.0538,
      "step": 7894
    },
    {
      "epoch": 1.8141084558823528,
      "grad_norm": 1.034071683883667,
      "learning_rate": 7.081801470588236e-06,
      "loss": 0.0552,
      "step": 7895
    },
    {
      "epoch": 1.8143382352941178,
      "grad_norm": 0.8063191771507263,
      "learning_rate": 7.081290849673204e-06,
      "loss": 0.0488,
      "step": 7896
    },
    {
      "epoch": 1.8145680147058822,
      "grad_norm": 1.2998219728469849,
      "learning_rate": 7.080780228758171e-06,
      "loss": 0.0667,
      "step": 7897
    },
    {
      "epoch": 1.8147977941176472,
      "grad_norm": 1.0050327777862549,
      "learning_rate": 7.080269607843138e-06,
      "loss": 0.0449,
      "step": 7898
    },
    {
      "epoch": 1.8150275735294117,
      "grad_norm": 1.031240463256836,
      "learning_rate": 7.079758986928105e-06,
      "loss": 0.0485,
      "step": 7899
    },
    {
      "epoch": 1.8152573529411766,
      "grad_norm": 1.6312669515609741,
      "learning_rate": 7.0792483660130725e-06,
      "loss": 0.0485,
      "step": 7900
    },
    {
      "epoch": 1.8154871323529411,
      "grad_norm": 0.88954758644104,
      "learning_rate": 7.0787377450980395e-06,
      "loss": 0.0513,
      "step": 7901
    },
    {
      "epoch": 1.8157169117647058,
      "grad_norm": 0.8363583087921143,
      "learning_rate": 7.0782271241830065e-06,
      "loss": 0.0418,
      "step": 7902
    },
    {
      "epoch": 1.8159466911764706,
      "grad_norm": 0.7386734485626221,
      "learning_rate": 7.077716503267974e-06,
      "loss": 0.0398,
      "step": 7903
    },
    {
      "epoch": 1.8161764705882353,
      "grad_norm": 1.0437099933624268,
      "learning_rate": 7.077205882352942e-06,
      "loss": 0.0446,
      "step": 7904
    },
    {
      "epoch": 1.81640625,
      "grad_norm": 1.183444619178772,
      "learning_rate": 7.076695261437909e-06,
      "loss": 0.092,
      "step": 7905
    },
    {
      "epoch": 1.8166360294117647,
      "grad_norm": 1.2521145343780518,
      "learning_rate": 7.076184640522876e-06,
      "loss": 0.0644,
      "step": 7906
    },
    {
      "epoch": 1.8168658088235294,
      "grad_norm": 1.2367292642593384,
      "learning_rate": 7.075674019607843e-06,
      "loss": 0.0433,
      "step": 7907
    },
    {
      "epoch": 1.8170955882352942,
      "grad_norm": 1.2644834518432617,
      "learning_rate": 7.075163398692811e-06,
      "loss": 0.0329,
      "step": 7908
    },
    {
      "epoch": 1.8173253676470589,
      "grad_norm": 0.9125595688819885,
      "learning_rate": 7.074652777777778e-06,
      "loss": 0.0403,
      "step": 7909
    },
    {
      "epoch": 1.8175551470588234,
      "grad_norm": 1.5039812326431274,
      "learning_rate": 7.074142156862745e-06,
      "loss": 0.0529,
      "step": 7910
    },
    {
      "epoch": 1.8177849264705883,
      "grad_norm": 0.9295931458473206,
      "learning_rate": 7.073631535947712e-06,
      "loss": 0.0456,
      "step": 7911
    },
    {
      "epoch": 1.8180147058823528,
      "grad_norm": 0.7535780072212219,
      "learning_rate": 7.073120915032681e-06,
      "loss": 0.0362,
      "step": 7912
    },
    {
      "epoch": 1.8182444852941178,
      "grad_norm": 0.9151085615158081,
      "learning_rate": 7.072610294117648e-06,
      "loss": 0.0462,
      "step": 7913
    },
    {
      "epoch": 1.8184742647058822,
      "grad_norm": 0.7288027405738831,
      "learning_rate": 7.072099673202615e-06,
      "loss": 0.0368,
      "step": 7914
    },
    {
      "epoch": 1.8187040441176472,
      "grad_norm": 2.205465316772461,
      "learning_rate": 7.071589052287582e-06,
      "loss": 0.0649,
      "step": 7915
    },
    {
      "epoch": 1.8189338235294117,
      "grad_norm": 1.15226149559021,
      "learning_rate": 7.07107843137255e-06,
      "loss": 0.0618,
      "step": 7916
    },
    {
      "epoch": 1.8191636029411766,
      "grad_norm": 0.6647663712501526,
      "learning_rate": 7.070567810457517e-06,
      "loss": 0.0232,
      "step": 7917
    },
    {
      "epoch": 1.8193933823529411,
      "grad_norm": 0.7528753280639648,
      "learning_rate": 7.070057189542484e-06,
      "loss": 0.0459,
      "step": 7918
    },
    {
      "epoch": 1.8196231617647058,
      "grad_norm": 0.8212646245956421,
      "learning_rate": 7.069546568627451e-06,
      "loss": 0.0342,
      "step": 7919
    },
    {
      "epoch": 1.8198529411764706,
      "grad_norm": 1.071122646331787,
      "learning_rate": 7.0690359477124196e-06,
      "loss": 0.0487,
      "step": 7920
    },
    {
      "epoch": 1.8200827205882353,
      "grad_norm": 0.6760123372077942,
      "learning_rate": 7.068525326797387e-06,
      "loss": 0.0357,
      "step": 7921
    },
    {
      "epoch": 1.8203125,
      "grad_norm": 1.4531469345092773,
      "learning_rate": 7.068014705882354e-06,
      "loss": 0.045,
      "step": 7922
    },
    {
      "epoch": 1.8205422794117647,
      "grad_norm": 0.8473089933395386,
      "learning_rate": 7.067504084967321e-06,
      "loss": 0.0366,
      "step": 7923
    },
    {
      "epoch": 1.8207720588235294,
      "grad_norm": 0.9217864871025085,
      "learning_rate": 7.0669934640522885e-06,
      "loss": 0.0718,
      "step": 7924
    },
    {
      "epoch": 1.8210018382352942,
      "grad_norm": 0.9025101661682129,
      "learning_rate": 7.0664828431372555e-06,
      "loss": 0.0421,
      "step": 7925
    },
    {
      "epoch": 1.8212316176470589,
      "grad_norm": 0.9044028520584106,
      "learning_rate": 7.0659722222222225e-06,
      "loss": 0.0438,
      "step": 7926
    },
    {
      "epoch": 1.8214613970588234,
      "grad_norm": 0.926888644695282,
      "learning_rate": 7.0654616013071895e-06,
      "loss": 0.0628,
      "step": 7927
    },
    {
      "epoch": 1.8216911764705883,
      "grad_norm": 0.7864047288894653,
      "learning_rate": 7.064950980392158e-06,
      "loss": 0.0317,
      "step": 7928
    },
    {
      "epoch": 1.8219209558823528,
      "grad_norm": 1.8436774015426636,
      "learning_rate": 7.064440359477125e-06,
      "loss": 0.0624,
      "step": 7929
    },
    {
      "epoch": 1.8221507352941178,
      "grad_norm": 0.6854852437973022,
      "learning_rate": 7.063929738562092e-06,
      "loss": 0.0374,
      "step": 7930
    },
    {
      "epoch": 1.8223805147058822,
      "grad_norm": 0.9405990839004517,
      "learning_rate": 7.063419117647059e-06,
      "loss": 0.0547,
      "step": 7931
    },
    {
      "epoch": 1.8226102941176472,
      "grad_norm": 1.0654661655426025,
      "learning_rate": 7.062908496732027e-06,
      "loss": 0.0415,
      "step": 7932
    },
    {
      "epoch": 1.8228400735294117,
      "grad_norm": 1.8847647905349731,
      "learning_rate": 7.062397875816994e-06,
      "loss": 0.0405,
      "step": 7933
    },
    {
      "epoch": 1.8230698529411766,
      "grad_norm": 0.9720956087112427,
      "learning_rate": 7.061887254901961e-06,
      "loss": 0.054,
      "step": 7934
    },
    {
      "epoch": 1.8232996323529411,
      "grad_norm": 1.0952064990997314,
      "learning_rate": 7.061376633986928e-06,
      "loss": 0.0566,
      "step": 7935
    },
    {
      "epoch": 1.8235294117647058,
      "grad_norm": 1.3537558317184448,
      "learning_rate": 7.060866013071896e-06,
      "loss": 0.0657,
      "step": 7936
    },
    {
      "epoch": 1.8237591911764706,
      "grad_norm": 0.8122470378875732,
      "learning_rate": 7.060355392156864e-06,
      "loss": 0.0558,
      "step": 7937
    },
    {
      "epoch": 1.8239889705882353,
      "grad_norm": 0.9196135401725769,
      "learning_rate": 7.059844771241831e-06,
      "loss": 0.0476,
      "step": 7938
    },
    {
      "epoch": 1.82421875,
      "grad_norm": 0.9497244954109192,
      "learning_rate": 7.059334150326798e-06,
      "loss": 0.038,
      "step": 7939
    },
    {
      "epoch": 1.8244485294117647,
      "grad_norm": 1.3407145738601685,
      "learning_rate": 7.058823529411766e-06,
      "loss": 0.0492,
      "step": 7940
    },
    {
      "epoch": 1.8246783088235294,
      "grad_norm": 0.8365616202354431,
      "learning_rate": 7.058312908496733e-06,
      "loss": 0.0424,
      "step": 7941
    },
    {
      "epoch": 1.8249080882352942,
      "grad_norm": 1.03331458568573,
      "learning_rate": 7.0578022875817e-06,
      "loss": 0.047,
      "step": 7942
    },
    {
      "epoch": 1.8251378676470589,
      "grad_norm": 1.1302919387817383,
      "learning_rate": 7.057291666666667e-06,
      "loss": 0.0626,
      "step": 7943
    },
    {
      "epoch": 1.8253676470588234,
      "grad_norm": 0.9812601208686829,
      "learning_rate": 7.056781045751635e-06,
      "loss": 0.0691,
      "step": 7944
    },
    {
      "epoch": 1.8255974264705883,
      "grad_norm": 0.7693256735801697,
      "learning_rate": 7.056270424836602e-06,
      "loss": 0.0445,
      "step": 7945
    },
    {
      "epoch": 1.8258272058823528,
      "grad_norm": 0.8790140151977539,
      "learning_rate": 7.055759803921569e-06,
      "loss": 0.056,
      "step": 7946
    },
    {
      "epoch": 1.8260569852941178,
      "grad_norm": 0.8367447853088379,
      "learning_rate": 7.055249183006537e-06,
      "loss": 0.0471,
      "step": 7947
    },
    {
      "epoch": 1.8262867647058822,
      "grad_norm": 0.7513917088508606,
      "learning_rate": 7.0547385620915044e-06,
      "loss": 0.0579,
      "step": 7948
    },
    {
      "epoch": 1.8265165441176472,
      "grad_norm": 0.8261703252792358,
      "learning_rate": 7.0542279411764715e-06,
      "loss": 0.0352,
      "step": 7949
    },
    {
      "epoch": 1.8267463235294117,
      "grad_norm": 0.6074621081352234,
      "learning_rate": 7.0537173202614385e-06,
      "loss": 0.0314,
      "step": 7950
    },
    {
      "epoch": 1.8269761029411766,
      "grad_norm": 0.6914159655570984,
      "learning_rate": 7.0532066993464055e-06,
      "loss": 0.029,
      "step": 7951
    },
    {
      "epoch": 1.8272058823529411,
      "grad_norm": 0.6998642683029175,
      "learning_rate": 7.052696078431373e-06,
      "loss": 0.0325,
      "step": 7952
    },
    {
      "epoch": 1.8274356617647058,
      "grad_norm": 1.0409332513809204,
      "learning_rate": 7.05218545751634e-06,
      "loss": 0.0485,
      "step": 7953
    },
    {
      "epoch": 1.8276654411764706,
      "grad_norm": 0.7836233377456665,
      "learning_rate": 7.051674836601307e-06,
      "loss": 0.0427,
      "step": 7954
    },
    {
      "epoch": 1.8278952205882353,
      "grad_norm": 0.9310061931610107,
      "learning_rate": 7.051164215686274e-06,
      "loss": 0.0517,
      "step": 7955
    },
    {
      "epoch": 1.828125,
      "grad_norm": 0.9949636459350586,
      "learning_rate": 7.050653594771243e-06,
      "loss": 0.0479,
      "step": 7956
    },
    {
      "epoch": 1.8283547794117647,
      "grad_norm": 0.914678692817688,
      "learning_rate": 7.05014297385621e-06,
      "loss": 0.0409,
      "step": 7957
    },
    {
      "epoch": 1.8285845588235294,
      "grad_norm": 0.8913227915763855,
      "learning_rate": 7.049632352941177e-06,
      "loss": 0.0379,
      "step": 7958
    },
    {
      "epoch": 1.8288143382352942,
      "grad_norm": 0.9005647897720337,
      "learning_rate": 7.049121732026144e-06,
      "loss": 0.0519,
      "step": 7959
    },
    {
      "epoch": 1.8290441176470589,
      "grad_norm": 0.9825257062911987,
      "learning_rate": 7.048611111111112e-06,
      "loss": 0.0501,
      "step": 7960
    },
    {
      "epoch": 1.8292738970588234,
      "grad_norm": 1.39176607131958,
      "learning_rate": 7.048100490196079e-06,
      "loss": 0.0799,
      "step": 7961
    },
    {
      "epoch": 1.8295036764705883,
      "grad_norm": 1.413320541381836,
      "learning_rate": 7.047589869281046e-06,
      "loss": 0.0399,
      "step": 7962
    },
    {
      "epoch": 1.8297334558823528,
      "grad_norm": 0.8301663994789124,
      "learning_rate": 7.047079248366013e-06,
      "loss": 0.0416,
      "step": 7963
    },
    {
      "epoch": 1.8299632352941178,
      "grad_norm": 0.879000186920166,
      "learning_rate": 7.046568627450982e-06,
      "loss": 0.0428,
      "step": 7964
    },
    {
      "epoch": 1.8301930147058822,
      "grad_norm": 0.7270282506942749,
      "learning_rate": 7.046058006535949e-06,
      "loss": 0.0299,
      "step": 7965
    },
    {
      "epoch": 1.8304227941176472,
      "grad_norm": 1.0961987972259521,
      "learning_rate": 7.045547385620916e-06,
      "loss": 0.0476,
      "step": 7966
    },
    {
      "epoch": 1.8306525735294117,
      "grad_norm": 0.9287440180778503,
      "learning_rate": 7.045036764705883e-06,
      "loss": 0.0471,
      "step": 7967
    },
    {
      "epoch": 1.8308823529411766,
      "grad_norm": 0.8677271008491516,
      "learning_rate": 7.044526143790851e-06,
      "loss": 0.048,
      "step": 7968
    },
    {
      "epoch": 1.8311121323529411,
      "grad_norm": 1.2524127960205078,
      "learning_rate": 7.044015522875818e-06,
      "loss": 0.0757,
      "step": 7969
    },
    {
      "epoch": 1.8313419117647058,
      "grad_norm": 1.7431392669677734,
      "learning_rate": 7.043504901960785e-06,
      "loss": 0.0903,
      "step": 7970
    },
    {
      "epoch": 1.8315716911764706,
      "grad_norm": 0.8848596811294556,
      "learning_rate": 7.042994281045752e-06,
      "loss": 0.0493,
      "step": 7971
    },
    {
      "epoch": 1.8318014705882353,
      "grad_norm": 1.0772839784622192,
      "learning_rate": 7.04248366013072e-06,
      "loss": 0.0427,
      "step": 7972
    },
    {
      "epoch": 1.83203125,
      "grad_norm": 1.0606005191802979,
      "learning_rate": 7.041973039215687e-06,
      "loss": 0.0637,
      "step": 7973
    },
    {
      "epoch": 1.8322610294117647,
      "grad_norm": 0.979802131652832,
      "learning_rate": 7.0414624183006544e-06,
      "loss": 0.0516,
      "step": 7974
    },
    {
      "epoch": 1.8324908088235294,
      "grad_norm": 1.0433857440948486,
      "learning_rate": 7.0409517973856215e-06,
      "loss": 0.0402,
      "step": 7975
    },
    {
      "epoch": 1.8327205882352942,
      "grad_norm": 0.9308345317840576,
      "learning_rate": 7.040441176470589e-06,
      "loss": 0.0459,
      "step": 7976
    },
    {
      "epoch": 1.8329503676470589,
      "grad_norm": 1.270678162574768,
      "learning_rate": 7.039930555555556e-06,
      "loss": 0.0607,
      "step": 7977
    },
    {
      "epoch": 1.8331801470588234,
      "grad_norm": 1.1438978910446167,
      "learning_rate": 7.039419934640523e-06,
      "loss": 0.0526,
      "step": 7978
    },
    {
      "epoch": 1.8334099264705883,
      "grad_norm": 1.2357367277145386,
      "learning_rate": 7.03890931372549e-06,
      "loss": 0.0425,
      "step": 7979
    },
    {
      "epoch": 1.8336397058823528,
      "grad_norm": 1.6437605619430542,
      "learning_rate": 7.038398692810458e-06,
      "loss": 0.0564,
      "step": 7980
    },
    {
      "epoch": 1.8338694852941178,
      "grad_norm": 0.9740869998931885,
      "learning_rate": 7.037888071895426e-06,
      "loss": 0.0517,
      "step": 7981
    },
    {
      "epoch": 1.8340992647058822,
      "grad_norm": 0.9744154810905457,
      "learning_rate": 7.037377450980393e-06,
      "loss": 0.0476,
      "step": 7982
    },
    {
      "epoch": 1.8343290441176472,
      "grad_norm": 1.0708993673324585,
      "learning_rate": 7.03686683006536e-06,
      "loss": 0.0529,
      "step": 7983
    },
    {
      "epoch": 1.8345588235294117,
      "grad_norm": 1.0380042791366577,
      "learning_rate": 7.036356209150328e-06,
      "loss": 0.049,
      "step": 7984
    },
    {
      "epoch": 1.8347886029411766,
      "grad_norm": 0.8591192364692688,
      "learning_rate": 7.035845588235295e-06,
      "loss": 0.0454,
      "step": 7985
    },
    {
      "epoch": 1.8350183823529411,
      "grad_norm": 1.5760809183120728,
      "learning_rate": 7.035334967320262e-06,
      "loss": 0.0723,
      "step": 7986
    },
    {
      "epoch": 1.8352481617647058,
      "grad_norm": 0.8952463269233704,
      "learning_rate": 7.034824346405229e-06,
      "loss": 0.0346,
      "step": 7987
    },
    {
      "epoch": 1.8354779411764706,
      "grad_norm": 0.748913049697876,
      "learning_rate": 7.034313725490197e-06,
      "loss": 0.0349,
      "step": 7988
    },
    {
      "epoch": 1.8357077205882353,
      "grad_norm": 0.685619056224823,
      "learning_rate": 7.033803104575164e-06,
      "loss": 0.0269,
      "step": 7989
    },
    {
      "epoch": 1.8359375,
      "grad_norm": 0.9928863644599915,
      "learning_rate": 7.033292483660131e-06,
      "loss": 0.0585,
      "step": 7990
    },
    {
      "epoch": 1.8361672794117647,
      "grad_norm": 1.0235145092010498,
      "learning_rate": 7.032781862745098e-06,
      "loss": 0.0637,
      "step": 7991
    },
    {
      "epoch": 1.8363970588235294,
      "grad_norm": 1.5607222318649292,
      "learning_rate": 7.032271241830067e-06,
      "loss": 0.06,
      "step": 7992
    },
    {
      "epoch": 1.8366268382352942,
      "grad_norm": 0.6731505990028381,
      "learning_rate": 7.031760620915034e-06,
      "loss": 0.0321,
      "step": 7993
    },
    {
      "epoch": 1.8368566176470589,
      "grad_norm": 1.1512560844421387,
      "learning_rate": 7.031250000000001e-06,
      "loss": 0.06,
      "step": 7994
    },
    {
      "epoch": 1.8370863970588234,
      "grad_norm": 1.1362109184265137,
      "learning_rate": 7.030739379084968e-06,
      "loss": 0.0575,
      "step": 7995
    },
    {
      "epoch": 1.8373161764705883,
      "grad_norm": 0.9938969016075134,
      "learning_rate": 7.030228758169935e-06,
      "loss": 0.0588,
      "step": 7996
    },
    {
      "epoch": 1.8375459558823528,
      "grad_norm": 1.0520187616348267,
      "learning_rate": 7.0297181372549025e-06,
      "loss": 0.0486,
      "step": 7997
    },
    {
      "epoch": 1.8377757352941178,
      "grad_norm": 1.2498338222503662,
      "learning_rate": 7.0292075163398696e-06,
      "loss": 0.0556,
      "step": 7998
    },
    {
      "epoch": 1.8380055147058822,
      "grad_norm": 1.0643227100372314,
      "learning_rate": 7.0286968954248366e-06,
      "loss": 0.0514,
      "step": 7999
    },
    {
      "epoch": 1.8382352941176472,
      "grad_norm": 0.9965839982032776,
      "learning_rate": 7.028186274509804e-06,
      "loss": 0.04,
      "step": 8000
    },
    {
      "epoch": 1.8382352941176472,
      "eval_loss": 0.05133356526494026,
      "eval_runtime": 2006.8845,
      "eval_samples_per_second": 4.438,
      "eval_steps_per_second": 2.219,
      "step": 8000
    },
    {
      "epoch": 1.8384650735294117,
      "grad_norm": 1.1681771278381348,
      "learning_rate": 7.027675653594772e-06,
      "loss": 0.0696,
      "step": 8001
    },
    {
      "epoch": 1.8386948529411766,
      "grad_norm": 1.1480973958969116,
      "learning_rate": 7.027165032679739e-06,
      "loss": 0.0818,
      "step": 8002
    },
    {
      "epoch": 1.8389246323529411,
      "grad_norm": 0.7003007531166077,
      "learning_rate": 7.026654411764706e-06,
      "loss": 0.0376,
      "step": 8003
    },
    {
      "epoch": 1.8391544117647058,
      "grad_norm": 1.2050930261611938,
      "learning_rate": 7.026143790849673e-06,
      "loss": 0.0538,
      "step": 8004
    },
    {
      "epoch": 1.8393841911764706,
      "grad_norm": 0.9061355590820312,
      "learning_rate": 7.025633169934641e-06,
      "loss": 0.0406,
      "step": 8005
    },
    {
      "epoch": 1.8396139705882353,
      "grad_norm": 1.2692790031433105,
      "learning_rate": 7.025122549019608e-06,
      "loss": 0.0473,
      "step": 8006
    },
    {
      "epoch": 1.83984375,
      "grad_norm": 0.879666805267334,
      "learning_rate": 7.024611928104575e-06,
      "loss": 0.0438,
      "step": 8007
    },
    {
      "epoch": 1.8400735294117647,
      "grad_norm": 0.8511562347412109,
      "learning_rate": 7.024101307189542e-06,
      "loss": 0.0463,
      "step": 8008
    },
    {
      "epoch": 1.8403033088235294,
      "grad_norm": 1.2734944820404053,
      "learning_rate": 7.023590686274511e-06,
      "loss": 0.0561,
      "step": 8009
    },
    {
      "epoch": 1.8405330882352942,
      "grad_norm": 1.1812888383865356,
      "learning_rate": 7.023080065359478e-06,
      "loss": 0.0515,
      "step": 8010
    },
    {
      "epoch": 1.8407628676470589,
      "grad_norm": 0.8484338521957397,
      "learning_rate": 7.022569444444445e-06,
      "loss": 0.0455,
      "step": 8011
    },
    {
      "epoch": 1.8409926470588234,
      "grad_norm": 0.9454735517501831,
      "learning_rate": 7.022058823529412e-06,
      "loss": 0.0477,
      "step": 8012
    },
    {
      "epoch": 1.8412224264705883,
      "grad_norm": 0.9456373453140259,
      "learning_rate": 7.02154820261438e-06,
      "loss": 0.057,
      "step": 8013
    },
    {
      "epoch": 1.8414522058823528,
      "grad_norm": 0.8346112370491028,
      "learning_rate": 7.021037581699347e-06,
      "loss": 0.0451,
      "step": 8014
    },
    {
      "epoch": 1.8416819852941178,
      "grad_norm": 0.9277878403663635,
      "learning_rate": 7.020526960784314e-06,
      "loss": 0.0375,
      "step": 8015
    },
    {
      "epoch": 1.8419117647058822,
      "grad_norm": 1.1225743293762207,
      "learning_rate": 7.020016339869281e-06,
      "loss": 0.0747,
      "step": 8016
    },
    {
      "epoch": 1.8421415441176472,
      "grad_norm": 1.265321969985962,
      "learning_rate": 7.01950571895425e-06,
      "loss": 0.0563,
      "step": 8017
    },
    {
      "epoch": 1.8423713235294117,
      "grad_norm": 1.1358492374420166,
      "learning_rate": 7.018995098039217e-06,
      "loss": 0.0611,
      "step": 8018
    },
    {
      "epoch": 1.8426011029411766,
      "grad_norm": 0.6995241641998291,
      "learning_rate": 7.018484477124184e-06,
      "loss": 0.0539,
      "step": 8019
    },
    {
      "epoch": 1.8428308823529411,
      "grad_norm": 0.8428422808647156,
      "learning_rate": 7.017973856209151e-06,
      "loss": 0.0384,
      "step": 8020
    },
    {
      "epoch": 1.8430606617647058,
      "grad_norm": 0.9203953146934509,
      "learning_rate": 7.0174632352941185e-06,
      "loss": 0.0415,
      "step": 8021
    },
    {
      "epoch": 1.8432904411764706,
      "grad_norm": 0.9975476264953613,
      "learning_rate": 7.0169526143790855e-06,
      "loss": 0.0481,
      "step": 8022
    },
    {
      "epoch": 1.8435202205882353,
      "grad_norm": 0.6978917717933655,
      "learning_rate": 7.0164419934640525e-06,
      "loss": 0.0377,
      "step": 8023
    },
    {
      "epoch": 1.84375,
      "grad_norm": 0.7754084467887878,
      "learning_rate": 7.0159313725490196e-06,
      "loss": 0.0455,
      "step": 8024
    },
    {
      "epoch": 1.8439797794117647,
      "grad_norm": 0.8169394135475159,
      "learning_rate": 7.015420751633987e-06,
      "loss": 0.0443,
      "step": 8025
    },
    {
      "epoch": 1.8442095588235294,
      "grad_norm": 1.0167540311813354,
      "learning_rate": 7.014910130718955e-06,
      "loss": 0.0497,
      "step": 8026
    },
    {
      "epoch": 1.8444393382352942,
      "grad_norm": 0.8591455817222595,
      "learning_rate": 7.014399509803922e-06,
      "loss": 0.0476,
      "step": 8027
    },
    {
      "epoch": 1.8446691176470589,
      "grad_norm": 0.8277876377105713,
      "learning_rate": 7.013888888888889e-06,
      "loss": 0.0564,
      "step": 8028
    },
    {
      "epoch": 1.8448988970588234,
      "grad_norm": 1.7123637199401855,
      "learning_rate": 7.013378267973857e-06,
      "loss": 0.0559,
      "step": 8029
    },
    {
      "epoch": 1.8451286764705883,
      "grad_norm": 0.7587170004844666,
      "learning_rate": 7.012867647058824e-06,
      "loss": 0.0431,
      "step": 8030
    },
    {
      "epoch": 1.8453584558823528,
      "grad_norm": 1.2919800281524658,
      "learning_rate": 7.012357026143791e-06,
      "loss": 0.0734,
      "step": 8031
    },
    {
      "epoch": 1.8455882352941178,
      "grad_norm": 1.1899681091308594,
      "learning_rate": 7.011846405228758e-06,
      "loss": 0.0473,
      "step": 8032
    },
    {
      "epoch": 1.8458180147058822,
      "grad_norm": 0.9591571092605591,
      "learning_rate": 7.011335784313726e-06,
      "loss": 0.069,
      "step": 8033
    },
    {
      "epoch": 1.8460477941176472,
      "grad_norm": 0.8017866015434265,
      "learning_rate": 7.010825163398693e-06,
      "loss": 0.0348,
      "step": 8034
    },
    {
      "epoch": 1.8462775735294117,
      "grad_norm": 0.6762130856513977,
      "learning_rate": 7.01031454248366e-06,
      "loss": 0.0358,
      "step": 8035
    },
    {
      "epoch": 1.8465073529411766,
      "grad_norm": 0.700343132019043,
      "learning_rate": 7.009803921568628e-06,
      "loss": 0.0501,
      "step": 8036
    },
    {
      "epoch": 1.8467371323529411,
      "grad_norm": 1.1210424900054932,
      "learning_rate": 7.009293300653596e-06,
      "loss": 0.0541,
      "step": 8037
    },
    {
      "epoch": 1.8469669117647058,
      "grad_norm": 1.0199373960494995,
      "learning_rate": 7.008782679738563e-06,
      "loss": 0.0628,
      "step": 8038
    },
    {
      "epoch": 1.8471966911764706,
      "grad_norm": 0.9550393223762512,
      "learning_rate": 7.00827205882353e-06,
      "loss": 0.0409,
      "step": 8039
    },
    {
      "epoch": 1.8474264705882353,
      "grad_norm": 1.1138558387756348,
      "learning_rate": 7.007761437908497e-06,
      "loss": 0.0463,
      "step": 8040
    },
    {
      "epoch": 1.84765625,
      "grad_norm": 1.1662756204605103,
      "learning_rate": 7.007250816993465e-06,
      "loss": 0.0443,
      "step": 8041
    },
    {
      "epoch": 1.8478860294117647,
      "grad_norm": 0.7684771418571472,
      "learning_rate": 7.006740196078432e-06,
      "loss": 0.0368,
      "step": 8042
    },
    {
      "epoch": 1.8481158088235294,
      "grad_norm": 1.0581717491149902,
      "learning_rate": 7.006229575163399e-06,
      "loss": 0.0424,
      "step": 8043
    },
    {
      "epoch": 1.8483455882352942,
      "grad_norm": 1.2996678352355957,
      "learning_rate": 7.005718954248366e-06,
      "loss": 0.074,
      "step": 8044
    },
    {
      "epoch": 1.8485753676470589,
      "grad_norm": 0.9451549053192139,
      "learning_rate": 7.0052083333333345e-06,
      "loss": 0.0536,
      "step": 8045
    },
    {
      "epoch": 1.8488051470588234,
      "grad_norm": 1.0217764377593994,
      "learning_rate": 7.0046977124183015e-06,
      "loss": 0.0472,
      "step": 8046
    },
    {
      "epoch": 1.8490349264705883,
      "grad_norm": 1.0736262798309326,
      "learning_rate": 7.0041870915032685e-06,
      "loss": 0.0602,
      "step": 8047
    },
    {
      "epoch": 1.8492647058823528,
      "grad_norm": 1.0750046968460083,
      "learning_rate": 7.0036764705882355e-06,
      "loss": 0.0592,
      "step": 8048
    },
    {
      "epoch": 1.8494944852941178,
      "grad_norm": 0.9349809885025024,
      "learning_rate": 7.003165849673203e-06,
      "loss": 0.0466,
      "step": 8049
    },
    {
      "epoch": 1.8497242647058822,
      "grad_norm": 0.9253020882606506,
      "learning_rate": 7.00265522875817e-06,
      "loss": 0.0518,
      "step": 8050
    },
    {
      "epoch": 1.8499540441176472,
      "grad_norm": 1.1895166635513306,
      "learning_rate": 7.002144607843137e-06,
      "loss": 0.0473,
      "step": 8051
    },
    {
      "epoch": 1.8501838235294117,
      "grad_norm": 0.83724045753479,
      "learning_rate": 7.0016339869281044e-06,
      "loss": 0.0424,
      "step": 8052
    },
    {
      "epoch": 1.8504136029411766,
      "grad_norm": 0.7707685828208923,
      "learning_rate": 7.001123366013073e-06,
      "loss": 0.0304,
      "step": 8053
    },
    {
      "epoch": 1.8506433823529411,
      "grad_norm": 1.1997796297073364,
      "learning_rate": 7.00061274509804e-06,
      "loss": 0.0493,
      "step": 8054
    },
    {
      "epoch": 1.8508731617647058,
      "grad_norm": 0.9022009372711182,
      "learning_rate": 7.000102124183007e-06,
      "loss": 0.0488,
      "step": 8055
    },
    {
      "epoch": 1.8511029411764706,
      "grad_norm": 0.8894148468971252,
      "learning_rate": 6.999591503267974e-06,
      "loss": 0.0452,
      "step": 8056
    },
    {
      "epoch": 1.8513327205882353,
      "grad_norm": 1.113545298576355,
      "learning_rate": 6.999080882352942e-06,
      "loss": 0.0537,
      "step": 8057
    },
    {
      "epoch": 1.8515625,
      "grad_norm": 0.9768754243850708,
      "learning_rate": 6.998570261437909e-06,
      "loss": 0.0576,
      "step": 8058
    },
    {
      "epoch": 1.8517922794117647,
      "grad_norm": 1.050989031791687,
      "learning_rate": 6.998059640522876e-06,
      "loss": 0.0399,
      "step": 8059
    },
    {
      "epoch": 1.8520220588235294,
      "grad_norm": 0.9336873888969421,
      "learning_rate": 6.997549019607843e-06,
      "loss": 0.042,
      "step": 8060
    },
    {
      "epoch": 1.8522518382352942,
      "grad_norm": 0.8143792152404785,
      "learning_rate": 6.997038398692812e-06,
      "loss": 0.0546,
      "step": 8061
    },
    {
      "epoch": 1.8524816176470589,
      "grad_norm": 0.8674982190132141,
      "learning_rate": 6.996527777777779e-06,
      "loss": 0.0488,
      "step": 8062
    },
    {
      "epoch": 1.8527113970588234,
      "grad_norm": 1.079085350036621,
      "learning_rate": 6.996017156862746e-06,
      "loss": 0.0684,
      "step": 8063
    },
    {
      "epoch": 1.8529411764705883,
      "grad_norm": 1.000605821609497,
      "learning_rate": 6.995506535947713e-06,
      "loss": 0.032,
      "step": 8064
    },
    {
      "epoch": 1.8531709558823528,
      "grad_norm": 1.1737746000289917,
      "learning_rate": 6.994995915032681e-06,
      "loss": 0.0532,
      "step": 8065
    },
    {
      "epoch": 1.8534007352941178,
      "grad_norm": 1.1002459526062012,
      "learning_rate": 6.994485294117648e-06,
      "loss": 0.0428,
      "step": 8066
    },
    {
      "epoch": 1.8536305147058822,
      "grad_norm": 0.9797859191894531,
      "learning_rate": 6.993974673202615e-06,
      "loss": 0.0599,
      "step": 8067
    },
    {
      "epoch": 1.8538602941176472,
      "grad_norm": 0.8353631496429443,
      "learning_rate": 6.993464052287582e-06,
      "loss": 0.0298,
      "step": 8068
    },
    {
      "epoch": 1.8540900735294117,
      "grad_norm": 0.8724355101585388,
      "learning_rate": 6.99295343137255e-06,
      "loss": 0.0375,
      "step": 8069
    },
    {
      "epoch": 1.8543198529411766,
      "grad_norm": 1.0585771799087524,
      "learning_rate": 6.9924428104575175e-06,
      "loss": 0.0551,
      "step": 8070
    },
    {
      "epoch": 1.8545496323529411,
      "grad_norm": 1.2203649282455444,
      "learning_rate": 6.9919321895424845e-06,
      "loss": 0.0592,
      "step": 8071
    },
    {
      "epoch": 1.8547794117647058,
      "grad_norm": 1.1073635816574097,
      "learning_rate": 6.9914215686274515e-06,
      "loss": 0.0485,
      "step": 8072
    },
    {
      "epoch": 1.8550091911764706,
      "grad_norm": 0.8370492458343506,
      "learning_rate": 6.990910947712419e-06,
      "loss": 0.0339,
      "step": 8073
    },
    {
      "epoch": 1.8552389705882353,
      "grad_norm": 1.3718760013580322,
      "learning_rate": 6.990400326797386e-06,
      "loss": 0.0498,
      "step": 8074
    },
    {
      "epoch": 1.85546875,
      "grad_norm": 0.7578758001327515,
      "learning_rate": 6.989889705882353e-06,
      "loss": 0.0461,
      "step": 8075
    },
    {
      "epoch": 1.8556985294117647,
      "grad_norm": 2.3890485763549805,
      "learning_rate": 6.98937908496732e-06,
      "loss": 0.1034,
      "step": 8076
    },
    {
      "epoch": 1.8559283088235294,
      "grad_norm": 0.990169107913971,
      "learning_rate": 6.988868464052288e-06,
      "loss": 0.057,
      "step": 8077
    },
    {
      "epoch": 1.8561580882352942,
      "grad_norm": 0.7414743304252625,
      "learning_rate": 6.988357843137255e-06,
      "loss": 0.031,
      "step": 8078
    },
    {
      "epoch": 1.8563878676470589,
      "grad_norm": 1.2079600095748901,
      "learning_rate": 6.987847222222222e-06,
      "loss": 0.0587,
      "step": 8079
    },
    {
      "epoch": 1.8566176470588234,
      "grad_norm": 0.8354232311248779,
      "learning_rate": 6.987336601307189e-06,
      "loss": 0.0616,
      "step": 8080
    },
    {
      "epoch": 1.8568474264705883,
      "grad_norm": 1.0666084289550781,
      "learning_rate": 6.986825980392158e-06,
      "loss": 0.0634,
      "step": 8081
    },
    {
      "epoch": 1.8570772058823528,
      "grad_norm": 0.9608855247497559,
      "learning_rate": 6.986315359477125e-06,
      "loss": 0.0372,
      "step": 8082
    },
    {
      "epoch": 1.8573069852941178,
      "grad_norm": 0.7667121291160583,
      "learning_rate": 6.985804738562092e-06,
      "loss": 0.0345,
      "step": 8083
    },
    {
      "epoch": 1.8575367647058822,
      "grad_norm": 0.9188764095306396,
      "learning_rate": 6.985294117647059e-06,
      "loss": 0.0357,
      "step": 8084
    },
    {
      "epoch": 1.8577665441176472,
      "grad_norm": 0.7458022832870483,
      "learning_rate": 6.984783496732027e-06,
      "loss": 0.0322,
      "step": 8085
    },
    {
      "epoch": 1.8579963235294117,
      "grad_norm": 0.9682321548461914,
      "learning_rate": 6.984272875816994e-06,
      "loss": 0.0541,
      "step": 8086
    },
    {
      "epoch": 1.8582261029411766,
      "grad_norm": 0.8340189456939697,
      "learning_rate": 6.983762254901961e-06,
      "loss": 0.0392,
      "step": 8087
    },
    {
      "epoch": 1.8584558823529411,
      "grad_norm": 1.0735372304916382,
      "learning_rate": 6.983251633986928e-06,
      "loss": 0.0572,
      "step": 8088
    },
    {
      "epoch": 1.8586856617647058,
      "grad_norm": 1.2221015691757202,
      "learning_rate": 6.982741013071897e-06,
      "loss": 0.0512,
      "step": 8089
    },
    {
      "epoch": 1.8589154411764706,
      "grad_norm": 0.9381819367408752,
      "learning_rate": 6.982230392156864e-06,
      "loss": 0.0466,
      "step": 8090
    },
    {
      "epoch": 1.8591452205882353,
      "grad_norm": 0.9689304828643799,
      "learning_rate": 6.981719771241831e-06,
      "loss": 0.0597,
      "step": 8091
    },
    {
      "epoch": 1.859375,
      "grad_norm": 0.9176076650619507,
      "learning_rate": 6.981209150326798e-06,
      "loss": 0.0519,
      "step": 8092
    },
    {
      "epoch": 1.8596047794117647,
      "grad_norm": 1.0050288438796997,
      "learning_rate": 6.980698529411766e-06,
      "loss": 0.0472,
      "step": 8093
    },
    {
      "epoch": 1.8598345588235294,
      "grad_norm": 0.9240148663520813,
      "learning_rate": 6.980187908496733e-06,
      "loss": 0.0543,
      "step": 8094
    },
    {
      "epoch": 1.8600643382352942,
      "grad_norm": 0.9002621173858643,
      "learning_rate": 6.9796772875817e-06,
      "loss": 0.0418,
      "step": 8095
    },
    {
      "epoch": 1.8602941176470589,
      "grad_norm": 0.5861465334892273,
      "learning_rate": 6.979166666666667e-06,
      "loss": 0.0323,
      "step": 8096
    },
    {
      "epoch": 1.8605238970588234,
      "grad_norm": 0.9048964381217957,
      "learning_rate": 6.978656045751635e-06,
      "loss": 0.0591,
      "step": 8097
    },
    {
      "epoch": 1.8607536764705883,
      "grad_norm": 0.9387823939323425,
      "learning_rate": 6.978145424836602e-06,
      "loss": 0.0419,
      "step": 8098
    },
    {
      "epoch": 1.8609834558823528,
      "grad_norm": 0.9302956461906433,
      "learning_rate": 6.977634803921569e-06,
      "loss": 0.0429,
      "step": 8099
    },
    {
      "epoch": 1.8612132352941178,
      "grad_norm": 0.9547266960144043,
      "learning_rate": 6.977124183006536e-06,
      "loss": 0.0423,
      "step": 8100
    },
    {
      "epoch": 1.8614430147058822,
      "grad_norm": 1.6588722467422485,
      "learning_rate": 6.976613562091504e-06,
      "loss": 0.0633,
      "step": 8101
    },
    {
      "epoch": 1.8616727941176472,
      "grad_norm": 0.9744452238082886,
      "learning_rate": 6.976102941176471e-06,
      "loss": 0.0475,
      "step": 8102
    },
    {
      "epoch": 1.8619025735294117,
      "grad_norm": 0.7170315980911255,
      "learning_rate": 6.975592320261438e-06,
      "loss": 0.039,
      "step": 8103
    },
    {
      "epoch": 1.8621323529411766,
      "grad_norm": 0.9027611613273621,
      "learning_rate": 6.975081699346405e-06,
      "loss": 0.0378,
      "step": 8104
    },
    {
      "epoch": 1.8623621323529411,
      "grad_norm": 1.0590811967849731,
      "learning_rate": 6.974571078431374e-06,
      "loss": 0.0648,
      "step": 8105
    },
    {
      "epoch": 1.8625919117647058,
      "grad_norm": 1.0134525299072266,
      "learning_rate": 6.974060457516341e-06,
      "loss": 0.0545,
      "step": 8106
    },
    {
      "epoch": 1.8628216911764706,
      "grad_norm": 0.862061083316803,
      "learning_rate": 6.973549836601308e-06,
      "loss": 0.0499,
      "step": 8107
    },
    {
      "epoch": 1.8630514705882353,
      "grad_norm": 0.8513525128364563,
      "learning_rate": 6.973039215686275e-06,
      "loss": 0.0509,
      "step": 8108
    },
    {
      "epoch": 1.86328125,
      "grad_norm": 0.8410559296607971,
      "learning_rate": 6.972528594771243e-06,
      "loss": 0.0258,
      "step": 8109
    },
    {
      "epoch": 1.8635110294117647,
      "grad_norm": 1.41262948513031,
      "learning_rate": 6.97201797385621e-06,
      "loss": 0.0408,
      "step": 8110
    },
    {
      "epoch": 1.8637408088235294,
      "grad_norm": 0.7554221749305725,
      "learning_rate": 6.971507352941177e-06,
      "loss": 0.0299,
      "step": 8111
    },
    {
      "epoch": 1.8639705882352942,
      "grad_norm": 1.0718462467193604,
      "learning_rate": 6.970996732026144e-06,
      "loss": 0.0542,
      "step": 8112
    },
    {
      "epoch": 1.8642003676470589,
      "grad_norm": 1.6509474515914917,
      "learning_rate": 6.970486111111112e-06,
      "loss": 0.0809,
      "step": 8113
    },
    {
      "epoch": 1.8644301470588234,
      "grad_norm": 1.0943045616149902,
      "learning_rate": 6.969975490196079e-06,
      "loss": 0.0612,
      "step": 8114
    },
    {
      "epoch": 1.8646599264705883,
      "grad_norm": 1.1206551790237427,
      "learning_rate": 6.969464869281047e-06,
      "loss": 0.0656,
      "step": 8115
    },
    {
      "epoch": 1.8648897058823528,
      "grad_norm": 1.4437731504440308,
      "learning_rate": 6.968954248366014e-06,
      "loss": 0.0373,
      "step": 8116
    },
    {
      "epoch": 1.8651194852941178,
      "grad_norm": 0.786358118057251,
      "learning_rate": 6.9684436274509815e-06,
      "loss": 0.0408,
      "step": 8117
    },
    {
      "epoch": 1.8653492647058822,
      "grad_norm": 0.8431552648544312,
      "learning_rate": 6.9679330065359486e-06,
      "loss": 0.042,
      "step": 8118
    },
    {
      "epoch": 1.8655790441176472,
      "grad_norm": 0.8638842701911926,
      "learning_rate": 6.9674223856209156e-06,
      "loss": 0.0541,
      "step": 8119
    },
    {
      "epoch": 1.8658088235294117,
      "grad_norm": 1.150560736656189,
      "learning_rate": 6.966911764705883e-06,
      "loss": 0.0519,
      "step": 8120
    },
    {
      "epoch": 1.8660386029411766,
      "grad_norm": 1.2160946130752563,
      "learning_rate": 6.9664011437908505e-06,
      "loss": 0.0635,
      "step": 8121
    },
    {
      "epoch": 1.8662683823529411,
      "grad_norm": 1.224714756011963,
      "learning_rate": 6.9658905228758175e-06,
      "loss": 0.067,
      "step": 8122
    },
    {
      "epoch": 1.8664981617647058,
      "grad_norm": 1.0170363187789917,
      "learning_rate": 6.9653799019607845e-06,
      "loss": 0.0526,
      "step": 8123
    },
    {
      "epoch": 1.8667279411764706,
      "grad_norm": 1.1071070432662964,
      "learning_rate": 6.9648692810457515e-06,
      "loss": 0.0513,
      "step": 8124
    },
    {
      "epoch": 1.8669577205882353,
      "grad_norm": 0.8018012046813965,
      "learning_rate": 6.96435866013072e-06,
      "loss": 0.0425,
      "step": 8125
    },
    {
      "epoch": 1.8671875,
      "grad_norm": 1.1832189559936523,
      "learning_rate": 6.963848039215687e-06,
      "loss": 0.0507,
      "step": 8126
    },
    {
      "epoch": 1.8674172794117647,
      "grad_norm": 0.87212735414505,
      "learning_rate": 6.963337418300654e-06,
      "loss": 0.0505,
      "step": 8127
    },
    {
      "epoch": 1.8676470588235294,
      "grad_norm": 1.6157910823822021,
      "learning_rate": 6.962826797385621e-06,
      "loss": 0.0431,
      "step": 8128
    },
    {
      "epoch": 1.8678768382352942,
      "grad_norm": 1.1743029356002808,
      "learning_rate": 6.962316176470589e-06,
      "loss": 0.0449,
      "step": 8129
    },
    {
      "epoch": 1.8681066176470589,
      "grad_norm": 0.907810389995575,
      "learning_rate": 6.961805555555556e-06,
      "loss": 0.0381,
      "step": 8130
    },
    {
      "epoch": 1.8683363970588234,
      "grad_norm": 1.070194959640503,
      "learning_rate": 6.961294934640523e-06,
      "loss": 0.0469,
      "step": 8131
    },
    {
      "epoch": 1.8685661764705883,
      "grad_norm": 1.1773253679275513,
      "learning_rate": 6.96078431372549e-06,
      "loss": 0.055,
      "step": 8132
    },
    {
      "epoch": 1.8687959558823528,
      "grad_norm": 0.8535255193710327,
      "learning_rate": 6.960273692810459e-06,
      "loss": 0.0463,
      "step": 8133
    },
    {
      "epoch": 1.8690257352941178,
      "grad_norm": 1.0331474542617798,
      "learning_rate": 6.959763071895426e-06,
      "loss": 0.0424,
      "step": 8134
    },
    {
      "epoch": 1.8692555147058822,
      "grad_norm": 1.1884654760360718,
      "learning_rate": 6.959252450980393e-06,
      "loss": 0.0478,
      "step": 8135
    },
    {
      "epoch": 1.8694852941176472,
      "grad_norm": 0.7799661159515381,
      "learning_rate": 6.95874183006536e-06,
      "loss": 0.0432,
      "step": 8136
    },
    {
      "epoch": 1.8697150735294117,
      "grad_norm": 0.8764112591743469,
      "learning_rate": 6.958231209150328e-06,
      "loss": 0.0506,
      "step": 8137
    },
    {
      "epoch": 1.8699448529411766,
      "grad_norm": 0.7918505668640137,
      "learning_rate": 6.957720588235295e-06,
      "loss": 0.0366,
      "step": 8138
    },
    {
      "epoch": 1.8701746323529411,
      "grad_norm": 1.116422176361084,
      "learning_rate": 6.957209967320262e-06,
      "loss": 0.0528,
      "step": 8139
    },
    {
      "epoch": 1.8704044117647058,
      "grad_norm": 1.1448630094528198,
      "learning_rate": 6.956699346405229e-06,
      "loss": 0.0582,
      "step": 8140
    },
    {
      "epoch": 1.8706341911764706,
      "grad_norm": 0.7638258337974548,
      "learning_rate": 6.9561887254901975e-06,
      "loss": 0.0361,
      "step": 8141
    },
    {
      "epoch": 1.8708639705882353,
      "grad_norm": 1.4040615558624268,
      "learning_rate": 6.9556781045751645e-06,
      "loss": 0.0667,
      "step": 8142
    },
    {
      "epoch": 1.87109375,
      "grad_norm": 0.9976194500923157,
      "learning_rate": 6.9551674836601315e-06,
      "loss": 0.0539,
      "step": 8143
    },
    {
      "epoch": 1.8713235294117647,
      "grad_norm": 0.878145694732666,
      "learning_rate": 6.9546568627450986e-06,
      "loss": 0.0369,
      "step": 8144
    },
    {
      "epoch": 1.8715533088235294,
      "grad_norm": 0.7248840928077698,
      "learning_rate": 6.954146241830066e-06,
      "loss": 0.054,
      "step": 8145
    },
    {
      "epoch": 1.8717830882352942,
      "grad_norm": 1.1070730686187744,
      "learning_rate": 6.9536356209150334e-06,
      "loss": 0.0482,
      "step": 8146
    },
    {
      "epoch": 1.8720128676470589,
      "grad_norm": 0.9614734053611755,
      "learning_rate": 6.9531250000000004e-06,
      "loss": 0.0356,
      "step": 8147
    },
    {
      "epoch": 1.8722426470588234,
      "grad_norm": 1.0494283437728882,
      "learning_rate": 6.9526143790849675e-06,
      "loss": 0.0512,
      "step": 8148
    },
    {
      "epoch": 1.8724724264705883,
      "grad_norm": 1.1574326753616333,
      "learning_rate": 6.9521037581699345e-06,
      "loss": 0.0849,
      "step": 8149
    },
    {
      "epoch": 1.8727022058823528,
      "grad_norm": 0.8201132416725159,
      "learning_rate": 6.951593137254903e-06,
      "loss": 0.0302,
      "step": 8150
    },
    {
      "epoch": 1.8729319852941178,
      "grad_norm": 0.8288026452064514,
      "learning_rate": 6.95108251633987e-06,
      "loss": 0.0387,
      "step": 8151
    },
    {
      "epoch": 1.8731617647058822,
      "grad_norm": 1.3098393678665161,
      "learning_rate": 6.950571895424837e-06,
      "loss": 0.0661,
      "step": 8152
    },
    {
      "epoch": 1.8733915441176472,
      "grad_norm": 1.1501610279083252,
      "learning_rate": 6.950061274509804e-06,
      "loss": 0.0701,
      "step": 8153
    },
    {
      "epoch": 1.8736213235294117,
      "grad_norm": 0.9786798357963562,
      "learning_rate": 6.949550653594772e-06,
      "loss": 0.0471,
      "step": 8154
    },
    {
      "epoch": 1.8738511029411766,
      "grad_norm": 0.8370408415794373,
      "learning_rate": 6.949040032679739e-06,
      "loss": 0.0408,
      "step": 8155
    },
    {
      "epoch": 1.8740808823529411,
      "grad_norm": 0.8845546245574951,
      "learning_rate": 6.948529411764706e-06,
      "loss": 0.0444,
      "step": 8156
    },
    {
      "epoch": 1.8743106617647058,
      "grad_norm": 1.1834615468978882,
      "learning_rate": 6.948018790849673e-06,
      "loss": 0.0618,
      "step": 8157
    },
    {
      "epoch": 1.8745404411764706,
      "grad_norm": 1.0238217115402222,
      "learning_rate": 6.947508169934641e-06,
      "loss": 0.0548,
      "step": 8158
    },
    {
      "epoch": 1.8747702205882353,
      "grad_norm": 0.7014090418815613,
      "learning_rate": 6.946997549019608e-06,
      "loss": 0.0392,
      "step": 8159
    },
    {
      "epoch": 1.875,
      "grad_norm": 0.9445772767066956,
      "learning_rate": 6.946486928104576e-06,
      "loss": 0.0459,
      "step": 8160
    },
    {
      "epoch": 1.8752297794117647,
      "grad_norm": 1.1032246351242065,
      "learning_rate": 6.945976307189543e-06,
      "loss": 0.0532,
      "step": 8161
    },
    {
      "epoch": 1.8754595588235294,
      "grad_norm": 0.7411767840385437,
      "learning_rate": 6.945465686274511e-06,
      "loss": 0.04,
      "step": 8162
    },
    {
      "epoch": 1.8756893382352942,
      "grad_norm": 1.323387622833252,
      "learning_rate": 6.944955065359478e-06,
      "loss": 0.0405,
      "step": 8163
    },
    {
      "epoch": 1.8759191176470589,
      "grad_norm": 0.9355639219284058,
      "learning_rate": 6.944444444444445e-06,
      "loss": 0.0568,
      "step": 8164
    },
    {
      "epoch": 1.8761488970588234,
      "grad_norm": 1.0055052042007446,
      "learning_rate": 6.943933823529412e-06,
      "loss": 0.051,
      "step": 8165
    },
    {
      "epoch": 1.8763786764705883,
      "grad_norm": 1.600928783416748,
      "learning_rate": 6.94342320261438e-06,
      "loss": 0.0605,
      "step": 8166
    },
    {
      "epoch": 1.8766084558823528,
      "grad_norm": 1.6129523515701294,
      "learning_rate": 6.942912581699347e-06,
      "loss": 0.0563,
      "step": 8167
    },
    {
      "epoch": 1.8768382352941178,
      "grad_norm": 0.8747086524963379,
      "learning_rate": 6.942401960784314e-06,
      "loss": 0.0385,
      "step": 8168
    },
    {
      "epoch": 1.8770680147058822,
      "grad_norm": 1.0016902685165405,
      "learning_rate": 6.941891339869281e-06,
      "loss": 0.0514,
      "step": 8169
    },
    {
      "epoch": 1.8772977941176472,
      "grad_norm": 1.0883491039276123,
      "learning_rate": 6.941380718954249e-06,
      "loss": 0.0669,
      "step": 8170
    },
    {
      "epoch": 1.8775275735294117,
      "grad_norm": 1.0262199640274048,
      "learning_rate": 6.940870098039216e-06,
      "loss": 0.0474,
      "step": 8171
    },
    {
      "epoch": 1.8777573529411766,
      "grad_norm": 1.3578811883926392,
      "learning_rate": 6.9403594771241834e-06,
      "loss": 0.066,
      "step": 8172
    },
    {
      "epoch": 1.8779871323529411,
      "grad_norm": 0.7204664349555969,
      "learning_rate": 6.9398488562091504e-06,
      "loss": 0.0459,
      "step": 8173
    },
    {
      "epoch": 1.8782169117647058,
      "grad_norm": 0.8812248110771179,
      "learning_rate": 6.939338235294118e-06,
      "loss": 0.0356,
      "step": 8174
    },
    {
      "epoch": 1.8784466911764706,
      "grad_norm": 0.8974788188934326,
      "learning_rate": 6.938827614379085e-06,
      "loss": 0.0376,
      "step": 8175
    },
    {
      "epoch": 1.8786764705882353,
      "grad_norm": 0.7887301445007324,
      "learning_rate": 6.938316993464052e-06,
      "loss": 0.0316,
      "step": 8176
    },
    {
      "epoch": 1.87890625,
      "grad_norm": 1.024814248085022,
      "learning_rate": 6.937806372549019e-06,
      "loss": 0.0517,
      "step": 8177
    },
    {
      "epoch": 1.8791360294117647,
      "grad_norm": 0.9578788876533508,
      "learning_rate": 6.937295751633988e-06,
      "loss": 0.0546,
      "step": 8178
    },
    {
      "epoch": 1.8793658088235294,
      "grad_norm": 0.9745143055915833,
      "learning_rate": 6.936785130718955e-06,
      "loss": 0.0601,
      "step": 8179
    },
    {
      "epoch": 1.8795955882352942,
      "grad_norm": 1.0977579355239868,
      "learning_rate": 6.936274509803922e-06,
      "loss": 0.0439,
      "step": 8180
    },
    {
      "epoch": 1.8798253676470589,
      "grad_norm": 1.0581470727920532,
      "learning_rate": 6.935763888888889e-06,
      "loss": 0.0662,
      "step": 8181
    },
    {
      "epoch": 1.8800551470588234,
      "grad_norm": 0.8098429441452026,
      "learning_rate": 6.935253267973857e-06,
      "loss": 0.0302,
      "step": 8182
    },
    {
      "epoch": 1.8802849264705883,
      "grad_norm": 1.3085767030715942,
      "learning_rate": 6.934742647058824e-06,
      "loss": 0.0637,
      "step": 8183
    },
    {
      "epoch": 1.8805147058823528,
      "grad_norm": 0.6429134607315063,
      "learning_rate": 6.934232026143791e-06,
      "loss": 0.0335,
      "step": 8184
    },
    {
      "epoch": 1.8807444852941178,
      "grad_norm": 0.9463657140731812,
      "learning_rate": 6.933721405228758e-06,
      "loss": 0.0561,
      "step": 8185
    },
    {
      "epoch": 1.8809742647058822,
      "grad_norm": 1.1538724899291992,
      "learning_rate": 6.933210784313727e-06,
      "loss": 0.0602,
      "step": 8186
    },
    {
      "epoch": 1.8812040441176472,
      "grad_norm": 1.323624849319458,
      "learning_rate": 6.932700163398694e-06,
      "loss": 0.0457,
      "step": 8187
    },
    {
      "epoch": 1.8814338235294117,
      "grad_norm": 0.9456878900527954,
      "learning_rate": 6.932189542483661e-06,
      "loss": 0.044,
      "step": 8188
    },
    {
      "epoch": 1.8816636029411766,
      "grad_norm": 0.9792458415031433,
      "learning_rate": 6.931678921568628e-06,
      "loss": 0.0432,
      "step": 8189
    },
    {
      "epoch": 1.8818933823529411,
      "grad_norm": 1.2289625406265259,
      "learning_rate": 6.931168300653596e-06,
      "loss": 0.0703,
      "step": 8190
    },
    {
      "epoch": 1.8821231617647058,
      "grad_norm": 0.9685231447219849,
      "learning_rate": 6.930657679738563e-06,
      "loss": 0.0623,
      "step": 8191
    },
    {
      "epoch": 1.8823529411764706,
      "grad_norm": 1.1479523181915283,
      "learning_rate": 6.93014705882353e-06,
      "loss": 0.0355,
      "step": 8192
    },
    {
      "epoch": 1.8825827205882353,
      "grad_norm": 1.4530102014541626,
      "learning_rate": 6.929636437908497e-06,
      "loss": 0.0662,
      "step": 8193
    },
    {
      "epoch": 1.8828125,
      "grad_norm": 0.9578307867050171,
      "learning_rate": 6.929125816993465e-06,
      "loss": 0.0455,
      "step": 8194
    },
    {
      "epoch": 1.8830422794117647,
      "grad_norm": 1.1766425371170044,
      "learning_rate": 6.928615196078432e-06,
      "loss": 0.053,
      "step": 8195
    },
    {
      "epoch": 1.8832720588235294,
      "grad_norm": 0.9991939067840576,
      "learning_rate": 6.928104575163399e-06,
      "loss": 0.0482,
      "step": 8196
    },
    {
      "epoch": 1.8835018382352942,
      "grad_norm": 0.8411173820495605,
      "learning_rate": 6.927593954248366e-06,
      "loss": 0.0482,
      "step": 8197
    },
    {
      "epoch": 1.8837316176470589,
      "grad_norm": 0.9404012560844421,
      "learning_rate": 6.927083333333334e-06,
      "loss": 0.0454,
      "step": 8198
    },
    {
      "epoch": 1.8839613970588234,
      "grad_norm": 0.8897036910057068,
      "learning_rate": 6.926572712418301e-06,
      "loss": 0.0567,
      "step": 8199
    },
    {
      "epoch": 1.8841911764705883,
      "grad_norm": 0.7243210673332214,
      "learning_rate": 6.926062091503268e-06,
      "loss": 0.0459,
      "step": 8200
    },
    {
      "epoch": 1.8844209558823528,
      "grad_norm": 0.811525285243988,
      "learning_rate": 6.925551470588235e-06,
      "loss": 0.0372,
      "step": 8201
    },
    {
      "epoch": 1.8846507352941178,
      "grad_norm": 0.9667167067527771,
      "learning_rate": 6.925040849673203e-06,
      "loss": 0.0441,
      "step": 8202
    },
    {
      "epoch": 1.8848805147058822,
      "grad_norm": 1.2458313703536987,
      "learning_rate": 6.92453022875817e-06,
      "loss": 0.0595,
      "step": 8203
    },
    {
      "epoch": 1.8851102941176472,
      "grad_norm": 0.8043097853660583,
      "learning_rate": 6.924019607843138e-06,
      "loss": 0.0388,
      "step": 8204
    },
    {
      "epoch": 1.8853400735294117,
      "grad_norm": 1.1794910430908203,
      "learning_rate": 6.923508986928105e-06,
      "loss": 0.0578,
      "step": 8205
    },
    {
      "epoch": 1.8855698529411766,
      "grad_norm": 0.8641535639762878,
      "learning_rate": 6.922998366013073e-06,
      "loss": 0.0426,
      "step": 8206
    },
    {
      "epoch": 1.8857996323529411,
      "grad_norm": 1.3218836784362793,
      "learning_rate": 6.92248774509804e-06,
      "loss": 0.0537,
      "step": 8207
    },
    {
      "epoch": 1.8860294117647058,
      "grad_norm": 1.1748087406158447,
      "learning_rate": 6.921977124183007e-06,
      "loss": 0.055,
      "step": 8208
    },
    {
      "epoch": 1.8862591911764706,
      "grad_norm": 0.7281433939933777,
      "learning_rate": 6.921466503267974e-06,
      "loss": 0.0213,
      "step": 8209
    },
    {
      "epoch": 1.8864889705882353,
      "grad_norm": 0.838988721370697,
      "learning_rate": 6.920955882352942e-06,
      "loss": 0.0485,
      "step": 8210
    },
    {
      "epoch": 1.88671875,
      "grad_norm": 0.9116144776344299,
      "learning_rate": 6.920445261437909e-06,
      "loss": 0.0509,
      "step": 8211
    },
    {
      "epoch": 1.8869485294117647,
      "grad_norm": 1.059518814086914,
      "learning_rate": 6.919934640522876e-06,
      "loss": 0.0534,
      "step": 8212
    },
    {
      "epoch": 1.8871783088235294,
      "grad_norm": 0.9384105801582336,
      "learning_rate": 6.919424019607843e-06,
      "loss": 0.0439,
      "step": 8213
    },
    {
      "epoch": 1.8874080882352942,
      "grad_norm": 1.1627177000045776,
      "learning_rate": 6.918913398692812e-06,
      "loss": 0.0734,
      "step": 8214
    },
    {
      "epoch": 1.8876378676470589,
      "grad_norm": 0.9144348502159119,
      "learning_rate": 6.918402777777779e-06,
      "loss": 0.0391,
      "step": 8215
    },
    {
      "epoch": 1.8878676470588234,
      "grad_norm": 0.9337173700332642,
      "learning_rate": 6.917892156862746e-06,
      "loss": 0.0431,
      "step": 8216
    },
    {
      "epoch": 1.8880974264705883,
      "grad_norm": 1.1950509548187256,
      "learning_rate": 6.917381535947713e-06,
      "loss": 0.0733,
      "step": 8217
    },
    {
      "epoch": 1.8883272058823528,
      "grad_norm": 1.6083250045776367,
      "learning_rate": 6.9168709150326805e-06,
      "loss": 0.0562,
      "step": 8218
    },
    {
      "epoch": 1.8885569852941178,
      "grad_norm": 0.6177859902381897,
      "learning_rate": 6.9163602941176475e-06,
      "loss": 0.0258,
      "step": 8219
    },
    {
      "epoch": 1.8887867647058822,
      "grad_norm": 1.0809415578842163,
      "learning_rate": 6.9158496732026145e-06,
      "loss": 0.0591,
      "step": 8220
    },
    {
      "epoch": 1.8890165441176472,
      "grad_norm": 0.7870793342590332,
      "learning_rate": 6.9153390522875815e-06,
      "loss": 0.0347,
      "step": 8221
    },
    {
      "epoch": 1.8892463235294117,
      "grad_norm": 1.4241676330566406,
      "learning_rate": 6.91482843137255e-06,
      "loss": 0.0411,
      "step": 8222
    },
    {
      "epoch": 1.8894761029411766,
      "grad_norm": 1.1476376056671143,
      "learning_rate": 6.914317810457517e-06,
      "loss": 0.0661,
      "step": 8223
    },
    {
      "epoch": 1.8897058823529411,
      "grad_norm": 0.9168469905853271,
      "learning_rate": 6.913807189542484e-06,
      "loss": 0.0685,
      "step": 8224
    },
    {
      "epoch": 1.8899356617647058,
      "grad_norm": 1.1021510362625122,
      "learning_rate": 6.913296568627451e-06,
      "loss": 0.0607,
      "step": 8225
    },
    {
      "epoch": 1.8901654411764706,
      "grad_norm": 0.9248837232589722,
      "learning_rate": 6.912785947712419e-06,
      "loss": 0.0501,
      "step": 8226
    },
    {
      "epoch": 1.8903952205882353,
      "grad_norm": 0.9904188513755798,
      "learning_rate": 6.912275326797386e-06,
      "loss": 0.0555,
      "step": 8227
    },
    {
      "epoch": 1.890625,
      "grad_norm": 1.0516656637191772,
      "learning_rate": 6.911764705882353e-06,
      "loss": 0.0512,
      "step": 8228
    },
    {
      "epoch": 1.8908547794117647,
      "grad_norm": 0.8472387194633484,
      "learning_rate": 6.91125408496732e-06,
      "loss": 0.0385,
      "step": 8229
    },
    {
      "epoch": 1.8910845588235294,
      "grad_norm": 1.3587700128555298,
      "learning_rate": 6.910743464052289e-06,
      "loss": 0.0723,
      "step": 8230
    },
    {
      "epoch": 1.8913143382352942,
      "grad_norm": 1.262252688407898,
      "learning_rate": 6.910232843137256e-06,
      "loss": 0.0933,
      "step": 8231
    },
    {
      "epoch": 1.8915441176470589,
      "grad_norm": 1.2829617261886597,
      "learning_rate": 6.909722222222223e-06,
      "loss": 0.0642,
      "step": 8232
    },
    {
      "epoch": 1.8917738970588234,
      "grad_norm": 1.2493219375610352,
      "learning_rate": 6.90921160130719e-06,
      "loss": 0.0667,
      "step": 8233
    },
    {
      "epoch": 1.8920036764705883,
      "grad_norm": 0.8356488943099976,
      "learning_rate": 6.908700980392158e-06,
      "loss": 0.0519,
      "step": 8234
    },
    {
      "epoch": 1.8922334558823528,
      "grad_norm": 1.0990175008773804,
      "learning_rate": 6.908190359477125e-06,
      "loss": 0.0473,
      "step": 8235
    },
    {
      "epoch": 1.8924632352941178,
      "grad_norm": 0.7515425682067871,
      "learning_rate": 6.907679738562092e-06,
      "loss": 0.0403,
      "step": 8236
    },
    {
      "epoch": 1.8926930147058822,
      "grad_norm": 1.0128132104873657,
      "learning_rate": 6.907169117647059e-06,
      "loss": 0.0401,
      "step": 8237
    },
    {
      "epoch": 1.8929227941176472,
      "grad_norm": 1.0025792121887207,
      "learning_rate": 6.9066584967320276e-06,
      "loss": 0.0425,
      "step": 8238
    },
    {
      "epoch": 1.8931525735294117,
      "grad_norm": 0.9859127998352051,
      "learning_rate": 6.906147875816995e-06,
      "loss": 0.0467,
      "step": 8239
    },
    {
      "epoch": 1.8933823529411766,
      "grad_norm": 0.8519598841667175,
      "learning_rate": 6.905637254901962e-06,
      "loss": 0.0558,
      "step": 8240
    },
    {
      "epoch": 1.8936121323529411,
      "grad_norm": 0.8387136459350586,
      "learning_rate": 6.905126633986929e-06,
      "loss": 0.048,
      "step": 8241
    },
    {
      "epoch": 1.8938419117647058,
      "grad_norm": 0.71226966381073,
      "learning_rate": 6.9046160130718965e-06,
      "loss": 0.0396,
      "step": 8242
    },
    {
      "epoch": 1.8940716911764706,
      "grad_norm": 0.7740054130554199,
      "learning_rate": 6.9041053921568635e-06,
      "loss": 0.038,
      "step": 8243
    },
    {
      "epoch": 1.8943014705882353,
      "grad_norm": 0.9708760380744934,
      "learning_rate": 6.9035947712418305e-06,
      "loss": 0.045,
      "step": 8244
    },
    {
      "epoch": 1.89453125,
      "grad_norm": 0.9958232641220093,
      "learning_rate": 6.9030841503267975e-06,
      "loss": 0.0689,
      "step": 8245
    },
    {
      "epoch": 1.8947610294117647,
      "grad_norm": 0.6943348050117493,
      "learning_rate": 6.902573529411765e-06,
      "loss": 0.0399,
      "step": 8246
    },
    {
      "epoch": 1.8949908088235294,
      "grad_norm": 0.8592974543571472,
      "learning_rate": 6.902062908496732e-06,
      "loss": 0.0431,
      "step": 8247
    },
    {
      "epoch": 1.8952205882352942,
      "grad_norm": 0.9529760479927063,
      "learning_rate": 6.901552287581699e-06,
      "loss": 0.0437,
      "step": 8248
    },
    {
      "epoch": 1.8954503676470589,
      "grad_norm": 0.866178572177887,
      "learning_rate": 6.901041666666667e-06,
      "loss": 0.0514,
      "step": 8249
    },
    {
      "epoch": 1.8956801470588234,
      "grad_norm": 0.8165878653526306,
      "learning_rate": 6.900531045751635e-06,
      "loss": 0.0416,
      "step": 8250
    },
    {
      "epoch": 1.8959099264705883,
      "grad_norm": 0.7604138851165771,
      "learning_rate": 6.900020424836602e-06,
      "loss": 0.044,
      "step": 8251
    },
    {
      "epoch": 1.8961397058823528,
      "grad_norm": 0.8107414841651917,
      "learning_rate": 6.899509803921569e-06,
      "loss": 0.0347,
      "step": 8252
    },
    {
      "epoch": 1.8963694852941178,
      "grad_norm": 1.1288622617721558,
      "learning_rate": 6.898999183006536e-06,
      "loss": 0.049,
      "step": 8253
    },
    {
      "epoch": 1.8965992647058822,
      "grad_norm": 0.9740338921546936,
      "learning_rate": 6.898488562091504e-06,
      "loss": 0.0642,
      "step": 8254
    },
    {
      "epoch": 1.8968290441176472,
      "grad_norm": 1.0308839082717896,
      "learning_rate": 6.897977941176471e-06,
      "loss": 0.069,
      "step": 8255
    },
    {
      "epoch": 1.8970588235294117,
      "grad_norm": 1.1505494117736816,
      "learning_rate": 6.897467320261438e-06,
      "loss": 0.054,
      "step": 8256
    },
    {
      "epoch": 1.8972886029411766,
      "grad_norm": 1.0550668239593506,
      "learning_rate": 6.896956699346405e-06,
      "loss": 0.0554,
      "step": 8257
    },
    {
      "epoch": 1.8975183823529411,
      "grad_norm": 1.181362509727478,
      "learning_rate": 6.896446078431374e-06,
      "loss": 0.0648,
      "step": 8258
    },
    {
      "epoch": 1.8977481617647058,
      "grad_norm": 1.0557525157928467,
      "learning_rate": 6.895935457516341e-06,
      "loss": 0.0513,
      "step": 8259
    },
    {
      "epoch": 1.8979779411764706,
      "grad_norm": 1.0724047422409058,
      "learning_rate": 6.895424836601308e-06,
      "loss": 0.0421,
      "step": 8260
    },
    {
      "epoch": 1.8982077205882353,
      "grad_norm": 0.967316746711731,
      "learning_rate": 6.894914215686275e-06,
      "loss": 0.0586,
      "step": 8261
    },
    {
      "epoch": 1.8984375,
      "grad_norm": 0.9241724610328674,
      "learning_rate": 6.894403594771243e-06,
      "loss": 0.0432,
      "step": 8262
    },
    {
      "epoch": 1.8986672794117647,
      "grad_norm": 0.9753797650337219,
      "learning_rate": 6.89389297385621e-06,
      "loss": 0.0624,
      "step": 8263
    },
    {
      "epoch": 1.8988970588235294,
      "grad_norm": 1.080030918121338,
      "learning_rate": 6.893382352941177e-06,
      "loss": 0.0537,
      "step": 8264
    },
    {
      "epoch": 1.8991268382352942,
      "grad_norm": 0.839055061340332,
      "learning_rate": 6.892871732026144e-06,
      "loss": 0.0449,
      "step": 8265
    },
    {
      "epoch": 1.8993566176470589,
      "grad_norm": 1.038610816001892,
      "learning_rate": 6.8923611111111124e-06,
      "loss": 0.0536,
      "step": 8266
    },
    {
      "epoch": 1.8995863970588234,
      "grad_norm": 0.8939616084098816,
      "learning_rate": 6.8918504901960795e-06,
      "loss": 0.0321,
      "step": 8267
    },
    {
      "epoch": 1.8998161764705883,
      "grad_norm": 0.9978185296058655,
      "learning_rate": 6.8913398692810465e-06,
      "loss": 0.0495,
      "step": 8268
    },
    {
      "epoch": 1.9000459558823528,
      "grad_norm": 1.0384148359298706,
      "learning_rate": 6.8908292483660135e-06,
      "loss": 0.0594,
      "step": 8269
    },
    {
      "epoch": 1.9002757352941178,
      "grad_norm": 1.0879709720611572,
      "learning_rate": 6.890318627450981e-06,
      "loss": 0.0548,
      "step": 8270
    },
    {
      "epoch": 1.9005055147058822,
      "grad_norm": 1.4605787992477417,
      "learning_rate": 6.889808006535948e-06,
      "loss": 0.0749,
      "step": 8271
    },
    {
      "epoch": 1.9007352941176472,
      "grad_norm": 0.976929247379303,
      "learning_rate": 6.889297385620915e-06,
      "loss": 0.0532,
      "step": 8272
    },
    {
      "epoch": 1.9009650735294117,
      "grad_norm": 0.8493947982788086,
      "learning_rate": 6.888786764705882e-06,
      "loss": 0.0373,
      "step": 8273
    },
    {
      "epoch": 1.9011948529411766,
      "grad_norm": 1.3388316631317139,
      "learning_rate": 6.888276143790851e-06,
      "loss": 0.044,
      "step": 8274
    },
    {
      "epoch": 1.9014246323529411,
      "grad_norm": 1.1996983289718628,
      "learning_rate": 6.887765522875818e-06,
      "loss": 0.0556,
      "step": 8275
    },
    {
      "epoch": 1.9016544117647058,
      "grad_norm": 0.9788912534713745,
      "learning_rate": 6.887254901960785e-06,
      "loss": 0.0609,
      "step": 8276
    },
    {
      "epoch": 1.9018841911764706,
      "grad_norm": 0.8148812055587769,
      "learning_rate": 6.886744281045752e-06,
      "loss": 0.0354,
      "step": 8277
    },
    {
      "epoch": 1.9021139705882353,
      "grad_norm": 0.9198800921440125,
      "learning_rate": 6.88623366013072e-06,
      "loss": 0.0461,
      "step": 8278
    },
    {
      "epoch": 1.90234375,
      "grad_norm": 0.8712879419326782,
      "learning_rate": 6.885723039215687e-06,
      "loss": 0.0536,
      "step": 8279
    },
    {
      "epoch": 1.9025735294117647,
      "grad_norm": 0.6914812326431274,
      "learning_rate": 6.885212418300654e-06,
      "loss": 0.0413,
      "step": 8280
    },
    {
      "epoch": 1.9028033088235294,
      "grad_norm": 0.773995578289032,
      "learning_rate": 6.884701797385621e-06,
      "loss": 0.0357,
      "step": 8281
    },
    {
      "epoch": 1.9030330882352942,
      "grad_norm": 0.7922443151473999,
      "learning_rate": 6.884191176470589e-06,
      "loss": 0.038,
      "step": 8282
    },
    {
      "epoch": 1.9032628676470589,
      "grad_norm": 0.9937137365341187,
      "learning_rate": 6.883680555555557e-06,
      "loss": 0.0425,
      "step": 8283
    },
    {
      "epoch": 1.9034926470588234,
      "grad_norm": 1.155308723449707,
      "learning_rate": 6.883169934640524e-06,
      "loss": 0.0634,
      "step": 8284
    },
    {
      "epoch": 1.9037224264705883,
      "grad_norm": 0.8784636855125427,
      "learning_rate": 6.882659313725491e-06,
      "loss": 0.0377,
      "step": 8285
    },
    {
      "epoch": 1.9039522058823528,
      "grad_norm": 0.9688299298286438,
      "learning_rate": 6.882148692810459e-06,
      "loss": 0.0367,
      "step": 8286
    },
    {
      "epoch": 1.9041819852941178,
      "grad_norm": 0.8734090328216553,
      "learning_rate": 6.881638071895426e-06,
      "loss": 0.0593,
      "step": 8287
    },
    {
      "epoch": 1.9044117647058822,
      "grad_norm": 1.0872434377670288,
      "learning_rate": 6.881127450980393e-06,
      "loss": 0.0724,
      "step": 8288
    },
    {
      "epoch": 1.9046415441176472,
      "grad_norm": 0.6091124415397644,
      "learning_rate": 6.88061683006536e-06,
      "loss": 0.0263,
      "step": 8289
    },
    {
      "epoch": 1.9048713235294117,
      "grad_norm": 0.9866064190864563,
      "learning_rate": 6.8801062091503276e-06,
      "loss": 0.0459,
      "step": 8290
    },
    {
      "epoch": 1.9051011029411766,
      "grad_norm": 1.1466635465621948,
      "learning_rate": 6.8795955882352946e-06,
      "loss": 0.0674,
      "step": 8291
    },
    {
      "epoch": 1.9053308823529411,
      "grad_norm": 0.7606931924819946,
      "learning_rate": 6.879084967320262e-06,
      "loss": 0.0417,
      "step": 8292
    },
    {
      "epoch": 1.9055606617647058,
      "grad_norm": 1.408203125,
      "learning_rate": 6.8785743464052294e-06,
      "loss": 0.0501,
      "step": 8293
    },
    {
      "epoch": 1.9057904411764706,
      "grad_norm": 0.9564959406852722,
      "learning_rate": 6.878063725490197e-06,
      "loss": 0.0531,
      "step": 8294
    },
    {
      "epoch": 1.9060202205882353,
      "grad_norm": 0.9148514270782471,
      "learning_rate": 6.877553104575164e-06,
      "loss": 0.0426,
      "step": 8295
    },
    {
      "epoch": 1.90625,
      "grad_norm": 0.6896015405654907,
      "learning_rate": 6.877042483660131e-06,
      "loss": 0.0225,
      "step": 8296
    },
    {
      "epoch": 1.9064797794117647,
      "grad_norm": 4.381775856018066,
      "learning_rate": 6.876531862745098e-06,
      "loss": 0.0651,
      "step": 8297
    },
    {
      "epoch": 1.9067095588235294,
      "grad_norm": 1.2552465200424194,
      "learning_rate": 6.876021241830066e-06,
      "loss": 0.0713,
      "step": 8298
    },
    {
      "epoch": 1.9069393382352942,
      "grad_norm": 1.1793746948242188,
      "learning_rate": 6.875510620915033e-06,
      "loss": 0.0645,
      "step": 8299
    },
    {
      "epoch": 1.9071691176470589,
      "grad_norm": 0.8784546256065369,
      "learning_rate": 6.875e-06,
      "loss": 0.0459,
      "step": 8300
    },
    {
      "epoch": 1.9073988970588234,
      "grad_norm": 1.0164859294891357,
      "learning_rate": 6.874489379084967e-06,
      "loss": 0.055,
      "step": 8301
    },
    {
      "epoch": 1.9076286764705883,
      "grad_norm": 0.6554094552993774,
      "learning_rate": 6.873978758169934e-06,
      "loss": 0.0295,
      "step": 8302
    },
    {
      "epoch": 1.9078584558823528,
      "grad_norm": 0.8028455972671509,
      "learning_rate": 6.873468137254903e-06,
      "loss": 0.0376,
      "step": 8303
    },
    {
      "epoch": 1.9080882352941178,
      "grad_norm": 0.8717551231384277,
      "learning_rate": 6.87295751633987e-06,
      "loss": 0.0324,
      "step": 8304
    },
    {
      "epoch": 1.9083180147058822,
      "grad_norm": 1.1728515625,
      "learning_rate": 6.872446895424837e-06,
      "loss": 0.058,
      "step": 8305
    },
    {
      "epoch": 1.9085477941176472,
      "grad_norm": 0.9750918745994568,
      "learning_rate": 6.871936274509804e-06,
      "loss": 0.0506,
      "step": 8306
    },
    {
      "epoch": 1.9087775735294117,
      "grad_norm": 0.7317628264427185,
      "learning_rate": 6.871425653594772e-06,
      "loss": 0.0302,
      "step": 8307
    },
    {
      "epoch": 1.9090073529411766,
      "grad_norm": 1.054639458656311,
      "learning_rate": 6.870915032679739e-06,
      "loss": 0.047,
      "step": 8308
    },
    {
      "epoch": 1.9092371323529411,
      "grad_norm": 0.8735601305961609,
      "learning_rate": 6.870404411764706e-06,
      "loss": 0.0367,
      "step": 8309
    },
    {
      "epoch": 1.9094669117647058,
      "grad_norm": 1.007912516593933,
      "learning_rate": 6.869893790849673e-06,
      "loss": 0.0457,
      "step": 8310
    },
    {
      "epoch": 1.9096966911764706,
      "grad_norm": 1.199654459953308,
      "learning_rate": 6.869383169934642e-06,
      "loss": 0.0644,
      "step": 8311
    },
    {
      "epoch": 1.9099264705882353,
      "grad_norm": 1.0683714151382446,
      "learning_rate": 6.868872549019609e-06,
      "loss": 0.0379,
      "step": 8312
    },
    {
      "epoch": 1.91015625,
      "grad_norm": 1.2558350563049316,
      "learning_rate": 6.868361928104576e-06,
      "loss": 0.0827,
      "step": 8313
    },
    {
      "epoch": 1.9103860294117647,
      "grad_norm": 0.8353956341743469,
      "learning_rate": 6.867851307189543e-06,
      "loss": 0.0562,
      "step": 8314
    },
    {
      "epoch": 1.9106158088235294,
      "grad_norm": 1.0270345211029053,
      "learning_rate": 6.8673406862745105e-06,
      "loss": 0.0485,
      "step": 8315
    },
    {
      "epoch": 1.9108455882352942,
      "grad_norm": 1.2338283061981201,
      "learning_rate": 6.8668300653594776e-06,
      "loss": 0.0733,
      "step": 8316
    },
    {
      "epoch": 1.9110753676470589,
      "grad_norm": 0.8163142800331116,
      "learning_rate": 6.8663194444444446e-06,
      "loss": 0.0292,
      "step": 8317
    },
    {
      "epoch": 1.9113051470588234,
      "grad_norm": 0.7683039307594299,
      "learning_rate": 6.865808823529412e-06,
      "loss": 0.0403,
      "step": 8318
    },
    {
      "epoch": 1.9115349264705883,
      "grad_norm": 0.8414280414581299,
      "learning_rate": 6.86529820261438e-06,
      "loss": 0.0538,
      "step": 8319
    },
    {
      "epoch": 1.9117647058823528,
      "grad_norm": 0.7056645750999451,
      "learning_rate": 6.864787581699347e-06,
      "loss": 0.0281,
      "step": 8320
    },
    {
      "epoch": 1.9119944852941178,
      "grad_norm": 0.8259775638580322,
      "learning_rate": 6.864276960784314e-06,
      "loss": 0.0448,
      "step": 8321
    },
    {
      "epoch": 1.9122242647058822,
      "grad_norm": 0.8744134306907654,
      "learning_rate": 6.863766339869281e-06,
      "loss": 0.0387,
      "step": 8322
    },
    {
      "epoch": 1.9124540441176472,
      "grad_norm": 0.9962974190711975,
      "learning_rate": 6.863255718954249e-06,
      "loss": 0.0467,
      "step": 8323
    },
    {
      "epoch": 1.9126838235294117,
      "grad_norm": 0.9619022607803345,
      "learning_rate": 6.862745098039216e-06,
      "loss": 0.0464,
      "step": 8324
    },
    {
      "epoch": 1.9129136029411766,
      "grad_norm": 0.8444048166275024,
      "learning_rate": 6.862234477124183e-06,
      "loss": 0.0444,
      "step": 8325
    },
    {
      "epoch": 1.9131433823529411,
      "grad_norm": 0.8228796124458313,
      "learning_rate": 6.86172385620915e-06,
      "loss": 0.0464,
      "step": 8326
    },
    {
      "epoch": 1.9133731617647058,
      "grad_norm": 0.9414681196212769,
      "learning_rate": 6.861213235294119e-06,
      "loss": 0.0414,
      "step": 8327
    },
    {
      "epoch": 1.9136029411764706,
      "grad_norm": 1.2986164093017578,
      "learning_rate": 6.860702614379086e-06,
      "loss": 0.05,
      "step": 8328
    },
    {
      "epoch": 1.9138327205882353,
      "grad_norm": 1.041014552116394,
      "learning_rate": 6.860191993464053e-06,
      "loss": 0.0631,
      "step": 8329
    },
    {
      "epoch": 1.9140625,
      "grad_norm": 0.716367781162262,
      "learning_rate": 6.85968137254902e-06,
      "loss": 0.0424,
      "step": 8330
    },
    {
      "epoch": 1.9142922794117647,
      "grad_norm": 1.2931405305862427,
      "learning_rate": 6.859170751633988e-06,
      "loss": 0.0505,
      "step": 8331
    },
    {
      "epoch": 1.9145220588235294,
      "grad_norm": 0.916348934173584,
      "learning_rate": 6.858660130718955e-06,
      "loss": 0.0471,
      "step": 8332
    },
    {
      "epoch": 1.9147518382352942,
      "grad_norm": 0.7108543515205383,
      "learning_rate": 6.858149509803922e-06,
      "loss": 0.0299,
      "step": 8333
    },
    {
      "epoch": 1.9149816176470589,
      "grad_norm": 0.8456127643585205,
      "learning_rate": 6.857638888888889e-06,
      "loss": 0.0389,
      "step": 8334
    },
    {
      "epoch": 1.9152113970588234,
      "grad_norm": 0.9728172421455383,
      "learning_rate": 6.857128267973857e-06,
      "loss": 0.0413,
      "step": 8335
    },
    {
      "epoch": 1.9154411764705883,
      "grad_norm": 0.7718210220336914,
      "learning_rate": 6.856617647058824e-06,
      "loss": 0.0293,
      "step": 8336
    },
    {
      "epoch": 1.9156709558823528,
      "grad_norm": 1.1460239887237549,
      "learning_rate": 6.856107026143791e-06,
      "loss": 0.0589,
      "step": 8337
    },
    {
      "epoch": 1.9159007352941178,
      "grad_norm": 0.881442666053772,
      "learning_rate": 6.855596405228759e-06,
      "loss": 0.0562,
      "step": 8338
    },
    {
      "epoch": 1.9161305147058822,
      "grad_norm": 0.830710232257843,
      "learning_rate": 6.8550857843137265e-06,
      "loss": 0.0422,
      "step": 8339
    },
    {
      "epoch": 1.9163602941176472,
      "grad_norm": 0.9582630395889282,
      "learning_rate": 6.8545751633986935e-06,
      "loss": 0.0499,
      "step": 8340
    },
    {
      "epoch": 1.9165900735294117,
      "grad_norm": 0.6088505983352661,
      "learning_rate": 6.8540645424836605e-06,
      "loss": 0.0251,
      "step": 8341
    },
    {
      "epoch": 1.9168198529411766,
      "grad_norm": 1.0819861888885498,
      "learning_rate": 6.8535539215686276e-06,
      "loss": 0.0859,
      "step": 8342
    },
    {
      "epoch": 1.9170496323529411,
      "grad_norm": 1.4567084312438965,
      "learning_rate": 6.853043300653595e-06,
      "loss": 0.0552,
      "step": 8343
    },
    {
      "epoch": 1.9172794117647058,
      "grad_norm": 1.0200740098953247,
      "learning_rate": 6.8525326797385624e-06,
      "loss": 0.055,
      "step": 8344
    },
    {
      "epoch": 1.9175091911764706,
      "grad_norm": 0.7241349220275879,
      "learning_rate": 6.8520220588235294e-06,
      "loss": 0.0415,
      "step": 8345
    },
    {
      "epoch": 1.9177389705882353,
      "grad_norm": 1.0484659671783447,
      "learning_rate": 6.8515114379084965e-06,
      "loss": 0.0354,
      "step": 8346
    },
    {
      "epoch": 1.91796875,
      "grad_norm": 1.1491236686706543,
      "learning_rate": 6.851000816993465e-06,
      "loss": 0.0712,
      "step": 8347
    },
    {
      "epoch": 1.9181985294117647,
      "grad_norm": 0.9827101826667786,
      "learning_rate": 6.850490196078432e-06,
      "loss": 0.037,
      "step": 8348
    },
    {
      "epoch": 1.9184283088235294,
      "grad_norm": 1.0801910161972046,
      "learning_rate": 6.849979575163399e-06,
      "loss": 0.0541,
      "step": 8349
    },
    {
      "epoch": 1.9186580882352942,
      "grad_norm": 0.7688566446304321,
      "learning_rate": 6.849468954248366e-06,
      "loss": 0.0391,
      "step": 8350
    },
    {
      "epoch": 1.9188878676470589,
      "grad_norm": 0.8135952353477478,
      "learning_rate": 6.848958333333334e-06,
      "loss": 0.0568,
      "step": 8351
    },
    {
      "epoch": 1.9191176470588234,
      "grad_norm": 1.0733721256256104,
      "learning_rate": 6.848447712418301e-06,
      "loss": 0.0455,
      "step": 8352
    },
    {
      "epoch": 1.9193474264705883,
      "grad_norm": 1.079986810684204,
      "learning_rate": 6.847937091503268e-06,
      "loss": 0.0472,
      "step": 8353
    },
    {
      "epoch": 1.9195772058823528,
      "grad_norm": 0.7029948234558105,
      "learning_rate": 6.847426470588235e-06,
      "loss": 0.0347,
      "step": 8354
    },
    {
      "epoch": 1.9198069852941178,
      "grad_norm": 0.7561583518981934,
      "learning_rate": 6.846915849673204e-06,
      "loss": 0.0396,
      "step": 8355
    },
    {
      "epoch": 1.9200367647058822,
      "grad_norm": 1.0404245853424072,
      "learning_rate": 6.846405228758171e-06,
      "loss": 0.0546,
      "step": 8356
    },
    {
      "epoch": 1.9202665441176472,
      "grad_norm": 0.9232419729232788,
      "learning_rate": 6.845894607843138e-06,
      "loss": 0.0706,
      "step": 8357
    },
    {
      "epoch": 1.9204963235294117,
      "grad_norm": 1.37714684009552,
      "learning_rate": 6.845383986928105e-06,
      "loss": 0.0668,
      "step": 8358
    },
    {
      "epoch": 1.9207261029411766,
      "grad_norm": 1.0347775220870972,
      "learning_rate": 6.844873366013073e-06,
      "loss": 0.051,
      "step": 8359
    },
    {
      "epoch": 1.9209558823529411,
      "grad_norm": 1.1892889738082886,
      "learning_rate": 6.84436274509804e-06,
      "loss": 0.0608,
      "step": 8360
    },
    {
      "epoch": 1.9211856617647058,
      "grad_norm": 0.873908281326294,
      "learning_rate": 6.843852124183007e-06,
      "loss": 0.037,
      "step": 8361
    },
    {
      "epoch": 1.9214154411764706,
      "grad_norm": 1.360630989074707,
      "learning_rate": 6.843341503267974e-06,
      "loss": 0.0659,
      "step": 8362
    },
    {
      "epoch": 1.9216452205882353,
      "grad_norm": 0.9768651127815247,
      "learning_rate": 6.8428308823529425e-06,
      "loss": 0.0538,
      "step": 8363
    },
    {
      "epoch": 1.921875,
      "grad_norm": 1.2791788578033447,
      "learning_rate": 6.8423202614379095e-06,
      "loss": 0.0846,
      "step": 8364
    },
    {
      "epoch": 1.9221047794117647,
      "grad_norm": 0.9694090485572815,
      "learning_rate": 6.8418096405228765e-06,
      "loss": 0.0427,
      "step": 8365
    },
    {
      "epoch": 1.9223345588235294,
      "grad_norm": 0.8871819972991943,
      "learning_rate": 6.8412990196078435e-06,
      "loss": 0.0565,
      "step": 8366
    },
    {
      "epoch": 1.9225643382352942,
      "grad_norm": 1.8560779094696045,
      "learning_rate": 6.840788398692811e-06,
      "loss": 0.0683,
      "step": 8367
    },
    {
      "epoch": 1.9227941176470589,
      "grad_norm": 1.026212453842163,
      "learning_rate": 6.840277777777778e-06,
      "loss": 0.0645,
      "step": 8368
    },
    {
      "epoch": 1.9230238970588234,
      "grad_norm": 0.6947993636131287,
      "learning_rate": 6.839767156862745e-06,
      "loss": 0.0276,
      "step": 8369
    },
    {
      "epoch": 1.9232536764705883,
      "grad_norm": 1.1336833238601685,
      "learning_rate": 6.8392565359477124e-06,
      "loss": 0.0542,
      "step": 8370
    },
    {
      "epoch": 1.9234834558823528,
      "grad_norm": 0.7229401469230652,
      "learning_rate": 6.83874591503268e-06,
      "loss": 0.0306,
      "step": 8371
    },
    {
      "epoch": 1.9237132352941178,
      "grad_norm": 0.7438598275184631,
      "learning_rate": 6.838235294117648e-06,
      "loss": 0.0297,
      "step": 8372
    },
    {
      "epoch": 1.9239430147058822,
      "grad_norm": 1.2388371229171753,
      "learning_rate": 6.837724673202615e-06,
      "loss": 0.045,
      "step": 8373
    },
    {
      "epoch": 1.9241727941176472,
      "grad_norm": 0.6436634063720703,
      "learning_rate": 6.837214052287582e-06,
      "loss": 0.0259,
      "step": 8374
    },
    {
      "epoch": 1.9244025735294117,
      "grad_norm": 1.1584665775299072,
      "learning_rate": 6.83670343137255e-06,
      "loss": 0.0561,
      "step": 8375
    },
    {
      "epoch": 1.9246323529411766,
      "grad_norm": 1.0137124061584473,
      "learning_rate": 6.836192810457517e-06,
      "loss": 0.0398,
      "step": 8376
    },
    {
      "epoch": 1.9248621323529411,
      "grad_norm": 1.0769487619400024,
      "learning_rate": 6.835682189542484e-06,
      "loss": 0.0508,
      "step": 8377
    },
    {
      "epoch": 1.9250919117647058,
      "grad_norm": 0.6336116194725037,
      "learning_rate": 6.835171568627451e-06,
      "loss": 0.0325,
      "step": 8378
    },
    {
      "epoch": 1.9253216911764706,
      "grad_norm": 0.9555951952934265,
      "learning_rate": 6.834660947712419e-06,
      "loss": 0.0548,
      "step": 8379
    },
    {
      "epoch": 1.9255514705882353,
      "grad_norm": 1.0032058954238892,
      "learning_rate": 6.834150326797386e-06,
      "loss": 0.0527,
      "step": 8380
    },
    {
      "epoch": 1.92578125,
      "grad_norm": 0.9073395133018494,
      "learning_rate": 6.833639705882353e-06,
      "loss": 0.0282,
      "step": 8381
    },
    {
      "epoch": 1.9260110294117647,
      "grad_norm": 0.9957796931266785,
      "learning_rate": 6.83312908496732e-06,
      "loss": 0.0724,
      "step": 8382
    },
    {
      "epoch": 1.9262408088235294,
      "grad_norm": 1.0236701965332031,
      "learning_rate": 6.832618464052289e-06,
      "loss": 0.0573,
      "step": 8383
    },
    {
      "epoch": 1.9264705882352942,
      "grad_norm": 0.9857674837112427,
      "learning_rate": 6.832107843137256e-06,
      "loss": 0.0526,
      "step": 8384
    },
    {
      "epoch": 1.9267003676470589,
      "grad_norm": 0.9052058458328247,
      "learning_rate": 6.831597222222223e-06,
      "loss": 0.0426,
      "step": 8385
    },
    {
      "epoch": 1.9269301470588234,
      "grad_norm": 0.9521511793136597,
      "learning_rate": 6.83108660130719e-06,
      "loss": 0.0712,
      "step": 8386
    },
    {
      "epoch": 1.9271599264705883,
      "grad_norm": 1.302156925201416,
      "learning_rate": 6.830575980392158e-06,
      "loss": 0.0445,
      "step": 8387
    },
    {
      "epoch": 1.9273897058823528,
      "grad_norm": 0.7489489912986755,
      "learning_rate": 6.830065359477125e-06,
      "loss": 0.0347,
      "step": 8388
    },
    {
      "epoch": 1.9276194852941178,
      "grad_norm": 0.9249759912490845,
      "learning_rate": 6.829554738562092e-06,
      "loss": 0.0437,
      "step": 8389
    },
    {
      "epoch": 1.9278492647058822,
      "grad_norm": 0.9317838549613953,
      "learning_rate": 6.829044117647059e-06,
      "loss": 0.041,
      "step": 8390
    },
    {
      "epoch": 1.9280790441176472,
      "grad_norm": 0.737902820110321,
      "learning_rate": 6.828533496732027e-06,
      "loss": 0.0354,
      "step": 8391
    },
    {
      "epoch": 1.9283088235294117,
      "grad_norm": 1.2528903484344482,
      "learning_rate": 6.828022875816994e-06,
      "loss": 0.0714,
      "step": 8392
    },
    {
      "epoch": 1.9285386029411766,
      "grad_norm": 0.793871283531189,
      "learning_rate": 6.827512254901961e-06,
      "loss": 0.0343,
      "step": 8393
    },
    {
      "epoch": 1.9287683823529411,
      "grad_norm": 0.9896767139434814,
      "learning_rate": 6.827001633986928e-06,
      "loss": 0.0307,
      "step": 8394
    },
    {
      "epoch": 1.9289981617647058,
      "grad_norm": 1.1038744449615479,
      "learning_rate": 6.826491013071896e-06,
      "loss": 0.063,
      "step": 8395
    },
    {
      "epoch": 1.9292279411764706,
      "grad_norm": 0.9140792489051819,
      "learning_rate": 6.825980392156863e-06,
      "loss": 0.0515,
      "step": 8396
    },
    {
      "epoch": 1.9294577205882353,
      "grad_norm": 0.8256936073303223,
      "learning_rate": 6.82546977124183e-06,
      "loss": 0.0404,
      "step": 8397
    },
    {
      "epoch": 1.9296875,
      "grad_norm": 0.7436232566833496,
      "learning_rate": 6.824959150326797e-06,
      "loss": 0.0394,
      "step": 8398
    },
    {
      "epoch": 1.9299172794117647,
      "grad_norm": 0.7984557151794434,
      "learning_rate": 6.824448529411766e-06,
      "loss": 0.0424,
      "step": 8399
    },
    {
      "epoch": 1.9301470588235294,
      "grad_norm": 0.8517000079154968,
      "learning_rate": 6.823937908496733e-06,
      "loss": 0.043,
      "step": 8400
    },
    {
      "epoch": 1.9303768382352942,
      "grad_norm": 0.9579487442970276,
      "learning_rate": 6.8234272875817e-06,
      "loss": 0.0443,
      "step": 8401
    },
    {
      "epoch": 1.9306066176470589,
      "grad_norm": 1.066703200340271,
      "learning_rate": 6.822916666666667e-06,
      "loss": 0.0416,
      "step": 8402
    },
    {
      "epoch": 1.9308363970588234,
      "grad_norm": 0.8969895839691162,
      "learning_rate": 6.822406045751635e-06,
      "loss": 0.0383,
      "step": 8403
    },
    {
      "epoch": 1.9310661764705883,
      "grad_norm": 0.7070631980895996,
      "learning_rate": 6.821895424836602e-06,
      "loss": 0.0262,
      "step": 8404
    },
    {
      "epoch": 1.9312959558823528,
      "grad_norm": 0.9062016606330872,
      "learning_rate": 6.821384803921569e-06,
      "loss": 0.0355,
      "step": 8405
    },
    {
      "epoch": 1.9315257352941178,
      "grad_norm": 1.466900110244751,
      "learning_rate": 6.820874183006536e-06,
      "loss": 0.0566,
      "step": 8406
    },
    {
      "epoch": 1.9317555147058822,
      "grad_norm": 0.9101962447166443,
      "learning_rate": 6.820363562091505e-06,
      "loss": 0.042,
      "step": 8407
    },
    {
      "epoch": 1.9319852941176472,
      "grad_norm": 0.8165826201438904,
      "learning_rate": 6.819852941176472e-06,
      "loss": 0.0436,
      "step": 8408
    },
    {
      "epoch": 1.9322150735294117,
      "grad_norm": 0.8766977787017822,
      "learning_rate": 6.819342320261439e-06,
      "loss": 0.0454,
      "step": 8409
    },
    {
      "epoch": 1.9324448529411766,
      "grad_norm": 0.9771209359169006,
      "learning_rate": 6.818831699346406e-06,
      "loss": 0.0508,
      "step": 8410
    },
    {
      "epoch": 1.9326746323529411,
      "grad_norm": 0.8965665698051453,
      "learning_rate": 6.8183210784313736e-06,
      "loss": 0.0438,
      "step": 8411
    },
    {
      "epoch": 1.9329044117647058,
      "grad_norm": 0.9915829300880432,
      "learning_rate": 6.817810457516341e-06,
      "loss": 0.059,
      "step": 8412
    },
    {
      "epoch": 1.9331341911764706,
      "grad_norm": 1.4243398904800415,
      "learning_rate": 6.817299836601308e-06,
      "loss": 0.0491,
      "step": 8413
    },
    {
      "epoch": 1.9333639705882353,
      "grad_norm": 1.218806266784668,
      "learning_rate": 6.816789215686275e-06,
      "loss": 0.0657,
      "step": 8414
    },
    {
      "epoch": 1.93359375,
      "grad_norm": 0.8767426609992981,
      "learning_rate": 6.8162785947712425e-06,
      "loss": 0.0336,
      "step": 8415
    },
    {
      "epoch": 1.9338235294117647,
      "grad_norm": 0.6976808905601501,
      "learning_rate": 6.81576797385621e-06,
      "loss": 0.034,
      "step": 8416
    },
    {
      "epoch": 1.9340533088235294,
      "grad_norm": 1.0614084005355835,
      "learning_rate": 6.815257352941177e-06,
      "loss": 0.0519,
      "step": 8417
    },
    {
      "epoch": 1.9342830882352942,
      "grad_norm": 1.0951242446899414,
      "learning_rate": 6.814746732026144e-06,
      "loss": 0.048,
      "step": 8418
    },
    {
      "epoch": 1.9345128676470589,
      "grad_norm": 0.8145352602005005,
      "learning_rate": 6.814236111111112e-06,
      "loss": 0.0463,
      "step": 8419
    },
    {
      "epoch": 1.9347426470588234,
      "grad_norm": 0.891434371471405,
      "learning_rate": 6.813725490196079e-06,
      "loss": 0.0519,
      "step": 8420
    },
    {
      "epoch": 1.9349724264705883,
      "grad_norm": 1.428963541984558,
      "learning_rate": 6.813214869281046e-06,
      "loss": 0.0781,
      "step": 8421
    },
    {
      "epoch": 1.9352022058823528,
      "grad_norm": 0.8880478143692017,
      "learning_rate": 6.812704248366013e-06,
      "loss": 0.0489,
      "step": 8422
    },
    {
      "epoch": 1.9354319852941178,
      "grad_norm": 0.9772088527679443,
      "learning_rate": 6.812193627450981e-06,
      "loss": 0.0347,
      "step": 8423
    },
    {
      "epoch": 1.9356617647058822,
      "grad_norm": 1.334557294845581,
      "learning_rate": 6.811683006535948e-06,
      "loss": 0.0523,
      "step": 8424
    },
    {
      "epoch": 1.9358915441176472,
      "grad_norm": 1.1678340435028076,
      "learning_rate": 6.811172385620915e-06,
      "loss": 0.0647,
      "step": 8425
    },
    {
      "epoch": 1.9361213235294117,
      "grad_norm": 0.7420963644981384,
      "learning_rate": 6.810661764705882e-06,
      "loss": 0.0402,
      "step": 8426
    },
    {
      "epoch": 1.9363511029411766,
      "grad_norm": 0.7523839473724365,
      "learning_rate": 6.810151143790851e-06,
      "loss": 0.0303,
      "step": 8427
    },
    {
      "epoch": 1.9365808823529411,
      "grad_norm": 0.8535634875297546,
      "learning_rate": 6.809640522875818e-06,
      "loss": 0.0404,
      "step": 8428
    },
    {
      "epoch": 1.9368106617647058,
      "grad_norm": 0.8791270852088928,
      "learning_rate": 6.809129901960785e-06,
      "loss": 0.052,
      "step": 8429
    },
    {
      "epoch": 1.9370404411764706,
      "grad_norm": 2.8026270866394043,
      "learning_rate": 6.808619281045752e-06,
      "loss": 0.0379,
      "step": 8430
    },
    {
      "epoch": 1.9372702205882353,
      "grad_norm": 0.9742113351821899,
      "learning_rate": 6.80810866013072e-06,
      "loss": 0.0557,
      "step": 8431
    },
    {
      "epoch": 1.9375,
      "grad_norm": 1.009721040725708,
      "learning_rate": 6.807598039215687e-06,
      "loss": 0.0313,
      "step": 8432
    },
    {
      "epoch": 1.9377297794117647,
      "grad_norm": 0.9590146541595459,
      "learning_rate": 6.807087418300654e-06,
      "loss": 0.0465,
      "step": 8433
    },
    {
      "epoch": 1.9379595588235294,
      "grad_norm": 1.0935763120651245,
      "learning_rate": 6.806576797385621e-06,
      "loss": 0.0555,
      "step": 8434
    },
    {
      "epoch": 1.9381893382352942,
      "grad_norm": 1.0786464214324951,
      "learning_rate": 6.8060661764705895e-06,
      "loss": 0.0617,
      "step": 8435
    },
    {
      "epoch": 1.9384191176470589,
      "grad_norm": 1.3037519454956055,
      "learning_rate": 6.8055555555555566e-06,
      "loss": 0.0589,
      "step": 8436
    },
    {
      "epoch": 1.9386488970588234,
      "grad_norm": 0.6735286712646484,
      "learning_rate": 6.8050449346405236e-06,
      "loss": 0.0216,
      "step": 8437
    },
    {
      "epoch": 1.9388786764705883,
      "grad_norm": 0.9684807062149048,
      "learning_rate": 6.804534313725491e-06,
      "loss": 0.0516,
      "step": 8438
    },
    {
      "epoch": 1.9391084558823528,
      "grad_norm": 1.1130353212356567,
      "learning_rate": 6.8040236928104584e-06,
      "loss": 0.0514,
      "step": 8439
    },
    {
      "epoch": 1.9393382352941178,
      "grad_norm": 1.1533820629119873,
      "learning_rate": 6.8035130718954255e-06,
      "loss": 0.0414,
      "step": 8440
    },
    {
      "epoch": 1.9395680147058822,
      "grad_norm": 1.2998195886611938,
      "learning_rate": 6.8030024509803925e-06,
      "loss": 0.0441,
      "step": 8441
    },
    {
      "epoch": 1.9397977941176472,
      "grad_norm": 0.9273403286933899,
      "learning_rate": 6.8024918300653595e-06,
      "loss": 0.0406,
      "step": 8442
    },
    {
      "epoch": 1.9400275735294117,
      "grad_norm": 0.7966462969779968,
      "learning_rate": 6.801981209150328e-06,
      "loss": 0.0593,
      "step": 8443
    },
    {
      "epoch": 1.9402573529411766,
      "grad_norm": 0.5587125420570374,
      "learning_rate": 6.801470588235295e-06,
      "loss": 0.0208,
      "step": 8444
    },
    {
      "epoch": 1.9404871323529411,
      "grad_norm": 0.8276248574256897,
      "learning_rate": 6.800959967320262e-06,
      "loss": 0.0403,
      "step": 8445
    },
    {
      "epoch": 1.9407169117647058,
      "grad_norm": 1.0757570266723633,
      "learning_rate": 6.800449346405229e-06,
      "loss": 0.0537,
      "step": 8446
    },
    {
      "epoch": 1.9409466911764706,
      "grad_norm": 1.3334912061691284,
      "learning_rate": 6.799938725490197e-06,
      "loss": 0.0446,
      "step": 8447
    },
    {
      "epoch": 1.9411764705882353,
      "grad_norm": 0.6944740414619446,
      "learning_rate": 6.799428104575164e-06,
      "loss": 0.0387,
      "step": 8448
    },
    {
      "epoch": 1.94140625,
      "grad_norm": 1.7800121307373047,
      "learning_rate": 6.798917483660131e-06,
      "loss": 0.0451,
      "step": 8449
    },
    {
      "epoch": 1.9416360294117647,
      "grad_norm": 1.2911230325698853,
      "learning_rate": 6.798406862745098e-06,
      "loss": 0.0679,
      "step": 8450
    },
    {
      "epoch": 1.9418658088235294,
      "grad_norm": 1.2065834999084473,
      "learning_rate": 6.797896241830067e-06,
      "loss": 0.056,
      "step": 8451
    },
    {
      "epoch": 1.9420955882352942,
      "grad_norm": 1.2514517307281494,
      "learning_rate": 6.797385620915034e-06,
      "loss": 0.0551,
      "step": 8452
    },
    {
      "epoch": 1.9423253676470589,
      "grad_norm": 0.6902562975883484,
      "learning_rate": 6.796875000000001e-06,
      "loss": 0.0325,
      "step": 8453
    },
    {
      "epoch": 1.9425551470588234,
      "grad_norm": 1.0245487689971924,
      "learning_rate": 6.796364379084968e-06,
      "loss": 0.0521,
      "step": 8454
    },
    {
      "epoch": 1.9427849264705883,
      "grad_norm": 0.936289370059967,
      "learning_rate": 6.795853758169935e-06,
      "loss": 0.0387,
      "step": 8455
    },
    {
      "epoch": 1.9430147058823528,
      "grad_norm": 0.8905341029167175,
      "learning_rate": 6.795343137254903e-06,
      "loss": 0.0414,
      "step": 8456
    },
    {
      "epoch": 1.9432444852941178,
      "grad_norm": 1.064339280128479,
      "learning_rate": 6.79483251633987e-06,
      "loss": 0.0501,
      "step": 8457
    },
    {
      "epoch": 1.9434742647058822,
      "grad_norm": 1.0977060794830322,
      "learning_rate": 6.794321895424837e-06,
      "loss": 0.0571,
      "step": 8458
    },
    {
      "epoch": 1.9437040441176472,
      "grad_norm": 1.182258129119873,
      "learning_rate": 6.793811274509804e-06,
      "loss": 0.0409,
      "step": 8459
    },
    {
      "epoch": 1.9439338235294117,
      "grad_norm": 1.2534451484680176,
      "learning_rate": 6.793300653594772e-06,
      "loss": 0.0767,
      "step": 8460
    },
    {
      "epoch": 1.9441636029411766,
      "grad_norm": 0.8799309134483337,
      "learning_rate": 6.7927900326797395e-06,
      "loss": 0.035,
      "step": 8461
    },
    {
      "epoch": 1.9443933823529411,
      "grad_norm": 1.3471286296844482,
      "learning_rate": 6.7922794117647066e-06,
      "loss": 0.0422,
      "step": 8462
    },
    {
      "epoch": 1.9446231617647058,
      "grad_norm": 1.011083722114563,
      "learning_rate": 6.7917687908496736e-06,
      "loss": 0.0493,
      "step": 8463
    },
    {
      "epoch": 1.9448529411764706,
      "grad_norm": 0.7613932490348816,
      "learning_rate": 6.7912581699346414e-06,
      "loss": 0.0366,
      "step": 8464
    },
    {
      "epoch": 1.9450827205882353,
      "grad_norm": 0.7596874237060547,
      "learning_rate": 6.7907475490196084e-06,
      "loss": 0.0266,
      "step": 8465
    },
    {
      "epoch": 1.9453125,
      "grad_norm": 1.3841958045959473,
      "learning_rate": 6.7902369281045755e-06,
      "loss": 0.0466,
      "step": 8466
    },
    {
      "epoch": 1.9455422794117647,
      "grad_norm": 0.7710468769073486,
      "learning_rate": 6.7897263071895425e-06,
      "loss": 0.0306,
      "step": 8467
    },
    {
      "epoch": 1.9457720588235294,
      "grad_norm": 0.9468539953231812,
      "learning_rate": 6.78921568627451e-06,
      "loss": 0.0646,
      "step": 8468
    },
    {
      "epoch": 1.9460018382352942,
      "grad_norm": 1.814468264579773,
      "learning_rate": 6.788705065359477e-06,
      "loss": 0.081,
      "step": 8469
    },
    {
      "epoch": 1.9462316176470589,
      "grad_norm": 0.7832948565483093,
      "learning_rate": 6.788194444444444e-06,
      "loss": 0.0205,
      "step": 8470
    },
    {
      "epoch": 1.9464613970588234,
      "grad_norm": 0.9952925443649292,
      "learning_rate": 6.787683823529411e-06,
      "loss": 0.0447,
      "step": 8471
    },
    {
      "epoch": 1.9466911764705883,
      "grad_norm": 1.2726941108703613,
      "learning_rate": 6.78717320261438e-06,
      "loss": 0.0405,
      "step": 8472
    },
    {
      "epoch": 1.9469209558823528,
      "grad_norm": 0.7129146456718445,
      "learning_rate": 6.786662581699347e-06,
      "loss": 0.0441,
      "step": 8473
    },
    {
      "epoch": 1.9471507352941178,
      "grad_norm": 1.0518667697906494,
      "learning_rate": 6.786151960784314e-06,
      "loss": 0.0497,
      "step": 8474
    },
    {
      "epoch": 1.9473805147058822,
      "grad_norm": 0.8618987798690796,
      "learning_rate": 6.785641339869281e-06,
      "loss": 0.045,
      "step": 8475
    },
    {
      "epoch": 1.9476102941176472,
      "grad_norm": 1.5315605401992798,
      "learning_rate": 6.785130718954249e-06,
      "loss": 0.0698,
      "step": 8476
    },
    {
      "epoch": 1.9478400735294117,
      "grad_norm": 1.032819390296936,
      "learning_rate": 6.784620098039216e-06,
      "loss": 0.0363,
      "step": 8477
    },
    {
      "epoch": 1.9480698529411766,
      "grad_norm": 1.0388048887252808,
      "learning_rate": 6.784109477124183e-06,
      "loss": 0.0453,
      "step": 8478
    },
    {
      "epoch": 1.9482996323529411,
      "grad_norm": 0.762855052947998,
      "learning_rate": 6.78359885620915e-06,
      "loss": 0.0326,
      "step": 8479
    },
    {
      "epoch": 1.9485294117647058,
      "grad_norm": 0.8742504119873047,
      "learning_rate": 6.783088235294119e-06,
      "loss": 0.0548,
      "step": 8480
    },
    {
      "epoch": 1.9487591911764706,
      "grad_norm": 1.3388327360153198,
      "learning_rate": 6.782577614379086e-06,
      "loss": 0.0812,
      "step": 8481
    },
    {
      "epoch": 1.9489889705882353,
      "grad_norm": 0.9242520928382874,
      "learning_rate": 6.782066993464053e-06,
      "loss": 0.0461,
      "step": 8482
    },
    {
      "epoch": 1.94921875,
      "grad_norm": 0.7612941265106201,
      "learning_rate": 6.78155637254902e-06,
      "loss": 0.0313,
      "step": 8483
    },
    {
      "epoch": 1.9494485294117647,
      "grad_norm": 1.148044228553772,
      "learning_rate": 6.781045751633988e-06,
      "loss": 0.0469,
      "step": 8484
    },
    {
      "epoch": 1.9496783088235294,
      "grad_norm": 0.7215731143951416,
      "learning_rate": 6.780535130718955e-06,
      "loss": 0.0329,
      "step": 8485
    },
    {
      "epoch": 1.9499080882352942,
      "grad_norm": 1.0038371086120605,
      "learning_rate": 6.780024509803922e-06,
      "loss": 0.0451,
      "step": 8486
    },
    {
      "epoch": 1.9501378676470589,
      "grad_norm": 0.8071751594543457,
      "learning_rate": 6.779513888888889e-06,
      "loss": 0.053,
      "step": 8487
    },
    {
      "epoch": 1.9503676470588234,
      "grad_norm": 1.099099040031433,
      "learning_rate": 6.779003267973857e-06,
      "loss": 0.0541,
      "step": 8488
    },
    {
      "epoch": 1.9505974264705883,
      "grad_norm": 0.9121626615524292,
      "learning_rate": 6.778492647058824e-06,
      "loss": 0.0306,
      "step": 8489
    },
    {
      "epoch": 1.9508272058823528,
      "grad_norm": 0.8299140930175781,
      "learning_rate": 6.7779820261437914e-06,
      "loss": 0.0383,
      "step": 8490
    },
    {
      "epoch": 1.9510569852941178,
      "grad_norm": 0.9725205302238464,
      "learning_rate": 6.7774714052287584e-06,
      "loss": 0.0467,
      "step": 8491
    },
    {
      "epoch": 1.9512867647058822,
      "grad_norm": 0.742112398147583,
      "learning_rate": 6.776960784313726e-06,
      "loss": 0.0486,
      "step": 8492
    },
    {
      "epoch": 1.9515165441176472,
      "grad_norm": 1.743821620941162,
      "learning_rate": 6.776450163398693e-06,
      "loss": 0.0668,
      "step": 8493
    },
    {
      "epoch": 1.9517463235294117,
      "grad_norm": 1.0111335515975952,
      "learning_rate": 6.77593954248366e-06,
      "loss": 0.036,
      "step": 8494
    },
    {
      "epoch": 1.9519761029411766,
      "grad_norm": 0.8267138004302979,
      "learning_rate": 6.775428921568627e-06,
      "loss": 0.0297,
      "step": 8495
    },
    {
      "epoch": 1.9522058823529411,
      "grad_norm": 0.8536245822906494,
      "learning_rate": 6.774918300653596e-06,
      "loss": 0.037,
      "step": 8496
    },
    {
      "epoch": 1.9524356617647058,
      "grad_norm": 0.9455093741416931,
      "learning_rate": 6.774407679738563e-06,
      "loss": 0.0461,
      "step": 8497
    },
    {
      "epoch": 1.9526654411764706,
      "grad_norm": 0.8575548529624939,
      "learning_rate": 6.77389705882353e-06,
      "loss": 0.0294,
      "step": 8498
    },
    {
      "epoch": 1.9528952205882353,
      "grad_norm": 1.2710528373718262,
      "learning_rate": 6.773386437908497e-06,
      "loss": 0.0635,
      "step": 8499
    },
    {
      "epoch": 1.953125,
      "grad_norm": 1.028402328491211,
      "learning_rate": 6.772875816993465e-06,
      "loss": 0.0387,
      "step": 8500
    },
    {
      "epoch": 1.953125,
      "eval_loss": 0.04967748373746872,
      "eval_runtime": 2007.2106,
      "eval_samples_per_second": 4.437,
      "eval_steps_per_second": 2.219,
      "step": 8500
    },
    {
      "epoch": 1.9533547794117647,
      "grad_norm": 0.914073646068573,
      "learning_rate": 6.772365196078432e-06,
      "loss": 0.0325,
      "step": 8501
    },
    {
      "epoch": 1.9535845588235294,
      "grad_norm": 1.1505796909332275,
      "learning_rate": 6.771854575163399e-06,
      "loss": 0.0476,
      "step": 8502
    },
    {
      "epoch": 1.9538143382352942,
      "grad_norm": 1.2498457431793213,
      "learning_rate": 6.771343954248366e-06,
      "loss": 0.0629,
      "step": 8503
    },
    {
      "epoch": 1.9540441176470589,
      "grad_norm": 0.7993141412734985,
      "learning_rate": 6.770833333333334e-06,
      "loss": 0.0433,
      "step": 8504
    },
    {
      "epoch": 1.9542738970588234,
      "grad_norm": 1.1268658638000488,
      "learning_rate": 6.770322712418301e-06,
      "loss": 0.0418,
      "step": 8505
    },
    {
      "epoch": 1.9545036764705883,
      "grad_norm": 0.7901071906089783,
      "learning_rate": 6.769812091503269e-06,
      "loss": 0.0346,
      "step": 8506
    },
    {
      "epoch": 1.9547334558823528,
      "grad_norm": 0.7729600071907043,
      "learning_rate": 6.769301470588236e-06,
      "loss": 0.0245,
      "step": 8507
    },
    {
      "epoch": 1.9549632352941178,
      "grad_norm": 1.1518199443817139,
      "learning_rate": 6.768790849673204e-06,
      "loss": 0.0439,
      "step": 8508
    },
    {
      "epoch": 1.9551930147058822,
      "grad_norm": 0.8617146015167236,
      "learning_rate": 6.768280228758171e-06,
      "loss": 0.0454,
      "step": 8509
    },
    {
      "epoch": 1.9554227941176472,
      "grad_norm": 1.2407348155975342,
      "learning_rate": 6.767769607843138e-06,
      "loss": 0.0492,
      "step": 8510
    },
    {
      "epoch": 1.9556525735294117,
      "grad_norm": 0.8935158848762512,
      "learning_rate": 6.767258986928105e-06,
      "loss": 0.0402,
      "step": 8511
    },
    {
      "epoch": 1.9558823529411766,
      "grad_norm": 0.91915363073349,
      "learning_rate": 6.7667483660130725e-06,
      "loss": 0.0365,
      "step": 8512
    },
    {
      "epoch": 1.9561121323529411,
      "grad_norm": 0.9164767265319824,
      "learning_rate": 6.7662377450980395e-06,
      "loss": 0.0363,
      "step": 8513
    },
    {
      "epoch": 1.9563419117647058,
      "grad_norm": 1.3259023427963257,
      "learning_rate": 6.7657271241830066e-06,
      "loss": 0.0449,
      "step": 8514
    },
    {
      "epoch": 1.9565716911764706,
      "grad_norm": 0.8059173226356506,
      "learning_rate": 6.7652165032679736e-06,
      "loss": 0.0401,
      "step": 8515
    },
    {
      "epoch": 1.9568014705882353,
      "grad_norm": 0.8325297832489014,
      "learning_rate": 6.764705882352942e-06,
      "loss": 0.0521,
      "step": 8516
    },
    {
      "epoch": 1.95703125,
      "grad_norm": 1.3406368494033813,
      "learning_rate": 6.764195261437909e-06,
      "loss": 0.0457,
      "step": 8517
    },
    {
      "epoch": 1.9572610294117647,
      "grad_norm": 1.0351696014404297,
      "learning_rate": 6.763684640522876e-06,
      "loss": 0.0545,
      "step": 8518
    },
    {
      "epoch": 1.9574908088235294,
      "grad_norm": 0.7643471956253052,
      "learning_rate": 6.763174019607843e-06,
      "loss": 0.0303,
      "step": 8519
    },
    {
      "epoch": 1.9577205882352942,
      "grad_norm": 0.8246751427650452,
      "learning_rate": 6.762663398692811e-06,
      "loss": 0.0438,
      "step": 8520
    },
    {
      "epoch": 1.9579503676470589,
      "grad_norm": 1.669859766960144,
      "learning_rate": 6.762152777777778e-06,
      "loss": 0.0341,
      "step": 8521
    },
    {
      "epoch": 1.9581801470588234,
      "grad_norm": 1.211586594581604,
      "learning_rate": 6.761642156862745e-06,
      "loss": 0.0402,
      "step": 8522
    },
    {
      "epoch": 1.9584099264705883,
      "grad_norm": 1.218671202659607,
      "learning_rate": 6.761131535947712e-06,
      "loss": 0.0402,
      "step": 8523
    },
    {
      "epoch": 1.9586397058823528,
      "grad_norm": 0.9530580043792725,
      "learning_rate": 6.760620915032681e-06,
      "loss": 0.0382,
      "step": 8524
    },
    {
      "epoch": 1.9588694852941178,
      "grad_norm": 1.0920636653900146,
      "learning_rate": 6.760110294117648e-06,
      "loss": 0.0264,
      "step": 8525
    },
    {
      "epoch": 1.9590992647058822,
      "grad_norm": 0.916924238204956,
      "learning_rate": 6.759599673202615e-06,
      "loss": 0.0422,
      "step": 8526
    },
    {
      "epoch": 1.9593290441176472,
      "grad_norm": 0.9480622410774231,
      "learning_rate": 6.759089052287582e-06,
      "loss": 0.041,
      "step": 8527
    },
    {
      "epoch": 1.9595588235294117,
      "grad_norm": 0.8510238528251648,
      "learning_rate": 6.75857843137255e-06,
      "loss": 0.0378,
      "step": 8528
    },
    {
      "epoch": 1.9597886029411766,
      "grad_norm": 0.7723015546798706,
      "learning_rate": 6.758067810457517e-06,
      "loss": 0.0336,
      "step": 8529
    },
    {
      "epoch": 1.9600183823529411,
      "grad_norm": 1.2081705331802368,
      "learning_rate": 6.757557189542484e-06,
      "loss": 0.0641,
      "step": 8530
    },
    {
      "epoch": 1.9602481617647058,
      "grad_norm": 0.7266328930854797,
      "learning_rate": 6.757046568627451e-06,
      "loss": 0.0277,
      "step": 8531
    },
    {
      "epoch": 1.9604779411764706,
      "grad_norm": 1.3821593523025513,
      "learning_rate": 6.75653594771242e-06,
      "loss": 0.0566,
      "step": 8532
    },
    {
      "epoch": 1.9607077205882353,
      "grad_norm": 0.9585634469985962,
      "learning_rate": 6.756025326797387e-06,
      "loss": 0.0539,
      "step": 8533
    },
    {
      "epoch": 1.9609375,
      "grad_norm": 0.8965330719947815,
      "learning_rate": 6.755514705882354e-06,
      "loss": 0.0446,
      "step": 8534
    },
    {
      "epoch": 1.9611672794117647,
      "grad_norm": 1.0592094659805298,
      "learning_rate": 6.755004084967321e-06,
      "loss": 0.0502,
      "step": 8535
    },
    {
      "epoch": 1.9613970588235294,
      "grad_norm": 0.7834656834602356,
      "learning_rate": 6.7544934640522885e-06,
      "loss": 0.0308,
      "step": 8536
    },
    {
      "epoch": 1.9616268382352942,
      "grad_norm": 1.2640471458435059,
      "learning_rate": 6.7539828431372555e-06,
      "loss": 0.0589,
      "step": 8537
    },
    {
      "epoch": 1.9618566176470589,
      "grad_norm": 0.7063613533973694,
      "learning_rate": 6.7534722222222225e-06,
      "loss": 0.037,
      "step": 8538
    },
    {
      "epoch": 1.9620863970588234,
      "grad_norm": 0.8799711465835571,
      "learning_rate": 6.7529616013071895e-06,
      "loss": 0.0513,
      "step": 8539
    },
    {
      "epoch": 1.9623161764705883,
      "grad_norm": 0.8634541034698486,
      "learning_rate": 6.752450980392158e-06,
      "loss": 0.0392,
      "step": 8540
    },
    {
      "epoch": 1.9625459558823528,
      "grad_norm": 1.6266053915023804,
      "learning_rate": 6.751940359477125e-06,
      "loss": 0.0481,
      "step": 8541
    },
    {
      "epoch": 1.9627757352941178,
      "grad_norm": 0.8289381861686707,
      "learning_rate": 6.751429738562092e-06,
      "loss": 0.048,
      "step": 8542
    },
    {
      "epoch": 1.9630055147058822,
      "grad_norm": 1.0946182012557983,
      "learning_rate": 6.750919117647059e-06,
      "loss": 0.0472,
      "step": 8543
    },
    {
      "epoch": 1.9632352941176472,
      "grad_norm": 0.7100862860679626,
      "learning_rate": 6.750408496732027e-06,
      "loss": 0.0375,
      "step": 8544
    },
    {
      "epoch": 1.9634650735294117,
      "grad_norm": 0.8497986197471619,
      "learning_rate": 6.749897875816994e-06,
      "loss": 0.0445,
      "step": 8545
    },
    {
      "epoch": 1.9636948529411766,
      "grad_norm": 1.1958657503128052,
      "learning_rate": 6.749387254901961e-06,
      "loss": 0.0669,
      "step": 8546
    },
    {
      "epoch": 1.9639246323529411,
      "grad_norm": 1.100019931793213,
      "learning_rate": 6.748876633986928e-06,
      "loss": 0.0548,
      "step": 8547
    },
    {
      "epoch": 1.9641544117647058,
      "grad_norm": 0.8944635391235352,
      "learning_rate": 6.748366013071896e-06,
      "loss": 0.0553,
      "step": 8548
    },
    {
      "epoch": 1.9643841911764706,
      "grad_norm": 0.7261723279953003,
      "learning_rate": 6.747855392156863e-06,
      "loss": 0.0339,
      "step": 8549
    },
    {
      "epoch": 1.9646139705882353,
      "grad_norm": 0.9508101344108582,
      "learning_rate": 6.747344771241831e-06,
      "loss": 0.0483,
      "step": 8550
    },
    {
      "epoch": 1.96484375,
      "grad_norm": 0.9683199524879456,
      "learning_rate": 6.746834150326798e-06,
      "loss": 0.0475,
      "step": 8551
    },
    {
      "epoch": 1.9650735294117647,
      "grad_norm": 0.9687066674232483,
      "learning_rate": 6.746323529411766e-06,
      "loss": 0.0501,
      "step": 8552
    },
    {
      "epoch": 1.9653033088235294,
      "grad_norm": 1.1246989965438843,
      "learning_rate": 6.745812908496733e-06,
      "loss": 0.0481,
      "step": 8553
    },
    {
      "epoch": 1.9655330882352942,
      "grad_norm": 0.8118287324905396,
      "learning_rate": 6.7453022875817e-06,
      "loss": 0.0548,
      "step": 8554
    },
    {
      "epoch": 1.9657628676470589,
      "grad_norm": 1.037992238998413,
      "learning_rate": 6.744791666666667e-06,
      "loss": 0.0586,
      "step": 8555
    },
    {
      "epoch": 1.9659926470588234,
      "grad_norm": 1.6364257335662842,
      "learning_rate": 6.744281045751635e-06,
      "loss": 0.0951,
      "step": 8556
    },
    {
      "epoch": 1.9662224264705883,
      "grad_norm": 1.0910065174102783,
      "learning_rate": 6.743770424836602e-06,
      "loss": 0.0689,
      "step": 8557
    },
    {
      "epoch": 1.9664522058823528,
      "grad_norm": 1.2372440099716187,
      "learning_rate": 6.743259803921569e-06,
      "loss": 0.061,
      "step": 8558
    },
    {
      "epoch": 1.9666819852941178,
      "grad_norm": 0.9064843058586121,
      "learning_rate": 6.742749183006536e-06,
      "loss": 0.0373,
      "step": 8559
    },
    {
      "epoch": 1.9669117647058822,
      "grad_norm": 0.7755186557769775,
      "learning_rate": 6.7422385620915045e-06,
      "loss": 0.0433,
      "step": 8560
    },
    {
      "epoch": 1.9671415441176472,
      "grad_norm": 0.7334787845611572,
      "learning_rate": 6.7417279411764715e-06,
      "loss": 0.0329,
      "step": 8561
    },
    {
      "epoch": 1.9673713235294117,
      "grad_norm": 1.0914864540100098,
      "learning_rate": 6.7412173202614385e-06,
      "loss": 0.0455,
      "step": 8562
    },
    {
      "epoch": 1.9676011029411766,
      "grad_norm": 1.162925124168396,
      "learning_rate": 6.7407066993464055e-06,
      "loss": 0.0766,
      "step": 8563
    },
    {
      "epoch": 1.9678308823529411,
      "grad_norm": 1.1534329652786255,
      "learning_rate": 6.740196078431373e-06,
      "loss": 0.0511,
      "step": 8564
    },
    {
      "epoch": 1.9680606617647058,
      "grad_norm": 1.0117932558059692,
      "learning_rate": 6.73968545751634e-06,
      "loss": 0.0556,
      "step": 8565
    },
    {
      "epoch": 1.9682904411764706,
      "grad_norm": 0.9817691445350647,
      "learning_rate": 6.739174836601307e-06,
      "loss": 0.0393,
      "step": 8566
    },
    {
      "epoch": 1.9685202205882353,
      "grad_norm": 0.9632528424263,
      "learning_rate": 6.738664215686274e-06,
      "loss": 0.0448,
      "step": 8567
    },
    {
      "epoch": 1.96875,
      "grad_norm": 0.7985866069793701,
      "learning_rate": 6.738153594771243e-06,
      "loss": 0.0318,
      "step": 8568
    },
    {
      "epoch": 1.9689797794117647,
      "grad_norm": 0.863325834274292,
      "learning_rate": 6.73764297385621e-06,
      "loss": 0.0678,
      "step": 8569
    },
    {
      "epoch": 1.9692095588235294,
      "grad_norm": 1.1244391202926636,
      "learning_rate": 6.737132352941177e-06,
      "loss": 0.0484,
      "step": 8570
    },
    {
      "epoch": 1.9694393382352942,
      "grad_norm": 1.0027315616607666,
      "learning_rate": 6.736621732026144e-06,
      "loss": 0.0509,
      "step": 8571
    },
    {
      "epoch": 1.9696691176470589,
      "grad_norm": 0.5040950179100037,
      "learning_rate": 6.736111111111112e-06,
      "loss": 0.0199,
      "step": 8572
    },
    {
      "epoch": 1.9698988970588234,
      "grad_norm": 0.8342792391777039,
      "learning_rate": 6.735600490196079e-06,
      "loss": 0.0382,
      "step": 8573
    },
    {
      "epoch": 1.9701286764705883,
      "grad_norm": 1.155860424041748,
      "learning_rate": 6.735089869281046e-06,
      "loss": 0.0751,
      "step": 8574
    },
    {
      "epoch": 1.9703584558823528,
      "grad_norm": 1.055981159210205,
      "learning_rate": 6.734579248366013e-06,
      "loss": 0.0416,
      "step": 8575
    },
    {
      "epoch": 1.9705882352941178,
      "grad_norm": 1.0325506925582886,
      "learning_rate": 6.734068627450982e-06,
      "loss": 0.0326,
      "step": 8576
    },
    {
      "epoch": 1.9708180147058822,
      "grad_norm": 1.2300753593444824,
      "learning_rate": 6.733558006535949e-06,
      "loss": 0.0604,
      "step": 8577
    },
    {
      "epoch": 1.9710477941176472,
      "grad_norm": 0.821460485458374,
      "learning_rate": 6.733047385620916e-06,
      "loss": 0.029,
      "step": 8578
    },
    {
      "epoch": 1.9712775735294117,
      "grad_norm": 0.8106746673583984,
      "learning_rate": 6.732536764705883e-06,
      "loss": 0.0465,
      "step": 8579
    },
    {
      "epoch": 1.9715073529411766,
      "grad_norm": 0.9302250742912292,
      "learning_rate": 6.732026143790851e-06,
      "loss": 0.0426,
      "step": 8580
    },
    {
      "epoch": 1.9717371323529411,
      "grad_norm": 0.7801425457000732,
      "learning_rate": 6.731515522875818e-06,
      "loss": 0.0379,
      "step": 8581
    },
    {
      "epoch": 1.9719669117647058,
      "grad_norm": 1.1100996732711792,
      "learning_rate": 6.731004901960785e-06,
      "loss": 0.0451,
      "step": 8582
    },
    {
      "epoch": 1.9721966911764706,
      "grad_norm": 0.7491273283958435,
      "learning_rate": 6.730494281045752e-06,
      "loss": 0.0431,
      "step": 8583
    },
    {
      "epoch": 1.9724264705882353,
      "grad_norm": 0.8741312026977539,
      "learning_rate": 6.7299836601307204e-06,
      "loss": 0.0509,
      "step": 8584
    },
    {
      "epoch": 1.97265625,
      "grad_norm": 0.997366726398468,
      "learning_rate": 6.7294730392156874e-06,
      "loss": 0.0397,
      "step": 8585
    },
    {
      "epoch": 1.9728860294117647,
      "grad_norm": 1.1925147771835327,
      "learning_rate": 6.7289624183006545e-06,
      "loss": 0.0543,
      "step": 8586
    },
    {
      "epoch": 1.9731158088235294,
      "grad_norm": 0.9802572727203369,
      "learning_rate": 6.7284517973856215e-06,
      "loss": 0.0423,
      "step": 8587
    },
    {
      "epoch": 1.9733455882352942,
      "grad_norm": 0.9224370718002319,
      "learning_rate": 6.727941176470589e-06,
      "loss": 0.0448,
      "step": 8588
    },
    {
      "epoch": 1.9735753676470589,
      "grad_norm": 1.6620032787322998,
      "learning_rate": 6.727430555555556e-06,
      "loss": 0.0836,
      "step": 8589
    },
    {
      "epoch": 1.9738051470588234,
      "grad_norm": 0.7597509026527405,
      "learning_rate": 6.726919934640523e-06,
      "loss": 0.0368,
      "step": 8590
    },
    {
      "epoch": 1.9740349264705883,
      "grad_norm": 1.0820609331130981,
      "learning_rate": 6.72640931372549e-06,
      "loss": 0.0584,
      "step": 8591
    },
    {
      "epoch": 1.9742647058823528,
      "grad_norm": 0.6493932604789734,
      "learning_rate": 6.725898692810458e-06,
      "loss": 0.0302,
      "step": 8592
    },
    {
      "epoch": 1.9744944852941178,
      "grad_norm": 1.0188558101654053,
      "learning_rate": 6.725388071895425e-06,
      "loss": 0.0432,
      "step": 8593
    },
    {
      "epoch": 1.9747242647058822,
      "grad_norm": 1.0732131004333496,
      "learning_rate": 6.724877450980392e-06,
      "loss": 0.0441,
      "step": 8594
    },
    {
      "epoch": 1.9749540441176472,
      "grad_norm": 0.9753608703613281,
      "learning_rate": 6.72436683006536e-06,
      "loss": 0.0299,
      "step": 8595
    },
    {
      "epoch": 1.9751838235294117,
      "grad_norm": 1.0244652032852173,
      "learning_rate": 6.723856209150328e-06,
      "loss": 0.0516,
      "step": 8596
    },
    {
      "epoch": 1.9754136029411766,
      "grad_norm": 1.2240524291992188,
      "learning_rate": 6.723345588235295e-06,
      "loss": 0.0765,
      "step": 8597
    },
    {
      "epoch": 1.9756433823529411,
      "grad_norm": 0.9466793537139893,
      "learning_rate": 6.722834967320262e-06,
      "loss": 0.0599,
      "step": 8598
    },
    {
      "epoch": 1.9758731617647058,
      "grad_norm": 0.7738659381866455,
      "learning_rate": 6.722324346405229e-06,
      "loss": 0.0404,
      "step": 8599
    },
    {
      "epoch": 1.9761029411764706,
      "grad_norm": 0.8083290457725525,
      "learning_rate": 6.721813725490197e-06,
      "loss": 0.0342,
      "step": 8600
    },
    {
      "epoch": 1.9763327205882353,
      "grad_norm": 1.310120701789856,
      "learning_rate": 6.721303104575164e-06,
      "loss": 0.0654,
      "step": 8601
    },
    {
      "epoch": 1.9765625,
      "grad_norm": 0.97379469871521,
      "learning_rate": 6.720792483660131e-06,
      "loss": 0.0324,
      "step": 8602
    },
    {
      "epoch": 1.9767922794117647,
      "grad_norm": 1.0460537672042847,
      "learning_rate": 6.720281862745098e-06,
      "loss": 0.0502,
      "step": 8603
    },
    {
      "epoch": 1.9770220588235294,
      "grad_norm": 1.1152724027633667,
      "learning_rate": 6.719771241830067e-06,
      "loss": 0.0477,
      "step": 8604
    },
    {
      "epoch": 1.9772518382352942,
      "grad_norm": 0.9418917298316956,
      "learning_rate": 6.719260620915034e-06,
      "loss": 0.0604,
      "step": 8605
    },
    {
      "epoch": 1.9774816176470589,
      "grad_norm": 1.1241093873977661,
      "learning_rate": 6.718750000000001e-06,
      "loss": 0.0573,
      "step": 8606
    },
    {
      "epoch": 1.9777113970588234,
      "grad_norm": 0.990235447883606,
      "learning_rate": 6.718239379084968e-06,
      "loss": 0.045,
      "step": 8607
    },
    {
      "epoch": 1.9779411764705883,
      "grad_norm": 0.7262500524520874,
      "learning_rate": 6.717728758169935e-06,
      "loss": 0.0261,
      "step": 8608
    },
    {
      "epoch": 1.9781709558823528,
      "grad_norm": 0.9620071053504944,
      "learning_rate": 6.7172181372549026e-06,
      "loss": 0.0507,
      "step": 8609
    },
    {
      "epoch": 1.9784007352941178,
      "grad_norm": 0.9565419554710388,
      "learning_rate": 6.71670751633987e-06,
      "loss": 0.0353,
      "step": 8610
    },
    {
      "epoch": 1.9786305147058822,
      "grad_norm": 0.998895525932312,
      "learning_rate": 6.716196895424837e-06,
      "loss": 0.0497,
      "step": 8611
    },
    {
      "epoch": 1.9788602941176472,
      "grad_norm": 0.8569348454475403,
      "learning_rate": 6.715686274509804e-06,
      "loss": 0.0402,
      "step": 8612
    },
    {
      "epoch": 1.9790900735294117,
      "grad_norm": 0.8713416457176208,
      "learning_rate": 6.715175653594772e-06,
      "loss": 0.0278,
      "step": 8613
    },
    {
      "epoch": 1.9793198529411766,
      "grad_norm": 0.8113464713096619,
      "learning_rate": 6.714665032679739e-06,
      "loss": 0.0455,
      "step": 8614
    },
    {
      "epoch": 1.9795496323529411,
      "grad_norm": 0.9926378726959229,
      "learning_rate": 6.714154411764706e-06,
      "loss": 0.0352,
      "step": 8615
    },
    {
      "epoch": 1.9797794117647058,
      "grad_norm": 0.9925740957260132,
      "learning_rate": 6.713643790849673e-06,
      "loss": 0.0465,
      "step": 8616
    },
    {
      "epoch": 1.9800091911764706,
      "grad_norm": 1.4664311408996582,
      "learning_rate": 6.713133169934641e-06,
      "loss": 0.0628,
      "step": 8617
    },
    {
      "epoch": 1.9802389705882353,
      "grad_norm": 0.7923387289047241,
      "learning_rate": 6.712622549019608e-06,
      "loss": 0.0273,
      "step": 8618
    },
    {
      "epoch": 1.98046875,
      "grad_norm": 0.8833896517753601,
      "learning_rate": 6.712111928104575e-06,
      "loss": 0.0348,
      "step": 8619
    },
    {
      "epoch": 1.9806985294117647,
      "grad_norm": 1.219616413116455,
      "learning_rate": 6.711601307189542e-06,
      "loss": 0.0596,
      "step": 8620
    },
    {
      "epoch": 1.9809283088235294,
      "grad_norm": 1.067646861076355,
      "learning_rate": 6.711090686274511e-06,
      "loss": 0.0402,
      "step": 8621
    },
    {
      "epoch": 1.9811580882352942,
      "grad_norm": 1.0744426250457764,
      "learning_rate": 6.710580065359478e-06,
      "loss": 0.046,
      "step": 8622
    },
    {
      "epoch": 1.9813878676470589,
      "grad_norm": 0.9105323553085327,
      "learning_rate": 6.710069444444445e-06,
      "loss": 0.0527,
      "step": 8623
    },
    {
      "epoch": 1.9816176470588234,
      "grad_norm": 0.8123772740364075,
      "learning_rate": 6.709558823529412e-06,
      "loss": 0.0316,
      "step": 8624
    },
    {
      "epoch": 1.9818474264705883,
      "grad_norm": 0.6422359347343445,
      "learning_rate": 6.70904820261438e-06,
      "loss": 0.0237,
      "step": 8625
    },
    {
      "epoch": 1.9820772058823528,
      "grad_norm": 1.0850284099578857,
      "learning_rate": 6.708537581699347e-06,
      "loss": 0.0431,
      "step": 8626
    },
    {
      "epoch": 1.9823069852941178,
      "grad_norm": 0.8390325307846069,
      "learning_rate": 6.708026960784314e-06,
      "loss": 0.0572,
      "step": 8627
    },
    {
      "epoch": 1.9825367647058822,
      "grad_norm": 0.8097668886184692,
      "learning_rate": 6.707516339869281e-06,
      "loss": 0.0269,
      "step": 8628
    },
    {
      "epoch": 1.9827665441176472,
      "grad_norm": 0.9960322380065918,
      "learning_rate": 6.70700571895425e-06,
      "loss": 0.0425,
      "step": 8629
    },
    {
      "epoch": 1.9829963235294117,
      "grad_norm": 1.1438462734222412,
      "learning_rate": 6.706495098039217e-06,
      "loss": 0.0559,
      "step": 8630
    },
    {
      "epoch": 1.9832261029411766,
      "grad_norm": 0.7213563919067383,
      "learning_rate": 6.705984477124184e-06,
      "loss": 0.0272,
      "step": 8631
    },
    {
      "epoch": 1.9834558823529411,
      "grad_norm": 1.1234248876571655,
      "learning_rate": 6.705473856209151e-06,
      "loss": 0.0449,
      "step": 8632
    },
    {
      "epoch": 1.9836856617647058,
      "grad_norm": 0.9678242206573486,
      "learning_rate": 6.7049632352941185e-06,
      "loss": 0.0505,
      "step": 8633
    },
    {
      "epoch": 1.9839154411764706,
      "grad_norm": 0.9530429244041443,
      "learning_rate": 6.7044526143790856e-06,
      "loss": 0.0407,
      "step": 8634
    },
    {
      "epoch": 1.9841452205882353,
      "grad_norm": 0.929486095905304,
      "learning_rate": 6.7039419934640526e-06,
      "loss": 0.0349,
      "step": 8635
    },
    {
      "epoch": 1.984375,
      "grad_norm": 0.8957226872444153,
      "learning_rate": 6.70343137254902e-06,
      "loss": 0.0476,
      "step": 8636
    },
    {
      "epoch": 1.9846047794117647,
      "grad_norm": 0.9447131156921387,
      "learning_rate": 6.7029207516339874e-06,
      "loss": 0.0339,
      "step": 8637
    },
    {
      "epoch": 1.9848345588235294,
      "grad_norm": 1.291478157043457,
      "learning_rate": 6.7024101307189545e-06,
      "loss": 0.0465,
      "step": 8638
    },
    {
      "epoch": 1.9850643382352942,
      "grad_norm": 1.042035460472107,
      "learning_rate": 6.701899509803922e-06,
      "loss": 0.0524,
      "step": 8639
    },
    {
      "epoch": 1.9852941176470589,
      "grad_norm": 2.1805481910705566,
      "learning_rate": 6.701388888888889e-06,
      "loss": 0.0488,
      "step": 8640
    },
    {
      "epoch": 1.9855238970588234,
      "grad_norm": 1.1699939966201782,
      "learning_rate": 6.700878267973857e-06,
      "loss": 0.0548,
      "step": 8641
    },
    {
      "epoch": 1.9857536764705883,
      "grad_norm": 1.0369337797164917,
      "learning_rate": 6.700367647058824e-06,
      "loss": 0.0615,
      "step": 8642
    },
    {
      "epoch": 1.9859834558823528,
      "grad_norm": 1.0106556415557861,
      "learning_rate": 6.699857026143791e-06,
      "loss": 0.0403,
      "step": 8643
    },
    {
      "epoch": 1.9862132352941178,
      "grad_norm": 0.7723209857940674,
      "learning_rate": 6.699346405228758e-06,
      "loss": 0.0385,
      "step": 8644
    },
    {
      "epoch": 1.9864430147058822,
      "grad_norm": 1.1723552942276,
      "learning_rate": 6.698835784313726e-06,
      "loss": 0.0433,
      "step": 8645
    },
    {
      "epoch": 1.9866727941176472,
      "grad_norm": 1.0108062028884888,
      "learning_rate": 6.698325163398693e-06,
      "loss": 0.0663,
      "step": 8646
    },
    {
      "epoch": 1.9869025735294117,
      "grad_norm": 1.2503947019577026,
      "learning_rate": 6.69781454248366e-06,
      "loss": 0.0655,
      "step": 8647
    },
    {
      "epoch": 1.9871323529411766,
      "grad_norm": 0.913461446762085,
      "learning_rate": 6.697303921568627e-06,
      "loss": 0.0443,
      "step": 8648
    },
    {
      "epoch": 1.9873621323529411,
      "grad_norm": 1.1997066736221313,
      "learning_rate": 6.696793300653596e-06,
      "loss": 0.0421,
      "step": 8649
    },
    {
      "epoch": 1.9875919117647058,
      "grad_norm": 0.6596279144287109,
      "learning_rate": 6.696282679738563e-06,
      "loss": 0.0376,
      "step": 8650
    },
    {
      "epoch": 1.9878216911764706,
      "grad_norm": 1.0113472938537598,
      "learning_rate": 6.69577205882353e-06,
      "loss": 0.0409,
      "step": 8651
    },
    {
      "epoch": 1.9880514705882353,
      "grad_norm": 1.0822052955627441,
      "learning_rate": 6.695261437908497e-06,
      "loss": 0.0469,
      "step": 8652
    },
    {
      "epoch": 1.98828125,
      "grad_norm": 1.1092778444290161,
      "learning_rate": 6.694750816993465e-06,
      "loss": 0.0478,
      "step": 8653
    },
    {
      "epoch": 1.9885110294117647,
      "grad_norm": 0.8170839548110962,
      "learning_rate": 6.694240196078432e-06,
      "loss": 0.0428,
      "step": 8654
    },
    {
      "epoch": 1.9887408088235294,
      "grad_norm": 1.2065030336380005,
      "learning_rate": 6.693729575163399e-06,
      "loss": 0.0496,
      "step": 8655
    },
    {
      "epoch": 1.9889705882352942,
      "grad_norm": 1.1449202299118042,
      "learning_rate": 6.693218954248366e-06,
      "loss": 0.044,
      "step": 8656
    },
    {
      "epoch": 1.9892003676470589,
      "grad_norm": 0.748233437538147,
      "learning_rate": 6.6927083333333345e-06,
      "loss": 0.0255,
      "step": 8657
    },
    {
      "epoch": 1.9894301470588234,
      "grad_norm": 1.1644985675811768,
      "learning_rate": 6.6921977124183015e-06,
      "loss": 0.0588,
      "step": 8658
    },
    {
      "epoch": 1.9896599264705883,
      "grad_norm": 0.7865719795227051,
      "learning_rate": 6.6916870915032685e-06,
      "loss": 0.0431,
      "step": 8659
    },
    {
      "epoch": 1.9898897058823528,
      "grad_norm": 1.332229495048523,
      "learning_rate": 6.6911764705882356e-06,
      "loss": 0.0806,
      "step": 8660
    },
    {
      "epoch": 1.9901194852941178,
      "grad_norm": 1.3803778886795044,
      "learning_rate": 6.690665849673203e-06,
      "loss": 0.0546,
      "step": 8661
    },
    {
      "epoch": 1.9903492647058822,
      "grad_norm": 0.8580063581466675,
      "learning_rate": 6.6901552287581704e-06,
      "loss": 0.0432,
      "step": 8662
    },
    {
      "epoch": 1.9905790441176472,
      "grad_norm": 0.9418846964836121,
      "learning_rate": 6.6896446078431374e-06,
      "loss": 0.0443,
      "step": 8663
    },
    {
      "epoch": 1.9908088235294117,
      "grad_norm": 0.9907877445220947,
      "learning_rate": 6.6891339869281045e-06,
      "loss": 0.0595,
      "step": 8664
    },
    {
      "epoch": 1.9910386029411766,
      "grad_norm": 0.8333671689033508,
      "learning_rate": 6.688623366013073e-06,
      "loss": 0.0407,
      "step": 8665
    },
    {
      "epoch": 1.9912683823529411,
      "grad_norm": 0.9418067932128906,
      "learning_rate": 6.68811274509804e-06,
      "loss": 0.049,
      "step": 8666
    },
    {
      "epoch": 1.9914981617647058,
      "grad_norm": 1.0818822383880615,
      "learning_rate": 6.687602124183007e-06,
      "loss": 0.0689,
      "step": 8667
    },
    {
      "epoch": 1.9917279411764706,
      "grad_norm": 0.903104841709137,
      "learning_rate": 6.687091503267974e-06,
      "loss": 0.0298,
      "step": 8668
    },
    {
      "epoch": 1.9919577205882353,
      "grad_norm": 0.9976871013641357,
      "learning_rate": 6.686580882352942e-06,
      "loss": 0.0448,
      "step": 8669
    },
    {
      "epoch": 1.9921875,
      "grad_norm": 0.7865661382675171,
      "learning_rate": 6.686070261437909e-06,
      "loss": 0.0354,
      "step": 8670
    },
    {
      "epoch": 1.9924172794117647,
      "grad_norm": 0.9194270372390747,
      "learning_rate": 6.685559640522876e-06,
      "loss": 0.0495,
      "step": 8671
    },
    {
      "epoch": 1.9926470588235294,
      "grad_norm": 1.0187116861343384,
      "learning_rate": 6.685049019607843e-06,
      "loss": 0.0576,
      "step": 8672
    },
    {
      "epoch": 1.9928768382352942,
      "grad_norm": 0.6947571039199829,
      "learning_rate": 6.684538398692812e-06,
      "loss": 0.0377,
      "step": 8673
    },
    {
      "epoch": 1.9931066176470589,
      "grad_norm": 1.173870325088501,
      "learning_rate": 6.684027777777779e-06,
      "loss": 0.0424,
      "step": 8674
    },
    {
      "epoch": 1.9933363970588234,
      "grad_norm": 1.0162638425827026,
      "learning_rate": 6.683517156862746e-06,
      "loss": 0.0479,
      "step": 8675
    },
    {
      "epoch": 1.9935661764705883,
      "grad_norm": 1.0039854049682617,
      "learning_rate": 6.683006535947713e-06,
      "loss": 0.0579,
      "step": 8676
    },
    {
      "epoch": 1.9937959558823528,
      "grad_norm": 0.8171591758728027,
      "learning_rate": 6.682495915032681e-06,
      "loss": 0.0405,
      "step": 8677
    },
    {
      "epoch": 1.9940257352941178,
      "grad_norm": 0.9454262852668762,
      "learning_rate": 6.681985294117648e-06,
      "loss": 0.041,
      "step": 8678
    },
    {
      "epoch": 1.9942555147058822,
      "grad_norm": 0.7480417490005493,
      "learning_rate": 6.681474673202615e-06,
      "loss": 0.0294,
      "step": 8679
    },
    {
      "epoch": 1.9944852941176472,
      "grad_norm": 0.5363818407058716,
      "learning_rate": 6.680964052287582e-06,
      "loss": 0.022,
      "step": 8680
    },
    {
      "epoch": 1.9947150735294117,
      "grad_norm": 0.9862712621688843,
      "learning_rate": 6.68045343137255e-06,
      "loss": 0.0526,
      "step": 8681
    },
    {
      "epoch": 1.9949448529411766,
      "grad_norm": 0.7706205248832703,
      "learning_rate": 6.679942810457517e-06,
      "loss": 0.0397,
      "step": 8682
    },
    {
      "epoch": 1.9951746323529411,
      "grad_norm": 0.8536419868469238,
      "learning_rate": 6.679432189542484e-06,
      "loss": 0.0377,
      "step": 8683
    },
    {
      "epoch": 1.9954044117647058,
      "grad_norm": 1.2158466577529907,
      "learning_rate": 6.6789215686274515e-06,
      "loss": 0.0507,
      "step": 8684
    },
    {
      "epoch": 1.9956341911764706,
      "grad_norm": 0.8954904675483704,
      "learning_rate": 6.678410947712419e-06,
      "loss": 0.0432,
      "step": 8685
    },
    {
      "epoch": 1.9958639705882353,
      "grad_norm": 0.8517258763313293,
      "learning_rate": 6.677900326797386e-06,
      "loss": 0.0358,
      "step": 8686
    },
    {
      "epoch": 1.99609375,
      "grad_norm": 1.1336833238601685,
      "learning_rate": 6.677389705882353e-06,
      "loss": 0.0662,
      "step": 8687
    },
    {
      "epoch": 1.9963235294117647,
      "grad_norm": 1.0471304655075073,
      "learning_rate": 6.6768790849673204e-06,
      "loss": 0.045,
      "step": 8688
    },
    {
      "epoch": 1.9965533088235294,
      "grad_norm": 1.085820198059082,
      "learning_rate": 6.676368464052288e-06,
      "loss": 0.0465,
      "step": 8689
    },
    {
      "epoch": 1.9967830882352942,
      "grad_norm": 1.0101498365402222,
      "learning_rate": 6.675857843137255e-06,
      "loss": 0.0506,
      "step": 8690
    },
    {
      "epoch": 1.9970128676470589,
      "grad_norm": 0.9790524840354919,
      "learning_rate": 6.675347222222222e-06,
      "loss": 0.0426,
      "step": 8691
    },
    {
      "epoch": 1.9972426470588234,
      "grad_norm": 1.0854448080062866,
      "learning_rate": 6.674836601307189e-06,
      "loss": 0.0495,
      "step": 8692
    },
    {
      "epoch": 1.9974724264705883,
      "grad_norm": 1.0554299354553223,
      "learning_rate": 6.674325980392158e-06,
      "loss": 0.0571,
      "step": 8693
    },
    {
      "epoch": 1.9977022058823528,
      "grad_norm": 0.9759488701820374,
      "learning_rate": 6.673815359477125e-06,
      "loss": 0.0499,
      "step": 8694
    },
    {
      "epoch": 1.9979319852941178,
      "grad_norm": 0.7850949764251709,
      "learning_rate": 6.673304738562092e-06,
      "loss": 0.0407,
      "step": 8695
    },
    {
      "epoch": 1.9981617647058822,
      "grad_norm": 0.5878980755805969,
      "learning_rate": 6.672794117647059e-06,
      "loss": 0.0202,
      "step": 8696
    },
    {
      "epoch": 1.9983915441176472,
      "grad_norm": 0.7290304899215698,
      "learning_rate": 6.672283496732027e-06,
      "loss": 0.0347,
      "step": 8697
    },
    {
      "epoch": 1.9986213235294117,
      "grad_norm": 0.8494381308555603,
      "learning_rate": 6.671772875816994e-06,
      "loss": 0.0378,
      "step": 8698
    },
    {
      "epoch": 1.9988511029411766,
      "grad_norm": 1.0772157907485962,
      "learning_rate": 6.671262254901961e-06,
      "loss": 0.0415,
      "step": 8699
    },
    {
      "epoch": 1.9990808823529411,
      "grad_norm": 0.9275455474853516,
      "learning_rate": 6.670751633986928e-06,
      "loss": 0.0542,
      "step": 8700
    },
    {
      "epoch": 1.9993106617647058,
      "grad_norm": 1.076518177986145,
      "learning_rate": 6.670241013071897e-06,
      "loss": 0.0603,
      "step": 8701
    },
    {
      "epoch": 1.9995404411764706,
      "grad_norm": 0.7737194895744324,
      "learning_rate": 6.669730392156864e-06,
      "loss": 0.0429,
      "step": 8702
    },
    {
      "epoch": 1.9997702205882353,
      "grad_norm": 0.7299259305000305,
      "learning_rate": 6.669219771241831e-06,
      "loss": 0.0359,
      "step": 8703
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.848884642124176,
      "learning_rate": 6.668709150326798e-06,
      "loss": 0.0392,
      "step": 8704
    },
    {
      "epoch": 2.0002297794117645,
      "grad_norm": 0.6287181377410889,
      "learning_rate": 6.668198529411766e-06,
      "loss": 0.032,
      "step": 8705
    },
    {
      "epoch": 2.0004595588235294,
      "grad_norm": 0.9533396363258362,
      "learning_rate": 6.667687908496733e-06,
      "loss": 0.0434,
      "step": 8706
    },
    {
      "epoch": 2.000689338235294,
      "grad_norm": 0.939435601234436,
      "learning_rate": 6.6671772875817e-06,
      "loss": 0.04,
      "step": 8707
    },
    {
      "epoch": 2.000919117647059,
      "grad_norm": 0.7587786316871643,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.031,
      "step": 8708
    },
    {
      "epoch": 2.0011488970588234,
      "grad_norm": 0.8166541457176208,
      "learning_rate": 6.666156045751635e-06,
      "loss": 0.0314,
      "step": 8709
    },
    {
      "epoch": 2.0013786764705883,
      "grad_norm": 0.9033381342887878,
      "learning_rate": 6.665645424836602e-06,
      "loss": 0.0425,
      "step": 8710
    },
    {
      "epoch": 2.001608455882353,
      "grad_norm": 0.7534870505332947,
      "learning_rate": 6.665134803921569e-06,
      "loss": 0.0364,
      "step": 8711
    },
    {
      "epoch": 2.0018382352941178,
      "grad_norm": 0.9012510776519775,
      "learning_rate": 6.664624183006536e-06,
      "loss": 0.0467,
      "step": 8712
    },
    {
      "epoch": 2.0020680147058822,
      "grad_norm": 1.1150230169296265,
      "learning_rate": 6.664113562091504e-06,
      "loss": 0.0543,
      "step": 8713
    },
    {
      "epoch": 2.002297794117647,
      "grad_norm": 0.9742277264595032,
      "learning_rate": 6.663602941176471e-06,
      "loss": 0.0492,
      "step": 8714
    },
    {
      "epoch": 2.0025275735294117,
      "grad_norm": 1.0549107789993286,
      "learning_rate": 6.663092320261438e-06,
      "loss": 0.0495,
      "step": 8715
    },
    {
      "epoch": 2.0027573529411766,
      "grad_norm": 0.8067837953567505,
      "learning_rate": 6.662581699346405e-06,
      "loss": 0.0322,
      "step": 8716
    },
    {
      "epoch": 2.002987132352941,
      "grad_norm": 0.8587728142738342,
      "learning_rate": 6.662071078431373e-06,
      "loss": 0.0407,
      "step": 8717
    },
    {
      "epoch": 2.003216911764706,
      "grad_norm": 0.8407264947891235,
      "learning_rate": 6.661560457516341e-06,
      "loss": 0.0525,
      "step": 8718
    },
    {
      "epoch": 2.0034466911764706,
      "grad_norm": 0.6578453183174133,
      "learning_rate": 6.661049836601308e-06,
      "loss": 0.0336,
      "step": 8719
    },
    {
      "epoch": 2.0036764705882355,
      "grad_norm": 1.0541023015975952,
      "learning_rate": 6.660539215686275e-06,
      "loss": 0.0524,
      "step": 8720
    },
    {
      "epoch": 2.00390625,
      "grad_norm": 1.1054232120513916,
      "learning_rate": 6.660028594771243e-06,
      "loss": 0.0523,
      "step": 8721
    },
    {
      "epoch": 2.0041360294117645,
      "grad_norm": 1.1978840827941895,
      "learning_rate": 6.65951797385621e-06,
      "loss": 0.0519,
      "step": 8722
    },
    {
      "epoch": 2.0043658088235294,
      "grad_norm": 0.8102008104324341,
      "learning_rate": 6.659007352941177e-06,
      "loss": 0.0385,
      "step": 8723
    },
    {
      "epoch": 2.004595588235294,
      "grad_norm": 1.1614744663238525,
      "learning_rate": 6.658496732026144e-06,
      "loss": 0.0495,
      "step": 8724
    },
    {
      "epoch": 2.004825367647059,
      "grad_norm": 1.0456541776657104,
      "learning_rate": 6.657986111111112e-06,
      "loss": 0.0418,
      "step": 8725
    },
    {
      "epoch": 2.0050551470588234,
      "grad_norm": 1.1503547430038452,
      "learning_rate": 6.657475490196079e-06,
      "loss": 0.0598,
      "step": 8726
    },
    {
      "epoch": 2.0052849264705883,
      "grad_norm": 0.9048783183097839,
      "learning_rate": 6.656964869281046e-06,
      "loss": 0.0428,
      "step": 8727
    },
    {
      "epoch": 2.005514705882353,
      "grad_norm": 0.9981974959373474,
      "learning_rate": 6.656454248366013e-06,
      "loss": 0.0571,
      "step": 8728
    },
    {
      "epoch": 2.0057444852941178,
      "grad_norm": 1.233744502067566,
      "learning_rate": 6.6559436274509816e-06,
      "loss": 0.057,
      "step": 8729
    },
    {
      "epoch": 2.0059742647058822,
      "grad_norm": 1.2085559368133545,
      "learning_rate": 6.655433006535949e-06,
      "loss": 0.0451,
      "step": 8730
    },
    {
      "epoch": 2.006204044117647,
      "grad_norm": 0.7377836108207703,
      "learning_rate": 6.654922385620916e-06,
      "loss": 0.047,
      "step": 8731
    },
    {
      "epoch": 2.0064338235294117,
      "grad_norm": 1.248532772064209,
      "learning_rate": 6.654411764705883e-06,
      "loss": 0.0702,
      "step": 8732
    },
    {
      "epoch": 2.0066636029411766,
      "grad_norm": 0.967187762260437,
      "learning_rate": 6.6539011437908505e-06,
      "loss": 0.0363,
      "step": 8733
    },
    {
      "epoch": 2.006893382352941,
      "grad_norm": 1.141684889793396,
      "learning_rate": 6.6533905228758175e-06,
      "loss": 0.0475,
      "step": 8734
    },
    {
      "epoch": 2.007123161764706,
      "grad_norm": 0.8535624146461487,
      "learning_rate": 6.6528799019607845e-06,
      "loss": 0.0297,
      "step": 8735
    },
    {
      "epoch": 2.0073529411764706,
      "grad_norm": 0.7456412315368652,
      "learning_rate": 6.6523692810457515e-06,
      "loss": 0.026,
      "step": 8736
    },
    {
      "epoch": 2.0075827205882355,
      "grad_norm": 1.0168007612228394,
      "learning_rate": 6.65185866013072e-06,
      "loss": 0.0554,
      "step": 8737
    },
    {
      "epoch": 2.0078125,
      "grad_norm": 1.0515079498291016,
      "learning_rate": 6.651348039215687e-06,
      "loss": 0.0518,
      "step": 8738
    },
    {
      "epoch": 2.0080422794117645,
      "grad_norm": 1.1117948293685913,
      "learning_rate": 6.650837418300654e-06,
      "loss": 0.0602,
      "step": 8739
    },
    {
      "epoch": 2.0082720588235294,
      "grad_norm": 1.0072036981582642,
      "learning_rate": 6.650326797385621e-06,
      "loss": 0.0408,
      "step": 8740
    },
    {
      "epoch": 2.008501838235294,
      "grad_norm": 1.161146879196167,
      "learning_rate": 6.649816176470589e-06,
      "loss": 0.0848,
      "step": 8741
    },
    {
      "epoch": 2.008731617647059,
      "grad_norm": 0.8472017645835876,
      "learning_rate": 6.649305555555556e-06,
      "loss": 0.0302,
      "step": 8742
    },
    {
      "epoch": 2.0089613970588234,
      "grad_norm": 0.7033374905586243,
      "learning_rate": 6.648794934640523e-06,
      "loss": 0.0276,
      "step": 8743
    },
    {
      "epoch": 2.0091911764705883,
      "grad_norm": 1.1580508947372437,
      "learning_rate": 6.64828431372549e-06,
      "loss": 0.0387,
      "step": 8744
    },
    {
      "epoch": 2.009420955882353,
      "grad_norm": 0.9866961240768433,
      "learning_rate": 6.647773692810459e-06,
      "loss": 0.0581,
      "step": 8745
    },
    {
      "epoch": 2.0096507352941178,
      "grad_norm": 0.9276576638221741,
      "learning_rate": 6.647263071895426e-06,
      "loss": 0.0322,
      "step": 8746
    },
    {
      "epoch": 2.0098805147058822,
      "grad_norm": 0.7981828451156616,
      "learning_rate": 6.646752450980393e-06,
      "loss": 0.0395,
      "step": 8747
    },
    {
      "epoch": 2.010110294117647,
      "grad_norm": 0.720782995223999,
      "learning_rate": 6.64624183006536e-06,
      "loss": 0.0325,
      "step": 8748
    },
    {
      "epoch": 2.0103400735294117,
      "grad_norm": 0.8058632612228394,
      "learning_rate": 6.645731209150328e-06,
      "loss": 0.04,
      "step": 8749
    },
    {
      "epoch": 2.0105698529411766,
      "grad_norm": 0.8770878314971924,
      "learning_rate": 6.645220588235295e-06,
      "loss": 0.0372,
      "step": 8750
    },
    {
      "epoch": 2.010799632352941,
      "grad_norm": 1.2083181142807007,
      "learning_rate": 6.644709967320262e-06,
      "loss": 0.0366,
      "step": 8751
    },
    {
      "epoch": 2.011029411764706,
      "grad_norm": 0.6885548830032349,
      "learning_rate": 6.644199346405229e-06,
      "loss": 0.033,
      "step": 8752
    },
    {
      "epoch": 2.0112591911764706,
      "grad_norm": 1.0104782581329346,
      "learning_rate": 6.6436887254901975e-06,
      "loss": 0.071,
      "step": 8753
    },
    {
      "epoch": 2.0114889705882355,
      "grad_norm": 0.9612784385681152,
      "learning_rate": 6.6431781045751646e-06,
      "loss": 0.0311,
      "step": 8754
    },
    {
      "epoch": 2.01171875,
      "grad_norm": 0.955447256565094,
      "learning_rate": 6.6426674836601316e-06,
      "loss": 0.0508,
      "step": 8755
    },
    {
      "epoch": 2.0119485294117645,
      "grad_norm": 1.1243771314620972,
      "learning_rate": 6.642156862745099e-06,
      "loss": 0.0456,
      "step": 8756
    },
    {
      "epoch": 2.0121783088235294,
      "grad_norm": 0.9191295504570007,
      "learning_rate": 6.6416462418300664e-06,
      "loss": 0.0529,
      "step": 8757
    },
    {
      "epoch": 2.012408088235294,
      "grad_norm": 1.0941741466522217,
      "learning_rate": 6.6411356209150335e-06,
      "loss": 0.0535,
      "step": 8758
    },
    {
      "epoch": 2.012637867647059,
      "grad_norm": 1.0643500089645386,
      "learning_rate": 6.6406250000000005e-06,
      "loss": 0.0479,
      "step": 8759
    },
    {
      "epoch": 2.0128676470588234,
      "grad_norm": 0.7042094469070435,
      "learning_rate": 6.6401143790849675e-06,
      "loss": 0.0326,
      "step": 8760
    },
    {
      "epoch": 2.0130974264705883,
      "grad_norm": 1.1473640203475952,
      "learning_rate": 6.6396037581699345e-06,
      "loss": 0.0564,
      "step": 8761
    },
    {
      "epoch": 2.013327205882353,
      "grad_norm": 1.058249831199646,
      "learning_rate": 6.639093137254902e-06,
      "loss": 0.0586,
      "step": 8762
    },
    {
      "epoch": 2.0135569852941178,
      "grad_norm": 1.1993733644485474,
      "learning_rate": 6.63858251633987e-06,
      "loss": 0.0452,
      "step": 8763
    },
    {
      "epoch": 2.0137867647058822,
      "grad_norm": 0.7214064002037048,
      "learning_rate": 6.638071895424837e-06,
      "loss": 0.0341,
      "step": 8764
    },
    {
      "epoch": 2.014016544117647,
      "grad_norm": 1.4043656587600708,
      "learning_rate": 6.637561274509804e-06,
      "loss": 0.071,
      "step": 8765
    },
    {
      "epoch": 2.0142463235294117,
      "grad_norm": 0.9339644312858582,
      "learning_rate": 6.637050653594772e-06,
      "loss": 0.0543,
      "step": 8766
    },
    {
      "epoch": 2.0144761029411766,
      "grad_norm": 0.8557146191596985,
      "learning_rate": 6.636540032679739e-06,
      "loss": 0.0305,
      "step": 8767
    },
    {
      "epoch": 2.014705882352941,
      "grad_norm": 1.0219695568084717,
      "learning_rate": 6.636029411764706e-06,
      "loss": 0.048,
      "step": 8768
    },
    {
      "epoch": 2.014935661764706,
      "grad_norm": 0.6981847286224365,
      "learning_rate": 6.635518790849673e-06,
      "loss": 0.0342,
      "step": 8769
    },
    {
      "epoch": 2.0151654411764706,
      "grad_norm": 1.2906535863876343,
      "learning_rate": 6.635008169934641e-06,
      "loss": 0.059,
      "step": 8770
    },
    {
      "epoch": 2.0153952205882355,
      "grad_norm": 0.871489405632019,
      "learning_rate": 6.634497549019608e-06,
      "loss": 0.0646,
      "step": 8771
    },
    {
      "epoch": 2.015625,
      "grad_norm": 0.7568601369857788,
      "learning_rate": 6.633986928104575e-06,
      "loss": 0.0185,
      "step": 8772
    },
    {
      "epoch": 2.0158547794117645,
      "grad_norm": 0.6851853132247925,
      "learning_rate": 6.633476307189543e-06,
      "loss": 0.0365,
      "step": 8773
    },
    {
      "epoch": 2.0160845588235294,
      "grad_norm": 0.6168209910392761,
      "learning_rate": 6.632965686274511e-06,
      "loss": 0.0222,
      "step": 8774
    },
    {
      "epoch": 2.016314338235294,
      "grad_norm": 0.8828266859054565,
      "learning_rate": 6.632455065359478e-06,
      "loss": 0.044,
      "step": 8775
    },
    {
      "epoch": 2.016544117647059,
      "grad_norm": 1.1308237314224243,
      "learning_rate": 6.631944444444445e-06,
      "loss": 0.0352,
      "step": 8776
    },
    {
      "epoch": 2.0167738970588234,
      "grad_norm": 1.0537678003311157,
      "learning_rate": 6.631433823529412e-06,
      "loss": 0.0517,
      "step": 8777
    },
    {
      "epoch": 2.0170036764705883,
      "grad_norm": 1.121373176574707,
      "learning_rate": 6.63092320261438e-06,
      "loss": 0.0591,
      "step": 8778
    },
    {
      "epoch": 2.017233455882353,
      "grad_norm": 1.042452335357666,
      "learning_rate": 6.630412581699347e-06,
      "loss": 0.0701,
      "step": 8779
    },
    {
      "epoch": 2.0174632352941178,
      "grad_norm": 0.8679059743881226,
      "learning_rate": 6.629901960784314e-06,
      "loss": 0.0399,
      "step": 8780
    },
    {
      "epoch": 2.0176930147058822,
      "grad_norm": 1.1163175106048584,
      "learning_rate": 6.629391339869281e-06,
      "loss": 0.047,
      "step": 8781
    },
    {
      "epoch": 2.017922794117647,
      "grad_norm": 1.1617391109466553,
      "learning_rate": 6.6288807189542494e-06,
      "loss": 0.0639,
      "step": 8782
    },
    {
      "epoch": 2.0181525735294117,
      "grad_norm": 0.8029547929763794,
      "learning_rate": 6.6283700980392164e-06,
      "loss": 0.0336,
      "step": 8783
    },
    {
      "epoch": 2.0183823529411766,
      "grad_norm": 1.109084129333496,
      "learning_rate": 6.6278594771241835e-06,
      "loss": 0.0534,
      "step": 8784
    },
    {
      "epoch": 2.018612132352941,
      "grad_norm": 1.0722627639770508,
      "learning_rate": 6.6273488562091505e-06,
      "loss": 0.0599,
      "step": 8785
    },
    {
      "epoch": 2.018841911764706,
      "grad_norm": 0.6341049671173096,
      "learning_rate": 6.626838235294118e-06,
      "loss": 0.028,
      "step": 8786
    },
    {
      "epoch": 2.0190716911764706,
      "grad_norm": 0.7304189205169678,
      "learning_rate": 6.626327614379085e-06,
      "loss": 0.0482,
      "step": 8787
    },
    {
      "epoch": 2.0193014705882355,
      "grad_norm": 0.7404254078865051,
      "learning_rate": 6.625816993464052e-06,
      "loss": 0.0416,
      "step": 8788
    },
    {
      "epoch": 2.01953125,
      "grad_norm": 0.8727657794952393,
      "learning_rate": 6.625306372549019e-06,
      "loss": 0.046,
      "step": 8789
    },
    {
      "epoch": 2.0197610294117645,
      "grad_norm": 1.1890515089035034,
      "learning_rate": 6.624795751633988e-06,
      "loss": 0.0377,
      "step": 8790
    },
    {
      "epoch": 2.0199908088235294,
      "grad_norm": 1.2314211130142212,
      "learning_rate": 6.624285130718955e-06,
      "loss": 0.0575,
      "step": 8791
    },
    {
      "epoch": 2.020220588235294,
      "grad_norm": 0.9555495381355286,
      "learning_rate": 6.623774509803922e-06,
      "loss": 0.0307,
      "step": 8792
    },
    {
      "epoch": 2.020450367647059,
      "grad_norm": 1.3133174180984497,
      "learning_rate": 6.623263888888889e-06,
      "loss": 0.0793,
      "step": 8793
    },
    {
      "epoch": 2.0206801470588234,
      "grad_norm": 0.7978304028511047,
      "learning_rate": 6.622753267973857e-06,
      "loss": 0.0381,
      "step": 8794
    },
    {
      "epoch": 2.0209099264705883,
      "grad_norm": 0.8313353657722473,
      "learning_rate": 6.622242647058824e-06,
      "loss": 0.0325,
      "step": 8795
    },
    {
      "epoch": 2.021139705882353,
      "grad_norm": 1.3184301853179932,
      "learning_rate": 6.621732026143791e-06,
      "loss": 0.0841,
      "step": 8796
    },
    {
      "epoch": 2.0213694852941178,
      "grad_norm": 1.027313232421875,
      "learning_rate": 6.621221405228758e-06,
      "loss": 0.0371,
      "step": 8797
    },
    {
      "epoch": 2.0215992647058822,
      "grad_norm": 1.0378507375717163,
      "learning_rate": 6.620710784313727e-06,
      "loss": 0.049,
      "step": 8798
    },
    {
      "epoch": 2.021829044117647,
      "grad_norm": 0.9078816771507263,
      "learning_rate": 6.620200163398694e-06,
      "loss": 0.0316,
      "step": 8799
    },
    {
      "epoch": 2.0220588235294117,
      "grad_norm": 0.8546719551086426,
      "learning_rate": 6.619689542483661e-06,
      "loss": 0.0306,
      "step": 8800
    },
    {
      "epoch": 2.0222886029411766,
      "grad_norm": 0.9771376848220825,
      "learning_rate": 6.619178921568628e-06,
      "loss": 0.0482,
      "step": 8801
    },
    {
      "epoch": 2.022518382352941,
      "grad_norm": 1.1115144491195679,
      "learning_rate": 6.618668300653596e-06,
      "loss": 0.0489,
      "step": 8802
    },
    {
      "epoch": 2.022748161764706,
      "grad_norm": 1.2254412174224854,
      "learning_rate": 6.618157679738563e-06,
      "loss": 0.0343,
      "step": 8803
    },
    {
      "epoch": 2.0229779411764706,
      "grad_norm": 1.4370601177215576,
      "learning_rate": 6.61764705882353e-06,
      "loss": 0.0474,
      "step": 8804
    },
    {
      "epoch": 2.0232077205882355,
      "grad_norm": 1.100364327430725,
      "learning_rate": 6.617136437908497e-06,
      "loss": 0.0409,
      "step": 8805
    },
    {
      "epoch": 2.0234375,
      "grad_norm": 0.9410584568977356,
      "learning_rate": 6.6166258169934646e-06,
      "loss": 0.0362,
      "step": 8806
    },
    {
      "epoch": 2.0236672794117645,
      "grad_norm": 0.9287853240966797,
      "learning_rate": 6.616115196078432e-06,
      "loss": 0.0588,
      "step": 8807
    },
    {
      "epoch": 2.0238970588235294,
      "grad_norm": 1.1285547018051147,
      "learning_rate": 6.6156045751633994e-06,
      "loss": 0.0347,
      "step": 8808
    },
    {
      "epoch": 2.024126838235294,
      "grad_norm": 0.6066093444824219,
      "learning_rate": 6.6150939542483664e-06,
      "loss": 0.0193,
      "step": 8809
    },
    {
      "epoch": 2.024356617647059,
      "grad_norm": 0.9110666513442993,
      "learning_rate": 6.614583333333334e-06,
      "loss": 0.0467,
      "step": 8810
    },
    {
      "epoch": 2.0245863970588234,
      "grad_norm": 1.7951332330703735,
      "learning_rate": 6.614072712418301e-06,
      "loss": 0.0519,
      "step": 8811
    },
    {
      "epoch": 2.0248161764705883,
      "grad_norm": 1.1958812475204468,
      "learning_rate": 6.613562091503268e-06,
      "loss": 0.0662,
      "step": 8812
    },
    {
      "epoch": 2.025045955882353,
      "grad_norm": 1.6277023553848267,
      "learning_rate": 6.613051470588235e-06,
      "loss": 0.0533,
      "step": 8813
    },
    {
      "epoch": 2.0252757352941178,
      "grad_norm": 1.5942379236221313,
      "learning_rate": 6.612540849673203e-06,
      "loss": 0.0665,
      "step": 8814
    },
    {
      "epoch": 2.0255055147058822,
      "grad_norm": 0.7977644801139832,
      "learning_rate": 6.61203022875817e-06,
      "loss": 0.026,
      "step": 8815
    },
    {
      "epoch": 2.025735294117647,
      "grad_norm": 0.8734652996063232,
      "learning_rate": 6.611519607843137e-06,
      "loss": 0.0308,
      "step": 8816
    },
    {
      "epoch": 2.0259650735294117,
      "grad_norm": 0.6840120553970337,
      "learning_rate": 6.611008986928104e-06,
      "loss": 0.0231,
      "step": 8817
    },
    {
      "epoch": 2.0261948529411766,
      "grad_norm": 1.0775537490844727,
      "learning_rate": 6.610498366013073e-06,
      "loss": 0.0562,
      "step": 8818
    },
    {
      "epoch": 2.026424632352941,
      "grad_norm": 0.838181734085083,
      "learning_rate": 6.60998774509804e-06,
      "loss": 0.0385,
      "step": 8819
    },
    {
      "epoch": 2.026654411764706,
      "grad_norm": 0.9765439033508301,
      "learning_rate": 6.609477124183007e-06,
      "loss": 0.0367,
      "step": 8820
    },
    {
      "epoch": 2.0268841911764706,
      "grad_norm": 0.9887548685073853,
      "learning_rate": 6.608966503267974e-06,
      "loss": 0.0379,
      "step": 8821
    },
    {
      "epoch": 2.0271139705882355,
      "grad_norm": 0.9730740189552307,
      "learning_rate": 6.608455882352942e-06,
      "loss": 0.0355,
      "step": 8822
    },
    {
      "epoch": 2.02734375,
      "grad_norm": 2.9729163646698,
      "learning_rate": 6.607945261437909e-06,
      "loss": 0.0551,
      "step": 8823
    },
    {
      "epoch": 2.0275735294117645,
      "grad_norm": 1.0187444686889648,
      "learning_rate": 6.607434640522876e-06,
      "loss": 0.051,
      "step": 8824
    },
    {
      "epoch": 2.0278033088235294,
      "grad_norm": 0.9569140672683716,
      "learning_rate": 6.606924019607843e-06,
      "loss": 0.0429,
      "step": 8825
    },
    {
      "epoch": 2.028033088235294,
      "grad_norm": 1.007777214050293,
      "learning_rate": 6.606413398692812e-06,
      "loss": 0.0448,
      "step": 8826
    },
    {
      "epoch": 2.028262867647059,
      "grad_norm": 1.0286325216293335,
      "learning_rate": 6.605902777777779e-06,
      "loss": 0.0595,
      "step": 8827
    },
    {
      "epoch": 2.0284926470588234,
      "grad_norm": 0.9170736074447632,
      "learning_rate": 6.605392156862746e-06,
      "loss": 0.0461,
      "step": 8828
    },
    {
      "epoch": 2.0287224264705883,
      "grad_norm": 1.2217146158218384,
      "learning_rate": 6.604881535947713e-06,
      "loss": 0.0557,
      "step": 8829
    },
    {
      "epoch": 2.028952205882353,
      "grad_norm": 0.7313655018806458,
      "learning_rate": 6.6043709150326805e-06,
      "loss": 0.023,
      "step": 8830
    },
    {
      "epoch": 2.0291819852941178,
      "grad_norm": 1.3927990198135376,
      "learning_rate": 6.6038602941176475e-06,
      "loss": 0.0923,
      "step": 8831
    },
    {
      "epoch": 2.0294117647058822,
      "grad_norm": 1.104785680770874,
      "learning_rate": 6.6033496732026146e-06,
      "loss": 0.0463,
      "step": 8832
    },
    {
      "epoch": 2.029641544117647,
      "grad_norm": 1.0383954048156738,
      "learning_rate": 6.6028390522875816e-06,
      "loss": 0.0492,
      "step": 8833
    },
    {
      "epoch": 2.0298713235294117,
      "grad_norm": 0.7391178011894226,
      "learning_rate": 6.60232843137255e-06,
      "loss": 0.0354,
      "step": 8834
    },
    {
      "epoch": 2.0301011029411766,
      "grad_norm": 1.0596587657928467,
      "learning_rate": 6.601817810457517e-06,
      "loss": 0.0494,
      "step": 8835
    },
    {
      "epoch": 2.030330882352941,
      "grad_norm": 1.305511474609375,
      "learning_rate": 6.601307189542484e-06,
      "loss": 0.06,
      "step": 8836
    },
    {
      "epoch": 2.030560661764706,
      "grad_norm": 1.0752475261688232,
      "learning_rate": 6.600796568627451e-06,
      "loss": 0.0427,
      "step": 8837
    },
    {
      "epoch": 2.0307904411764706,
      "grad_norm": 1.090182900428772,
      "learning_rate": 6.600285947712419e-06,
      "loss": 0.0495,
      "step": 8838
    },
    {
      "epoch": 2.0310202205882355,
      "grad_norm": 0.8220418691635132,
      "learning_rate": 6.599775326797386e-06,
      "loss": 0.0344,
      "step": 8839
    },
    {
      "epoch": 2.03125,
      "grad_norm": 0.7564694285392761,
      "learning_rate": 6.599264705882353e-06,
      "loss": 0.0452,
      "step": 8840
    },
    {
      "epoch": 2.0314797794117645,
      "grad_norm": 1.1034979820251465,
      "learning_rate": 6.59875408496732e-06,
      "loss": 0.0527,
      "step": 8841
    },
    {
      "epoch": 2.0317095588235294,
      "grad_norm": 0.9742639064788818,
      "learning_rate": 6.598243464052289e-06,
      "loss": 0.0486,
      "step": 8842
    },
    {
      "epoch": 2.031939338235294,
      "grad_norm": 1.0867115259170532,
      "learning_rate": 6.597732843137256e-06,
      "loss": 0.0504,
      "step": 8843
    },
    {
      "epoch": 2.032169117647059,
      "grad_norm": 0.8814185857772827,
      "learning_rate": 6.597222222222223e-06,
      "loss": 0.0355,
      "step": 8844
    },
    {
      "epoch": 2.0323988970588234,
      "grad_norm": 0.6923615336418152,
      "learning_rate": 6.59671160130719e-06,
      "loss": 0.0205,
      "step": 8845
    },
    {
      "epoch": 2.0326286764705883,
      "grad_norm": 0.841819703578949,
      "learning_rate": 6.596200980392158e-06,
      "loss": 0.0398,
      "step": 8846
    },
    {
      "epoch": 2.032858455882353,
      "grad_norm": 1.1700693368911743,
      "learning_rate": 6.595690359477125e-06,
      "loss": 0.0521,
      "step": 8847
    },
    {
      "epoch": 2.0330882352941178,
      "grad_norm": 0.9619479179382324,
      "learning_rate": 6.595179738562092e-06,
      "loss": 0.0521,
      "step": 8848
    },
    {
      "epoch": 2.0333180147058822,
      "grad_norm": 0.9223754405975342,
      "learning_rate": 6.594669117647059e-06,
      "loss": 0.0443,
      "step": 8849
    },
    {
      "epoch": 2.033547794117647,
      "grad_norm": 0.713727593421936,
      "learning_rate": 6.594158496732027e-06,
      "loss": 0.0346,
      "step": 8850
    },
    {
      "epoch": 2.0337775735294117,
      "grad_norm": 0.8300326466560364,
      "learning_rate": 6.593647875816994e-06,
      "loss": 0.038,
      "step": 8851
    },
    {
      "epoch": 2.0340073529411766,
      "grad_norm": 0.8099273443222046,
      "learning_rate": 6.593137254901962e-06,
      "loss": 0.0255,
      "step": 8852
    },
    {
      "epoch": 2.034237132352941,
      "grad_norm": 1.0433804988861084,
      "learning_rate": 6.592626633986929e-06,
      "loss": 0.0491,
      "step": 8853
    },
    {
      "epoch": 2.034466911764706,
      "grad_norm": 1.2124817371368408,
      "learning_rate": 6.5921160130718965e-06,
      "loss": 0.0518,
      "step": 8854
    },
    {
      "epoch": 2.0346966911764706,
      "grad_norm": 0.8676118850708008,
      "learning_rate": 6.5916053921568635e-06,
      "loss": 0.0435,
      "step": 8855
    },
    {
      "epoch": 2.0349264705882355,
      "grad_norm": 1.03033447265625,
      "learning_rate": 6.5910947712418305e-06,
      "loss": 0.0517,
      "step": 8856
    },
    {
      "epoch": 2.03515625,
      "grad_norm": 0.8162639141082764,
      "learning_rate": 6.5905841503267975e-06,
      "loss": 0.036,
      "step": 8857
    },
    {
      "epoch": 2.0353860294117645,
      "grad_norm": 0.7635530233383179,
      "learning_rate": 6.590073529411765e-06,
      "loss": 0.0295,
      "step": 8858
    },
    {
      "epoch": 2.0356158088235294,
      "grad_norm": 0.9667951464653015,
      "learning_rate": 6.589562908496732e-06,
      "loss": 0.0451,
      "step": 8859
    },
    {
      "epoch": 2.035845588235294,
      "grad_norm": 0.7349085211753845,
      "learning_rate": 6.5890522875816994e-06,
      "loss": 0.031,
      "step": 8860
    },
    {
      "epoch": 2.036075367647059,
      "grad_norm": 0.6796231269836426,
      "learning_rate": 6.5885416666666664e-06,
      "loss": 0.0266,
      "step": 8861
    },
    {
      "epoch": 2.0363051470588234,
      "grad_norm": 1.183253526687622,
      "learning_rate": 6.588031045751635e-06,
      "loss": 0.0498,
      "step": 8862
    },
    {
      "epoch": 2.0365349264705883,
      "grad_norm": 0.7526534199714661,
      "learning_rate": 6.587520424836602e-06,
      "loss": 0.0316,
      "step": 8863
    },
    {
      "epoch": 2.036764705882353,
      "grad_norm": 1.2712510824203491,
      "learning_rate": 6.587009803921569e-06,
      "loss": 0.0552,
      "step": 8864
    },
    {
      "epoch": 2.0369944852941178,
      "grad_norm": 0.8385955095291138,
      "learning_rate": 6.586499183006536e-06,
      "loss": 0.0286,
      "step": 8865
    },
    {
      "epoch": 2.0372242647058822,
      "grad_norm": 1.045763611793518,
      "learning_rate": 6.585988562091504e-06,
      "loss": 0.0465,
      "step": 8866
    },
    {
      "epoch": 2.037454044117647,
      "grad_norm": 0.9760538339614868,
      "learning_rate": 6.585477941176471e-06,
      "loss": 0.0488,
      "step": 8867
    },
    {
      "epoch": 2.0376838235294117,
      "grad_norm": 0.8357511758804321,
      "learning_rate": 6.584967320261438e-06,
      "loss": 0.041,
      "step": 8868
    },
    {
      "epoch": 2.0379136029411766,
      "grad_norm": 0.9722285866737366,
      "learning_rate": 6.584456699346405e-06,
      "loss": 0.0286,
      "step": 8869
    },
    {
      "epoch": 2.038143382352941,
      "grad_norm": 0.8759163022041321,
      "learning_rate": 6.583946078431374e-06,
      "loss": 0.0291,
      "step": 8870
    },
    {
      "epoch": 2.038373161764706,
      "grad_norm": 0.9135481715202332,
      "learning_rate": 6.583435457516341e-06,
      "loss": 0.0467,
      "step": 8871
    },
    {
      "epoch": 2.0386029411764706,
      "grad_norm": 1.2967532873153687,
      "learning_rate": 6.582924836601308e-06,
      "loss": 0.079,
      "step": 8872
    },
    {
      "epoch": 2.0388327205882355,
      "grad_norm": 0.9146925210952759,
      "learning_rate": 6.582414215686275e-06,
      "loss": 0.0579,
      "step": 8873
    },
    {
      "epoch": 2.0390625,
      "grad_norm": 0.7522847652435303,
      "learning_rate": 6.581903594771243e-06,
      "loss": 0.0398,
      "step": 8874
    },
    {
      "epoch": 2.0392922794117645,
      "grad_norm": 1.110378384590149,
      "learning_rate": 6.58139297385621e-06,
      "loss": 0.0369,
      "step": 8875
    },
    {
      "epoch": 2.0395220588235294,
      "grad_norm": 0.6996421217918396,
      "learning_rate": 6.580882352941177e-06,
      "loss": 0.0219,
      "step": 8876
    },
    {
      "epoch": 2.039751838235294,
      "grad_norm": 0.9255090355873108,
      "learning_rate": 6.580371732026144e-06,
      "loss": 0.0362,
      "step": 8877
    },
    {
      "epoch": 2.039981617647059,
      "grad_norm": 0.7910643219947815,
      "learning_rate": 6.5798611111111125e-06,
      "loss": 0.051,
      "step": 8878
    },
    {
      "epoch": 2.0402113970588234,
      "grad_norm": 1.371934175491333,
      "learning_rate": 6.5793504901960795e-06,
      "loss": 0.0431,
      "step": 8879
    },
    {
      "epoch": 2.0404411764705883,
      "grad_norm": 0.8243312239646912,
      "learning_rate": 6.5788398692810465e-06,
      "loss": 0.0325,
      "step": 8880
    },
    {
      "epoch": 2.040670955882353,
      "grad_norm": 0.7559467554092407,
      "learning_rate": 6.5783292483660135e-06,
      "loss": 0.0309,
      "step": 8881
    },
    {
      "epoch": 2.0409007352941178,
      "grad_norm": 1.0725934505462646,
      "learning_rate": 6.577818627450981e-06,
      "loss": 0.064,
      "step": 8882
    },
    {
      "epoch": 2.0411305147058822,
      "grad_norm": 0.9249885678291321,
      "learning_rate": 6.577308006535948e-06,
      "loss": 0.0417,
      "step": 8883
    },
    {
      "epoch": 2.041360294117647,
      "grad_norm": 0.8266350626945496,
      "learning_rate": 6.576797385620915e-06,
      "loss": 0.0315,
      "step": 8884
    },
    {
      "epoch": 2.0415900735294117,
      "grad_norm": 0.8233721256256104,
      "learning_rate": 6.576286764705882e-06,
      "loss": 0.0335,
      "step": 8885
    },
    {
      "epoch": 2.0418198529411766,
      "grad_norm": 0.8200097680091858,
      "learning_rate": 6.575776143790851e-06,
      "loss": 0.0327,
      "step": 8886
    },
    {
      "epoch": 2.042049632352941,
      "grad_norm": 1.2882800102233887,
      "learning_rate": 6.575265522875818e-06,
      "loss": 0.0605,
      "step": 8887
    },
    {
      "epoch": 2.042279411764706,
      "grad_norm": 0.9895032048225403,
      "learning_rate": 6.574754901960785e-06,
      "loss": 0.0556,
      "step": 8888
    },
    {
      "epoch": 2.0425091911764706,
      "grad_norm": 1.036771535873413,
      "learning_rate": 6.574244281045752e-06,
      "loss": 0.0468,
      "step": 8889
    },
    {
      "epoch": 2.0427389705882355,
      "grad_norm": 0.9690647721290588,
      "learning_rate": 6.57373366013072e-06,
      "loss": 0.0441,
      "step": 8890
    },
    {
      "epoch": 2.04296875,
      "grad_norm": 0.8444070816040039,
      "learning_rate": 6.573223039215687e-06,
      "loss": 0.0208,
      "step": 8891
    },
    {
      "epoch": 2.0431985294117645,
      "grad_norm": 0.8954814076423645,
      "learning_rate": 6.572712418300654e-06,
      "loss": 0.0386,
      "step": 8892
    },
    {
      "epoch": 2.0434283088235294,
      "grad_norm": 0.7819923162460327,
      "learning_rate": 6.572201797385621e-06,
      "loss": 0.0389,
      "step": 8893
    },
    {
      "epoch": 2.043658088235294,
      "grad_norm": 1.1232939958572388,
      "learning_rate": 6.571691176470589e-06,
      "loss": 0.0317,
      "step": 8894
    },
    {
      "epoch": 2.043887867647059,
      "grad_norm": 0.7226833701133728,
      "learning_rate": 6.571180555555556e-06,
      "loss": 0.0206,
      "step": 8895
    },
    {
      "epoch": 2.0441176470588234,
      "grad_norm": 1.183303952217102,
      "learning_rate": 6.570669934640524e-06,
      "loss": 0.0676,
      "step": 8896
    },
    {
      "epoch": 2.0443474264705883,
      "grad_norm": 0.9229022860527039,
      "learning_rate": 6.570159313725491e-06,
      "loss": 0.0376,
      "step": 8897
    },
    {
      "epoch": 2.044577205882353,
      "grad_norm": 0.8846959471702576,
      "learning_rate": 6.569648692810459e-06,
      "loss": 0.0615,
      "step": 8898
    },
    {
      "epoch": 2.0448069852941178,
      "grad_norm": 1.001764178276062,
      "learning_rate": 6.569138071895426e-06,
      "loss": 0.0365,
      "step": 8899
    },
    {
      "epoch": 2.0450367647058822,
      "grad_norm": 0.9760801196098328,
      "learning_rate": 6.568627450980393e-06,
      "loss": 0.0401,
      "step": 8900
    },
    {
      "epoch": 2.045266544117647,
      "grad_norm": 1.13718581199646,
      "learning_rate": 6.56811683006536e-06,
      "loss": 0.0628,
      "step": 8901
    },
    {
      "epoch": 2.0454963235294117,
      "grad_norm": 1.3440911769866943,
      "learning_rate": 6.567606209150328e-06,
      "loss": 0.067,
      "step": 8902
    },
    {
      "epoch": 2.0457261029411766,
      "grad_norm": 0.6883592009544373,
      "learning_rate": 6.567095588235295e-06,
      "loss": 0.0227,
      "step": 8903
    },
    {
      "epoch": 2.045955882352941,
      "grad_norm": 0.9819124341011047,
      "learning_rate": 6.566584967320262e-06,
      "loss": 0.0322,
      "step": 8904
    },
    {
      "epoch": 2.046185661764706,
      "grad_norm": 0.7484779357910156,
      "learning_rate": 6.566074346405229e-06,
      "loss": 0.0325,
      "step": 8905
    },
    {
      "epoch": 2.0464154411764706,
      "grad_norm": 0.9614683985710144,
      "learning_rate": 6.565563725490197e-06,
      "loss": 0.0438,
      "step": 8906
    },
    {
      "epoch": 2.0466452205882355,
      "grad_norm": 1.1732885837554932,
      "learning_rate": 6.565053104575164e-06,
      "loss": 0.0651,
      "step": 8907
    },
    {
      "epoch": 2.046875,
      "grad_norm": 0.9047325253486633,
      "learning_rate": 6.564542483660131e-06,
      "loss": 0.0386,
      "step": 8908
    },
    {
      "epoch": 2.0471047794117645,
      "grad_norm": 1.0856783390045166,
      "learning_rate": 6.564031862745098e-06,
      "loss": 0.0623,
      "step": 8909
    },
    {
      "epoch": 2.0473345588235294,
      "grad_norm": 0.8555825352668762,
      "learning_rate": 6.563521241830066e-06,
      "loss": 0.0395,
      "step": 8910
    },
    {
      "epoch": 2.047564338235294,
      "grad_norm": 1.0960962772369385,
      "learning_rate": 6.563010620915033e-06,
      "loss": 0.077,
      "step": 8911
    },
    {
      "epoch": 2.047794117647059,
      "grad_norm": 0.8128964304924011,
      "learning_rate": 6.5625e-06,
      "loss": 0.0296,
      "step": 8912
    },
    {
      "epoch": 2.0480238970588234,
      "grad_norm": 0.8414627909660339,
      "learning_rate": 6.561989379084967e-06,
      "loss": 0.0363,
      "step": 8913
    },
    {
      "epoch": 2.0482536764705883,
      "grad_norm": 0.9195523262023926,
      "learning_rate": 6.561478758169934e-06,
      "loss": 0.0491,
      "step": 8914
    },
    {
      "epoch": 2.048483455882353,
      "grad_norm": 1.2343332767486572,
      "learning_rate": 6.560968137254903e-06,
      "loss": 0.0562,
      "step": 8915
    },
    {
      "epoch": 2.0487132352941178,
      "grad_norm": 0.8384712934494019,
      "learning_rate": 6.56045751633987e-06,
      "loss": 0.0411,
      "step": 8916
    },
    {
      "epoch": 2.0489430147058822,
      "grad_norm": 0.690413773059845,
      "learning_rate": 6.559946895424837e-06,
      "loss": 0.0299,
      "step": 8917
    },
    {
      "epoch": 2.049172794117647,
      "grad_norm": 0.8390831351280212,
      "learning_rate": 6.559436274509804e-06,
      "loss": 0.0518,
      "step": 8918
    },
    {
      "epoch": 2.0494025735294117,
      "grad_norm": 1.0263714790344238,
      "learning_rate": 6.558925653594772e-06,
      "loss": 0.0585,
      "step": 8919
    },
    {
      "epoch": 2.0496323529411766,
      "grad_norm": 0.8989188075065613,
      "learning_rate": 6.558415032679739e-06,
      "loss": 0.0388,
      "step": 8920
    },
    {
      "epoch": 2.049862132352941,
      "grad_norm": 0.9131412506103516,
      "learning_rate": 6.557904411764706e-06,
      "loss": 0.0567,
      "step": 8921
    },
    {
      "epoch": 2.050091911764706,
      "grad_norm": 1.1302070617675781,
      "learning_rate": 6.557393790849673e-06,
      "loss": 0.0666,
      "step": 8922
    },
    {
      "epoch": 2.0503216911764706,
      "grad_norm": 0.6977934837341309,
      "learning_rate": 6.556883169934642e-06,
      "loss": 0.0325,
      "step": 8923
    },
    {
      "epoch": 2.0505514705882355,
      "grad_norm": 0.7543925642967224,
      "learning_rate": 6.556372549019609e-06,
      "loss": 0.0432,
      "step": 8924
    },
    {
      "epoch": 2.05078125,
      "grad_norm": 0.6589696407318115,
      "learning_rate": 6.555861928104576e-06,
      "loss": 0.0321,
      "step": 8925
    },
    {
      "epoch": 2.0510110294117645,
      "grad_norm": 1.3335245847702026,
      "learning_rate": 6.555351307189543e-06,
      "loss": 0.0492,
      "step": 8926
    },
    {
      "epoch": 2.0512408088235294,
      "grad_norm": 0.7929139733314514,
      "learning_rate": 6.5548406862745106e-06,
      "loss": 0.0442,
      "step": 8927
    },
    {
      "epoch": 2.051470588235294,
      "grad_norm": 1.3392834663391113,
      "learning_rate": 6.554330065359478e-06,
      "loss": 0.066,
      "step": 8928
    },
    {
      "epoch": 2.051700367647059,
      "grad_norm": 0.688244640827179,
      "learning_rate": 6.553819444444445e-06,
      "loss": 0.0276,
      "step": 8929
    },
    {
      "epoch": 2.0519301470588234,
      "grad_norm": 0.9142074584960938,
      "learning_rate": 6.553308823529412e-06,
      "loss": 0.0403,
      "step": 8930
    },
    {
      "epoch": 2.0521599264705883,
      "grad_norm": 0.7315841317176819,
      "learning_rate": 6.55279820261438e-06,
      "loss": 0.0295,
      "step": 8931
    },
    {
      "epoch": 2.052389705882353,
      "grad_norm": 1.4062926769256592,
      "learning_rate": 6.552287581699347e-06,
      "loss": 0.0556,
      "step": 8932
    },
    {
      "epoch": 2.0526194852941178,
      "grad_norm": 0.6918068528175354,
      "learning_rate": 6.551776960784314e-06,
      "loss": 0.0276,
      "step": 8933
    },
    {
      "epoch": 2.0528492647058822,
      "grad_norm": 1.1890367269515991,
      "learning_rate": 6.551266339869281e-06,
      "loss": 0.0422,
      "step": 8934
    },
    {
      "epoch": 2.053079044117647,
      "grad_norm": 1.1977596282958984,
      "learning_rate": 6.550755718954249e-06,
      "loss": 0.0732,
      "step": 8935
    },
    {
      "epoch": 2.0533088235294117,
      "grad_norm": 0.7879923582077026,
      "learning_rate": 6.550245098039216e-06,
      "loss": 0.0281,
      "step": 8936
    },
    {
      "epoch": 2.0535386029411766,
      "grad_norm": 0.7714848518371582,
      "learning_rate": 6.549734477124183e-06,
      "loss": 0.0369,
      "step": 8937
    },
    {
      "epoch": 2.053768382352941,
      "grad_norm": 0.8841803073883057,
      "learning_rate": 6.54922385620915e-06,
      "loss": 0.0439,
      "step": 8938
    },
    {
      "epoch": 2.053998161764706,
      "grad_norm": 0.8382442593574524,
      "learning_rate": 6.548713235294118e-06,
      "loss": 0.0304,
      "step": 8939
    },
    {
      "epoch": 2.0542279411764706,
      "grad_norm": 1.167154312133789,
      "learning_rate": 6.548202614379085e-06,
      "loss": 0.0587,
      "step": 8940
    },
    {
      "epoch": 2.0544577205882355,
      "grad_norm": 1.8502391576766968,
      "learning_rate": 6.547691993464053e-06,
      "loss": 0.0519,
      "step": 8941
    },
    {
      "epoch": 2.0546875,
      "grad_norm": 0.8813521862030029,
      "learning_rate": 6.54718137254902e-06,
      "loss": 0.044,
      "step": 8942
    },
    {
      "epoch": 2.0549172794117645,
      "grad_norm": 1.0008877515792847,
      "learning_rate": 6.546670751633988e-06,
      "loss": 0.0318,
      "step": 8943
    },
    {
      "epoch": 2.0551470588235294,
      "grad_norm": 0.8154441118240356,
      "learning_rate": 6.546160130718955e-06,
      "loss": 0.0414,
      "step": 8944
    },
    {
      "epoch": 2.055376838235294,
      "grad_norm": 0.8158858418464661,
      "learning_rate": 6.545649509803922e-06,
      "loss": 0.0294,
      "step": 8945
    },
    {
      "epoch": 2.055606617647059,
      "grad_norm": 1.0431057214736938,
      "learning_rate": 6.545138888888889e-06,
      "loss": 0.0503,
      "step": 8946
    },
    {
      "epoch": 2.0558363970588234,
      "grad_norm": 1.1116153001785278,
      "learning_rate": 6.544628267973857e-06,
      "loss": 0.0474,
      "step": 8947
    },
    {
      "epoch": 2.0560661764705883,
      "grad_norm": 0.840172290802002,
      "learning_rate": 6.544117647058824e-06,
      "loss": 0.0339,
      "step": 8948
    },
    {
      "epoch": 2.056295955882353,
      "grad_norm": 0.9861721992492676,
      "learning_rate": 6.543607026143791e-06,
      "loss": 0.0527,
      "step": 8949
    },
    {
      "epoch": 2.0565257352941178,
      "grad_norm": 0.8062552809715271,
      "learning_rate": 6.543096405228758e-06,
      "loss": 0.0385,
      "step": 8950
    },
    {
      "epoch": 2.0567555147058822,
      "grad_norm": 1.236864686012268,
      "learning_rate": 6.5425857843137265e-06,
      "loss": 0.0466,
      "step": 8951
    },
    {
      "epoch": 2.056985294117647,
      "grad_norm": 1.5937490463256836,
      "learning_rate": 6.5420751633986936e-06,
      "loss": 0.0608,
      "step": 8952
    },
    {
      "epoch": 2.0572150735294117,
      "grad_norm": 0.9118473529815674,
      "learning_rate": 6.5415645424836606e-06,
      "loss": 0.0512,
      "step": 8953
    },
    {
      "epoch": 2.0574448529411766,
      "grad_norm": 1.21224844455719,
      "learning_rate": 6.541053921568628e-06,
      "loss": 0.0455,
      "step": 8954
    },
    {
      "epoch": 2.057674632352941,
      "grad_norm": 0.7782933712005615,
      "learning_rate": 6.5405433006535954e-06,
      "loss": 0.0348,
      "step": 8955
    },
    {
      "epoch": 2.057904411764706,
      "grad_norm": 1.048487901687622,
      "learning_rate": 6.5400326797385625e-06,
      "loss": 0.0527,
      "step": 8956
    },
    {
      "epoch": 2.0581341911764706,
      "grad_norm": 0.9054355621337891,
      "learning_rate": 6.5395220588235295e-06,
      "loss": 0.0454,
      "step": 8957
    },
    {
      "epoch": 2.0583639705882355,
      "grad_norm": 0.9792221188545227,
      "learning_rate": 6.5390114379084965e-06,
      "loss": 0.0379,
      "step": 8958
    },
    {
      "epoch": 2.05859375,
      "grad_norm": 1.193522572517395,
      "learning_rate": 6.538500816993465e-06,
      "loss": 0.0465,
      "step": 8959
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 0.8622803092002869,
      "learning_rate": 6.537990196078432e-06,
      "loss": 0.0501,
      "step": 8960
    },
    {
      "epoch": 2.0590533088235294,
      "grad_norm": 0.8838793635368347,
      "learning_rate": 6.537479575163399e-06,
      "loss": 0.0263,
      "step": 8961
    },
    {
      "epoch": 2.059283088235294,
      "grad_norm": 1.0771831274032593,
      "learning_rate": 6.536968954248366e-06,
      "loss": 0.0486,
      "step": 8962
    },
    {
      "epoch": 2.059512867647059,
      "grad_norm": 0.7643978595733643,
      "learning_rate": 6.536458333333334e-06,
      "loss": 0.0397,
      "step": 8963
    },
    {
      "epoch": 2.0597426470588234,
      "grad_norm": 0.9590117335319519,
      "learning_rate": 6.535947712418301e-06,
      "loss": 0.0544,
      "step": 8964
    },
    {
      "epoch": 2.0599724264705883,
      "grad_norm": 1.2118160724639893,
      "learning_rate": 6.535437091503268e-06,
      "loss": 0.0341,
      "step": 8965
    },
    {
      "epoch": 2.060202205882353,
      "grad_norm": 0.8981199264526367,
      "learning_rate": 6.534926470588235e-06,
      "loss": 0.037,
      "step": 8966
    },
    {
      "epoch": 2.0604319852941178,
      "grad_norm": 0.8890368938446045,
      "learning_rate": 6.534415849673204e-06,
      "loss": 0.0369,
      "step": 8967
    },
    {
      "epoch": 2.0606617647058822,
      "grad_norm": 1.1732622385025024,
      "learning_rate": 6.533905228758171e-06,
      "loss": 0.0642,
      "step": 8968
    },
    {
      "epoch": 2.060891544117647,
      "grad_norm": 1.1631301641464233,
      "learning_rate": 6.533394607843138e-06,
      "loss": 0.0439,
      "step": 8969
    },
    {
      "epoch": 2.0611213235294117,
      "grad_norm": 1.1945087909698486,
      "learning_rate": 6.532883986928105e-06,
      "loss": 0.0613,
      "step": 8970
    },
    {
      "epoch": 2.0613511029411766,
      "grad_norm": 0.8195431232452393,
      "learning_rate": 6.532373366013073e-06,
      "loss": 0.0429,
      "step": 8971
    },
    {
      "epoch": 2.061580882352941,
      "grad_norm": 0.6520081758499146,
      "learning_rate": 6.53186274509804e-06,
      "loss": 0.0261,
      "step": 8972
    },
    {
      "epoch": 2.061810661764706,
      "grad_norm": 1.0716925859451294,
      "learning_rate": 6.531352124183007e-06,
      "loss": 0.0353,
      "step": 8973
    },
    {
      "epoch": 2.0620404411764706,
      "grad_norm": 0.8582828640937805,
      "learning_rate": 6.530841503267974e-06,
      "loss": 0.0447,
      "step": 8974
    },
    {
      "epoch": 2.0622702205882355,
      "grad_norm": 0.7285882830619812,
      "learning_rate": 6.5303308823529425e-06,
      "loss": 0.0254,
      "step": 8975
    },
    {
      "epoch": 2.0625,
      "grad_norm": 0.7452635169029236,
      "learning_rate": 6.5298202614379095e-06,
      "loss": 0.037,
      "step": 8976
    },
    {
      "epoch": 2.0627297794117645,
      "grad_norm": 0.942103922367096,
      "learning_rate": 6.5293096405228765e-06,
      "loss": 0.0382,
      "step": 8977
    },
    {
      "epoch": 2.0629595588235294,
      "grad_norm": 0.9269629120826721,
      "learning_rate": 6.5287990196078436e-06,
      "loss": 0.0519,
      "step": 8978
    },
    {
      "epoch": 2.063189338235294,
      "grad_norm": 0.6378331780433655,
      "learning_rate": 6.528288398692811e-06,
      "loss": 0.0349,
      "step": 8979
    },
    {
      "epoch": 2.063419117647059,
      "grad_norm": 1.0417596101760864,
      "learning_rate": 6.5277777777777784e-06,
      "loss": 0.0511,
      "step": 8980
    },
    {
      "epoch": 2.0636488970588234,
      "grad_norm": 1.1156920194625854,
      "learning_rate": 6.5272671568627454e-06,
      "loss": 0.035,
      "step": 8981
    },
    {
      "epoch": 2.0638786764705883,
      "grad_norm": 1.155683159828186,
      "learning_rate": 6.5267565359477125e-06,
      "loss": 0.045,
      "step": 8982
    },
    {
      "epoch": 2.064108455882353,
      "grad_norm": 0.9994273781776428,
      "learning_rate": 6.52624591503268e-06,
      "loss": 0.0544,
      "step": 8983
    },
    {
      "epoch": 2.0643382352941178,
      "grad_norm": 0.699524998664856,
      "learning_rate": 6.525735294117647e-06,
      "loss": 0.0308,
      "step": 8984
    },
    {
      "epoch": 2.0645680147058822,
      "grad_norm": 0.9155750274658203,
      "learning_rate": 6.525224673202614e-06,
      "loss": 0.0337,
      "step": 8985
    },
    {
      "epoch": 2.064797794117647,
      "grad_norm": 0.8833356499671936,
      "learning_rate": 6.524714052287582e-06,
      "loss": 0.0401,
      "step": 8986
    },
    {
      "epoch": 2.0650275735294117,
      "grad_norm": 0.9186224341392517,
      "learning_rate": 6.52420343137255e-06,
      "loss": 0.0363,
      "step": 8987
    },
    {
      "epoch": 2.0652573529411766,
      "grad_norm": 1.1121608018875122,
      "learning_rate": 6.523692810457517e-06,
      "loss": 0.0608,
      "step": 8988
    },
    {
      "epoch": 2.065487132352941,
      "grad_norm": 0.7038803100585938,
      "learning_rate": 6.523182189542484e-06,
      "loss": 0.0265,
      "step": 8989
    },
    {
      "epoch": 2.065716911764706,
      "grad_norm": 0.9752243757247925,
      "learning_rate": 6.522671568627451e-06,
      "loss": 0.0375,
      "step": 8990
    },
    {
      "epoch": 2.0659466911764706,
      "grad_norm": 0.8668532371520996,
      "learning_rate": 6.522160947712419e-06,
      "loss": 0.0386,
      "step": 8991
    },
    {
      "epoch": 2.0661764705882355,
      "grad_norm": 0.7625265121459961,
      "learning_rate": 6.521650326797386e-06,
      "loss": 0.0232,
      "step": 8992
    },
    {
      "epoch": 2.06640625,
      "grad_norm": 1.1212964057922363,
      "learning_rate": 6.521139705882353e-06,
      "loss": 0.0385,
      "step": 8993
    },
    {
      "epoch": 2.0666360294117645,
      "grad_norm": 1.1578855514526367,
      "learning_rate": 6.52062908496732e-06,
      "loss": 0.0489,
      "step": 8994
    },
    {
      "epoch": 2.0668658088235294,
      "grad_norm": 1.1872668266296387,
      "learning_rate": 6.520118464052289e-06,
      "loss": 0.0711,
      "step": 8995
    },
    {
      "epoch": 2.067095588235294,
      "grad_norm": 1.1287654638290405,
      "learning_rate": 6.519607843137256e-06,
      "loss": 0.0459,
      "step": 8996
    },
    {
      "epoch": 2.067325367647059,
      "grad_norm": 0.9590149521827698,
      "learning_rate": 6.519097222222223e-06,
      "loss": 0.0333,
      "step": 8997
    },
    {
      "epoch": 2.0675551470588234,
      "grad_norm": 0.9875375628471375,
      "learning_rate": 6.51858660130719e-06,
      "loss": 0.0346,
      "step": 8998
    },
    {
      "epoch": 2.0677849264705883,
      "grad_norm": 0.8248283863067627,
      "learning_rate": 6.518075980392158e-06,
      "loss": 0.0242,
      "step": 8999
    },
    {
      "epoch": 2.068014705882353,
      "grad_norm": 0.9630730748176575,
      "learning_rate": 6.517565359477125e-06,
      "loss": 0.0452,
      "step": 9000
    },
    {
      "epoch": 2.068014705882353,
      "eval_loss": 0.048903074115514755,
      "eval_runtime": 2006.6605,
      "eval_samples_per_second": 4.438,
      "eval_steps_per_second": 2.219,
      "step": 9000
    },
    {
      "epoch": 2.0682444852941178,
      "grad_norm": 0.8481473922729492,
      "learning_rate": 6.517054738562092e-06,
      "loss": 0.0549,
      "step": 9001
    },
    {
      "epoch": 2.0684742647058822,
      "grad_norm": 0.9524601101875305,
      "learning_rate": 6.516544117647059e-06,
      "loss": 0.0458,
      "step": 9002
    },
    {
      "epoch": 2.068704044117647,
      "grad_norm": 0.7868493795394897,
      "learning_rate": 6.516033496732027e-06,
      "loss": 0.0364,
      "step": 9003
    },
    {
      "epoch": 2.0689338235294117,
      "grad_norm": 0.6885111331939697,
      "learning_rate": 6.515522875816994e-06,
      "loss": 0.0399,
      "step": 9004
    },
    {
      "epoch": 2.0691636029411766,
      "grad_norm": 0.8102517127990723,
      "learning_rate": 6.515012254901961e-06,
      "loss": 0.0335,
      "step": 9005
    },
    {
      "epoch": 2.069393382352941,
      "grad_norm": 1.2248914241790771,
      "learning_rate": 6.5145016339869284e-06,
      "loss": 0.053,
      "step": 9006
    },
    {
      "epoch": 2.069623161764706,
      "grad_norm": 1.1636326313018799,
      "learning_rate": 6.513991013071896e-06,
      "loss": 0.0456,
      "step": 9007
    },
    {
      "epoch": 2.0698529411764706,
      "grad_norm": 1.0327004194259644,
      "learning_rate": 6.513480392156863e-06,
      "loss": 0.0395,
      "step": 9008
    },
    {
      "epoch": 2.0700827205882355,
      "grad_norm": 1.3259549140930176,
      "learning_rate": 6.51296977124183e-06,
      "loss": 0.0611,
      "step": 9009
    },
    {
      "epoch": 2.0703125,
      "grad_norm": 0.9177753925323486,
      "learning_rate": 6.512459150326797e-06,
      "loss": 0.0415,
      "step": 9010
    },
    {
      "epoch": 2.0705422794117645,
      "grad_norm": 1.084236741065979,
      "learning_rate": 6.511948529411766e-06,
      "loss": 0.0659,
      "step": 9011
    },
    {
      "epoch": 2.0707720588235294,
      "grad_norm": 1.014478325843811,
      "learning_rate": 6.511437908496733e-06,
      "loss": 0.0405,
      "step": 9012
    },
    {
      "epoch": 2.071001838235294,
      "grad_norm": 1.2568717002868652,
      "learning_rate": 6.5109272875817e-06,
      "loss": 0.0505,
      "step": 9013
    },
    {
      "epoch": 2.071231617647059,
      "grad_norm": 0.7542171478271484,
      "learning_rate": 6.510416666666667e-06,
      "loss": 0.0288,
      "step": 9014
    },
    {
      "epoch": 2.0714613970588234,
      "grad_norm": 0.7131068110466003,
      "learning_rate": 6.509906045751635e-06,
      "loss": 0.0492,
      "step": 9015
    },
    {
      "epoch": 2.0716911764705883,
      "grad_norm": 1.0597418546676636,
      "learning_rate": 6.509395424836602e-06,
      "loss": 0.05,
      "step": 9016
    },
    {
      "epoch": 2.071920955882353,
      "grad_norm": 0.7919148802757263,
      "learning_rate": 6.508884803921569e-06,
      "loss": 0.0304,
      "step": 9017
    },
    {
      "epoch": 2.0721507352941178,
      "grad_norm": 0.8910722732543945,
      "learning_rate": 6.508374183006536e-06,
      "loss": 0.0372,
      "step": 9018
    },
    {
      "epoch": 2.0723805147058822,
      "grad_norm": 0.9836875796318054,
      "learning_rate": 6.507863562091504e-06,
      "loss": 0.0436,
      "step": 9019
    },
    {
      "epoch": 2.072610294117647,
      "grad_norm": 0.8035875558853149,
      "learning_rate": 6.507352941176472e-06,
      "loss": 0.0404,
      "step": 9020
    },
    {
      "epoch": 2.0728400735294117,
      "grad_norm": 1.2717422246932983,
      "learning_rate": 6.506842320261439e-06,
      "loss": 0.0577,
      "step": 9021
    },
    {
      "epoch": 2.0730698529411766,
      "grad_norm": 1.1294059753417969,
      "learning_rate": 6.506331699346406e-06,
      "loss": 0.0603,
      "step": 9022
    },
    {
      "epoch": 2.073299632352941,
      "grad_norm": 1.0726842880249023,
      "learning_rate": 6.505821078431374e-06,
      "loss": 0.0449,
      "step": 9023
    },
    {
      "epoch": 2.073529411764706,
      "grad_norm": 1.0571523904800415,
      "learning_rate": 6.505310457516341e-06,
      "loss": 0.045,
      "step": 9024
    },
    {
      "epoch": 2.0737591911764706,
      "grad_norm": 0.9098922610282898,
      "learning_rate": 6.504799836601308e-06,
      "loss": 0.0397,
      "step": 9025
    },
    {
      "epoch": 2.0739889705882355,
      "grad_norm": 1.0916410684585571,
      "learning_rate": 6.504289215686275e-06,
      "loss": 0.0564,
      "step": 9026
    },
    {
      "epoch": 2.07421875,
      "grad_norm": 1.2192604541778564,
      "learning_rate": 6.5037785947712425e-06,
      "loss": 0.0348,
      "step": 9027
    },
    {
      "epoch": 2.0744485294117645,
      "grad_norm": 1.1171214580535889,
      "learning_rate": 6.5032679738562095e-06,
      "loss": 0.0468,
      "step": 9028
    },
    {
      "epoch": 2.0746783088235294,
      "grad_norm": 0.8516799211502075,
      "learning_rate": 6.5027573529411765e-06,
      "loss": 0.0346,
      "step": 9029
    },
    {
      "epoch": 2.074908088235294,
      "grad_norm": 1.6486871242523193,
      "learning_rate": 6.502246732026144e-06,
      "loss": 0.0581,
      "step": 9030
    },
    {
      "epoch": 2.075137867647059,
      "grad_norm": 0.7808294892311096,
      "learning_rate": 6.501736111111112e-06,
      "loss": 0.0307,
      "step": 9031
    },
    {
      "epoch": 2.0753676470588234,
      "grad_norm": 0.8172977566719055,
      "learning_rate": 6.501225490196079e-06,
      "loss": 0.05,
      "step": 9032
    },
    {
      "epoch": 2.0755974264705883,
      "grad_norm": 0.6592622995376587,
      "learning_rate": 6.500714869281046e-06,
      "loss": 0.025,
      "step": 9033
    },
    {
      "epoch": 2.075827205882353,
      "grad_norm": 1.7621148824691772,
      "learning_rate": 6.500204248366013e-06,
      "loss": 0.0683,
      "step": 9034
    },
    {
      "epoch": 2.0760569852941178,
      "grad_norm": 0.9177384972572327,
      "learning_rate": 6.499693627450981e-06,
      "loss": 0.0418,
      "step": 9035
    },
    {
      "epoch": 2.0762867647058822,
      "grad_norm": 0.8714353442192078,
      "learning_rate": 6.499183006535948e-06,
      "loss": 0.0415,
      "step": 9036
    },
    {
      "epoch": 2.076516544117647,
      "grad_norm": 0.9245855212211609,
      "learning_rate": 6.498672385620915e-06,
      "loss": 0.0396,
      "step": 9037
    },
    {
      "epoch": 2.0767463235294117,
      "grad_norm": 0.8460394144058228,
      "learning_rate": 6.498161764705882e-06,
      "loss": 0.0441,
      "step": 9038
    },
    {
      "epoch": 2.0769761029411766,
      "grad_norm": 0.9176295399665833,
      "learning_rate": 6.497651143790851e-06,
      "loss": 0.0272,
      "step": 9039
    },
    {
      "epoch": 2.077205882352941,
      "grad_norm": 1.0391082763671875,
      "learning_rate": 6.497140522875818e-06,
      "loss": 0.0767,
      "step": 9040
    },
    {
      "epoch": 2.077435661764706,
      "grad_norm": 1.0554989576339722,
      "learning_rate": 6.496629901960785e-06,
      "loss": 0.0404,
      "step": 9041
    },
    {
      "epoch": 2.0776654411764706,
      "grad_norm": 0.8225768208503723,
      "learning_rate": 6.496119281045752e-06,
      "loss": 0.0417,
      "step": 9042
    },
    {
      "epoch": 2.0778952205882355,
      "grad_norm": 1.207032322883606,
      "learning_rate": 6.49560866013072e-06,
      "loss": 0.0609,
      "step": 9043
    },
    {
      "epoch": 2.078125,
      "grad_norm": 0.8090530633926392,
      "learning_rate": 6.495098039215687e-06,
      "loss": 0.0231,
      "step": 9044
    },
    {
      "epoch": 2.0783547794117645,
      "grad_norm": 1.3392808437347412,
      "learning_rate": 6.494587418300654e-06,
      "loss": 0.0663,
      "step": 9045
    },
    {
      "epoch": 2.0785845588235294,
      "grad_norm": 1.0076487064361572,
      "learning_rate": 6.494076797385621e-06,
      "loss": 0.043,
      "step": 9046
    },
    {
      "epoch": 2.078814338235294,
      "grad_norm": 0.9799842834472656,
      "learning_rate": 6.4935661764705896e-06,
      "loss": 0.0314,
      "step": 9047
    },
    {
      "epoch": 2.079044117647059,
      "grad_norm": 0.8697075843811035,
      "learning_rate": 6.493055555555557e-06,
      "loss": 0.0382,
      "step": 9048
    },
    {
      "epoch": 2.0792738970588234,
      "grad_norm": 0.9625505805015564,
      "learning_rate": 6.492544934640524e-06,
      "loss": 0.0454,
      "step": 9049
    },
    {
      "epoch": 2.0795036764705883,
      "grad_norm": 1.2502728700637817,
      "learning_rate": 6.492034313725491e-06,
      "loss": 0.0684,
      "step": 9050
    },
    {
      "epoch": 2.079733455882353,
      "grad_norm": 1.0442036390304565,
      "learning_rate": 6.4915236928104585e-06,
      "loss": 0.0474,
      "step": 9051
    },
    {
      "epoch": 2.0799632352941178,
      "grad_norm": 0.7835524678230286,
      "learning_rate": 6.4910130718954255e-06,
      "loss": 0.0389,
      "step": 9052
    },
    {
      "epoch": 2.0801930147058822,
      "grad_norm": 1.5179646015167236,
      "learning_rate": 6.4905024509803925e-06,
      "loss": 0.0729,
      "step": 9053
    },
    {
      "epoch": 2.080422794117647,
      "grad_norm": 1.6146131753921509,
      "learning_rate": 6.4899918300653595e-06,
      "loss": 0.059,
      "step": 9054
    },
    {
      "epoch": 2.0806525735294117,
      "grad_norm": 1.0305407047271729,
      "learning_rate": 6.489481209150328e-06,
      "loss": 0.0479,
      "step": 9055
    },
    {
      "epoch": 2.0808823529411766,
      "grad_norm": 1.0065003633499146,
      "learning_rate": 6.488970588235295e-06,
      "loss": 0.0476,
      "step": 9056
    },
    {
      "epoch": 2.081112132352941,
      "grad_norm": 1.147375464439392,
      "learning_rate": 6.488459967320262e-06,
      "loss": 0.0371,
      "step": 9057
    },
    {
      "epoch": 2.081341911764706,
      "grad_norm": 1.5394929647445679,
      "learning_rate": 6.487949346405229e-06,
      "loss": 0.0637,
      "step": 9058
    },
    {
      "epoch": 2.0815716911764706,
      "grad_norm": 1.1230682134628296,
      "learning_rate": 6.487438725490197e-06,
      "loss": 0.0461,
      "step": 9059
    },
    {
      "epoch": 2.0818014705882355,
      "grad_norm": 0.9440177083015442,
      "learning_rate": 6.486928104575164e-06,
      "loss": 0.0625,
      "step": 9060
    },
    {
      "epoch": 2.08203125,
      "grad_norm": 1.0951511859893799,
      "learning_rate": 6.486417483660131e-06,
      "loss": 0.0418,
      "step": 9061
    },
    {
      "epoch": 2.0822610294117645,
      "grad_norm": 0.9339231252670288,
      "learning_rate": 6.485906862745098e-06,
      "loss": 0.0446,
      "step": 9062
    },
    {
      "epoch": 2.0824908088235294,
      "grad_norm": 0.8125858902931213,
      "learning_rate": 6.485396241830066e-06,
      "loss": 0.0334,
      "step": 9063
    },
    {
      "epoch": 2.082720588235294,
      "grad_norm": 1.0452768802642822,
      "learning_rate": 6.484885620915034e-06,
      "loss": 0.0472,
      "step": 9064
    },
    {
      "epoch": 2.082950367647059,
      "grad_norm": 1.0453119277954102,
      "learning_rate": 6.484375000000001e-06,
      "loss": 0.0332,
      "step": 9065
    },
    {
      "epoch": 2.0831801470588234,
      "grad_norm": 0.987348198890686,
      "learning_rate": 6.483864379084968e-06,
      "loss": 0.0209,
      "step": 9066
    },
    {
      "epoch": 2.0834099264705883,
      "grad_norm": 1.2367088794708252,
      "learning_rate": 6.483353758169935e-06,
      "loss": 0.0527,
      "step": 9067
    },
    {
      "epoch": 2.083639705882353,
      "grad_norm": 0.9065464735031128,
      "learning_rate": 6.482843137254903e-06,
      "loss": 0.0438,
      "step": 9068
    },
    {
      "epoch": 2.0838694852941178,
      "grad_norm": 0.854465901851654,
      "learning_rate": 6.48233251633987e-06,
      "loss": 0.0401,
      "step": 9069
    },
    {
      "epoch": 2.0840992647058822,
      "grad_norm": 0.9869157671928406,
      "learning_rate": 6.481821895424837e-06,
      "loss": 0.0503,
      "step": 9070
    },
    {
      "epoch": 2.084329044117647,
      "grad_norm": 0.7484104633331299,
      "learning_rate": 6.481311274509804e-06,
      "loss": 0.0317,
      "step": 9071
    },
    {
      "epoch": 2.0845588235294117,
      "grad_norm": 0.6780559420585632,
      "learning_rate": 6.480800653594772e-06,
      "loss": 0.0223,
      "step": 9072
    },
    {
      "epoch": 2.0847886029411766,
      "grad_norm": 0.9097715020179749,
      "learning_rate": 6.480290032679739e-06,
      "loss": 0.0421,
      "step": 9073
    },
    {
      "epoch": 2.085018382352941,
      "grad_norm": 1.0811623334884644,
      "learning_rate": 6.479779411764706e-06,
      "loss": 0.0435,
      "step": 9074
    },
    {
      "epoch": 2.085248161764706,
      "grad_norm": 1.127227544784546,
      "learning_rate": 6.479268790849674e-06,
      "loss": 0.0584,
      "step": 9075
    },
    {
      "epoch": 2.0854779411764706,
      "grad_norm": 1.472003698348999,
      "learning_rate": 6.4787581699346415e-06,
      "loss": 0.0587,
      "step": 9076
    },
    {
      "epoch": 2.0857077205882355,
      "grad_norm": 0.9728162884712219,
      "learning_rate": 6.4782475490196085e-06,
      "loss": 0.0481,
      "step": 9077
    },
    {
      "epoch": 2.0859375,
      "grad_norm": 1.3415499925613403,
      "learning_rate": 6.4777369281045755e-06,
      "loss": 0.0577,
      "step": 9078
    },
    {
      "epoch": 2.0861672794117645,
      "grad_norm": 0.9884690046310425,
      "learning_rate": 6.4772263071895425e-06,
      "loss": 0.05,
      "step": 9079
    },
    {
      "epoch": 2.0863970588235294,
      "grad_norm": 0.9185386300086975,
      "learning_rate": 6.47671568627451e-06,
      "loss": 0.0347,
      "step": 9080
    },
    {
      "epoch": 2.086626838235294,
      "grad_norm": 0.7404099702835083,
      "learning_rate": 6.476205065359477e-06,
      "loss": 0.034,
      "step": 9081
    },
    {
      "epoch": 2.086856617647059,
      "grad_norm": 0.7265973091125488,
      "learning_rate": 6.475694444444444e-06,
      "loss": 0.0202,
      "step": 9082
    },
    {
      "epoch": 2.0870863970588234,
      "grad_norm": 0.9394162893295288,
      "learning_rate": 6.475183823529411e-06,
      "loss": 0.0486,
      "step": 9083
    },
    {
      "epoch": 2.0873161764705883,
      "grad_norm": 1.710550308227539,
      "learning_rate": 6.47467320261438e-06,
      "loss": 0.0575,
      "step": 9084
    },
    {
      "epoch": 2.087545955882353,
      "grad_norm": 0.9890526533126831,
      "learning_rate": 6.474162581699347e-06,
      "loss": 0.0504,
      "step": 9085
    },
    {
      "epoch": 2.0877757352941178,
      "grad_norm": 1.0369447469711304,
      "learning_rate": 6.473651960784314e-06,
      "loss": 0.0507,
      "step": 9086
    },
    {
      "epoch": 2.0880055147058822,
      "grad_norm": 0.8718886375427246,
      "learning_rate": 6.473141339869281e-06,
      "loss": 0.0275,
      "step": 9087
    },
    {
      "epoch": 2.088235294117647,
      "grad_norm": 0.7643749117851257,
      "learning_rate": 6.472630718954249e-06,
      "loss": 0.032,
      "step": 9088
    },
    {
      "epoch": 2.0884650735294117,
      "grad_norm": 1.1893514394760132,
      "learning_rate": 6.472120098039216e-06,
      "loss": 0.0719,
      "step": 9089
    },
    {
      "epoch": 2.0886948529411766,
      "grad_norm": 0.6737800240516663,
      "learning_rate": 6.471609477124183e-06,
      "loss": 0.0291,
      "step": 9090
    },
    {
      "epoch": 2.088924632352941,
      "grad_norm": 0.7650606632232666,
      "learning_rate": 6.47109885620915e-06,
      "loss": 0.0385,
      "step": 9091
    },
    {
      "epoch": 2.089154411764706,
      "grad_norm": 0.9349465370178223,
      "learning_rate": 6.470588235294119e-06,
      "loss": 0.0531,
      "step": 9092
    },
    {
      "epoch": 2.0893841911764706,
      "grad_norm": 0.9915115833282471,
      "learning_rate": 6.470077614379086e-06,
      "loss": 0.0398,
      "step": 9093
    },
    {
      "epoch": 2.0896139705882355,
      "grad_norm": 1.1858059167861938,
      "learning_rate": 6.469566993464053e-06,
      "loss": 0.0603,
      "step": 9094
    },
    {
      "epoch": 2.08984375,
      "grad_norm": 0.8825015425682068,
      "learning_rate": 6.46905637254902e-06,
      "loss": 0.0391,
      "step": 9095
    },
    {
      "epoch": 2.0900735294117645,
      "grad_norm": 1.0655962228775024,
      "learning_rate": 6.468545751633988e-06,
      "loss": 0.0424,
      "step": 9096
    },
    {
      "epoch": 2.0903033088235294,
      "grad_norm": 0.742977499961853,
      "learning_rate": 6.468035130718955e-06,
      "loss": 0.0235,
      "step": 9097
    },
    {
      "epoch": 2.090533088235294,
      "grad_norm": 0.8704671263694763,
      "learning_rate": 6.467524509803922e-06,
      "loss": 0.039,
      "step": 9098
    },
    {
      "epoch": 2.090762867647059,
      "grad_norm": 1.8426259756088257,
      "learning_rate": 6.467013888888889e-06,
      "loss": 0.04,
      "step": 9099
    },
    {
      "epoch": 2.0909926470588234,
      "grad_norm": 1.0535792112350464,
      "learning_rate": 6.4665032679738574e-06,
      "loss": 0.0594,
      "step": 9100
    },
    {
      "epoch": 2.0912224264705883,
      "grad_norm": 0.8060981631278992,
      "learning_rate": 6.4659926470588244e-06,
      "loss": 0.0306,
      "step": 9101
    },
    {
      "epoch": 2.091452205882353,
      "grad_norm": 0.7835373878479004,
      "learning_rate": 6.4654820261437915e-06,
      "loss": 0.0361,
      "step": 9102
    },
    {
      "epoch": 2.0916819852941178,
      "grad_norm": 1.0772514343261719,
      "learning_rate": 6.4649714052287585e-06,
      "loss": 0.0464,
      "step": 9103
    },
    {
      "epoch": 2.0919117647058822,
      "grad_norm": 0.993596076965332,
      "learning_rate": 6.464460784313726e-06,
      "loss": 0.0326,
      "step": 9104
    },
    {
      "epoch": 2.092141544117647,
      "grad_norm": 1.107879638671875,
      "learning_rate": 6.463950163398693e-06,
      "loss": 0.0622,
      "step": 9105
    },
    {
      "epoch": 2.0923713235294117,
      "grad_norm": 1.1123954057693481,
      "learning_rate": 6.46343954248366e-06,
      "loss": 0.0563,
      "step": 9106
    },
    {
      "epoch": 2.0926011029411766,
      "grad_norm": 1.2238737344741821,
      "learning_rate": 6.462928921568627e-06,
      "loss": 0.0516,
      "step": 9107
    },
    {
      "epoch": 2.092830882352941,
      "grad_norm": 1.3118561506271362,
      "learning_rate": 6.462418300653595e-06,
      "loss": 0.0523,
      "step": 9108
    },
    {
      "epoch": 2.093060661764706,
      "grad_norm": 0.653077244758606,
      "learning_rate": 6.461907679738563e-06,
      "loss": 0.0387,
      "step": 9109
    },
    {
      "epoch": 2.0932904411764706,
      "grad_norm": 1.01317298412323,
      "learning_rate": 6.46139705882353e-06,
      "loss": 0.0473,
      "step": 9110
    },
    {
      "epoch": 2.0935202205882355,
      "grad_norm": 1.0894633531570435,
      "learning_rate": 6.460886437908497e-06,
      "loss": 0.0479,
      "step": 9111
    },
    {
      "epoch": 2.09375,
      "grad_norm": 1.1290820837020874,
      "learning_rate": 6.460375816993465e-06,
      "loss": 0.0556,
      "step": 9112
    },
    {
      "epoch": 2.0939797794117645,
      "grad_norm": 1.1175694465637207,
      "learning_rate": 6.459865196078432e-06,
      "loss": 0.0367,
      "step": 9113
    },
    {
      "epoch": 2.0942095588235294,
      "grad_norm": 0.9128634929656982,
      "learning_rate": 6.459354575163399e-06,
      "loss": 0.0491,
      "step": 9114
    },
    {
      "epoch": 2.094439338235294,
      "grad_norm": 0.9009064435958862,
      "learning_rate": 6.458843954248366e-06,
      "loss": 0.0526,
      "step": 9115
    },
    {
      "epoch": 2.094669117647059,
      "grad_norm": 0.9038547873497009,
      "learning_rate": 6.458333333333334e-06,
      "loss": 0.0359,
      "step": 9116
    },
    {
      "epoch": 2.0948988970588234,
      "grad_norm": 0.8556246757507324,
      "learning_rate": 6.457822712418301e-06,
      "loss": 0.0393,
      "step": 9117
    },
    {
      "epoch": 2.0951286764705883,
      "grad_norm": 1.0072253942489624,
      "learning_rate": 6.457312091503268e-06,
      "loss": 0.0285,
      "step": 9118
    },
    {
      "epoch": 2.095358455882353,
      "grad_norm": 0.8254197835922241,
      "learning_rate": 6.456801470588236e-06,
      "loss": 0.0409,
      "step": 9119
    },
    {
      "epoch": 2.0955882352941178,
      "grad_norm": 0.8565303087234497,
      "learning_rate": 6.456290849673204e-06,
      "loss": 0.0598,
      "step": 9120
    },
    {
      "epoch": 2.0958180147058822,
      "grad_norm": 1.2418849468231201,
      "learning_rate": 6.455780228758171e-06,
      "loss": 0.0884,
      "step": 9121
    },
    {
      "epoch": 2.096047794117647,
      "grad_norm": 0.8465673327445984,
      "learning_rate": 6.455269607843138e-06,
      "loss": 0.0415,
      "step": 9122
    },
    {
      "epoch": 2.0962775735294117,
      "grad_norm": 1.0095601081848145,
      "learning_rate": 6.454758986928105e-06,
      "loss": 0.0612,
      "step": 9123
    },
    {
      "epoch": 2.0965073529411766,
      "grad_norm": 0.8877528309822083,
      "learning_rate": 6.4542483660130726e-06,
      "loss": 0.0431,
      "step": 9124
    },
    {
      "epoch": 2.096737132352941,
      "grad_norm": 0.8053385019302368,
      "learning_rate": 6.4537377450980396e-06,
      "loss": 0.0389,
      "step": 9125
    },
    {
      "epoch": 2.096966911764706,
      "grad_norm": 0.9213672876358032,
      "learning_rate": 6.453227124183007e-06,
      "loss": 0.0355,
      "step": 9126
    },
    {
      "epoch": 2.0971966911764706,
      "grad_norm": 0.7912269830703735,
      "learning_rate": 6.452716503267974e-06,
      "loss": 0.0405,
      "step": 9127
    },
    {
      "epoch": 2.0974264705882355,
      "grad_norm": 0.8785075545310974,
      "learning_rate": 6.452205882352942e-06,
      "loss": 0.0413,
      "step": 9128
    },
    {
      "epoch": 2.09765625,
      "grad_norm": 0.8935110569000244,
      "learning_rate": 6.451695261437909e-06,
      "loss": 0.0366,
      "step": 9129
    },
    {
      "epoch": 2.0978860294117645,
      "grad_norm": 0.8385164141654968,
      "learning_rate": 6.451184640522876e-06,
      "loss": 0.0287,
      "step": 9130
    },
    {
      "epoch": 2.0981158088235294,
      "grad_norm": 0.8169072866439819,
      "learning_rate": 6.450674019607843e-06,
      "loss": 0.0469,
      "step": 9131
    },
    {
      "epoch": 2.098345588235294,
      "grad_norm": 1.1136200428009033,
      "learning_rate": 6.450163398692811e-06,
      "loss": 0.0438,
      "step": 9132
    },
    {
      "epoch": 2.098575367647059,
      "grad_norm": 1.0741297006607056,
      "learning_rate": 6.449652777777778e-06,
      "loss": 0.0541,
      "step": 9133
    },
    {
      "epoch": 2.0988051470588234,
      "grad_norm": 0.7435236573219299,
      "learning_rate": 6.449142156862745e-06,
      "loss": 0.0274,
      "step": 9134
    },
    {
      "epoch": 2.0990349264705883,
      "grad_norm": 1.3070498704910278,
      "learning_rate": 6.448631535947712e-06,
      "loss": 0.0439,
      "step": 9135
    },
    {
      "epoch": 2.099264705882353,
      "grad_norm": 0.924224853515625,
      "learning_rate": 6.448120915032681e-06,
      "loss": 0.033,
      "step": 9136
    },
    {
      "epoch": 2.0994944852941178,
      "grad_norm": 0.8043264150619507,
      "learning_rate": 6.447610294117648e-06,
      "loss": 0.0404,
      "step": 9137
    },
    {
      "epoch": 2.0997242647058822,
      "grad_norm": 0.841059684753418,
      "learning_rate": 6.447099673202615e-06,
      "loss": 0.0344,
      "step": 9138
    },
    {
      "epoch": 2.099954044117647,
      "grad_norm": 1.1296941041946411,
      "learning_rate": 6.446589052287582e-06,
      "loss": 0.0606,
      "step": 9139
    },
    {
      "epoch": 2.1001838235294117,
      "grad_norm": 1.3769079446792603,
      "learning_rate": 6.44607843137255e-06,
      "loss": 0.043,
      "step": 9140
    },
    {
      "epoch": 2.1004136029411766,
      "grad_norm": 0.9096407294273376,
      "learning_rate": 6.445567810457517e-06,
      "loss": 0.0356,
      "step": 9141
    },
    {
      "epoch": 2.100643382352941,
      "grad_norm": 1.203747034072876,
      "learning_rate": 6.445057189542484e-06,
      "loss": 0.053,
      "step": 9142
    },
    {
      "epoch": 2.100873161764706,
      "grad_norm": 0.8508797287940979,
      "learning_rate": 6.444546568627451e-06,
      "loss": 0.0312,
      "step": 9143
    },
    {
      "epoch": 2.1011029411764706,
      "grad_norm": 0.9084551930427551,
      "learning_rate": 6.44403594771242e-06,
      "loss": 0.0431,
      "step": 9144
    },
    {
      "epoch": 2.1013327205882355,
      "grad_norm": 0.9547789692878723,
      "learning_rate": 6.443525326797387e-06,
      "loss": 0.0431,
      "step": 9145
    },
    {
      "epoch": 2.1015625,
      "grad_norm": 0.9878273606300354,
      "learning_rate": 6.443014705882354e-06,
      "loss": 0.044,
      "step": 9146
    },
    {
      "epoch": 2.1017922794117645,
      "grad_norm": 1.1224876642227173,
      "learning_rate": 6.442504084967321e-06,
      "loss": 0.0479,
      "step": 9147
    },
    {
      "epoch": 2.1020220588235294,
      "grad_norm": 0.866974413394928,
      "learning_rate": 6.4419934640522885e-06,
      "loss": 0.0399,
      "step": 9148
    },
    {
      "epoch": 2.102251838235294,
      "grad_norm": 1.131716251373291,
      "learning_rate": 6.4414828431372555e-06,
      "loss": 0.0561,
      "step": 9149
    },
    {
      "epoch": 2.102481617647059,
      "grad_norm": 1.3965959548950195,
      "learning_rate": 6.4409722222222226e-06,
      "loss": 0.0461,
      "step": 9150
    },
    {
      "epoch": 2.1027113970588234,
      "grad_norm": 0.8056157231330872,
      "learning_rate": 6.4404616013071896e-06,
      "loss": 0.0336,
      "step": 9151
    },
    {
      "epoch": 2.1029411764705883,
      "grad_norm": 1.3888283967971802,
      "learning_rate": 6.4399509803921574e-06,
      "loss": 0.0662,
      "step": 9152
    },
    {
      "epoch": 2.103170955882353,
      "grad_norm": 0.8667250275611877,
      "learning_rate": 6.439440359477125e-06,
      "loss": 0.0399,
      "step": 9153
    },
    {
      "epoch": 2.1034007352941178,
      "grad_norm": 1.7639350891113281,
      "learning_rate": 6.438929738562092e-06,
      "loss": 0.0584,
      "step": 9154
    },
    {
      "epoch": 2.1036305147058822,
      "grad_norm": 1.213472604751587,
      "learning_rate": 6.438419117647059e-06,
      "loss": 0.0313,
      "step": 9155
    },
    {
      "epoch": 2.103860294117647,
      "grad_norm": 1.0166950225830078,
      "learning_rate": 6.437908496732027e-06,
      "loss": 0.044,
      "step": 9156
    },
    {
      "epoch": 2.1040900735294117,
      "grad_norm": 0.7864627242088318,
      "learning_rate": 6.437397875816994e-06,
      "loss": 0.0382,
      "step": 9157
    },
    {
      "epoch": 2.1043198529411766,
      "grad_norm": 0.8982291221618652,
      "learning_rate": 6.436887254901961e-06,
      "loss": 0.0402,
      "step": 9158
    },
    {
      "epoch": 2.104549632352941,
      "grad_norm": 1.2892327308654785,
      "learning_rate": 6.436376633986928e-06,
      "loss": 0.0715,
      "step": 9159
    },
    {
      "epoch": 2.104779411764706,
      "grad_norm": 0.8826652765274048,
      "learning_rate": 6.435866013071896e-06,
      "loss": 0.031,
      "step": 9160
    },
    {
      "epoch": 2.1050091911764706,
      "grad_norm": 1.587873935699463,
      "learning_rate": 6.435355392156863e-06,
      "loss": 0.0539,
      "step": 9161
    },
    {
      "epoch": 2.1052389705882355,
      "grad_norm": 1.626158356666565,
      "learning_rate": 6.43484477124183e-06,
      "loss": 0.081,
      "step": 9162
    },
    {
      "epoch": 2.10546875,
      "grad_norm": 0.8158734440803528,
      "learning_rate": 6.434334150326797e-06,
      "loss": 0.0243,
      "step": 9163
    },
    {
      "epoch": 2.1056985294117645,
      "grad_norm": 0.7727553844451904,
      "learning_rate": 6.433823529411766e-06,
      "loss": 0.0402,
      "step": 9164
    },
    {
      "epoch": 2.1059283088235294,
      "grad_norm": 0.8977357745170593,
      "learning_rate": 6.433312908496733e-06,
      "loss": 0.0347,
      "step": 9165
    },
    {
      "epoch": 2.106158088235294,
      "grad_norm": 0.9120752811431885,
      "learning_rate": 6.4328022875817e-06,
      "loss": 0.0373,
      "step": 9166
    },
    {
      "epoch": 2.106387867647059,
      "grad_norm": 1.0334044694900513,
      "learning_rate": 6.432291666666667e-06,
      "loss": 0.044,
      "step": 9167
    },
    {
      "epoch": 2.1066176470588234,
      "grad_norm": 1.9636986255645752,
      "learning_rate": 6.431781045751635e-06,
      "loss": 0.0775,
      "step": 9168
    },
    {
      "epoch": 2.1068474264705883,
      "grad_norm": 0.7472406029701233,
      "learning_rate": 6.431270424836602e-06,
      "loss": 0.0217,
      "step": 9169
    },
    {
      "epoch": 2.107077205882353,
      "grad_norm": 0.841731071472168,
      "learning_rate": 6.430759803921569e-06,
      "loss": 0.0329,
      "step": 9170
    },
    {
      "epoch": 2.1073069852941178,
      "grad_norm": 0.8055609464645386,
      "learning_rate": 6.430249183006536e-06,
      "loss": 0.0339,
      "step": 9171
    },
    {
      "epoch": 2.1075367647058822,
      "grad_norm": 0.9685935974121094,
      "learning_rate": 6.4297385620915045e-06,
      "loss": 0.0412,
      "step": 9172
    },
    {
      "epoch": 2.107766544117647,
      "grad_norm": 0.8915781378746033,
      "learning_rate": 6.4292279411764715e-06,
      "loss": 0.0345,
      "step": 9173
    },
    {
      "epoch": 2.1079963235294117,
      "grad_norm": 1.3041335344314575,
      "learning_rate": 6.4287173202614385e-06,
      "loss": 0.0561,
      "step": 9174
    },
    {
      "epoch": 2.1082261029411766,
      "grad_norm": 1.052586317062378,
      "learning_rate": 6.4282066993464055e-06,
      "loss": 0.0414,
      "step": 9175
    },
    {
      "epoch": 2.108455882352941,
      "grad_norm": 0.7492402791976929,
      "learning_rate": 6.427696078431373e-06,
      "loss": 0.0205,
      "step": 9176
    },
    {
      "epoch": 2.108685661764706,
      "grad_norm": 1.1844886541366577,
      "learning_rate": 6.42718545751634e-06,
      "loss": 0.034,
      "step": 9177
    },
    {
      "epoch": 2.1089154411764706,
      "grad_norm": 0.6758891344070435,
      "learning_rate": 6.4266748366013074e-06,
      "loss": 0.0215,
      "step": 9178
    },
    {
      "epoch": 2.1091452205882355,
      "grad_norm": 1.0657522678375244,
      "learning_rate": 6.4261642156862744e-06,
      "loss": 0.0597,
      "step": 9179
    },
    {
      "epoch": 2.109375,
      "grad_norm": 1.163484811782837,
      "learning_rate": 6.425653594771243e-06,
      "loss": 0.0493,
      "step": 9180
    },
    {
      "epoch": 2.1096047794117645,
      "grad_norm": 0.9619719982147217,
      "learning_rate": 6.42514297385621e-06,
      "loss": 0.0354,
      "step": 9181
    },
    {
      "epoch": 2.1098345588235294,
      "grad_norm": 0.964320957660675,
      "learning_rate": 6.424632352941177e-06,
      "loss": 0.0369,
      "step": 9182
    },
    {
      "epoch": 2.110064338235294,
      "grad_norm": 0.9041252136230469,
      "learning_rate": 6.424121732026144e-06,
      "loss": 0.0435,
      "step": 9183
    },
    {
      "epoch": 2.110294117647059,
      "grad_norm": 0.7456398606300354,
      "learning_rate": 6.423611111111112e-06,
      "loss": 0.0336,
      "step": 9184
    },
    {
      "epoch": 2.1105238970588234,
      "grad_norm": 0.9574227929115295,
      "learning_rate": 6.423100490196079e-06,
      "loss": 0.0294,
      "step": 9185
    },
    {
      "epoch": 2.1107536764705883,
      "grad_norm": 0.9028527736663818,
      "learning_rate": 6.422589869281046e-06,
      "loss": 0.0351,
      "step": 9186
    },
    {
      "epoch": 2.110983455882353,
      "grad_norm": 0.8364507555961609,
      "learning_rate": 6.422079248366013e-06,
      "loss": 0.0456,
      "step": 9187
    },
    {
      "epoch": 2.1112132352941178,
      "grad_norm": 0.692546010017395,
      "learning_rate": 6.421568627450982e-06,
      "loss": 0.026,
      "step": 9188
    },
    {
      "epoch": 2.1114430147058822,
      "grad_norm": 1.0424656867980957,
      "learning_rate": 6.421058006535949e-06,
      "loss": 0.0513,
      "step": 9189
    },
    {
      "epoch": 2.111672794117647,
      "grad_norm": 0.7368237972259521,
      "learning_rate": 6.420547385620916e-06,
      "loss": 0.0372,
      "step": 9190
    },
    {
      "epoch": 2.1119025735294117,
      "grad_norm": 0.8210532069206238,
      "learning_rate": 6.420036764705883e-06,
      "loss": 0.049,
      "step": 9191
    },
    {
      "epoch": 2.1121323529411766,
      "grad_norm": 1.1186639070510864,
      "learning_rate": 6.419526143790851e-06,
      "loss": 0.0507,
      "step": 9192
    },
    {
      "epoch": 2.112362132352941,
      "grad_norm": 1.1293286085128784,
      "learning_rate": 6.419015522875818e-06,
      "loss": 0.0429,
      "step": 9193
    },
    {
      "epoch": 2.112591911764706,
      "grad_norm": 0.7906232476234436,
      "learning_rate": 6.418504901960785e-06,
      "loss": 0.0356,
      "step": 9194
    },
    {
      "epoch": 2.1128216911764706,
      "grad_norm": 1.1226093769073486,
      "learning_rate": 6.417994281045752e-06,
      "loss": 0.0392,
      "step": 9195
    },
    {
      "epoch": 2.1130514705882355,
      "grad_norm": 1.2757254838943481,
      "learning_rate": 6.41748366013072e-06,
      "loss": 0.0651,
      "step": 9196
    },
    {
      "epoch": 2.11328125,
      "grad_norm": 0.6797299385070801,
      "learning_rate": 6.416973039215687e-06,
      "loss": 0.0446,
      "step": 9197
    },
    {
      "epoch": 2.1135110294117645,
      "grad_norm": 0.9109116196632385,
      "learning_rate": 6.4164624183006545e-06,
      "loss": 0.0387,
      "step": 9198
    },
    {
      "epoch": 2.1137408088235294,
      "grad_norm": 1.0489054918289185,
      "learning_rate": 6.4159517973856215e-06,
      "loss": 0.0456,
      "step": 9199
    },
    {
      "epoch": 2.113970588235294,
      "grad_norm": 1.2109808921813965,
      "learning_rate": 6.415441176470589e-06,
      "loss": 0.0674,
      "step": 9200
    },
    {
      "epoch": 2.114200367647059,
      "grad_norm": 0.9105067849159241,
      "learning_rate": 6.414930555555556e-06,
      "loss": 0.0345,
      "step": 9201
    },
    {
      "epoch": 2.1144301470588234,
      "grad_norm": 1.0477159023284912,
      "learning_rate": 6.414419934640523e-06,
      "loss": 0.0557,
      "step": 9202
    },
    {
      "epoch": 2.1146599264705883,
      "grad_norm": 0.7463713884353638,
      "learning_rate": 6.41390931372549e-06,
      "loss": 0.0364,
      "step": 9203
    },
    {
      "epoch": 2.114889705882353,
      "grad_norm": 1.1124463081359863,
      "learning_rate": 6.413398692810458e-06,
      "loss": 0.0463,
      "step": 9204
    },
    {
      "epoch": 2.1151194852941178,
      "grad_norm": 1.2386667728424072,
      "learning_rate": 6.412888071895425e-06,
      "loss": 0.0409,
      "step": 9205
    },
    {
      "epoch": 2.1153492647058822,
      "grad_norm": 1.0405094623565674,
      "learning_rate": 6.412377450980392e-06,
      "loss": 0.0479,
      "step": 9206
    },
    {
      "epoch": 2.115579044117647,
      "grad_norm": 0.6761431097984314,
      "learning_rate": 6.411866830065359e-06,
      "loss": 0.0295,
      "step": 9207
    },
    {
      "epoch": 2.1158088235294117,
      "grad_norm": 1.0078375339508057,
      "learning_rate": 6.411356209150328e-06,
      "loss": 0.0401,
      "step": 9208
    },
    {
      "epoch": 2.1160386029411766,
      "grad_norm": 1.1396949291229248,
      "learning_rate": 6.410845588235295e-06,
      "loss": 0.0814,
      "step": 9209
    },
    {
      "epoch": 2.116268382352941,
      "grad_norm": 1.06510591506958,
      "learning_rate": 6.410334967320262e-06,
      "loss": 0.0425,
      "step": 9210
    },
    {
      "epoch": 2.116498161764706,
      "grad_norm": 0.7889460921287537,
      "learning_rate": 6.409824346405229e-06,
      "loss": 0.031,
      "step": 9211
    },
    {
      "epoch": 2.1167279411764706,
      "grad_norm": 0.9666141867637634,
      "learning_rate": 6.409313725490197e-06,
      "loss": 0.0327,
      "step": 9212
    },
    {
      "epoch": 2.1169577205882355,
      "grad_norm": 0.7039762139320374,
      "learning_rate": 6.408803104575164e-06,
      "loss": 0.0323,
      "step": 9213
    },
    {
      "epoch": 2.1171875,
      "grad_norm": 1.4121832847595215,
      "learning_rate": 6.408292483660131e-06,
      "loss": 0.0662,
      "step": 9214
    },
    {
      "epoch": 2.1174172794117645,
      "grad_norm": 1.0166534185409546,
      "learning_rate": 6.407781862745098e-06,
      "loss": 0.0386,
      "step": 9215
    },
    {
      "epoch": 2.1176470588235294,
      "grad_norm": 0.9423298239707947,
      "learning_rate": 6.407271241830067e-06,
      "loss": 0.0331,
      "step": 9216
    },
    {
      "epoch": 2.117876838235294,
      "grad_norm": 1.8421833515167236,
      "learning_rate": 6.406760620915034e-06,
      "loss": 0.0383,
      "step": 9217
    },
    {
      "epoch": 2.118106617647059,
      "grad_norm": 1.1120331287384033,
      "learning_rate": 6.406250000000001e-06,
      "loss": 0.0568,
      "step": 9218
    },
    {
      "epoch": 2.1183363970588234,
      "grad_norm": 0.7222864031791687,
      "learning_rate": 6.405739379084968e-06,
      "loss": 0.032,
      "step": 9219
    },
    {
      "epoch": 2.1185661764705883,
      "grad_norm": 0.8853159546852112,
      "learning_rate": 6.405228758169935e-06,
      "loss": 0.0453,
      "step": 9220
    },
    {
      "epoch": 2.118795955882353,
      "grad_norm": 1.0405853986740112,
      "learning_rate": 6.404718137254903e-06,
      "loss": 0.0351,
      "step": 9221
    },
    {
      "epoch": 2.1190257352941178,
      "grad_norm": 0.9301741123199463,
      "learning_rate": 6.40420751633987e-06,
      "loss": 0.0447,
      "step": 9222
    },
    {
      "epoch": 2.1192555147058822,
      "grad_norm": 0.9873364567756653,
      "learning_rate": 6.403696895424837e-06,
      "loss": 0.0385,
      "step": 9223
    },
    {
      "epoch": 2.119485294117647,
      "grad_norm": 1.1081974506378174,
      "learning_rate": 6.403186274509804e-06,
      "loss": 0.0319,
      "step": 9224
    },
    {
      "epoch": 2.1197150735294117,
      "grad_norm": 0.8090613484382629,
      "learning_rate": 6.402675653594772e-06,
      "loss": 0.0309,
      "step": 9225
    },
    {
      "epoch": 2.1199448529411766,
      "grad_norm": 1.135599136352539,
      "learning_rate": 6.402165032679739e-06,
      "loss": 0.0562,
      "step": 9226
    },
    {
      "epoch": 2.120174632352941,
      "grad_norm": 0.9477061629295349,
      "learning_rate": 6.401654411764706e-06,
      "loss": 0.0501,
      "step": 9227
    },
    {
      "epoch": 2.120404411764706,
      "grad_norm": 0.8867806792259216,
      "learning_rate": 6.401143790849673e-06,
      "loss": 0.0366,
      "step": 9228
    },
    {
      "epoch": 2.1206341911764706,
      "grad_norm": 0.9827606081962585,
      "learning_rate": 6.400633169934641e-06,
      "loss": 0.0505,
      "step": 9229
    },
    {
      "epoch": 2.1208639705882355,
      "grad_norm": 0.8813412189483643,
      "learning_rate": 6.400122549019608e-06,
      "loss": 0.046,
      "step": 9230
    },
    {
      "epoch": 2.12109375,
      "grad_norm": 1.1165331602096558,
      "learning_rate": 6.399611928104575e-06,
      "loss": 0.0406,
      "step": 9231
    },
    {
      "epoch": 2.1213235294117645,
      "grad_norm": 0.7916243672370911,
      "learning_rate": 6.399101307189542e-06,
      "loss": 0.0342,
      "step": 9232
    },
    {
      "epoch": 2.1215533088235294,
      "grad_norm": 0.8290827870368958,
      "learning_rate": 6.398590686274511e-06,
      "loss": 0.032,
      "step": 9233
    },
    {
      "epoch": 2.121783088235294,
      "grad_norm": 0.9543606638908386,
      "learning_rate": 6.398080065359478e-06,
      "loss": 0.0602,
      "step": 9234
    },
    {
      "epoch": 2.122012867647059,
      "grad_norm": 0.9744476675987244,
      "learning_rate": 6.397569444444445e-06,
      "loss": 0.0418,
      "step": 9235
    },
    {
      "epoch": 2.1222426470588234,
      "grad_norm": 0.7690774202346802,
      "learning_rate": 6.397058823529412e-06,
      "loss": 0.0341,
      "step": 9236
    },
    {
      "epoch": 2.1224724264705883,
      "grad_norm": 1.0424588918685913,
      "learning_rate": 6.39654820261438e-06,
      "loss": 0.0456,
      "step": 9237
    },
    {
      "epoch": 2.122702205882353,
      "grad_norm": 0.9122097492218018,
      "learning_rate": 6.396037581699347e-06,
      "loss": 0.0385,
      "step": 9238
    },
    {
      "epoch": 2.1229319852941178,
      "grad_norm": 1.2164404392242432,
      "learning_rate": 6.395526960784314e-06,
      "loss": 0.0514,
      "step": 9239
    },
    {
      "epoch": 2.1231617647058822,
      "grad_norm": 0.9704481959342957,
      "learning_rate": 6.395016339869281e-06,
      "loss": 0.0424,
      "step": 9240
    },
    {
      "epoch": 2.123391544117647,
      "grad_norm": 0.7563516497612,
      "learning_rate": 6.394505718954249e-06,
      "loss": 0.0351,
      "step": 9241
    },
    {
      "epoch": 2.1236213235294117,
      "grad_norm": 0.8039131760597229,
      "learning_rate": 6.393995098039216e-06,
      "loss": 0.0457,
      "step": 9242
    },
    {
      "epoch": 2.1238511029411766,
      "grad_norm": 1.0689337253570557,
      "learning_rate": 6.393484477124184e-06,
      "loss": 0.0525,
      "step": 9243
    },
    {
      "epoch": 2.124080882352941,
      "grad_norm": 0.6872687935829163,
      "learning_rate": 6.392973856209151e-06,
      "loss": 0.0304,
      "step": 9244
    },
    {
      "epoch": 2.124310661764706,
      "grad_norm": 1.0563098192214966,
      "learning_rate": 6.3924632352941186e-06,
      "loss": 0.0495,
      "step": 9245
    },
    {
      "epoch": 2.1245404411764706,
      "grad_norm": 1.1890079975128174,
      "learning_rate": 6.391952614379086e-06,
      "loss": 0.0448,
      "step": 9246
    },
    {
      "epoch": 2.1247702205882355,
      "grad_norm": 0.9425524473190308,
      "learning_rate": 6.391441993464053e-06,
      "loss": 0.0447,
      "step": 9247
    },
    {
      "epoch": 2.125,
      "grad_norm": 1.2862651348114014,
      "learning_rate": 6.39093137254902e-06,
      "loss": 0.0536,
      "step": 9248
    },
    {
      "epoch": 2.1252297794117645,
      "grad_norm": 1.492000937461853,
      "learning_rate": 6.3904207516339875e-06,
      "loss": 0.0638,
      "step": 9249
    },
    {
      "epoch": 2.1254595588235294,
      "grad_norm": 0.8827400803565979,
      "learning_rate": 6.3899101307189545e-06,
      "loss": 0.0363,
      "step": 9250
    },
    {
      "epoch": 2.125689338235294,
      "grad_norm": 0.9845278859138489,
      "learning_rate": 6.3893995098039215e-06,
      "loss": 0.0475,
      "step": 9251
    },
    {
      "epoch": 2.125919117647059,
      "grad_norm": 0.9493170976638794,
      "learning_rate": 6.3888888888888885e-06,
      "loss": 0.0409,
      "step": 9252
    },
    {
      "epoch": 2.1261488970588234,
      "grad_norm": 0.9417251348495483,
      "learning_rate": 6.388378267973857e-06,
      "loss": 0.0406,
      "step": 9253
    },
    {
      "epoch": 2.1263786764705883,
      "grad_norm": 0.9062091708183289,
      "learning_rate": 6.387867647058824e-06,
      "loss": 0.0465,
      "step": 9254
    },
    {
      "epoch": 2.126608455882353,
      "grad_norm": 0.9564327597618103,
      "learning_rate": 6.387357026143791e-06,
      "loss": 0.0469,
      "step": 9255
    },
    {
      "epoch": 2.1268382352941178,
      "grad_norm": 1.0186272859573364,
      "learning_rate": 6.386846405228758e-06,
      "loss": 0.0554,
      "step": 9256
    },
    {
      "epoch": 2.1270680147058822,
      "grad_norm": 1.1540976762771606,
      "learning_rate": 6.386335784313726e-06,
      "loss": 0.0532,
      "step": 9257
    },
    {
      "epoch": 2.127297794117647,
      "grad_norm": 0.9694763422012329,
      "learning_rate": 6.385825163398693e-06,
      "loss": 0.06,
      "step": 9258
    },
    {
      "epoch": 2.1275275735294117,
      "grad_norm": 0.9221271276473999,
      "learning_rate": 6.38531454248366e-06,
      "loss": 0.0479,
      "step": 9259
    },
    {
      "epoch": 2.1277573529411766,
      "grad_norm": 0.662998616695404,
      "learning_rate": 6.384803921568627e-06,
      "loss": 0.0235,
      "step": 9260
    },
    {
      "epoch": 2.127987132352941,
      "grad_norm": 0.8085826635360718,
      "learning_rate": 6.384293300653596e-06,
      "loss": 0.0342,
      "step": 9261
    },
    {
      "epoch": 2.128216911764706,
      "grad_norm": 0.9601728320121765,
      "learning_rate": 6.383782679738563e-06,
      "loss": 0.0329,
      "step": 9262
    },
    {
      "epoch": 2.1284466911764706,
      "grad_norm": 0.849269688129425,
      "learning_rate": 6.38327205882353e-06,
      "loss": 0.0458,
      "step": 9263
    },
    {
      "epoch": 2.1286764705882355,
      "grad_norm": 0.9425193071365356,
      "learning_rate": 6.382761437908497e-06,
      "loss": 0.0359,
      "step": 9264
    },
    {
      "epoch": 2.12890625,
      "grad_norm": 0.7940637469291687,
      "learning_rate": 6.382250816993465e-06,
      "loss": 0.0405,
      "step": 9265
    },
    {
      "epoch": 2.1291360294117645,
      "grad_norm": 0.7032123804092407,
      "learning_rate": 6.381740196078432e-06,
      "loss": 0.0251,
      "step": 9266
    },
    {
      "epoch": 2.1293658088235294,
      "grad_norm": 1.000596523284912,
      "learning_rate": 6.381229575163399e-06,
      "loss": 0.0431,
      "step": 9267
    },
    {
      "epoch": 2.129595588235294,
      "grad_norm": 1.0435009002685547,
      "learning_rate": 6.380718954248366e-06,
      "loss": 0.0473,
      "step": 9268
    },
    {
      "epoch": 2.129825367647059,
      "grad_norm": 0.861922562122345,
      "learning_rate": 6.3802083333333345e-06,
      "loss": 0.0334,
      "step": 9269
    },
    {
      "epoch": 2.1300551470588234,
      "grad_norm": 0.9865617156028748,
      "learning_rate": 6.3796977124183016e-06,
      "loss": 0.0487,
      "step": 9270
    },
    {
      "epoch": 2.1302849264705883,
      "grad_norm": 0.8319308757781982,
      "learning_rate": 6.3791870915032686e-06,
      "loss": 0.0269,
      "step": 9271
    },
    {
      "epoch": 2.130514705882353,
      "grad_norm": 0.788806676864624,
      "learning_rate": 6.378676470588236e-06,
      "loss": 0.0364,
      "step": 9272
    },
    {
      "epoch": 2.1307444852941178,
      "grad_norm": 1.7776380777359009,
      "learning_rate": 6.3781658496732034e-06,
      "loss": 0.0612,
      "step": 9273
    },
    {
      "epoch": 2.1309742647058822,
      "grad_norm": 0.9421188235282898,
      "learning_rate": 6.3776552287581705e-06,
      "loss": 0.0572,
      "step": 9274
    },
    {
      "epoch": 2.131204044117647,
      "grad_norm": 0.7980433702468872,
      "learning_rate": 6.3771446078431375e-06,
      "loss": 0.028,
      "step": 9275
    },
    {
      "epoch": 2.1314338235294117,
      "grad_norm": 1.0089365243911743,
      "learning_rate": 6.3766339869281045e-06,
      "loss": 0.0526,
      "step": 9276
    },
    {
      "epoch": 2.1316636029411766,
      "grad_norm": 0.9042372703552246,
      "learning_rate": 6.376123366013073e-06,
      "loss": 0.0369,
      "step": 9277
    },
    {
      "epoch": 2.131893382352941,
      "grad_norm": 1.7823461294174194,
      "learning_rate": 6.37561274509804e-06,
      "loss": 0.0722,
      "step": 9278
    },
    {
      "epoch": 2.132123161764706,
      "grad_norm": 1.1152743101119995,
      "learning_rate": 6.375102124183007e-06,
      "loss": 0.0357,
      "step": 9279
    },
    {
      "epoch": 2.1323529411764706,
      "grad_norm": 0.9649171233177185,
      "learning_rate": 6.374591503267974e-06,
      "loss": 0.0396,
      "step": 9280
    },
    {
      "epoch": 2.1325827205882355,
      "grad_norm": 0.8041839599609375,
      "learning_rate": 6.374080882352942e-06,
      "loss": 0.0327,
      "step": 9281
    },
    {
      "epoch": 2.1328125,
      "grad_norm": 0.974515974521637,
      "learning_rate": 6.373570261437909e-06,
      "loss": 0.034,
      "step": 9282
    },
    {
      "epoch": 2.1330422794117645,
      "grad_norm": 1.3390835523605347,
      "learning_rate": 6.373059640522876e-06,
      "loss": 0.064,
      "step": 9283
    },
    {
      "epoch": 2.1332720588235294,
      "grad_norm": 0.7309345602989197,
      "learning_rate": 6.372549019607843e-06,
      "loss": 0.0263,
      "step": 9284
    },
    {
      "epoch": 2.133501838235294,
      "grad_norm": 1.171447515487671,
      "learning_rate": 6.372038398692811e-06,
      "loss": 0.051,
      "step": 9285
    },
    {
      "epoch": 2.133731617647059,
      "grad_norm": 1.0875890254974365,
      "learning_rate": 6.371527777777778e-06,
      "loss": 0.0301,
      "step": 9286
    },
    {
      "epoch": 2.1339613970588234,
      "grad_norm": 0.8511514663696289,
      "learning_rate": 6.371017156862746e-06,
      "loss": 0.0304,
      "step": 9287
    },
    {
      "epoch": 2.1341911764705883,
      "grad_norm": 0.8743834495544434,
      "learning_rate": 6.370506535947713e-06,
      "loss": 0.0341,
      "step": 9288
    },
    {
      "epoch": 2.134420955882353,
      "grad_norm": 0.9163483381271362,
      "learning_rate": 6.369995915032681e-06,
      "loss": 0.0233,
      "step": 9289
    },
    {
      "epoch": 2.1346507352941178,
      "grad_norm": 1.1259832382202148,
      "learning_rate": 6.369485294117648e-06,
      "loss": 0.0449,
      "step": 9290
    },
    {
      "epoch": 2.1348805147058822,
      "grad_norm": 0.8734238743782043,
      "learning_rate": 6.368974673202615e-06,
      "loss": 0.04,
      "step": 9291
    },
    {
      "epoch": 2.135110294117647,
      "grad_norm": 1.0736192464828491,
      "learning_rate": 6.368464052287582e-06,
      "loss": 0.0389,
      "step": 9292
    },
    {
      "epoch": 2.1353400735294117,
      "grad_norm": 1.1498867273330688,
      "learning_rate": 6.36795343137255e-06,
      "loss": 0.0648,
      "step": 9293
    },
    {
      "epoch": 2.1355698529411766,
      "grad_norm": 0.9237087368965149,
      "learning_rate": 6.367442810457517e-06,
      "loss": 0.045,
      "step": 9294
    },
    {
      "epoch": 2.135799632352941,
      "grad_norm": 1.0509973764419556,
      "learning_rate": 6.366932189542484e-06,
      "loss": 0.033,
      "step": 9295
    },
    {
      "epoch": 2.136029411764706,
      "grad_norm": 1.3066942691802979,
      "learning_rate": 6.366421568627451e-06,
      "loss": 0.0679,
      "step": 9296
    },
    {
      "epoch": 2.1362591911764706,
      "grad_norm": 1.5359337329864502,
      "learning_rate": 6.365910947712419e-06,
      "loss": 0.0869,
      "step": 9297
    },
    {
      "epoch": 2.1364889705882355,
      "grad_norm": 1.0194053649902344,
      "learning_rate": 6.3654003267973864e-06,
      "loss": 0.0466,
      "step": 9298
    },
    {
      "epoch": 2.13671875,
      "grad_norm": 1.3437880277633667,
      "learning_rate": 6.3648897058823534e-06,
      "loss": 0.0559,
      "step": 9299
    },
    {
      "epoch": 2.1369485294117645,
      "grad_norm": 0.9539950489997864,
      "learning_rate": 6.3643790849673205e-06,
      "loss": 0.0586,
      "step": 9300
    },
    {
      "epoch": 2.1371783088235294,
      "grad_norm": 1.0313506126403809,
      "learning_rate": 6.363868464052288e-06,
      "loss": 0.0431,
      "step": 9301
    },
    {
      "epoch": 2.137408088235294,
      "grad_norm": 1.0627026557922363,
      "learning_rate": 6.363357843137255e-06,
      "loss": 0.0533,
      "step": 9302
    },
    {
      "epoch": 2.137637867647059,
      "grad_norm": 1.0416679382324219,
      "learning_rate": 6.362847222222222e-06,
      "loss": 0.0405,
      "step": 9303
    },
    {
      "epoch": 2.1378676470588234,
      "grad_norm": 0.9581061005592346,
      "learning_rate": 6.362336601307189e-06,
      "loss": 0.0381,
      "step": 9304
    },
    {
      "epoch": 2.1380974264705883,
      "grad_norm": 1.103661298751831,
      "learning_rate": 6.361825980392158e-06,
      "loss": 0.0357,
      "step": 9305
    },
    {
      "epoch": 2.138327205882353,
      "grad_norm": 0.8387293219566345,
      "learning_rate": 6.361315359477125e-06,
      "loss": 0.0322,
      "step": 9306
    },
    {
      "epoch": 2.1385569852941178,
      "grad_norm": 0.7798328995704651,
      "learning_rate": 6.360804738562092e-06,
      "loss": 0.0338,
      "step": 9307
    },
    {
      "epoch": 2.1387867647058822,
      "grad_norm": 0.6946943402290344,
      "learning_rate": 6.360294117647059e-06,
      "loss": 0.0232,
      "step": 9308
    },
    {
      "epoch": 2.139016544117647,
      "grad_norm": 0.9518070816993713,
      "learning_rate": 6.359783496732027e-06,
      "loss": 0.0393,
      "step": 9309
    },
    {
      "epoch": 2.1392463235294117,
      "grad_norm": 0.9209126234054565,
      "learning_rate": 6.359272875816994e-06,
      "loss": 0.0385,
      "step": 9310
    },
    {
      "epoch": 2.1394761029411766,
      "grad_norm": 1.2695177793502808,
      "learning_rate": 6.358762254901961e-06,
      "loss": 0.0461,
      "step": 9311
    },
    {
      "epoch": 2.139705882352941,
      "grad_norm": 1.0408746004104614,
      "learning_rate": 6.358251633986928e-06,
      "loss": 0.0466,
      "step": 9312
    },
    {
      "epoch": 2.139935661764706,
      "grad_norm": 0.7960158586502075,
      "learning_rate": 6.357741013071897e-06,
      "loss": 0.0284,
      "step": 9313
    },
    {
      "epoch": 2.1401654411764706,
      "grad_norm": 1.1838761568069458,
      "learning_rate": 6.357230392156864e-06,
      "loss": 0.043,
      "step": 9314
    },
    {
      "epoch": 2.1403952205882355,
      "grad_norm": 0.7113810181617737,
      "learning_rate": 6.356719771241831e-06,
      "loss": 0.0228,
      "step": 9315
    },
    {
      "epoch": 2.140625,
      "grad_norm": 1.1535497903823853,
      "learning_rate": 6.356209150326798e-06,
      "loss": 0.0542,
      "step": 9316
    },
    {
      "epoch": 2.1408547794117645,
      "grad_norm": 0.818988561630249,
      "learning_rate": 6.355698529411766e-06,
      "loss": 0.0332,
      "step": 9317
    },
    {
      "epoch": 2.1410845588235294,
      "grad_norm": 0.9800836443901062,
      "learning_rate": 6.355187908496733e-06,
      "loss": 0.0546,
      "step": 9318
    },
    {
      "epoch": 2.141314338235294,
      "grad_norm": 1.297849178314209,
      "learning_rate": 6.3546772875817e-06,
      "loss": 0.0237,
      "step": 9319
    },
    {
      "epoch": 2.141544117647059,
      "grad_norm": 0.8633654117584229,
      "learning_rate": 6.354166666666667e-06,
      "loss": 0.0454,
      "step": 9320
    },
    {
      "epoch": 2.1417738970588234,
      "grad_norm": 1.0682992935180664,
      "learning_rate": 6.353656045751635e-06,
      "loss": 0.0415,
      "step": 9321
    },
    {
      "epoch": 2.1420036764705883,
      "grad_norm": 0.7378084063529968,
      "learning_rate": 6.353145424836602e-06,
      "loss": 0.0382,
      "step": 9322
    },
    {
      "epoch": 2.142233455882353,
      "grad_norm": 1.000014066696167,
      "learning_rate": 6.352634803921569e-06,
      "loss": 0.0466,
      "step": 9323
    },
    {
      "epoch": 2.1424632352941178,
      "grad_norm": 0.9302466511726379,
      "learning_rate": 6.3521241830065364e-06,
      "loss": 0.0364,
      "step": 9324
    },
    {
      "epoch": 2.1426930147058822,
      "grad_norm": 1.1980767250061035,
      "learning_rate": 6.351613562091504e-06,
      "loss": 0.0591,
      "step": 9325
    },
    {
      "epoch": 2.142922794117647,
      "grad_norm": 1.0488088130950928,
      "learning_rate": 6.351102941176471e-06,
      "loss": 0.0519,
      "step": 9326
    },
    {
      "epoch": 2.1431525735294117,
      "grad_norm": 0.8890820145606995,
      "learning_rate": 6.350592320261438e-06,
      "loss": 0.0539,
      "step": 9327
    },
    {
      "epoch": 2.1433823529411766,
      "grad_norm": 1.0562756061553955,
      "learning_rate": 6.350081699346405e-06,
      "loss": 0.0493,
      "step": 9328
    },
    {
      "epoch": 2.143612132352941,
      "grad_norm": 1.1507114171981812,
      "learning_rate": 6.349571078431373e-06,
      "loss": 0.0583,
      "step": 9329
    },
    {
      "epoch": 2.143841911764706,
      "grad_norm": 1.0480972528457642,
      "learning_rate": 6.34906045751634e-06,
      "loss": 0.0479,
      "step": 9330
    },
    {
      "epoch": 2.1440716911764706,
      "grad_norm": 0.6421810984611511,
      "learning_rate": 6.348549836601307e-06,
      "loss": 0.0254,
      "step": 9331
    },
    {
      "epoch": 2.1443014705882355,
      "grad_norm": 1.0439778566360474,
      "learning_rate": 6.348039215686275e-06,
      "loss": 0.0413,
      "step": 9332
    },
    {
      "epoch": 2.14453125,
      "grad_norm": 0.9806585907936096,
      "learning_rate": 6.347528594771243e-06,
      "loss": 0.0468,
      "step": 9333
    },
    {
      "epoch": 2.1447610294117645,
      "grad_norm": 0.799437403678894,
      "learning_rate": 6.34701797385621e-06,
      "loss": 0.0367,
      "step": 9334
    },
    {
      "epoch": 2.1449908088235294,
      "grad_norm": 1.3839389085769653,
      "learning_rate": 6.346507352941177e-06,
      "loss": 0.0609,
      "step": 9335
    },
    {
      "epoch": 2.145220588235294,
      "grad_norm": 0.8174501061439514,
      "learning_rate": 6.345996732026144e-06,
      "loss": 0.0363,
      "step": 9336
    },
    {
      "epoch": 2.145450367647059,
      "grad_norm": 0.6460140347480774,
      "learning_rate": 6.345486111111112e-06,
      "loss": 0.0333,
      "step": 9337
    },
    {
      "epoch": 2.1456801470588234,
      "grad_norm": 0.8574997782707214,
      "learning_rate": 6.344975490196079e-06,
      "loss": 0.0418,
      "step": 9338
    },
    {
      "epoch": 2.1459099264705883,
      "grad_norm": 0.9797515869140625,
      "learning_rate": 6.344464869281046e-06,
      "loss": 0.0363,
      "step": 9339
    },
    {
      "epoch": 2.146139705882353,
      "grad_norm": 1.0665532350540161,
      "learning_rate": 6.343954248366013e-06,
      "loss": 0.0294,
      "step": 9340
    },
    {
      "epoch": 2.1463694852941178,
      "grad_norm": 0.5730997920036316,
      "learning_rate": 6.343443627450982e-06,
      "loss": 0.0288,
      "step": 9341
    },
    {
      "epoch": 2.1465992647058822,
      "grad_norm": 0.8491045236587524,
      "learning_rate": 6.342933006535949e-06,
      "loss": 0.0431,
      "step": 9342
    },
    {
      "epoch": 2.146829044117647,
      "grad_norm": 1.1784119606018066,
      "learning_rate": 6.342422385620916e-06,
      "loss": 0.0518,
      "step": 9343
    },
    {
      "epoch": 2.1470588235294117,
      "grad_norm": 1.1833741664886475,
      "learning_rate": 6.341911764705883e-06,
      "loss": 0.0333,
      "step": 9344
    },
    {
      "epoch": 2.1472886029411766,
      "grad_norm": 0.8779149651527405,
      "learning_rate": 6.3414011437908505e-06,
      "loss": 0.0376,
      "step": 9345
    },
    {
      "epoch": 2.147518382352941,
      "grad_norm": 0.872698187828064,
      "learning_rate": 6.3408905228758175e-06,
      "loss": 0.0474,
      "step": 9346
    },
    {
      "epoch": 2.147748161764706,
      "grad_norm": 1.0133451223373413,
      "learning_rate": 6.3403799019607845e-06,
      "loss": 0.0425,
      "step": 9347
    },
    {
      "epoch": 2.1479779411764706,
      "grad_norm": 0.9038422107696533,
      "learning_rate": 6.3398692810457515e-06,
      "loss": 0.037,
      "step": 9348
    },
    {
      "epoch": 2.1482077205882355,
      "grad_norm": 1.0334575176239014,
      "learning_rate": 6.33935866013072e-06,
      "loss": 0.0428,
      "step": 9349
    },
    {
      "epoch": 2.1484375,
      "grad_norm": 0.8162694573402405,
      "learning_rate": 6.338848039215687e-06,
      "loss": 0.0434,
      "step": 9350
    },
    {
      "epoch": 2.1486672794117645,
      "grad_norm": 0.7789832949638367,
      "learning_rate": 6.338337418300654e-06,
      "loss": 0.0357,
      "step": 9351
    },
    {
      "epoch": 2.1488970588235294,
      "grad_norm": 1.1746917963027954,
      "learning_rate": 6.337826797385621e-06,
      "loss": 0.0506,
      "step": 9352
    },
    {
      "epoch": 2.149126838235294,
      "grad_norm": 1.0772278308868408,
      "learning_rate": 6.337316176470589e-06,
      "loss": 0.0387,
      "step": 9353
    },
    {
      "epoch": 2.149356617647059,
      "grad_norm": 0.8760025501251221,
      "learning_rate": 6.336805555555556e-06,
      "loss": 0.0389,
      "step": 9354
    },
    {
      "epoch": 2.1495863970588234,
      "grad_norm": 1.0498634576797485,
      "learning_rate": 6.336294934640523e-06,
      "loss": 0.0346,
      "step": 9355
    },
    {
      "epoch": 2.1498161764705883,
      "grad_norm": 0.8348380327224731,
      "learning_rate": 6.33578431372549e-06,
      "loss": 0.0244,
      "step": 9356
    },
    {
      "epoch": 2.150045955882353,
      "grad_norm": 1.0112181901931763,
      "learning_rate": 6.335273692810459e-06,
      "loss": 0.047,
      "step": 9357
    },
    {
      "epoch": 2.1502757352941178,
      "grad_norm": 1.1132527589797974,
      "learning_rate": 6.334763071895426e-06,
      "loss": 0.0525,
      "step": 9358
    },
    {
      "epoch": 2.1505055147058822,
      "grad_norm": 0.7876095175743103,
      "learning_rate": 6.334252450980393e-06,
      "loss": 0.0369,
      "step": 9359
    },
    {
      "epoch": 2.150735294117647,
      "grad_norm": 0.867216944694519,
      "learning_rate": 6.33374183006536e-06,
      "loss": 0.0461,
      "step": 9360
    },
    {
      "epoch": 2.1509650735294117,
      "grad_norm": 0.9181605577468872,
      "learning_rate": 6.333231209150328e-06,
      "loss": 0.0352,
      "step": 9361
    },
    {
      "epoch": 2.1511948529411766,
      "grad_norm": 0.7548788785934448,
      "learning_rate": 6.332720588235295e-06,
      "loss": 0.0347,
      "step": 9362
    },
    {
      "epoch": 2.151424632352941,
      "grad_norm": 0.9159125685691833,
      "learning_rate": 6.332209967320262e-06,
      "loss": 0.0408,
      "step": 9363
    },
    {
      "epoch": 2.151654411764706,
      "grad_norm": 0.995871365070343,
      "learning_rate": 6.331699346405229e-06,
      "loss": 0.044,
      "step": 9364
    },
    {
      "epoch": 2.1518841911764706,
      "grad_norm": 0.8798818588256836,
      "learning_rate": 6.331188725490197e-06,
      "loss": 0.0369,
      "step": 9365
    },
    {
      "epoch": 2.1521139705882355,
      "grad_norm": 0.7600051164627075,
      "learning_rate": 6.330678104575165e-06,
      "loss": 0.0278,
      "step": 9366
    },
    {
      "epoch": 2.15234375,
      "grad_norm": 0.7777922749519348,
      "learning_rate": 6.330167483660132e-06,
      "loss": 0.0364,
      "step": 9367
    },
    {
      "epoch": 2.1525735294117645,
      "grad_norm": 1.165756106376648,
      "learning_rate": 6.329656862745099e-06,
      "loss": 0.0436,
      "step": 9368
    },
    {
      "epoch": 2.1528033088235294,
      "grad_norm": 1.0400967597961426,
      "learning_rate": 6.3291462418300665e-06,
      "loss": 0.0521,
      "step": 9369
    },
    {
      "epoch": 2.153033088235294,
      "grad_norm": 0.9352298378944397,
      "learning_rate": 6.3286356209150335e-06,
      "loss": 0.0376,
      "step": 9370
    },
    {
      "epoch": 2.153262867647059,
      "grad_norm": 0.9576496481895447,
      "learning_rate": 6.3281250000000005e-06,
      "loss": 0.0408,
      "step": 9371
    },
    {
      "epoch": 2.1534926470588234,
      "grad_norm": 1.017988920211792,
      "learning_rate": 6.3276143790849675e-06,
      "loss": 0.0406,
      "step": 9372
    },
    {
      "epoch": 2.1537224264705883,
      "grad_norm": 0.8248981237411499,
      "learning_rate": 6.3271037581699345e-06,
      "loss": 0.0406,
      "step": 9373
    },
    {
      "epoch": 2.153952205882353,
      "grad_norm": 0.9383592009544373,
      "learning_rate": 6.326593137254902e-06,
      "loss": 0.0442,
      "step": 9374
    },
    {
      "epoch": 2.1541819852941178,
      "grad_norm": 1.1056749820709229,
      "learning_rate": 6.326082516339869e-06,
      "loss": 0.0393,
      "step": 9375
    },
    {
      "epoch": 2.1544117647058822,
      "grad_norm": 0.9340966939926147,
      "learning_rate": 6.325571895424837e-06,
      "loss": 0.0403,
      "step": 9376
    },
    {
      "epoch": 2.154641544117647,
      "grad_norm": 1.0485466718673706,
      "learning_rate": 6.325061274509804e-06,
      "loss": 0.0371,
      "step": 9377
    },
    {
      "epoch": 2.1548713235294117,
      "grad_norm": 1.2809932231903076,
      "learning_rate": 6.324550653594772e-06,
      "loss": 0.0554,
      "step": 9378
    },
    {
      "epoch": 2.1551011029411766,
      "grad_norm": 1.0419338941574097,
      "learning_rate": 6.324040032679739e-06,
      "loss": 0.0467,
      "step": 9379
    },
    {
      "epoch": 2.155330882352941,
      "grad_norm": 0.7479004859924316,
      "learning_rate": 6.323529411764706e-06,
      "loss": 0.0231,
      "step": 9380
    },
    {
      "epoch": 2.155560661764706,
      "grad_norm": 1.1042615175247192,
      "learning_rate": 6.323018790849673e-06,
      "loss": 0.0625,
      "step": 9381
    },
    {
      "epoch": 2.1557904411764706,
      "grad_norm": 0.9854820370674133,
      "learning_rate": 6.322508169934641e-06,
      "loss": 0.0419,
      "step": 9382
    },
    {
      "epoch": 2.1560202205882355,
      "grad_norm": 0.9907472133636475,
      "learning_rate": 6.321997549019608e-06,
      "loss": 0.065,
      "step": 9383
    },
    {
      "epoch": 2.15625,
      "grad_norm": 1.6651973724365234,
      "learning_rate": 6.321486928104575e-06,
      "loss": 0.0361,
      "step": 9384
    },
    {
      "epoch": 2.1564797794117645,
      "grad_norm": 1.226378083229065,
      "learning_rate": 6.320976307189542e-06,
      "loss": 0.0377,
      "step": 9385
    },
    {
      "epoch": 2.1567095588235294,
      "grad_norm": 0.8581680655479431,
      "learning_rate": 6.320465686274511e-06,
      "loss": 0.0503,
      "step": 9386
    },
    {
      "epoch": 2.156939338235294,
      "grad_norm": 0.8538499474525452,
      "learning_rate": 6.319955065359478e-06,
      "loss": 0.0335,
      "step": 9387
    },
    {
      "epoch": 2.157169117647059,
      "grad_norm": 0.9202275276184082,
      "learning_rate": 6.319444444444445e-06,
      "loss": 0.0537,
      "step": 9388
    },
    {
      "epoch": 2.1573988970588234,
      "grad_norm": 0.8416086435317993,
      "learning_rate": 6.318933823529412e-06,
      "loss": 0.0388,
      "step": 9389
    },
    {
      "epoch": 2.1576286764705883,
      "grad_norm": 0.9761165380477905,
      "learning_rate": 6.31842320261438e-06,
      "loss": 0.0322,
      "step": 9390
    },
    {
      "epoch": 2.157858455882353,
      "grad_norm": 0.6957783102989197,
      "learning_rate": 6.317912581699347e-06,
      "loss": 0.0255,
      "step": 9391
    },
    {
      "epoch": 2.1580882352941178,
      "grad_norm": 1.0705899000167847,
      "learning_rate": 6.317401960784314e-06,
      "loss": 0.0631,
      "step": 9392
    },
    {
      "epoch": 2.1583180147058822,
      "grad_norm": 0.5860141515731812,
      "learning_rate": 6.316891339869281e-06,
      "loss": 0.0195,
      "step": 9393
    },
    {
      "epoch": 2.158547794117647,
      "grad_norm": 0.9288212656974792,
      "learning_rate": 6.3163807189542495e-06,
      "loss": 0.0415,
      "step": 9394
    },
    {
      "epoch": 2.1587775735294117,
      "grad_norm": 1.2618333101272583,
      "learning_rate": 6.3158700980392165e-06,
      "loss": 0.0577,
      "step": 9395
    },
    {
      "epoch": 2.1590073529411766,
      "grad_norm": 0.8996695280075073,
      "learning_rate": 6.3153594771241835e-06,
      "loss": 0.0386,
      "step": 9396
    },
    {
      "epoch": 2.159237132352941,
      "grad_norm": 0.8889927268028259,
      "learning_rate": 6.3148488562091505e-06,
      "loss": 0.0482,
      "step": 9397
    },
    {
      "epoch": 2.159466911764706,
      "grad_norm": 1.0404242277145386,
      "learning_rate": 6.314338235294118e-06,
      "loss": 0.0419,
      "step": 9398
    },
    {
      "epoch": 2.1596966911764706,
      "grad_norm": 0.93405681848526,
      "learning_rate": 6.313827614379085e-06,
      "loss": 0.0466,
      "step": 9399
    },
    {
      "epoch": 2.1599264705882355,
      "grad_norm": 1.0250415802001953,
      "learning_rate": 6.313316993464052e-06,
      "loss": 0.0445,
      "step": 9400
    },
    {
      "epoch": 2.16015625,
      "grad_norm": 0.9595567584037781,
      "learning_rate": 6.312806372549019e-06,
      "loss": 0.0554,
      "step": 9401
    },
    {
      "epoch": 2.1603860294117645,
      "grad_norm": 1.0450148582458496,
      "learning_rate": 6.312295751633988e-06,
      "loss": 0.0445,
      "step": 9402
    },
    {
      "epoch": 2.1606158088235294,
      "grad_norm": 0.7118468880653381,
      "learning_rate": 6.311785130718955e-06,
      "loss": 0.0271,
      "step": 9403
    },
    {
      "epoch": 2.160845588235294,
      "grad_norm": 0.7640693783760071,
      "learning_rate": 6.311274509803922e-06,
      "loss": 0.0264,
      "step": 9404
    },
    {
      "epoch": 2.161075367647059,
      "grad_norm": 0.9771925806999207,
      "learning_rate": 6.310763888888889e-06,
      "loss": 0.0608,
      "step": 9405
    },
    {
      "epoch": 2.1613051470588234,
      "grad_norm": 1.0516300201416016,
      "learning_rate": 6.310253267973857e-06,
      "loss": 0.0449,
      "step": 9406
    },
    {
      "epoch": 2.1615349264705883,
      "grad_norm": 0.9015963077545166,
      "learning_rate": 6.309742647058824e-06,
      "loss": 0.0427,
      "step": 9407
    },
    {
      "epoch": 2.161764705882353,
      "grad_norm": 0.7224814891815186,
      "learning_rate": 6.309232026143791e-06,
      "loss": 0.0342,
      "step": 9408
    },
    {
      "epoch": 2.1619944852941178,
      "grad_norm": 0.8662388920783997,
      "learning_rate": 6.308721405228758e-06,
      "loss": 0.0384,
      "step": 9409
    },
    {
      "epoch": 2.1622242647058822,
      "grad_norm": 1.1601842641830444,
      "learning_rate": 6.308210784313727e-06,
      "loss": 0.04,
      "step": 9410
    },
    {
      "epoch": 2.162454044117647,
      "grad_norm": 1.089117407798767,
      "learning_rate": 6.307700163398694e-06,
      "loss": 0.0391,
      "step": 9411
    },
    {
      "epoch": 2.1626838235294117,
      "grad_norm": 0.8290266990661621,
      "learning_rate": 6.307189542483661e-06,
      "loss": 0.0277,
      "step": 9412
    },
    {
      "epoch": 2.1629136029411766,
      "grad_norm": 1.7170065641403198,
      "learning_rate": 6.306678921568628e-06,
      "loss": 0.0701,
      "step": 9413
    },
    {
      "epoch": 2.163143382352941,
      "grad_norm": 0.8019490838050842,
      "learning_rate": 6.306168300653596e-06,
      "loss": 0.0442,
      "step": 9414
    },
    {
      "epoch": 2.163373161764706,
      "grad_norm": 0.6545589566230774,
      "learning_rate": 6.305657679738563e-06,
      "loss": 0.0262,
      "step": 9415
    },
    {
      "epoch": 2.1636029411764706,
      "grad_norm": 0.9724511504173279,
      "learning_rate": 6.30514705882353e-06,
      "loss": 0.05,
      "step": 9416
    },
    {
      "epoch": 2.1638327205882355,
      "grad_norm": 1.072340726852417,
      "learning_rate": 6.304636437908497e-06,
      "loss": 0.0505,
      "step": 9417
    },
    {
      "epoch": 2.1640625,
      "grad_norm": 1.0575854778289795,
      "learning_rate": 6.304125816993465e-06,
      "loss": 0.0568,
      "step": 9418
    },
    {
      "epoch": 2.1642922794117645,
      "grad_norm": 0.8207283616065979,
      "learning_rate": 6.303615196078432e-06,
      "loss": 0.0406,
      "step": 9419
    },
    {
      "epoch": 2.1645220588235294,
      "grad_norm": 1.2766815423965454,
      "learning_rate": 6.303104575163399e-06,
      "loss": 0.0591,
      "step": 9420
    },
    {
      "epoch": 2.164751838235294,
      "grad_norm": 1.0623914003372192,
      "learning_rate": 6.3025939542483665e-06,
      "loss": 0.0448,
      "step": 9421
    },
    {
      "epoch": 2.164981617647059,
      "grad_norm": 1.011580228805542,
      "learning_rate": 6.302083333333334e-06,
      "loss": 0.0591,
      "step": 9422
    },
    {
      "epoch": 2.1652113970588234,
      "grad_norm": 0.9413585662841797,
      "learning_rate": 6.301572712418301e-06,
      "loss": 0.0408,
      "step": 9423
    },
    {
      "epoch": 2.1654411764705883,
      "grad_norm": 0.8657873868942261,
      "learning_rate": 6.301062091503268e-06,
      "loss": 0.0513,
      "step": 9424
    },
    {
      "epoch": 2.165670955882353,
      "grad_norm": 1.2723685503005981,
      "learning_rate": 6.300551470588235e-06,
      "loss": 0.0567,
      "step": 9425
    },
    {
      "epoch": 2.1659007352941178,
      "grad_norm": 1.0195286273956299,
      "learning_rate": 6.300040849673203e-06,
      "loss": 0.0433,
      "step": 9426
    },
    {
      "epoch": 2.1661305147058822,
      "grad_norm": 1.4178699254989624,
      "learning_rate": 6.29953022875817e-06,
      "loss": 0.0416,
      "step": 9427
    },
    {
      "epoch": 2.166360294117647,
      "grad_norm": 1.0221736431121826,
      "learning_rate": 6.299019607843137e-06,
      "loss": 0.0464,
      "step": 9428
    },
    {
      "epoch": 2.1665900735294117,
      "grad_norm": 0.8381363153457642,
      "learning_rate": 6.298508986928104e-06,
      "loss": 0.0406,
      "step": 9429
    },
    {
      "epoch": 2.1668198529411766,
      "grad_norm": 0.8564486503601074,
      "learning_rate": 6.297998366013073e-06,
      "loss": 0.0379,
      "step": 9430
    },
    {
      "epoch": 2.167049632352941,
      "grad_norm": 0.881507933139801,
      "learning_rate": 6.29748774509804e-06,
      "loss": 0.0463,
      "step": 9431
    },
    {
      "epoch": 2.167279411764706,
      "grad_norm": 0.7976569533348083,
      "learning_rate": 6.296977124183007e-06,
      "loss": 0.051,
      "step": 9432
    },
    {
      "epoch": 2.1675091911764706,
      "grad_norm": 0.9901324510574341,
      "learning_rate": 6.296466503267974e-06,
      "loss": 0.0646,
      "step": 9433
    },
    {
      "epoch": 2.1677389705882355,
      "grad_norm": 0.967860996723175,
      "learning_rate": 6.295955882352942e-06,
      "loss": 0.0352,
      "step": 9434
    },
    {
      "epoch": 2.16796875,
      "grad_norm": 1.2847042083740234,
      "learning_rate": 6.295445261437909e-06,
      "loss": 0.0522,
      "step": 9435
    },
    {
      "epoch": 2.1681985294117645,
      "grad_norm": 1.7163234949111938,
      "learning_rate": 6.294934640522876e-06,
      "loss": 0.0438,
      "step": 9436
    },
    {
      "epoch": 2.1684283088235294,
      "grad_norm": 0.8978908061981201,
      "learning_rate": 6.294424019607843e-06,
      "loss": 0.0334,
      "step": 9437
    },
    {
      "epoch": 2.168658088235294,
      "grad_norm": 0.9954729080200195,
      "learning_rate": 6.293913398692812e-06,
      "loss": 0.0572,
      "step": 9438
    },
    {
      "epoch": 2.168887867647059,
      "grad_norm": 0.9163489937782288,
      "learning_rate": 6.293402777777779e-06,
      "loss": 0.0401,
      "step": 9439
    },
    {
      "epoch": 2.1691176470588234,
      "grad_norm": 0.9637488126754761,
      "learning_rate": 6.292892156862746e-06,
      "loss": 0.0666,
      "step": 9440
    },
    {
      "epoch": 2.1693474264705883,
      "grad_norm": 0.9953434467315674,
      "learning_rate": 6.292381535947713e-06,
      "loss": 0.0462,
      "step": 9441
    },
    {
      "epoch": 2.169577205882353,
      "grad_norm": 1.2126320600509644,
      "learning_rate": 6.2918709150326806e-06,
      "loss": 0.0543,
      "step": 9442
    },
    {
      "epoch": 2.1698069852941178,
      "grad_norm": 0.8043320178985596,
      "learning_rate": 6.2913602941176476e-06,
      "loss": 0.0256,
      "step": 9443
    },
    {
      "epoch": 2.1700367647058822,
      "grad_norm": 0.8954272866249084,
      "learning_rate": 6.290849673202615e-06,
      "loss": 0.0523,
      "step": 9444
    },
    {
      "epoch": 2.170266544117647,
      "grad_norm": 1.1815993785858154,
      "learning_rate": 6.290339052287582e-06,
      "loss": 0.0653,
      "step": 9445
    },
    {
      "epoch": 2.1704963235294117,
      "grad_norm": 0.7796192765235901,
      "learning_rate": 6.28982843137255e-06,
      "loss": 0.0495,
      "step": 9446
    },
    {
      "epoch": 2.1707261029411766,
      "grad_norm": 0.8967583179473877,
      "learning_rate": 6.289317810457517e-06,
      "loss": 0.0358,
      "step": 9447
    },
    {
      "epoch": 2.170955882352941,
      "grad_norm": 0.9762439131736755,
      "learning_rate": 6.288807189542484e-06,
      "loss": 0.0411,
      "step": 9448
    },
    {
      "epoch": 2.171185661764706,
      "grad_norm": 0.8440394997596741,
      "learning_rate": 6.288296568627451e-06,
      "loss": 0.0283,
      "step": 9449
    },
    {
      "epoch": 2.1714154411764706,
      "grad_norm": 0.7981431484222412,
      "learning_rate": 6.287785947712419e-06,
      "loss": 0.0309,
      "step": 9450
    },
    {
      "epoch": 2.1716452205882355,
      "grad_norm": 0.9708822965621948,
      "learning_rate": 6.287275326797386e-06,
      "loss": 0.0416,
      "step": 9451
    },
    {
      "epoch": 2.171875,
      "grad_norm": 0.7581386566162109,
      "learning_rate": 6.286764705882353e-06,
      "loss": 0.0291,
      "step": 9452
    },
    {
      "epoch": 2.1721047794117645,
      "grad_norm": 1.1146024465560913,
      "learning_rate": 6.28625408496732e-06,
      "loss": 0.0317,
      "step": 9453
    },
    {
      "epoch": 2.1723345588235294,
      "grad_norm": 0.779876172542572,
      "learning_rate": 6.285743464052288e-06,
      "loss": 0.0271,
      "step": 9454
    },
    {
      "epoch": 2.172564338235294,
      "grad_norm": 0.835058867931366,
      "learning_rate": 6.285232843137256e-06,
      "loss": 0.0389,
      "step": 9455
    },
    {
      "epoch": 2.172794117647059,
      "grad_norm": 0.8923620581626892,
      "learning_rate": 6.284722222222223e-06,
      "loss": 0.0507,
      "step": 9456
    },
    {
      "epoch": 2.1730238970588234,
      "grad_norm": 1.4733734130859375,
      "learning_rate": 6.28421160130719e-06,
      "loss": 0.0578,
      "step": 9457
    },
    {
      "epoch": 2.1732536764705883,
      "grad_norm": 1.2368634939193726,
      "learning_rate": 6.283700980392158e-06,
      "loss": 0.0378,
      "step": 9458
    },
    {
      "epoch": 2.173483455882353,
      "grad_norm": 0.9548559784889221,
      "learning_rate": 6.283190359477125e-06,
      "loss": 0.0428,
      "step": 9459
    },
    {
      "epoch": 2.1737132352941178,
      "grad_norm": 0.8835404515266418,
      "learning_rate": 6.282679738562092e-06,
      "loss": 0.0366,
      "step": 9460
    },
    {
      "epoch": 2.1739430147058822,
      "grad_norm": 0.7995392680168152,
      "learning_rate": 6.282169117647059e-06,
      "loss": 0.0396,
      "step": 9461
    },
    {
      "epoch": 2.174172794117647,
      "grad_norm": 1.0548235177993774,
      "learning_rate": 6.281658496732027e-06,
      "loss": 0.0475,
      "step": 9462
    },
    {
      "epoch": 2.1744025735294117,
      "grad_norm": 1.0484992265701294,
      "learning_rate": 6.281147875816994e-06,
      "loss": 0.0455,
      "step": 9463
    },
    {
      "epoch": 2.1746323529411766,
      "grad_norm": 0.9532930254936218,
      "learning_rate": 6.280637254901961e-06,
      "loss": 0.0387,
      "step": 9464
    },
    {
      "epoch": 2.174862132352941,
      "grad_norm": 0.9153646230697632,
      "learning_rate": 6.280126633986928e-06,
      "loss": 0.0503,
      "step": 9465
    },
    {
      "epoch": 2.175091911764706,
      "grad_norm": 0.9071413278579712,
      "learning_rate": 6.2796160130718965e-06,
      "loss": 0.0301,
      "step": 9466
    },
    {
      "epoch": 2.1753216911764706,
      "grad_norm": 0.984957754611969,
      "learning_rate": 6.2791053921568635e-06,
      "loss": 0.0405,
      "step": 9467
    },
    {
      "epoch": 2.1755514705882355,
      "grad_norm": 1.1103882789611816,
      "learning_rate": 6.2785947712418306e-06,
      "loss": 0.0528,
      "step": 9468
    },
    {
      "epoch": 2.17578125,
      "grad_norm": 0.9017897248268127,
      "learning_rate": 6.2780841503267976e-06,
      "loss": 0.0565,
      "step": 9469
    },
    {
      "epoch": 2.1760110294117645,
      "grad_norm": 1.52760910987854,
      "learning_rate": 6.2775735294117654e-06,
      "loss": 0.0384,
      "step": 9470
    },
    {
      "epoch": 2.1762408088235294,
      "grad_norm": 0.8493847846984863,
      "learning_rate": 6.2770629084967324e-06,
      "loss": 0.0521,
      "step": 9471
    },
    {
      "epoch": 2.176470588235294,
      "grad_norm": 1.1669983863830566,
      "learning_rate": 6.2765522875816995e-06,
      "loss": 0.0602,
      "step": 9472
    },
    {
      "epoch": 2.176700367647059,
      "grad_norm": 0.9973747134208679,
      "learning_rate": 6.2760416666666665e-06,
      "loss": 0.0432,
      "step": 9473
    },
    {
      "epoch": 2.1769301470588234,
      "grad_norm": 0.9602133631706238,
      "learning_rate": 6.275531045751635e-06,
      "loss": 0.0435,
      "step": 9474
    },
    {
      "epoch": 2.1771599264705883,
      "grad_norm": 0.7116102576255798,
      "learning_rate": 6.275020424836602e-06,
      "loss": 0.0396,
      "step": 9475
    },
    {
      "epoch": 2.177389705882353,
      "grad_norm": 0.8310762643814087,
      "learning_rate": 6.274509803921569e-06,
      "loss": 0.0372,
      "step": 9476
    },
    {
      "epoch": 2.1776194852941178,
      "grad_norm": 0.8523465394973755,
      "learning_rate": 6.273999183006536e-06,
      "loss": 0.0283,
      "step": 9477
    },
    {
      "epoch": 2.1778492647058822,
      "grad_norm": 1.2577844858169556,
      "learning_rate": 6.273488562091504e-06,
      "loss": 0.0575,
      "step": 9478
    },
    {
      "epoch": 2.178079044117647,
      "grad_norm": 0.7759677767753601,
      "learning_rate": 6.272977941176471e-06,
      "loss": 0.0273,
      "step": 9479
    },
    {
      "epoch": 2.1783088235294117,
      "grad_norm": 1.3562757968902588,
      "learning_rate": 6.272467320261438e-06,
      "loss": 0.0744,
      "step": 9480
    },
    {
      "epoch": 2.1785386029411766,
      "grad_norm": 1.789638876914978,
      "learning_rate": 6.271956699346405e-06,
      "loss": 0.088,
      "step": 9481
    },
    {
      "epoch": 2.178768382352941,
      "grad_norm": 1.2452939748764038,
      "learning_rate": 6.271446078431374e-06,
      "loss": 0.0383,
      "step": 9482
    },
    {
      "epoch": 2.178998161764706,
      "grad_norm": 1.0589642524719238,
      "learning_rate": 6.270935457516341e-06,
      "loss": 0.0381,
      "step": 9483
    },
    {
      "epoch": 2.1792279411764706,
      "grad_norm": 0.6649261713027954,
      "learning_rate": 6.270424836601308e-06,
      "loss": 0.0222,
      "step": 9484
    },
    {
      "epoch": 2.1794577205882355,
      "grad_norm": 1.0416333675384521,
      "learning_rate": 6.269914215686275e-06,
      "loss": 0.035,
      "step": 9485
    },
    {
      "epoch": 2.1796875,
      "grad_norm": 0.8959128856658936,
      "learning_rate": 6.269403594771243e-06,
      "loss": 0.0405,
      "step": 9486
    },
    {
      "epoch": 2.1799172794117645,
      "grad_norm": 0.9285488128662109,
      "learning_rate": 6.26889297385621e-06,
      "loss": 0.0401,
      "step": 9487
    },
    {
      "epoch": 2.1801470588235294,
      "grad_norm": 1.0357903242111206,
      "learning_rate": 6.268382352941177e-06,
      "loss": 0.0617,
      "step": 9488
    },
    {
      "epoch": 2.180376838235294,
      "grad_norm": 1.4903820753097534,
      "learning_rate": 6.267871732026144e-06,
      "loss": 0.0626,
      "step": 9489
    },
    {
      "epoch": 2.180606617647059,
      "grad_norm": 1.108250379562378,
      "learning_rate": 6.2673611111111125e-06,
      "loss": 0.0517,
      "step": 9490
    },
    {
      "epoch": 2.1808363970588234,
      "grad_norm": 1.2237409353256226,
      "learning_rate": 6.2668504901960795e-06,
      "loss": 0.0614,
      "step": 9491
    },
    {
      "epoch": 2.1810661764705883,
      "grad_norm": 1.3489594459533691,
      "learning_rate": 6.2663398692810465e-06,
      "loss": 0.0529,
      "step": 9492
    },
    {
      "epoch": 2.181295955882353,
      "grad_norm": 0.9860715866088867,
      "learning_rate": 6.2658292483660135e-06,
      "loss": 0.0368,
      "step": 9493
    },
    {
      "epoch": 2.1815257352941178,
      "grad_norm": 1.0880662202835083,
      "learning_rate": 6.265318627450981e-06,
      "loss": 0.0549,
      "step": 9494
    },
    {
      "epoch": 2.1817555147058822,
      "grad_norm": 0.6855387687683105,
      "learning_rate": 6.264808006535948e-06,
      "loss": 0.0271,
      "step": 9495
    },
    {
      "epoch": 2.181985294117647,
      "grad_norm": 1.0085084438323975,
      "learning_rate": 6.2642973856209154e-06,
      "loss": 0.0488,
      "step": 9496
    },
    {
      "epoch": 2.1822150735294117,
      "grad_norm": 0.8824166059494019,
      "learning_rate": 6.2637867647058824e-06,
      "loss": 0.0372,
      "step": 9497
    },
    {
      "epoch": 2.1824448529411766,
      "grad_norm": 1.0054339170455933,
      "learning_rate": 6.26327614379085e-06,
      "loss": 0.0413,
      "step": 9498
    },
    {
      "epoch": 2.182674632352941,
      "grad_norm": 1.055158019065857,
      "learning_rate": 6.262765522875817e-06,
      "loss": 0.0367,
      "step": 9499
    },
    {
      "epoch": 2.182904411764706,
      "grad_norm": 0.9587196707725525,
      "learning_rate": 6.262254901960785e-06,
      "loss": 0.0488,
      "step": 9500
    },
    {
      "epoch": 2.182904411764706,
      "eval_loss": 0.04861943796277046,
      "eval_runtime": 2007.451,
      "eval_samples_per_second": 4.436,
      "eval_steps_per_second": 2.218,
      "step": 9500
    },
    {
      "epoch": 2.1831341911764706,
      "grad_norm": 1.0200531482696533,
      "learning_rate": 6.261744281045752e-06,
      "loss": 0.0466,
      "step": 9501
    },
    {
      "epoch": 2.1833639705882355,
      "grad_norm": 1.5541868209838867,
      "learning_rate": 6.26123366013072e-06,
      "loss": 0.0494,
      "step": 9502
    },
    {
      "epoch": 2.18359375,
      "grad_norm": 1.0686495304107666,
      "learning_rate": 6.260723039215687e-06,
      "loss": 0.054,
      "step": 9503
    },
    {
      "epoch": 2.1838235294117645,
      "grad_norm": 0.9289501309394836,
      "learning_rate": 6.260212418300654e-06,
      "loss": 0.0484,
      "step": 9504
    },
    {
      "epoch": 2.1840533088235294,
      "grad_norm": 1.1228567361831665,
      "learning_rate": 6.259701797385621e-06,
      "loss": 0.0622,
      "step": 9505
    },
    {
      "epoch": 2.184283088235294,
      "grad_norm": 0.9476848840713501,
      "learning_rate": 6.259191176470589e-06,
      "loss": 0.0421,
      "step": 9506
    },
    {
      "epoch": 2.184512867647059,
      "grad_norm": 0.9098403453826904,
      "learning_rate": 6.258680555555556e-06,
      "loss": 0.0504,
      "step": 9507
    },
    {
      "epoch": 2.1847426470588234,
      "grad_norm": 0.7183120846748352,
      "learning_rate": 6.258169934640523e-06,
      "loss": 0.0348,
      "step": 9508
    },
    {
      "epoch": 2.1849724264705883,
      "grad_norm": 0.8560936450958252,
      "learning_rate": 6.25765931372549e-06,
      "loss": 0.0409,
      "step": 9509
    },
    {
      "epoch": 2.185202205882353,
      "grad_norm": 0.7801960110664368,
      "learning_rate": 6.257148692810459e-06,
      "loss": 0.0328,
      "step": 9510
    },
    {
      "epoch": 2.1854319852941178,
      "grad_norm": 0.9147039651870728,
      "learning_rate": 6.256638071895426e-06,
      "loss": 0.043,
      "step": 9511
    },
    {
      "epoch": 2.1856617647058822,
      "grad_norm": 1.5494319200515747,
      "learning_rate": 6.256127450980393e-06,
      "loss": 0.0496,
      "step": 9512
    },
    {
      "epoch": 2.185891544117647,
      "grad_norm": 1.0109895467758179,
      "learning_rate": 6.25561683006536e-06,
      "loss": 0.0473,
      "step": 9513
    },
    {
      "epoch": 2.1861213235294117,
      "grad_norm": 0.7284311652183533,
      "learning_rate": 6.255106209150328e-06,
      "loss": 0.0275,
      "step": 9514
    },
    {
      "epoch": 2.1863511029411766,
      "grad_norm": 0.9228435158729553,
      "learning_rate": 6.254595588235295e-06,
      "loss": 0.0307,
      "step": 9515
    },
    {
      "epoch": 2.186580882352941,
      "grad_norm": 1.0354832410812378,
      "learning_rate": 6.254084967320262e-06,
      "loss": 0.0433,
      "step": 9516
    },
    {
      "epoch": 2.186810661764706,
      "grad_norm": 1.1332851648330688,
      "learning_rate": 6.253574346405229e-06,
      "loss": 0.0412,
      "step": 9517
    },
    {
      "epoch": 2.1870404411764706,
      "grad_norm": 0.9175974130630493,
      "learning_rate": 6.253063725490197e-06,
      "loss": 0.0363,
      "step": 9518
    },
    {
      "epoch": 2.1872702205882355,
      "grad_norm": 1.2549089193344116,
      "learning_rate": 6.252553104575164e-06,
      "loss": 0.049,
      "step": 9519
    },
    {
      "epoch": 2.1875,
      "grad_norm": 0.9476765394210815,
      "learning_rate": 6.252042483660131e-06,
      "loss": 0.0442,
      "step": 9520
    },
    {
      "epoch": 2.1877297794117645,
      "grad_norm": 0.8774320483207703,
      "learning_rate": 6.251531862745098e-06,
      "loss": 0.0373,
      "step": 9521
    },
    {
      "epoch": 2.1879595588235294,
      "grad_norm": 1.0904618501663208,
      "learning_rate": 6.251021241830066e-06,
      "loss": 0.0578,
      "step": 9522
    },
    {
      "epoch": 2.188189338235294,
      "grad_norm": 0.9639376401901245,
      "learning_rate": 6.250510620915033e-06,
      "loss": 0.038,
      "step": 9523
    },
    {
      "epoch": 2.188419117647059,
      "grad_norm": 1.222893238067627,
      "learning_rate": 6.25e-06,
      "loss": 0.0658,
      "step": 9524
    },
    {
      "epoch": 2.1886488970588234,
      "grad_norm": 0.8500701189041138,
      "learning_rate": 6.249489379084967e-06,
      "loss": 0.0486,
      "step": 9525
    },
    {
      "epoch": 2.1888786764705883,
      "grad_norm": 0.8895508646965027,
      "learning_rate": 6.248978758169934e-06,
      "loss": 0.0345,
      "step": 9526
    },
    {
      "epoch": 2.189108455882353,
      "grad_norm": 1.2396767139434814,
      "learning_rate": 6.248468137254903e-06,
      "loss": 0.0518,
      "step": 9527
    },
    {
      "epoch": 2.1893382352941178,
      "grad_norm": 1.3438313007354736,
      "learning_rate": 6.24795751633987e-06,
      "loss": 0.0484,
      "step": 9528
    },
    {
      "epoch": 2.1895680147058822,
      "grad_norm": 0.8713761568069458,
      "learning_rate": 6.247446895424837e-06,
      "loss": 0.0319,
      "step": 9529
    },
    {
      "epoch": 2.189797794117647,
      "grad_norm": 1.0145941972732544,
      "learning_rate": 6.246936274509804e-06,
      "loss": 0.0482,
      "step": 9530
    },
    {
      "epoch": 2.1900275735294117,
      "grad_norm": 1.1563215255737305,
      "learning_rate": 6.246425653594772e-06,
      "loss": 0.0495,
      "step": 9531
    },
    {
      "epoch": 2.1902573529411766,
      "grad_norm": 1.014803171157837,
      "learning_rate": 6.245915032679739e-06,
      "loss": 0.0444,
      "step": 9532
    },
    {
      "epoch": 2.190487132352941,
      "grad_norm": 1.1627929210662842,
      "learning_rate": 6.245404411764706e-06,
      "loss": 0.0448,
      "step": 9533
    },
    {
      "epoch": 2.190716911764706,
      "grad_norm": 1.1061526536941528,
      "learning_rate": 6.244893790849673e-06,
      "loss": 0.0664,
      "step": 9534
    },
    {
      "epoch": 2.1909466911764706,
      "grad_norm": 0.8152506351470947,
      "learning_rate": 6.244383169934642e-06,
      "loss": 0.0365,
      "step": 9535
    },
    {
      "epoch": 2.1911764705882355,
      "grad_norm": 1.1428914070129395,
      "learning_rate": 6.243872549019609e-06,
      "loss": 0.0765,
      "step": 9536
    },
    {
      "epoch": 2.19140625,
      "grad_norm": 1.5332070589065552,
      "learning_rate": 6.243361928104576e-06,
      "loss": 0.0321,
      "step": 9537
    },
    {
      "epoch": 2.1916360294117645,
      "grad_norm": 1.159927487373352,
      "learning_rate": 6.242851307189543e-06,
      "loss": 0.0517,
      "step": 9538
    },
    {
      "epoch": 2.1918658088235294,
      "grad_norm": 0.8677148818969727,
      "learning_rate": 6.242340686274511e-06,
      "loss": 0.0453,
      "step": 9539
    },
    {
      "epoch": 2.192095588235294,
      "grad_norm": 0.7915650010108948,
      "learning_rate": 6.241830065359478e-06,
      "loss": 0.0443,
      "step": 9540
    },
    {
      "epoch": 2.192325367647059,
      "grad_norm": 0.9749771952629089,
      "learning_rate": 6.241319444444445e-06,
      "loss": 0.0366,
      "step": 9541
    },
    {
      "epoch": 2.1925551470588234,
      "grad_norm": 0.953441321849823,
      "learning_rate": 6.240808823529412e-06,
      "loss": 0.0343,
      "step": 9542
    },
    {
      "epoch": 2.1927849264705883,
      "grad_norm": 0.7682289481163025,
      "learning_rate": 6.2402982026143795e-06,
      "loss": 0.0512,
      "step": 9543
    },
    {
      "epoch": 2.193014705882353,
      "grad_norm": 1.2615662813186646,
      "learning_rate": 6.239787581699347e-06,
      "loss": 0.0734,
      "step": 9544
    },
    {
      "epoch": 2.1932444852941178,
      "grad_norm": 0.9561361074447632,
      "learning_rate": 6.239276960784314e-06,
      "loss": 0.0398,
      "step": 9545
    },
    {
      "epoch": 2.1934742647058822,
      "grad_norm": 1.2306665182113647,
      "learning_rate": 6.238766339869281e-06,
      "loss": 0.0599,
      "step": 9546
    },
    {
      "epoch": 2.193704044117647,
      "grad_norm": 1.580114483833313,
      "learning_rate": 6.238255718954249e-06,
      "loss": 0.0851,
      "step": 9547
    },
    {
      "epoch": 2.1939338235294117,
      "grad_norm": 0.6447940468788147,
      "learning_rate": 6.237745098039216e-06,
      "loss": 0.0233,
      "step": 9548
    },
    {
      "epoch": 2.1941636029411766,
      "grad_norm": 0.8547647595405579,
      "learning_rate": 6.237234477124183e-06,
      "loss": 0.0339,
      "step": 9549
    },
    {
      "epoch": 2.194393382352941,
      "grad_norm": 0.6979166269302368,
      "learning_rate": 6.23672385620915e-06,
      "loss": 0.0335,
      "step": 9550
    },
    {
      "epoch": 2.194623161764706,
      "grad_norm": 1.2257195711135864,
      "learning_rate": 6.236213235294118e-06,
      "loss": 0.0573,
      "step": 9551
    },
    {
      "epoch": 2.1948529411764706,
      "grad_norm": 0.6722874641418457,
      "learning_rate": 6.235702614379085e-06,
      "loss": 0.0203,
      "step": 9552
    },
    {
      "epoch": 2.1950827205882355,
      "grad_norm": 1.1616685390472412,
      "learning_rate": 6.235191993464052e-06,
      "loss": 0.0473,
      "step": 9553
    },
    {
      "epoch": 2.1953125,
      "grad_norm": 1.0378094911575317,
      "learning_rate": 6.234681372549019e-06,
      "loss": 0.0476,
      "step": 9554
    },
    {
      "epoch": 2.1955422794117645,
      "grad_norm": 0.9805580973625183,
      "learning_rate": 6.234170751633988e-06,
      "loss": 0.0372,
      "step": 9555
    },
    {
      "epoch": 2.1957720588235294,
      "grad_norm": 0.8469287753105164,
      "learning_rate": 6.233660130718955e-06,
      "loss": 0.052,
      "step": 9556
    },
    {
      "epoch": 2.196001838235294,
      "grad_norm": 0.9376229047775269,
      "learning_rate": 6.233149509803922e-06,
      "loss": 0.0444,
      "step": 9557
    },
    {
      "epoch": 2.196231617647059,
      "grad_norm": 0.9836387038230896,
      "learning_rate": 6.232638888888889e-06,
      "loss": 0.0319,
      "step": 9558
    },
    {
      "epoch": 2.1964613970588234,
      "grad_norm": 0.7599915266036987,
      "learning_rate": 6.232128267973857e-06,
      "loss": 0.0346,
      "step": 9559
    },
    {
      "epoch": 2.1966911764705883,
      "grad_norm": 0.9534868001937866,
      "learning_rate": 6.231617647058824e-06,
      "loss": 0.0388,
      "step": 9560
    },
    {
      "epoch": 2.196920955882353,
      "grad_norm": 1.038444995880127,
      "learning_rate": 6.231107026143791e-06,
      "loss": 0.0436,
      "step": 9561
    },
    {
      "epoch": 2.1971507352941178,
      "grad_norm": 1.4467657804489136,
      "learning_rate": 6.230596405228758e-06,
      "loss": 0.0544,
      "step": 9562
    },
    {
      "epoch": 2.1973805147058822,
      "grad_norm": 0.9606364369392395,
      "learning_rate": 6.2300857843137266e-06,
      "loss": 0.0574,
      "step": 9563
    },
    {
      "epoch": 2.197610294117647,
      "grad_norm": 0.8198198080062866,
      "learning_rate": 6.229575163398694e-06,
      "loss": 0.034,
      "step": 9564
    },
    {
      "epoch": 2.1978400735294117,
      "grad_norm": 0.7240810394287109,
      "learning_rate": 6.229064542483661e-06,
      "loss": 0.0289,
      "step": 9565
    },
    {
      "epoch": 2.1980698529411766,
      "grad_norm": 0.9720390439033508,
      "learning_rate": 6.228553921568628e-06,
      "loss": 0.0359,
      "step": 9566
    },
    {
      "epoch": 2.198299632352941,
      "grad_norm": 1.4453624486923218,
      "learning_rate": 6.2280433006535955e-06,
      "loss": 0.0503,
      "step": 9567
    },
    {
      "epoch": 2.198529411764706,
      "grad_norm": 0.9804459810256958,
      "learning_rate": 6.2275326797385625e-06,
      "loss": 0.0489,
      "step": 9568
    },
    {
      "epoch": 2.1987591911764706,
      "grad_norm": 1.2251489162445068,
      "learning_rate": 6.2270220588235295e-06,
      "loss": 0.0588,
      "step": 9569
    },
    {
      "epoch": 2.1989889705882355,
      "grad_norm": 0.9415497779846191,
      "learning_rate": 6.2265114379084965e-06,
      "loss": 0.0414,
      "step": 9570
    },
    {
      "epoch": 2.19921875,
      "grad_norm": 1.054832935333252,
      "learning_rate": 6.226000816993465e-06,
      "loss": 0.0573,
      "step": 9571
    },
    {
      "epoch": 2.1994485294117645,
      "grad_norm": 0.7995659708976746,
      "learning_rate": 6.225490196078432e-06,
      "loss": 0.0319,
      "step": 9572
    },
    {
      "epoch": 2.1996783088235294,
      "grad_norm": 0.954647421836853,
      "learning_rate": 6.224979575163399e-06,
      "loss": 0.0724,
      "step": 9573
    },
    {
      "epoch": 2.199908088235294,
      "grad_norm": 1.940466284751892,
      "learning_rate": 6.224468954248366e-06,
      "loss": 0.0617,
      "step": 9574
    },
    {
      "epoch": 2.200137867647059,
      "grad_norm": 0.9914741516113281,
      "learning_rate": 6.223958333333334e-06,
      "loss": 0.0261,
      "step": 9575
    },
    {
      "epoch": 2.2003676470588234,
      "grad_norm": 0.7923296689987183,
      "learning_rate": 6.223447712418301e-06,
      "loss": 0.0399,
      "step": 9576
    },
    {
      "epoch": 2.2005974264705883,
      "grad_norm": 0.84194016456604,
      "learning_rate": 6.222937091503268e-06,
      "loss": 0.0403,
      "step": 9577
    },
    {
      "epoch": 2.200827205882353,
      "grad_norm": 1.2641693353652954,
      "learning_rate": 6.222426470588235e-06,
      "loss": 0.0573,
      "step": 9578
    },
    {
      "epoch": 2.2010569852941178,
      "grad_norm": 0.9884870648384094,
      "learning_rate": 6.221915849673204e-06,
      "loss": 0.0426,
      "step": 9579
    },
    {
      "epoch": 2.2012867647058822,
      "grad_norm": 1.0251548290252686,
      "learning_rate": 6.221405228758171e-06,
      "loss": 0.0408,
      "step": 9580
    },
    {
      "epoch": 2.201516544117647,
      "grad_norm": 0.8362317085266113,
      "learning_rate": 6.220894607843138e-06,
      "loss": 0.0305,
      "step": 9581
    },
    {
      "epoch": 2.2017463235294117,
      "grad_norm": 0.8722777962684631,
      "learning_rate": 6.220383986928105e-06,
      "loss": 0.0353,
      "step": 9582
    },
    {
      "epoch": 2.2019761029411766,
      "grad_norm": 0.7743385434150696,
      "learning_rate": 6.219873366013073e-06,
      "loss": 0.0277,
      "step": 9583
    },
    {
      "epoch": 2.202205882352941,
      "grad_norm": 1.0178059339523315,
      "learning_rate": 6.21936274509804e-06,
      "loss": 0.0617,
      "step": 9584
    },
    {
      "epoch": 2.202435661764706,
      "grad_norm": 0.8061972260475159,
      "learning_rate": 6.218852124183007e-06,
      "loss": 0.0403,
      "step": 9585
    },
    {
      "epoch": 2.2026654411764706,
      "grad_norm": 1.1313300132751465,
      "learning_rate": 6.218341503267974e-06,
      "loss": 0.0477,
      "step": 9586
    },
    {
      "epoch": 2.2028952205882355,
      "grad_norm": 1.0535342693328857,
      "learning_rate": 6.217830882352942e-06,
      "loss": 0.0337,
      "step": 9587
    },
    {
      "epoch": 2.203125,
      "grad_norm": 1.0357547998428345,
      "learning_rate": 6.217320261437909e-06,
      "loss": 0.0472,
      "step": 9588
    },
    {
      "epoch": 2.2033547794117645,
      "grad_norm": 1.1205068826675415,
      "learning_rate": 6.2168096405228766e-06,
      "loss": 0.0577,
      "step": 9589
    },
    {
      "epoch": 2.2035845588235294,
      "grad_norm": 0.9640048742294312,
      "learning_rate": 6.216299019607844e-06,
      "loss": 0.0419,
      "step": 9590
    },
    {
      "epoch": 2.203814338235294,
      "grad_norm": 0.8838944435119629,
      "learning_rate": 6.2157883986928114e-06,
      "loss": 0.0393,
      "step": 9591
    },
    {
      "epoch": 2.204044117647059,
      "grad_norm": 1.0682016611099243,
      "learning_rate": 6.2152777777777785e-06,
      "loss": 0.0561,
      "step": 9592
    },
    {
      "epoch": 2.2042738970588234,
      "grad_norm": 0.9248733520507812,
      "learning_rate": 6.2147671568627455e-06,
      "loss": 0.0332,
      "step": 9593
    },
    {
      "epoch": 2.2045036764705883,
      "grad_norm": 1.1671600341796875,
      "learning_rate": 6.2142565359477125e-06,
      "loss": 0.0635,
      "step": 9594
    },
    {
      "epoch": 2.204733455882353,
      "grad_norm": 0.6709797382354736,
      "learning_rate": 6.21374591503268e-06,
      "loss": 0.0252,
      "step": 9595
    },
    {
      "epoch": 2.2049632352941178,
      "grad_norm": 1.2630658149719238,
      "learning_rate": 6.213235294117647e-06,
      "loss": 0.0636,
      "step": 9596
    },
    {
      "epoch": 2.2051930147058822,
      "grad_norm": 0.8996130228042603,
      "learning_rate": 6.212724673202614e-06,
      "loss": 0.0473,
      "step": 9597
    },
    {
      "epoch": 2.205422794117647,
      "grad_norm": 0.8910464644432068,
      "learning_rate": 6.212214052287581e-06,
      "loss": 0.0346,
      "step": 9598
    },
    {
      "epoch": 2.2056525735294117,
      "grad_norm": 0.8779935240745544,
      "learning_rate": 6.21170343137255e-06,
      "loss": 0.047,
      "step": 9599
    },
    {
      "epoch": 2.2058823529411766,
      "grad_norm": 0.7581086754798889,
      "learning_rate": 6.211192810457517e-06,
      "loss": 0.0308,
      "step": 9600
    },
    {
      "epoch": 2.206112132352941,
      "grad_norm": 0.8101681470870972,
      "learning_rate": 6.210682189542484e-06,
      "loss": 0.0513,
      "step": 9601
    },
    {
      "epoch": 2.206341911764706,
      "grad_norm": 1.1387982368469238,
      "learning_rate": 6.210171568627451e-06,
      "loss": 0.0612,
      "step": 9602
    },
    {
      "epoch": 2.2065716911764706,
      "grad_norm": 0.7037436962127686,
      "learning_rate": 6.209660947712419e-06,
      "loss": 0.0379,
      "step": 9603
    },
    {
      "epoch": 2.2068014705882355,
      "grad_norm": 0.7516831755638123,
      "learning_rate": 6.209150326797386e-06,
      "loss": 0.0301,
      "step": 9604
    },
    {
      "epoch": 2.20703125,
      "grad_norm": 0.858363151550293,
      "learning_rate": 6.208639705882353e-06,
      "loss": 0.0337,
      "step": 9605
    },
    {
      "epoch": 2.2072610294117645,
      "grad_norm": 0.8600714206695557,
      "learning_rate": 6.20812908496732e-06,
      "loss": 0.0574,
      "step": 9606
    },
    {
      "epoch": 2.2074908088235294,
      "grad_norm": 0.784630298614502,
      "learning_rate": 6.207618464052289e-06,
      "loss": 0.0369,
      "step": 9607
    },
    {
      "epoch": 2.207720588235294,
      "grad_norm": 1.1035256385803223,
      "learning_rate": 6.207107843137256e-06,
      "loss": 0.0474,
      "step": 9608
    },
    {
      "epoch": 2.207950367647059,
      "grad_norm": 0.9264838099479675,
      "learning_rate": 6.206597222222223e-06,
      "loss": 0.0358,
      "step": 9609
    },
    {
      "epoch": 2.2081801470588234,
      "grad_norm": 1.0305757522583008,
      "learning_rate": 6.20608660130719e-06,
      "loss": 0.0634,
      "step": 9610
    },
    {
      "epoch": 2.2084099264705883,
      "grad_norm": 0.5436100363731384,
      "learning_rate": 6.205575980392158e-06,
      "loss": 0.0218,
      "step": 9611
    },
    {
      "epoch": 2.208639705882353,
      "grad_norm": 0.7588280439376831,
      "learning_rate": 6.205065359477125e-06,
      "loss": 0.0284,
      "step": 9612
    },
    {
      "epoch": 2.2088694852941178,
      "grad_norm": 0.9866109490394592,
      "learning_rate": 6.204554738562092e-06,
      "loss": 0.058,
      "step": 9613
    },
    {
      "epoch": 2.2090992647058822,
      "grad_norm": 1.6528319120407104,
      "learning_rate": 6.204044117647059e-06,
      "loss": 0.0601,
      "step": 9614
    },
    {
      "epoch": 2.209329044117647,
      "grad_norm": 1.0292717218399048,
      "learning_rate": 6.203533496732027e-06,
      "loss": 0.0453,
      "step": 9615
    },
    {
      "epoch": 2.2095588235294117,
      "grad_norm": 1.2741974592208862,
      "learning_rate": 6.2030228758169944e-06,
      "loss": 0.071,
      "step": 9616
    },
    {
      "epoch": 2.2097886029411766,
      "grad_norm": 1.5816106796264648,
      "learning_rate": 6.2025122549019614e-06,
      "loss": 0.0597,
      "step": 9617
    },
    {
      "epoch": 2.210018382352941,
      "grad_norm": 1.1818557977676392,
      "learning_rate": 6.2020016339869285e-06,
      "loss": 0.0578,
      "step": 9618
    },
    {
      "epoch": 2.210248161764706,
      "grad_norm": 1.3432608842849731,
      "learning_rate": 6.201491013071896e-06,
      "loss": 0.064,
      "step": 9619
    },
    {
      "epoch": 2.2104779411764706,
      "grad_norm": 1.3291120529174805,
      "learning_rate": 6.200980392156863e-06,
      "loss": 0.0632,
      "step": 9620
    },
    {
      "epoch": 2.2107077205882355,
      "grad_norm": 0.8535836338996887,
      "learning_rate": 6.20046977124183e-06,
      "loss": 0.0426,
      "step": 9621
    },
    {
      "epoch": 2.2109375,
      "grad_norm": 0.9316861033439636,
      "learning_rate": 6.199959150326797e-06,
      "loss": 0.0525,
      "step": 9622
    },
    {
      "epoch": 2.2111672794117645,
      "grad_norm": 1.0287734270095825,
      "learning_rate": 6.199448529411766e-06,
      "loss": 0.0404,
      "step": 9623
    },
    {
      "epoch": 2.2113970588235294,
      "grad_norm": 0.883551836013794,
      "learning_rate": 6.198937908496733e-06,
      "loss": 0.0456,
      "step": 9624
    },
    {
      "epoch": 2.211626838235294,
      "grad_norm": 1.0440127849578857,
      "learning_rate": 6.1984272875817e-06,
      "loss": 0.0657,
      "step": 9625
    },
    {
      "epoch": 2.211856617647059,
      "grad_norm": 1.1738287210464478,
      "learning_rate": 6.197916666666667e-06,
      "loss": 0.0474,
      "step": 9626
    },
    {
      "epoch": 2.2120863970588234,
      "grad_norm": 0.8376060128211975,
      "learning_rate": 6.197406045751635e-06,
      "loss": 0.0391,
      "step": 9627
    },
    {
      "epoch": 2.2123161764705883,
      "grad_norm": 1.1938823461532593,
      "learning_rate": 6.196895424836602e-06,
      "loss": 0.0524,
      "step": 9628
    },
    {
      "epoch": 2.212545955882353,
      "grad_norm": 0.8265119791030884,
      "learning_rate": 6.196384803921569e-06,
      "loss": 0.0429,
      "step": 9629
    },
    {
      "epoch": 2.2127757352941178,
      "grad_norm": 0.7953559756278992,
      "learning_rate": 6.195874183006536e-06,
      "loss": 0.0401,
      "step": 9630
    },
    {
      "epoch": 2.2130055147058822,
      "grad_norm": 0.6362169981002808,
      "learning_rate": 6.195363562091504e-06,
      "loss": 0.0221,
      "step": 9631
    },
    {
      "epoch": 2.213235294117647,
      "grad_norm": 0.8355147242546082,
      "learning_rate": 6.194852941176471e-06,
      "loss": 0.0324,
      "step": 9632
    },
    {
      "epoch": 2.2134650735294117,
      "grad_norm": 0.8189555406570435,
      "learning_rate": 6.194342320261439e-06,
      "loss": 0.0373,
      "step": 9633
    },
    {
      "epoch": 2.2136948529411766,
      "grad_norm": 0.893882155418396,
      "learning_rate": 6.193831699346406e-06,
      "loss": 0.0343,
      "step": 9634
    },
    {
      "epoch": 2.213924632352941,
      "grad_norm": 0.8600782155990601,
      "learning_rate": 6.193321078431374e-06,
      "loss": 0.0423,
      "step": 9635
    },
    {
      "epoch": 2.214154411764706,
      "grad_norm": 0.8844096660614014,
      "learning_rate": 6.192810457516341e-06,
      "loss": 0.0281,
      "step": 9636
    },
    {
      "epoch": 2.2143841911764706,
      "grad_norm": 0.7213785648345947,
      "learning_rate": 6.192299836601308e-06,
      "loss": 0.0286,
      "step": 9637
    },
    {
      "epoch": 2.2146139705882355,
      "grad_norm": 0.889022707939148,
      "learning_rate": 6.191789215686275e-06,
      "loss": 0.0237,
      "step": 9638
    },
    {
      "epoch": 2.21484375,
      "grad_norm": 0.9407047629356384,
      "learning_rate": 6.1912785947712425e-06,
      "loss": 0.04,
      "step": 9639
    },
    {
      "epoch": 2.2150735294117645,
      "grad_norm": 0.8193259835243225,
      "learning_rate": 6.1907679738562095e-06,
      "loss": 0.0426,
      "step": 9640
    },
    {
      "epoch": 2.2153033088235294,
      "grad_norm": 0.9112770557403564,
      "learning_rate": 6.1902573529411766e-06,
      "loss": 0.037,
      "step": 9641
    },
    {
      "epoch": 2.215533088235294,
      "grad_norm": 1.065050482749939,
      "learning_rate": 6.189746732026144e-06,
      "loss": 0.0566,
      "step": 9642
    },
    {
      "epoch": 2.215762867647059,
      "grad_norm": 0.9359935522079468,
      "learning_rate": 6.189236111111112e-06,
      "loss": 0.038,
      "step": 9643
    },
    {
      "epoch": 2.2159926470588234,
      "grad_norm": 1.246388554573059,
      "learning_rate": 6.188725490196079e-06,
      "loss": 0.0541,
      "step": 9644
    },
    {
      "epoch": 2.2162224264705883,
      "grad_norm": 0.9935768842697144,
      "learning_rate": 6.188214869281046e-06,
      "loss": 0.0464,
      "step": 9645
    },
    {
      "epoch": 2.216452205882353,
      "grad_norm": 0.7774204015731812,
      "learning_rate": 6.187704248366013e-06,
      "loss": 0.0336,
      "step": 9646
    },
    {
      "epoch": 2.2166819852941178,
      "grad_norm": 0.8351951241493225,
      "learning_rate": 6.187193627450981e-06,
      "loss": 0.0295,
      "step": 9647
    },
    {
      "epoch": 2.2169117647058822,
      "grad_norm": 0.9273262023925781,
      "learning_rate": 6.186683006535948e-06,
      "loss": 0.0627,
      "step": 9648
    },
    {
      "epoch": 2.217141544117647,
      "grad_norm": 1.1249903440475464,
      "learning_rate": 6.186172385620915e-06,
      "loss": 0.0487,
      "step": 9649
    },
    {
      "epoch": 2.2173713235294117,
      "grad_norm": 0.5805982947349548,
      "learning_rate": 6.185661764705882e-06,
      "loss": 0.0212,
      "step": 9650
    },
    {
      "epoch": 2.2176011029411766,
      "grad_norm": 1.2425512075424194,
      "learning_rate": 6.185151143790851e-06,
      "loss": 0.0611,
      "step": 9651
    },
    {
      "epoch": 2.217830882352941,
      "grad_norm": 1.1889574527740479,
      "learning_rate": 6.184640522875818e-06,
      "loss": 0.0434,
      "step": 9652
    },
    {
      "epoch": 2.218060661764706,
      "grad_norm": 0.9512483477592468,
      "learning_rate": 6.184129901960785e-06,
      "loss": 0.0463,
      "step": 9653
    },
    {
      "epoch": 2.2182904411764706,
      "grad_norm": 1.2516640424728394,
      "learning_rate": 6.183619281045752e-06,
      "loss": 0.0504,
      "step": 9654
    },
    {
      "epoch": 2.2185202205882355,
      "grad_norm": 0.9439584016799927,
      "learning_rate": 6.18310866013072e-06,
      "loss": 0.0501,
      "step": 9655
    },
    {
      "epoch": 2.21875,
      "grad_norm": 1.310210943222046,
      "learning_rate": 6.182598039215687e-06,
      "loss": 0.0977,
      "step": 9656
    },
    {
      "epoch": 2.2189797794117645,
      "grad_norm": 1.037279725074768,
      "learning_rate": 6.182087418300654e-06,
      "loss": 0.0397,
      "step": 9657
    },
    {
      "epoch": 2.2192095588235294,
      "grad_norm": 0.86272132396698,
      "learning_rate": 6.181576797385621e-06,
      "loss": 0.0329,
      "step": 9658
    },
    {
      "epoch": 2.219439338235294,
      "grad_norm": 1.0130224227905273,
      "learning_rate": 6.18106617647059e-06,
      "loss": 0.0533,
      "step": 9659
    },
    {
      "epoch": 2.219669117647059,
      "grad_norm": 0.9057993292808533,
      "learning_rate": 6.180555555555557e-06,
      "loss": 0.0442,
      "step": 9660
    },
    {
      "epoch": 2.2198988970588234,
      "grad_norm": 0.8547912240028381,
      "learning_rate": 6.180044934640524e-06,
      "loss": 0.0327,
      "step": 9661
    },
    {
      "epoch": 2.2201286764705883,
      "grad_norm": 0.7570469379425049,
      "learning_rate": 6.179534313725491e-06,
      "loss": 0.0417,
      "step": 9662
    },
    {
      "epoch": 2.220358455882353,
      "grad_norm": 0.922737181186676,
      "learning_rate": 6.1790236928104585e-06,
      "loss": 0.0464,
      "step": 9663
    },
    {
      "epoch": 2.2205882352941178,
      "grad_norm": 0.9327330589294434,
      "learning_rate": 6.1785130718954255e-06,
      "loss": 0.0642,
      "step": 9664
    },
    {
      "epoch": 2.2208180147058822,
      "grad_norm": 0.8337530493736267,
      "learning_rate": 6.1780024509803925e-06,
      "loss": 0.0349,
      "step": 9665
    },
    {
      "epoch": 2.221047794117647,
      "grad_norm": 0.6506696939468384,
      "learning_rate": 6.1774918300653595e-06,
      "loss": 0.0257,
      "step": 9666
    },
    {
      "epoch": 2.2212775735294117,
      "grad_norm": 1.1179687976837158,
      "learning_rate": 6.176981209150328e-06,
      "loss": 0.0434,
      "step": 9667
    },
    {
      "epoch": 2.2215073529411766,
      "grad_norm": 1.3198455572128296,
      "learning_rate": 6.176470588235295e-06,
      "loss": 0.0674,
      "step": 9668
    },
    {
      "epoch": 2.221737132352941,
      "grad_norm": 1.053572654724121,
      "learning_rate": 6.175959967320262e-06,
      "loss": 0.0376,
      "step": 9669
    },
    {
      "epoch": 2.221966911764706,
      "grad_norm": 1.0152370929718018,
      "learning_rate": 6.175449346405229e-06,
      "loss": 0.042,
      "step": 9670
    },
    {
      "epoch": 2.2221966911764706,
      "grad_norm": 0.7069824934005737,
      "learning_rate": 6.174938725490197e-06,
      "loss": 0.0294,
      "step": 9671
    },
    {
      "epoch": 2.2224264705882355,
      "grad_norm": 1.117833137512207,
      "learning_rate": 6.174428104575164e-06,
      "loss": 0.0445,
      "step": 9672
    },
    {
      "epoch": 2.22265625,
      "grad_norm": 1.0056357383728027,
      "learning_rate": 6.173917483660131e-06,
      "loss": 0.0475,
      "step": 9673
    },
    {
      "epoch": 2.2228860294117645,
      "grad_norm": 0.8538693189620972,
      "learning_rate": 6.173406862745098e-06,
      "loss": 0.037,
      "step": 9674
    },
    {
      "epoch": 2.2231158088235294,
      "grad_norm": 1.1994233131408691,
      "learning_rate": 6.172896241830066e-06,
      "loss": 0.0432,
      "step": 9675
    },
    {
      "epoch": 2.223345588235294,
      "grad_norm": 0.7797922492027283,
      "learning_rate": 6.172385620915033e-06,
      "loss": 0.0379,
      "step": 9676
    },
    {
      "epoch": 2.223575367647059,
      "grad_norm": 1.2097097635269165,
      "learning_rate": 6.171875e-06,
      "loss": 0.063,
      "step": 9677
    },
    {
      "epoch": 2.2238051470588234,
      "grad_norm": 0.9275410771369934,
      "learning_rate": 6.171364379084968e-06,
      "loss": 0.0336,
      "step": 9678
    },
    {
      "epoch": 2.2240349264705883,
      "grad_norm": 0.8561196327209473,
      "learning_rate": 6.170853758169935e-06,
      "loss": 0.0424,
      "step": 9679
    },
    {
      "epoch": 2.224264705882353,
      "grad_norm": 0.9487177729606628,
      "learning_rate": 6.170343137254903e-06,
      "loss": 0.032,
      "step": 9680
    },
    {
      "epoch": 2.2244944852941178,
      "grad_norm": 1.006605863571167,
      "learning_rate": 6.16983251633987e-06,
      "loss": 0.0541,
      "step": 9681
    },
    {
      "epoch": 2.2247242647058822,
      "grad_norm": 1.0452003479003906,
      "learning_rate": 6.169321895424837e-06,
      "loss": 0.0569,
      "step": 9682
    },
    {
      "epoch": 2.224954044117647,
      "grad_norm": 1.137614369392395,
      "learning_rate": 6.168811274509804e-06,
      "loss": 0.0542,
      "step": 9683
    },
    {
      "epoch": 2.2251838235294117,
      "grad_norm": 0.6588019728660583,
      "learning_rate": 6.168300653594772e-06,
      "loss": 0.0239,
      "step": 9684
    },
    {
      "epoch": 2.2254136029411766,
      "grad_norm": 1.395139455795288,
      "learning_rate": 6.167790032679739e-06,
      "loss": 0.0499,
      "step": 9685
    },
    {
      "epoch": 2.225643382352941,
      "grad_norm": 0.8825164437294006,
      "learning_rate": 6.167279411764706e-06,
      "loss": 0.0399,
      "step": 9686
    },
    {
      "epoch": 2.225873161764706,
      "grad_norm": 1.0246245861053467,
      "learning_rate": 6.166768790849673e-06,
      "loss": 0.0443,
      "step": 9687
    },
    {
      "epoch": 2.2261029411764706,
      "grad_norm": 0.8306083083152771,
      "learning_rate": 6.1662581699346415e-06,
      "loss": 0.0382,
      "step": 9688
    },
    {
      "epoch": 2.2263327205882355,
      "grad_norm": 1.0585861206054688,
      "learning_rate": 6.1657475490196085e-06,
      "loss": 0.0357,
      "step": 9689
    },
    {
      "epoch": 2.2265625,
      "grad_norm": 0.6419892311096191,
      "learning_rate": 6.1652369281045755e-06,
      "loss": 0.0321,
      "step": 9690
    },
    {
      "epoch": 2.2267922794117645,
      "grad_norm": 1.1595354080200195,
      "learning_rate": 6.1647263071895425e-06,
      "loss": 0.0335,
      "step": 9691
    },
    {
      "epoch": 2.2270220588235294,
      "grad_norm": 1.1412551403045654,
      "learning_rate": 6.16421568627451e-06,
      "loss": 0.0705,
      "step": 9692
    },
    {
      "epoch": 2.227251838235294,
      "grad_norm": 1.0611151456832886,
      "learning_rate": 6.163705065359477e-06,
      "loss": 0.0386,
      "step": 9693
    },
    {
      "epoch": 2.227481617647059,
      "grad_norm": 0.8842126131057739,
      "learning_rate": 6.163194444444444e-06,
      "loss": 0.0294,
      "step": 9694
    },
    {
      "epoch": 2.2277113970588234,
      "grad_norm": 0.9720683693885803,
      "learning_rate": 6.1626838235294114e-06,
      "loss": 0.0397,
      "step": 9695
    },
    {
      "epoch": 2.2279411764705883,
      "grad_norm": 0.9135491251945496,
      "learning_rate": 6.16217320261438e-06,
      "loss": 0.0316,
      "step": 9696
    },
    {
      "epoch": 2.228170955882353,
      "grad_norm": 0.8268120884895325,
      "learning_rate": 6.161662581699347e-06,
      "loss": 0.0262,
      "step": 9697
    },
    {
      "epoch": 2.2284007352941178,
      "grad_norm": 0.7367501258850098,
      "learning_rate": 6.161151960784314e-06,
      "loss": 0.0317,
      "step": 9698
    },
    {
      "epoch": 2.2286305147058822,
      "grad_norm": 0.9208243489265442,
      "learning_rate": 6.160641339869281e-06,
      "loss": 0.0372,
      "step": 9699
    },
    {
      "epoch": 2.228860294117647,
      "grad_norm": 0.7406697869300842,
      "learning_rate": 6.160130718954249e-06,
      "loss": 0.0336,
      "step": 9700
    },
    {
      "epoch": 2.2290900735294117,
      "grad_norm": 0.8468742966651917,
      "learning_rate": 6.159620098039216e-06,
      "loss": 0.0375,
      "step": 9701
    },
    {
      "epoch": 2.2293198529411766,
      "grad_norm": 1.0816032886505127,
      "learning_rate": 6.159109477124183e-06,
      "loss": 0.0449,
      "step": 9702
    },
    {
      "epoch": 2.229549632352941,
      "grad_norm": 0.7099042534828186,
      "learning_rate": 6.15859885620915e-06,
      "loss": 0.0185,
      "step": 9703
    },
    {
      "epoch": 2.229779411764706,
      "grad_norm": 0.9223952293395996,
      "learning_rate": 6.158088235294119e-06,
      "loss": 0.0378,
      "step": 9704
    },
    {
      "epoch": 2.2300091911764706,
      "grad_norm": 0.9570901393890381,
      "learning_rate": 6.157577614379086e-06,
      "loss": 0.0448,
      "step": 9705
    },
    {
      "epoch": 2.2302389705882355,
      "grad_norm": 0.7382621169090271,
      "learning_rate": 6.157066993464053e-06,
      "loss": 0.022,
      "step": 9706
    },
    {
      "epoch": 2.23046875,
      "grad_norm": 1.2242858409881592,
      "learning_rate": 6.15655637254902e-06,
      "loss": 0.0465,
      "step": 9707
    },
    {
      "epoch": 2.2306985294117645,
      "grad_norm": 1.05049729347229,
      "learning_rate": 6.156045751633988e-06,
      "loss": 0.0611,
      "step": 9708
    },
    {
      "epoch": 2.2309283088235294,
      "grad_norm": 1.2960937023162842,
      "learning_rate": 6.155535130718955e-06,
      "loss": 0.0608,
      "step": 9709
    },
    {
      "epoch": 2.231158088235294,
      "grad_norm": 1.0166654586791992,
      "learning_rate": 6.155024509803922e-06,
      "loss": 0.0516,
      "step": 9710
    },
    {
      "epoch": 2.231387867647059,
      "grad_norm": 0.9000418782234192,
      "learning_rate": 6.154513888888889e-06,
      "loss": 0.0334,
      "step": 9711
    },
    {
      "epoch": 2.2316176470588234,
      "grad_norm": 1.0108251571655273,
      "learning_rate": 6.1540032679738575e-06,
      "loss": 0.0393,
      "step": 9712
    },
    {
      "epoch": 2.2318474264705883,
      "grad_norm": 1.3553194999694824,
      "learning_rate": 6.1534926470588245e-06,
      "loss": 0.0556,
      "step": 9713
    },
    {
      "epoch": 2.232077205882353,
      "grad_norm": 1.190778136253357,
      "learning_rate": 6.1529820261437915e-06,
      "loss": 0.0595,
      "step": 9714
    },
    {
      "epoch": 2.2323069852941178,
      "grad_norm": 0.9465286135673523,
      "learning_rate": 6.1524714052287585e-06,
      "loss": 0.0528,
      "step": 9715
    },
    {
      "epoch": 2.2325367647058822,
      "grad_norm": 1.0956156253814697,
      "learning_rate": 6.151960784313726e-06,
      "loss": 0.04,
      "step": 9716
    },
    {
      "epoch": 2.232766544117647,
      "grad_norm": 0.7544846534729004,
      "learning_rate": 6.151450163398693e-06,
      "loss": 0.0328,
      "step": 9717
    },
    {
      "epoch": 2.2329963235294117,
      "grad_norm": 0.7797253727912903,
      "learning_rate": 6.15093954248366e-06,
      "loss": 0.0362,
      "step": 9718
    },
    {
      "epoch": 2.2332261029411766,
      "grad_norm": 1.5595736503601074,
      "learning_rate": 6.150428921568627e-06,
      "loss": 0.0514,
      "step": 9719
    },
    {
      "epoch": 2.233455882352941,
      "grad_norm": 1.0572201013565063,
      "learning_rate": 6.149918300653595e-06,
      "loss": 0.0344,
      "step": 9720
    },
    {
      "epoch": 2.233685661764706,
      "grad_norm": 1.2604358196258545,
      "learning_rate": 6.149407679738562e-06,
      "loss": 0.056,
      "step": 9721
    },
    {
      "epoch": 2.2339154411764706,
      "grad_norm": 0.9133571982383728,
      "learning_rate": 6.148897058823529e-06,
      "loss": 0.0542,
      "step": 9722
    },
    {
      "epoch": 2.2341452205882355,
      "grad_norm": 0.7768994569778442,
      "learning_rate": 6.148386437908497e-06,
      "loss": 0.0331,
      "step": 9723
    },
    {
      "epoch": 2.234375,
      "grad_norm": 0.8318465352058411,
      "learning_rate": 6.147875816993465e-06,
      "loss": 0.0345,
      "step": 9724
    },
    {
      "epoch": 2.2346047794117645,
      "grad_norm": 1.2385133504867554,
      "learning_rate": 6.147365196078432e-06,
      "loss": 0.0725,
      "step": 9725
    },
    {
      "epoch": 2.2348345588235294,
      "grad_norm": 0.8721937537193298,
      "learning_rate": 6.146854575163399e-06,
      "loss": 0.0432,
      "step": 9726
    },
    {
      "epoch": 2.235064338235294,
      "grad_norm": 0.7065802812576294,
      "learning_rate": 6.146343954248366e-06,
      "loss": 0.0296,
      "step": 9727
    },
    {
      "epoch": 2.235294117647059,
      "grad_norm": 1.0546460151672363,
      "learning_rate": 6.145833333333334e-06,
      "loss": 0.0424,
      "step": 9728
    },
    {
      "epoch": 2.2355238970588234,
      "grad_norm": 1.1908578872680664,
      "learning_rate": 6.145322712418301e-06,
      "loss": 0.035,
      "step": 9729
    },
    {
      "epoch": 2.2357536764705883,
      "grad_norm": 0.9216916561126709,
      "learning_rate": 6.144812091503268e-06,
      "loss": 0.0398,
      "step": 9730
    },
    {
      "epoch": 2.235983455882353,
      "grad_norm": 0.8724206686019897,
      "learning_rate": 6.144301470588235e-06,
      "loss": 0.0341,
      "step": 9731
    },
    {
      "epoch": 2.2362132352941178,
      "grad_norm": 0.7681811451911926,
      "learning_rate": 6.143790849673204e-06,
      "loss": 0.0391,
      "step": 9732
    },
    {
      "epoch": 2.2364430147058822,
      "grad_norm": 1.1332780122756958,
      "learning_rate": 6.143280228758171e-06,
      "loss": 0.0616,
      "step": 9733
    },
    {
      "epoch": 2.236672794117647,
      "grad_norm": 0.9631223082542419,
      "learning_rate": 6.142769607843138e-06,
      "loss": 0.0351,
      "step": 9734
    },
    {
      "epoch": 2.2369025735294117,
      "grad_norm": 0.7911209464073181,
      "learning_rate": 6.142258986928105e-06,
      "loss": 0.0396,
      "step": 9735
    },
    {
      "epoch": 2.2371323529411766,
      "grad_norm": 1.2886793613433838,
      "learning_rate": 6.141748366013073e-06,
      "loss": 0.038,
      "step": 9736
    },
    {
      "epoch": 2.237362132352941,
      "grad_norm": 0.8716010451316833,
      "learning_rate": 6.14123774509804e-06,
      "loss": 0.0357,
      "step": 9737
    },
    {
      "epoch": 2.237591911764706,
      "grad_norm": 0.6935632824897766,
      "learning_rate": 6.140727124183007e-06,
      "loss": 0.0448,
      "step": 9738
    },
    {
      "epoch": 2.2378216911764706,
      "grad_norm": 1.0145219564437866,
      "learning_rate": 6.140216503267974e-06,
      "loss": 0.0476,
      "step": 9739
    },
    {
      "epoch": 2.2380514705882355,
      "grad_norm": 0.9512439966201782,
      "learning_rate": 6.139705882352942e-06,
      "loss": 0.0571,
      "step": 9740
    },
    {
      "epoch": 2.23828125,
      "grad_norm": 0.909008264541626,
      "learning_rate": 6.139195261437909e-06,
      "loss": 0.0439,
      "step": 9741
    },
    {
      "epoch": 2.2385110294117645,
      "grad_norm": 1.3297847509384155,
      "learning_rate": 6.138684640522876e-06,
      "loss": 0.0663,
      "step": 9742
    },
    {
      "epoch": 2.2387408088235294,
      "grad_norm": 0.8418481349945068,
      "learning_rate": 6.138174019607843e-06,
      "loss": 0.0455,
      "step": 9743
    },
    {
      "epoch": 2.238970588235294,
      "grad_norm": 1.0411056280136108,
      "learning_rate": 6.137663398692811e-06,
      "loss": 0.0513,
      "step": 9744
    },
    {
      "epoch": 2.239200367647059,
      "grad_norm": 1.1473238468170166,
      "learning_rate": 6.137152777777778e-06,
      "loss": 0.0589,
      "step": 9745
    },
    {
      "epoch": 2.2394301470588234,
      "grad_norm": 1.8214579820632935,
      "learning_rate": 6.136642156862745e-06,
      "loss": 0.1043,
      "step": 9746
    },
    {
      "epoch": 2.2396599264705883,
      "grad_norm": 1.4536194801330566,
      "learning_rate": 6.136131535947712e-06,
      "loss": 0.0709,
      "step": 9747
    },
    {
      "epoch": 2.239889705882353,
      "grad_norm": 0.8176718950271606,
      "learning_rate": 6.135620915032681e-06,
      "loss": 0.0394,
      "step": 9748
    },
    {
      "epoch": 2.2401194852941178,
      "grad_norm": 0.7476691007614136,
      "learning_rate": 6.135110294117648e-06,
      "loss": 0.0227,
      "step": 9749
    },
    {
      "epoch": 2.2403492647058822,
      "grad_norm": 1.0941636562347412,
      "learning_rate": 6.134599673202615e-06,
      "loss": 0.0345,
      "step": 9750
    },
    {
      "epoch": 2.240579044117647,
      "grad_norm": 1.1891692876815796,
      "learning_rate": 6.134089052287582e-06,
      "loss": 0.0618,
      "step": 9751
    },
    {
      "epoch": 2.2408088235294117,
      "grad_norm": 1.0805021524429321,
      "learning_rate": 6.13357843137255e-06,
      "loss": 0.0357,
      "step": 9752
    },
    {
      "epoch": 2.2410386029411766,
      "grad_norm": 0.7210514545440674,
      "learning_rate": 6.133067810457517e-06,
      "loss": 0.0364,
      "step": 9753
    },
    {
      "epoch": 2.241268382352941,
      "grad_norm": 0.9980308413505554,
      "learning_rate": 6.132557189542484e-06,
      "loss": 0.0602,
      "step": 9754
    },
    {
      "epoch": 2.241498161764706,
      "grad_norm": 0.8240028023719788,
      "learning_rate": 6.132046568627451e-06,
      "loss": 0.0413,
      "step": 9755
    },
    {
      "epoch": 2.2417279411764706,
      "grad_norm": 1.0210427045822144,
      "learning_rate": 6.13153594771242e-06,
      "loss": 0.0531,
      "step": 9756
    },
    {
      "epoch": 2.2419577205882355,
      "grad_norm": 0.9122871160507202,
      "learning_rate": 6.131025326797387e-06,
      "loss": 0.0364,
      "step": 9757
    },
    {
      "epoch": 2.2421875,
      "grad_norm": 0.9342690706253052,
      "learning_rate": 6.130514705882354e-06,
      "loss": 0.0352,
      "step": 9758
    },
    {
      "epoch": 2.2424172794117645,
      "grad_norm": 1.5816733837127686,
      "learning_rate": 6.130004084967321e-06,
      "loss": 0.081,
      "step": 9759
    },
    {
      "epoch": 2.2426470588235294,
      "grad_norm": 1.0705145597457886,
      "learning_rate": 6.1294934640522886e-06,
      "loss": 0.0593,
      "step": 9760
    },
    {
      "epoch": 2.242876838235294,
      "grad_norm": 1.2214398384094238,
      "learning_rate": 6.1289828431372556e-06,
      "loss": 0.0571,
      "step": 9761
    },
    {
      "epoch": 2.243106617647059,
      "grad_norm": 0.9649247527122498,
      "learning_rate": 6.128472222222223e-06,
      "loss": 0.0511,
      "step": 9762
    },
    {
      "epoch": 2.2433363970588234,
      "grad_norm": 1.4358768463134766,
      "learning_rate": 6.12796160130719e-06,
      "loss": 0.0524,
      "step": 9763
    },
    {
      "epoch": 2.2435661764705883,
      "grad_norm": 1.0338776111602783,
      "learning_rate": 6.1274509803921575e-06,
      "loss": 0.0342,
      "step": 9764
    },
    {
      "epoch": 2.243795955882353,
      "grad_norm": 0.9304589629173279,
      "learning_rate": 6.1269403594771245e-06,
      "loss": 0.0335,
      "step": 9765
    },
    {
      "epoch": 2.2440257352941178,
      "grad_norm": 1.3615831136703491,
      "learning_rate": 6.1264297385620915e-06,
      "loss": 0.0674,
      "step": 9766
    },
    {
      "epoch": 2.2442555147058822,
      "grad_norm": 0.9602875709533691,
      "learning_rate": 6.125919117647059e-06,
      "loss": 0.0408,
      "step": 9767
    },
    {
      "epoch": 2.244485294117647,
      "grad_norm": 1.050312876701355,
      "learning_rate": 6.125408496732027e-06,
      "loss": 0.0426,
      "step": 9768
    },
    {
      "epoch": 2.2447150735294117,
      "grad_norm": 0.9856294989585876,
      "learning_rate": 6.124897875816994e-06,
      "loss": 0.0387,
      "step": 9769
    },
    {
      "epoch": 2.2449448529411766,
      "grad_norm": 0.9907997846603394,
      "learning_rate": 6.124387254901961e-06,
      "loss": 0.0496,
      "step": 9770
    },
    {
      "epoch": 2.245174632352941,
      "grad_norm": 1.10677969455719,
      "learning_rate": 6.123876633986928e-06,
      "loss": 0.0403,
      "step": 9771
    },
    {
      "epoch": 2.245404411764706,
      "grad_norm": 0.6923786997795105,
      "learning_rate": 6.123366013071896e-06,
      "loss": 0.0327,
      "step": 9772
    },
    {
      "epoch": 2.2456341911764706,
      "grad_norm": 1.318077802658081,
      "learning_rate": 6.122855392156863e-06,
      "loss": 0.0543,
      "step": 9773
    },
    {
      "epoch": 2.2458639705882355,
      "grad_norm": 0.8265380263328552,
      "learning_rate": 6.12234477124183e-06,
      "loss": 0.0464,
      "step": 9774
    },
    {
      "epoch": 2.24609375,
      "grad_norm": 1.0175418853759766,
      "learning_rate": 6.121834150326797e-06,
      "loss": 0.0469,
      "step": 9775
    },
    {
      "epoch": 2.2463235294117645,
      "grad_norm": 0.9977567195892334,
      "learning_rate": 6.121323529411766e-06,
      "loss": 0.0418,
      "step": 9776
    },
    {
      "epoch": 2.2465533088235294,
      "grad_norm": 1.3669118881225586,
      "learning_rate": 6.120812908496733e-06,
      "loss": 0.0582,
      "step": 9777
    },
    {
      "epoch": 2.246783088235294,
      "grad_norm": 1.0738343000411987,
      "learning_rate": 6.1203022875817e-06,
      "loss": 0.0329,
      "step": 9778
    },
    {
      "epoch": 2.247012867647059,
      "grad_norm": 0.8555471897125244,
      "learning_rate": 6.119791666666667e-06,
      "loss": 0.0322,
      "step": 9779
    },
    {
      "epoch": 2.2472426470588234,
      "grad_norm": 0.9725939631462097,
      "learning_rate": 6.119281045751635e-06,
      "loss": 0.0433,
      "step": 9780
    },
    {
      "epoch": 2.2474724264705883,
      "grad_norm": 0.8168801665306091,
      "learning_rate": 6.118770424836602e-06,
      "loss": 0.0297,
      "step": 9781
    },
    {
      "epoch": 2.247702205882353,
      "grad_norm": 0.7608427405357361,
      "learning_rate": 6.118259803921569e-06,
      "loss": 0.0426,
      "step": 9782
    },
    {
      "epoch": 2.2479319852941178,
      "grad_norm": 0.7065771222114563,
      "learning_rate": 6.117749183006536e-06,
      "loss": 0.0262,
      "step": 9783
    },
    {
      "epoch": 2.2481617647058822,
      "grad_norm": 1.7157707214355469,
      "learning_rate": 6.1172385620915045e-06,
      "loss": 0.0531,
      "step": 9784
    },
    {
      "epoch": 2.248391544117647,
      "grad_norm": 0.7672421336174011,
      "learning_rate": 6.1167279411764715e-06,
      "loss": 0.0282,
      "step": 9785
    },
    {
      "epoch": 2.2486213235294117,
      "grad_norm": 0.8988662958145142,
      "learning_rate": 6.1162173202614385e-06,
      "loss": 0.0445,
      "step": 9786
    },
    {
      "epoch": 2.2488511029411766,
      "grad_norm": 1.152193546295166,
      "learning_rate": 6.1157066993464056e-06,
      "loss": 0.0597,
      "step": 9787
    },
    {
      "epoch": 2.249080882352941,
      "grad_norm": 0.883632481098175,
      "learning_rate": 6.1151960784313734e-06,
      "loss": 0.0405,
      "step": 9788
    },
    {
      "epoch": 2.249310661764706,
      "grad_norm": 0.9609598517417908,
      "learning_rate": 6.1146854575163404e-06,
      "loss": 0.0252,
      "step": 9789
    },
    {
      "epoch": 2.2495404411764706,
      "grad_norm": 0.8514840602874756,
      "learning_rate": 6.1141748366013075e-06,
      "loss": 0.0333,
      "step": 9790
    },
    {
      "epoch": 2.2497702205882355,
      "grad_norm": 0.7763693928718567,
      "learning_rate": 6.1136642156862745e-06,
      "loss": 0.0302,
      "step": 9791
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.8334605097770691,
      "learning_rate": 6.113153594771243e-06,
      "loss": 0.0352,
      "step": 9792
    },
    {
      "epoch": 2.2502297794117645,
      "grad_norm": 0.8624449372291565,
      "learning_rate": 6.11264297385621e-06,
      "loss": 0.0335,
      "step": 9793
    },
    {
      "epoch": 2.2504595588235294,
      "grad_norm": 1.0401654243469238,
      "learning_rate": 6.112132352941177e-06,
      "loss": 0.046,
      "step": 9794
    },
    {
      "epoch": 2.250689338235294,
      "grad_norm": 1.1414580345153809,
      "learning_rate": 6.111621732026144e-06,
      "loss": 0.0446,
      "step": 9795
    },
    {
      "epoch": 2.250919117647059,
      "grad_norm": 1.0245294570922852,
      "learning_rate": 6.111111111111112e-06,
      "loss": 0.0371,
      "step": 9796
    },
    {
      "epoch": 2.2511488970588234,
      "grad_norm": 0.8280254602432251,
      "learning_rate": 6.110600490196079e-06,
      "loss": 0.0393,
      "step": 9797
    },
    {
      "epoch": 2.2513786764705883,
      "grad_norm": 0.8531528115272522,
      "learning_rate": 6.110089869281046e-06,
      "loss": 0.0335,
      "step": 9798
    },
    {
      "epoch": 2.251608455882353,
      "grad_norm": 0.98119056224823,
      "learning_rate": 6.109579248366013e-06,
      "loss": 0.0444,
      "step": 9799
    },
    {
      "epoch": 2.2518382352941178,
      "grad_norm": 0.9529450535774231,
      "learning_rate": 6.109068627450981e-06,
      "loss": 0.0413,
      "step": 9800
    },
    {
      "epoch": 2.2520680147058822,
      "grad_norm": 0.9516668915748596,
      "learning_rate": 6.108558006535949e-06,
      "loss": 0.0281,
      "step": 9801
    },
    {
      "epoch": 2.252297794117647,
      "grad_norm": 0.931529700756073,
      "learning_rate": 6.108047385620916e-06,
      "loss": 0.0284,
      "step": 9802
    },
    {
      "epoch": 2.2525275735294117,
      "grad_norm": 1.2560161352157593,
      "learning_rate": 6.107536764705883e-06,
      "loss": 0.0603,
      "step": 9803
    },
    {
      "epoch": 2.2527573529411766,
      "grad_norm": 1.1515543460845947,
      "learning_rate": 6.107026143790851e-06,
      "loss": 0.0635,
      "step": 9804
    },
    {
      "epoch": 2.252987132352941,
      "grad_norm": 1.4664764404296875,
      "learning_rate": 6.106515522875818e-06,
      "loss": 0.0314,
      "step": 9805
    },
    {
      "epoch": 2.253216911764706,
      "grad_norm": 1.1349945068359375,
      "learning_rate": 6.106004901960785e-06,
      "loss": 0.0587,
      "step": 9806
    },
    {
      "epoch": 2.2534466911764706,
      "grad_norm": 0.8342905044555664,
      "learning_rate": 6.105494281045752e-06,
      "loss": 0.0341,
      "step": 9807
    },
    {
      "epoch": 2.2536764705882355,
      "grad_norm": 0.8947431445121765,
      "learning_rate": 6.10498366013072e-06,
      "loss": 0.0442,
      "step": 9808
    },
    {
      "epoch": 2.25390625,
      "grad_norm": 1.0492630004882812,
      "learning_rate": 6.104473039215687e-06,
      "loss": 0.0356,
      "step": 9809
    },
    {
      "epoch": 2.2541360294117645,
      "grad_norm": 1.2892889976501465,
      "learning_rate": 6.103962418300654e-06,
      "loss": 0.0592,
      "step": 9810
    },
    {
      "epoch": 2.2543658088235294,
      "grad_norm": 0.8794037699699402,
      "learning_rate": 6.103451797385621e-06,
      "loss": 0.0498,
      "step": 9811
    },
    {
      "epoch": 2.254595588235294,
      "grad_norm": 0.9364500045776367,
      "learning_rate": 6.102941176470589e-06,
      "loss": 0.0523,
      "step": 9812
    },
    {
      "epoch": 2.254825367647059,
      "grad_norm": 1.051937460899353,
      "learning_rate": 6.102430555555556e-06,
      "loss": 0.0465,
      "step": 9813
    },
    {
      "epoch": 2.2550551470588234,
      "grad_norm": 1.207828402519226,
      "learning_rate": 6.1019199346405234e-06,
      "loss": 0.0579,
      "step": 9814
    },
    {
      "epoch": 2.2552849264705883,
      "grad_norm": 0.995720624923706,
      "learning_rate": 6.1014093137254904e-06,
      "loss": 0.0487,
      "step": 9815
    },
    {
      "epoch": 2.255514705882353,
      "grad_norm": 0.8351364731788635,
      "learning_rate": 6.100898692810458e-06,
      "loss": 0.0381,
      "step": 9816
    },
    {
      "epoch": 2.2557444852941178,
      "grad_norm": 0.9194802641868591,
      "learning_rate": 6.100388071895425e-06,
      "loss": 0.0479,
      "step": 9817
    },
    {
      "epoch": 2.2559742647058822,
      "grad_norm": 0.9397187232971191,
      "learning_rate": 6.099877450980392e-06,
      "loss": 0.0425,
      "step": 9818
    },
    {
      "epoch": 2.256204044117647,
      "grad_norm": 0.9027560353279114,
      "learning_rate": 6.099366830065359e-06,
      "loss": 0.0522,
      "step": 9819
    },
    {
      "epoch": 2.2564338235294117,
      "grad_norm": 0.7000799179077148,
      "learning_rate": 6.098856209150328e-06,
      "loss": 0.04,
      "step": 9820
    },
    {
      "epoch": 2.2566636029411766,
      "grad_norm": 0.7144994735717773,
      "learning_rate": 6.098345588235295e-06,
      "loss": 0.0368,
      "step": 9821
    },
    {
      "epoch": 2.256893382352941,
      "grad_norm": 0.9080371260643005,
      "learning_rate": 6.097834967320262e-06,
      "loss": 0.0261,
      "step": 9822
    },
    {
      "epoch": 2.257123161764706,
      "grad_norm": 1.0958492755889893,
      "learning_rate": 6.097324346405229e-06,
      "loss": 0.0349,
      "step": 9823
    },
    {
      "epoch": 2.2573529411764706,
      "grad_norm": 0.8062816262245178,
      "learning_rate": 6.096813725490197e-06,
      "loss": 0.0327,
      "step": 9824
    },
    {
      "epoch": 2.2575827205882355,
      "grad_norm": 0.8894440531730652,
      "learning_rate": 6.096303104575164e-06,
      "loss": 0.0455,
      "step": 9825
    },
    {
      "epoch": 2.2578125,
      "grad_norm": 0.8816794753074646,
      "learning_rate": 6.095792483660131e-06,
      "loss": 0.044,
      "step": 9826
    },
    {
      "epoch": 2.2580422794117645,
      "grad_norm": 0.8352614641189575,
      "learning_rate": 6.095281862745098e-06,
      "loss": 0.0374,
      "step": 9827
    },
    {
      "epoch": 2.2582720588235294,
      "grad_norm": 0.97420334815979,
      "learning_rate": 6.094771241830067e-06,
      "loss": 0.0484,
      "step": 9828
    },
    {
      "epoch": 2.258501838235294,
      "grad_norm": 1.0658464431762695,
      "learning_rate": 6.094260620915034e-06,
      "loss": 0.0488,
      "step": 9829
    },
    {
      "epoch": 2.258731617647059,
      "grad_norm": 0.783370852470398,
      "learning_rate": 6.093750000000001e-06,
      "loss": 0.0334,
      "step": 9830
    },
    {
      "epoch": 2.2589613970588234,
      "grad_norm": 0.7972110509872437,
      "learning_rate": 6.093239379084968e-06,
      "loss": 0.0312,
      "step": 9831
    },
    {
      "epoch": 2.2591911764705883,
      "grad_norm": 0.7361633777618408,
      "learning_rate": 6.092728758169935e-06,
      "loss": 0.0322,
      "step": 9832
    },
    {
      "epoch": 2.259420955882353,
      "grad_norm": 1.1589688062667847,
      "learning_rate": 6.092218137254903e-06,
      "loss": 0.0501,
      "step": 9833
    },
    {
      "epoch": 2.2596507352941178,
      "grad_norm": 1.0217698812484741,
      "learning_rate": 6.09170751633987e-06,
      "loss": 0.0447,
      "step": 9834
    },
    {
      "epoch": 2.2598805147058822,
      "grad_norm": 1.4786802530288696,
      "learning_rate": 6.091196895424837e-06,
      "loss": 0.0327,
      "step": 9835
    },
    {
      "epoch": 2.260110294117647,
      "grad_norm": 1.1696993112564087,
      "learning_rate": 6.090686274509804e-06,
      "loss": 0.0687,
      "step": 9836
    },
    {
      "epoch": 2.2603400735294117,
      "grad_norm": 0.9125719666481018,
      "learning_rate": 6.090175653594772e-06,
      "loss": 0.0517,
      "step": 9837
    },
    {
      "epoch": 2.2605698529411766,
      "grad_norm": 0.9980493783950806,
      "learning_rate": 6.089665032679739e-06,
      "loss": 0.044,
      "step": 9838
    },
    {
      "epoch": 2.260799632352941,
      "grad_norm": 1.0946037769317627,
      "learning_rate": 6.089154411764706e-06,
      "loss": 0.0487,
      "step": 9839
    },
    {
      "epoch": 2.261029411764706,
      "grad_norm": 1.1468347311019897,
      "learning_rate": 6.088643790849673e-06,
      "loss": 0.0621,
      "step": 9840
    },
    {
      "epoch": 2.2612591911764706,
      "grad_norm": 0.6370804905891418,
      "learning_rate": 6.088133169934641e-06,
      "loss": 0.0273,
      "step": 9841
    },
    {
      "epoch": 2.2614889705882355,
      "grad_norm": 1.1548171043395996,
      "learning_rate": 6.087622549019608e-06,
      "loss": 0.0563,
      "step": 9842
    },
    {
      "epoch": 2.26171875,
      "grad_norm": 0.8770534992218018,
      "learning_rate": 6.087111928104575e-06,
      "loss": 0.0367,
      "step": 9843
    },
    {
      "epoch": 2.2619485294117645,
      "grad_norm": 1.086309790611267,
      "learning_rate": 6.086601307189542e-06,
      "loss": 0.05,
      "step": 9844
    },
    {
      "epoch": 2.2621783088235294,
      "grad_norm": 0.6978759765625,
      "learning_rate": 6.08609068627451e-06,
      "loss": 0.0396,
      "step": 9845
    },
    {
      "epoch": 2.262408088235294,
      "grad_norm": 0.8617885112762451,
      "learning_rate": 6.085580065359478e-06,
      "loss": 0.0345,
      "step": 9846
    },
    {
      "epoch": 2.262637867647059,
      "grad_norm": 0.9348530769348145,
      "learning_rate": 6.085069444444445e-06,
      "loss": 0.0546,
      "step": 9847
    },
    {
      "epoch": 2.2628676470588234,
      "grad_norm": 1.0491244792938232,
      "learning_rate": 6.084558823529412e-06,
      "loss": 0.0457,
      "step": 9848
    },
    {
      "epoch": 2.2630974264705883,
      "grad_norm": 0.7892230153083801,
      "learning_rate": 6.08404820261438e-06,
      "loss": 0.0464,
      "step": 9849
    },
    {
      "epoch": 2.263327205882353,
      "grad_norm": 0.872757613658905,
      "learning_rate": 6.083537581699347e-06,
      "loss": 0.042,
      "step": 9850
    },
    {
      "epoch": 2.2635569852941178,
      "grad_norm": 0.9953876733779907,
      "learning_rate": 6.083026960784314e-06,
      "loss": 0.0435,
      "step": 9851
    },
    {
      "epoch": 2.2637867647058822,
      "grad_norm": 0.8404616713523865,
      "learning_rate": 6.082516339869281e-06,
      "loss": 0.0323,
      "step": 9852
    },
    {
      "epoch": 2.264016544117647,
      "grad_norm": 0.7183326482772827,
      "learning_rate": 6.082005718954249e-06,
      "loss": 0.0384,
      "step": 9853
    },
    {
      "epoch": 2.2642463235294117,
      "grad_norm": 0.8033905625343323,
      "learning_rate": 6.081495098039216e-06,
      "loss": 0.0279,
      "step": 9854
    },
    {
      "epoch": 2.2644761029411766,
      "grad_norm": 1.1145623922348022,
      "learning_rate": 6.080984477124183e-06,
      "loss": 0.0421,
      "step": 9855
    },
    {
      "epoch": 2.264705882352941,
      "grad_norm": 1.0409802198410034,
      "learning_rate": 6.080473856209151e-06,
      "loss": 0.0415,
      "step": 9856
    },
    {
      "epoch": 2.264935661764706,
      "grad_norm": 0.9168550372123718,
      "learning_rate": 6.079963235294119e-06,
      "loss": 0.046,
      "step": 9857
    },
    {
      "epoch": 2.2651654411764706,
      "grad_norm": 0.763702929019928,
      "learning_rate": 6.079452614379086e-06,
      "loss": 0.0303,
      "step": 9858
    },
    {
      "epoch": 2.2653952205882355,
      "grad_norm": 0.7789438962936401,
      "learning_rate": 6.078941993464053e-06,
      "loss": 0.0215,
      "step": 9859
    },
    {
      "epoch": 2.265625,
      "grad_norm": 0.7072994709014893,
      "learning_rate": 6.07843137254902e-06,
      "loss": 0.0241,
      "step": 9860
    },
    {
      "epoch": 2.2658547794117645,
      "grad_norm": 0.90513014793396,
      "learning_rate": 6.0779207516339875e-06,
      "loss": 0.0375,
      "step": 9861
    },
    {
      "epoch": 2.2660845588235294,
      "grad_norm": 0.9704767465591431,
      "learning_rate": 6.0774101307189545e-06,
      "loss": 0.0347,
      "step": 9862
    },
    {
      "epoch": 2.266314338235294,
      "grad_norm": 0.9569570422172546,
      "learning_rate": 6.0768995098039215e-06,
      "loss": 0.0632,
      "step": 9863
    },
    {
      "epoch": 2.266544117647059,
      "grad_norm": 1.0972867012023926,
      "learning_rate": 6.0763888888888885e-06,
      "loss": 0.0504,
      "step": 9864
    },
    {
      "epoch": 2.2667738970588234,
      "grad_norm": 1.0661524534225464,
      "learning_rate": 6.075878267973857e-06,
      "loss": 0.0631,
      "step": 9865
    },
    {
      "epoch": 2.2670036764705883,
      "grad_norm": 0.8391202688217163,
      "learning_rate": 6.075367647058824e-06,
      "loss": 0.0467,
      "step": 9866
    },
    {
      "epoch": 2.267233455882353,
      "grad_norm": 1.0872188806533813,
      "learning_rate": 6.074857026143791e-06,
      "loss": 0.043,
      "step": 9867
    },
    {
      "epoch": 2.2674632352941178,
      "grad_norm": 1.416813850402832,
      "learning_rate": 6.074346405228758e-06,
      "loss": 0.0449,
      "step": 9868
    },
    {
      "epoch": 2.2676930147058822,
      "grad_norm": 0.8404935002326965,
      "learning_rate": 6.073835784313726e-06,
      "loss": 0.0343,
      "step": 9869
    },
    {
      "epoch": 2.267922794117647,
      "grad_norm": 1.0063048601150513,
      "learning_rate": 6.073325163398693e-06,
      "loss": 0.0559,
      "step": 9870
    },
    {
      "epoch": 2.2681525735294117,
      "grad_norm": 0.9596396684646606,
      "learning_rate": 6.07281454248366e-06,
      "loss": 0.0392,
      "step": 9871
    },
    {
      "epoch": 2.2683823529411766,
      "grad_norm": 0.9172675609588623,
      "learning_rate": 6.072303921568627e-06,
      "loss": 0.0391,
      "step": 9872
    },
    {
      "epoch": 2.268612132352941,
      "grad_norm": 1.1927660703659058,
      "learning_rate": 6.071793300653596e-06,
      "loss": 0.0458,
      "step": 9873
    },
    {
      "epoch": 2.268841911764706,
      "grad_norm": 1.1202529668807983,
      "learning_rate": 6.071282679738563e-06,
      "loss": 0.0683,
      "step": 9874
    },
    {
      "epoch": 2.2690716911764706,
      "grad_norm": 1.0847463607788086,
      "learning_rate": 6.07077205882353e-06,
      "loss": 0.0359,
      "step": 9875
    },
    {
      "epoch": 2.2693014705882355,
      "grad_norm": 1.079088807106018,
      "learning_rate": 6.070261437908497e-06,
      "loss": 0.0499,
      "step": 9876
    },
    {
      "epoch": 2.26953125,
      "grad_norm": 1.0028096437454224,
      "learning_rate": 6.069750816993465e-06,
      "loss": 0.0509,
      "step": 9877
    },
    {
      "epoch": 2.2697610294117645,
      "grad_norm": 1.230180025100708,
      "learning_rate": 6.069240196078432e-06,
      "loss": 0.0875,
      "step": 9878
    },
    {
      "epoch": 2.2699908088235294,
      "grad_norm": 0.9697540998458862,
      "learning_rate": 6.068729575163399e-06,
      "loss": 0.0391,
      "step": 9879
    },
    {
      "epoch": 2.270220588235294,
      "grad_norm": 0.8899667263031006,
      "learning_rate": 6.068218954248366e-06,
      "loss": 0.0386,
      "step": 9880
    },
    {
      "epoch": 2.270450367647059,
      "grad_norm": 0.9049836993217468,
      "learning_rate": 6.0677083333333346e-06,
      "loss": 0.0429,
      "step": 9881
    },
    {
      "epoch": 2.2706801470588234,
      "grad_norm": 0.9174321293830872,
      "learning_rate": 6.067197712418302e-06,
      "loss": 0.0475,
      "step": 9882
    },
    {
      "epoch": 2.2709099264705883,
      "grad_norm": 0.8978605270385742,
      "learning_rate": 6.066687091503269e-06,
      "loss": 0.0474,
      "step": 9883
    },
    {
      "epoch": 2.271139705882353,
      "grad_norm": 0.9488953351974487,
      "learning_rate": 6.066176470588236e-06,
      "loss": 0.0349,
      "step": 9884
    },
    {
      "epoch": 2.2713694852941178,
      "grad_norm": 0.7488570809364319,
      "learning_rate": 6.0656658496732035e-06,
      "loss": 0.0278,
      "step": 9885
    },
    {
      "epoch": 2.2715992647058822,
      "grad_norm": 0.827542781829834,
      "learning_rate": 6.0651552287581705e-06,
      "loss": 0.0333,
      "step": 9886
    },
    {
      "epoch": 2.271829044117647,
      "grad_norm": 1.1738113164901733,
      "learning_rate": 6.0646446078431375e-06,
      "loss": 0.0442,
      "step": 9887
    },
    {
      "epoch": 2.2720588235294117,
      "grad_norm": 0.9720928072929382,
      "learning_rate": 6.0641339869281045e-06,
      "loss": 0.0368,
      "step": 9888
    },
    {
      "epoch": 2.2722886029411766,
      "grad_norm": 0.9213565587997437,
      "learning_rate": 6.063623366013072e-06,
      "loss": 0.0339,
      "step": 9889
    },
    {
      "epoch": 2.272518382352941,
      "grad_norm": 1.4205518960952759,
      "learning_rate": 6.06311274509804e-06,
      "loss": 0.0655,
      "step": 9890
    },
    {
      "epoch": 2.272748161764706,
      "grad_norm": 1.0619570016860962,
      "learning_rate": 6.062602124183007e-06,
      "loss": 0.0458,
      "step": 9891
    },
    {
      "epoch": 2.2729779411764706,
      "grad_norm": 0.9599047899246216,
      "learning_rate": 6.062091503267974e-06,
      "loss": 0.0527,
      "step": 9892
    },
    {
      "epoch": 2.2732077205882355,
      "grad_norm": 0.9944071769714355,
      "learning_rate": 6.061580882352942e-06,
      "loss": 0.049,
      "step": 9893
    },
    {
      "epoch": 2.2734375,
      "grad_norm": 0.8133177757263184,
      "learning_rate": 6.061070261437909e-06,
      "loss": 0.0456,
      "step": 9894
    },
    {
      "epoch": 2.2736672794117645,
      "grad_norm": 0.8534569144248962,
      "learning_rate": 6.060559640522876e-06,
      "loss": 0.0484,
      "step": 9895
    },
    {
      "epoch": 2.2738970588235294,
      "grad_norm": 1.0479532480239868,
      "learning_rate": 6.060049019607843e-06,
      "loss": 0.041,
      "step": 9896
    },
    {
      "epoch": 2.274126838235294,
      "grad_norm": 0.8844733238220215,
      "learning_rate": 6.059538398692811e-06,
      "loss": 0.0298,
      "step": 9897
    },
    {
      "epoch": 2.274356617647059,
      "grad_norm": 0.816207230091095,
      "learning_rate": 6.059027777777778e-06,
      "loss": 0.0422,
      "step": 9898
    },
    {
      "epoch": 2.2745863970588234,
      "grad_norm": 0.7899467945098877,
      "learning_rate": 6.058517156862745e-06,
      "loss": 0.0433,
      "step": 9899
    },
    {
      "epoch": 2.2748161764705883,
      "grad_norm": 0.8314708471298218,
      "learning_rate": 6.058006535947712e-06,
      "loss": 0.0378,
      "step": 9900
    },
    {
      "epoch": 2.275045955882353,
      "grad_norm": 0.9054051637649536,
      "learning_rate": 6.057495915032681e-06,
      "loss": 0.0418,
      "step": 9901
    },
    {
      "epoch": 2.2752757352941178,
      "grad_norm": 0.7991700172424316,
      "learning_rate": 6.056985294117648e-06,
      "loss": 0.0365,
      "step": 9902
    },
    {
      "epoch": 2.2755055147058822,
      "grad_norm": 0.9369027614593506,
      "learning_rate": 6.056474673202615e-06,
      "loss": 0.0425,
      "step": 9903
    },
    {
      "epoch": 2.275735294117647,
      "grad_norm": 1.131797194480896,
      "learning_rate": 6.055964052287582e-06,
      "loss": 0.0423,
      "step": 9904
    },
    {
      "epoch": 2.2759650735294117,
      "grad_norm": 1.1113735437393188,
      "learning_rate": 6.05545343137255e-06,
      "loss": 0.0416,
      "step": 9905
    },
    {
      "epoch": 2.2761948529411766,
      "grad_norm": 0.948745608329773,
      "learning_rate": 6.054942810457517e-06,
      "loss": 0.0512,
      "step": 9906
    },
    {
      "epoch": 2.276424632352941,
      "grad_norm": 1.0404856204986572,
      "learning_rate": 6.054432189542484e-06,
      "loss": 0.0529,
      "step": 9907
    },
    {
      "epoch": 2.276654411764706,
      "grad_norm": 0.7437454462051392,
      "learning_rate": 6.053921568627451e-06,
      "loss": 0.0286,
      "step": 9908
    },
    {
      "epoch": 2.2768841911764706,
      "grad_norm": 1.4981073141098022,
      "learning_rate": 6.0534109477124194e-06,
      "loss": 0.037,
      "step": 9909
    },
    {
      "epoch": 2.2771139705882355,
      "grad_norm": 0.973461389541626,
      "learning_rate": 6.0529003267973865e-06,
      "loss": 0.0493,
      "step": 9910
    },
    {
      "epoch": 2.27734375,
      "grad_norm": 0.8086000680923462,
      "learning_rate": 6.0523897058823535e-06,
      "loss": 0.027,
      "step": 9911
    },
    {
      "epoch": 2.2775735294117645,
      "grad_norm": 1.1108776330947876,
      "learning_rate": 6.0518790849673205e-06,
      "loss": 0.0548,
      "step": 9912
    },
    {
      "epoch": 2.2778033088235294,
      "grad_norm": 1.3495436906814575,
      "learning_rate": 6.051368464052288e-06,
      "loss": 0.0521,
      "step": 9913
    },
    {
      "epoch": 2.278033088235294,
      "grad_norm": 1.009873628616333,
      "learning_rate": 6.050857843137255e-06,
      "loss": 0.0532,
      "step": 9914
    },
    {
      "epoch": 2.278262867647059,
      "grad_norm": 0.8670327067375183,
      "learning_rate": 6.050347222222222e-06,
      "loss": 0.0366,
      "step": 9915
    },
    {
      "epoch": 2.2784926470588234,
      "grad_norm": 1.9223604202270508,
      "learning_rate": 6.049836601307189e-06,
      "loss": 0.042,
      "step": 9916
    },
    {
      "epoch": 2.2787224264705883,
      "grad_norm": 0.8921071290969849,
      "learning_rate": 6.049325980392158e-06,
      "loss": 0.0423,
      "step": 9917
    },
    {
      "epoch": 2.278952205882353,
      "grad_norm": 1.1957184076309204,
      "learning_rate": 6.048815359477125e-06,
      "loss": 0.0631,
      "step": 9918
    },
    {
      "epoch": 2.2791819852941178,
      "grad_norm": 0.9769012331962585,
      "learning_rate": 6.048304738562092e-06,
      "loss": 0.0373,
      "step": 9919
    },
    {
      "epoch": 2.2794117647058822,
      "grad_norm": 0.8375625610351562,
      "learning_rate": 6.047794117647059e-06,
      "loss": 0.0481,
      "step": 9920
    },
    {
      "epoch": 2.279641544117647,
      "grad_norm": 0.8593316078186035,
      "learning_rate": 6.047283496732027e-06,
      "loss": 0.0269,
      "step": 9921
    },
    {
      "epoch": 2.2798713235294117,
      "grad_norm": 1.1123335361480713,
      "learning_rate": 6.046772875816994e-06,
      "loss": 0.0616,
      "step": 9922
    },
    {
      "epoch": 2.2801011029411766,
      "grad_norm": 0.8751475811004639,
      "learning_rate": 6.046262254901961e-06,
      "loss": 0.0357,
      "step": 9923
    },
    {
      "epoch": 2.280330882352941,
      "grad_norm": 1.0555311441421509,
      "learning_rate": 6.045751633986928e-06,
      "loss": 0.0482,
      "step": 9924
    },
    {
      "epoch": 2.280560661764706,
      "grad_norm": 1.1479605436325073,
      "learning_rate": 6.045241013071897e-06,
      "loss": 0.0416,
      "step": 9925
    },
    {
      "epoch": 2.2807904411764706,
      "grad_norm": 0.835114061832428,
      "learning_rate": 6.044730392156864e-06,
      "loss": 0.0368,
      "step": 9926
    },
    {
      "epoch": 2.2810202205882355,
      "grad_norm": 1.0144553184509277,
      "learning_rate": 6.044219771241831e-06,
      "loss": 0.039,
      "step": 9927
    },
    {
      "epoch": 2.28125,
      "grad_norm": 0.654613196849823,
      "learning_rate": 6.043709150326798e-06,
      "loss": 0.0256,
      "step": 9928
    },
    {
      "epoch": 2.2814797794117645,
      "grad_norm": 0.7319398522377014,
      "learning_rate": 6.043198529411766e-06,
      "loss": 0.0254,
      "step": 9929
    },
    {
      "epoch": 2.2817095588235294,
      "grad_norm": 0.9228076338768005,
      "learning_rate": 6.042687908496733e-06,
      "loss": 0.0384,
      "step": 9930
    },
    {
      "epoch": 2.281939338235294,
      "grad_norm": 0.7270556092262268,
      "learning_rate": 6.0421772875817e-06,
      "loss": 0.0283,
      "step": 9931
    },
    {
      "epoch": 2.282169117647059,
      "grad_norm": 0.7235431671142578,
      "learning_rate": 6.041666666666667e-06,
      "loss": 0.0314,
      "step": 9932
    },
    {
      "epoch": 2.2823988970588234,
      "grad_norm": 1.1444872617721558,
      "learning_rate": 6.0411560457516346e-06,
      "loss": 0.0382,
      "step": 9933
    },
    {
      "epoch": 2.2826286764705883,
      "grad_norm": 1.0161694288253784,
      "learning_rate": 6.040645424836602e-06,
      "loss": 0.04,
      "step": 9934
    },
    {
      "epoch": 2.282858455882353,
      "grad_norm": 0.7716650366783142,
      "learning_rate": 6.0401348039215694e-06,
      "loss": 0.0192,
      "step": 9935
    },
    {
      "epoch": 2.2830882352941178,
      "grad_norm": 0.8881198763847351,
      "learning_rate": 6.0396241830065365e-06,
      "loss": 0.0337,
      "step": 9936
    },
    {
      "epoch": 2.2833180147058822,
      "grad_norm": 0.8809747099876404,
      "learning_rate": 6.039113562091504e-06,
      "loss": 0.0303,
      "step": 9937
    },
    {
      "epoch": 2.283547794117647,
      "grad_norm": 1.0334763526916504,
      "learning_rate": 6.038602941176471e-06,
      "loss": 0.0358,
      "step": 9938
    },
    {
      "epoch": 2.2837775735294117,
      "grad_norm": 0.9212313890457153,
      "learning_rate": 6.038092320261438e-06,
      "loss": 0.0407,
      "step": 9939
    },
    {
      "epoch": 2.2840073529411766,
      "grad_norm": 1.0951331853866577,
      "learning_rate": 6.037581699346405e-06,
      "loss": 0.0463,
      "step": 9940
    },
    {
      "epoch": 2.284237132352941,
      "grad_norm": 0.9828364253044128,
      "learning_rate": 6.037071078431373e-06,
      "loss": 0.0312,
      "step": 9941
    },
    {
      "epoch": 2.284466911764706,
      "grad_norm": 0.9790666699409485,
      "learning_rate": 6.03656045751634e-06,
      "loss": 0.0327,
      "step": 9942
    },
    {
      "epoch": 2.2846966911764706,
      "grad_norm": 1.0951590538024902,
      "learning_rate": 6.036049836601307e-06,
      "loss": 0.037,
      "step": 9943
    },
    {
      "epoch": 2.2849264705882355,
      "grad_norm": 0.9047605395317078,
      "learning_rate": 6.035539215686274e-06,
      "loss": 0.0271,
      "step": 9944
    },
    {
      "epoch": 2.28515625,
      "grad_norm": 0.8281831741333008,
      "learning_rate": 6.035028594771243e-06,
      "loss": 0.0363,
      "step": 9945
    },
    {
      "epoch": 2.2853860294117645,
      "grad_norm": 1.1321916580200195,
      "learning_rate": 6.03451797385621e-06,
      "loss": 0.0409,
      "step": 9946
    },
    {
      "epoch": 2.2856158088235294,
      "grad_norm": 0.7783995866775513,
      "learning_rate": 6.034007352941177e-06,
      "loss": 0.038,
      "step": 9947
    },
    {
      "epoch": 2.285845588235294,
      "grad_norm": 1.071146011352539,
      "learning_rate": 6.033496732026144e-06,
      "loss": 0.0468,
      "step": 9948
    },
    {
      "epoch": 2.286075367647059,
      "grad_norm": 1.3555467128753662,
      "learning_rate": 6.032986111111112e-06,
      "loss": 0.0695,
      "step": 9949
    },
    {
      "epoch": 2.2863051470588234,
      "grad_norm": 1.0562816858291626,
      "learning_rate": 6.032475490196079e-06,
      "loss": 0.0528,
      "step": 9950
    },
    {
      "epoch": 2.2865349264705883,
      "grad_norm": 0.77396559715271,
      "learning_rate": 6.031964869281046e-06,
      "loss": 0.0345,
      "step": 9951
    },
    {
      "epoch": 2.286764705882353,
      "grad_norm": 1.0138218402862549,
      "learning_rate": 6.031454248366013e-06,
      "loss": 0.0248,
      "step": 9952
    },
    {
      "epoch": 2.2869944852941178,
      "grad_norm": 0.7280510663986206,
      "learning_rate": 6.030943627450982e-06,
      "loss": 0.0263,
      "step": 9953
    },
    {
      "epoch": 2.2872242647058822,
      "grad_norm": 0.9639248251914978,
      "learning_rate": 6.030433006535949e-06,
      "loss": 0.0459,
      "step": 9954
    },
    {
      "epoch": 2.287454044117647,
      "grad_norm": 1.217344045639038,
      "learning_rate": 6.029922385620916e-06,
      "loss": 0.0329,
      "step": 9955
    },
    {
      "epoch": 2.2876838235294117,
      "grad_norm": 1.2447354793548584,
      "learning_rate": 6.029411764705883e-06,
      "loss": 0.0608,
      "step": 9956
    },
    {
      "epoch": 2.2879136029411766,
      "grad_norm": 0.807976484298706,
      "learning_rate": 6.0289011437908505e-06,
      "loss": 0.0438,
      "step": 9957
    },
    {
      "epoch": 2.288143382352941,
      "grad_norm": 1.163975715637207,
      "learning_rate": 6.0283905228758175e-06,
      "loss": 0.0409,
      "step": 9958
    },
    {
      "epoch": 2.288373161764706,
      "grad_norm": 1.0257768630981445,
      "learning_rate": 6.0278799019607846e-06,
      "loss": 0.0378,
      "step": 9959
    },
    {
      "epoch": 2.2886029411764706,
      "grad_norm": 1.694375991821289,
      "learning_rate": 6.027369281045752e-06,
      "loss": 0.0518,
      "step": 9960
    },
    {
      "epoch": 2.2888327205882355,
      "grad_norm": 1.1766620874404907,
      "learning_rate": 6.02685866013072e-06,
      "loss": 0.0425,
      "step": 9961
    },
    {
      "epoch": 2.2890625,
      "grad_norm": 1.13551926612854,
      "learning_rate": 6.026348039215687e-06,
      "loss": 0.0596,
      "step": 9962
    },
    {
      "epoch": 2.2892922794117645,
      "grad_norm": 0.8973135948181152,
      "learning_rate": 6.025837418300654e-06,
      "loss": 0.0389,
      "step": 9963
    },
    {
      "epoch": 2.2895220588235294,
      "grad_norm": 0.7982679009437561,
      "learning_rate": 6.025326797385621e-06,
      "loss": 0.0342,
      "step": 9964
    },
    {
      "epoch": 2.289751838235294,
      "grad_norm": 1.2006393671035767,
      "learning_rate": 6.024816176470589e-06,
      "loss": 0.0692,
      "step": 9965
    },
    {
      "epoch": 2.289981617647059,
      "grad_norm": 1.137758493423462,
      "learning_rate": 6.024305555555556e-06,
      "loss": 0.0603,
      "step": 9966
    },
    {
      "epoch": 2.2902113970588234,
      "grad_norm": 0.7998568415641785,
      "learning_rate": 6.023794934640523e-06,
      "loss": 0.0365,
      "step": 9967
    },
    {
      "epoch": 2.2904411764705883,
      "grad_norm": 0.7524368166923523,
      "learning_rate": 6.02328431372549e-06,
      "loss": 0.0479,
      "step": 9968
    },
    {
      "epoch": 2.290670955882353,
      "grad_norm": 1.2020562887191772,
      "learning_rate": 6.022773692810459e-06,
      "loss": 0.0594,
      "step": 9969
    },
    {
      "epoch": 2.2909007352941178,
      "grad_norm": 0.6849786043167114,
      "learning_rate": 6.022263071895426e-06,
      "loss": 0.0301,
      "step": 9970
    },
    {
      "epoch": 2.2911305147058822,
      "grad_norm": 0.8623980283737183,
      "learning_rate": 6.021752450980393e-06,
      "loss": 0.028,
      "step": 9971
    },
    {
      "epoch": 2.291360294117647,
      "grad_norm": 0.9054644703865051,
      "learning_rate": 6.02124183006536e-06,
      "loss": 0.0349,
      "step": 9972
    },
    {
      "epoch": 2.2915900735294117,
      "grad_norm": 1.2496850490570068,
      "learning_rate": 6.020731209150328e-06,
      "loss": 0.0359,
      "step": 9973
    },
    {
      "epoch": 2.2918198529411766,
      "grad_norm": 1.2569841146469116,
      "learning_rate": 6.020220588235295e-06,
      "loss": 0.0613,
      "step": 9974
    },
    {
      "epoch": 2.292049632352941,
      "grad_norm": 1.0260785818099976,
      "learning_rate": 6.019709967320262e-06,
      "loss": 0.0541,
      "step": 9975
    },
    {
      "epoch": 2.292279411764706,
      "grad_norm": 0.8678430914878845,
      "learning_rate": 6.019199346405229e-06,
      "loss": 0.0264,
      "step": 9976
    },
    {
      "epoch": 2.2925091911764706,
      "grad_norm": 0.911157488822937,
      "learning_rate": 6.018688725490197e-06,
      "loss": 0.0468,
      "step": 9977
    },
    {
      "epoch": 2.2927389705882355,
      "grad_norm": 0.8299311995506287,
      "learning_rate": 6.018178104575164e-06,
      "loss": 0.0353,
      "step": 9978
    },
    {
      "epoch": 2.29296875,
      "grad_norm": 1.0672904253005981,
      "learning_rate": 6.017667483660132e-06,
      "loss": 0.0509,
      "step": 9979
    },
    {
      "epoch": 2.2931985294117645,
      "grad_norm": 0.7212978601455688,
      "learning_rate": 6.017156862745099e-06,
      "loss": 0.0335,
      "step": 9980
    },
    {
      "epoch": 2.2934283088235294,
      "grad_norm": 1.1843189001083374,
      "learning_rate": 6.0166462418300665e-06,
      "loss": 0.0361,
      "step": 9981
    },
    {
      "epoch": 2.293658088235294,
      "grad_norm": 1.1371721029281616,
      "learning_rate": 6.0161356209150335e-06,
      "loss": 0.0674,
      "step": 9982
    },
    {
      "epoch": 2.293887867647059,
      "grad_norm": 0.8617299795150757,
      "learning_rate": 6.0156250000000005e-06,
      "loss": 0.0382,
      "step": 9983
    },
    {
      "epoch": 2.2941176470588234,
      "grad_norm": 1.1611392498016357,
      "learning_rate": 6.0151143790849675e-06,
      "loss": 0.0416,
      "step": 9984
    },
    {
      "epoch": 2.2943474264705883,
      "grad_norm": 1.0823473930358887,
      "learning_rate": 6.0146037581699346e-06,
      "loss": 0.0551,
      "step": 9985
    },
    {
      "epoch": 2.294577205882353,
      "grad_norm": 0.9253410696983337,
      "learning_rate": 6.014093137254902e-06,
      "loss": 0.0585,
      "step": 9986
    },
    {
      "epoch": 2.2948069852941178,
      "grad_norm": 0.8006407022476196,
      "learning_rate": 6.0135825163398694e-06,
      "loss": 0.0427,
      "step": 9987
    },
    {
      "epoch": 2.2950367647058822,
      "grad_norm": 0.9305890798568726,
      "learning_rate": 6.0130718954248365e-06,
      "loss": 0.046,
      "step": 9988
    },
    {
      "epoch": 2.295266544117647,
      "grad_norm": 0.905147135257721,
      "learning_rate": 6.0125612745098035e-06,
      "loss": 0.042,
      "step": 9989
    },
    {
      "epoch": 2.2954963235294117,
      "grad_norm": 1.1715507507324219,
      "learning_rate": 6.012050653594772e-06,
      "loss": 0.0558,
      "step": 9990
    },
    {
      "epoch": 2.2957261029411766,
      "grad_norm": 0.9453670382499695,
      "learning_rate": 6.011540032679739e-06,
      "loss": 0.0595,
      "step": 9991
    },
    {
      "epoch": 2.295955882352941,
      "grad_norm": 0.9625750184059143,
      "learning_rate": 6.011029411764706e-06,
      "loss": 0.0413,
      "step": 9992
    },
    {
      "epoch": 2.296185661764706,
      "grad_norm": 0.6899487972259521,
      "learning_rate": 6.010518790849673e-06,
      "loss": 0.0323,
      "step": 9993
    },
    {
      "epoch": 2.2964154411764706,
      "grad_norm": 1.153982162475586,
      "learning_rate": 6.010008169934641e-06,
      "loss": 0.0463,
      "step": 9994
    },
    {
      "epoch": 2.2966452205882355,
      "grad_norm": 0.9410313963890076,
      "learning_rate": 6.009497549019608e-06,
      "loss": 0.0545,
      "step": 9995
    },
    {
      "epoch": 2.296875,
      "grad_norm": 0.8673306703567505,
      "learning_rate": 6.008986928104575e-06,
      "loss": 0.0417,
      "step": 9996
    },
    {
      "epoch": 2.2971047794117645,
      "grad_norm": 1.0843772888183594,
      "learning_rate": 6.008476307189542e-06,
      "loss": 0.0588,
      "step": 9997
    },
    {
      "epoch": 2.2973345588235294,
      "grad_norm": 0.9341731071472168,
      "learning_rate": 6.007965686274511e-06,
      "loss": 0.0431,
      "step": 9998
    },
    {
      "epoch": 2.297564338235294,
      "grad_norm": 0.7446395754814148,
      "learning_rate": 6.007455065359478e-06,
      "loss": 0.0316,
      "step": 9999
    },
    {
      "epoch": 2.297794117647059,
      "grad_norm": 1.3331586122512817,
      "learning_rate": 6.006944444444445e-06,
      "loss": 0.0622,
      "step": 10000
    },
    {
      "epoch": 2.297794117647059,
      "eval_loss": 0.04760287329554558,
      "eval_runtime": 2007.9606,
      "eval_samples_per_second": 4.435,
      "eval_steps_per_second": 2.218,
      "step": 10000
    },
    {
      "epoch": 2.2980238970588234,
      "grad_norm": 1.0951467752456665,
      "learning_rate": 6.006433823529412e-06,
      "loss": 0.0603,
      "step": 10001
    },
    {
      "epoch": 2.2982536764705883,
      "grad_norm": 0.9180158376693726,
      "learning_rate": 6.00592320261438e-06,
      "loss": 0.0425,
      "step": 10002
    },
    {
      "epoch": 2.298483455882353,
      "grad_norm": 0.6629658937454224,
      "learning_rate": 6.005412581699347e-06,
      "loss": 0.0286,
      "step": 10003
    },
    {
      "epoch": 2.2987132352941178,
      "grad_norm": 0.9449341893196106,
      "learning_rate": 6.004901960784314e-06,
      "loss": 0.0354,
      "step": 10004
    },
    {
      "epoch": 2.2989430147058822,
      "grad_norm": 0.9436794519424438,
      "learning_rate": 6.004391339869281e-06,
      "loss": 0.0398,
      "step": 10005
    },
    {
      "epoch": 2.299172794117647,
      "grad_norm": 0.8320928812026978,
      "learning_rate": 6.0038807189542495e-06,
      "loss": 0.0373,
      "step": 10006
    },
    {
      "epoch": 2.2994025735294117,
      "grad_norm": 0.840047299861908,
      "learning_rate": 6.0033700980392165e-06,
      "loss": 0.0314,
      "step": 10007
    },
    {
      "epoch": 2.2996323529411766,
      "grad_norm": 0.8257401585578918,
      "learning_rate": 6.0028594771241835e-06,
      "loss": 0.0363,
      "step": 10008
    },
    {
      "epoch": 2.299862132352941,
      "grad_norm": 0.9080832600593567,
      "learning_rate": 6.0023488562091505e-06,
      "loss": 0.0444,
      "step": 10009
    },
    {
      "epoch": 2.300091911764706,
      "grad_norm": 1.0648374557495117,
      "learning_rate": 6.001838235294118e-06,
      "loss": 0.0511,
      "step": 10010
    },
    {
      "epoch": 2.3003216911764706,
      "grad_norm": 1.337193250656128,
      "learning_rate": 6.001327614379085e-06,
      "loss": 0.0583,
      "step": 10011
    },
    {
      "epoch": 2.3005514705882355,
      "grad_norm": 0.835884690284729,
      "learning_rate": 6.000816993464052e-06,
      "loss": 0.0385,
      "step": 10012
    },
    {
      "epoch": 2.30078125,
      "grad_norm": 1.16502845287323,
      "learning_rate": 6.0003063725490194e-06,
      "loss": 0.05,
      "step": 10013
    },
    {
      "epoch": 2.3010110294117645,
      "grad_norm": 0.9540680646896362,
      "learning_rate": 5.999795751633988e-06,
      "loss": 0.0413,
      "step": 10014
    },
    {
      "epoch": 2.3012408088235294,
      "grad_norm": 0.6694636344909668,
      "learning_rate": 5.999285130718955e-06,
      "loss": 0.0317,
      "step": 10015
    },
    {
      "epoch": 2.301470588235294,
      "grad_norm": 0.7306967973709106,
      "learning_rate": 5.998774509803922e-06,
      "loss": 0.0269,
      "step": 10016
    },
    {
      "epoch": 2.301700367647059,
      "grad_norm": 1.085703730583191,
      "learning_rate": 5.998263888888889e-06,
      "loss": 0.0476,
      "step": 10017
    },
    {
      "epoch": 2.3019301470588234,
      "grad_norm": 0.934168815612793,
      "learning_rate": 5.997753267973857e-06,
      "loss": 0.0448,
      "step": 10018
    },
    {
      "epoch": 2.3021599264705883,
      "grad_norm": 0.997619092464447,
      "learning_rate": 5.997242647058824e-06,
      "loss": 0.0267,
      "step": 10019
    },
    {
      "epoch": 2.302389705882353,
      "grad_norm": 0.7640196084976196,
      "learning_rate": 5.996732026143791e-06,
      "loss": 0.0296,
      "step": 10020
    },
    {
      "epoch": 2.3026194852941178,
      "grad_norm": 0.8309303522109985,
      "learning_rate": 5.996221405228758e-06,
      "loss": 0.0471,
      "step": 10021
    },
    {
      "epoch": 2.3028492647058822,
      "grad_norm": 0.9646982550621033,
      "learning_rate": 5.995710784313726e-06,
      "loss": 0.0501,
      "step": 10022
    },
    {
      "epoch": 2.303079044117647,
      "grad_norm": 0.9829694032669067,
      "learning_rate": 5.995200163398693e-06,
      "loss": 0.0339,
      "step": 10023
    },
    {
      "epoch": 2.3033088235294117,
      "grad_norm": 1.270864486694336,
      "learning_rate": 5.994689542483661e-06,
      "loss": 0.0303,
      "step": 10024
    },
    {
      "epoch": 2.3035386029411766,
      "grad_norm": 1.0305476188659668,
      "learning_rate": 5.994178921568628e-06,
      "loss": 0.035,
      "step": 10025
    },
    {
      "epoch": 2.303768382352941,
      "grad_norm": 1.258289098739624,
      "learning_rate": 5.993668300653596e-06,
      "loss": 0.0419,
      "step": 10026
    },
    {
      "epoch": 2.303998161764706,
      "grad_norm": 1.2054967880249023,
      "learning_rate": 5.993157679738563e-06,
      "loss": 0.0559,
      "step": 10027
    },
    {
      "epoch": 2.3042279411764706,
      "grad_norm": 0.9696325659751892,
      "learning_rate": 5.99264705882353e-06,
      "loss": 0.0516,
      "step": 10028
    },
    {
      "epoch": 2.3044577205882355,
      "grad_norm": 0.8412609696388245,
      "learning_rate": 5.992136437908497e-06,
      "loss": 0.0364,
      "step": 10029
    },
    {
      "epoch": 2.3046875,
      "grad_norm": 0.86737459897995,
      "learning_rate": 5.991625816993465e-06,
      "loss": 0.0365,
      "step": 10030
    },
    {
      "epoch": 2.3049172794117645,
      "grad_norm": 0.8186423778533936,
      "learning_rate": 5.991115196078432e-06,
      "loss": 0.0349,
      "step": 10031
    },
    {
      "epoch": 2.3051470588235294,
      "grad_norm": 0.9334333539009094,
      "learning_rate": 5.990604575163399e-06,
      "loss": 0.0334,
      "step": 10032
    },
    {
      "epoch": 2.305376838235294,
      "grad_norm": 0.8276879787445068,
      "learning_rate": 5.990093954248366e-06,
      "loss": 0.0242,
      "step": 10033
    },
    {
      "epoch": 2.305606617647059,
      "grad_norm": 1.4349710941314697,
      "learning_rate": 5.989583333333334e-06,
      "loss": 0.0434,
      "step": 10034
    },
    {
      "epoch": 2.3058363970588234,
      "grad_norm": 1.2196940183639526,
      "learning_rate": 5.989072712418301e-06,
      "loss": 0.0451,
      "step": 10035
    },
    {
      "epoch": 2.3060661764705883,
      "grad_norm": 0.8764904737472534,
      "learning_rate": 5.988562091503268e-06,
      "loss": 0.049,
      "step": 10036
    },
    {
      "epoch": 2.306295955882353,
      "grad_norm": 0.7776596546173096,
      "learning_rate": 5.988051470588235e-06,
      "loss": 0.0347,
      "step": 10037
    },
    {
      "epoch": 2.3065257352941178,
      "grad_norm": 1.2038112878799438,
      "learning_rate": 5.987540849673203e-06,
      "loss": 0.0381,
      "step": 10038
    },
    {
      "epoch": 2.3067555147058822,
      "grad_norm": 1.2707512378692627,
      "learning_rate": 5.98703022875817e-06,
      "loss": 0.0498,
      "step": 10039
    },
    {
      "epoch": 2.306985294117647,
      "grad_norm": 0.9868990778923035,
      "learning_rate": 5.986519607843137e-06,
      "loss": 0.062,
      "step": 10040
    },
    {
      "epoch": 2.3072150735294117,
      "grad_norm": 0.8664569854736328,
      "learning_rate": 5.986008986928104e-06,
      "loss": 0.0243,
      "step": 10041
    },
    {
      "epoch": 2.3074448529411766,
      "grad_norm": 1.3205970525741577,
      "learning_rate": 5.985498366013073e-06,
      "loss": 0.056,
      "step": 10042
    },
    {
      "epoch": 2.307674632352941,
      "grad_norm": 0.6835888624191284,
      "learning_rate": 5.98498774509804e-06,
      "loss": 0.0276,
      "step": 10043
    },
    {
      "epoch": 2.307904411764706,
      "grad_norm": 0.9290571212768555,
      "learning_rate": 5.984477124183007e-06,
      "loss": 0.0475,
      "step": 10044
    },
    {
      "epoch": 2.3081341911764706,
      "grad_norm": 1.2458783388137817,
      "learning_rate": 5.983966503267974e-06,
      "loss": 0.0647,
      "step": 10045
    },
    {
      "epoch": 2.3083639705882355,
      "grad_norm": 1.33428156375885,
      "learning_rate": 5.983455882352942e-06,
      "loss": 0.0593,
      "step": 10046
    },
    {
      "epoch": 2.30859375,
      "grad_norm": 1.8047419786453247,
      "learning_rate": 5.982945261437909e-06,
      "loss": 0.0454,
      "step": 10047
    },
    {
      "epoch": 2.3088235294117645,
      "grad_norm": 1.1040748357772827,
      "learning_rate": 5.982434640522876e-06,
      "loss": 0.061,
      "step": 10048
    },
    {
      "epoch": 2.3090533088235294,
      "grad_norm": 0.8678873181343079,
      "learning_rate": 5.981924019607843e-06,
      "loss": 0.0332,
      "step": 10049
    },
    {
      "epoch": 2.309283088235294,
      "grad_norm": 0.8987341523170471,
      "learning_rate": 5.981413398692812e-06,
      "loss": 0.0481,
      "step": 10050
    },
    {
      "epoch": 2.309512867647059,
      "grad_norm": 1.054948329925537,
      "learning_rate": 5.980902777777779e-06,
      "loss": 0.0475,
      "step": 10051
    },
    {
      "epoch": 2.3097426470588234,
      "grad_norm": 0.8608197569847107,
      "learning_rate": 5.980392156862746e-06,
      "loss": 0.0439,
      "step": 10052
    },
    {
      "epoch": 2.3099724264705883,
      "grad_norm": 0.8640280961990356,
      "learning_rate": 5.979881535947713e-06,
      "loss": 0.0473,
      "step": 10053
    },
    {
      "epoch": 2.310202205882353,
      "grad_norm": 0.8632741570472717,
      "learning_rate": 5.979370915032681e-06,
      "loss": 0.0334,
      "step": 10054
    },
    {
      "epoch": 2.3104319852941178,
      "grad_norm": 0.8747894763946533,
      "learning_rate": 5.978860294117648e-06,
      "loss": 0.038,
      "step": 10055
    },
    {
      "epoch": 2.3106617647058822,
      "grad_norm": 0.8699251413345337,
      "learning_rate": 5.978349673202615e-06,
      "loss": 0.0506,
      "step": 10056
    },
    {
      "epoch": 2.310891544117647,
      "grad_norm": 1.1746430397033691,
      "learning_rate": 5.977839052287582e-06,
      "loss": 0.0452,
      "step": 10057
    },
    {
      "epoch": 2.3111213235294117,
      "grad_norm": 0.7985681891441345,
      "learning_rate": 5.97732843137255e-06,
      "loss": 0.0273,
      "step": 10058
    },
    {
      "epoch": 2.3113511029411766,
      "grad_norm": 1.037357211112976,
      "learning_rate": 5.976817810457517e-06,
      "loss": 0.0432,
      "step": 10059
    },
    {
      "epoch": 2.311580882352941,
      "grad_norm": 0.7320590019226074,
      "learning_rate": 5.976307189542484e-06,
      "loss": 0.0309,
      "step": 10060
    },
    {
      "epoch": 2.311810661764706,
      "grad_norm": 0.8361952900886536,
      "learning_rate": 5.975796568627451e-06,
      "loss": 0.0339,
      "step": 10061
    },
    {
      "epoch": 2.3120404411764706,
      "grad_norm": 0.8455364108085632,
      "learning_rate": 5.975285947712419e-06,
      "loss": 0.0319,
      "step": 10062
    },
    {
      "epoch": 2.3122702205882355,
      "grad_norm": 0.9556214809417725,
      "learning_rate": 5.974775326797386e-06,
      "loss": 0.0327,
      "step": 10063
    },
    {
      "epoch": 2.3125,
      "grad_norm": 0.8324152231216431,
      "learning_rate": 5.974264705882353e-06,
      "loss": 0.0377,
      "step": 10064
    },
    {
      "epoch": 2.3127297794117645,
      "grad_norm": 0.7009448409080505,
      "learning_rate": 5.97375408496732e-06,
      "loss": 0.0349,
      "step": 10065
    },
    {
      "epoch": 2.3129595588235294,
      "grad_norm": 1.239056944847107,
      "learning_rate": 5.973243464052288e-06,
      "loss": 0.0454,
      "step": 10066
    },
    {
      "epoch": 2.313189338235294,
      "grad_norm": 1.060349464416504,
      "learning_rate": 5.972732843137255e-06,
      "loss": 0.0428,
      "step": 10067
    },
    {
      "epoch": 2.313419117647059,
      "grad_norm": 0.8896430730819702,
      "learning_rate": 5.972222222222222e-06,
      "loss": 0.0347,
      "step": 10068
    },
    {
      "epoch": 2.3136488970588234,
      "grad_norm": 1.0390443801879883,
      "learning_rate": 5.97171160130719e-06,
      "loss": 0.0526,
      "step": 10069
    },
    {
      "epoch": 2.3138786764705883,
      "grad_norm": 1.0206124782562256,
      "learning_rate": 5.971200980392158e-06,
      "loss": 0.0351,
      "step": 10070
    },
    {
      "epoch": 2.314108455882353,
      "grad_norm": 0.8491817712783813,
      "learning_rate": 5.970690359477125e-06,
      "loss": 0.0519,
      "step": 10071
    },
    {
      "epoch": 2.3143382352941178,
      "grad_norm": 0.8069887757301331,
      "learning_rate": 5.970179738562092e-06,
      "loss": 0.0343,
      "step": 10072
    },
    {
      "epoch": 2.3145680147058822,
      "grad_norm": 1.1441890001296997,
      "learning_rate": 5.969669117647059e-06,
      "loss": 0.0624,
      "step": 10073
    },
    {
      "epoch": 2.314797794117647,
      "grad_norm": 0.7984508872032166,
      "learning_rate": 5.969158496732027e-06,
      "loss": 0.041,
      "step": 10074
    },
    {
      "epoch": 2.3150275735294117,
      "grad_norm": 0.8303703665733337,
      "learning_rate": 5.968647875816994e-06,
      "loss": 0.0359,
      "step": 10075
    },
    {
      "epoch": 2.3152573529411766,
      "grad_norm": 0.8142210245132446,
      "learning_rate": 5.968137254901961e-06,
      "loss": 0.0438,
      "step": 10076
    },
    {
      "epoch": 2.315487132352941,
      "grad_norm": 0.670419454574585,
      "learning_rate": 5.967626633986928e-06,
      "loss": 0.0251,
      "step": 10077
    },
    {
      "epoch": 2.315716911764706,
      "grad_norm": 1.0056259632110596,
      "learning_rate": 5.9671160130718965e-06,
      "loss": 0.0553,
      "step": 10078
    },
    {
      "epoch": 2.3159466911764706,
      "grad_norm": 1.0320186614990234,
      "learning_rate": 5.9666053921568636e-06,
      "loss": 0.0487,
      "step": 10079
    },
    {
      "epoch": 2.3161764705882355,
      "grad_norm": 0.89760422706604,
      "learning_rate": 5.966094771241831e-06,
      "loss": 0.0343,
      "step": 10080
    },
    {
      "epoch": 2.31640625,
      "grad_norm": 0.8548380732536316,
      "learning_rate": 5.965584150326798e-06,
      "loss": 0.0288,
      "step": 10081
    },
    {
      "epoch": 2.3166360294117645,
      "grad_norm": 0.9895697236061096,
      "learning_rate": 5.9650735294117655e-06,
      "loss": 0.0338,
      "step": 10082
    },
    {
      "epoch": 2.3168658088235294,
      "grad_norm": 1.1225810050964355,
      "learning_rate": 5.9645629084967325e-06,
      "loss": 0.0528,
      "step": 10083
    },
    {
      "epoch": 2.317095588235294,
      "grad_norm": 1.0044289827346802,
      "learning_rate": 5.9640522875816995e-06,
      "loss": 0.0381,
      "step": 10084
    },
    {
      "epoch": 2.317325367647059,
      "grad_norm": 1.1940090656280518,
      "learning_rate": 5.9635416666666665e-06,
      "loss": 0.0331,
      "step": 10085
    },
    {
      "epoch": 2.3175551470588234,
      "grad_norm": 1.1570760011672974,
      "learning_rate": 5.963031045751635e-06,
      "loss": 0.0517,
      "step": 10086
    },
    {
      "epoch": 2.3177849264705883,
      "grad_norm": 1.0924742221832275,
      "learning_rate": 5.962520424836602e-06,
      "loss": 0.0478,
      "step": 10087
    },
    {
      "epoch": 2.318014705882353,
      "grad_norm": 1.1339856386184692,
      "learning_rate": 5.962009803921569e-06,
      "loss": 0.0581,
      "step": 10088
    },
    {
      "epoch": 2.3182444852941178,
      "grad_norm": 0.9411295056343079,
      "learning_rate": 5.961499183006536e-06,
      "loss": 0.0329,
      "step": 10089
    },
    {
      "epoch": 2.3184742647058822,
      "grad_norm": 0.8709642291069031,
      "learning_rate": 5.960988562091504e-06,
      "loss": 0.0365,
      "step": 10090
    },
    {
      "epoch": 2.318704044117647,
      "grad_norm": 0.7989328503608704,
      "learning_rate": 5.960477941176471e-06,
      "loss": 0.0341,
      "step": 10091
    },
    {
      "epoch": 2.3189338235294117,
      "grad_norm": 0.6311403512954712,
      "learning_rate": 5.959967320261438e-06,
      "loss": 0.0191,
      "step": 10092
    },
    {
      "epoch": 2.3191636029411766,
      "grad_norm": 1.1266788244247437,
      "learning_rate": 5.959456699346405e-06,
      "loss": 0.0494,
      "step": 10093
    },
    {
      "epoch": 2.319393382352941,
      "grad_norm": 0.8035500049591064,
      "learning_rate": 5.958946078431374e-06,
      "loss": 0.0343,
      "step": 10094
    },
    {
      "epoch": 2.319623161764706,
      "grad_norm": 0.8255125880241394,
      "learning_rate": 5.958435457516341e-06,
      "loss": 0.0297,
      "step": 10095
    },
    {
      "epoch": 2.3198529411764706,
      "grad_norm": 0.8216124176979065,
      "learning_rate": 5.957924836601308e-06,
      "loss": 0.0414,
      "step": 10096
    },
    {
      "epoch": 2.3200827205882355,
      "grad_norm": 1.6486648321151733,
      "learning_rate": 5.957414215686275e-06,
      "loss": 0.0619,
      "step": 10097
    },
    {
      "epoch": 2.3203125,
      "grad_norm": 0.9426801800727844,
      "learning_rate": 5.956903594771243e-06,
      "loss": 0.0397,
      "step": 10098
    },
    {
      "epoch": 2.3205422794117645,
      "grad_norm": 0.8527064323425293,
      "learning_rate": 5.95639297385621e-06,
      "loss": 0.0401,
      "step": 10099
    },
    {
      "epoch": 2.3207720588235294,
      "grad_norm": 0.9798121452331543,
      "learning_rate": 5.955882352941177e-06,
      "loss": 0.0426,
      "step": 10100
    },
    {
      "epoch": 2.321001838235294,
      "grad_norm": 0.834833025932312,
      "learning_rate": 5.955371732026144e-06,
      "loss": 0.0398,
      "step": 10101
    },
    {
      "epoch": 2.321231617647059,
      "grad_norm": 0.81339031457901,
      "learning_rate": 5.954861111111112e-06,
      "loss": 0.0343,
      "step": 10102
    },
    {
      "epoch": 2.3214613970588234,
      "grad_norm": 0.7463461756706238,
      "learning_rate": 5.9543504901960795e-06,
      "loss": 0.0307,
      "step": 10103
    },
    {
      "epoch": 2.3216911764705883,
      "grad_norm": 0.7951806783676147,
      "learning_rate": 5.9538398692810465e-06,
      "loss": 0.0395,
      "step": 10104
    },
    {
      "epoch": 2.321920955882353,
      "grad_norm": 1.017401099205017,
      "learning_rate": 5.9533292483660136e-06,
      "loss": 0.0464,
      "step": 10105
    },
    {
      "epoch": 2.3221507352941178,
      "grad_norm": 1.1022416353225708,
      "learning_rate": 5.9528186274509814e-06,
      "loss": 0.0627,
      "step": 10106
    },
    {
      "epoch": 2.3223805147058822,
      "grad_norm": 1.0779417753219604,
      "learning_rate": 5.9523080065359484e-06,
      "loss": 0.0444,
      "step": 10107
    },
    {
      "epoch": 2.322610294117647,
      "grad_norm": 0.8510655164718628,
      "learning_rate": 5.9517973856209155e-06,
      "loss": 0.0461,
      "step": 10108
    },
    {
      "epoch": 2.3228400735294117,
      "grad_norm": 0.8332423567771912,
      "learning_rate": 5.9512867647058825e-06,
      "loss": 0.0349,
      "step": 10109
    },
    {
      "epoch": 2.3230698529411766,
      "grad_norm": 1.2338788509368896,
      "learning_rate": 5.95077614379085e-06,
      "loss": 0.0731,
      "step": 10110
    },
    {
      "epoch": 2.323299632352941,
      "grad_norm": 0.7720966339111328,
      "learning_rate": 5.950265522875817e-06,
      "loss": 0.0277,
      "step": 10111
    },
    {
      "epoch": 2.323529411764706,
      "grad_norm": 1.239963412284851,
      "learning_rate": 5.949754901960784e-06,
      "loss": 0.0456,
      "step": 10112
    },
    {
      "epoch": 2.3237591911764706,
      "grad_norm": 0.8239285945892334,
      "learning_rate": 5.949244281045752e-06,
      "loss": 0.0249,
      "step": 10113
    },
    {
      "epoch": 2.3239889705882355,
      "grad_norm": 0.8576471209526062,
      "learning_rate": 5.94873366013072e-06,
      "loss": 0.0428,
      "step": 10114
    },
    {
      "epoch": 2.32421875,
      "grad_norm": 0.7579052448272705,
      "learning_rate": 5.948223039215687e-06,
      "loss": 0.0301,
      "step": 10115
    },
    {
      "epoch": 2.3244485294117645,
      "grad_norm": 1.259333848953247,
      "learning_rate": 5.947712418300654e-06,
      "loss": 0.0575,
      "step": 10116
    },
    {
      "epoch": 2.3246783088235294,
      "grad_norm": 1.1133431196212769,
      "learning_rate": 5.947201797385621e-06,
      "loss": 0.0498,
      "step": 10117
    },
    {
      "epoch": 2.324908088235294,
      "grad_norm": 1.1984723806381226,
      "learning_rate": 5.946691176470589e-06,
      "loss": 0.038,
      "step": 10118
    },
    {
      "epoch": 2.325137867647059,
      "grad_norm": 0.819125771522522,
      "learning_rate": 5.946180555555556e-06,
      "loss": 0.0249,
      "step": 10119
    },
    {
      "epoch": 2.3253676470588234,
      "grad_norm": 1.1091495752334595,
      "learning_rate": 5.945669934640523e-06,
      "loss": 0.0455,
      "step": 10120
    },
    {
      "epoch": 2.3255974264705883,
      "grad_norm": 0.9480804800987244,
      "learning_rate": 5.94515931372549e-06,
      "loss": 0.0426,
      "step": 10121
    },
    {
      "epoch": 2.325827205882353,
      "grad_norm": 0.8976777791976929,
      "learning_rate": 5.944648692810459e-06,
      "loss": 0.0274,
      "step": 10122
    },
    {
      "epoch": 2.3260569852941178,
      "grad_norm": 1.0758943557739258,
      "learning_rate": 5.944138071895426e-06,
      "loss": 0.0535,
      "step": 10123
    },
    {
      "epoch": 2.3262867647058822,
      "grad_norm": 0.8471956849098206,
      "learning_rate": 5.943627450980393e-06,
      "loss": 0.027,
      "step": 10124
    },
    {
      "epoch": 2.326516544117647,
      "grad_norm": 0.8845623135566711,
      "learning_rate": 5.94311683006536e-06,
      "loss": 0.0369,
      "step": 10125
    },
    {
      "epoch": 2.3267463235294117,
      "grad_norm": 0.8766499757766724,
      "learning_rate": 5.942606209150328e-06,
      "loss": 0.0553,
      "step": 10126
    },
    {
      "epoch": 2.3269761029411766,
      "grad_norm": 1.0159441232681274,
      "learning_rate": 5.942095588235295e-06,
      "loss": 0.0387,
      "step": 10127
    },
    {
      "epoch": 2.327205882352941,
      "grad_norm": 0.928859293460846,
      "learning_rate": 5.941584967320262e-06,
      "loss": 0.0404,
      "step": 10128
    },
    {
      "epoch": 2.327435661764706,
      "grad_norm": 1.44892418384552,
      "learning_rate": 5.941074346405229e-06,
      "loss": 0.0582,
      "step": 10129
    },
    {
      "epoch": 2.3276654411764706,
      "grad_norm": 0.7684967517852783,
      "learning_rate": 5.940563725490197e-06,
      "loss": 0.0324,
      "step": 10130
    },
    {
      "epoch": 2.3278952205882355,
      "grad_norm": 0.6532092094421387,
      "learning_rate": 5.940053104575164e-06,
      "loss": 0.0324,
      "step": 10131
    },
    {
      "epoch": 2.328125,
      "grad_norm": 0.8854370713233948,
      "learning_rate": 5.939542483660131e-06,
      "loss": 0.0233,
      "step": 10132
    },
    {
      "epoch": 2.3283547794117645,
      "grad_norm": 1.0301607847213745,
      "learning_rate": 5.9390318627450984e-06,
      "loss": 0.0484,
      "step": 10133
    },
    {
      "epoch": 2.3285845588235294,
      "grad_norm": 0.8989688754081726,
      "learning_rate": 5.938521241830066e-06,
      "loss": 0.0205,
      "step": 10134
    },
    {
      "epoch": 2.328814338235294,
      "grad_norm": 0.8152428269386292,
      "learning_rate": 5.938010620915033e-06,
      "loss": 0.0352,
      "step": 10135
    },
    {
      "epoch": 2.329044117647059,
      "grad_norm": 0.7864273190498352,
      "learning_rate": 5.9375e-06,
      "loss": 0.034,
      "step": 10136
    },
    {
      "epoch": 2.3292738970588234,
      "grad_norm": 0.8618781566619873,
      "learning_rate": 5.936989379084967e-06,
      "loss": 0.0347,
      "step": 10137
    },
    {
      "epoch": 2.3295036764705883,
      "grad_norm": 0.7853313684463501,
      "learning_rate": 5.936478758169934e-06,
      "loss": 0.0299,
      "step": 10138
    },
    {
      "epoch": 2.329733455882353,
      "grad_norm": 1.119555115699768,
      "learning_rate": 5.935968137254903e-06,
      "loss": 0.0612,
      "step": 10139
    },
    {
      "epoch": 2.3299632352941178,
      "grad_norm": 1.0198609828948975,
      "learning_rate": 5.93545751633987e-06,
      "loss": 0.0539,
      "step": 10140
    },
    {
      "epoch": 2.3301930147058822,
      "grad_norm": 1.0648115873336792,
      "learning_rate": 5.934946895424837e-06,
      "loss": 0.0318,
      "step": 10141
    },
    {
      "epoch": 2.330422794117647,
      "grad_norm": 0.8043693900108337,
      "learning_rate": 5.934436274509804e-06,
      "loss": 0.0339,
      "step": 10142
    },
    {
      "epoch": 2.3306525735294117,
      "grad_norm": 1.1837025880813599,
      "learning_rate": 5.933925653594772e-06,
      "loss": 0.0399,
      "step": 10143
    },
    {
      "epoch": 2.3308823529411766,
      "grad_norm": 1.616936445236206,
      "learning_rate": 5.933415032679739e-06,
      "loss": 0.0935,
      "step": 10144
    },
    {
      "epoch": 2.331112132352941,
      "grad_norm": 1.0483920574188232,
      "learning_rate": 5.932904411764706e-06,
      "loss": 0.0492,
      "step": 10145
    },
    {
      "epoch": 2.331341911764706,
      "grad_norm": 0.6998242735862732,
      "learning_rate": 5.932393790849673e-06,
      "loss": 0.0215,
      "step": 10146
    },
    {
      "epoch": 2.3315716911764706,
      "grad_norm": 1.3135124444961548,
      "learning_rate": 5.931883169934642e-06,
      "loss": 0.0661,
      "step": 10147
    },
    {
      "epoch": 2.3318014705882355,
      "grad_norm": 1.277374029159546,
      "learning_rate": 5.931372549019609e-06,
      "loss": 0.0424,
      "step": 10148
    },
    {
      "epoch": 2.33203125,
      "grad_norm": 0.8891511559486389,
      "learning_rate": 5.930861928104576e-06,
      "loss": 0.0407,
      "step": 10149
    },
    {
      "epoch": 2.3322610294117645,
      "grad_norm": 1.0217156410217285,
      "learning_rate": 5.930351307189543e-06,
      "loss": 0.0445,
      "step": 10150
    },
    {
      "epoch": 2.3324908088235294,
      "grad_norm": 1.3658369779586792,
      "learning_rate": 5.929840686274511e-06,
      "loss": 0.0446,
      "step": 10151
    },
    {
      "epoch": 2.332720588235294,
      "grad_norm": 0.719078540802002,
      "learning_rate": 5.929330065359478e-06,
      "loss": 0.0346,
      "step": 10152
    },
    {
      "epoch": 2.332950367647059,
      "grad_norm": 1.1079176664352417,
      "learning_rate": 5.928819444444445e-06,
      "loss": 0.049,
      "step": 10153
    },
    {
      "epoch": 2.3331801470588234,
      "grad_norm": 1.0166910886764526,
      "learning_rate": 5.928308823529412e-06,
      "loss": 0.0651,
      "step": 10154
    },
    {
      "epoch": 2.3334099264705883,
      "grad_norm": 1.0625715255737305,
      "learning_rate": 5.9277982026143795e-06,
      "loss": 0.041,
      "step": 10155
    },
    {
      "epoch": 2.333639705882353,
      "grad_norm": 0.9425894021987915,
      "learning_rate": 5.9272875816993465e-06,
      "loss": 0.0404,
      "step": 10156
    },
    {
      "epoch": 2.3338694852941178,
      "grad_norm": 1.941606879234314,
      "learning_rate": 5.9267769607843136e-06,
      "loss": 0.0414,
      "step": 10157
    },
    {
      "epoch": 2.3340992647058822,
      "grad_norm": 0.8239161372184753,
      "learning_rate": 5.926266339869281e-06,
      "loss": 0.028,
      "step": 10158
    },
    {
      "epoch": 2.334329044117647,
      "grad_norm": 1.5922706127166748,
      "learning_rate": 5.925755718954249e-06,
      "loss": 0.023,
      "step": 10159
    },
    {
      "epoch": 2.3345588235294117,
      "grad_norm": 0.8887732028961182,
      "learning_rate": 5.925245098039216e-06,
      "loss": 0.0356,
      "step": 10160
    },
    {
      "epoch": 2.3347886029411766,
      "grad_norm": 0.7892605662345886,
      "learning_rate": 5.924734477124183e-06,
      "loss": 0.0292,
      "step": 10161
    },
    {
      "epoch": 2.335018382352941,
      "grad_norm": 0.6503090262413025,
      "learning_rate": 5.92422385620915e-06,
      "loss": 0.0298,
      "step": 10162
    },
    {
      "epoch": 2.335248161764706,
      "grad_norm": 0.927594006061554,
      "learning_rate": 5.923713235294118e-06,
      "loss": 0.0351,
      "step": 10163
    },
    {
      "epoch": 2.3354779411764706,
      "grad_norm": 0.9138369560241699,
      "learning_rate": 5.923202614379085e-06,
      "loss": 0.0421,
      "step": 10164
    },
    {
      "epoch": 2.3357077205882355,
      "grad_norm": 0.9370406866073608,
      "learning_rate": 5.922691993464052e-06,
      "loss": 0.047,
      "step": 10165
    },
    {
      "epoch": 2.3359375,
      "grad_norm": 1.256058692932129,
      "learning_rate": 5.922181372549019e-06,
      "loss": 0.0474,
      "step": 10166
    },
    {
      "epoch": 2.3361672794117645,
      "grad_norm": 0.8999924063682556,
      "learning_rate": 5.921670751633988e-06,
      "loss": 0.035,
      "step": 10167
    },
    {
      "epoch": 2.3363970588235294,
      "grad_norm": 0.9526990652084351,
      "learning_rate": 5.921160130718955e-06,
      "loss": 0.0583,
      "step": 10168
    },
    {
      "epoch": 2.336626838235294,
      "grad_norm": 0.8171693682670593,
      "learning_rate": 5.920649509803922e-06,
      "loss": 0.0433,
      "step": 10169
    },
    {
      "epoch": 2.336856617647059,
      "grad_norm": 0.8930091857910156,
      "learning_rate": 5.920138888888889e-06,
      "loss": 0.0427,
      "step": 10170
    },
    {
      "epoch": 2.3370863970588234,
      "grad_norm": 1.0562164783477783,
      "learning_rate": 5.919628267973857e-06,
      "loss": 0.0446,
      "step": 10171
    },
    {
      "epoch": 2.3373161764705883,
      "grad_norm": 1.0394868850708008,
      "learning_rate": 5.919117647058824e-06,
      "loss": 0.0224,
      "step": 10172
    },
    {
      "epoch": 2.337545955882353,
      "grad_norm": 0.8320863246917725,
      "learning_rate": 5.918607026143791e-06,
      "loss": 0.057,
      "step": 10173
    },
    {
      "epoch": 2.3377757352941178,
      "grad_norm": 1.1269479990005493,
      "learning_rate": 5.918096405228758e-06,
      "loss": 0.0444,
      "step": 10174
    },
    {
      "epoch": 2.3380055147058822,
      "grad_norm": 0.9546303749084473,
      "learning_rate": 5.917585784313727e-06,
      "loss": 0.0448,
      "step": 10175
    },
    {
      "epoch": 2.338235294117647,
      "grad_norm": 0.9469185471534729,
      "learning_rate": 5.917075163398694e-06,
      "loss": 0.0352,
      "step": 10176
    },
    {
      "epoch": 2.3384650735294117,
      "grad_norm": 0.9631643891334534,
      "learning_rate": 5.916564542483661e-06,
      "loss": 0.0453,
      "step": 10177
    },
    {
      "epoch": 2.3386948529411766,
      "grad_norm": 0.9137976765632629,
      "learning_rate": 5.916053921568628e-06,
      "loss": 0.0541,
      "step": 10178
    },
    {
      "epoch": 2.338924632352941,
      "grad_norm": 0.9352156519889832,
      "learning_rate": 5.9155433006535955e-06,
      "loss": 0.043,
      "step": 10179
    },
    {
      "epoch": 2.339154411764706,
      "grad_norm": 0.742583692073822,
      "learning_rate": 5.9150326797385625e-06,
      "loss": 0.0254,
      "step": 10180
    },
    {
      "epoch": 2.3393841911764706,
      "grad_norm": 1.2793190479278564,
      "learning_rate": 5.9145220588235295e-06,
      "loss": 0.0547,
      "step": 10181
    },
    {
      "epoch": 2.3396139705882355,
      "grad_norm": 0.8875153064727783,
      "learning_rate": 5.9140114379084965e-06,
      "loss": 0.0443,
      "step": 10182
    },
    {
      "epoch": 2.33984375,
      "grad_norm": 0.9371885657310486,
      "learning_rate": 5.913500816993465e-06,
      "loss": 0.0435,
      "step": 10183
    },
    {
      "epoch": 2.3400735294117645,
      "grad_norm": 1.1227023601531982,
      "learning_rate": 5.912990196078432e-06,
      "loss": 0.0499,
      "step": 10184
    },
    {
      "epoch": 2.3403033088235294,
      "grad_norm": 1.1352431774139404,
      "learning_rate": 5.912479575163399e-06,
      "loss": 0.0559,
      "step": 10185
    },
    {
      "epoch": 2.340533088235294,
      "grad_norm": 0.9176682829856873,
      "learning_rate": 5.911968954248366e-06,
      "loss": 0.041,
      "step": 10186
    },
    {
      "epoch": 2.340762867647059,
      "grad_norm": 0.8251376152038574,
      "learning_rate": 5.911458333333334e-06,
      "loss": 0.0297,
      "step": 10187
    },
    {
      "epoch": 2.3409926470588234,
      "grad_norm": 0.9188358783721924,
      "learning_rate": 5.910947712418301e-06,
      "loss": 0.0289,
      "step": 10188
    },
    {
      "epoch": 2.3412224264705883,
      "grad_norm": 0.7197123765945435,
      "learning_rate": 5.910437091503268e-06,
      "loss": 0.0401,
      "step": 10189
    },
    {
      "epoch": 2.341452205882353,
      "grad_norm": 0.9689906239509583,
      "learning_rate": 5.909926470588235e-06,
      "loss": 0.0497,
      "step": 10190
    },
    {
      "epoch": 2.3416819852941178,
      "grad_norm": 1.1368733644485474,
      "learning_rate": 5.909415849673203e-06,
      "loss": 0.0445,
      "step": 10191
    },
    {
      "epoch": 2.3419117647058822,
      "grad_norm": 1.0030144453048706,
      "learning_rate": 5.908905228758171e-06,
      "loss": 0.0424,
      "step": 10192
    },
    {
      "epoch": 2.342141544117647,
      "grad_norm": 1.4246413707733154,
      "learning_rate": 5.908394607843138e-06,
      "loss": 0.0343,
      "step": 10193
    },
    {
      "epoch": 2.3423713235294117,
      "grad_norm": 0.8655084371566772,
      "learning_rate": 5.907883986928105e-06,
      "loss": 0.0376,
      "step": 10194
    },
    {
      "epoch": 2.3426011029411766,
      "grad_norm": 0.9251366257667542,
      "learning_rate": 5.907373366013073e-06,
      "loss": 0.0495,
      "step": 10195
    },
    {
      "epoch": 2.342830882352941,
      "grad_norm": 1.1154592037200928,
      "learning_rate": 5.90686274509804e-06,
      "loss": 0.0611,
      "step": 10196
    },
    {
      "epoch": 2.343060661764706,
      "grad_norm": 0.7573961019515991,
      "learning_rate": 5.906352124183007e-06,
      "loss": 0.0219,
      "step": 10197
    },
    {
      "epoch": 2.3432904411764706,
      "grad_norm": 1.317381739616394,
      "learning_rate": 5.905841503267974e-06,
      "loss": 0.0604,
      "step": 10198
    },
    {
      "epoch": 2.3435202205882355,
      "grad_norm": 0.9886758327484131,
      "learning_rate": 5.905330882352942e-06,
      "loss": 0.0526,
      "step": 10199
    },
    {
      "epoch": 2.34375,
      "grad_norm": 0.9858144521713257,
      "learning_rate": 5.904820261437909e-06,
      "loss": 0.0374,
      "step": 10200
    },
    {
      "epoch": 2.3439797794117645,
      "grad_norm": 0.8981735706329346,
      "learning_rate": 5.904309640522876e-06,
      "loss": 0.0393,
      "step": 10201
    },
    {
      "epoch": 2.3442095588235294,
      "grad_norm": 1.0574164390563965,
      "learning_rate": 5.903799019607844e-06,
      "loss": 0.0338,
      "step": 10202
    },
    {
      "epoch": 2.344439338235294,
      "grad_norm": 0.9588950276374817,
      "learning_rate": 5.9032883986928115e-06,
      "loss": 0.0369,
      "step": 10203
    },
    {
      "epoch": 2.344669117647059,
      "grad_norm": 0.9420584440231323,
      "learning_rate": 5.9027777777777785e-06,
      "loss": 0.0426,
      "step": 10204
    },
    {
      "epoch": 2.3448988970588234,
      "grad_norm": 0.6921296715736389,
      "learning_rate": 5.9022671568627455e-06,
      "loss": 0.0296,
      "step": 10205
    },
    {
      "epoch": 2.3451286764705883,
      "grad_norm": 0.8450009226799011,
      "learning_rate": 5.9017565359477125e-06,
      "loss": 0.0364,
      "step": 10206
    },
    {
      "epoch": 2.345358455882353,
      "grad_norm": 1.0228298902511597,
      "learning_rate": 5.90124591503268e-06,
      "loss": 0.0465,
      "step": 10207
    },
    {
      "epoch": 2.3455882352941178,
      "grad_norm": 0.9100966453552246,
      "learning_rate": 5.900735294117647e-06,
      "loss": 0.0484,
      "step": 10208
    },
    {
      "epoch": 2.3458180147058822,
      "grad_norm": 0.6344591975212097,
      "learning_rate": 5.900224673202614e-06,
      "loss": 0.0263,
      "step": 10209
    },
    {
      "epoch": 2.346047794117647,
      "grad_norm": 0.8414310216903687,
      "learning_rate": 5.899714052287581e-06,
      "loss": 0.031,
      "step": 10210
    },
    {
      "epoch": 2.3462775735294117,
      "grad_norm": 1.075627326965332,
      "learning_rate": 5.89920343137255e-06,
      "loss": 0.0473,
      "step": 10211
    },
    {
      "epoch": 2.3465073529411766,
      "grad_norm": 1.4611397981643677,
      "learning_rate": 5.898692810457517e-06,
      "loss": 0.0597,
      "step": 10212
    },
    {
      "epoch": 2.346737132352941,
      "grad_norm": 0.7781912088394165,
      "learning_rate": 5.898182189542484e-06,
      "loss": 0.0228,
      "step": 10213
    },
    {
      "epoch": 2.346966911764706,
      "grad_norm": 1.020246982574463,
      "learning_rate": 5.897671568627451e-06,
      "loss": 0.0389,
      "step": 10214
    },
    {
      "epoch": 2.3471966911764706,
      "grad_norm": 0.9510996341705322,
      "learning_rate": 5.897160947712419e-06,
      "loss": 0.0449,
      "step": 10215
    },
    {
      "epoch": 2.3474264705882355,
      "grad_norm": 0.8047500252723694,
      "learning_rate": 5.896650326797386e-06,
      "loss": 0.0337,
      "step": 10216
    },
    {
      "epoch": 2.34765625,
      "grad_norm": 0.8236491084098816,
      "learning_rate": 5.896139705882353e-06,
      "loss": 0.029,
      "step": 10217
    },
    {
      "epoch": 2.3478860294117645,
      "grad_norm": 0.8177395462989807,
      "learning_rate": 5.89562908496732e-06,
      "loss": 0.0366,
      "step": 10218
    },
    {
      "epoch": 2.3481158088235294,
      "grad_norm": 1.203020691871643,
      "learning_rate": 5.895118464052289e-06,
      "loss": 0.0537,
      "step": 10219
    },
    {
      "epoch": 2.348345588235294,
      "grad_norm": 1.1334799528121948,
      "learning_rate": 5.894607843137256e-06,
      "loss": 0.0542,
      "step": 10220
    },
    {
      "epoch": 2.348575367647059,
      "grad_norm": 1.2265245914459229,
      "learning_rate": 5.894097222222223e-06,
      "loss": 0.0309,
      "step": 10221
    },
    {
      "epoch": 2.3488051470588234,
      "grad_norm": 0.885250985622406,
      "learning_rate": 5.89358660130719e-06,
      "loss": 0.0343,
      "step": 10222
    },
    {
      "epoch": 2.3490349264705883,
      "grad_norm": 1.1620876789093018,
      "learning_rate": 5.893075980392158e-06,
      "loss": 0.046,
      "step": 10223
    },
    {
      "epoch": 2.349264705882353,
      "grad_norm": 0.8179683089256287,
      "learning_rate": 5.892565359477125e-06,
      "loss": 0.0344,
      "step": 10224
    },
    {
      "epoch": 2.3494944852941178,
      "grad_norm": 1.1935577392578125,
      "learning_rate": 5.892054738562092e-06,
      "loss": 0.0588,
      "step": 10225
    },
    {
      "epoch": 2.3497242647058822,
      "grad_norm": 1.1662660837173462,
      "learning_rate": 5.891544117647059e-06,
      "loss": 0.0567,
      "step": 10226
    },
    {
      "epoch": 2.349954044117647,
      "grad_norm": 0.8172292113304138,
      "learning_rate": 5.8910334967320274e-06,
      "loss": 0.0316,
      "step": 10227
    },
    {
      "epoch": 2.3501838235294117,
      "grad_norm": 1.0687918663024902,
      "learning_rate": 5.8905228758169945e-06,
      "loss": 0.0414,
      "step": 10228
    },
    {
      "epoch": 2.3504136029411766,
      "grad_norm": 0.6655762195587158,
      "learning_rate": 5.8900122549019615e-06,
      "loss": 0.0276,
      "step": 10229
    },
    {
      "epoch": 2.350643382352941,
      "grad_norm": 1.3608874082565308,
      "learning_rate": 5.8895016339869285e-06,
      "loss": 0.0762,
      "step": 10230
    },
    {
      "epoch": 2.350873161764706,
      "grad_norm": 1.0086137056350708,
      "learning_rate": 5.888991013071896e-06,
      "loss": 0.0368,
      "step": 10231
    },
    {
      "epoch": 2.3511029411764706,
      "grad_norm": 0.9727194309234619,
      "learning_rate": 5.888480392156863e-06,
      "loss": 0.0409,
      "step": 10232
    },
    {
      "epoch": 2.3513327205882355,
      "grad_norm": 0.7156863808631897,
      "learning_rate": 5.88796977124183e-06,
      "loss": 0.0293,
      "step": 10233
    },
    {
      "epoch": 2.3515625,
      "grad_norm": 0.9417368769645691,
      "learning_rate": 5.887459150326797e-06,
      "loss": 0.0456,
      "step": 10234
    },
    {
      "epoch": 2.3517922794117645,
      "grad_norm": 1.0730140209197998,
      "learning_rate": 5.886948529411765e-06,
      "loss": 0.0411,
      "step": 10235
    },
    {
      "epoch": 2.3520220588235294,
      "grad_norm": 0.7755621671676636,
      "learning_rate": 5.886437908496733e-06,
      "loss": 0.0346,
      "step": 10236
    },
    {
      "epoch": 2.352251838235294,
      "grad_norm": 1.111533522605896,
      "learning_rate": 5.8859272875817e-06,
      "loss": 0.0594,
      "step": 10237
    },
    {
      "epoch": 2.352481617647059,
      "grad_norm": 1.3058584928512573,
      "learning_rate": 5.885416666666667e-06,
      "loss": 0.0562,
      "step": 10238
    },
    {
      "epoch": 2.3527113970588234,
      "grad_norm": 0.9080166816711426,
      "learning_rate": 5.884906045751635e-06,
      "loss": 0.0322,
      "step": 10239
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 0.9988443851470947,
      "learning_rate": 5.884395424836602e-06,
      "loss": 0.0408,
      "step": 10240
    },
    {
      "epoch": 2.353170955882353,
      "grad_norm": 0.8827731609344482,
      "learning_rate": 5.883884803921569e-06,
      "loss": 0.0355,
      "step": 10241
    },
    {
      "epoch": 2.3534007352941178,
      "grad_norm": 0.9165476560592651,
      "learning_rate": 5.883374183006536e-06,
      "loss": 0.0343,
      "step": 10242
    },
    {
      "epoch": 2.3536305147058822,
      "grad_norm": 0.9364675879478455,
      "learning_rate": 5.882863562091504e-06,
      "loss": 0.0479,
      "step": 10243
    },
    {
      "epoch": 2.353860294117647,
      "grad_norm": 0.8625759482383728,
      "learning_rate": 5.882352941176471e-06,
      "loss": 0.0251,
      "step": 10244
    },
    {
      "epoch": 2.3540900735294117,
      "grad_norm": 1.1481682062149048,
      "learning_rate": 5.881842320261438e-06,
      "loss": 0.0477,
      "step": 10245
    },
    {
      "epoch": 2.3543198529411766,
      "grad_norm": 0.9754394888877869,
      "learning_rate": 5.881331699346405e-06,
      "loss": 0.0387,
      "step": 10246
    },
    {
      "epoch": 2.354549632352941,
      "grad_norm": 1.0303550958633423,
      "learning_rate": 5.880821078431374e-06,
      "loss": 0.0346,
      "step": 10247
    },
    {
      "epoch": 2.354779411764706,
      "grad_norm": 0.7308780550956726,
      "learning_rate": 5.880310457516341e-06,
      "loss": 0.025,
      "step": 10248
    },
    {
      "epoch": 2.3550091911764706,
      "grad_norm": 1.3027106523513794,
      "learning_rate": 5.879799836601308e-06,
      "loss": 0.0789,
      "step": 10249
    },
    {
      "epoch": 2.3552389705882355,
      "grad_norm": 2.3302016258239746,
      "learning_rate": 5.879289215686275e-06,
      "loss": 0.0291,
      "step": 10250
    },
    {
      "epoch": 2.35546875,
      "grad_norm": 1.0364158153533936,
      "learning_rate": 5.8787785947712426e-06,
      "loss": 0.0341,
      "step": 10251
    },
    {
      "epoch": 2.3556985294117645,
      "grad_norm": 0.9045392870903015,
      "learning_rate": 5.87826797385621e-06,
      "loss": 0.0475,
      "step": 10252
    },
    {
      "epoch": 2.3559283088235294,
      "grad_norm": 1.5914466381072998,
      "learning_rate": 5.877757352941177e-06,
      "loss": 0.0759,
      "step": 10253
    },
    {
      "epoch": 2.356158088235294,
      "grad_norm": 1.294150710105896,
      "learning_rate": 5.877246732026144e-06,
      "loss": 0.0538,
      "step": 10254
    },
    {
      "epoch": 2.356387867647059,
      "grad_norm": 0.8071292638778687,
      "learning_rate": 5.876736111111112e-06,
      "loss": 0.0234,
      "step": 10255
    },
    {
      "epoch": 2.3566176470588234,
      "grad_norm": 0.8300054669380188,
      "learning_rate": 5.876225490196079e-06,
      "loss": 0.0289,
      "step": 10256
    },
    {
      "epoch": 2.3568474264705883,
      "grad_norm": 0.9261354804039001,
      "learning_rate": 5.875714869281046e-06,
      "loss": 0.0497,
      "step": 10257
    },
    {
      "epoch": 2.357077205882353,
      "grad_norm": 0.9617864489555359,
      "learning_rate": 5.875204248366013e-06,
      "loss": 0.0474,
      "step": 10258
    },
    {
      "epoch": 2.3573069852941178,
      "grad_norm": 0.8460677266120911,
      "learning_rate": 5.874693627450981e-06,
      "loss": 0.0321,
      "step": 10259
    },
    {
      "epoch": 2.3575367647058822,
      "grad_norm": 0.9368451237678528,
      "learning_rate": 5.874183006535948e-06,
      "loss": 0.0453,
      "step": 10260
    },
    {
      "epoch": 2.357766544117647,
      "grad_norm": 1.7208176851272583,
      "learning_rate": 5.873672385620915e-06,
      "loss": 0.0318,
      "step": 10261
    },
    {
      "epoch": 2.3579963235294117,
      "grad_norm": 1.1195435523986816,
      "learning_rate": 5.873161764705882e-06,
      "loss": 0.0438,
      "step": 10262
    },
    {
      "epoch": 2.3582261029411766,
      "grad_norm": 1.0120973587036133,
      "learning_rate": 5.872651143790851e-06,
      "loss": 0.0482,
      "step": 10263
    },
    {
      "epoch": 2.358455882352941,
      "grad_norm": 1.039428472518921,
      "learning_rate": 5.872140522875818e-06,
      "loss": 0.0361,
      "step": 10264
    },
    {
      "epoch": 2.358685661764706,
      "grad_norm": 0.7102312445640564,
      "learning_rate": 5.871629901960785e-06,
      "loss": 0.0176,
      "step": 10265
    },
    {
      "epoch": 2.3589154411764706,
      "grad_norm": 0.934380054473877,
      "learning_rate": 5.871119281045752e-06,
      "loss": 0.0391,
      "step": 10266
    },
    {
      "epoch": 2.3591452205882355,
      "grad_norm": 0.9727998375892639,
      "learning_rate": 5.87060866013072e-06,
      "loss": 0.0358,
      "step": 10267
    },
    {
      "epoch": 2.359375,
      "grad_norm": 0.9062250256538391,
      "learning_rate": 5.870098039215687e-06,
      "loss": 0.0365,
      "step": 10268
    },
    {
      "epoch": 2.3596047794117645,
      "grad_norm": 0.8281701803207397,
      "learning_rate": 5.869587418300654e-06,
      "loss": 0.0462,
      "step": 10269
    },
    {
      "epoch": 2.3598345588235294,
      "grad_norm": 0.9211028218269348,
      "learning_rate": 5.869076797385621e-06,
      "loss": 0.0552,
      "step": 10270
    },
    {
      "epoch": 2.360064338235294,
      "grad_norm": 1.0080291032791138,
      "learning_rate": 5.86856617647059e-06,
      "loss": 0.0301,
      "step": 10271
    },
    {
      "epoch": 2.360294117647059,
      "grad_norm": 1.4254486560821533,
      "learning_rate": 5.868055555555557e-06,
      "loss": 0.0515,
      "step": 10272
    },
    {
      "epoch": 2.3605238970588234,
      "grad_norm": 0.9577931761741638,
      "learning_rate": 5.867544934640524e-06,
      "loss": 0.044,
      "step": 10273
    },
    {
      "epoch": 2.3607536764705883,
      "grad_norm": 1.2903871536254883,
      "learning_rate": 5.867034313725491e-06,
      "loss": 0.0678,
      "step": 10274
    },
    {
      "epoch": 2.360983455882353,
      "grad_norm": 1.0892714262008667,
      "learning_rate": 5.8665236928104585e-06,
      "loss": 0.059,
      "step": 10275
    },
    {
      "epoch": 2.3612132352941178,
      "grad_norm": 1.0132055282592773,
      "learning_rate": 5.8660130718954255e-06,
      "loss": 0.0358,
      "step": 10276
    },
    {
      "epoch": 2.3614430147058822,
      "grad_norm": 0.9944836497306824,
      "learning_rate": 5.8655024509803926e-06,
      "loss": 0.0435,
      "step": 10277
    },
    {
      "epoch": 2.361672794117647,
      "grad_norm": 1.446402668952942,
      "learning_rate": 5.8649918300653596e-06,
      "loss": 0.0444,
      "step": 10278
    },
    {
      "epoch": 2.3619025735294117,
      "grad_norm": 0.9176732897758484,
      "learning_rate": 5.8644812091503274e-06,
      "loss": 0.0334,
      "step": 10279
    },
    {
      "epoch": 2.3621323529411766,
      "grad_norm": 0.8103154897689819,
      "learning_rate": 5.8639705882352945e-06,
      "loss": 0.0396,
      "step": 10280
    },
    {
      "epoch": 2.362362132352941,
      "grad_norm": 1.1505268812179565,
      "learning_rate": 5.863459967320262e-06,
      "loss": 0.0729,
      "step": 10281
    },
    {
      "epoch": 2.362591911764706,
      "grad_norm": 0.6646724939346313,
      "learning_rate": 5.862949346405229e-06,
      "loss": 0.0285,
      "step": 10282
    },
    {
      "epoch": 2.3628216911764706,
      "grad_norm": 0.5755611062049866,
      "learning_rate": 5.862438725490197e-06,
      "loss": 0.0195,
      "step": 10283
    },
    {
      "epoch": 2.3630514705882355,
      "grad_norm": 1.0769098997116089,
      "learning_rate": 5.861928104575164e-06,
      "loss": 0.0502,
      "step": 10284
    },
    {
      "epoch": 2.36328125,
      "grad_norm": 0.8577038645744324,
      "learning_rate": 5.861417483660131e-06,
      "loss": 0.0452,
      "step": 10285
    },
    {
      "epoch": 2.3635110294117645,
      "grad_norm": 1.2772412300109863,
      "learning_rate": 5.860906862745098e-06,
      "loss": 0.0471,
      "step": 10286
    },
    {
      "epoch": 2.3637408088235294,
      "grad_norm": 1.1966220140457153,
      "learning_rate": 5.860396241830066e-06,
      "loss": 0.0321,
      "step": 10287
    },
    {
      "epoch": 2.363970588235294,
      "grad_norm": 0.8635609745979309,
      "learning_rate": 5.859885620915033e-06,
      "loss": 0.0464,
      "step": 10288
    },
    {
      "epoch": 2.364200367647059,
      "grad_norm": 1.241697907447815,
      "learning_rate": 5.859375e-06,
      "loss": 0.0626,
      "step": 10289
    },
    {
      "epoch": 2.3644301470588234,
      "grad_norm": 1.0623047351837158,
      "learning_rate": 5.858864379084967e-06,
      "loss": 0.0381,
      "step": 10290
    },
    {
      "epoch": 2.3646599264705883,
      "grad_norm": 1.0476640462875366,
      "learning_rate": 5.858353758169934e-06,
      "loss": 0.0456,
      "step": 10291
    },
    {
      "epoch": 2.364889705882353,
      "grad_norm": 0.8898147344589233,
      "learning_rate": 5.857843137254903e-06,
      "loss": 0.0361,
      "step": 10292
    },
    {
      "epoch": 2.3651194852941178,
      "grad_norm": 0.8729804158210754,
      "learning_rate": 5.85733251633987e-06,
      "loss": 0.0444,
      "step": 10293
    },
    {
      "epoch": 2.3653492647058822,
      "grad_norm": 0.8702328205108643,
      "learning_rate": 5.856821895424837e-06,
      "loss": 0.0339,
      "step": 10294
    },
    {
      "epoch": 2.365579044117647,
      "grad_norm": 1.05500328540802,
      "learning_rate": 5.856311274509804e-06,
      "loss": 0.0525,
      "step": 10295
    },
    {
      "epoch": 2.3658088235294117,
      "grad_norm": 0.9658532738685608,
      "learning_rate": 5.855800653594772e-06,
      "loss": 0.0504,
      "step": 10296
    },
    {
      "epoch": 2.3660386029411766,
      "grad_norm": 0.8280997276306152,
      "learning_rate": 5.855290032679739e-06,
      "loss": 0.0398,
      "step": 10297
    },
    {
      "epoch": 2.366268382352941,
      "grad_norm": 0.9753674268722534,
      "learning_rate": 5.854779411764706e-06,
      "loss": 0.0381,
      "step": 10298
    },
    {
      "epoch": 2.366498161764706,
      "grad_norm": 0.9441157579421997,
      "learning_rate": 5.854268790849673e-06,
      "loss": 0.0474,
      "step": 10299
    },
    {
      "epoch": 2.3667279411764706,
      "grad_norm": 1.2101576328277588,
      "learning_rate": 5.8537581699346415e-06,
      "loss": 0.058,
      "step": 10300
    },
    {
      "epoch": 2.3669577205882355,
      "grad_norm": 0.7945454716682434,
      "learning_rate": 5.8532475490196085e-06,
      "loss": 0.0379,
      "step": 10301
    },
    {
      "epoch": 2.3671875,
      "grad_norm": 0.7590590715408325,
      "learning_rate": 5.8527369281045755e-06,
      "loss": 0.0298,
      "step": 10302
    },
    {
      "epoch": 2.3674172794117645,
      "grad_norm": 1.2075610160827637,
      "learning_rate": 5.8522263071895426e-06,
      "loss": 0.0482,
      "step": 10303
    },
    {
      "epoch": 2.3676470588235294,
      "grad_norm": 0.9981496334075928,
      "learning_rate": 5.85171568627451e-06,
      "loss": 0.0594,
      "step": 10304
    },
    {
      "epoch": 2.367876838235294,
      "grad_norm": 0.9074117541313171,
      "learning_rate": 5.8512050653594774e-06,
      "loss": 0.0417,
      "step": 10305
    },
    {
      "epoch": 2.368106617647059,
      "grad_norm": 0.992902934551239,
      "learning_rate": 5.8506944444444444e-06,
      "loss": 0.0391,
      "step": 10306
    },
    {
      "epoch": 2.3683363970588234,
      "grad_norm": 0.8265333771705627,
      "learning_rate": 5.8501838235294115e-06,
      "loss": 0.0447,
      "step": 10307
    },
    {
      "epoch": 2.3685661764705883,
      "grad_norm": 1.1190853118896484,
      "learning_rate": 5.84967320261438e-06,
      "loss": 0.0461,
      "step": 10308
    },
    {
      "epoch": 2.368795955882353,
      "grad_norm": 1.0481255054473877,
      "learning_rate": 5.849162581699347e-06,
      "loss": 0.0504,
      "step": 10309
    },
    {
      "epoch": 2.3690257352941178,
      "grad_norm": 0.9554367065429688,
      "learning_rate": 5.848651960784314e-06,
      "loss": 0.0399,
      "step": 10310
    },
    {
      "epoch": 2.3692555147058822,
      "grad_norm": 0.6994929909706116,
      "learning_rate": 5.848141339869281e-06,
      "loss": 0.0301,
      "step": 10311
    },
    {
      "epoch": 2.369485294117647,
      "grad_norm": 0.8760294914245605,
      "learning_rate": 5.847630718954249e-06,
      "loss": 0.0515,
      "step": 10312
    },
    {
      "epoch": 2.3697150735294117,
      "grad_norm": 0.9510068893432617,
      "learning_rate": 5.847120098039216e-06,
      "loss": 0.0514,
      "step": 10313
    },
    {
      "epoch": 2.3699448529411766,
      "grad_norm": 0.8297197818756104,
      "learning_rate": 5.846609477124183e-06,
      "loss": 0.0384,
      "step": 10314
    },
    {
      "epoch": 2.370174632352941,
      "grad_norm": 0.9267697930335999,
      "learning_rate": 5.84609885620915e-06,
      "loss": 0.0405,
      "step": 10315
    },
    {
      "epoch": 2.370404411764706,
      "grad_norm": 0.801157534122467,
      "learning_rate": 5.845588235294119e-06,
      "loss": 0.033,
      "step": 10316
    },
    {
      "epoch": 2.3706341911764706,
      "grad_norm": 0.9047189354896545,
      "learning_rate": 5.845077614379086e-06,
      "loss": 0.0326,
      "step": 10317
    },
    {
      "epoch": 2.3708639705882355,
      "grad_norm": 0.9261645674705505,
      "learning_rate": 5.844566993464053e-06,
      "loss": 0.0345,
      "step": 10318
    },
    {
      "epoch": 2.37109375,
      "grad_norm": 0.992220938205719,
      "learning_rate": 5.84405637254902e-06,
      "loss": 0.0334,
      "step": 10319
    },
    {
      "epoch": 2.3713235294117645,
      "grad_norm": 1.0398998260498047,
      "learning_rate": 5.843545751633988e-06,
      "loss": 0.0472,
      "step": 10320
    },
    {
      "epoch": 2.3715533088235294,
      "grad_norm": 0.907872200012207,
      "learning_rate": 5.843035130718955e-06,
      "loss": 0.0518,
      "step": 10321
    },
    {
      "epoch": 2.371783088235294,
      "grad_norm": 0.8782650828361511,
      "learning_rate": 5.842524509803922e-06,
      "loss": 0.0372,
      "step": 10322
    },
    {
      "epoch": 2.372012867647059,
      "grad_norm": 1.504034399986267,
      "learning_rate": 5.842013888888889e-06,
      "loss": 0.086,
      "step": 10323
    },
    {
      "epoch": 2.3722426470588234,
      "grad_norm": 0.9942247867584229,
      "learning_rate": 5.841503267973857e-06,
      "loss": 0.049,
      "step": 10324
    },
    {
      "epoch": 2.3724724264705883,
      "grad_norm": 0.9866488575935364,
      "learning_rate": 5.840992647058824e-06,
      "loss": 0.0518,
      "step": 10325
    },
    {
      "epoch": 2.372702205882353,
      "grad_norm": 1.1535197496414185,
      "learning_rate": 5.8404820261437915e-06,
      "loss": 0.0452,
      "step": 10326
    },
    {
      "epoch": 2.3729319852941178,
      "grad_norm": 0.999393880367279,
      "learning_rate": 5.8399714052287585e-06,
      "loss": 0.0335,
      "step": 10327
    },
    {
      "epoch": 2.3731617647058822,
      "grad_norm": 0.7476392984390259,
      "learning_rate": 5.839460784313726e-06,
      "loss": 0.0275,
      "step": 10328
    },
    {
      "epoch": 2.373391544117647,
      "grad_norm": 1.5008271932601929,
      "learning_rate": 5.838950163398693e-06,
      "loss": 0.081,
      "step": 10329
    },
    {
      "epoch": 2.3736213235294117,
      "grad_norm": 0.6641258597373962,
      "learning_rate": 5.83843954248366e-06,
      "loss": 0.0374,
      "step": 10330
    },
    {
      "epoch": 2.3738511029411766,
      "grad_norm": 0.8108391761779785,
      "learning_rate": 5.8379289215686274e-06,
      "loss": 0.0353,
      "step": 10331
    },
    {
      "epoch": 2.374080882352941,
      "grad_norm": 0.7236417531967163,
      "learning_rate": 5.837418300653595e-06,
      "loss": 0.0262,
      "step": 10332
    },
    {
      "epoch": 2.374310661764706,
      "grad_norm": 0.7836652994155884,
      "learning_rate": 5.836907679738562e-06,
      "loss": 0.0334,
      "step": 10333
    },
    {
      "epoch": 2.3745404411764706,
      "grad_norm": 0.6921998858451843,
      "learning_rate": 5.836397058823529e-06,
      "loss": 0.0412,
      "step": 10334
    },
    {
      "epoch": 2.3747702205882355,
      "grad_norm": 0.7305458784103394,
      "learning_rate": 5.835886437908496e-06,
      "loss": 0.0234,
      "step": 10335
    },
    {
      "epoch": 2.375,
      "grad_norm": 0.8777416944503784,
      "learning_rate": 5.835375816993465e-06,
      "loss": 0.0414,
      "step": 10336
    },
    {
      "epoch": 2.3752297794117645,
      "grad_norm": 0.753089189529419,
      "learning_rate": 5.834865196078432e-06,
      "loss": 0.0347,
      "step": 10337
    },
    {
      "epoch": 2.3754595588235294,
      "grad_norm": 0.9709012508392334,
      "learning_rate": 5.834354575163399e-06,
      "loss": 0.0458,
      "step": 10338
    },
    {
      "epoch": 2.375689338235294,
      "grad_norm": 1.3047007322311401,
      "learning_rate": 5.833843954248366e-06,
      "loss": 0.0457,
      "step": 10339
    },
    {
      "epoch": 2.375919117647059,
      "grad_norm": 1.0514922142028809,
      "learning_rate": 5.833333333333334e-06,
      "loss": 0.0505,
      "step": 10340
    },
    {
      "epoch": 2.3761488970588234,
      "grad_norm": 0.7000536322593689,
      "learning_rate": 5.832822712418301e-06,
      "loss": 0.03,
      "step": 10341
    },
    {
      "epoch": 2.3763786764705883,
      "grad_norm": 1.161292314529419,
      "learning_rate": 5.832312091503268e-06,
      "loss": 0.0414,
      "step": 10342
    },
    {
      "epoch": 2.376608455882353,
      "grad_norm": 0.8955392241477966,
      "learning_rate": 5.831801470588235e-06,
      "loss": 0.0327,
      "step": 10343
    },
    {
      "epoch": 2.3768382352941178,
      "grad_norm": 1.0044833421707153,
      "learning_rate": 5.831290849673204e-06,
      "loss": 0.0318,
      "step": 10344
    },
    {
      "epoch": 2.3770680147058822,
      "grad_norm": 0.879870593547821,
      "learning_rate": 5.830780228758171e-06,
      "loss": 0.0429,
      "step": 10345
    },
    {
      "epoch": 2.377297794117647,
      "grad_norm": 1.1791794300079346,
      "learning_rate": 5.830269607843138e-06,
      "loss": 0.0306,
      "step": 10346
    },
    {
      "epoch": 2.3775275735294117,
      "grad_norm": 1.0742506980895996,
      "learning_rate": 5.829758986928105e-06,
      "loss": 0.0538,
      "step": 10347
    },
    {
      "epoch": 2.3777573529411766,
      "grad_norm": 0.7067326903343201,
      "learning_rate": 5.829248366013073e-06,
      "loss": 0.0345,
      "step": 10348
    },
    {
      "epoch": 2.377987132352941,
      "grad_norm": 1.655717134475708,
      "learning_rate": 5.82873774509804e-06,
      "loss": 0.0365,
      "step": 10349
    },
    {
      "epoch": 2.378216911764706,
      "grad_norm": 1.3692294359207153,
      "learning_rate": 5.828227124183007e-06,
      "loss": 0.0481,
      "step": 10350
    },
    {
      "epoch": 2.3784466911764706,
      "grad_norm": 1.119408369064331,
      "learning_rate": 5.827716503267974e-06,
      "loss": 0.0429,
      "step": 10351
    },
    {
      "epoch": 2.3786764705882355,
      "grad_norm": 1.1199736595153809,
      "learning_rate": 5.827205882352942e-06,
      "loss": 0.0556,
      "step": 10352
    },
    {
      "epoch": 2.37890625,
      "grad_norm": 0.9816626310348511,
      "learning_rate": 5.826695261437909e-06,
      "loss": 0.0266,
      "step": 10353
    },
    {
      "epoch": 2.3791360294117645,
      "grad_norm": 0.7098767757415771,
      "learning_rate": 5.826184640522876e-06,
      "loss": 0.034,
      "step": 10354
    },
    {
      "epoch": 2.3793658088235294,
      "grad_norm": 1.127914309501648,
      "learning_rate": 5.825674019607843e-06,
      "loss": 0.0389,
      "step": 10355
    },
    {
      "epoch": 2.379595588235294,
      "grad_norm": 0.8398142457008362,
      "learning_rate": 5.825163398692811e-06,
      "loss": 0.0412,
      "step": 10356
    },
    {
      "epoch": 2.379825367647059,
      "grad_norm": 0.8216124176979065,
      "learning_rate": 5.824652777777778e-06,
      "loss": 0.043,
      "step": 10357
    },
    {
      "epoch": 2.3800551470588234,
      "grad_norm": 1.341462254524231,
      "learning_rate": 5.824142156862745e-06,
      "loss": 0.0505,
      "step": 10358
    },
    {
      "epoch": 2.3802849264705883,
      "grad_norm": 1.1156891584396362,
      "learning_rate": 5.823631535947712e-06,
      "loss": 0.0525,
      "step": 10359
    },
    {
      "epoch": 2.380514705882353,
      "grad_norm": 0.8530881404876709,
      "learning_rate": 5.823120915032681e-06,
      "loss": 0.0275,
      "step": 10360
    },
    {
      "epoch": 2.3807444852941178,
      "grad_norm": 0.9869087934494019,
      "learning_rate": 5.822610294117648e-06,
      "loss": 0.043,
      "step": 10361
    },
    {
      "epoch": 2.3809742647058822,
      "grad_norm": 0.4543611407279968,
      "learning_rate": 5.822099673202615e-06,
      "loss": 0.0152,
      "step": 10362
    },
    {
      "epoch": 2.381204044117647,
      "grad_norm": 0.942183256149292,
      "learning_rate": 5.821589052287582e-06,
      "loss": 0.0377,
      "step": 10363
    },
    {
      "epoch": 2.3814338235294117,
      "grad_norm": 0.9408735632896423,
      "learning_rate": 5.82107843137255e-06,
      "loss": 0.0278,
      "step": 10364
    },
    {
      "epoch": 2.3816636029411766,
      "grad_norm": 0.9070360064506531,
      "learning_rate": 5.820567810457517e-06,
      "loss": 0.0393,
      "step": 10365
    },
    {
      "epoch": 2.381893382352941,
      "grad_norm": 0.7159312963485718,
      "learning_rate": 5.820057189542484e-06,
      "loss": 0.0389,
      "step": 10366
    },
    {
      "epoch": 2.382123161764706,
      "grad_norm": 0.9784935712814331,
      "learning_rate": 5.819546568627451e-06,
      "loss": 0.0402,
      "step": 10367
    },
    {
      "epoch": 2.3823529411764706,
      "grad_norm": 0.7100027799606323,
      "learning_rate": 5.819035947712419e-06,
      "loss": 0.0219,
      "step": 10368
    },
    {
      "epoch": 2.3825827205882355,
      "grad_norm": 0.9903501272201538,
      "learning_rate": 5.818525326797386e-06,
      "loss": 0.0496,
      "step": 10369
    },
    {
      "epoch": 2.3828125,
      "grad_norm": 0.9216293692588806,
      "learning_rate": 5.818014705882354e-06,
      "loss": 0.0356,
      "step": 10370
    },
    {
      "epoch": 2.3830422794117645,
      "grad_norm": 0.7752546072006226,
      "learning_rate": 5.817504084967321e-06,
      "loss": 0.03,
      "step": 10371
    },
    {
      "epoch": 2.3832720588235294,
      "grad_norm": 0.8437005281448364,
      "learning_rate": 5.816993464052289e-06,
      "loss": 0.0338,
      "step": 10372
    },
    {
      "epoch": 2.383501838235294,
      "grad_norm": 0.9358784556388855,
      "learning_rate": 5.816482843137256e-06,
      "loss": 0.0577,
      "step": 10373
    },
    {
      "epoch": 2.383731617647059,
      "grad_norm": 0.8236395716667175,
      "learning_rate": 5.815972222222223e-06,
      "loss": 0.0298,
      "step": 10374
    },
    {
      "epoch": 2.3839613970588234,
      "grad_norm": 0.9979684352874756,
      "learning_rate": 5.81546160130719e-06,
      "loss": 0.0408,
      "step": 10375
    },
    {
      "epoch": 2.3841911764705883,
      "grad_norm": 1.2046207189559937,
      "learning_rate": 5.8149509803921575e-06,
      "loss": 0.0416,
      "step": 10376
    },
    {
      "epoch": 2.384420955882353,
      "grad_norm": 1.0075474977493286,
      "learning_rate": 5.8144403594771245e-06,
      "loss": 0.041,
      "step": 10377
    },
    {
      "epoch": 2.3846507352941178,
      "grad_norm": 1.3029447793960571,
      "learning_rate": 5.8139297385620915e-06,
      "loss": 0.0366,
      "step": 10378
    },
    {
      "epoch": 2.3848805147058822,
      "grad_norm": 1.1573398113250732,
      "learning_rate": 5.8134191176470585e-06,
      "loss": 0.0461,
      "step": 10379
    },
    {
      "epoch": 2.385110294117647,
      "grad_norm": 0.9466731548309326,
      "learning_rate": 5.812908496732027e-06,
      "loss": 0.0394,
      "step": 10380
    },
    {
      "epoch": 2.3853400735294117,
      "grad_norm": 1.026167392730713,
      "learning_rate": 5.812397875816994e-06,
      "loss": 0.0502,
      "step": 10381
    },
    {
      "epoch": 2.3855698529411766,
      "grad_norm": 0.9166198372840881,
      "learning_rate": 5.811887254901961e-06,
      "loss": 0.0365,
      "step": 10382
    },
    {
      "epoch": 2.385799632352941,
      "grad_norm": 1.0833702087402344,
      "learning_rate": 5.811376633986928e-06,
      "loss": 0.0255,
      "step": 10383
    },
    {
      "epoch": 2.386029411764706,
      "grad_norm": 0.9146567583084106,
      "learning_rate": 5.810866013071896e-06,
      "loss": 0.0435,
      "step": 10384
    },
    {
      "epoch": 2.3862591911764706,
      "grad_norm": 1.064060091972351,
      "learning_rate": 5.810355392156863e-06,
      "loss": 0.0462,
      "step": 10385
    },
    {
      "epoch": 2.3864889705882355,
      "grad_norm": 0.8588808178901672,
      "learning_rate": 5.80984477124183e-06,
      "loss": 0.0459,
      "step": 10386
    },
    {
      "epoch": 2.38671875,
      "grad_norm": 1.2929140329360962,
      "learning_rate": 5.809334150326797e-06,
      "loss": 0.0482,
      "step": 10387
    },
    {
      "epoch": 2.3869485294117645,
      "grad_norm": 0.9966903328895569,
      "learning_rate": 5.808823529411766e-06,
      "loss": 0.0553,
      "step": 10388
    },
    {
      "epoch": 2.3871783088235294,
      "grad_norm": 0.8163930177688599,
      "learning_rate": 5.808312908496733e-06,
      "loss": 0.0284,
      "step": 10389
    },
    {
      "epoch": 2.387408088235294,
      "grad_norm": 0.8076812028884888,
      "learning_rate": 5.8078022875817e-06,
      "loss": 0.039,
      "step": 10390
    },
    {
      "epoch": 2.387637867647059,
      "grad_norm": 0.99848473072052,
      "learning_rate": 5.807291666666667e-06,
      "loss": 0.0435,
      "step": 10391
    },
    {
      "epoch": 2.3878676470588234,
      "grad_norm": 0.9396998286247253,
      "learning_rate": 5.806781045751635e-06,
      "loss": 0.0398,
      "step": 10392
    },
    {
      "epoch": 2.3880974264705883,
      "grad_norm": 1.4440248012542725,
      "learning_rate": 5.806270424836602e-06,
      "loss": 0.0398,
      "step": 10393
    },
    {
      "epoch": 2.388327205882353,
      "grad_norm": 1.2863746881484985,
      "learning_rate": 5.805759803921569e-06,
      "loss": 0.0476,
      "step": 10394
    },
    {
      "epoch": 2.3885569852941178,
      "grad_norm": 1.273422360420227,
      "learning_rate": 5.805249183006536e-06,
      "loss": 0.0351,
      "step": 10395
    },
    {
      "epoch": 2.3887867647058822,
      "grad_norm": 1.375861644744873,
      "learning_rate": 5.8047385620915045e-06,
      "loss": 0.0663,
      "step": 10396
    },
    {
      "epoch": 2.389016544117647,
      "grad_norm": 0.7403460144996643,
      "learning_rate": 5.8042279411764716e-06,
      "loss": 0.0346,
      "step": 10397
    },
    {
      "epoch": 2.3892463235294117,
      "grad_norm": 0.9465776681900024,
      "learning_rate": 5.803717320261439e-06,
      "loss": 0.0538,
      "step": 10398
    },
    {
      "epoch": 2.3894761029411766,
      "grad_norm": 1.4852396249771118,
      "learning_rate": 5.803206699346406e-06,
      "loss": 0.0614,
      "step": 10399
    },
    {
      "epoch": 2.389705882352941,
      "grad_norm": 0.9394651651382446,
      "learning_rate": 5.8026960784313735e-06,
      "loss": 0.0288,
      "step": 10400
    },
    {
      "epoch": 2.389935661764706,
      "grad_norm": 1.8862463235855103,
      "learning_rate": 5.8021854575163405e-06,
      "loss": 0.0453,
      "step": 10401
    },
    {
      "epoch": 2.3901654411764706,
      "grad_norm": 0.9646302461624146,
      "learning_rate": 5.8016748366013075e-06,
      "loss": 0.0535,
      "step": 10402
    },
    {
      "epoch": 2.3903952205882355,
      "grad_norm": 1.0749998092651367,
      "learning_rate": 5.8011642156862745e-06,
      "loss": 0.0433,
      "step": 10403
    },
    {
      "epoch": 2.390625,
      "grad_norm": 0.9470112323760986,
      "learning_rate": 5.800653594771243e-06,
      "loss": 0.0492,
      "step": 10404
    },
    {
      "epoch": 2.3908547794117645,
      "grad_norm": 0.9540027379989624,
      "learning_rate": 5.80014297385621e-06,
      "loss": 0.0478,
      "step": 10405
    },
    {
      "epoch": 2.3910845588235294,
      "grad_norm": 0.9261402487754822,
      "learning_rate": 5.799632352941177e-06,
      "loss": 0.0558,
      "step": 10406
    },
    {
      "epoch": 2.391314338235294,
      "grad_norm": 0.772065281867981,
      "learning_rate": 5.799121732026144e-06,
      "loss": 0.0456,
      "step": 10407
    },
    {
      "epoch": 2.391544117647059,
      "grad_norm": 0.9756284356117249,
      "learning_rate": 5.798611111111112e-06,
      "loss": 0.0381,
      "step": 10408
    },
    {
      "epoch": 2.3917738970588234,
      "grad_norm": 1.4692000150680542,
      "learning_rate": 5.798100490196079e-06,
      "loss": 0.0757,
      "step": 10409
    },
    {
      "epoch": 2.3920036764705883,
      "grad_norm": 0.6696696877479553,
      "learning_rate": 5.797589869281046e-06,
      "loss": 0.032,
      "step": 10410
    },
    {
      "epoch": 2.392233455882353,
      "grad_norm": 0.8988016247749329,
      "learning_rate": 5.797079248366013e-06,
      "loss": 0.0334,
      "step": 10411
    },
    {
      "epoch": 2.3924632352941178,
      "grad_norm": 0.8615599274635315,
      "learning_rate": 5.796568627450981e-06,
      "loss": 0.0326,
      "step": 10412
    },
    {
      "epoch": 2.3926930147058822,
      "grad_norm": 0.7377625703811646,
      "learning_rate": 5.796058006535948e-06,
      "loss": 0.028,
      "step": 10413
    },
    {
      "epoch": 2.392922794117647,
      "grad_norm": 0.9864783883094788,
      "learning_rate": 5.795547385620915e-06,
      "loss": 0.0315,
      "step": 10414
    },
    {
      "epoch": 2.3931525735294117,
      "grad_norm": 1.6716728210449219,
      "learning_rate": 5.795036764705883e-06,
      "loss": 0.0478,
      "step": 10415
    },
    {
      "epoch": 2.3933823529411766,
      "grad_norm": 0.8459413051605225,
      "learning_rate": 5.794526143790851e-06,
      "loss": 0.043,
      "step": 10416
    },
    {
      "epoch": 2.393612132352941,
      "grad_norm": 1.078771948814392,
      "learning_rate": 5.794015522875818e-06,
      "loss": 0.0394,
      "step": 10417
    },
    {
      "epoch": 2.393841911764706,
      "grad_norm": 1.06121027469635,
      "learning_rate": 5.793504901960785e-06,
      "loss": 0.0409,
      "step": 10418
    },
    {
      "epoch": 2.3940716911764706,
      "grad_norm": 1.2584216594696045,
      "learning_rate": 5.792994281045752e-06,
      "loss": 0.0555,
      "step": 10419
    },
    {
      "epoch": 2.3943014705882355,
      "grad_norm": 0.8401711583137512,
      "learning_rate": 5.79248366013072e-06,
      "loss": 0.0411,
      "step": 10420
    },
    {
      "epoch": 2.39453125,
      "grad_norm": 1.6120420694351196,
      "learning_rate": 5.791973039215687e-06,
      "loss": 0.0671,
      "step": 10421
    },
    {
      "epoch": 2.3947610294117645,
      "grad_norm": 0.8001800775527954,
      "learning_rate": 5.791462418300654e-06,
      "loss": 0.0402,
      "step": 10422
    },
    {
      "epoch": 2.3949908088235294,
      "grad_norm": 1.1753077507019043,
      "learning_rate": 5.790951797385621e-06,
      "loss": 0.0419,
      "step": 10423
    },
    {
      "epoch": 2.395220588235294,
      "grad_norm": 0.9992650151252747,
      "learning_rate": 5.790441176470589e-06,
      "loss": 0.0412,
      "step": 10424
    },
    {
      "epoch": 2.395450367647059,
      "grad_norm": 1.0347135066986084,
      "learning_rate": 5.7899305555555564e-06,
      "loss": 0.0658,
      "step": 10425
    },
    {
      "epoch": 2.3956801470588234,
      "grad_norm": 0.8568730354309082,
      "learning_rate": 5.7894199346405235e-06,
      "loss": 0.0397,
      "step": 10426
    },
    {
      "epoch": 2.3959099264705883,
      "grad_norm": 0.658621072769165,
      "learning_rate": 5.7889093137254905e-06,
      "loss": 0.0236,
      "step": 10427
    },
    {
      "epoch": 2.396139705882353,
      "grad_norm": 0.9287752509117126,
      "learning_rate": 5.788398692810458e-06,
      "loss": 0.0531,
      "step": 10428
    },
    {
      "epoch": 2.3963694852941178,
      "grad_norm": 0.9298591017723083,
      "learning_rate": 5.787888071895425e-06,
      "loss": 0.0342,
      "step": 10429
    },
    {
      "epoch": 2.3965992647058822,
      "grad_norm": 1.1293691396713257,
      "learning_rate": 5.787377450980392e-06,
      "loss": 0.049,
      "step": 10430
    },
    {
      "epoch": 2.396829044117647,
      "grad_norm": 1.230323076248169,
      "learning_rate": 5.786866830065359e-06,
      "loss": 0.0527,
      "step": 10431
    },
    {
      "epoch": 2.3970588235294117,
      "grad_norm": 0.7095631957054138,
      "learning_rate": 5.786356209150328e-06,
      "loss": 0.0284,
      "step": 10432
    },
    {
      "epoch": 2.3972886029411766,
      "grad_norm": 1.152537226676941,
      "learning_rate": 5.785845588235295e-06,
      "loss": 0.0488,
      "step": 10433
    },
    {
      "epoch": 2.397518382352941,
      "grad_norm": 0.7921002507209778,
      "learning_rate": 5.785334967320262e-06,
      "loss": 0.0266,
      "step": 10434
    },
    {
      "epoch": 2.397748161764706,
      "grad_norm": 0.7568697333335876,
      "learning_rate": 5.784824346405229e-06,
      "loss": 0.0369,
      "step": 10435
    },
    {
      "epoch": 2.3979779411764706,
      "grad_norm": 0.6573617458343506,
      "learning_rate": 5.784313725490197e-06,
      "loss": 0.0368,
      "step": 10436
    },
    {
      "epoch": 2.3982077205882355,
      "grad_norm": 0.9093659520149231,
      "learning_rate": 5.783803104575164e-06,
      "loss": 0.0424,
      "step": 10437
    },
    {
      "epoch": 2.3984375,
      "grad_norm": 0.8248488903045654,
      "learning_rate": 5.783292483660131e-06,
      "loss": 0.0237,
      "step": 10438
    },
    {
      "epoch": 2.3986672794117645,
      "grad_norm": 1.101243495941162,
      "learning_rate": 5.782781862745098e-06,
      "loss": 0.0432,
      "step": 10439
    },
    {
      "epoch": 2.3988970588235294,
      "grad_norm": 0.8028947710990906,
      "learning_rate": 5.782271241830067e-06,
      "loss": 0.0254,
      "step": 10440
    },
    {
      "epoch": 2.399126838235294,
      "grad_norm": 1.3527292013168335,
      "learning_rate": 5.781760620915034e-06,
      "loss": 0.0542,
      "step": 10441
    },
    {
      "epoch": 2.399356617647059,
      "grad_norm": 0.9959283471107483,
      "learning_rate": 5.781250000000001e-06,
      "loss": 0.0366,
      "step": 10442
    },
    {
      "epoch": 2.3995863970588234,
      "grad_norm": 1.1684659719467163,
      "learning_rate": 5.780739379084968e-06,
      "loss": 0.0574,
      "step": 10443
    },
    {
      "epoch": 2.3998161764705883,
      "grad_norm": 1.05918288230896,
      "learning_rate": 5.780228758169935e-06,
      "loss": 0.0398,
      "step": 10444
    },
    {
      "epoch": 2.400045955882353,
      "grad_norm": 1.1879521608352661,
      "learning_rate": 5.779718137254903e-06,
      "loss": 0.0639,
      "step": 10445
    },
    {
      "epoch": 2.4002757352941178,
      "grad_norm": 0.669177234172821,
      "learning_rate": 5.77920751633987e-06,
      "loss": 0.0336,
      "step": 10446
    },
    {
      "epoch": 2.4005055147058822,
      "grad_norm": 0.6898761987686157,
      "learning_rate": 5.778696895424837e-06,
      "loss": 0.0238,
      "step": 10447
    },
    {
      "epoch": 2.400735294117647,
      "grad_norm": 1.0849112272262573,
      "learning_rate": 5.778186274509804e-06,
      "loss": 0.0477,
      "step": 10448
    },
    {
      "epoch": 2.4009650735294117,
      "grad_norm": 1.5911870002746582,
      "learning_rate": 5.777675653594772e-06,
      "loss": 0.0592,
      "step": 10449
    },
    {
      "epoch": 2.4011948529411766,
      "grad_norm": 1.0263891220092773,
      "learning_rate": 5.777165032679739e-06,
      "loss": 0.0488,
      "step": 10450
    },
    {
      "epoch": 2.401424632352941,
      "grad_norm": 0.9741297364234924,
      "learning_rate": 5.7766544117647064e-06,
      "loss": 0.041,
      "step": 10451
    },
    {
      "epoch": 2.401654411764706,
      "grad_norm": 0.968427836894989,
      "learning_rate": 5.7761437908496734e-06,
      "loss": 0.0369,
      "step": 10452
    },
    {
      "epoch": 2.4018841911764706,
      "grad_norm": 0.8402712941169739,
      "learning_rate": 5.775633169934641e-06,
      "loss": 0.0393,
      "step": 10453
    },
    {
      "epoch": 2.4021139705882355,
      "grad_norm": 1.0144139528274536,
      "learning_rate": 5.775122549019608e-06,
      "loss": 0.0648,
      "step": 10454
    },
    {
      "epoch": 2.40234375,
      "grad_norm": 1.1051650047302246,
      "learning_rate": 5.774611928104575e-06,
      "loss": 0.0531,
      "step": 10455
    },
    {
      "epoch": 2.4025735294117645,
      "grad_norm": 1.2308872938156128,
      "learning_rate": 5.774101307189542e-06,
      "loss": 0.0318,
      "step": 10456
    },
    {
      "epoch": 2.4028033088235294,
      "grad_norm": 0.8328104019165039,
      "learning_rate": 5.77359068627451e-06,
      "loss": 0.0351,
      "step": 10457
    },
    {
      "epoch": 2.403033088235294,
      "grad_norm": 1.3713983297348022,
      "learning_rate": 5.773080065359477e-06,
      "loss": 0.0404,
      "step": 10458
    },
    {
      "epoch": 2.403262867647059,
      "grad_norm": 1.1965744495391846,
      "learning_rate": 5.772569444444445e-06,
      "loss": 0.0464,
      "step": 10459
    },
    {
      "epoch": 2.4034926470588234,
      "grad_norm": 0.8988353610038757,
      "learning_rate": 5.772058823529412e-06,
      "loss": 0.0278,
      "step": 10460
    },
    {
      "epoch": 2.4037224264705883,
      "grad_norm": 0.6714205741882324,
      "learning_rate": 5.77154820261438e-06,
      "loss": 0.0247,
      "step": 10461
    },
    {
      "epoch": 2.403952205882353,
      "grad_norm": 1.3295539617538452,
      "learning_rate": 5.771037581699347e-06,
      "loss": 0.058,
      "step": 10462
    },
    {
      "epoch": 2.4041819852941178,
      "grad_norm": 1.2738912105560303,
      "learning_rate": 5.770526960784314e-06,
      "loss": 0.0543,
      "step": 10463
    },
    {
      "epoch": 2.4044117647058822,
      "grad_norm": 1.3903872966766357,
      "learning_rate": 5.770016339869281e-06,
      "loss": 0.0492,
      "step": 10464
    },
    {
      "epoch": 2.404641544117647,
      "grad_norm": 1.124192476272583,
      "learning_rate": 5.769505718954249e-06,
      "loss": 0.0641,
      "step": 10465
    },
    {
      "epoch": 2.4048713235294117,
      "grad_norm": 0.7441908717155457,
      "learning_rate": 5.768995098039216e-06,
      "loss": 0.0375,
      "step": 10466
    },
    {
      "epoch": 2.4051011029411766,
      "grad_norm": 1.0814708471298218,
      "learning_rate": 5.768484477124183e-06,
      "loss": 0.034,
      "step": 10467
    },
    {
      "epoch": 2.405330882352941,
      "grad_norm": 1.2223730087280273,
      "learning_rate": 5.76797385620915e-06,
      "loss": 0.0652,
      "step": 10468
    },
    {
      "epoch": 2.405560661764706,
      "grad_norm": 0.9887190461158752,
      "learning_rate": 5.767463235294119e-06,
      "loss": 0.0534,
      "step": 10469
    },
    {
      "epoch": 2.4057904411764706,
      "grad_norm": 1.3825104236602783,
      "learning_rate": 5.766952614379086e-06,
      "loss": 0.0598,
      "step": 10470
    },
    {
      "epoch": 2.4060202205882355,
      "grad_norm": 1.0473413467407227,
      "learning_rate": 5.766441993464053e-06,
      "loss": 0.0444,
      "step": 10471
    },
    {
      "epoch": 2.40625,
      "grad_norm": 0.9239403605461121,
      "learning_rate": 5.76593137254902e-06,
      "loss": 0.04,
      "step": 10472
    },
    {
      "epoch": 2.4064797794117645,
      "grad_norm": 0.8004297614097595,
      "learning_rate": 5.7654207516339875e-06,
      "loss": 0.0493,
      "step": 10473
    },
    {
      "epoch": 2.4067095588235294,
      "grad_norm": 0.8869059681892395,
      "learning_rate": 5.7649101307189545e-06,
      "loss": 0.0485,
      "step": 10474
    },
    {
      "epoch": 2.406939338235294,
      "grad_norm": 0.6883610486984253,
      "learning_rate": 5.7643995098039216e-06,
      "loss": 0.032,
      "step": 10475
    },
    {
      "epoch": 2.407169117647059,
      "grad_norm": 1.2371230125427246,
      "learning_rate": 5.7638888888888886e-06,
      "loss": 0.0583,
      "step": 10476
    },
    {
      "epoch": 2.4073988970588234,
      "grad_norm": 1.244264841079712,
      "learning_rate": 5.763378267973857e-06,
      "loss": 0.0647,
      "step": 10477
    },
    {
      "epoch": 2.4076286764705883,
      "grad_norm": 0.866882860660553,
      "learning_rate": 5.762867647058824e-06,
      "loss": 0.0385,
      "step": 10478
    },
    {
      "epoch": 2.407858455882353,
      "grad_norm": 0.9555773735046387,
      "learning_rate": 5.762357026143791e-06,
      "loss": 0.0492,
      "step": 10479
    },
    {
      "epoch": 2.4080882352941178,
      "grad_norm": 0.811138927936554,
      "learning_rate": 5.761846405228758e-06,
      "loss": 0.0442,
      "step": 10480
    },
    {
      "epoch": 2.4083180147058822,
      "grad_norm": 0.938808262348175,
      "learning_rate": 5.761335784313726e-06,
      "loss": 0.0321,
      "step": 10481
    },
    {
      "epoch": 2.408547794117647,
      "grad_norm": 0.8945503234863281,
      "learning_rate": 5.760825163398693e-06,
      "loss": 0.0443,
      "step": 10482
    },
    {
      "epoch": 2.4087775735294117,
      "grad_norm": 0.8140122294425964,
      "learning_rate": 5.76031454248366e-06,
      "loss": 0.0441,
      "step": 10483
    },
    {
      "epoch": 2.4090073529411766,
      "grad_norm": 1.578598976135254,
      "learning_rate": 5.759803921568627e-06,
      "loss": 0.0472,
      "step": 10484
    },
    {
      "epoch": 2.409237132352941,
      "grad_norm": 0.9886688590049744,
      "learning_rate": 5.759293300653596e-06,
      "loss": 0.0342,
      "step": 10485
    },
    {
      "epoch": 2.409466911764706,
      "grad_norm": 0.6820555329322815,
      "learning_rate": 5.758782679738563e-06,
      "loss": 0.0218,
      "step": 10486
    },
    {
      "epoch": 2.4096966911764706,
      "grad_norm": 1.1586925983428955,
      "learning_rate": 5.75827205882353e-06,
      "loss": 0.0439,
      "step": 10487
    },
    {
      "epoch": 2.4099264705882355,
      "grad_norm": 0.890877366065979,
      "learning_rate": 5.757761437908497e-06,
      "loss": 0.037,
      "step": 10488
    },
    {
      "epoch": 2.41015625,
      "grad_norm": 0.7562357187271118,
      "learning_rate": 5.757250816993465e-06,
      "loss": 0.0382,
      "step": 10489
    },
    {
      "epoch": 2.4103860294117645,
      "grad_norm": 0.8773914575576782,
      "learning_rate": 5.756740196078432e-06,
      "loss": 0.0385,
      "step": 10490
    },
    {
      "epoch": 2.4106158088235294,
      "grad_norm": 1.0725994110107422,
      "learning_rate": 5.756229575163399e-06,
      "loss": 0.0663,
      "step": 10491
    },
    {
      "epoch": 2.410845588235294,
      "grad_norm": 1.2666058540344238,
      "learning_rate": 5.755718954248366e-06,
      "loss": 0.0505,
      "step": 10492
    },
    {
      "epoch": 2.411075367647059,
      "grad_norm": 1.0469533205032349,
      "learning_rate": 5.755208333333335e-06,
      "loss": 0.0457,
      "step": 10493
    },
    {
      "epoch": 2.4113051470588234,
      "grad_norm": 1.008249044418335,
      "learning_rate": 5.754697712418302e-06,
      "loss": 0.051,
      "step": 10494
    },
    {
      "epoch": 2.4115349264705883,
      "grad_norm": 1.1444156169891357,
      "learning_rate": 5.754187091503269e-06,
      "loss": 0.0503,
      "step": 10495
    },
    {
      "epoch": 2.411764705882353,
      "grad_norm": 1.2493820190429688,
      "learning_rate": 5.753676470588236e-06,
      "loss": 0.0449,
      "step": 10496
    },
    {
      "epoch": 2.4119944852941178,
      "grad_norm": 0.9019122123718262,
      "learning_rate": 5.7531658496732035e-06,
      "loss": 0.0409,
      "step": 10497
    },
    {
      "epoch": 2.4122242647058822,
      "grad_norm": 1.0207583904266357,
      "learning_rate": 5.7526552287581705e-06,
      "loss": 0.0489,
      "step": 10498
    },
    {
      "epoch": 2.412454044117647,
      "grad_norm": 0.8352413773536682,
      "learning_rate": 5.7521446078431375e-06,
      "loss": 0.0339,
      "step": 10499
    },
    {
      "epoch": 2.4126838235294117,
      "grad_norm": 1.019754409790039,
      "learning_rate": 5.7516339869281045e-06,
      "loss": 0.0471,
      "step": 10500
    },
    {
      "epoch": 2.4126838235294117,
      "eval_loss": 0.04694807529449463,
      "eval_runtime": 2006.8876,
      "eval_samples_per_second": 4.438,
      "eval_steps_per_second": 2.219,
      "step": 10500
    },
    {
      "epoch": 2.4129136029411766,
      "grad_norm": 1.0186121463775635,
      "learning_rate": 5.751123366013072e-06,
      "loss": 0.0286,
      "step": 10501
    },
    {
      "epoch": 2.413143382352941,
      "grad_norm": 0.9786466360092163,
      "learning_rate": 5.750612745098039e-06,
      "loss": 0.051,
      "step": 10502
    },
    {
      "epoch": 2.413373161764706,
      "grad_norm": 1.3572211265563965,
      "learning_rate": 5.7501021241830064e-06,
      "loss": 0.0617,
      "step": 10503
    },
    {
      "epoch": 2.4136029411764706,
      "grad_norm": 2.2563235759735107,
      "learning_rate": 5.749591503267974e-06,
      "loss": 0.0711,
      "step": 10504
    },
    {
      "epoch": 2.4138327205882355,
      "grad_norm": 1.2502145767211914,
      "learning_rate": 5.749080882352942e-06,
      "loss": 0.0556,
      "step": 10505
    },
    {
      "epoch": 2.4140625,
      "grad_norm": 1.1336709260940552,
      "learning_rate": 5.748570261437909e-06,
      "loss": 0.0438,
      "step": 10506
    },
    {
      "epoch": 2.4142922794117645,
      "grad_norm": 0.7902897596359253,
      "learning_rate": 5.748059640522876e-06,
      "loss": 0.0294,
      "step": 10507
    },
    {
      "epoch": 2.4145220588235294,
      "grad_norm": 1.1011183261871338,
      "learning_rate": 5.747549019607843e-06,
      "loss": 0.0627,
      "step": 10508
    },
    {
      "epoch": 2.414751838235294,
      "grad_norm": 0.7947642207145691,
      "learning_rate": 5.747038398692811e-06,
      "loss": 0.0289,
      "step": 10509
    },
    {
      "epoch": 2.414981617647059,
      "grad_norm": 0.7116534113883972,
      "learning_rate": 5.746527777777778e-06,
      "loss": 0.0268,
      "step": 10510
    },
    {
      "epoch": 2.4152113970588234,
      "grad_norm": 1.0295933485031128,
      "learning_rate": 5.746017156862745e-06,
      "loss": 0.031,
      "step": 10511
    },
    {
      "epoch": 2.4154411764705883,
      "grad_norm": 0.9941631555557251,
      "learning_rate": 5.745506535947712e-06,
      "loss": 0.0496,
      "step": 10512
    },
    {
      "epoch": 2.415670955882353,
      "grad_norm": 0.8329885005950928,
      "learning_rate": 5.744995915032681e-06,
      "loss": 0.0273,
      "step": 10513
    },
    {
      "epoch": 2.4159007352941178,
      "grad_norm": 0.708677351474762,
      "learning_rate": 5.744485294117648e-06,
      "loss": 0.033,
      "step": 10514
    },
    {
      "epoch": 2.4161305147058822,
      "grad_norm": 1.0089962482452393,
      "learning_rate": 5.743974673202615e-06,
      "loss": 0.0422,
      "step": 10515
    },
    {
      "epoch": 2.416360294117647,
      "grad_norm": 0.9739291071891785,
      "learning_rate": 5.743464052287582e-06,
      "loss": 0.0432,
      "step": 10516
    },
    {
      "epoch": 2.4165900735294117,
      "grad_norm": 0.8839173316955566,
      "learning_rate": 5.74295343137255e-06,
      "loss": 0.0581,
      "step": 10517
    },
    {
      "epoch": 2.4168198529411766,
      "grad_norm": 0.8876440525054932,
      "learning_rate": 5.742442810457517e-06,
      "loss": 0.0387,
      "step": 10518
    },
    {
      "epoch": 2.417049632352941,
      "grad_norm": 0.9102199673652649,
      "learning_rate": 5.741932189542484e-06,
      "loss": 0.0473,
      "step": 10519
    },
    {
      "epoch": 2.417279411764706,
      "grad_norm": 0.8051570057868958,
      "learning_rate": 5.741421568627451e-06,
      "loss": 0.0377,
      "step": 10520
    },
    {
      "epoch": 2.4175091911764706,
      "grad_norm": 0.8320451378822327,
      "learning_rate": 5.7409109477124195e-06,
      "loss": 0.0367,
      "step": 10521
    },
    {
      "epoch": 2.4177389705882355,
      "grad_norm": 1.0373802185058594,
      "learning_rate": 5.7404003267973865e-06,
      "loss": 0.0505,
      "step": 10522
    },
    {
      "epoch": 2.41796875,
      "grad_norm": 0.9922935962677002,
      "learning_rate": 5.7398897058823535e-06,
      "loss": 0.0432,
      "step": 10523
    },
    {
      "epoch": 2.4181985294117645,
      "grad_norm": 0.8343093991279602,
      "learning_rate": 5.7393790849673205e-06,
      "loss": 0.0346,
      "step": 10524
    },
    {
      "epoch": 2.4184283088235294,
      "grad_norm": 1.1366933584213257,
      "learning_rate": 5.738868464052288e-06,
      "loss": 0.0569,
      "step": 10525
    },
    {
      "epoch": 2.418658088235294,
      "grad_norm": 0.6698915958404541,
      "learning_rate": 5.738357843137255e-06,
      "loss": 0.0271,
      "step": 10526
    },
    {
      "epoch": 2.418887867647059,
      "grad_norm": 1.1748046875,
      "learning_rate": 5.737847222222222e-06,
      "loss": 0.0429,
      "step": 10527
    },
    {
      "epoch": 2.4191176470588234,
      "grad_norm": 0.9964159727096558,
      "learning_rate": 5.737336601307189e-06,
      "loss": 0.0492,
      "step": 10528
    },
    {
      "epoch": 2.4193474264705883,
      "grad_norm": 0.6835587024688721,
      "learning_rate": 5.736825980392158e-06,
      "loss": 0.0369,
      "step": 10529
    },
    {
      "epoch": 2.419577205882353,
      "grad_norm": 0.8598283529281616,
      "learning_rate": 5.736315359477125e-06,
      "loss": 0.0363,
      "step": 10530
    },
    {
      "epoch": 2.4198069852941178,
      "grad_norm": 0.8249726295471191,
      "learning_rate": 5.735804738562092e-06,
      "loss": 0.0279,
      "step": 10531
    },
    {
      "epoch": 2.4200367647058822,
      "grad_norm": 0.8255519270896912,
      "learning_rate": 5.735294117647059e-06,
      "loss": 0.0303,
      "step": 10532
    },
    {
      "epoch": 2.420266544117647,
      "grad_norm": 0.7967019081115723,
      "learning_rate": 5.734783496732027e-06,
      "loss": 0.0295,
      "step": 10533
    },
    {
      "epoch": 2.4204963235294117,
      "grad_norm": 0.8421464562416077,
      "learning_rate": 5.734272875816994e-06,
      "loss": 0.0257,
      "step": 10534
    },
    {
      "epoch": 2.4207261029411766,
      "grad_norm": 0.8388280868530273,
      "learning_rate": 5.733762254901961e-06,
      "loss": 0.0382,
      "step": 10535
    },
    {
      "epoch": 2.420955882352941,
      "grad_norm": 0.9518052935600281,
      "learning_rate": 5.733251633986928e-06,
      "loss": 0.0446,
      "step": 10536
    },
    {
      "epoch": 2.421185661764706,
      "grad_norm": 0.7732716202735901,
      "learning_rate": 5.732741013071896e-06,
      "loss": 0.0299,
      "step": 10537
    },
    {
      "epoch": 2.4214154411764706,
      "grad_norm": 0.713248610496521,
      "learning_rate": 5.732230392156864e-06,
      "loss": 0.0415,
      "step": 10538
    },
    {
      "epoch": 2.4216452205882355,
      "grad_norm": 0.8722971677780151,
      "learning_rate": 5.731719771241831e-06,
      "loss": 0.0499,
      "step": 10539
    },
    {
      "epoch": 2.421875,
      "grad_norm": 1.1568704843521118,
      "learning_rate": 5.731209150326798e-06,
      "loss": 0.0687,
      "step": 10540
    },
    {
      "epoch": 2.4221047794117645,
      "grad_norm": 0.7464308738708496,
      "learning_rate": 5.730698529411766e-06,
      "loss": 0.0422,
      "step": 10541
    },
    {
      "epoch": 2.4223345588235294,
      "grad_norm": 1.4438856840133667,
      "learning_rate": 5.730187908496733e-06,
      "loss": 0.0467,
      "step": 10542
    },
    {
      "epoch": 2.422564338235294,
      "grad_norm": 1.0789318084716797,
      "learning_rate": 5.7296772875817e-06,
      "loss": 0.0409,
      "step": 10543
    },
    {
      "epoch": 2.422794117647059,
      "grad_norm": 0.9880083203315735,
      "learning_rate": 5.729166666666667e-06,
      "loss": 0.0438,
      "step": 10544
    },
    {
      "epoch": 2.4230238970588234,
      "grad_norm": 1.0295495986938477,
      "learning_rate": 5.728656045751635e-06,
      "loss": 0.0337,
      "step": 10545
    },
    {
      "epoch": 2.4232536764705883,
      "grad_norm": 0.9604179859161377,
      "learning_rate": 5.728145424836602e-06,
      "loss": 0.0301,
      "step": 10546
    },
    {
      "epoch": 2.423483455882353,
      "grad_norm": 0.8720451593399048,
      "learning_rate": 5.727634803921569e-06,
      "loss": 0.0361,
      "step": 10547
    },
    {
      "epoch": 2.4237132352941178,
      "grad_norm": 0.8705320358276367,
      "learning_rate": 5.727124183006536e-06,
      "loss": 0.0374,
      "step": 10548
    },
    {
      "epoch": 2.4239430147058822,
      "grad_norm": 0.6071212291717529,
      "learning_rate": 5.726613562091504e-06,
      "loss": 0.0284,
      "step": 10549
    },
    {
      "epoch": 2.424172794117647,
      "grad_norm": 1.0366716384887695,
      "learning_rate": 5.726102941176471e-06,
      "loss": 0.0491,
      "step": 10550
    },
    {
      "epoch": 2.4244025735294117,
      "grad_norm": 0.9833146333694458,
      "learning_rate": 5.725592320261438e-06,
      "loss": 0.0458,
      "step": 10551
    },
    {
      "epoch": 2.4246323529411766,
      "grad_norm": 2.0080223083496094,
      "learning_rate": 5.725081699346405e-06,
      "loss": 0.0661,
      "step": 10552
    },
    {
      "epoch": 2.424862132352941,
      "grad_norm": 0.9800350069999695,
      "learning_rate": 5.724571078431373e-06,
      "loss": 0.04,
      "step": 10553
    },
    {
      "epoch": 2.425091911764706,
      "grad_norm": 0.7606068253517151,
      "learning_rate": 5.72406045751634e-06,
      "loss": 0.0393,
      "step": 10554
    },
    {
      "epoch": 2.4253216911764706,
      "grad_norm": 1.3747152090072632,
      "learning_rate": 5.723549836601307e-06,
      "loss": 0.0563,
      "step": 10555
    },
    {
      "epoch": 2.4255514705882355,
      "grad_norm": 0.7091951370239258,
      "learning_rate": 5.723039215686274e-06,
      "loss": 0.0237,
      "step": 10556
    },
    {
      "epoch": 2.42578125,
      "grad_norm": 1.1345465183258057,
      "learning_rate": 5.722528594771243e-06,
      "loss": 0.0609,
      "step": 10557
    },
    {
      "epoch": 2.4260110294117645,
      "grad_norm": 0.9608235955238342,
      "learning_rate": 5.72201797385621e-06,
      "loss": 0.0481,
      "step": 10558
    },
    {
      "epoch": 2.4262408088235294,
      "grad_norm": 0.941672682762146,
      "learning_rate": 5.721507352941177e-06,
      "loss": 0.0388,
      "step": 10559
    },
    {
      "epoch": 2.426470588235294,
      "grad_norm": 1.0008906126022339,
      "learning_rate": 5.720996732026144e-06,
      "loss": 0.0432,
      "step": 10560
    },
    {
      "epoch": 2.426700367647059,
      "grad_norm": 0.9966166019439697,
      "learning_rate": 5.720486111111112e-06,
      "loss": 0.0475,
      "step": 10561
    },
    {
      "epoch": 2.4269301470588234,
      "grad_norm": 1.3724507093429565,
      "learning_rate": 5.719975490196079e-06,
      "loss": 0.0511,
      "step": 10562
    },
    {
      "epoch": 2.4271599264705883,
      "grad_norm": 1.0256091356277466,
      "learning_rate": 5.719464869281046e-06,
      "loss": 0.0285,
      "step": 10563
    },
    {
      "epoch": 2.427389705882353,
      "grad_norm": 1.0615073442459106,
      "learning_rate": 5.718954248366013e-06,
      "loss": 0.0618,
      "step": 10564
    },
    {
      "epoch": 2.4276194852941178,
      "grad_norm": 0.8229324817657471,
      "learning_rate": 5.718443627450982e-06,
      "loss": 0.0296,
      "step": 10565
    },
    {
      "epoch": 2.4278492647058822,
      "grad_norm": 1.0706071853637695,
      "learning_rate": 5.717933006535949e-06,
      "loss": 0.054,
      "step": 10566
    },
    {
      "epoch": 2.428079044117647,
      "grad_norm": 0.911217212677002,
      "learning_rate": 5.717422385620916e-06,
      "loss": 0.0378,
      "step": 10567
    },
    {
      "epoch": 2.4283088235294117,
      "grad_norm": 0.8728297352790833,
      "learning_rate": 5.716911764705883e-06,
      "loss": 0.0427,
      "step": 10568
    },
    {
      "epoch": 2.4285386029411766,
      "grad_norm": 1.0842252969741821,
      "learning_rate": 5.7164011437908506e-06,
      "loss": 0.0656,
      "step": 10569
    },
    {
      "epoch": 2.428768382352941,
      "grad_norm": 0.8962379097938538,
      "learning_rate": 5.7158905228758176e-06,
      "loss": 0.0359,
      "step": 10570
    },
    {
      "epoch": 2.428998161764706,
      "grad_norm": 0.9464581608772278,
      "learning_rate": 5.715379901960785e-06,
      "loss": 0.0366,
      "step": 10571
    },
    {
      "epoch": 2.4292279411764706,
      "grad_norm": 0.8937318921089172,
      "learning_rate": 5.714869281045752e-06,
      "loss": 0.0433,
      "step": 10572
    },
    {
      "epoch": 2.4294577205882355,
      "grad_norm": 0.7915604114532471,
      "learning_rate": 5.71435866013072e-06,
      "loss": 0.0293,
      "step": 10573
    },
    {
      "epoch": 2.4296875,
      "grad_norm": 0.970057487487793,
      "learning_rate": 5.713848039215687e-06,
      "loss": 0.0438,
      "step": 10574
    },
    {
      "epoch": 2.4299172794117645,
      "grad_norm": 1.0010968446731567,
      "learning_rate": 5.713337418300654e-06,
      "loss": 0.0472,
      "step": 10575
    },
    {
      "epoch": 2.4301470588235294,
      "grad_norm": 0.7471703886985779,
      "learning_rate": 5.712826797385621e-06,
      "loss": 0.0415,
      "step": 10576
    },
    {
      "epoch": 2.430376838235294,
      "grad_norm": 1.1887202262878418,
      "learning_rate": 5.712316176470589e-06,
      "loss": 0.0377,
      "step": 10577
    },
    {
      "epoch": 2.430606617647059,
      "grad_norm": 1.1198318004608154,
      "learning_rate": 5.711805555555556e-06,
      "loss": 0.0478,
      "step": 10578
    },
    {
      "epoch": 2.4308363970588234,
      "grad_norm": 0.9339496493339539,
      "learning_rate": 5.711294934640523e-06,
      "loss": 0.0426,
      "step": 10579
    },
    {
      "epoch": 2.4310661764705883,
      "grad_norm": 0.8765150308609009,
      "learning_rate": 5.71078431372549e-06,
      "loss": 0.0437,
      "step": 10580
    },
    {
      "epoch": 2.431295955882353,
      "grad_norm": 0.882554292678833,
      "learning_rate": 5.710273692810458e-06,
      "loss": 0.0455,
      "step": 10581
    },
    {
      "epoch": 2.4315257352941178,
      "grad_norm": 0.9843061566352844,
      "learning_rate": 5.709763071895425e-06,
      "loss": 0.0489,
      "step": 10582
    },
    {
      "epoch": 2.4317555147058822,
      "grad_norm": 0.9966973066329956,
      "learning_rate": 5.709252450980393e-06,
      "loss": 0.0433,
      "step": 10583
    },
    {
      "epoch": 2.431985294117647,
      "grad_norm": 0.8535001873970032,
      "learning_rate": 5.70874183006536e-06,
      "loss": 0.0345,
      "step": 10584
    },
    {
      "epoch": 2.4322150735294117,
      "grad_norm": 0.9716647267341614,
      "learning_rate": 5.708231209150328e-06,
      "loss": 0.0448,
      "step": 10585
    },
    {
      "epoch": 2.4324448529411766,
      "grad_norm": 0.8352066874504089,
      "learning_rate": 5.707720588235295e-06,
      "loss": 0.027,
      "step": 10586
    },
    {
      "epoch": 2.432674632352941,
      "grad_norm": 1.089871883392334,
      "learning_rate": 5.707209967320262e-06,
      "loss": 0.0437,
      "step": 10587
    },
    {
      "epoch": 2.432904411764706,
      "grad_norm": 1.0273686647415161,
      "learning_rate": 5.706699346405229e-06,
      "loss": 0.0467,
      "step": 10588
    },
    {
      "epoch": 2.4331341911764706,
      "grad_norm": 1.1381229162216187,
      "learning_rate": 5.706188725490197e-06,
      "loss": 0.0595,
      "step": 10589
    },
    {
      "epoch": 2.4333639705882355,
      "grad_norm": 0.9843654036521912,
      "learning_rate": 5.705678104575164e-06,
      "loss": 0.061,
      "step": 10590
    },
    {
      "epoch": 2.43359375,
      "grad_norm": 0.9486546516418457,
      "learning_rate": 5.705167483660131e-06,
      "loss": 0.0501,
      "step": 10591
    },
    {
      "epoch": 2.4338235294117645,
      "grad_norm": 1.0264747142791748,
      "learning_rate": 5.704656862745098e-06,
      "loss": 0.0328,
      "step": 10592
    },
    {
      "epoch": 2.4340533088235294,
      "grad_norm": 0.9976817965507507,
      "learning_rate": 5.7041462418300665e-06,
      "loss": 0.0466,
      "step": 10593
    },
    {
      "epoch": 2.434283088235294,
      "grad_norm": 0.6596685647964478,
      "learning_rate": 5.7036356209150335e-06,
      "loss": 0.0321,
      "step": 10594
    },
    {
      "epoch": 2.434512867647059,
      "grad_norm": 0.9107080101966858,
      "learning_rate": 5.7031250000000006e-06,
      "loss": 0.0361,
      "step": 10595
    },
    {
      "epoch": 2.4347426470588234,
      "grad_norm": 0.8177425861358643,
      "learning_rate": 5.7026143790849676e-06,
      "loss": 0.0363,
      "step": 10596
    },
    {
      "epoch": 2.4349724264705883,
      "grad_norm": 1.7422502040863037,
      "learning_rate": 5.702103758169935e-06,
      "loss": 0.0648,
      "step": 10597
    },
    {
      "epoch": 2.435202205882353,
      "grad_norm": 0.9036571383476257,
      "learning_rate": 5.7015931372549024e-06,
      "loss": 0.0308,
      "step": 10598
    },
    {
      "epoch": 2.4354319852941178,
      "grad_norm": 0.7639113068580627,
      "learning_rate": 5.7010825163398695e-06,
      "loss": 0.0276,
      "step": 10599
    },
    {
      "epoch": 2.4356617647058822,
      "grad_norm": 0.9804403781890869,
      "learning_rate": 5.7005718954248365e-06,
      "loss": 0.0492,
      "step": 10600
    },
    {
      "epoch": 2.435891544117647,
      "grad_norm": 1.0772051811218262,
      "learning_rate": 5.7000612745098035e-06,
      "loss": 0.0415,
      "step": 10601
    },
    {
      "epoch": 2.4361213235294117,
      "grad_norm": 1.0367705821990967,
      "learning_rate": 5.699550653594772e-06,
      "loss": 0.0335,
      "step": 10602
    },
    {
      "epoch": 2.4363511029411766,
      "grad_norm": 1.0853335857391357,
      "learning_rate": 5.699040032679739e-06,
      "loss": 0.0389,
      "step": 10603
    },
    {
      "epoch": 2.436580882352941,
      "grad_norm": 1.0740350484848022,
      "learning_rate": 5.698529411764706e-06,
      "loss": 0.0571,
      "step": 10604
    },
    {
      "epoch": 2.436810661764706,
      "grad_norm": 0.980805516242981,
      "learning_rate": 5.698018790849673e-06,
      "loss": 0.0381,
      "step": 10605
    },
    {
      "epoch": 2.4370404411764706,
      "grad_norm": 1.0319831371307373,
      "learning_rate": 5.697508169934641e-06,
      "loss": 0.0296,
      "step": 10606
    },
    {
      "epoch": 2.4372702205882355,
      "grad_norm": 1.037331223487854,
      "learning_rate": 5.696997549019608e-06,
      "loss": 0.046,
      "step": 10607
    },
    {
      "epoch": 2.4375,
      "grad_norm": 0.8657755255699158,
      "learning_rate": 5.696486928104575e-06,
      "loss": 0.0366,
      "step": 10608
    },
    {
      "epoch": 2.4377297794117645,
      "grad_norm": 0.8465359807014465,
      "learning_rate": 5.695976307189542e-06,
      "loss": 0.0358,
      "step": 10609
    },
    {
      "epoch": 2.4379595588235294,
      "grad_norm": 1.5210936069488525,
      "learning_rate": 5.695465686274511e-06,
      "loss": 0.0548,
      "step": 10610
    },
    {
      "epoch": 2.438189338235294,
      "grad_norm": 0.9929804801940918,
      "learning_rate": 5.694955065359478e-06,
      "loss": 0.0473,
      "step": 10611
    },
    {
      "epoch": 2.438419117647059,
      "grad_norm": 1.2220616340637207,
      "learning_rate": 5.694444444444445e-06,
      "loss": 0.0516,
      "step": 10612
    },
    {
      "epoch": 2.4386488970588234,
      "grad_norm": 0.8703027963638306,
      "learning_rate": 5.693933823529412e-06,
      "loss": 0.0361,
      "step": 10613
    },
    {
      "epoch": 2.4388786764705883,
      "grad_norm": 0.8251698017120361,
      "learning_rate": 5.69342320261438e-06,
      "loss": 0.0509,
      "step": 10614
    },
    {
      "epoch": 2.439108455882353,
      "grad_norm": 0.8009593486785889,
      "learning_rate": 5.692912581699347e-06,
      "loss": 0.0336,
      "step": 10615
    },
    {
      "epoch": 2.4393382352941178,
      "grad_norm": 0.9598382115364075,
      "learning_rate": 5.692401960784314e-06,
      "loss": 0.0415,
      "step": 10616
    },
    {
      "epoch": 2.4395680147058822,
      "grad_norm": 0.9619601368904114,
      "learning_rate": 5.691891339869281e-06,
      "loss": 0.0478,
      "step": 10617
    },
    {
      "epoch": 2.439797794117647,
      "grad_norm": 0.7185539603233337,
      "learning_rate": 5.6913807189542495e-06,
      "loss": 0.0324,
      "step": 10618
    },
    {
      "epoch": 2.4400275735294117,
      "grad_norm": 0.6023650765419006,
      "learning_rate": 5.6908700980392165e-06,
      "loss": 0.0182,
      "step": 10619
    },
    {
      "epoch": 2.4402573529411766,
      "grad_norm": 0.9079580903053284,
      "learning_rate": 5.6903594771241835e-06,
      "loss": 0.0412,
      "step": 10620
    },
    {
      "epoch": 2.440487132352941,
      "grad_norm": 0.8124509453773499,
      "learning_rate": 5.6898488562091506e-06,
      "loss": 0.0273,
      "step": 10621
    },
    {
      "epoch": 2.440716911764706,
      "grad_norm": 0.7124599814414978,
      "learning_rate": 5.689338235294118e-06,
      "loss": 0.023,
      "step": 10622
    },
    {
      "epoch": 2.4409466911764706,
      "grad_norm": 0.6817243099212646,
      "learning_rate": 5.6888276143790854e-06,
      "loss": 0.02,
      "step": 10623
    },
    {
      "epoch": 2.4411764705882355,
      "grad_norm": 0.847620964050293,
      "learning_rate": 5.6883169934640524e-06,
      "loss": 0.0332,
      "step": 10624
    },
    {
      "epoch": 2.44140625,
      "grad_norm": 0.8157575130462646,
      "learning_rate": 5.6878063725490195e-06,
      "loss": 0.0433,
      "step": 10625
    },
    {
      "epoch": 2.4416360294117645,
      "grad_norm": 0.6340202689170837,
      "learning_rate": 5.687295751633987e-06,
      "loss": 0.0267,
      "step": 10626
    },
    {
      "epoch": 2.4418658088235294,
      "grad_norm": 0.9616810083389282,
      "learning_rate": 5.686785130718955e-06,
      "loss": 0.0406,
      "step": 10627
    },
    {
      "epoch": 2.442095588235294,
      "grad_norm": 1.0088387727737427,
      "learning_rate": 5.686274509803922e-06,
      "loss": 0.0496,
      "step": 10628
    },
    {
      "epoch": 2.442325367647059,
      "grad_norm": 0.9191374778747559,
      "learning_rate": 5.685763888888889e-06,
      "loss": 0.0501,
      "step": 10629
    },
    {
      "epoch": 2.4425551470588234,
      "grad_norm": 1.1545119285583496,
      "learning_rate": 5.685253267973857e-06,
      "loss": 0.0497,
      "step": 10630
    },
    {
      "epoch": 2.4427849264705883,
      "grad_norm": 1.0733699798583984,
      "learning_rate": 5.684742647058824e-06,
      "loss": 0.046,
      "step": 10631
    },
    {
      "epoch": 2.443014705882353,
      "grad_norm": 1.5864988565444946,
      "learning_rate": 5.684232026143791e-06,
      "loss": 0.0709,
      "step": 10632
    },
    {
      "epoch": 2.4432444852941178,
      "grad_norm": 0.7007380723953247,
      "learning_rate": 5.683721405228758e-06,
      "loss": 0.0341,
      "step": 10633
    },
    {
      "epoch": 2.4434742647058822,
      "grad_norm": 1.1646870374679565,
      "learning_rate": 5.683210784313726e-06,
      "loss": 0.0452,
      "step": 10634
    },
    {
      "epoch": 2.443704044117647,
      "grad_norm": 0.8812680244445801,
      "learning_rate": 5.682700163398693e-06,
      "loss": 0.0398,
      "step": 10635
    },
    {
      "epoch": 2.4439338235294117,
      "grad_norm": 0.9363178014755249,
      "learning_rate": 5.68218954248366e-06,
      "loss": 0.0333,
      "step": 10636
    },
    {
      "epoch": 2.4441636029411766,
      "grad_norm": 0.9028606414794922,
      "learning_rate": 5.681678921568627e-06,
      "loss": 0.0287,
      "step": 10637
    },
    {
      "epoch": 2.444393382352941,
      "grad_norm": 1.00787353515625,
      "learning_rate": 5.681168300653596e-06,
      "loss": 0.0364,
      "step": 10638
    },
    {
      "epoch": 2.444623161764706,
      "grad_norm": 1.1695886850357056,
      "learning_rate": 5.680657679738563e-06,
      "loss": 0.0328,
      "step": 10639
    },
    {
      "epoch": 2.4448529411764706,
      "grad_norm": 0.949396550655365,
      "learning_rate": 5.68014705882353e-06,
      "loss": 0.0409,
      "step": 10640
    },
    {
      "epoch": 2.4450827205882355,
      "grad_norm": 0.8998197317123413,
      "learning_rate": 5.679636437908497e-06,
      "loss": 0.0394,
      "step": 10641
    },
    {
      "epoch": 2.4453125,
      "grad_norm": 1.296318531036377,
      "learning_rate": 5.679125816993465e-06,
      "loss": 0.0467,
      "step": 10642
    },
    {
      "epoch": 2.4455422794117645,
      "grad_norm": 0.7609654664993286,
      "learning_rate": 5.678615196078432e-06,
      "loss": 0.0368,
      "step": 10643
    },
    {
      "epoch": 2.4457720588235294,
      "grad_norm": 0.7173675894737244,
      "learning_rate": 5.678104575163399e-06,
      "loss": 0.0292,
      "step": 10644
    },
    {
      "epoch": 2.446001838235294,
      "grad_norm": 1.0574383735656738,
      "learning_rate": 5.677593954248366e-06,
      "loss": 0.0626,
      "step": 10645
    },
    {
      "epoch": 2.446231617647059,
      "grad_norm": 0.8380923867225647,
      "learning_rate": 5.677083333333334e-06,
      "loss": 0.0399,
      "step": 10646
    },
    {
      "epoch": 2.4464613970588234,
      "grad_norm": 0.9462034106254578,
      "learning_rate": 5.676572712418301e-06,
      "loss": 0.0467,
      "step": 10647
    },
    {
      "epoch": 2.4466911764705883,
      "grad_norm": 0.9308491945266724,
      "learning_rate": 5.676062091503268e-06,
      "loss": 0.0565,
      "step": 10648
    },
    {
      "epoch": 2.446920955882353,
      "grad_norm": 1.18667471408844,
      "learning_rate": 5.6755514705882354e-06,
      "loss": 0.0364,
      "step": 10649
    },
    {
      "epoch": 2.4471507352941178,
      "grad_norm": 0.7553419470787048,
      "learning_rate": 5.675040849673203e-06,
      "loss": 0.0345,
      "step": 10650
    },
    {
      "epoch": 2.4473805147058822,
      "grad_norm": 0.9757323265075684,
      "learning_rate": 5.67453022875817e-06,
      "loss": 0.0606,
      "step": 10651
    },
    {
      "epoch": 2.447610294117647,
      "grad_norm": 1.0407768487930298,
      "learning_rate": 5.674019607843137e-06,
      "loss": 0.0587,
      "step": 10652
    },
    {
      "epoch": 2.4478400735294117,
      "grad_norm": 0.7795077562332153,
      "learning_rate": 5.673508986928104e-06,
      "loss": 0.0302,
      "step": 10653
    },
    {
      "epoch": 2.4480698529411766,
      "grad_norm": 0.8347715735435486,
      "learning_rate": 5.672998366013073e-06,
      "loss": 0.039,
      "step": 10654
    },
    {
      "epoch": 2.448299632352941,
      "grad_norm": 0.9368200302124023,
      "learning_rate": 5.67248774509804e-06,
      "loss": 0.0447,
      "step": 10655
    },
    {
      "epoch": 2.448529411764706,
      "grad_norm": 0.7098087668418884,
      "learning_rate": 5.671977124183007e-06,
      "loss": 0.0266,
      "step": 10656
    },
    {
      "epoch": 2.4487591911764706,
      "grad_norm": 0.9214525818824768,
      "learning_rate": 5.671466503267974e-06,
      "loss": 0.0385,
      "step": 10657
    },
    {
      "epoch": 2.4489889705882355,
      "grad_norm": 0.8823306560516357,
      "learning_rate": 5.670955882352942e-06,
      "loss": 0.0381,
      "step": 10658
    },
    {
      "epoch": 2.44921875,
      "grad_norm": 0.9053414463996887,
      "learning_rate": 5.670445261437909e-06,
      "loss": 0.037,
      "step": 10659
    },
    {
      "epoch": 2.4494485294117645,
      "grad_norm": 1.0410798788070679,
      "learning_rate": 5.669934640522876e-06,
      "loss": 0.0465,
      "step": 10660
    },
    {
      "epoch": 2.4496783088235294,
      "grad_norm": 1.0065709352493286,
      "learning_rate": 5.669424019607843e-06,
      "loss": 0.0505,
      "step": 10661
    },
    {
      "epoch": 2.449908088235294,
      "grad_norm": 0.9309924244880676,
      "learning_rate": 5.668913398692812e-06,
      "loss": 0.0366,
      "step": 10662
    },
    {
      "epoch": 2.450137867647059,
      "grad_norm": 0.6952416300773621,
      "learning_rate": 5.668402777777779e-06,
      "loss": 0.0261,
      "step": 10663
    },
    {
      "epoch": 2.4503676470588234,
      "grad_norm": 1.2492763996124268,
      "learning_rate": 5.667892156862746e-06,
      "loss": 0.0544,
      "step": 10664
    },
    {
      "epoch": 2.4505974264705883,
      "grad_norm": 1.6326258182525635,
      "learning_rate": 5.667381535947713e-06,
      "loss": 0.0536,
      "step": 10665
    },
    {
      "epoch": 2.450827205882353,
      "grad_norm": 0.904492199420929,
      "learning_rate": 5.666870915032681e-06,
      "loss": 0.0351,
      "step": 10666
    },
    {
      "epoch": 2.4510569852941178,
      "grad_norm": 0.9700260162353516,
      "learning_rate": 5.666360294117648e-06,
      "loss": 0.0504,
      "step": 10667
    },
    {
      "epoch": 2.4512867647058822,
      "grad_norm": 1.0027707815170288,
      "learning_rate": 5.665849673202615e-06,
      "loss": 0.0637,
      "step": 10668
    },
    {
      "epoch": 2.451516544117647,
      "grad_norm": 1.0185532569885254,
      "learning_rate": 5.665339052287582e-06,
      "loss": 0.046,
      "step": 10669
    },
    {
      "epoch": 2.4517463235294117,
      "grad_norm": 0.7184358835220337,
      "learning_rate": 5.6648284313725495e-06,
      "loss": 0.0375,
      "step": 10670
    },
    {
      "epoch": 2.4519761029411766,
      "grad_norm": 0.7715970277786255,
      "learning_rate": 5.6643178104575165e-06,
      "loss": 0.0414,
      "step": 10671
    },
    {
      "epoch": 2.452205882352941,
      "grad_norm": 0.8819371461868286,
      "learning_rate": 5.663807189542484e-06,
      "loss": 0.053,
      "step": 10672
    },
    {
      "epoch": 2.452435661764706,
      "grad_norm": 1.094018578529358,
      "learning_rate": 5.663296568627451e-06,
      "loss": 0.0383,
      "step": 10673
    },
    {
      "epoch": 2.4526654411764706,
      "grad_norm": 1.0135306119918823,
      "learning_rate": 5.662785947712419e-06,
      "loss": 0.0346,
      "step": 10674
    },
    {
      "epoch": 2.4528952205882355,
      "grad_norm": 0.8381379842758179,
      "learning_rate": 5.662275326797386e-06,
      "loss": 0.0429,
      "step": 10675
    },
    {
      "epoch": 2.453125,
      "grad_norm": 0.8930066823959351,
      "learning_rate": 5.661764705882353e-06,
      "loss": 0.0335,
      "step": 10676
    },
    {
      "epoch": 2.4533547794117645,
      "grad_norm": 1.0050932168960571,
      "learning_rate": 5.66125408496732e-06,
      "loss": 0.0367,
      "step": 10677
    },
    {
      "epoch": 2.4535845588235294,
      "grad_norm": 0.9134015440940857,
      "learning_rate": 5.660743464052288e-06,
      "loss": 0.0503,
      "step": 10678
    },
    {
      "epoch": 2.453814338235294,
      "grad_norm": 1.0559097528457642,
      "learning_rate": 5.660232843137255e-06,
      "loss": 0.0413,
      "step": 10679
    },
    {
      "epoch": 2.454044117647059,
      "grad_norm": 0.6639849543571472,
      "learning_rate": 5.659722222222222e-06,
      "loss": 0.0252,
      "step": 10680
    },
    {
      "epoch": 2.4542738970588234,
      "grad_norm": 0.8627140522003174,
      "learning_rate": 5.659211601307189e-06,
      "loss": 0.0321,
      "step": 10681
    },
    {
      "epoch": 2.4545036764705883,
      "grad_norm": 1.5165108442306519,
      "learning_rate": 5.658700980392158e-06,
      "loss": 0.0344,
      "step": 10682
    },
    {
      "epoch": 2.454733455882353,
      "grad_norm": 0.8875823616981506,
      "learning_rate": 5.658190359477125e-06,
      "loss": 0.0328,
      "step": 10683
    },
    {
      "epoch": 2.4549632352941178,
      "grad_norm": 0.7356099486351013,
      "learning_rate": 5.657679738562092e-06,
      "loss": 0.0377,
      "step": 10684
    },
    {
      "epoch": 2.4551930147058822,
      "grad_norm": 1.4221045970916748,
      "learning_rate": 5.657169117647059e-06,
      "loss": 0.0692,
      "step": 10685
    },
    {
      "epoch": 2.455422794117647,
      "grad_norm": 1.0156116485595703,
      "learning_rate": 5.656658496732027e-06,
      "loss": 0.0444,
      "step": 10686
    },
    {
      "epoch": 2.4556525735294117,
      "grad_norm": 0.6449425220489502,
      "learning_rate": 5.656147875816994e-06,
      "loss": 0.0242,
      "step": 10687
    },
    {
      "epoch": 2.4558823529411766,
      "grad_norm": 0.635774552822113,
      "learning_rate": 5.655637254901961e-06,
      "loss": 0.0317,
      "step": 10688
    },
    {
      "epoch": 2.456112132352941,
      "grad_norm": 1.1058439016342163,
      "learning_rate": 5.655126633986928e-06,
      "loss": 0.0596,
      "step": 10689
    },
    {
      "epoch": 2.456341911764706,
      "grad_norm": 0.9411917924880981,
      "learning_rate": 5.6546160130718966e-06,
      "loss": 0.0544,
      "step": 10690
    },
    {
      "epoch": 2.4565716911764706,
      "grad_norm": 0.8411248326301575,
      "learning_rate": 5.654105392156864e-06,
      "loss": 0.0334,
      "step": 10691
    },
    {
      "epoch": 2.4568014705882355,
      "grad_norm": 0.737145721912384,
      "learning_rate": 5.653594771241831e-06,
      "loss": 0.0305,
      "step": 10692
    },
    {
      "epoch": 2.45703125,
      "grad_norm": 0.8738811612129211,
      "learning_rate": 5.653084150326798e-06,
      "loss": 0.0457,
      "step": 10693
    },
    {
      "epoch": 2.4572610294117645,
      "grad_norm": 0.7264594435691833,
      "learning_rate": 5.6525735294117655e-06,
      "loss": 0.022,
      "step": 10694
    },
    {
      "epoch": 2.4574908088235294,
      "grad_norm": 1.170835256576538,
      "learning_rate": 5.6520629084967325e-06,
      "loss": 0.0605,
      "step": 10695
    },
    {
      "epoch": 2.457720588235294,
      "grad_norm": 1.0053600072860718,
      "learning_rate": 5.6515522875816995e-06,
      "loss": 0.0438,
      "step": 10696
    },
    {
      "epoch": 2.457950367647059,
      "grad_norm": 1.2738771438598633,
      "learning_rate": 5.6510416666666665e-06,
      "loss": 0.0371,
      "step": 10697
    },
    {
      "epoch": 2.4581801470588234,
      "grad_norm": 0.9555581212043762,
      "learning_rate": 5.650531045751635e-06,
      "loss": 0.0433,
      "step": 10698
    },
    {
      "epoch": 2.4584099264705883,
      "grad_norm": 1.080103874206543,
      "learning_rate": 5.650020424836602e-06,
      "loss": 0.0342,
      "step": 10699
    },
    {
      "epoch": 2.458639705882353,
      "grad_norm": 1.3084620237350464,
      "learning_rate": 5.649509803921569e-06,
      "loss": 0.0404,
      "step": 10700
    },
    {
      "epoch": 2.4588694852941178,
      "grad_norm": 0.8966876268386841,
      "learning_rate": 5.648999183006536e-06,
      "loss": 0.0517,
      "step": 10701
    },
    {
      "epoch": 2.4590992647058822,
      "grad_norm": 1.0319890975952148,
      "learning_rate": 5.648488562091504e-06,
      "loss": 0.0649,
      "step": 10702
    },
    {
      "epoch": 2.459329044117647,
      "grad_norm": 0.7522101402282715,
      "learning_rate": 5.647977941176471e-06,
      "loss": 0.0291,
      "step": 10703
    },
    {
      "epoch": 2.4595588235294117,
      "grad_norm": 0.9919195175170898,
      "learning_rate": 5.647467320261438e-06,
      "loss": 0.0501,
      "step": 10704
    },
    {
      "epoch": 2.4597886029411766,
      "grad_norm": 1.3514955043792725,
      "learning_rate": 5.646956699346405e-06,
      "loss": 0.0443,
      "step": 10705
    },
    {
      "epoch": 2.460018382352941,
      "grad_norm": 0.7360989451408386,
      "learning_rate": 5.646446078431374e-06,
      "loss": 0.0445,
      "step": 10706
    },
    {
      "epoch": 2.460248161764706,
      "grad_norm": 1.0244237184524536,
      "learning_rate": 5.645935457516341e-06,
      "loss": 0.0366,
      "step": 10707
    },
    {
      "epoch": 2.4604779411764706,
      "grad_norm": 0.8336371183395386,
      "learning_rate": 5.645424836601308e-06,
      "loss": 0.0371,
      "step": 10708
    },
    {
      "epoch": 2.4607077205882355,
      "grad_norm": 1.0953314304351807,
      "learning_rate": 5.644914215686275e-06,
      "loss": 0.0374,
      "step": 10709
    },
    {
      "epoch": 2.4609375,
      "grad_norm": 0.9429643750190735,
      "learning_rate": 5.644403594771243e-06,
      "loss": 0.0407,
      "step": 10710
    },
    {
      "epoch": 2.4611672794117645,
      "grad_norm": 1.362596035003662,
      "learning_rate": 5.64389297385621e-06,
      "loss": 0.0618,
      "step": 10711
    },
    {
      "epoch": 2.4613970588235294,
      "grad_norm": 0.8523026704788208,
      "learning_rate": 5.643382352941177e-06,
      "loss": 0.0286,
      "step": 10712
    },
    {
      "epoch": 2.461626838235294,
      "grad_norm": 0.6953300833702087,
      "learning_rate": 5.642871732026144e-06,
      "loss": 0.0236,
      "step": 10713
    },
    {
      "epoch": 2.461856617647059,
      "grad_norm": 0.9021278619766235,
      "learning_rate": 5.642361111111112e-06,
      "loss": 0.0249,
      "step": 10714
    },
    {
      "epoch": 2.4620863970588234,
      "grad_norm": 0.8000320792198181,
      "learning_rate": 5.641850490196079e-06,
      "loss": 0.0405,
      "step": 10715
    },
    {
      "epoch": 2.4623161764705883,
      "grad_norm": 0.8604138493537903,
      "learning_rate": 5.6413398692810466e-06,
      "loss": 0.0423,
      "step": 10716
    },
    {
      "epoch": 2.462545955882353,
      "grad_norm": 1.1502209901809692,
      "learning_rate": 5.640829248366014e-06,
      "loss": 0.0378,
      "step": 10717
    },
    {
      "epoch": 2.4627757352941178,
      "grad_norm": 0.8204827904701233,
      "learning_rate": 5.6403186274509815e-06,
      "loss": 0.0538,
      "step": 10718
    },
    {
      "epoch": 2.4630055147058822,
      "grad_norm": 0.7820489406585693,
      "learning_rate": 5.6398080065359485e-06,
      "loss": 0.0323,
      "step": 10719
    },
    {
      "epoch": 2.463235294117647,
      "grad_norm": 0.7429953217506409,
      "learning_rate": 5.6392973856209155e-06,
      "loss": 0.0281,
      "step": 10720
    },
    {
      "epoch": 2.4634650735294117,
      "grad_norm": 1.0374486446380615,
      "learning_rate": 5.6387867647058825e-06,
      "loss": 0.0466,
      "step": 10721
    },
    {
      "epoch": 2.4636948529411766,
      "grad_norm": 1.3692373037338257,
      "learning_rate": 5.63827614379085e-06,
      "loss": 0.0473,
      "step": 10722
    },
    {
      "epoch": 2.463924632352941,
      "grad_norm": 0.835625946521759,
      "learning_rate": 5.637765522875817e-06,
      "loss": 0.0437,
      "step": 10723
    },
    {
      "epoch": 2.464154411764706,
      "grad_norm": 1.0926427841186523,
      "learning_rate": 5.637254901960784e-06,
      "loss": 0.0588,
      "step": 10724
    },
    {
      "epoch": 2.4643841911764706,
      "grad_norm": 0.8817872405052185,
      "learning_rate": 5.636744281045751e-06,
      "loss": 0.0433,
      "step": 10725
    },
    {
      "epoch": 2.4646139705882355,
      "grad_norm": 0.9738894104957581,
      "learning_rate": 5.63623366013072e-06,
      "loss": 0.0298,
      "step": 10726
    },
    {
      "epoch": 2.46484375,
      "grad_norm": 0.8429162502288818,
      "learning_rate": 5.635723039215687e-06,
      "loss": 0.0269,
      "step": 10727
    },
    {
      "epoch": 2.4650735294117645,
      "grad_norm": 1.0480008125305176,
      "learning_rate": 5.635212418300654e-06,
      "loss": 0.0638,
      "step": 10728
    },
    {
      "epoch": 2.4653033088235294,
      "grad_norm": 0.7725301384925842,
      "learning_rate": 5.634701797385621e-06,
      "loss": 0.0342,
      "step": 10729
    },
    {
      "epoch": 2.465533088235294,
      "grad_norm": 0.717478334903717,
      "learning_rate": 5.634191176470589e-06,
      "loss": 0.0376,
      "step": 10730
    },
    {
      "epoch": 2.465762867647059,
      "grad_norm": 0.7603731155395508,
      "learning_rate": 5.633680555555556e-06,
      "loss": 0.0309,
      "step": 10731
    },
    {
      "epoch": 2.4659926470588234,
      "grad_norm": 1.045385479927063,
      "learning_rate": 5.633169934640523e-06,
      "loss": 0.0359,
      "step": 10732
    },
    {
      "epoch": 2.4662224264705883,
      "grad_norm": 0.913813591003418,
      "learning_rate": 5.63265931372549e-06,
      "loss": 0.0427,
      "step": 10733
    },
    {
      "epoch": 2.466452205882353,
      "grad_norm": 0.9786044955253601,
      "learning_rate": 5.632148692810459e-06,
      "loss": 0.042,
      "step": 10734
    },
    {
      "epoch": 2.4666819852941178,
      "grad_norm": 1.2236552238464355,
      "learning_rate": 5.631638071895426e-06,
      "loss": 0.0378,
      "step": 10735
    },
    {
      "epoch": 2.4669117647058822,
      "grad_norm": 1.8041056394577026,
      "learning_rate": 5.631127450980393e-06,
      "loss": 0.0511,
      "step": 10736
    },
    {
      "epoch": 2.467141544117647,
      "grad_norm": 1.0104925632476807,
      "learning_rate": 5.63061683006536e-06,
      "loss": 0.0595,
      "step": 10737
    },
    {
      "epoch": 2.4673713235294117,
      "grad_norm": 0.9625248908996582,
      "learning_rate": 5.630106209150328e-06,
      "loss": 0.0246,
      "step": 10738
    },
    {
      "epoch": 2.4676011029411766,
      "grad_norm": 0.8010322451591492,
      "learning_rate": 5.629595588235295e-06,
      "loss": 0.0331,
      "step": 10739
    },
    {
      "epoch": 2.467830882352941,
      "grad_norm": 0.9829199910163879,
      "learning_rate": 5.629084967320262e-06,
      "loss": 0.043,
      "step": 10740
    },
    {
      "epoch": 2.468060661764706,
      "grad_norm": 0.8349037766456604,
      "learning_rate": 5.628574346405229e-06,
      "loss": 0.0296,
      "step": 10741
    },
    {
      "epoch": 2.4682904411764706,
      "grad_norm": 0.8548192977905273,
      "learning_rate": 5.628063725490197e-06,
      "loss": 0.0313,
      "step": 10742
    },
    {
      "epoch": 2.4685202205882355,
      "grad_norm": 1.093940258026123,
      "learning_rate": 5.6275531045751644e-06,
      "loss": 0.0321,
      "step": 10743
    },
    {
      "epoch": 2.46875,
      "grad_norm": 0.9671849012374878,
      "learning_rate": 5.6270424836601314e-06,
      "loss": 0.0483,
      "step": 10744
    },
    {
      "epoch": 2.4689797794117645,
      "grad_norm": 0.8098476529121399,
      "learning_rate": 5.6265318627450985e-06,
      "loss": 0.0328,
      "step": 10745
    },
    {
      "epoch": 2.4692095588235294,
      "grad_norm": 0.8927667140960693,
      "learning_rate": 5.626021241830066e-06,
      "loss": 0.0345,
      "step": 10746
    },
    {
      "epoch": 2.469439338235294,
      "grad_norm": 1.3390281200408936,
      "learning_rate": 5.625510620915033e-06,
      "loss": 0.0589,
      "step": 10747
    },
    {
      "epoch": 2.469669117647059,
      "grad_norm": 1.0421733856201172,
      "learning_rate": 5.625e-06,
      "loss": 0.0445,
      "step": 10748
    },
    {
      "epoch": 2.4698988970588234,
      "grad_norm": 0.9829736351966858,
      "learning_rate": 5.624489379084967e-06,
      "loss": 0.0304,
      "step": 10749
    },
    {
      "epoch": 2.4701286764705883,
      "grad_norm": 1.009489893913269,
      "learning_rate": 5.623978758169934e-06,
      "loss": 0.034,
      "step": 10750
    },
    {
      "epoch": 2.470358455882353,
      "grad_norm": 0.9689818024635315,
      "learning_rate": 5.623468137254903e-06,
      "loss": 0.0341,
      "step": 10751
    },
    {
      "epoch": 2.4705882352941178,
      "grad_norm": 0.7491319179534912,
      "learning_rate": 5.62295751633987e-06,
      "loss": 0.0205,
      "step": 10752
    },
    {
      "epoch": 2.4708180147058822,
      "grad_norm": 1.623307466506958,
      "learning_rate": 5.622446895424837e-06,
      "loss": 0.0479,
      "step": 10753
    },
    {
      "epoch": 2.471047794117647,
      "grad_norm": 0.9571521878242493,
      "learning_rate": 5.621936274509804e-06,
      "loss": 0.0493,
      "step": 10754
    },
    {
      "epoch": 2.4712775735294117,
      "grad_norm": 0.9382907748222351,
      "learning_rate": 5.621425653594772e-06,
      "loss": 0.0411,
      "step": 10755
    },
    {
      "epoch": 2.4715073529411766,
      "grad_norm": 0.9677988886833191,
      "learning_rate": 5.620915032679739e-06,
      "loss": 0.0458,
      "step": 10756
    },
    {
      "epoch": 2.471737132352941,
      "grad_norm": 1.0618034601211548,
      "learning_rate": 5.620404411764706e-06,
      "loss": 0.0282,
      "step": 10757
    },
    {
      "epoch": 2.471966911764706,
      "grad_norm": 1.1105118989944458,
      "learning_rate": 5.619893790849673e-06,
      "loss": 0.0507,
      "step": 10758
    },
    {
      "epoch": 2.4721966911764706,
      "grad_norm": 0.9147427678108215,
      "learning_rate": 5.619383169934641e-06,
      "loss": 0.0387,
      "step": 10759
    },
    {
      "epoch": 2.4724264705882355,
      "grad_norm": 0.9260653257369995,
      "learning_rate": 5.618872549019608e-06,
      "loss": 0.0326,
      "step": 10760
    },
    {
      "epoch": 2.47265625,
      "grad_norm": 0.7087405920028687,
      "learning_rate": 5.618361928104576e-06,
      "loss": 0.0294,
      "step": 10761
    },
    {
      "epoch": 2.4728860294117645,
      "grad_norm": 1.0091713666915894,
      "learning_rate": 5.617851307189543e-06,
      "loss": 0.0341,
      "step": 10762
    },
    {
      "epoch": 2.4731158088235294,
      "grad_norm": 1.1575345993041992,
      "learning_rate": 5.617340686274511e-06,
      "loss": 0.0535,
      "step": 10763
    },
    {
      "epoch": 2.473345588235294,
      "grad_norm": 1.2919999361038208,
      "learning_rate": 5.616830065359478e-06,
      "loss": 0.0542,
      "step": 10764
    },
    {
      "epoch": 2.473575367647059,
      "grad_norm": 1.0461593866348267,
      "learning_rate": 5.616319444444445e-06,
      "loss": 0.0526,
      "step": 10765
    },
    {
      "epoch": 2.4738051470588234,
      "grad_norm": 1.1292176246643066,
      "learning_rate": 5.615808823529412e-06,
      "loss": 0.0587,
      "step": 10766
    },
    {
      "epoch": 2.4740349264705883,
      "grad_norm": 1.1330846548080444,
      "learning_rate": 5.6152982026143796e-06,
      "loss": 0.0552,
      "step": 10767
    },
    {
      "epoch": 2.474264705882353,
      "grad_norm": 1.0522191524505615,
      "learning_rate": 5.6147875816993466e-06,
      "loss": 0.0405,
      "step": 10768
    },
    {
      "epoch": 2.4744944852941178,
      "grad_norm": 0.6115285754203796,
      "learning_rate": 5.614276960784314e-06,
      "loss": 0.0255,
      "step": 10769
    },
    {
      "epoch": 2.4747242647058822,
      "grad_norm": 1.1741206645965576,
      "learning_rate": 5.613766339869281e-06,
      "loss": 0.0405,
      "step": 10770
    },
    {
      "epoch": 2.474954044117647,
      "grad_norm": 0.9189472794532776,
      "learning_rate": 5.613255718954249e-06,
      "loss": 0.0409,
      "step": 10771
    },
    {
      "epoch": 2.4751838235294117,
      "grad_norm": 0.9201225638389587,
      "learning_rate": 5.612745098039216e-06,
      "loss": 0.0298,
      "step": 10772
    },
    {
      "epoch": 2.4754136029411766,
      "grad_norm": 0.8381252288818359,
      "learning_rate": 5.612234477124183e-06,
      "loss": 0.0385,
      "step": 10773
    },
    {
      "epoch": 2.475643382352941,
      "grad_norm": 0.9033945202827454,
      "learning_rate": 5.61172385620915e-06,
      "loss": 0.0292,
      "step": 10774
    },
    {
      "epoch": 2.475873161764706,
      "grad_norm": 0.744329571723938,
      "learning_rate": 5.611213235294118e-06,
      "loss": 0.0376,
      "step": 10775
    },
    {
      "epoch": 2.4761029411764706,
      "grad_norm": 0.6511391997337341,
      "learning_rate": 5.610702614379085e-06,
      "loss": 0.0195,
      "step": 10776
    },
    {
      "epoch": 2.4763327205882355,
      "grad_norm": 1.0360760688781738,
      "learning_rate": 5.610191993464052e-06,
      "loss": 0.0388,
      "step": 10777
    },
    {
      "epoch": 2.4765625,
      "grad_norm": 0.82813560962677,
      "learning_rate": 5.609681372549019e-06,
      "loss": 0.0415,
      "step": 10778
    },
    {
      "epoch": 2.4767922794117645,
      "grad_norm": 1.2683192491531372,
      "learning_rate": 5.609170751633988e-06,
      "loss": 0.0399,
      "step": 10779
    },
    {
      "epoch": 2.4770220588235294,
      "grad_norm": 0.8709676265716553,
      "learning_rate": 5.608660130718955e-06,
      "loss": 0.043,
      "step": 10780
    },
    {
      "epoch": 2.477251838235294,
      "grad_norm": 0.843352735042572,
      "learning_rate": 5.608149509803922e-06,
      "loss": 0.0364,
      "step": 10781
    },
    {
      "epoch": 2.477481617647059,
      "grad_norm": 0.9553788304328918,
      "learning_rate": 5.607638888888889e-06,
      "loss": 0.0404,
      "step": 10782
    },
    {
      "epoch": 2.4777113970588234,
      "grad_norm": 0.9455300569534302,
      "learning_rate": 5.607128267973857e-06,
      "loss": 0.0318,
      "step": 10783
    },
    {
      "epoch": 2.4779411764705883,
      "grad_norm": 0.9793989062309265,
      "learning_rate": 5.606617647058824e-06,
      "loss": 0.0344,
      "step": 10784
    },
    {
      "epoch": 2.478170955882353,
      "grad_norm": 0.9839033484458923,
      "learning_rate": 5.606107026143791e-06,
      "loss": 0.0429,
      "step": 10785
    },
    {
      "epoch": 2.4784007352941178,
      "grad_norm": 1.1146618127822876,
      "learning_rate": 5.605596405228758e-06,
      "loss": 0.0404,
      "step": 10786
    },
    {
      "epoch": 2.4786305147058822,
      "grad_norm": 1.0013993978500366,
      "learning_rate": 5.605085784313727e-06,
      "loss": 0.0488,
      "step": 10787
    },
    {
      "epoch": 2.478860294117647,
      "grad_norm": 0.9571378827095032,
      "learning_rate": 5.604575163398694e-06,
      "loss": 0.0382,
      "step": 10788
    },
    {
      "epoch": 2.4790900735294117,
      "grad_norm": 0.7901171445846558,
      "learning_rate": 5.604064542483661e-06,
      "loss": 0.0244,
      "step": 10789
    },
    {
      "epoch": 2.4793198529411766,
      "grad_norm": 0.6819028854370117,
      "learning_rate": 5.603553921568628e-06,
      "loss": 0.022,
      "step": 10790
    },
    {
      "epoch": 2.479549632352941,
      "grad_norm": 1.0129238367080688,
      "learning_rate": 5.6030433006535955e-06,
      "loss": 0.0454,
      "step": 10791
    },
    {
      "epoch": 2.479779411764706,
      "grad_norm": 0.8881890177726746,
      "learning_rate": 5.6025326797385625e-06,
      "loss": 0.039,
      "step": 10792
    },
    {
      "epoch": 2.4800091911764706,
      "grad_norm": 0.8194876313209534,
      "learning_rate": 5.6020220588235296e-06,
      "loss": 0.0437,
      "step": 10793
    },
    {
      "epoch": 2.4802389705882355,
      "grad_norm": 0.6385701298713684,
      "learning_rate": 5.6015114379084966e-06,
      "loss": 0.0286,
      "step": 10794
    },
    {
      "epoch": 2.48046875,
      "grad_norm": 1.1329787969589233,
      "learning_rate": 5.601000816993465e-06,
      "loss": 0.0446,
      "step": 10795
    },
    {
      "epoch": 2.4806985294117645,
      "grad_norm": 0.6083999276161194,
      "learning_rate": 5.600490196078432e-06,
      "loss": 0.0213,
      "step": 10796
    },
    {
      "epoch": 2.4809283088235294,
      "grad_norm": 0.9683430790901184,
      "learning_rate": 5.599979575163399e-06,
      "loss": 0.0368,
      "step": 10797
    },
    {
      "epoch": 2.481158088235294,
      "grad_norm": 1.3691825866699219,
      "learning_rate": 5.599468954248366e-06,
      "loss": 0.0316,
      "step": 10798
    },
    {
      "epoch": 2.481387867647059,
      "grad_norm": 1.1416349411010742,
      "learning_rate": 5.598958333333334e-06,
      "loss": 0.0555,
      "step": 10799
    },
    {
      "epoch": 2.4816176470588234,
      "grad_norm": 1.2476214170455933,
      "learning_rate": 5.598447712418301e-06,
      "loss": 0.047,
      "step": 10800
    },
    {
      "epoch": 2.4818474264705883,
      "grad_norm": 0.8939810395240784,
      "learning_rate": 5.597937091503268e-06,
      "loss": 0.0393,
      "step": 10801
    },
    {
      "epoch": 2.482077205882353,
      "grad_norm": 0.9201463460922241,
      "learning_rate": 5.597426470588235e-06,
      "loss": 0.0352,
      "step": 10802
    },
    {
      "epoch": 2.4823069852941178,
      "grad_norm": 0.8400843143463135,
      "learning_rate": 5.596915849673203e-06,
      "loss": 0.0373,
      "step": 10803
    },
    {
      "epoch": 2.4825367647058822,
      "grad_norm": 1.0136206150054932,
      "learning_rate": 5.59640522875817e-06,
      "loss": 0.0587,
      "step": 10804
    },
    {
      "epoch": 2.482766544117647,
      "grad_norm": 0.7514461278915405,
      "learning_rate": 5.595894607843137e-06,
      "loss": 0.0324,
      "step": 10805
    },
    {
      "epoch": 2.4829963235294117,
      "grad_norm": 0.8689795732498169,
      "learning_rate": 5.595383986928105e-06,
      "loss": 0.0418,
      "step": 10806
    },
    {
      "epoch": 2.4832261029411766,
      "grad_norm": 0.8632826805114746,
      "learning_rate": 5.594873366013073e-06,
      "loss": 0.0455,
      "step": 10807
    },
    {
      "epoch": 2.483455882352941,
      "grad_norm": 0.7460640072822571,
      "learning_rate": 5.59436274509804e-06,
      "loss": 0.0393,
      "step": 10808
    },
    {
      "epoch": 2.483685661764706,
      "grad_norm": 0.9680513739585876,
      "learning_rate": 5.593852124183007e-06,
      "loss": 0.0305,
      "step": 10809
    },
    {
      "epoch": 2.4839154411764706,
      "grad_norm": 1.0210158824920654,
      "learning_rate": 5.593341503267974e-06,
      "loss": 0.0513,
      "step": 10810
    },
    {
      "epoch": 2.4841452205882355,
      "grad_norm": 1.0416914224624634,
      "learning_rate": 5.592830882352942e-06,
      "loss": 0.0392,
      "step": 10811
    },
    {
      "epoch": 2.484375,
      "grad_norm": 0.6828746199607849,
      "learning_rate": 5.592320261437909e-06,
      "loss": 0.0214,
      "step": 10812
    },
    {
      "epoch": 2.4846047794117645,
      "grad_norm": 0.8696187734603882,
      "learning_rate": 5.591809640522876e-06,
      "loss": 0.0208,
      "step": 10813
    },
    {
      "epoch": 2.4848345588235294,
      "grad_norm": 0.8733327984809875,
      "learning_rate": 5.591299019607843e-06,
      "loss": 0.0358,
      "step": 10814
    },
    {
      "epoch": 2.485064338235294,
      "grad_norm": 1.8672946691513062,
      "learning_rate": 5.5907883986928115e-06,
      "loss": 0.0486,
      "step": 10815
    },
    {
      "epoch": 2.485294117647059,
      "grad_norm": 1.2170674800872803,
      "learning_rate": 5.5902777777777785e-06,
      "loss": 0.0681,
      "step": 10816
    },
    {
      "epoch": 2.4855238970588234,
      "grad_norm": 0.9986416101455688,
      "learning_rate": 5.5897671568627455e-06,
      "loss": 0.0487,
      "step": 10817
    },
    {
      "epoch": 2.4857536764705883,
      "grad_norm": 1.0432075262069702,
      "learning_rate": 5.5892565359477125e-06,
      "loss": 0.0377,
      "step": 10818
    },
    {
      "epoch": 2.485983455882353,
      "grad_norm": 0.878452718257904,
      "learning_rate": 5.58874591503268e-06,
      "loss": 0.0449,
      "step": 10819
    },
    {
      "epoch": 2.4862132352941178,
      "grad_norm": 1.2283720970153809,
      "learning_rate": 5.588235294117647e-06,
      "loss": 0.0596,
      "step": 10820
    },
    {
      "epoch": 2.4864430147058822,
      "grad_norm": 0.8567518591880798,
      "learning_rate": 5.5877246732026144e-06,
      "loss": 0.0251,
      "step": 10821
    },
    {
      "epoch": 2.486672794117647,
      "grad_norm": 0.6970855593681335,
      "learning_rate": 5.5872140522875814e-06,
      "loss": 0.0283,
      "step": 10822
    },
    {
      "epoch": 2.4869025735294117,
      "grad_norm": 0.7205060720443726,
      "learning_rate": 5.58670343137255e-06,
      "loss": 0.0362,
      "step": 10823
    },
    {
      "epoch": 2.4871323529411766,
      "grad_norm": 1.3281117677688599,
      "learning_rate": 5.586192810457517e-06,
      "loss": 0.039,
      "step": 10824
    },
    {
      "epoch": 2.487362132352941,
      "grad_norm": 1.3617783784866333,
      "learning_rate": 5.585682189542484e-06,
      "loss": 0.0554,
      "step": 10825
    },
    {
      "epoch": 2.487591911764706,
      "grad_norm": 0.8923144936561584,
      "learning_rate": 5.585171568627451e-06,
      "loss": 0.0373,
      "step": 10826
    },
    {
      "epoch": 2.4878216911764706,
      "grad_norm": 1.117605209350586,
      "learning_rate": 5.584660947712419e-06,
      "loss": 0.0438,
      "step": 10827
    },
    {
      "epoch": 2.4880514705882355,
      "grad_norm": 0.8614602088928223,
      "learning_rate": 5.584150326797386e-06,
      "loss": 0.0334,
      "step": 10828
    },
    {
      "epoch": 2.48828125,
      "grad_norm": 1.5760767459869385,
      "learning_rate": 5.583639705882353e-06,
      "loss": 0.0476,
      "step": 10829
    },
    {
      "epoch": 2.4885110294117645,
      "grad_norm": 0.8161511421203613,
      "learning_rate": 5.58312908496732e-06,
      "loss": 0.0284,
      "step": 10830
    },
    {
      "epoch": 2.4887408088235294,
      "grad_norm": 0.9793705344200134,
      "learning_rate": 5.582618464052289e-06,
      "loss": 0.0346,
      "step": 10831
    },
    {
      "epoch": 2.488970588235294,
      "grad_norm": 1.272939920425415,
      "learning_rate": 5.582107843137256e-06,
      "loss": 0.0662,
      "step": 10832
    },
    {
      "epoch": 2.489200367647059,
      "grad_norm": 0.7837589979171753,
      "learning_rate": 5.581597222222223e-06,
      "loss": 0.0384,
      "step": 10833
    },
    {
      "epoch": 2.4894301470588234,
      "grad_norm": 1.1232290267944336,
      "learning_rate": 5.58108660130719e-06,
      "loss": 0.0394,
      "step": 10834
    },
    {
      "epoch": 2.4896599264705883,
      "grad_norm": 1.1064887046813965,
      "learning_rate": 5.580575980392158e-06,
      "loss": 0.0325,
      "step": 10835
    },
    {
      "epoch": 2.489889705882353,
      "grad_norm": 0.7465431690216064,
      "learning_rate": 5.580065359477125e-06,
      "loss": 0.027,
      "step": 10836
    },
    {
      "epoch": 2.4901194852941178,
      "grad_norm": 1.6005680561065674,
      "learning_rate": 5.579554738562092e-06,
      "loss": 0.0533,
      "step": 10837
    },
    {
      "epoch": 2.4903492647058822,
      "grad_norm": 0.7762412428855896,
      "learning_rate": 5.579044117647059e-06,
      "loss": 0.026,
      "step": 10838
    },
    {
      "epoch": 2.490579044117647,
      "grad_norm": 1.9291410446166992,
      "learning_rate": 5.578533496732027e-06,
      "loss": 0.0474,
      "step": 10839
    },
    {
      "epoch": 2.4908088235294117,
      "grad_norm": 0.9881446361541748,
      "learning_rate": 5.5780228758169945e-06,
      "loss": 0.0309,
      "step": 10840
    },
    {
      "epoch": 2.4910386029411766,
      "grad_norm": 0.9481668472290039,
      "learning_rate": 5.5775122549019615e-06,
      "loss": 0.0582,
      "step": 10841
    },
    {
      "epoch": 2.491268382352941,
      "grad_norm": 1.2315912246704102,
      "learning_rate": 5.5770016339869285e-06,
      "loss": 0.0402,
      "step": 10842
    },
    {
      "epoch": 2.491498161764706,
      "grad_norm": 0.8129465579986572,
      "learning_rate": 5.576491013071896e-06,
      "loss": 0.0317,
      "step": 10843
    },
    {
      "epoch": 2.4917279411764706,
      "grad_norm": 0.843496561050415,
      "learning_rate": 5.575980392156863e-06,
      "loss": 0.0379,
      "step": 10844
    },
    {
      "epoch": 2.4919577205882355,
      "grad_norm": 0.8521574139595032,
      "learning_rate": 5.57546977124183e-06,
      "loss": 0.0339,
      "step": 10845
    },
    {
      "epoch": 2.4921875,
      "grad_norm": 0.7492735385894775,
      "learning_rate": 5.574959150326797e-06,
      "loss": 0.0265,
      "step": 10846
    },
    {
      "epoch": 2.4924172794117645,
      "grad_norm": 0.9786662459373474,
      "learning_rate": 5.574448529411765e-06,
      "loss": 0.0474,
      "step": 10847
    },
    {
      "epoch": 2.4926470588235294,
      "grad_norm": 1.1238963603973389,
      "learning_rate": 5.573937908496732e-06,
      "loss": 0.0742,
      "step": 10848
    },
    {
      "epoch": 2.492876838235294,
      "grad_norm": 0.8801175951957703,
      "learning_rate": 5.573427287581699e-06,
      "loss": 0.047,
      "step": 10849
    },
    {
      "epoch": 2.493106617647059,
      "grad_norm": 0.9316568374633789,
      "learning_rate": 5.572916666666667e-06,
      "loss": 0.0321,
      "step": 10850
    },
    {
      "epoch": 2.4933363970588234,
      "grad_norm": 1.0104564428329468,
      "learning_rate": 5.572406045751635e-06,
      "loss": 0.0374,
      "step": 10851
    },
    {
      "epoch": 2.4935661764705883,
      "grad_norm": 1.3785769939422607,
      "learning_rate": 5.571895424836602e-06,
      "loss": 0.0438,
      "step": 10852
    },
    {
      "epoch": 2.493795955882353,
      "grad_norm": 0.8590538501739502,
      "learning_rate": 5.571384803921569e-06,
      "loss": 0.0334,
      "step": 10853
    },
    {
      "epoch": 2.4940257352941178,
      "grad_norm": 0.9300900101661682,
      "learning_rate": 5.570874183006536e-06,
      "loss": 0.0416,
      "step": 10854
    },
    {
      "epoch": 2.4942555147058822,
      "grad_norm": 0.8409778475761414,
      "learning_rate": 5.570363562091504e-06,
      "loss": 0.0404,
      "step": 10855
    },
    {
      "epoch": 2.494485294117647,
      "grad_norm": 0.9601619243621826,
      "learning_rate": 5.569852941176471e-06,
      "loss": 0.0315,
      "step": 10856
    },
    {
      "epoch": 2.4947150735294117,
      "grad_norm": 0.7346106171607971,
      "learning_rate": 5.569342320261438e-06,
      "loss": 0.0196,
      "step": 10857
    },
    {
      "epoch": 2.4949448529411766,
      "grad_norm": 0.7200042605400085,
      "learning_rate": 5.568831699346405e-06,
      "loss": 0.0387,
      "step": 10858
    },
    {
      "epoch": 2.495174632352941,
      "grad_norm": 0.9751936197280884,
      "learning_rate": 5.568321078431374e-06,
      "loss": 0.0317,
      "step": 10859
    },
    {
      "epoch": 2.495404411764706,
      "grad_norm": 0.8508443236351013,
      "learning_rate": 5.567810457516341e-06,
      "loss": 0.0431,
      "step": 10860
    },
    {
      "epoch": 2.4956341911764706,
      "grad_norm": 0.8922989964485168,
      "learning_rate": 5.567299836601308e-06,
      "loss": 0.0576,
      "step": 10861
    },
    {
      "epoch": 2.4958639705882355,
      "grad_norm": 1.145345687866211,
      "learning_rate": 5.566789215686275e-06,
      "loss": 0.0552,
      "step": 10862
    },
    {
      "epoch": 2.49609375,
      "grad_norm": 1.1987007856369019,
      "learning_rate": 5.566278594771243e-06,
      "loss": 0.0398,
      "step": 10863
    },
    {
      "epoch": 2.4963235294117645,
      "grad_norm": 1.5246036052703857,
      "learning_rate": 5.56576797385621e-06,
      "loss": 0.0362,
      "step": 10864
    },
    {
      "epoch": 2.4965533088235294,
      "grad_norm": 0.730391263961792,
      "learning_rate": 5.565257352941177e-06,
      "loss": 0.0364,
      "step": 10865
    },
    {
      "epoch": 2.496783088235294,
      "grad_norm": 0.9031324982643127,
      "learning_rate": 5.564746732026144e-06,
      "loss": 0.0502,
      "step": 10866
    },
    {
      "epoch": 2.497012867647059,
      "grad_norm": 0.9560993909835815,
      "learning_rate": 5.564236111111112e-06,
      "loss": 0.0457,
      "step": 10867
    },
    {
      "epoch": 2.4972426470588234,
      "grad_norm": 1.1241917610168457,
      "learning_rate": 5.563725490196079e-06,
      "loss": 0.0291,
      "step": 10868
    },
    {
      "epoch": 2.4974724264705883,
      "grad_norm": 0.936944842338562,
      "learning_rate": 5.563214869281046e-06,
      "loss": 0.0337,
      "step": 10869
    },
    {
      "epoch": 2.497702205882353,
      "grad_norm": 0.7350155115127563,
      "learning_rate": 5.562704248366013e-06,
      "loss": 0.0286,
      "step": 10870
    },
    {
      "epoch": 2.4979319852941178,
      "grad_norm": 0.8351763486862183,
      "learning_rate": 5.562193627450981e-06,
      "loss": 0.0502,
      "step": 10871
    },
    {
      "epoch": 2.4981617647058822,
      "grad_norm": 0.7221266031265259,
      "learning_rate": 5.561683006535948e-06,
      "loss": 0.0328,
      "step": 10872
    },
    {
      "epoch": 2.498391544117647,
      "grad_norm": 0.808696985244751,
      "learning_rate": 5.561172385620915e-06,
      "loss": 0.0399,
      "step": 10873
    },
    {
      "epoch": 2.4986213235294117,
      "grad_norm": 1.289319396018982,
      "learning_rate": 5.560661764705882e-06,
      "loss": 0.045,
      "step": 10874
    },
    {
      "epoch": 2.4988511029411766,
      "grad_norm": 0.6771984696388245,
      "learning_rate": 5.560151143790851e-06,
      "loss": 0.0204,
      "step": 10875
    },
    {
      "epoch": 2.499080882352941,
      "grad_norm": 1.0521726608276367,
      "learning_rate": 5.559640522875818e-06,
      "loss": 0.0413,
      "step": 10876
    },
    {
      "epoch": 2.499310661764706,
      "grad_norm": 0.8800347447395325,
      "learning_rate": 5.559129901960785e-06,
      "loss": 0.0355,
      "step": 10877
    },
    {
      "epoch": 2.4995404411764706,
      "grad_norm": 0.8005955815315247,
      "learning_rate": 5.558619281045752e-06,
      "loss": 0.0342,
      "step": 10878
    },
    {
      "epoch": 2.4997702205882355,
      "grad_norm": 0.854059100151062,
      "learning_rate": 5.55810866013072e-06,
      "loss": 0.0467,
      "step": 10879
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.1771787405014038,
      "learning_rate": 5.557598039215687e-06,
      "loss": 0.0505,
      "step": 10880
    },
    {
      "epoch": 2.5002297794117645,
      "grad_norm": 0.7935543656349182,
      "learning_rate": 5.557087418300654e-06,
      "loss": 0.0327,
      "step": 10881
    },
    {
      "epoch": 2.5004595588235294,
      "grad_norm": 0.7398213744163513,
      "learning_rate": 5.556576797385621e-06,
      "loss": 0.0232,
      "step": 10882
    },
    {
      "epoch": 2.5006893382352944,
      "grad_norm": 0.8576135039329529,
      "learning_rate": 5.556066176470589e-06,
      "loss": 0.0404,
      "step": 10883
    },
    {
      "epoch": 2.500919117647059,
      "grad_norm": 0.8772863149642944,
      "learning_rate": 5.555555555555557e-06,
      "loss": 0.0326,
      "step": 10884
    },
    {
      "epoch": 2.5011488970588234,
      "grad_norm": 0.9576658010482788,
      "learning_rate": 5.555044934640524e-06,
      "loss": 0.033,
      "step": 10885
    },
    {
      "epoch": 2.5013786764705883,
      "grad_norm": 1.0366020202636719,
      "learning_rate": 5.554534313725491e-06,
      "loss": 0.0429,
      "step": 10886
    },
    {
      "epoch": 2.501608455882353,
      "grad_norm": 1.115807294845581,
      "learning_rate": 5.5540236928104586e-06,
      "loss": 0.047,
      "step": 10887
    },
    {
      "epoch": 2.5018382352941178,
      "grad_norm": 1.0171335935592651,
      "learning_rate": 5.5535130718954256e-06,
      "loss": 0.0382,
      "step": 10888
    },
    {
      "epoch": 2.5020680147058822,
      "grad_norm": 1.0625313520431519,
      "learning_rate": 5.553002450980393e-06,
      "loss": 0.0513,
      "step": 10889
    },
    {
      "epoch": 2.502297794117647,
      "grad_norm": 0.9742706418037415,
      "learning_rate": 5.55249183006536e-06,
      "loss": 0.042,
      "step": 10890
    },
    {
      "epoch": 2.5025275735294117,
      "grad_norm": 1.0663667917251587,
      "learning_rate": 5.5519812091503275e-06,
      "loss": 0.0423,
      "step": 10891
    },
    {
      "epoch": 2.5027573529411766,
      "grad_norm": 0.8770630359649658,
      "learning_rate": 5.5514705882352945e-06,
      "loss": 0.0382,
      "step": 10892
    },
    {
      "epoch": 2.502987132352941,
      "grad_norm": 1.150701880455017,
      "learning_rate": 5.5509599673202615e-06,
      "loss": 0.0613,
      "step": 10893
    },
    {
      "epoch": 2.5032169117647056,
      "grad_norm": 1.0875979661941528,
      "learning_rate": 5.5504493464052285e-06,
      "loss": 0.025,
      "step": 10894
    },
    {
      "epoch": 2.5034466911764706,
      "grad_norm": 1.1002497673034668,
      "learning_rate": 5.549938725490197e-06,
      "loss": 0.0467,
      "step": 10895
    },
    {
      "epoch": 2.5036764705882355,
      "grad_norm": 0.8687970042228699,
      "learning_rate": 5.549428104575164e-06,
      "loss": 0.0416,
      "step": 10896
    },
    {
      "epoch": 2.50390625,
      "grad_norm": 0.8875629901885986,
      "learning_rate": 5.548917483660131e-06,
      "loss": 0.0475,
      "step": 10897
    },
    {
      "epoch": 2.5041360294117645,
      "grad_norm": 0.7240291237831116,
      "learning_rate": 5.548406862745098e-06,
      "loss": 0.031,
      "step": 10898
    },
    {
      "epoch": 2.5043658088235294,
      "grad_norm": 0.8207235336303711,
      "learning_rate": 5.547896241830066e-06,
      "loss": 0.0341,
      "step": 10899
    },
    {
      "epoch": 2.5045955882352944,
      "grad_norm": 0.7084212303161621,
      "learning_rate": 5.547385620915033e-06,
      "loss": 0.0356,
      "step": 10900
    },
    {
      "epoch": 2.504825367647059,
      "grad_norm": 0.7221838235855103,
      "learning_rate": 5.546875e-06,
      "loss": 0.0344,
      "step": 10901
    },
    {
      "epoch": 2.5050551470588234,
      "grad_norm": 1.2615042924880981,
      "learning_rate": 5.546364379084967e-06,
      "loss": 0.0504,
      "step": 10902
    },
    {
      "epoch": 2.5052849264705883,
      "grad_norm": 1.5022411346435547,
      "learning_rate": 5.545853758169934e-06,
      "loss": 0.07,
      "step": 10903
    },
    {
      "epoch": 2.505514705882353,
      "grad_norm": 1.2971490621566772,
      "learning_rate": 5.545343137254903e-06,
      "loss": 0.0493,
      "step": 10904
    },
    {
      "epoch": 2.5057444852941178,
      "grad_norm": 1.2594289779663086,
      "learning_rate": 5.54483251633987e-06,
      "loss": 0.0408,
      "step": 10905
    },
    {
      "epoch": 2.5059742647058822,
      "grad_norm": 0.8469523191452026,
      "learning_rate": 5.544321895424837e-06,
      "loss": 0.028,
      "step": 10906
    },
    {
      "epoch": 2.506204044117647,
      "grad_norm": 0.8820419907569885,
      "learning_rate": 5.543811274509804e-06,
      "loss": 0.0485,
      "step": 10907
    },
    {
      "epoch": 2.5064338235294117,
      "grad_norm": 1.0799986124038696,
      "learning_rate": 5.543300653594772e-06,
      "loss": 0.0302,
      "step": 10908
    },
    {
      "epoch": 2.5066636029411766,
      "grad_norm": 0.914304792881012,
      "learning_rate": 5.542790032679739e-06,
      "loss": 0.0408,
      "step": 10909
    },
    {
      "epoch": 2.506893382352941,
      "grad_norm": 0.8783556222915649,
      "learning_rate": 5.542279411764706e-06,
      "loss": 0.0353,
      "step": 10910
    },
    {
      "epoch": 2.5071231617647056,
      "grad_norm": 0.8846315741539001,
      "learning_rate": 5.541768790849673e-06,
      "loss": 0.0385,
      "step": 10911
    },
    {
      "epoch": 2.5073529411764706,
      "grad_norm": 0.7496381402015686,
      "learning_rate": 5.5412581699346415e-06,
      "loss": 0.0386,
      "step": 10912
    },
    {
      "epoch": 2.5075827205882355,
      "grad_norm": 0.9463784694671631,
      "learning_rate": 5.5407475490196086e-06,
      "loss": 0.057,
      "step": 10913
    },
    {
      "epoch": 2.5078125,
      "grad_norm": 1.1342182159423828,
      "learning_rate": 5.5402369281045756e-06,
      "loss": 0.0508,
      "step": 10914
    },
    {
      "epoch": 2.5080422794117645,
      "grad_norm": 1.4916712045669556,
      "learning_rate": 5.539726307189543e-06,
      "loss": 0.0817,
      "step": 10915
    },
    {
      "epoch": 2.5082720588235294,
      "grad_norm": 0.9591171145439148,
      "learning_rate": 5.5392156862745104e-06,
      "loss": 0.036,
      "step": 10916
    },
    {
      "epoch": 2.5085018382352944,
      "grad_norm": 1.4887526035308838,
      "learning_rate": 5.5387050653594775e-06,
      "loss": 0.0462,
      "step": 10917
    },
    {
      "epoch": 2.508731617647059,
      "grad_norm": 1.1805927753448486,
      "learning_rate": 5.5381944444444445e-06,
      "loss": 0.0574,
      "step": 10918
    },
    {
      "epoch": 2.5089613970588234,
      "grad_norm": 1.3838526010513306,
      "learning_rate": 5.5376838235294115e-06,
      "loss": 0.0744,
      "step": 10919
    },
    {
      "epoch": 2.5091911764705883,
      "grad_norm": 1.1801801919937134,
      "learning_rate": 5.53717320261438e-06,
      "loss": 0.0529,
      "step": 10920
    },
    {
      "epoch": 2.509420955882353,
      "grad_norm": 0.792921781539917,
      "learning_rate": 5.536662581699347e-06,
      "loss": 0.0429,
      "step": 10921
    },
    {
      "epoch": 2.5096507352941178,
      "grad_norm": 0.6973351836204529,
      "learning_rate": 5.536151960784314e-06,
      "loss": 0.03,
      "step": 10922
    },
    {
      "epoch": 2.5098805147058822,
      "grad_norm": 0.7276415228843689,
      "learning_rate": 5.535641339869281e-06,
      "loss": 0.0388,
      "step": 10923
    },
    {
      "epoch": 2.510110294117647,
      "grad_norm": 0.8771082162857056,
      "learning_rate": 5.535130718954249e-06,
      "loss": 0.0348,
      "step": 10924
    },
    {
      "epoch": 2.5103400735294117,
      "grad_norm": 0.6732767224311829,
      "learning_rate": 5.534620098039216e-06,
      "loss": 0.0274,
      "step": 10925
    },
    {
      "epoch": 2.5105698529411766,
      "grad_norm": 1.1116232872009277,
      "learning_rate": 5.534109477124183e-06,
      "loss": 0.0468,
      "step": 10926
    },
    {
      "epoch": 2.510799632352941,
      "grad_norm": 1.185740351676941,
      "learning_rate": 5.53359885620915e-06,
      "loss": 0.0581,
      "step": 10927
    },
    {
      "epoch": 2.5110294117647056,
      "grad_norm": 1.2455638647079468,
      "learning_rate": 5.533088235294118e-06,
      "loss": 0.055,
      "step": 10928
    },
    {
      "epoch": 2.5112591911764706,
      "grad_norm": 0.775825023651123,
      "learning_rate": 5.532577614379086e-06,
      "loss": 0.0316,
      "step": 10929
    },
    {
      "epoch": 2.5114889705882355,
      "grad_norm": 1.0423877239227295,
      "learning_rate": 5.532066993464053e-06,
      "loss": 0.0451,
      "step": 10930
    },
    {
      "epoch": 2.51171875,
      "grad_norm": 1.7265965938568115,
      "learning_rate": 5.53155637254902e-06,
      "loss": 0.0723,
      "step": 10931
    },
    {
      "epoch": 2.5119485294117645,
      "grad_norm": 1.1225855350494385,
      "learning_rate": 5.531045751633988e-06,
      "loss": 0.0498,
      "step": 10932
    },
    {
      "epoch": 2.5121783088235294,
      "grad_norm": 0.9631138443946838,
      "learning_rate": 5.530535130718955e-06,
      "loss": 0.0383,
      "step": 10933
    },
    {
      "epoch": 2.5124080882352944,
      "grad_norm": 0.9807170033454895,
      "learning_rate": 5.530024509803922e-06,
      "loss": 0.0369,
      "step": 10934
    },
    {
      "epoch": 2.512637867647059,
      "grad_norm": 1.2548192739486694,
      "learning_rate": 5.529513888888889e-06,
      "loss": 0.0455,
      "step": 10935
    },
    {
      "epoch": 2.5128676470588234,
      "grad_norm": 0.84894859790802,
      "learning_rate": 5.529003267973857e-06,
      "loss": 0.0516,
      "step": 10936
    },
    {
      "epoch": 2.5130974264705883,
      "grad_norm": 1.0274568796157837,
      "learning_rate": 5.528492647058824e-06,
      "loss": 0.0416,
      "step": 10937
    },
    {
      "epoch": 2.513327205882353,
      "grad_norm": 0.7942222356796265,
      "learning_rate": 5.527982026143791e-06,
      "loss": 0.0322,
      "step": 10938
    },
    {
      "epoch": 2.5135569852941178,
      "grad_norm": 0.6816983819007874,
      "learning_rate": 5.5274714052287586e-06,
      "loss": 0.0251,
      "step": 10939
    },
    {
      "epoch": 2.5137867647058822,
      "grad_norm": 0.9097975492477417,
      "learning_rate": 5.526960784313726e-06,
      "loss": 0.0473,
      "step": 10940
    },
    {
      "epoch": 2.514016544117647,
      "grad_norm": 0.7694272398948669,
      "learning_rate": 5.5264501633986934e-06,
      "loss": 0.0338,
      "step": 10941
    },
    {
      "epoch": 2.5142463235294117,
      "grad_norm": 1.4675136804580688,
      "learning_rate": 5.5259395424836604e-06,
      "loss": 0.0529,
      "step": 10942
    },
    {
      "epoch": 2.5144761029411766,
      "grad_norm": 0.9220060706138611,
      "learning_rate": 5.5254289215686275e-06,
      "loss": 0.0303,
      "step": 10943
    },
    {
      "epoch": 2.514705882352941,
      "grad_norm": 0.9331602454185486,
      "learning_rate": 5.524918300653595e-06,
      "loss": 0.046,
      "step": 10944
    },
    {
      "epoch": 2.5149356617647056,
      "grad_norm": 0.8683445453643799,
      "learning_rate": 5.524407679738562e-06,
      "loss": 0.0381,
      "step": 10945
    },
    {
      "epoch": 2.5151654411764706,
      "grad_norm": 1.0112122297286987,
      "learning_rate": 5.523897058823529e-06,
      "loss": 0.0388,
      "step": 10946
    },
    {
      "epoch": 2.5153952205882355,
      "grad_norm": 0.7513043880462646,
      "learning_rate": 5.523386437908496e-06,
      "loss": 0.0273,
      "step": 10947
    },
    {
      "epoch": 2.515625,
      "grad_norm": 0.8227120041847229,
      "learning_rate": 5.522875816993465e-06,
      "loss": 0.0422,
      "step": 10948
    },
    {
      "epoch": 2.5158547794117645,
      "grad_norm": 0.9980888366699219,
      "learning_rate": 5.522365196078432e-06,
      "loss": 0.0573,
      "step": 10949
    },
    {
      "epoch": 2.5160845588235294,
      "grad_norm": 1.089699387550354,
      "learning_rate": 5.521854575163399e-06,
      "loss": 0.0362,
      "step": 10950
    },
    {
      "epoch": 2.5163143382352944,
      "grad_norm": 1.1810263395309448,
      "learning_rate": 5.521343954248366e-06,
      "loss": 0.0409,
      "step": 10951
    },
    {
      "epoch": 2.516544117647059,
      "grad_norm": 1.2719545364379883,
      "learning_rate": 5.520833333333334e-06,
      "loss": 0.0441,
      "step": 10952
    },
    {
      "epoch": 2.5167738970588234,
      "grad_norm": 1.3722683191299438,
      "learning_rate": 5.520322712418301e-06,
      "loss": 0.055,
      "step": 10953
    },
    {
      "epoch": 2.5170036764705883,
      "grad_norm": 0.8925368189811707,
      "learning_rate": 5.519812091503268e-06,
      "loss": 0.058,
      "step": 10954
    },
    {
      "epoch": 2.517233455882353,
      "grad_norm": 1.3655717372894287,
      "learning_rate": 5.519301470588235e-06,
      "loss": 0.0439,
      "step": 10955
    },
    {
      "epoch": 2.5174632352941178,
      "grad_norm": 0.9131569862365723,
      "learning_rate": 5.518790849673204e-06,
      "loss": 0.0603,
      "step": 10956
    },
    {
      "epoch": 2.5176930147058822,
      "grad_norm": 1.3017727136611938,
      "learning_rate": 5.518280228758171e-06,
      "loss": 0.0693,
      "step": 10957
    },
    {
      "epoch": 2.517922794117647,
      "grad_norm": 0.9007448554039001,
      "learning_rate": 5.517769607843138e-06,
      "loss": 0.0356,
      "step": 10958
    },
    {
      "epoch": 2.5181525735294117,
      "grad_norm": 0.7899044752120972,
      "learning_rate": 5.517258986928105e-06,
      "loss": 0.0318,
      "step": 10959
    },
    {
      "epoch": 2.5183823529411766,
      "grad_norm": 0.8403612375259399,
      "learning_rate": 5.516748366013073e-06,
      "loss": 0.0435,
      "step": 10960
    },
    {
      "epoch": 2.518612132352941,
      "grad_norm": 1.0317590236663818,
      "learning_rate": 5.51623774509804e-06,
      "loss": 0.0482,
      "step": 10961
    },
    {
      "epoch": 2.5188419117647056,
      "grad_norm": 0.8048486113548279,
      "learning_rate": 5.515727124183007e-06,
      "loss": 0.0436,
      "step": 10962
    },
    {
      "epoch": 2.5190716911764706,
      "grad_norm": 0.9647262096405029,
      "learning_rate": 5.515216503267974e-06,
      "loss": 0.0505,
      "step": 10963
    },
    {
      "epoch": 2.5193014705882355,
      "grad_norm": 1.1069254875183105,
      "learning_rate": 5.514705882352942e-06,
      "loss": 0.0769,
      "step": 10964
    },
    {
      "epoch": 2.51953125,
      "grad_norm": 0.8530982136726379,
      "learning_rate": 5.514195261437909e-06,
      "loss": 0.0356,
      "step": 10965
    },
    {
      "epoch": 2.5197610294117645,
      "grad_norm": 0.8409922122955322,
      "learning_rate": 5.513684640522876e-06,
      "loss": 0.0444,
      "step": 10966
    },
    {
      "epoch": 2.5199908088235294,
      "grad_norm": 0.7425827383995056,
      "learning_rate": 5.5131740196078434e-06,
      "loss": 0.0216,
      "step": 10967
    },
    {
      "epoch": 2.5202205882352944,
      "grad_norm": 0.8673049807548523,
      "learning_rate": 5.512663398692811e-06,
      "loss": 0.042,
      "step": 10968
    },
    {
      "epoch": 2.520450367647059,
      "grad_norm": 0.7337770462036133,
      "learning_rate": 5.512152777777778e-06,
      "loss": 0.0237,
      "step": 10969
    },
    {
      "epoch": 2.5206801470588234,
      "grad_norm": 1.0789923667907715,
      "learning_rate": 5.511642156862745e-06,
      "loss": 0.0522,
      "step": 10970
    },
    {
      "epoch": 2.5209099264705883,
      "grad_norm": 1.0142104625701904,
      "learning_rate": 5.511131535947712e-06,
      "loss": 0.0374,
      "step": 10971
    },
    {
      "epoch": 2.521139705882353,
      "grad_norm": 0.9243643879890442,
      "learning_rate": 5.51062091503268e-06,
      "loss": 0.0364,
      "step": 10972
    },
    {
      "epoch": 2.5213694852941178,
      "grad_norm": 0.9282881617546082,
      "learning_rate": 5.510110294117648e-06,
      "loss": 0.0403,
      "step": 10973
    },
    {
      "epoch": 2.5215992647058822,
      "grad_norm": 0.7723627686500549,
      "learning_rate": 5.509599673202615e-06,
      "loss": 0.0328,
      "step": 10974
    },
    {
      "epoch": 2.521829044117647,
      "grad_norm": 0.7325979471206665,
      "learning_rate": 5.509089052287582e-06,
      "loss": 0.041,
      "step": 10975
    },
    {
      "epoch": 2.5220588235294117,
      "grad_norm": 0.7741699814796448,
      "learning_rate": 5.50857843137255e-06,
      "loss": 0.0368,
      "step": 10976
    },
    {
      "epoch": 2.5222886029411766,
      "grad_norm": 0.7302485704421997,
      "learning_rate": 5.508067810457517e-06,
      "loss": 0.0252,
      "step": 10977
    },
    {
      "epoch": 2.522518382352941,
      "grad_norm": 0.6753310561180115,
      "learning_rate": 5.507557189542484e-06,
      "loss": 0.0316,
      "step": 10978
    },
    {
      "epoch": 2.5227481617647056,
      "grad_norm": 1.0341331958770752,
      "learning_rate": 5.507046568627451e-06,
      "loss": 0.0514,
      "step": 10979
    },
    {
      "epoch": 2.5229779411764706,
      "grad_norm": 1.094179630279541,
      "learning_rate": 5.506535947712419e-06,
      "loss": 0.0445,
      "step": 10980
    },
    {
      "epoch": 2.5232077205882355,
      "grad_norm": 1.3539918661117554,
      "learning_rate": 5.506025326797386e-06,
      "loss": 0.0672,
      "step": 10981
    },
    {
      "epoch": 2.5234375,
      "grad_norm": 0.8678295612335205,
      "learning_rate": 5.505514705882353e-06,
      "loss": 0.0355,
      "step": 10982
    },
    {
      "epoch": 2.5236672794117645,
      "grad_norm": 1.0342426300048828,
      "learning_rate": 5.50500408496732e-06,
      "loss": 0.0461,
      "step": 10983
    },
    {
      "epoch": 2.5238970588235294,
      "grad_norm": 0.9840816855430603,
      "learning_rate": 5.504493464052289e-06,
      "loss": 0.0392,
      "step": 10984
    },
    {
      "epoch": 2.5241268382352944,
      "grad_norm": 0.6873922348022461,
      "learning_rate": 5.503982843137256e-06,
      "loss": 0.0221,
      "step": 10985
    },
    {
      "epoch": 2.524356617647059,
      "grad_norm": 1.0331108570098877,
      "learning_rate": 5.503472222222223e-06,
      "loss": 0.0422,
      "step": 10986
    },
    {
      "epoch": 2.5245863970588234,
      "grad_norm": 1.0012636184692383,
      "learning_rate": 5.50296160130719e-06,
      "loss": 0.0204,
      "step": 10987
    },
    {
      "epoch": 2.5248161764705883,
      "grad_norm": 1.1789729595184326,
      "learning_rate": 5.5024509803921575e-06,
      "loss": 0.0517,
      "step": 10988
    },
    {
      "epoch": 2.525045955882353,
      "grad_norm": 0.8945832252502441,
      "learning_rate": 5.5019403594771245e-06,
      "loss": 0.0419,
      "step": 10989
    },
    {
      "epoch": 2.5252757352941178,
      "grad_norm": 1.1342346668243408,
      "learning_rate": 5.5014297385620915e-06,
      "loss": 0.0565,
      "step": 10990
    },
    {
      "epoch": 2.5255055147058822,
      "grad_norm": 1.1455140113830566,
      "learning_rate": 5.5009191176470586e-06,
      "loss": 0.0611,
      "step": 10991
    },
    {
      "epoch": 2.525735294117647,
      "grad_norm": 0.9614419341087341,
      "learning_rate": 5.500408496732027e-06,
      "loss": 0.0441,
      "step": 10992
    },
    {
      "epoch": 2.5259650735294117,
      "grad_norm": 1.0070652961730957,
      "learning_rate": 5.499897875816994e-06,
      "loss": 0.0451,
      "step": 10993
    },
    {
      "epoch": 2.5261948529411766,
      "grad_norm": 0.9732388854026794,
      "learning_rate": 5.499387254901961e-06,
      "loss": 0.0335,
      "step": 10994
    },
    {
      "epoch": 2.526424632352941,
      "grad_norm": 0.6654415130615234,
      "learning_rate": 5.498876633986928e-06,
      "loss": 0.031,
      "step": 10995
    },
    {
      "epoch": 2.5266544117647056,
      "grad_norm": 1.0725027322769165,
      "learning_rate": 5.498366013071896e-06,
      "loss": 0.0547,
      "step": 10996
    },
    {
      "epoch": 2.5268841911764706,
      "grad_norm": 0.9979639053344727,
      "learning_rate": 5.497855392156863e-06,
      "loss": 0.0607,
      "step": 10997
    },
    {
      "epoch": 2.5271139705882355,
      "grad_norm": 1.0254790782928467,
      "learning_rate": 5.49734477124183e-06,
      "loss": 0.0385,
      "step": 10998
    },
    {
      "epoch": 2.52734375,
      "grad_norm": 1.0522891283035278,
      "learning_rate": 5.496834150326797e-06,
      "loss": 0.0504,
      "step": 10999
    },
    {
      "epoch": 2.5275735294117645,
      "grad_norm": 1.470711588859558,
      "learning_rate": 5.496323529411766e-06,
      "loss": 0.0558,
      "step": 11000
    },
    {
      "epoch": 2.5275735294117645,
      "eval_loss": 0.04632040113210678,
      "eval_runtime": 2006.5771,
      "eval_samples_per_second": 4.438,
      "eval_steps_per_second": 2.219,
      "step": 11000
    },
    {
      "epoch": 2.5278033088235294,
      "grad_norm": 0.8561055660247803,
      "learning_rate": 5.495812908496733e-06,
      "loss": 0.0371,
      "step": 11001
    },
    {
      "epoch": 2.5280330882352944,
      "grad_norm": 0.8383464813232422,
      "learning_rate": 5.4953022875817e-06,
      "loss": 0.0349,
      "step": 11002
    },
    {
      "epoch": 2.528262867647059,
      "grad_norm": 1.0844842195510864,
      "learning_rate": 5.494791666666667e-06,
      "loss": 0.0372,
      "step": 11003
    },
    {
      "epoch": 2.5284926470588234,
      "grad_norm": 1.3214153051376343,
      "learning_rate": 5.494281045751635e-06,
      "loss": 0.0532,
      "step": 11004
    },
    {
      "epoch": 2.5287224264705883,
      "grad_norm": 0.9427211880683899,
      "learning_rate": 5.493770424836602e-06,
      "loss": 0.0503,
      "step": 11005
    },
    {
      "epoch": 2.528952205882353,
      "grad_norm": 0.7701108455657959,
      "learning_rate": 5.493259803921569e-06,
      "loss": 0.0312,
      "step": 11006
    },
    {
      "epoch": 2.5291819852941178,
      "grad_norm": 1.2405177354812622,
      "learning_rate": 5.492749183006536e-06,
      "loss": 0.0848,
      "step": 11007
    },
    {
      "epoch": 2.5294117647058822,
      "grad_norm": 0.8262498378753662,
      "learning_rate": 5.4922385620915046e-06,
      "loss": 0.0419,
      "step": 11008
    },
    {
      "epoch": 2.529641544117647,
      "grad_norm": 0.6785430908203125,
      "learning_rate": 5.491727941176472e-06,
      "loss": 0.0316,
      "step": 11009
    },
    {
      "epoch": 2.5298713235294117,
      "grad_norm": 1.091597080230713,
      "learning_rate": 5.491217320261439e-06,
      "loss": 0.0343,
      "step": 11010
    },
    {
      "epoch": 2.5301011029411766,
      "grad_norm": 1.028609037399292,
      "learning_rate": 5.490706699346406e-06,
      "loss": 0.0509,
      "step": 11011
    },
    {
      "epoch": 2.530330882352941,
      "grad_norm": 0.8918461203575134,
      "learning_rate": 5.4901960784313735e-06,
      "loss": 0.0509,
      "step": 11012
    },
    {
      "epoch": 2.5305606617647056,
      "grad_norm": 0.9651585817337036,
      "learning_rate": 5.4896854575163405e-06,
      "loss": 0.0653,
      "step": 11013
    },
    {
      "epoch": 2.5307904411764706,
      "grad_norm": 0.8255344033241272,
      "learning_rate": 5.4891748366013075e-06,
      "loss": 0.0341,
      "step": 11014
    },
    {
      "epoch": 2.5310202205882355,
      "grad_norm": 0.9088965654373169,
      "learning_rate": 5.4886642156862745e-06,
      "loss": 0.0306,
      "step": 11015
    },
    {
      "epoch": 2.53125,
      "grad_norm": 0.9480385780334473,
      "learning_rate": 5.488153594771242e-06,
      "loss": 0.032,
      "step": 11016
    },
    {
      "epoch": 2.5314797794117645,
      "grad_norm": 0.8661069273948669,
      "learning_rate": 5.487642973856209e-06,
      "loss": 0.0374,
      "step": 11017
    },
    {
      "epoch": 2.5317095588235294,
      "grad_norm": 0.8679121732711792,
      "learning_rate": 5.487132352941177e-06,
      "loss": 0.0454,
      "step": 11018
    },
    {
      "epoch": 2.5319393382352944,
      "grad_norm": 0.8911914825439453,
      "learning_rate": 5.486621732026144e-06,
      "loss": 0.0443,
      "step": 11019
    },
    {
      "epoch": 2.532169117647059,
      "grad_norm": 0.7192313075065613,
      "learning_rate": 5.486111111111112e-06,
      "loss": 0.0268,
      "step": 11020
    },
    {
      "epoch": 2.5323988970588234,
      "grad_norm": 0.9570572972297668,
      "learning_rate": 5.485600490196079e-06,
      "loss": 0.0436,
      "step": 11021
    },
    {
      "epoch": 2.5326286764705883,
      "grad_norm": 0.8182008266448975,
      "learning_rate": 5.485089869281046e-06,
      "loss": 0.0324,
      "step": 11022
    },
    {
      "epoch": 2.532858455882353,
      "grad_norm": 0.974479615688324,
      "learning_rate": 5.484579248366013e-06,
      "loss": 0.0391,
      "step": 11023
    },
    {
      "epoch": 2.5330882352941178,
      "grad_norm": 0.9344365000724792,
      "learning_rate": 5.484068627450981e-06,
      "loss": 0.0401,
      "step": 11024
    },
    {
      "epoch": 2.5333180147058822,
      "grad_norm": 0.9980380535125732,
      "learning_rate": 5.483558006535948e-06,
      "loss": 0.0346,
      "step": 11025
    },
    {
      "epoch": 2.533547794117647,
      "grad_norm": 0.849423348903656,
      "learning_rate": 5.483047385620915e-06,
      "loss": 0.0352,
      "step": 11026
    },
    {
      "epoch": 2.5337775735294117,
      "grad_norm": 1.0157852172851562,
      "learning_rate": 5.482536764705882e-06,
      "loss": 0.0439,
      "step": 11027
    },
    {
      "epoch": 2.5340073529411766,
      "grad_norm": 0.8004123568534851,
      "learning_rate": 5.482026143790851e-06,
      "loss": 0.038,
      "step": 11028
    },
    {
      "epoch": 2.534237132352941,
      "grad_norm": 0.7100118398666382,
      "learning_rate": 5.481515522875818e-06,
      "loss": 0.022,
      "step": 11029
    },
    {
      "epoch": 2.5344669117647056,
      "grad_norm": 0.7338208556175232,
      "learning_rate": 5.481004901960785e-06,
      "loss": 0.0306,
      "step": 11030
    },
    {
      "epoch": 2.5346966911764706,
      "grad_norm": 0.8176404237747192,
      "learning_rate": 5.480494281045752e-06,
      "loss": 0.0304,
      "step": 11031
    },
    {
      "epoch": 2.5349264705882355,
      "grad_norm": 0.6635050773620605,
      "learning_rate": 5.47998366013072e-06,
      "loss": 0.0258,
      "step": 11032
    },
    {
      "epoch": 2.53515625,
      "grad_norm": 0.7799559235572815,
      "learning_rate": 5.479473039215687e-06,
      "loss": 0.0387,
      "step": 11033
    },
    {
      "epoch": 2.5353860294117645,
      "grad_norm": 0.6567602157592773,
      "learning_rate": 5.478962418300654e-06,
      "loss": 0.0294,
      "step": 11034
    },
    {
      "epoch": 2.5356158088235294,
      "grad_norm": 0.8051461577415466,
      "learning_rate": 5.478451797385621e-06,
      "loss": 0.0189,
      "step": 11035
    },
    {
      "epoch": 2.5358455882352944,
      "grad_norm": 1.0433136224746704,
      "learning_rate": 5.4779411764705894e-06,
      "loss": 0.0521,
      "step": 11036
    },
    {
      "epoch": 2.536075367647059,
      "grad_norm": 0.9995996356010437,
      "learning_rate": 5.4774305555555565e-06,
      "loss": 0.0506,
      "step": 11037
    },
    {
      "epoch": 2.5363051470588234,
      "grad_norm": 1.163642406463623,
      "learning_rate": 5.4769199346405235e-06,
      "loss": 0.049,
      "step": 11038
    },
    {
      "epoch": 2.5365349264705883,
      "grad_norm": 0.8205960392951965,
      "learning_rate": 5.4764093137254905e-06,
      "loss": 0.0346,
      "step": 11039
    },
    {
      "epoch": 2.536764705882353,
      "grad_norm": 0.5885565876960754,
      "learning_rate": 5.475898692810458e-06,
      "loss": 0.0261,
      "step": 11040
    },
    {
      "epoch": 2.5369944852941178,
      "grad_norm": 0.8842613697052002,
      "learning_rate": 5.475388071895425e-06,
      "loss": 0.0489,
      "step": 11041
    },
    {
      "epoch": 2.5372242647058822,
      "grad_norm": 0.7688480019569397,
      "learning_rate": 5.474877450980392e-06,
      "loss": 0.0288,
      "step": 11042
    },
    {
      "epoch": 2.537454044117647,
      "grad_norm": 1.6105022430419922,
      "learning_rate": 5.474366830065359e-06,
      "loss": 0.0527,
      "step": 11043
    },
    {
      "epoch": 2.5376838235294117,
      "grad_norm": 1.0192686319351196,
      "learning_rate": 5.473856209150328e-06,
      "loss": 0.0492,
      "step": 11044
    },
    {
      "epoch": 2.5379136029411766,
      "grad_norm": 0.9400466680526733,
      "learning_rate": 5.473345588235295e-06,
      "loss": 0.031,
      "step": 11045
    },
    {
      "epoch": 2.538143382352941,
      "grad_norm": 0.7345858216285706,
      "learning_rate": 5.472834967320262e-06,
      "loss": 0.0302,
      "step": 11046
    },
    {
      "epoch": 2.5383731617647056,
      "grad_norm": 0.7707772254943848,
      "learning_rate": 5.472324346405229e-06,
      "loss": 0.0303,
      "step": 11047
    },
    {
      "epoch": 2.5386029411764706,
      "grad_norm": 1.0547009706497192,
      "learning_rate": 5.471813725490197e-06,
      "loss": 0.0371,
      "step": 11048
    },
    {
      "epoch": 2.5388327205882355,
      "grad_norm": 0.653971791267395,
      "learning_rate": 5.471303104575164e-06,
      "loss": 0.0241,
      "step": 11049
    },
    {
      "epoch": 2.5390625,
      "grad_norm": 0.935409426689148,
      "learning_rate": 5.470792483660131e-06,
      "loss": 0.0318,
      "step": 11050
    },
    {
      "epoch": 2.5392922794117645,
      "grad_norm": 1.618207573890686,
      "learning_rate": 5.470281862745098e-06,
      "loss": 0.0654,
      "step": 11051
    },
    {
      "epoch": 2.5395220588235294,
      "grad_norm": 1.2097508907318115,
      "learning_rate": 5.469771241830067e-06,
      "loss": 0.0426,
      "step": 11052
    },
    {
      "epoch": 2.5397518382352944,
      "grad_norm": 1.379908561706543,
      "learning_rate": 5.469260620915034e-06,
      "loss": 0.0665,
      "step": 11053
    },
    {
      "epoch": 2.539981617647059,
      "grad_norm": 0.8329470753669739,
      "learning_rate": 5.468750000000001e-06,
      "loss": 0.0459,
      "step": 11054
    },
    {
      "epoch": 2.5402113970588234,
      "grad_norm": 1.0859241485595703,
      "learning_rate": 5.468239379084968e-06,
      "loss": 0.0531,
      "step": 11055
    },
    {
      "epoch": 2.5404411764705883,
      "grad_norm": 1.179404377937317,
      "learning_rate": 5.467728758169935e-06,
      "loss": 0.0579,
      "step": 11056
    },
    {
      "epoch": 2.540670955882353,
      "grad_norm": 0.7067691087722778,
      "learning_rate": 5.467218137254903e-06,
      "loss": 0.0325,
      "step": 11057
    },
    {
      "epoch": 2.5409007352941178,
      "grad_norm": 0.8920876979827881,
      "learning_rate": 5.46670751633987e-06,
      "loss": 0.0365,
      "step": 11058
    },
    {
      "epoch": 2.5411305147058822,
      "grad_norm": 0.9730488657951355,
      "learning_rate": 5.466196895424837e-06,
      "loss": 0.0348,
      "step": 11059
    },
    {
      "epoch": 2.541360294117647,
      "grad_norm": 0.9691787362098694,
      "learning_rate": 5.465686274509804e-06,
      "loss": 0.0441,
      "step": 11060
    },
    {
      "epoch": 2.5415900735294117,
      "grad_norm": 0.8886092901229858,
      "learning_rate": 5.465175653594772e-06,
      "loss": 0.0305,
      "step": 11061
    },
    {
      "epoch": 2.5418198529411766,
      "grad_norm": 1.1021983623504639,
      "learning_rate": 5.464665032679739e-06,
      "loss": 0.0691,
      "step": 11062
    },
    {
      "epoch": 2.542049632352941,
      "grad_norm": 1.2956039905548096,
      "learning_rate": 5.4641544117647065e-06,
      "loss": 0.0473,
      "step": 11063
    },
    {
      "epoch": 2.5422794117647056,
      "grad_norm": 1.5968427658081055,
      "learning_rate": 5.4636437908496735e-06,
      "loss": 0.0568,
      "step": 11064
    },
    {
      "epoch": 2.5425091911764706,
      "grad_norm": 1.1442145109176636,
      "learning_rate": 5.463133169934641e-06,
      "loss": 0.05,
      "step": 11065
    },
    {
      "epoch": 2.5427389705882355,
      "grad_norm": 0.7539030909538269,
      "learning_rate": 5.462622549019608e-06,
      "loss": 0.038,
      "step": 11066
    },
    {
      "epoch": 2.54296875,
      "grad_norm": 1.022704839706421,
      "learning_rate": 5.462111928104575e-06,
      "loss": 0.049,
      "step": 11067
    },
    {
      "epoch": 2.5431985294117645,
      "grad_norm": 0.7392296195030212,
      "learning_rate": 5.461601307189542e-06,
      "loss": 0.0278,
      "step": 11068
    },
    {
      "epoch": 2.5434283088235294,
      "grad_norm": 0.8958178758621216,
      "learning_rate": 5.46109068627451e-06,
      "loss": 0.0421,
      "step": 11069
    },
    {
      "epoch": 2.5436580882352944,
      "grad_norm": 0.9973757863044739,
      "learning_rate": 5.460580065359477e-06,
      "loss": 0.0394,
      "step": 11070
    },
    {
      "epoch": 2.543887867647059,
      "grad_norm": Infinity,
      "learning_rate": 5.460069444444444e-06,
      "loss": 0.0594,
      "step": 11071
    },
    {
      "epoch": 2.5441176470588234,
      "grad_norm": 0.9963119029998779,
      "learning_rate": 5.460069444444444e-06,
      "loss": 0.0419,
      "step": 11072
    },
    {
      "epoch": 2.5443474264705883,
      "grad_norm": 0.6892746686935425,
      "learning_rate": 5.459558823529411e-06,
      "loss": 0.0214,
      "step": 11073
    },
    {
      "epoch": 2.544577205882353,
      "grad_norm": 0.9255508780479431,
      "learning_rate": 5.45904820261438e-06,
      "loss": 0.0351,
      "step": 11074
    },
    {
      "epoch": 2.5448069852941178,
      "grad_norm": 0.6923589706420898,
      "learning_rate": 5.458537581699347e-06,
      "loss": 0.0373,
      "step": 11075
    },
    {
      "epoch": 2.5450367647058822,
      "grad_norm": 1.1676859855651855,
      "learning_rate": 5.458026960784314e-06,
      "loss": 0.0397,
      "step": 11076
    },
    {
      "epoch": 2.545266544117647,
      "grad_norm": 1.0555862188339233,
      "learning_rate": 5.457516339869281e-06,
      "loss": 0.05,
      "step": 11077
    },
    {
      "epoch": 2.5454963235294117,
      "grad_norm": 0.9185885190963745,
      "learning_rate": 5.457005718954249e-06,
      "loss": 0.0364,
      "step": 11078
    },
    {
      "epoch": 2.5457261029411766,
      "grad_norm": 0.8324349522590637,
      "learning_rate": 5.456495098039216e-06,
      "loss": 0.0222,
      "step": 11079
    },
    {
      "epoch": 2.545955882352941,
      "grad_norm": 0.8106174468994141,
      "learning_rate": 5.455984477124183e-06,
      "loss": 0.0447,
      "step": 11080
    },
    {
      "epoch": 2.5461856617647056,
      "grad_norm": 1.1995729207992554,
      "learning_rate": 5.45547385620915e-06,
      "loss": 0.0533,
      "step": 11081
    },
    {
      "epoch": 2.5464154411764706,
      "grad_norm": 0.6668888330459595,
      "learning_rate": 5.454963235294119e-06,
      "loss": 0.0277,
      "step": 11082
    },
    {
      "epoch": 2.5466452205882355,
      "grad_norm": 1.1109603643417358,
      "learning_rate": 5.454452614379086e-06,
      "loss": 0.0523,
      "step": 11083
    },
    {
      "epoch": 2.546875,
      "grad_norm": 0.7231283783912659,
      "learning_rate": 5.453941993464053e-06,
      "loss": 0.0427,
      "step": 11084
    },
    {
      "epoch": 2.5471047794117645,
      "grad_norm": 0.836954653263092,
      "learning_rate": 5.45343137254902e-06,
      "loss": 0.0293,
      "step": 11085
    },
    {
      "epoch": 2.5473345588235294,
      "grad_norm": 1.1311728954315186,
      "learning_rate": 5.4529207516339876e-06,
      "loss": 0.0453,
      "step": 11086
    },
    {
      "epoch": 2.5475643382352944,
      "grad_norm": 0.9208158850669861,
      "learning_rate": 5.4524101307189546e-06,
      "loss": 0.0299,
      "step": 11087
    },
    {
      "epoch": 2.547794117647059,
      "grad_norm": 0.8590688109397888,
      "learning_rate": 5.451899509803922e-06,
      "loss": 0.0334,
      "step": 11088
    },
    {
      "epoch": 2.5480238970588234,
      "grad_norm": 0.7277470231056213,
      "learning_rate": 5.451388888888889e-06,
      "loss": 0.0249,
      "step": 11089
    },
    {
      "epoch": 2.5482536764705883,
      "grad_norm": 1.1628655195236206,
      "learning_rate": 5.450878267973857e-06,
      "loss": 0.0399,
      "step": 11090
    },
    {
      "epoch": 2.548483455882353,
      "grad_norm": 1.4982531070709229,
      "learning_rate": 5.450367647058824e-06,
      "loss": 0.0641,
      "step": 11091
    },
    {
      "epoch": 2.5487132352941178,
      "grad_norm": 0.7731660604476929,
      "learning_rate": 5.449857026143791e-06,
      "loss": 0.0383,
      "step": 11092
    },
    {
      "epoch": 2.5489430147058822,
      "grad_norm": 0.883791446685791,
      "learning_rate": 5.449346405228758e-06,
      "loss": 0.0283,
      "step": 11093
    },
    {
      "epoch": 2.549172794117647,
      "grad_norm": 1.2759453058242798,
      "learning_rate": 5.448835784313726e-06,
      "loss": 0.0509,
      "step": 11094
    },
    {
      "epoch": 2.5494025735294117,
      "grad_norm": 0.7842352986335754,
      "learning_rate": 5.448325163398693e-06,
      "loss": 0.0335,
      "step": 11095
    },
    {
      "epoch": 2.5496323529411766,
      "grad_norm": 0.9576677680015564,
      "learning_rate": 5.44781454248366e-06,
      "loss": 0.0464,
      "step": 11096
    },
    {
      "epoch": 2.549862132352941,
      "grad_norm": 1.067685842514038,
      "learning_rate": 5.447303921568627e-06,
      "loss": 0.0434,
      "step": 11097
    },
    {
      "epoch": 2.5500919117647056,
      "grad_norm": 0.8568828701972961,
      "learning_rate": 5.446793300653596e-06,
      "loss": 0.0454,
      "step": 11098
    },
    {
      "epoch": 2.5503216911764706,
      "grad_norm": 0.5837855339050293,
      "learning_rate": 5.446282679738563e-06,
      "loss": 0.0221,
      "step": 11099
    },
    {
      "epoch": 2.5505514705882355,
      "grad_norm": 0.8375315070152283,
      "learning_rate": 5.44577205882353e-06,
      "loss": 0.0462,
      "step": 11100
    },
    {
      "epoch": 2.55078125,
      "grad_norm": 1.1481996774673462,
      "learning_rate": 5.445261437908497e-06,
      "loss": 0.0524,
      "step": 11101
    },
    {
      "epoch": 2.5510110294117645,
      "grad_norm": 0.8364565372467041,
      "learning_rate": 5.444750816993465e-06,
      "loss": 0.0442,
      "step": 11102
    },
    {
      "epoch": 2.5512408088235294,
      "grad_norm": 0.8794755339622498,
      "learning_rate": 5.444240196078432e-06,
      "loss": 0.0345,
      "step": 11103
    },
    {
      "epoch": 2.5514705882352944,
      "grad_norm": 1.4443894624710083,
      "learning_rate": 5.443729575163399e-06,
      "loss": 0.068,
      "step": 11104
    },
    {
      "epoch": 2.551700367647059,
      "grad_norm": 0.8637354373931885,
      "learning_rate": 5.443218954248366e-06,
      "loss": 0.0552,
      "step": 11105
    },
    {
      "epoch": 2.5519301470588234,
      "grad_norm": 0.8328033685684204,
      "learning_rate": 5.442708333333334e-06,
      "loss": 0.0247,
      "step": 11106
    },
    {
      "epoch": 2.5521599264705883,
      "grad_norm": 0.945850670337677,
      "learning_rate": 5.442197712418301e-06,
      "loss": 0.0408,
      "step": 11107
    },
    {
      "epoch": 2.552389705882353,
      "grad_norm": 1.0162726640701294,
      "learning_rate": 5.441687091503269e-06,
      "loss": 0.0404,
      "step": 11108
    },
    {
      "epoch": 2.5526194852941178,
      "grad_norm": 0.9447590708732605,
      "learning_rate": 5.441176470588236e-06,
      "loss": 0.0311,
      "step": 11109
    },
    {
      "epoch": 2.5528492647058822,
      "grad_norm": 0.8224695920944214,
      "learning_rate": 5.4406658496732035e-06,
      "loss": 0.0313,
      "step": 11110
    },
    {
      "epoch": 2.553079044117647,
      "grad_norm": 1.0024046897888184,
      "learning_rate": 5.4401552287581705e-06,
      "loss": 0.0358,
      "step": 11111
    },
    {
      "epoch": 2.5533088235294117,
      "grad_norm": 1.1074379682540894,
      "learning_rate": 5.4396446078431376e-06,
      "loss": 0.0581,
      "step": 11112
    },
    {
      "epoch": 2.5535386029411766,
      "grad_norm": 0.8816101551055908,
      "learning_rate": 5.4391339869281046e-06,
      "loss": 0.0432,
      "step": 11113
    },
    {
      "epoch": 2.553768382352941,
      "grad_norm": 1.032503604888916,
      "learning_rate": 5.4386233660130724e-06,
      "loss": 0.0403,
      "step": 11114
    },
    {
      "epoch": 2.5539981617647056,
      "grad_norm": 0.8740717172622681,
      "learning_rate": 5.4381127450980394e-06,
      "loss": 0.0336,
      "step": 11115
    },
    {
      "epoch": 2.5542279411764706,
      "grad_norm": 0.6995322704315186,
      "learning_rate": 5.4376021241830065e-06,
      "loss": 0.0268,
      "step": 11116
    },
    {
      "epoch": 2.5544577205882355,
      "grad_norm": 0.9581001996994019,
      "learning_rate": 5.4370915032679735e-06,
      "loss": 0.0302,
      "step": 11117
    },
    {
      "epoch": 2.5546875,
      "grad_norm": 0.7353768348693848,
      "learning_rate": 5.436580882352942e-06,
      "loss": 0.0251,
      "step": 11118
    },
    {
      "epoch": 2.5549172794117645,
      "grad_norm": 1.4145572185516357,
      "learning_rate": 5.436070261437909e-06,
      "loss": 0.0306,
      "step": 11119
    },
    {
      "epoch": 2.5551470588235294,
      "grad_norm": 0.9219267964363098,
      "learning_rate": 5.435559640522876e-06,
      "loss": 0.0397,
      "step": 11120
    },
    {
      "epoch": 2.5553768382352944,
      "grad_norm": 0.9275237917900085,
      "learning_rate": 5.435049019607843e-06,
      "loss": 0.0372,
      "step": 11121
    },
    {
      "epoch": 2.555606617647059,
      "grad_norm": 0.7160449624061584,
      "learning_rate": 5.434538398692811e-06,
      "loss": 0.029,
      "step": 11122
    },
    {
      "epoch": 2.5558363970588234,
      "grad_norm": 0.916715681552887,
      "learning_rate": 5.434027777777778e-06,
      "loss": 0.0495,
      "step": 11123
    },
    {
      "epoch": 2.5560661764705883,
      "grad_norm": 0.8627667427062988,
      "learning_rate": 5.433517156862745e-06,
      "loss": 0.0424,
      "step": 11124
    },
    {
      "epoch": 2.556295955882353,
      "grad_norm": 1.049037218093872,
      "learning_rate": 5.433006535947712e-06,
      "loss": 0.0384,
      "step": 11125
    },
    {
      "epoch": 2.5565257352941178,
      "grad_norm": 0.8406492471694946,
      "learning_rate": 5.432495915032681e-06,
      "loss": 0.0337,
      "step": 11126
    },
    {
      "epoch": 2.5567555147058822,
      "grad_norm": 0.8738505244255066,
      "learning_rate": 5.431985294117648e-06,
      "loss": 0.0379,
      "step": 11127
    },
    {
      "epoch": 2.556985294117647,
      "grad_norm": 0.903846025466919,
      "learning_rate": 5.431474673202615e-06,
      "loss": 0.0308,
      "step": 11128
    },
    {
      "epoch": 2.5572150735294117,
      "grad_norm": 0.7926871180534363,
      "learning_rate": 5.430964052287582e-06,
      "loss": 0.0433,
      "step": 11129
    },
    {
      "epoch": 2.5574448529411766,
      "grad_norm": 0.8387408256530762,
      "learning_rate": 5.43045343137255e-06,
      "loss": 0.0354,
      "step": 11130
    },
    {
      "epoch": 2.557674632352941,
      "grad_norm": 1.225990653038025,
      "learning_rate": 5.429942810457517e-06,
      "loss": 0.061,
      "step": 11131
    },
    {
      "epoch": 2.5579044117647056,
      "grad_norm": 1.2097454071044922,
      "learning_rate": 5.429432189542484e-06,
      "loss": 0.057,
      "step": 11132
    },
    {
      "epoch": 2.5581341911764706,
      "grad_norm": 1.1499974727630615,
      "learning_rate": 5.428921568627451e-06,
      "loss": 0.0681,
      "step": 11133
    },
    {
      "epoch": 2.5583639705882355,
      "grad_norm": 0.8917264938354492,
      "learning_rate": 5.4284109477124195e-06,
      "loss": 0.0429,
      "step": 11134
    },
    {
      "epoch": 2.55859375,
      "grad_norm": 1.207212209701538,
      "learning_rate": 5.4279003267973865e-06,
      "loss": 0.0517,
      "step": 11135
    },
    {
      "epoch": 2.5588235294117645,
      "grad_norm": 1.2692583799362183,
      "learning_rate": 5.4273897058823535e-06,
      "loss": 0.0578,
      "step": 11136
    },
    {
      "epoch": 2.5590533088235294,
      "grad_norm": 0.7939675450325012,
      "learning_rate": 5.4268790849673205e-06,
      "loss": 0.0282,
      "step": 11137
    },
    {
      "epoch": 2.5592830882352944,
      "grad_norm": 0.8974624276161194,
      "learning_rate": 5.426368464052288e-06,
      "loss": 0.0472,
      "step": 11138
    },
    {
      "epoch": 2.559512867647059,
      "grad_norm": 0.6081893444061279,
      "learning_rate": 5.425857843137255e-06,
      "loss": 0.0341,
      "step": 11139
    },
    {
      "epoch": 2.5597426470588234,
      "grad_norm": 0.9732176065444946,
      "learning_rate": 5.4253472222222224e-06,
      "loss": 0.0358,
      "step": 11140
    },
    {
      "epoch": 2.5599724264705883,
      "grad_norm": 1.1147414445877075,
      "learning_rate": 5.4248366013071894e-06,
      "loss": 0.043,
      "step": 11141
    },
    {
      "epoch": 2.560202205882353,
      "grad_norm": 1.1032389402389526,
      "learning_rate": 5.424325980392158e-06,
      "loss": 0.0426,
      "step": 11142
    },
    {
      "epoch": 2.5604319852941178,
      "grad_norm": 1.1287453174591064,
      "learning_rate": 5.423815359477125e-06,
      "loss": 0.0533,
      "step": 11143
    },
    {
      "epoch": 2.5606617647058822,
      "grad_norm": 0.6358441114425659,
      "learning_rate": 5.423304738562092e-06,
      "loss": 0.0334,
      "step": 11144
    },
    {
      "epoch": 2.560891544117647,
      "grad_norm": 0.8242461681365967,
      "learning_rate": 5.422794117647059e-06,
      "loss": 0.037,
      "step": 11145
    },
    {
      "epoch": 2.5611213235294117,
      "grad_norm": 1.1154639720916748,
      "learning_rate": 5.422283496732027e-06,
      "loss": 0.0698,
      "step": 11146
    },
    {
      "epoch": 2.5613511029411766,
      "grad_norm": 1.08540678024292,
      "learning_rate": 5.421772875816994e-06,
      "loss": 0.0509,
      "step": 11147
    },
    {
      "epoch": 2.561580882352941,
      "grad_norm": 1.0350347757339478,
      "learning_rate": 5.421262254901961e-06,
      "loss": 0.0512,
      "step": 11148
    },
    {
      "epoch": 2.5618106617647056,
      "grad_norm": 0.6849801540374756,
      "learning_rate": 5.420751633986928e-06,
      "loss": 0.0259,
      "step": 11149
    },
    {
      "epoch": 2.5620404411764706,
      "grad_norm": 0.9283512830734253,
      "learning_rate": 5.420241013071896e-06,
      "loss": 0.0468,
      "step": 11150
    },
    {
      "epoch": 2.5622702205882355,
      "grad_norm": 1.066118597984314,
      "learning_rate": 5.419730392156863e-06,
      "loss": 0.0543,
      "step": 11151
    },
    {
      "epoch": 2.5625,
      "grad_norm": 1.1276659965515137,
      "learning_rate": 5.41921977124183e-06,
      "loss": 0.0492,
      "step": 11152
    },
    {
      "epoch": 2.5627297794117645,
      "grad_norm": 1.0966606140136719,
      "learning_rate": 5.418709150326798e-06,
      "loss": 0.0879,
      "step": 11153
    },
    {
      "epoch": 2.5629595588235294,
      "grad_norm": 0.8084696531295776,
      "learning_rate": 5.418198529411766e-06,
      "loss": 0.0483,
      "step": 11154
    },
    {
      "epoch": 2.5631893382352944,
      "grad_norm": 0.6485305428504944,
      "learning_rate": 5.417687908496733e-06,
      "loss": 0.0309,
      "step": 11155
    },
    {
      "epoch": 2.563419117647059,
      "grad_norm": 1.1270860433578491,
      "learning_rate": 5.4171772875817e-06,
      "loss": 0.0608,
      "step": 11156
    },
    {
      "epoch": 2.5636488970588234,
      "grad_norm": 0.7972946763038635,
      "learning_rate": 5.416666666666667e-06,
      "loss": 0.0455,
      "step": 11157
    },
    {
      "epoch": 2.5638786764705883,
      "grad_norm": 1.626861333847046,
      "learning_rate": 5.416156045751635e-06,
      "loss": 0.0525,
      "step": 11158
    },
    {
      "epoch": 2.564108455882353,
      "grad_norm": 1.273220419883728,
      "learning_rate": 5.415645424836602e-06,
      "loss": 0.0742,
      "step": 11159
    },
    {
      "epoch": 2.5643382352941178,
      "grad_norm": 0.7470555305480957,
      "learning_rate": 5.415134803921569e-06,
      "loss": 0.0263,
      "step": 11160
    },
    {
      "epoch": 2.5645680147058822,
      "grad_norm": 1.236358880996704,
      "learning_rate": 5.414624183006536e-06,
      "loss": 0.0539,
      "step": 11161
    },
    {
      "epoch": 2.564797794117647,
      "grad_norm": 0.9190732836723328,
      "learning_rate": 5.414113562091504e-06,
      "loss": 0.0472,
      "step": 11162
    },
    {
      "epoch": 2.5650275735294117,
      "grad_norm": 0.9033105969429016,
      "learning_rate": 5.413602941176471e-06,
      "loss": 0.0332,
      "step": 11163
    },
    {
      "epoch": 2.5652573529411766,
      "grad_norm": 0.7758083939552307,
      "learning_rate": 5.413092320261438e-06,
      "loss": 0.0414,
      "step": 11164
    },
    {
      "epoch": 2.565487132352941,
      "grad_norm": 1.1002155542373657,
      "learning_rate": 5.412581699346405e-06,
      "loss": 0.0512,
      "step": 11165
    },
    {
      "epoch": 2.5657169117647056,
      "grad_norm": 0.7784658670425415,
      "learning_rate": 5.412071078431373e-06,
      "loss": 0.0327,
      "step": 11166
    },
    {
      "epoch": 2.5659466911764706,
      "grad_norm": 0.7017744183540344,
      "learning_rate": 5.41156045751634e-06,
      "loss": 0.0402,
      "step": 11167
    },
    {
      "epoch": 2.5661764705882355,
      "grad_norm": 0.9874624609947205,
      "learning_rate": 5.411049836601307e-06,
      "loss": 0.0339,
      "step": 11168
    },
    {
      "epoch": 2.56640625,
      "grad_norm": 0.8647386431694031,
      "learning_rate": 5.410539215686274e-06,
      "loss": 0.0374,
      "step": 11169
    },
    {
      "epoch": 2.5666360294117645,
      "grad_norm": 0.7960025668144226,
      "learning_rate": 5.410028594771243e-06,
      "loss": 0.0379,
      "step": 11170
    },
    {
      "epoch": 2.5668658088235294,
      "grad_norm": 0.8422783017158508,
      "learning_rate": 5.40951797385621e-06,
      "loss": 0.0438,
      "step": 11171
    },
    {
      "epoch": 2.5670955882352944,
      "grad_norm": 0.8261228203773499,
      "learning_rate": 5.409007352941177e-06,
      "loss": 0.037,
      "step": 11172
    },
    {
      "epoch": 2.567325367647059,
      "grad_norm": 1.0885916948318481,
      "learning_rate": 5.408496732026144e-06,
      "loss": 0.0441,
      "step": 11173
    },
    {
      "epoch": 2.5675551470588234,
      "grad_norm": 0.7136032581329346,
      "learning_rate": 5.407986111111112e-06,
      "loss": 0.0238,
      "step": 11174
    },
    {
      "epoch": 2.5677849264705883,
      "grad_norm": 0.7067968845367432,
      "learning_rate": 5.407475490196079e-06,
      "loss": 0.0258,
      "step": 11175
    },
    {
      "epoch": 2.568014705882353,
      "grad_norm": 0.9629825949668884,
      "learning_rate": 5.406964869281046e-06,
      "loss": 0.0341,
      "step": 11176
    },
    {
      "epoch": 2.5682444852941178,
      "grad_norm": 0.8421881198883057,
      "learning_rate": 5.406454248366013e-06,
      "loss": 0.0407,
      "step": 11177
    },
    {
      "epoch": 2.5684742647058822,
      "grad_norm": 0.7568432092666626,
      "learning_rate": 5.405943627450982e-06,
      "loss": 0.0318,
      "step": 11178
    },
    {
      "epoch": 2.568704044117647,
      "grad_norm": 1.2379117012023926,
      "learning_rate": 5.405433006535949e-06,
      "loss": 0.044,
      "step": 11179
    },
    {
      "epoch": 2.5689338235294117,
      "grad_norm": 1.0039373636245728,
      "learning_rate": 5.404922385620916e-06,
      "loss": 0.0484,
      "step": 11180
    },
    {
      "epoch": 2.5691636029411766,
      "grad_norm": 1.254919409751892,
      "learning_rate": 5.404411764705883e-06,
      "loss": 0.0401,
      "step": 11181
    },
    {
      "epoch": 2.569393382352941,
      "grad_norm": 0.8977962136268616,
      "learning_rate": 5.403901143790851e-06,
      "loss": 0.0413,
      "step": 11182
    },
    {
      "epoch": 2.5696231617647056,
      "grad_norm": 0.8762667179107666,
      "learning_rate": 5.403390522875818e-06,
      "loss": 0.0398,
      "step": 11183
    },
    {
      "epoch": 2.5698529411764706,
      "grad_norm": 0.9301860332489014,
      "learning_rate": 5.402879901960785e-06,
      "loss": 0.0437,
      "step": 11184
    },
    {
      "epoch": 2.5700827205882355,
      "grad_norm": 0.8837374448776245,
      "learning_rate": 5.402369281045752e-06,
      "loss": 0.0436,
      "step": 11185
    },
    {
      "epoch": 2.5703125,
      "grad_norm": 0.9753702878952026,
      "learning_rate": 5.4018586601307195e-06,
      "loss": 0.0372,
      "step": 11186
    },
    {
      "epoch": 2.5705422794117645,
      "grad_norm": 1.0308623313903809,
      "learning_rate": 5.401348039215687e-06,
      "loss": 0.0443,
      "step": 11187
    },
    {
      "epoch": 2.5707720588235294,
      "grad_norm": 0.8037614226341248,
      "learning_rate": 5.400837418300654e-06,
      "loss": 0.0332,
      "step": 11188
    },
    {
      "epoch": 2.5710018382352944,
      "grad_norm": 1.2160775661468506,
      "learning_rate": 5.400326797385621e-06,
      "loss": 0.0448,
      "step": 11189
    },
    {
      "epoch": 2.571231617647059,
      "grad_norm": 0.7634660005569458,
      "learning_rate": 5.399816176470589e-06,
      "loss": 0.0433,
      "step": 11190
    },
    {
      "epoch": 2.5714613970588234,
      "grad_norm": 0.8729108572006226,
      "learning_rate": 5.399305555555556e-06,
      "loss": 0.0385,
      "step": 11191
    },
    {
      "epoch": 2.5716911764705883,
      "grad_norm": 0.9199585318565369,
      "learning_rate": 5.398794934640523e-06,
      "loss": 0.0389,
      "step": 11192
    },
    {
      "epoch": 2.571920955882353,
      "grad_norm": 1.2640352249145508,
      "learning_rate": 5.39828431372549e-06,
      "loss": 0.049,
      "step": 11193
    },
    {
      "epoch": 2.5721507352941178,
      "grad_norm": 0.8636745810508728,
      "learning_rate": 5.397773692810458e-06,
      "loss": 0.0355,
      "step": 11194
    },
    {
      "epoch": 2.5723805147058822,
      "grad_norm": 0.9031417369842529,
      "learning_rate": 5.397263071895425e-06,
      "loss": 0.0272,
      "step": 11195
    },
    {
      "epoch": 2.572610294117647,
      "grad_norm": 0.8143326044082642,
      "learning_rate": 5.396752450980392e-06,
      "loss": 0.029,
      "step": 11196
    },
    {
      "epoch": 2.5728400735294117,
      "grad_norm": 1.1160997152328491,
      "learning_rate": 5.39624183006536e-06,
      "loss": 0.0523,
      "step": 11197
    },
    {
      "epoch": 2.5730698529411766,
      "grad_norm": 1.107088565826416,
      "learning_rate": 5.395731209150328e-06,
      "loss": 0.0481,
      "step": 11198
    },
    {
      "epoch": 2.573299632352941,
      "grad_norm": 0.9106523990631104,
      "learning_rate": 5.395220588235295e-06,
      "loss": 0.0325,
      "step": 11199
    },
    {
      "epoch": 2.5735294117647056,
      "grad_norm": 0.8439371585845947,
      "learning_rate": 5.394709967320262e-06,
      "loss": 0.0352,
      "step": 11200
    },
    {
      "epoch": 2.5737591911764706,
      "grad_norm": 0.8698267936706543,
      "learning_rate": 5.394199346405229e-06,
      "loss": 0.0351,
      "step": 11201
    },
    {
      "epoch": 2.5739889705882355,
      "grad_norm": 1.0017017126083374,
      "learning_rate": 5.393688725490197e-06,
      "loss": 0.0389,
      "step": 11202
    },
    {
      "epoch": 2.57421875,
      "grad_norm": 1.062902808189392,
      "learning_rate": 5.393178104575164e-06,
      "loss": 0.0421,
      "step": 11203
    },
    {
      "epoch": 2.5744485294117645,
      "grad_norm": 0.9552811980247498,
      "learning_rate": 5.392667483660131e-06,
      "loss": 0.0413,
      "step": 11204
    },
    {
      "epoch": 2.5746783088235294,
      "grad_norm": 1.0556257963180542,
      "learning_rate": 5.392156862745098e-06,
      "loss": 0.0632,
      "step": 11205
    },
    {
      "epoch": 2.5749080882352944,
      "grad_norm": 0.7223072052001953,
      "learning_rate": 5.3916462418300666e-06,
      "loss": 0.0241,
      "step": 11206
    },
    {
      "epoch": 2.575137867647059,
      "grad_norm": 1.1793041229248047,
      "learning_rate": 5.3911356209150336e-06,
      "loss": 0.0636,
      "step": 11207
    },
    {
      "epoch": 2.5753676470588234,
      "grad_norm": 1.0579266548156738,
      "learning_rate": 5.390625000000001e-06,
      "loss": 0.0464,
      "step": 11208
    },
    {
      "epoch": 2.5755974264705883,
      "grad_norm": 1.1435219049453735,
      "learning_rate": 5.390114379084968e-06,
      "loss": 0.053,
      "step": 11209
    },
    {
      "epoch": 2.575827205882353,
      "grad_norm": 0.6341428160667419,
      "learning_rate": 5.389603758169935e-06,
      "loss": 0.026,
      "step": 11210
    },
    {
      "epoch": 2.5760569852941178,
      "grad_norm": 1.1358661651611328,
      "learning_rate": 5.3890931372549025e-06,
      "loss": 0.0692,
      "step": 11211
    },
    {
      "epoch": 2.5762867647058822,
      "grad_norm": 0.8859058022499084,
      "learning_rate": 5.3885825163398695e-06,
      "loss": 0.0445,
      "step": 11212
    },
    {
      "epoch": 2.576516544117647,
      "grad_norm": 0.742142379283905,
      "learning_rate": 5.3880718954248365e-06,
      "loss": 0.03,
      "step": 11213
    },
    {
      "epoch": 2.5767463235294117,
      "grad_norm": 1.0683624744415283,
      "learning_rate": 5.3875612745098035e-06,
      "loss": 0.0515,
      "step": 11214
    },
    {
      "epoch": 2.5769761029411766,
      "grad_norm": 0.8839269280433655,
      "learning_rate": 5.387050653594772e-06,
      "loss": 0.0454,
      "step": 11215
    },
    {
      "epoch": 2.577205882352941,
      "grad_norm": 0.7508869767189026,
      "learning_rate": 5.386540032679739e-06,
      "loss": 0.037,
      "step": 11216
    },
    {
      "epoch": 2.5774356617647056,
      "grad_norm": 1.0808809995651245,
      "learning_rate": 5.386029411764706e-06,
      "loss": 0.037,
      "step": 11217
    },
    {
      "epoch": 2.5776654411764706,
      "grad_norm": 0.8205216526985168,
      "learning_rate": 5.385518790849673e-06,
      "loss": 0.046,
      "step": 11218
    },
    {
      "epoch": 2.5778952205882355,
      "grad_norm": 1.08635675907135,
      "learning_rate": 5.385008169934641e-06,
      "loss": 0.0439,
      "step": 11219
    },
    {
      "epoch": 2.578125,
      "grad_norm": 0.5952969789505005,
      "learning_rate": 5.384497549019608e-06,
      "loss": 0.0216,
      "step": 11220
    },
    {
      "epoch": 2.5783547794117645,
      "grad_norm": 0.8574045300483704,
      "learning_rate": 5.383986928104575e-06,
      "loss": 0.0459,
      "step": 11221
    },
    {
      "epoch": 2.5785845588235294,
      "grad_norm": 0.9497452974319458,
      "learning_rate": 5.383476307189542e-06,
      "loss": 0.0381,
      "step": 11222
    },
    {
      "epoch": 2.5788143382352944,
      "grad_norm": 0.9509694576263428,
      "learning_rate": 5.382965686274511e-06,
      "loss": 0.0395,
      "step": 11223
    },
    {
      "epoch": 2.579044117647059,
      "grad_norm": 1.085995078086853,
      "learning_rate": 5.382455065359478e-06,
      "loss": 0.0562,
      "step": 11224
    },
    {
      "epoch": 2.5792738970588234,
      "grad_norm": 0.8947831392288208,
      "learning_rate": 5.381944444444445e-06,
      "loss": 0.0373,
      "step": 11225
    },
    {
      "epoch": 2.5795036764705883,
      "grad_norm": 0.7493554949760437,
      "learning_rate": 5.381433823529412e-06,
      "loss": 0.0407,
      "step": 11226
    },
    {
      "epoch": 2.579733455882353,
      "grad_norm": 1.25734281539917,
      "learning_rate": 5.38092320261438e-06,
      "loss": 0.0348,
      "step": 11227
    },
    {
      "epoch": 2.5799632352941178,
      "grad_norm": 0.9919134974479675,
      "learning_rate": 5.380412581699347e-06,
      "loss": 0.0444,
      "step": 11228
    },
    {
      "epoch": 2.5801930147058822,
      "grad_norm": 1.0800156593322754,
      "learning_rate": 5.379901960784314e-06,
      "loss": 0.0454,
      "step": 11229
    },
    {
      "epoch": 2.580422794117647,
      "grad_norm": 1.3968355655670166,
      "learning_rate": 5.379391339869281e-06,
      "loss": 0.046,
      "step": 11230
    },
    {
      "epoch": 2.5806525735294117,
      "grad_norm": 0.62857586145401,
      "learning_rate": 5.3788807189542495e-06,
      "loss": 0.0212,
      "step": 11231
    },
    {
      "epoch": 2.5808823529411766,
      "grad_norm": 0.8300668597221375,
      "learning_rate": 5.3783700980392166e-06,
      "loss": 0.0357,
      "step": 11232
    },
    {
      "epoch": 2.581112132352941,
      "grad_norm": 1.011802077293396,
      "learning_rate": 5.3778594771241836e-06,
      "loss": 0.0325,
      "step": 11233
    },
    {
      "epoch": 2.5813419117647056,
      "grad_norm": 1.542482614517212,
      "learning_rate": 5.377348856209151e-06,
      "loss": 0.0608,
      "step": 11234
    },
    {
      "epoch": 2.5815716911764706,
      "grad_norm": 1.0293841361999512,
      "learning_rate": 5.3768382352941184e-06,
      "loss": 0.0352,
      "step": 11235
    },
    {
      "epoch": 2.5818014705882355,
      "grad_norm": 1.1116547584533691,
      "learning_rate": 5.3763276143790855e-06,
      "loss": 0.0483,
      "step": 11236
    },
    {
      "epoch": 2.58203125,
      "grad_norm": 1.0396132469177246,
      "learning_rate": 5.3758169934640525e-06,
      "loss": 0.0546,
      "step": 11237
    },
    {
      "epoch": 2.5822610294117645,
      "grad_norm": 0.9337738156318665,
      "learning_rate": 5.3753063725490195e-06,
      "loss": 0.0465,
      "step": 11238
    },
    {
      "epoch": 2.5824908088235294,
      "grad_norm": 0.6558922529220581,
      "learning_rate": 5.374795751633987e-06,
      "loss": 0.0263,
      "step": 11239
    },
    {
      "epoch": 2.5827205882352944,
      "grad_norm": 0.8233649134635925,
      "learning_rate": 5.374285130718954e-06,
      "loss": 0.0474,
      "step": 11240
    },
    {
      "epoch": 2.582950367647059,
      "grad_norm": 0.6884114146232605,
      "learning_rate": 5.373774509803921e-06,
      "loss": 0.0324,
      "step": 11241
    },
    {
      "epoch": 2.5831801470588234,
      "grad_norm": 0.9522426724433899,
      "learning_rate": 5.373263888888889e-06,
      "loss": 0.0443,
      "step": 11242
    },
    {
      "epoch": 2.5834099264705883,
      "grad_norm": 0.9422662854194641,
      "learning_rate": 5.372753267973857e-06,
      "loss": 0.0419,
      "step": 11243
    },
    {
      "epoch": 2.583639705882353,
      "grad_norm": 1.3051363229751587,
      "learning_rate": 5.372242647058824e-06,
      "loss": 0.0457,
      "step": 11244
    },
    {
      "epoch": 2.5838694852941178,
      "grad_norm": 0.9406086802482605,
      "learning_rate": 5.371732026143791e-06,
      "loss": 0.0447,
      "step": 11245
    },
    {
      "epoch": 2.5840992647058822,
      "grad_norm": 0.7793093323707581,
      "learning_rate": 5.371221405228758e-06,
      "loss": 0.0353,
      "step": 11246
    },
    {
      "epoch": 2.584329044117647,
      "grad_norm": 1.0347094535827637,
      "learning_rate": 5.370710784313726e-06,
      "loss": 0.0519,
      "step": 11247
    },
    {
      "epoch": 2.5845588235294117,
      "grad_norm": 1.0242079496383667,
      "learning_rate": 5.370200163398693e-06,
      "loss": 0.0478,
      "step": 11248
    },
    {
      "epoch": 2.5847886029411766,
      "grad_norm": 0.9017411470413208,
      "learning_rate": 5.36968954248366e-06,
      "loss": 0.0366,
      "step": 11249
    },
    {
      "epoch": 2.585018382352941,
      "grad_norm": 0.8331505656242371,
      "learning_rate": 5.369178921568627e-06,
      "loss": 0.0282,
      "step": 11250
    },
    {
      "epoch": 2.5852481617647056,
      "grad_norm": 0.5488921999931335,
      "learning_rate": 5.368668300653596e-06,
      "loss": 0.0143,
      "step": 11251
    },
    {
      "epoch": 2.5854779411764706,
      "grad_norm": 0.7829154133796692,
      "learning_rate": 5.368157679738563e-06,
      "loss": 0.0317,
      "step": 11252
    },
    {
      "epoch": 2.5857077205882355,
      "grad_norm": 1.4046486616134644,
      "learning_rate": 5.36764705882353e-06,
      "loss": 0.0694,
      "step": 11253
    },
    {
      "epoch": 2.5859375,
      "grad_norm": 0.8789283037185669,
      "learning_rate": 5.367136437908497e-06,
      "loss": 0.0388,
      "step": 11254
    },
    {
      "epoch": 2.5861672794117645,
      "grad_norm": 1.0600064992904663,
      "learning_rate": 5.366625816993465e-06,
      "loss": 0.0482,
      "step": 11255
    },
    {
      "epoch": 2.5863970588235294,
      "grad_norm": 0.7600158452987671,
      "learning_rate": 5.366115196078432e-06,
      "loss": 0.0324,
      "step": 11256
    },
    {
      "epoch": 2.5866268382352944,
      "grad_norm": 1.3252506256103516,
      "learning_rate": 5.365604575163399e-06,
      "loss": 0.0545,
      "step": 11257
    },
    {
      "epoch": 2.586856617647059,
      "grad_norm": 1.1895277500152588,
      "learning_rate": 5.365093954248366e-06,
      "loss": 0.0585,
      "step": 11258
    },
    {
      "epoch": 2.5870863970588234,
      "grad_norm": 0.7835925221443176,
      "learning_rate": 5.364583333333334e-06,
      "loss": 0.0486,
      "step": 11259
    },
    {
      "epoch": 2.5873161764705883,
      "grad_norm": 0.9092673659324646,
      "learning_rate": 5.3640727124183014e-06,
      "loss": 0.0229,
      "step": 11260
    },
    {
      "epoch": 2.587545955882353,
      "grad_norm": 1.2624589204788208,
      "learning_rate": 5.3635620915032684e-06,
      "loss": 0.0571,
      "step": 11261
    },
    {
      "epoch": 2.5877757352941178,
      "grad_norm": 1.0059036016464233,
      "learning_rate": 5.3630514705882355e-06,
      "loss": 0.0503,
      "step": 11262
    },
    {
      "epoch": 2.5880055147058822,
      "grad_norm": 1.1443055868148804,
      "learning_rate": 5.362540849673203e-06,
      "loss": 0.0509,
      "step": 11263
    },
    {
      "epoch": 2.588235294117647,
      "grad_norm": 0.8841293454170227,
      "learning_rate": 5.36203022875817e-06,
      "loss": 0.0451,
      "step": 11264
    },
    {
      "epoch": 2.5884650735294117,
      "grad_norm": 0.7824169397354126,
      "learning_rate": 5.361519607843137e-06,
      "loss": 0.0382,
      "step": 11265
    },
    {
      "epoch": 2.5886948529411766,
      "grad_norm": 0.9112231731414795,
      "learning_rate": 5.361008986928104e-06,
      "loss": 0.0374,
      "step": 11266
    },
    {
      "epoch": 2.588924632352941,
      "grad_norm": 1.0135176181793213,
      "learning_rate": 5.360498366013073e-06,
      "loss": 0.0395,
      "step": 11267
    },
    {
      "epoch": 2.5891544117647056,
      "grad_norm": 0.9232005476951599,
      "learning_rate": 5.35998774509804e-06,
      "loss": 0.0312,
      "step": 11268
    },
    {
      "epoch": 2.5893841911764706,
      "grad_norm": 0.911827027797699,
      "learning_rate": 5.359477124183007e-06,
      "loss": 0.0327,
      "step": 11269
    },
    {
      "epoch": 2.5896139705882355,
      "grad_norm": 0.703885555267334,
      "learning_rate": 5.358966503267974e-06,
      "loss": 0.0269,
      "step": 11270
    },
    {
      "epoch": 2.58984375,
      "grad_norm": 1.1024681329727173,
      "learning_rate": 5.358455882352942e-06,
      "loss": 0.0468,
      "step": 11271
    },
    {
      "epoch": 2.5900735294117645,
      "grad_norm": 0.7188619375228882,
      "learning_rate": 5.357945261437909e-06,
      "loss": 0.0242,
      "step": 11272
    },
    {
      "epoch": 2.5903033088235294,
      "grad_norm": 1.0465410947799683,
      "learning_rate": 5.357434640522876e-06,
      "loss": 0.0473,
      "step": 11273
    },
    {
      "epoch": 2.5905330882352944,
      "grad_norm": 0.850275993347168,
      "learning_rate": 5.356924019607843e-06,
      "loss": 0.0324,
      "step": 11274
    },
    {
      "epoch": 2.590762867647059,
      "grad_norm": 1.0861587524414062,
      "learning_rate": 5.356413398692811e-06,
      "loss": 0.0371,
      "step": 11275
    },
    {
      "epoch": 2.5909926470588234,
      "grad_norm": 0.7109502553939819,
      "learning_rate": 5.355902777777779e-06,
      "loss": 0.0332,
      "step": 11276
    },
    {
      "epoch": 2.5912224264705883,
      "grad_norm": 0.8506054282188416,
      "learning_rate": 5.355392156862746e-06,
      "loss": 0.027,
      "step": 11277
    },
    {
      "epoch": 2.591452205882353,
      "grad_norm": 0.8558894991874695,
      "learning_rate": 5.354881535947713e-06,
      "loss": 0.0439,
      "step": 11278
    },
    {
      "epoch": 2.5916819852941178,
      "grad_norm": 0.9384357929229736,
      "learning_rate": 5.354370915032681e-06,
      "loss": 0.0443,
      "step": 11279
    },
    {
      "epoch": 2.5919117647058822,
      "grad_norm": 0.8394728899002075,
      "learning_rate": 5.353860294117648e-06,
      "loss": 0.0298,
      "step": 11280
    },
    {
      "epoch": 2.592141544117647,
      "grad_norm": 0.948832094669342,
      "learning_rate": 5.353349673202615e-06,
      "loss": 0.0399,
      "step": 11281
    },
    {
      "epoch": 2.5923713235294117,
      "grad_norm": 0.9812031984329224,
      "learning_rate": 5.352839052287582e-06,
      "loss": 0.0385,
      "step": 11282
    },
    {
      "epoch": 2.5926011029411766,
      "grad_norm": 0.718011736869812,
      "learning_rate": 5.3523284313725495e-06,
      "loss": 0.0298,
      "step": 11283
    },
    {
      "epoch": 2.592830882352941,
      "grad_norm": 0.7779951095581055,
      "learning_rate": 5.3518178104575166e-06,
      "loss": 0.0319,
      "step": 11284
    },
    {
      "epoch": 2.5930606617647056,
      "grad_norm": 1.330414056777954,
      "learning_rate": 5.3513071895424836e-06,
      "loss": 0.0326,
      "step": 11285
    },
    {
      "epoch": 2.5932904411764706,
      "grad_norm": 0.8595255017280579,
      "learning_rate": 5.350796568627451e-06,
      "loss": 0.0427,
      "step": 11286
    },
    {
      "epoch": 2.5935202205882355,
      "grad_norm": 0.8693825006484985,
      "learning_rate": 5.350285947712419e-06,
      "loss": 0.0369,
      "step": 11287
    },
    {
      "epoch": 2.59375,
      "grad_norm": 0.9505016207695007,
      "learning_rate": 5.349775326797386e-06,
      "loss": 0.0355,
      "step": 11288
    },
    {
      "epoch": 2.5939797794117645,
      "grad_norm": 0.6269543170928955,
      "learning_rate": 5.349264705882353e-06,
      "loss": 0.0184,
      "step": 11289
    },
    {
      "epoch": 2.5942095588235294,
      "grad_norm": 0.860898494720459,
      "learning_rate": 5.34875408496732e-06,
      "loss": 0.034,
      "step": 11290
    },
    {
      "epoch": 2.5944393382352944,
      "grad_norm": 1.0559284687042236,
      "learning_rate": 5.348243464052288e-06,
      "loss": 0.0371,
      "step": 11291
    },
    {
      "epoch": 2.594669117647059,
      "grad_norm": 1.4561209678649902,
      "learning_rate": 5.347732843137255e-06,
      "loss": 0.049,
      "step": 11292
    },
    {
      "epoch": 2.5948988970588234,
      "grad_norm": 0.9222022294998169,
      "learning_rate": 5.347222222222222e-06,
      "loss": 0.0527,
      "step": 11293
    },
    {
      "epoch": 2.5951286764705883,
      "grad_norm": 0.7862163186073303,
      "learning_rate": 5.346711601307189e-06,
      "loss": 0.0214,
      "step": 11294
    },
    {
      "epoch": 2.595358455882353,
      "grad_norm": 0.9924296140670776,
      "learning_rate": 5.346200980392158e-06,
      "loss": 0.0437,
      "step": 11295
    },
    {
      "epoch": 2.5955882352941178,
      "grad_norm": 1.0450149774551392,
      "learning_rate": 5.345690359477125e-06,
      "loss": 0.0459,
      "step": 11296
    },
    {
      "epoch": 2.5958180147058822,
      "grad_norm": 0.7220696210861206,
      "learning_rate": 5.345179738562092e-06,
      "loss": 0.0309,
      "step": 11297
    },
    {
      "epoch": 2.596047794117647,
      "grad_norm": 0.9382767677307129,
      "learning_rate": 5.344669117647059e-06,
      "loss": 0.0447,
      "step": 11298
    },
    {
      "epoch": 2.5962775735294117,
      "grad_norm": 1.1079719066619873,
      "learning_rate": 5.344158496732027e-06,
      "loss": 0.0441,
      "step": 11299
    },
    {
      "epoch": 2.5965073529411766,
      "grad_norm": 0.7951621413230896,
      "learning_rate": 5.343647875816994e-06,
      "loss": 0.0352,
      "step": 11300
    },
    {
      "epoch": 2.596737132352941,
      "grad_norm": 0.9939345717430115,
      "learning_rate": 5.343137254901961e-06,
      "loss": 0.0347,
      "step": 11301
    },
    {
      "epoch": 2.5969669117647056,
      "grad_norm": 0.9163428544998169,
      "learning_rate": 5.342626633986928e-06,
      "loss": 0.041,
      "step": 11302
    },
    {
      "epoch": 2.5971966911764706,
      "grad_norm": 0.8117421865463257,
      "learning_rate": 5.342116013071897e-06,
      "loss": 0.0311,
      "step": 11303
    },
    {
      "epoch": 2.5974264705882355,
      "grad_norm": 0.801866888999939,
      "learning_rate": 5.341605392156864e-06,
      "loss": 0.0273,
      "step": 11304
    },
    {
      "epoch": 2.59765625,
      "grad_norm": 2.6010019779205322,
      "learning_rate": 5.341094771241831e-06,
      "loss": 0.0662,
      "step": 11305
    },
    {
      "epoch": 2.5978860294117645,
      "grad_norm": 1.3589403629302979,
      "learning_rate": 5.340584150326798e-06,
      "loss": 0.0488,
      "step": 11306
    },
    {
      "epoch": 2.5981158088235294,
      "grad_norm": 1.3631850481033325,
      "learning_rate": 5.3400735294117655e-06,
      "loss": 0.0532,
      "step": 11307
    },
    {
      "epoch": 2.5983455882352944,
      "grad_norm": 1.0698518753051758,
      "learning_rate": 5.3395629084967325e-06,
      "loss": 0.0465,
      "step": 11308
    },
    {
      "epoch": 2.598575367647059,
      "grad_norm": 0.6970623731613159,
      "learning_rate": 5.3390522875816995e-06,
      "loss": 0.0202,
      "step": 11309
    },
    {
      "epoch": 2.5988051470588234,
      "grad_norm": 1.0525237321853638,
      "learning_rate": 5.3385416666666666e-06,
      "loss": 0.0317,
      "step": 11310
    },
    {
      "epoch": 2.5990349264705883,
      "grad_norm": 0.7680785059928894,
      "learning_rate": 5.338031045751635e-06,
      "loss": 0.0417,
      "step": 11311
    },
    {
      "epoch": 2.599264705882353,
      "grad_norm": 1.1093493700027466,
      "learning_rate": 5.337520424836602e-06,
      "loss": 0.0501,
      "step": 11312
    },
    {
      "epoch": 2.5994944852941178,
      "grad_norm": 0.7557135820388794,
      "learning_rate": 5.337009803921569e-06,
      "loss": 0.0251,
      "step": 11313
    },
    {
      "epoch": 2.5997242647058822,
      "grad_norm": 1.0702213048934937,
      "learning_rate": 5.336499183006536e-06,
      "loss": 0.0434,
      "step": 11314
    },
    {
      "epoch": 2.599954044117647,
      "grad_norm": 0.8943132758140564,
      "learning_rate": 5.335988562091504e-06,
      "loss": 0.0308,
      "step": 11315
    },
    {
      "epoch": 2.6001838235294117,
      "grad_norm": 0.7651641964912415,
      "learning_rate": 5.335477941176471e-06,
      "loss": 0.0276,
      "step": 11316
    },
    {
      "epoch": 2.6004136029411766,
      "grad_norm": 0.8258653283119202,
      "learning_rate": 5.334967320261438e-06,
      "loss": 0.0309,
      "step": 11317
    },
    {
      "epoch": 2.600643382352941,
      "grad_norm": 1.0290195941925049,
      "learning_rate": 5.334456699346405e-06,
      "loss": 0.0525,
      "step": 11318
    },
    {
      "epoch": 2.6008731617647056,
      "grad_norm": 0.7250891327857971,
      "learning_rate": 5.333946078431373e-06,
      "loss": 0.0362,
      "step": 11319
    },
    {
      "epoch": 2.6011029411764706,
      "grad_norm": 1.0605744123458862,
      "learning_rate": 5.333435457516341e-06,
      "loss": 0.0612,
      "step": 11320
    },
    {
      "epoch": 2.6013327205882355,
      "grad_norm": 0.8608598709106445,
      "learning_rate": 5.332924836601308e-06,
      "loss": 0.0328,
      "step": 11321
    },
    {
      "epoch": 2.6015625,
      "grad_norm": 0.882636308670044,
      "learning_rate": 5.332414215686275e-06,
      "loss": 0.0421,
      "step": 11322
    },
    {
      "epoch": 2.6017922794117645,
      "grad_norm": 0.9550964832305908,
      "learning_rate": 5.331903594771243e-06,
      "loss": 0.0448,
      "step": 11323
    },
    {
      "epoch": 2.6020220588235294,
      "grad_norm": 0.8584559559822083,
      "learning_rate": 5.33139297385621e-06,
      "loss": 0.0262,
      "step": 11324
    },
    {
      "epoch": 2.6022518382352944,
      "grad_norm": 0.7737739086151123,
      "learning_rate": 5.330882352941177e-06,
      "loss": 0.0344,
      "step": 11325
    },
    {
      "epoch": 2.602481617647059,
      "grad_norm": 1.0303575992584229,
      "learning_rate": 5.330371732026144e-06,
      "loss": 0.0427,
      "step": 11326
    },
    {
      "epoch": 2.6027113970588234,
      "grad_norm": 1.2197498083114624,
      "learning_rate": 5.329861111111112e-06,
      "loss": 0.0502,
      "step": 11327
    },
    {
      "epoch": 2.6029411764705883,
      "grad_norm": 0.9238620400428772,
      "learning_rate": 5.329350490196079e-06,
      "loss": 0.0413,
      "step": 11328
    },
    {
      "epoch": 2.603170955882353,
      "grad_norm": 0.6279187202453613,
      "learning_rate": 5.328839869281046e-06,
      "loss": 0.0256,
      "step": 11329
    },
    {
      "epoch": 2.6034007352941178,
      "grad_norm": 0.9000374674797058,
      "learning_rate": 5.328329248366013e-06,
      "loss": 0.0352,
      "step": 11330
    },
    {
      "epoch": 2.6036305147058822,
      "grad_norm": 1.0436911582946777,
      "learning_rate": 5.3278186274509815e-06,
      "loss": 0.0455,
      "step": 11331
    },
    {
      "epoch": 2.603860294117647,
      "grad_norm": 1.0177812576293945,
      "learning_rate": 5.3273080065359485e-06,
      "loss": 0.0552,
      "step": 11332
    },
    {
      "epoch": 2.6040900735294117,
      "grad_norm": 1.356454610824585,
      "learning_rate": 5.3267973856209155e-06,
      "loss": 0.0626,
      "step": 11333
    },
    {
      "epoch": 2.6043198529411766,
      "grad_norm": 1.3214651346206665,
      "learning_rate": 5.3262867647058825e-06,
      "loss": 0.0501,
      "step": 11334
    },
    {
      "epoch": 2.604549632352941,
      "grad_norm": 1.2694072723388672,
      "learning_rate": 5.32577614379085e-06,
      "loss": 0.06,
      "step": 11335
    },
    {
      "epoch": 2.6047794117647056,
      "grad_norm": 0.9563063979148865,
      "learning_rate": 5.325265522875817e-06,
      "loss": 0.0344,
      "step": 11336
    },
    {
      "epoch": 2.6050091911764706,
      "grad_norm": 0.8007306456565857,
      "learning_rate": 5.324754901960784e-06,
      "loss": 0.0349,
      "step": 11337
    },
    {
      "epoch": 2.6052389705882355,
      "grad_norm": 1.2237533330917358,
      "learning_rate": 5.3242442810457514e-06,
      "loss": 0.043,
      "step": 11338
    },
    {
      "epoch": 2.60546875,
      "grad_norm": 0.9110087752342224,
      "learning_rate": 5.32373366013072e-06,
      "loss": 0.0408,
      "step": 11339
    },
    {
      "epoch": 2.6056985294117645,
      "grad_norm": 0.8619490265846252,
      "learning_rate": 5.323223039215687e-06,
      "loss": 0.0293,
      "step": 11340
    },
    {
      "epoch": 2.6059283088235294,
      "grad_norm": 0.8340057730674744,
      "learning_rate": 5.322712418300654e-06,
      "loss": 0.0441,
      "step": 11341
    },
    {
      "epoch": 2.6061580882352944,
      "grad_norm": 0.7822740077972412,
      "learning_rate": 5.322201797385621e-06,
      "loss": 0.0282,
      "step": 11342
    },
    {
      "epoch": 2.606387867647059,
      "grad_norm": 1.0970737934112549,
      "learning_rate": 5.321691176470589e-06,
      "loss": 0.0478,
      "step": 11343
    },
    {
      "epoch": 2.6066176470588234,
      "grad_norm": 1.0422848463058472,
      "learning_rate": 5.321180555555556e-06,
      "loss": 0.0396,
      "step": 11344
    },
    {
      "epoch": 2.6068474264705883,
      "grad_norm": 1.0056493282318115,
      "learning_rate": 5.320669934640523e-06,
      "loss": 0.0366,
      "step": 11345
    },
    {
      "epoch": 2.607077205882353,
      "grad_norm": 0.9496453404426575,
      "learning_rate": 5.32015931372549e-06,
      "loss": 0.0621,
      "step": 11346
    },
    {
      "epoch": 2.6073069852941178,
      "grad_norm": 0.6919944882392883,
      "learning_rate": 5.319648692810459e-06,
      "loss": 0.0273,
      "step": 11347
    },
    {
      "epoch": 2.6075367647058822,
      "grad_norm": 1.0414159297943115,
      "learning_rate": 5.319138071895426e-06,
      "loss": 0.0481,
      "step": 11348
    },
    {
      "epoch": 2.607766544117647,
      "grad_norm": 0.5943455696105957,
      "learning_rate": 5.318627450980393e-06,
      "loss": 0.0178,
      "step": 11349
    },
    {
      "epoch": 2.6079963235294117,
      "grad_norm": 0.8391181230545044,
      "learning_rate": 5.31811683006536e-06,
      "loss": 0.0372,
      "step": 11350
    },
    {
      "epoch": 2.6082261029411766,
      "grad_norm": 1.1113381385803223,
      "learning_rate": 5.317606209150328e-06,
      "loss": 0.0425,
      "step": 11351
    },
    {
      "epoch": 2.608455882352941,
      "grad_norm": 0.8693690896034241,
      "learning_rate": 5.317095588235295e-06,
      "loss": 0.0471,
      "step": 11352
    },
    {
      "epoch": 2.6086856617647056,
      "grad_norm": 0.9584068059921265,
      "learning_rate": 5.316584967320262e-06,
      "loss": 0.0402,
      "step": 11353
    },
    {
      "epoch": 2.6089154411764706,
      "grad_norm": 0.8796180486679077,
      "learning_rate": 5.316074346405229e-06,
      "loss": 0.0255,
      "step": 11354
    },
    {
      "epoch": 2.6091452205882355,
      "grad_norm": 1.1756486892700195,
      "learning_rate": 5.3155637254901974e-06,
      "loss": 0.035,
      "step": 11355
    },
    {
      "epoch": 2.609375,
      "grad_norm": 1.0800492763519287,
      "learning_rate": 5.3150531045751645e-06,
      "loss": 0.0448,
      "step": 11356
    },
    {
      "epoch": 2.6096047794117645,
      "grad_norm": 1.0577753782272339,
      "learning_rate": 5.3145424836601315e-06,
      "loss": 0.0431,
      "step": 11357
    },
    {
      "epoch": 2.6098345588235294,
      "grad_norm": 0.8695757389068604,
      "learning_rate": 5.3140318627450985e-06,
      "loss": 0.037,
      "step": 11358
    },
    {
      "epoch": 2.6100643382352944,
      "grad_norm": 1.1938754320144653,
      "learning_rate": 5.313521241830066e-06,
      "loss": 0.0645,
      "step": 11359
    },
    {
      "epoch": 2.610294117647059,
      "grad_norm": 0.8755132555961609,
      "learning_rate": 5.313010620915033e-06,
      "loss": 0.0405,
      "step": 11360
    },
    {
      "epoch": 2.6105238970588234,
      "grad_norm": 1.049153208732605,
      "learning_rate": 5.3125e-06,
      "loss": 0.0479,
      "step": 11361
    },
    {
      "epoch": 2.6107536764705883,
      "grad_norm": 0.9830467104911804,
      "learning_rate": 5.311989379084967e-06,
      "loss": 0.0251,
      "step": 11362
    },
    {
      "epoch": 2.610983455882353,
      "grad_norm": 1.3116415739059448,
      "learning_rate": 5.311478758169934e-06,
      "loss": 0.0575,
      "step": 11363
    },
    {
      "epoch": 2.6112132352941178,
      "grad_norm": 0.8478938937187195,
      "learning_rate": 5.310968137254902e-06,
      "loss": 0.0329,
      "step": 11364
    },
    {
      "epoch": 2.6114430147058822,
      "grad_norm": 0.9045053124427795,
      "learning_rate": 5.31045751633987e-06,
      "loss": 0.0272,
      "step": 11365
    },
    {
      "epoch": 2.611672794117647,
      "grad_norm": 0.69500333070755,
      "learning_rate": 5.309946895424837e-06,
      "loss": 0.034,
      "step": 11366
    },
    {
      "epoch": 2.6119025735294117,
      "grad_norm": 0.7395122647285461,
      "learning_rate": 5.309436274509804e-06,
      "loss": 0.0386,
      "step": 11367
    },
    {
      "epoch": 2.6121323529411766,
      "grad_norm": 0.9966410398483276,
      "learning_rate": 5.308925653594772e-06,
      "loss": 0.0409,
      "step": 11368
    },
    {
      "epoch": 2.612362132352941,
      "grad_norm": 0.7228585481643677,
      "learning_rate": 5.308415032679739e-06,
      "loss": 0.0297,
      "step": 11369
    },
    {
      "epoch": 2.6125919117647056,
      "grad_norm": 1.0003695487976074,
      "learning_rate": 5.307904411764706e-06,
      "loss": 0.0569,
      "step": 11370
    },
    {
      "epoch": 2.6128216911764706,
      "grad_norm": 0.957828164100647,
      "learning_rate": 5.307393790849673e-06,
      "loss": 0.034,
      "step": 11371
    },
    {
      "epoch": 2.6130514705882355,
      "grad_norm": 0.6691799163818359,
      "learning_rate": 5.306883169934641e-06,
      "loss": 0.0286,
      "step": 11372
    },
    {
      "epoch": 2.61328125,
      "grad_norm": 1.0633838176727295,
      "learning_rate": 5.306372549019608e-06,
      "loss": 0.0433,
      "step": 11373
    },
    {
      "epoch": 2.6135110294117645,
      "grad_norm": 1.1026074886322021,
      "learning_rate": 5.305861928104575e-06,
      "loss": 0.0535,
      "step": 11374
    },
    {
      "epoch": 2.6137408088235294,
      "grad_norm": 1.051444411277771,
      "learning_rate": 5.305351307189542e-06,
      "loss": 0.0435,
      "step": 11375
    },
    {
      "epoch": 2.6139705882352944,
      "grad_norm": 1.005130648612976,
      "learning_rate": 5.304840686274511e-06,
      "loss": 0.0359,
      "step": 11376
    },
    {
      "epoch": 2.614200367647059,
      "grad_norm": 1.076884388923645,
      "learning_rate": 5.304330065359478e-06,
      "loss": 0.0299,
      "step": 11377
    },
    {
      "epoch": 2.6144301470588234,
      "grad_norm": 1.3553327322006226,
      "learning_rate": 5.303819444444445e-06,
      "loss": 0.0363,
      "step": 11378
    },
    {
      "epoch": 2.6146599264705883,
      "grad_norm": 0.9840125441551208,
      "learning_rate": 5.303308823529412e-06,
      "loss": 0.0391,
      "step": 11379
    },
    {
      "epoch": 2.614889705882353,
      "grad_norm": 0.8122169375419617,
      "learning_rate": 5.30279820261438e-06,
      "loss": 0.0363,
      "step": 11380
    },
    {
      "epoch": 2.6151194852941178,
      "grad_norm": 1.6155033111572266,
      "learning_rate": 5.302287581699347e-06,
      "loss": 0.0539,
      "step": 11381
    },
    {
      "epoch": 2.6153492647058822,
      "grad_norm": 0.745779275894165,
      "learning_rate": 5.301776960784314e-06,
      "loss": 0.0279,
      "step": 11382
    },
    {
      "epoch": 2.615579044117647,
      "grad_norm": 1.0710362195968628,
      "learning_rate": 5.301266339869281e-06,
      "loss": 0.0394,
      "step": 11383
    },
    {
      "epoch": 2.6158088235294117,
      "grad_norm": 0.8645262122154236,
      "learning_rate": 5.300755718954249e-06,
      "loss": 0.0333,
      "step": 11384
    },
    {
      "epoch": 2.6160386029411766,
      "grad_norm": 1.296936273574829,
      "learning_rate": 5.300245098039216e-06,
      "loss": 0.0444,
      "step": 11385
    },
    {
      "epoch": 2.616268382352941,
      "grad_norm": 1.2676104307174683,
      "learning_rate": 5.299734477124183e-06,
      "loss": 0.0455,
      "step": 11386
    },
    {
      "epoch": 2.6164981617647056,
      "grad_norm": 0.9492132663726807,
      "learning_rate": 5.29922385620915e-06,
      "loss": 0.0442,
      "step": 11387
    },
    {
      "epoch": 2.6167279411764706,
      "grad_norm": 0.6601452827453613,
      "learning_rate": 5.298713235294118e-06,
      "loss": 0.0368,
      "step": 11388
    },
    {
      "epoch": 2.6169577205882355,
      "grad_norm": 1.2298237085342407,
      "learning_rate": 5.298202614379085e-06,
      "loss": 0.0458,
      "step": 11389
    },
    {
      "epoch": 2.6171875,
      "grad_norm": 1.0302858352661133,
      "learning_rate": 5.297691993464052e-06,
      "loss": 0.0381,
      "step": 11390
    },
    {
      "epoch": 2.6174172794117645,
      "grad_norm": 1.056807518005371,
      "learning_rate": 5.297181372549019e-06,
      "loss": 0.0425,
      "step": 11391
    },
    {
      "epoch": 2.6176470588235294,
      "grad_norm": 0.9249927997589111,
      "learning_rate": 5.296670751633988e-06,
      "loss": 0.0394,
      "step": 11392
    },
    {
      "epoch": 2.6178768382352944,
      "grad_norm": 0.7883870005607605,
      "learning_rate": 5.296160130718955e-06,
      "loss": 0.031,
      "step": 11393
    },
    {
      "epoch": 2.618106617647059,
      "grad_norm": 0.8057833313941956,
      "learning_rate": 5.295649509803922e-06,
      "loss": 0.0364,
      "step": 11394
    },
    {
      "epoch": 2.6183363970588234,
      "grad_norm": 0.9321080446243286,
      "learning_rate": 5.295138888888889e-06,
      "loss": 0.039,
      "step": 11395
    },
    {
      "epoch": 2.6185661764705883,
      "grad_norm": 0.940869927406311,
      "learning_rate": 5.294628267973857e-06,
      "loss": 0.0371,
      "step": 11396
    },
    {
      "epoch": 2.618795955882353,
      "grad_norm": 0.3793383538722992,
      "learning_rate": 5.294117647058824e-06,
      "loss": 0.018,
      "step": 11397
    },
    {
      "epoch": 2.6190257352941178,
      "grad_norm": 1.0846495628356934,
      "learning_rate": 5.293607026143791e-06,
      "loss": 0.042,
      "step": 11398
    },
    {
      "epoch": 2.6192555147058822,
      "grad_norm": 1.057663083076477,
      "learning_rate": 5.293096405228758e-06,
      "loss": 0.0431,
      "step": 11399
    },
    {
      "epoch": 2.619485294117647,
      "grad_norm": 1.0582427978515625,
      "learning_rate": 5.292585784313727e-06,
      "loss": 0.0411,
      "step": 11400
    },
    {
      "epoch": 2.6197150735294117,
      "grad_norm": 1.0879087448120117,
      "learning_rate": 5.292075163398694e-06,
      "loss": 0.0423,
      "step": 11401
    },
    {
      "epoch": 2.6199448529411766,
      "grad_norm": 0.8270494937896729,
      "learning_rate": 5.291564542483661e-06,
      "loss": 0.0346,
      "step": 11402
    },
    {
      "epoch": 2.620174632352941,
      "grad_norm": 1.0396206378936768,
      "learning_rate": 5.291053921568628e-06,
      "loss": 0.0463,
      "step": 11403
    },
    {
      "epoch": 2.6204044117647056,
      "grad_norm": 0.8617804646492004,
      "learning_rate": 5.2905433006535956e-06,
      "loss": 0.0517,
      "step": 11404
    },
    {
      "epoch": 2.6206341911764706,
      "grad_norm": 0.9960055947303772,
      "learning_rate": 5.2900326797385626e-06,
      "loss": 0.0291,
      "step": 11405
    },
    {
      "epoch": 2.6208639705882355,
      "grad_norm": 2.00277042388916,
      "learning_rate": 5.28952205882353e-06,
      "loss": 0.081,
      "step": 11406
    },
    {
      "epoch": 2.62109375,
      "grad_norm": 1.6191827058792114,
      "learning_rate": 5.289011437908497e-06,
      "loss": 0.0483,
      "step": 11407
    },
    {
      "epoch": 2.6213235294117645,
      "grad_norm": 0.7580682635307312,
      "learning_rate": 5.2885008169934645e-06,
      "loss": 0.0338,
      "step": 11408
    },
    {
      "epoch": 2.6215533088235294,
      "grad_norm": 1.0940192937850952,
      "learning_rate": 5.2879901960784315e-06,
      "loss": 0.0423,
      "step": 11409
    },
    {
      "epoch": 2.6217830882352944,
      "grad_norm": 0.7646618485450745,
      "learning_rate": 5.287479575163399e-06,
      "loss": 0.0408,
      "step": 11410
    },
    {
      "epoch": 2.622012867647059,
      "grad_norm": 0.9839402437210083,
      "learning_rate": 5.286968954248366e-06,
      "loss": 0.0316,
      "step": 11411
    },
    {
      "epoch": 2.6222426470588234,
      "grad_norm": 1.0936686992645264,
      "learning_rate": 5.286458333333334e-06,
      "loss": 0.0376,
      "step": 11412
    },
    {
      "epoch": 2.6224724264705883,
      "grad_norm": 0.7624342441558838,
      "learning_rate": 5.285947712418301e-06,
      "loss": 0.0433,
      "step": 11413
    },
    {
      "epoch": 2.622702205882353,
      "grad_norm": 0.9142959117889404,
      "learning_rate": 5.285437091503268e-06,
      "loss": 0.0541,
      "step": 11414
    },
    {
      "epoch": 2.6229319852941178,
      "grad_norm": 1.2014895677566528,
      "learning_rate": 5.284926470588235e-06,
      "loss": 0.0563,
      "step": 11415
    },
    {
      "epoch": 2.6231617647058822,
      "grad_norm": 0.8300802707672119,
      "learning_rate": 5.284415849673203e-06,
      "loss": 0.0158,
      "step": 11416
    },
    {
      "epoch": 2.623391544117647,
      "grad_norm": 1.0380306243896484,
      "learning_rate": 5.28390522875817e-06,
      "loss": 0.0441,
      "step": 11417
    },
    {
      "epoch": 2.6236213235294117,
      "grad_norm": 0.6875277161598206,
      "learning_rate": 5.283394607843137e-06,
      "loss": 0.0351,
      "step": 11418
    },
    {
      "epoch": 2.6238511029411766,
      "grad_norm": 1.061086893081665,
      "learning_rate": 5.282883986928104e-06,
      "loss": 0.0396,
      "step": 11419
    },
    {
      "epoch": 2.624080882352941,
      "grad_norm": 1.020308017730713,
      "learning_rate": 5.282373366013073e-06,
      "loss": 0.0454,
      "step": 11420
    },
    {
      "epoch": 2.6243106617647056,
      "grad_norm": 1.0168581008911133,
      "learning_rate": 5.28186274509804e-06,
      "loss": 0.0424,
      "step": 11421
    },
    {
      "epoch": 2.6245404411764706,
      "grad_norm": 0.8104321956634521,
      "learning_rate": 5.281352124183007e-06,
      "loss": 0.0403,
      "step": 11422
    },
    {
      "epoch": 2.6247702205882355,
      "grad_norm": 1.0776588916778564,
      "learning_rate": 5.280841503267974e-06,
      "loss": 0.0509,
      "step": 11423
    },
    {
      "epoch": 2.625,
      "grad_norm": 1.1246578693389893,
      "learning_rate": 5.280330882352942e-06,
      "loss": 0.0459,
      "step": 11424
    },
    {
      "epoch": 2.6252297794117645,
      "grad_norm": 0.8927029967308044,
      "learning_rate": 5.279820261437909e-06,
      "loss": 0.0326,
      "step": 11425
    },
    {
      "epoch": 2.6254595588235294,
      "grad_norm": 0.8821360468864441,
      "learning_rate": 5.279309640522876e-06,
      "loss": 0.036,
      "step": 11426
    },
    {
      "epoch": 2.6256893382352944,
      "grad_norm": 0.7874131798744202,
      "learning_rate": 5.278799019607843e-06,
      "loss": 0.039,
      "step": 11427
    },
    {
      "epoch": 2.625919117647059,
      "grad_norm": 1.4025167226791382,
      "learning_rate": 5.2782883986928115e-06,
      "loss": 0.0568,
      "step": 11428
    },
    {
      "epoch": 2.6261488970588234,
      "grad_norm": 0.896428108215332,
      "learning_rate": 5.2777777777777785e-06,
      "loss": 0.0371,
      "step": 11429
    },
    {
      "epoch": 2.6263786764705883,
      "grad_norm": 1.2151142358779907,
      "learning_rate": 5.2772671568627456e-06,
      "loss": 0.053,
      "step": 11430
    },
    {
      "epoch": 2.626608455882353,
      "grad_norm": 0.9969037175178528,
      "learning_rate": 5.2767565359477126e-06,
      "loss": 0.0536,
      "step": 11431
    },
    {
      "epoch": 2.6268382352941178,
      "grad_norm": 0.6991046071052551,
      "learning_rate": 5.2762459150326804e-06,
      "loss": 0.0262,
      "step": 11432
    },
    {
      "epoch": 2.6270680147058822,
      "grad_norm": 0.7875238060951233,
      "learning_rate": 5.2757352941176474e-06,
      "loss": 0.0251,
      "step": 11433
    },
    {
      "epoch": 2.627297794117647,
      "grad_norm": 1.1787832975387573,
      "learning_rate": 5.2752246732026145e-06,
      "loss": 0.0583,
      "step": 11434
    },
    {
      "epoch": 2.6275275735294117,
      "grad_norm": 0.795807421207428,
      "learning_rate": 5.2747140522875815e-06,
      "loss": 0.0292,
      "step": 11435
    },
    {
      "epoch": 2.6277573529411766,
      "grad_norm": 0.7387406826019287,
      "learning_rate": 5.27420343137255e-06,
      "loss": 0.0405,
      "step": 11436
    },
    {
      "epoch": 2.627987132352941,
      "grad_norm": 0.7916783690452576,
      "learning_rate": 5.273692810457517e-06,
      "loss": 0.0331,
      "step": 11437
    },
    {
      "epoch": 2.6282169117647056,
      "grad_norm": 1.1728631258010864,
      "learning_rate": 5.273182189542484e-06,
      "loss": 0.0432,
      "step": 11438
    },
    {
      "epoch": 2.6284466911764706,
      "grad_norm": 1.0303854942321777,
      "learning_rate": 5.272671568627451e-06,
      "loss": 0.0492,
      "step": 11439
    },
    {
      "epoch": 2.6286764705882355,
      "grad_norm": 1.0612823963165283,
      "learning_rate": 5.272160947712419e-06,
      "loss": 0.0341,
      "step": 11440
    },
    {
      "epoch": 2.62890625,
      "grad_norm": 0.9648367166519165,
      "learning_rate": 5.271650326797386e-06,
      "loss": 0.043,
      "step": 11441
    },
    {
      "epoch": 2.6291360294117645,
      "grad_norm": 0.7768203020095825,
      "learning_rate": 5.271139705882353e-06,
      "loss": 0.0355,
      "step": 11442
    },
    {
      "epoch": 2.6293658088235294,
      "grad_norm": 0.7730154395103455,
      "learning_rate": 5.27062908496732e-06,
      "loss": 0.0471,
      "step": 11443
    },
    {
      "epoch": 2.6295955882352944,
      "grad_norm": 0.9498175382614136,
      "learning_rate": 5.270118464052289e-06,
      "loss": 0.044,
      "step": 11444
    },
    {
      "epoch": 2.629825367647059,
      "grad_norm": 1.0409021377563477,
      "learning_rate": 5.269607843137256e-06,
      "loss": 0.0641,
      "step": 11445
    },
    {
      "epoch": 2.6300551470588234,
      "grad_norm": 1.0857982635498047,
      "learning_rate": 5.269097222222223e-06,
      "loss": 0.0444,
      "step": 11446
    },
    {
      "epoch": 2.6302849264705883,
      "grad_norm": 0.9622502326965332,
      "learning_rate": 5.26858660130719e-06,
      "loss": 0.0283,
      "step": 11447
    },
    {
      "epoch": 2.630514705882353,
      "grad_norm": 0.8438543081283569,
      "learning_rate": 5.268075980392158e-06,
      "loss": 0.0312,
      "step": 11448
    },
    {
      "epoch": 2.6307444852941178,
      "grad_norm": 1.2186981439590454,
      "learning_rate": 5.267565359477125e-06,
      "loss": 0.0429,
      "step": 11449
    },
    {
      "epoch": 2.6309742647058822,
      "grad_norm": 0.834516167640686,
      "learning_rate": 5.267054738562092e-06,
      "loss": 0.0481,
      "step": 11450
    },
    {
      "epoch": 2.631204044117647,
      "grad_norm": 0.7725241184234619,
      "learning_rate": 5.266544117647059e-06,
      "loss": 0.0317,
      "step": 11451
    },
    {
      "epoch": 2.6314338235294117,
      "grad_norm": 0.8173111081123352,
      "learning_rate": 5.266033496732027e-06,
      "loss": 0.0406,
      "step": 11452
    },
    {
      "epoch": 2.6316636029411766,
      "grad_norm": 0.957709550857544,
      "learning_rate": 5.265522875816994e-06,
      "loss": 0.034,
      "step": 11453
    },
    {
      "epoch": 2.631893382352941,
      "grad_norm": 0.918729841709137,
      "learning_rate": 5.2650122549019615e-06,
      "loss": 0.0323,
      "step": 11454
    },
    {
      "epoch": 2.6321231617647056,
      "grad_norm": 0.9669908881187439,
      "learning_rate": 5.2645016339869285e-06,
      "loss": 0.0376,
      "step": 11455
    },
    {
      "epoch": 2.6323529411764706,
      "grad_norm": 0.9992691874504089,
      "learning_rate": 5.263991013071896e-06,
      "loss": 0.0388,
      "step": 11456
    },
    {
      "epoch": 2.6325827205882355,
      "grad_norm": 1.0392906665802002,
      "learning_rate": 5.263480392156863e-06,
      "loss": 0.0516,
      "step": 11457
    },
    {
      "epoch": 2.6328125,
      "grad_norm": 1.1813912391662598,
      "learning_rate": 5.2629697712418304e-06,
      "loss": 0.0641,
      "step": 11458
    },
    {
      "epoch": 2.6330422794117645,
      "grad_norm": 1.1072098016738892,
      "learning_rate": 5.2624591503267974e-06,
      "loss": 0.0384,
      "step": 11459
    },
    {
      "epoch": 2.6332720588235294,
      "grad_norm": 1.1087584495544434,
      "learning_rate": 5.261948529411765e-06,
      "loss": 0.052,
      "step": 11460
    },
    {
      "epoch": 2.6335018382352944,
      "grad_norm": 1.0597727298736572,
      "learning_rate": 5.261437908496732e-06,
      "loss": 0.0419,
      "step": 11461
    },
    {
      "epoch": 2.633731617647059,
      "grad_norm": 1.0794034004211426,
      "learning_rate": 5.260927287581699e-06,
      "loss": 0.0618,
      "step": 11462
    },
    {
      "epoch": 2.6339613970588234,
      "grad_norm": 0.9385581016540527,
      "learning_rate": 5.260416666666666e-06,
      "loss": 0.0605,
      "step": 11463
    },
    {
      "epoch": 2.6341911764705883,
      "grad_norm": 0.9541733860969543,
      "learning_rate": 5.259906045751635e-06,
      "loss": 0.0373,
      "step": 11464
    },
    {
      "epoch": 2.634420955882353,
      "grad_norm": 0.6182933449745178,
      "learning_rate": 5.259395424836602e-06,
      "loss": 0.024,
      "step": 11465
    },
    {
      "epoch": 2.6346507352941178,
      "grad_norm": 0.8615066409111023,
      "learning_rate": 5.258884803921569e-06,
      "loss": 0.0216,
      "step": 11466
    },
    {
      "epoch": 2.6348805147058822,
      "grad_norm": 1.0209681987762451,
      "learning_rate": 5.258374183006536e-06,
      "loss": 0.0452,
      "step": 11467
    },
    {
      "epoch": 2.635110294117647,
      "grad_norm": 1.052125334739685,
      "learning_rate": 5.257863562091504e-06,
      "loss": 0.0457,
      "step": 11468
    },
    {
      "epoch": 2.6353400735294117,
      "grad_norm": 0.7786173224449158,
      "learning_rate": 5.257352941176471e-06,
      "loss": 0.0381,
      "step": 11469
    },
    {
      "epoch": 2.6355698529411766,
      "grad_norm": 0.6910704374313354,
      "learning_rate": 5.256842320261438e-06,
      "loss": 0.0166,
      "step": 11470
    },
    {
      "epoch": 2.635799632352941,
      "grad_norm": 0.9644941091537476,
      "learning_rate": 5.256331699346405e-06,
      "loss": 0.0478,
      "step": 11471
    },
    {
      "epoch": 2.6360294117647056,
      "grad_norm": 0.9348270297050476,
      "learning_rate": 5.255821078431374e-06,
      "loss": 0.0383,
      "step": 11472
    },
    {
      "epoch": 2.6362591911764706,
      "grad_norm": 1.2564234733581543,
      "learning_rate": 5.255310457516341e-06,
      "loss": 0.0616,
      "step": 11473
    },
    {
      "epoch": 2.6364889705882355,
      "grad_norm": 0.9192264080047607,
      "learning_rate": 5.254799836601308e-06,
      "loss": 0.034,
      "step": 11474
    },
    {
      "epoch": 2.63671875,
      "grad_norm": 1.0219361782073975,
      "learning_rate": 5.254289215686275e-06,
      "loss": 0.0514,
      "step": 11475
    },
    {
      "epoch": 2.6369485294117645,
      "grad_norm": 0.879281222820282,
      "learning_rate": 5.253778594771243e-06,
      "loss": 0.0454,
      "step": 11476
    },
    {
      "epoch": 2.6371783088235294,
      "grad_norm": 0.8752832412719727,
      "learning_rate": 5.25326797385621e-06,
      "loss": 0.0341,
      "step": 11477
    },
    {
      "epoch": 2.6374080882352944,
      "grad_norm": 0.9694072604179382,
      "learning_rate": 5.252757352941177e-06,
      "loss": 0.0325,
      "step": 11478
    },
    {
      "epoch": 2.637637867647059,
      "grad_norm": 0.8613982200622559,
      "learning_rate": 5.252246732026144e-06,
      "loss": 0.0369,
      "step": 11479
    },
    {
      "epoch": 2.6378676470588234,
      "grad_norm": 1.278369426727295,
      "learning_rate": 5.251736111111112e-06,
      "loss": 0.033,
      "step": 11480
    },
    {
      "epoch": 2.6380974264705883,
      "grad_norm": 0.9856894612312317,
      "learning_rate": 5.251225490196079e-06,
      "loss": 0.0457,
      "step": 11481
    },
    {
      "epoch": 2.638327205882353,
      "grad_norm": 0.8758994936943054,
      "learning_rate": 5.250714869281046e-06,
      "loss": 0.0504,
      "step": 11482
    },
    {
      "epoch": 2.6385569852941178,
      "grad_norm": 0.6039000153541565,
      "learning_rate": 5.250204248366013e-06,
      "loss": 0.0195,
      "step": 11483
    },
    {
      "epoch": 2.6387867647058822,
      "grad_norm": 1.0764319896697998,
      "learning_rate": 5.249693627450981e-06,
      "loss": 0.048,
      "step": 11484
    },
    {
      "epoch": 2.639016544117647,
      "grad_norm": 0.8476155996322632,
      "learning_rate": 5.249183006535948e-06,
      "loss": 0.0281,
      "step": 11485
    },
    {
      "epoch": 2.6392463235294117,
      "grad_norm": 1.2028089761734009,
      "learning_rate": 5.248672385620915e-06,
      "loss": 0.0702,
      "step": 11486
    },
    {
      "epoch": 2.6394761029411766,
      "grad_norm": 1.1173012256622314,
      "learning_rate": 5.248161764705882e-06,
      "loss": 0.0441,
      "step": 11487
    },
    {
      "epoch": 2.639705882352941,
      "grad_norm": 0.8431586623191833,
      "learning_rate": 5.247651143790851e-06,
      "loss": 0.0378,
      "step": 11488
    },
    {
      "epoch": 2.6399356617647056,
      "grad_norm": 1.266892910003662,
      "learning_rate": 5.247140522875818e-06,
      "loss": 0.0343,
      "step": 11489
    },
    {
      "epoch": 2.6401654411764706,
      "grad_norm": 0.8566045761108398,
      "learning_rate": 5.246629901960785e-06,
      "loss": 0.0298,
      "step": 11490
    },
    {
      "epoch": 2.6403952205882355,
      "grad_norm": 1.1870429515838623,
      "learning_rate": 5.246119281045752e-06,
      "loss": 0.0364,
      "step": 11491
    },
    {
      "epoch": 2.640625,
      "grad_norm": 0.7509654760360718,
      "learning_rate": 5.24560866013072e-06,
      "loss": 0.0305,
      "step": 11492
    },
    {
      "epoch": 2.6408547794117645,
      "grad_norm": 0.9154485464096069,
      "learning_rate": 5.245098039215687e-06,
      "loss": 0.0405,
      "step": 11493
    },
    {
      "epoch": 2.6410845588235294,
      "grad_norm": 0.8527808785438538,
      "learning_rate": 5.244587418300654e-06,
      "loss": 0.0397,
      "step": 11494
    },
    {
      "epoch": 2.6413143382352944,
      "grad_norm": 1.1434468030929565,
      "learning_rate": 5.244076797385621e-06,
      "loss": 0.0451,
      "step": 11495
    },
    {
      "epoch": 2.641544117647059,
      "grad_norm": 0.8213304877281189,
      "learning_rate": 5.243566176470589e-06,
      "loss": 0.0288,
      "step": 11496
    },
    {
      "epoch": 2.6417738970588234,
      "grad_norm": 0.8168151378631592,
      "learning_rate": 5.243055555555556e-06,
      "loss": 0.0509,
      "step": 11497
    },
    {
      "epoch": 2.6420036764705883,
      "grad_norm": 1.3488820791244507,
      "learning_rate": 5.242544934640523e-06,
      "loss": 0.0433,
      "step": 11498
    },
    {
      "epoch": 2.642233455882353,
      "grad_norm": 0.902204692363739,
      "learning_rate": 5.242034313725491e-06,
      "loss": 0.0381,
      "step": 11499
    },
    {
      "epoch": 2.6424632352941178,
      "grad_norm": 0.9405896067619324,
      "learning_rate": 5.241523692810459e-06,
      "loss": 0.0345,
      "step": 11500
    },
    {
      "epoch": 2.6424632352941178,
      "eval_loss": 0.045432187616825104,
      "eval_runtime": 2006.6084,
      "eval_samples_per_second": 4.438,
      "eval_steps_per_second": 2.219,
      "step": 11500
    },
    {
      "epoch": 2.6426930147058822,
      "grad_norm": 1.0151978731155396,
      "learning_rate": 5.241013071895426e-06,
      "loss": 0.04,
      "step": 11501
    },
    {
      "epoch": 2.642922794117647,
      "grad_norm": 1.1512871980667114,
      "learning_rate": 5.240502450980393e-06,
      "loss": 0.0525,
      "step": 11502
    },
    {
      "epoch": 2.6431525735294117,
      "grad_norm": 0.7531522512435913,
      "learning_rate": 5.23999183006536e-06,
      "loss": 0.0324,
      "step": 11503
    },
    {
      "epoch": 2.6433823529411766,
      "grad_norm": 1.0317195653915405,
      "learning_rate": 5.2394812091503275e-06,
      "loss": 0.0337,
      "step": 11504
    },
    {
      "epoch": 2.643612132352941,
      "grad_norm": 0.9516991376876831,
      "learning_rate": 5.2389705882352945e-06,
      "loss": 0.0402,
      "step": 11505
    },
    {
      "epoch": 2.6438419117647056,
      "grad_norm": 0.7286263108253479,
      "learning_rate": 5.2384599673202615e-06,
      "loss": 0.0264,
      "step": 11506
    },
    {
      "epoch": 2.6440716911764706,
      "grad_norm": 0.917658805847168,
      "learning_rate": 5.2379493464052285e-06,
      "loss": 0.0358,
      "step": 11507
    },
    {
      "epoch": 2.6443014705882355,
      "grad_norm": 1.1132417917251587,
      "learning_rate": 5.237438725490197e-06,
      "loss": 0.0662,
      "step": 11508
    },
    {
      "epoch": 2.64453125,
      "grad_norm": 0.8989042043685913,
      "learning_rate": 5.236928104575164e-06,
      "loss": 0.041,
      "step": 11509
    },
    {
      "epoch": 2.6447610294117645,
      "grad_norm": 1.0504168272018433,
      "learning_rate": 5.236417483660131e-06,
      "loss": 0.0512,
      "step": 11510
    },
    {
      "epoch": 2.6449908088235294,
      "grad_norm": 0.6468763947486877,
      "learning_rate": 5.235906862745098e-06,
      "loss": 0.024,
      "step": 11511
    },
    {
      "epoch": 2.6452205882352944,
      "grad_norm": 0.7926779985427856,
      "learning_rate": 5.235396241830066e-06,
      "loss": 0.0276,
      "step": 11512
    },
    {
      "epoch": 2.645450367647059,
      "grad_norm": 1.164467215538025,
      "learning_rate": 5.234885620915033e-06,
      "loss": 0.0539,
      "step": 11513
    },
    {
      "epoch": 2.6456801470588234,
      "grad_norm": 0.9588444828987122,
      "learning_rate": 5.234375e-06,
      "loss": 0.0441,
      "step": 11514
    },
    {
      "epoch": 2.6459099264705883,
      "grad_norm": 1.0555602312088013,
      "learning_rate": 5.233864379084967e-06,
      "loss": 0.0572,
      "step": 11515
    },
    {
      "epoch": 2.646139705882353,
      "grad_norm": 0.6403929591178894,
      "learning_rate": 5.233353758169934e-06,
      "loss": 0.0264,
      "step": 11516
    },
    {
      "epoch": 2.6463694852941178,
      "grad_norm": 0.8317235112190247,
      "learning_rate": 5.232843137254903e-06,
      "loss": 0.0339,
      "step": 11517
    },
    {
      "epoch": 2.6465992647058822,
      "grad_norm": 0.6858493089675903,
      "learning_rate": 5.23233251633987e-06,
      "loss": 0.0223,
      "step": 11518
    },
    {
      "epoch": 2.646829044117647,
      "grad_norm": 1.299906611442566,
      "learning_rate": 5.231821895424837e-06,
      "loss": 0.0628,
      "step": 11519
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 0.9597514271736145,
      "learning_rate": 5.231311274509804e-06,
      "loss": 0.0333,
      "step": 11520
    },
    {
      "epoch": 2.6472886029411766,
      "grad_norm": 0.7432186603546143,
      "learning_rate": 5.230800653594772e-06,
      "loss": 0.0247,
      "step": 11521
    },
    {
      "epoch": 2.647518382352941,
      "grad_norm": 0.9360369443893433,
      "learning_rate": 5.230290032679739e-06,
      "loss": 0.0412,
      "step": 11522
    },
    {
      "epoch": 2.6477481617647056,
      "grad_norm": 1.061902642250061,
      "learning_rate": 5.229779411764706e-06,
      "loss": 0.0633,
      "step": 11523
    },
    {
      "epoch": 2.6479779411764706,
      "grad_norm": 0.9030222296714783,
      "learning_rate": 5.229268790849673e-06,
      "loss": 0.0346,
      "step": 11524
    },
    {
      "epoch": 2.6482077205882355,
      "grad_norm": 0.8819289207458496,
      "learning_rate": 5.2287581699346416e-06,
      "loss": 0.0394,
      "step": 11525
    },
    {
      "epoch": 2.6484375,
      "grad_norm": 0.7695081233978271,
      "learning_rate": 5.228247549019609e-06,
      "loss": 0.0299,
      "step": 11526
    },
    {
      "epoch": 2.6486672794117645,
      "grad_norm": 1.1671477556228638,
      "learning_rate": 5.227736928104576e-06,
      "loss": 0.05,
      "step": 11527
    },
    {
      "epoch": 2.6488970588235294,
      "grad_norm": 1.1210508346557617,
      "learning_rate": 5.227226307189543e-06,
      "loss": 0.0332,
      "step": 11528
    },
    {
      "epoch": 2.6491268382352944,
      "grad_norm": 1.0085563659667969,
      "learning_rate": 5.2267156862745105e-06,
      "loss": 0.0575,
      "step": 11529
    },
    {
      "epoch": 2.649356617647059,
      "grad_norm": 0.8882879614830017,
      "learning_rate": 5.2262050653594775e-06,
      "loss": 0.0341,
      "step": 11530
    },
    {
      "epoch": 2.6495863970588234,
      "grad_norm": 1.0447039604187012,
      "learning_rate": 5.2256944444444445e-06,
      "loss": 0.0352,
      "step": 11531
    },
    {
      "epoch": 2.6498161764705883,
      "grad_norm": 0.794279158115387,
      "learning_rate": 5.2251838235294115e-06,
      "loss": 0.0341,
      "step": 11532
    },
    {
      "epoch": 2.650045955882353,
      "grad_norm": 0.9633870720863342,
      "learning_rate": 5.22467320261438e-06,
      "loss": 0.0356,
      "step": 11533
    },
    {
      "epoch": 2.6502757352941178,
      "grad_norm": 0.7209293246269226,
      "learning_rate": 5.224162581699347e-06,
      "loss": 0.0278,
      "step": 11534
    },
    {
      "epoch": 2.6505055147058822,
      "grad_norm": 0.9712469577789307,
      "learning_rate": 5.223651960784314e-06,
      "loss": 0.0382,
      "step": 11535
    },
    {
      "epoch": 2.650735294117647,
      "grad_norm": 1.1939470767974854,
      "learning_rate": 5.223141339869281e-06,
      "loss": 0.0332,
      "step": 11536
    },
    {
      "epoch": 2.6509650735294117,
      "grad_norm": 1.0338350534439087,
      "learning_rate": 5.222630718954249e-06,
      "loss": 0.0325,
      "step": 11537
    },
    {
      "epoch": 2.6511948529411766,
      "grad_norm": 0.8653356432914734,
      "learning_rate": 5.222120098039216e-06,
      "loss": 0.0316,
      "step": 11538
    },
    {
      "epoch": 2.651424632352941,
      "grad_norm": 1.3728607892990112,
      "learning_rate": 5.221609477124183e-06,
      "loss": 0.0426,
      "step": 11539
    },
    {
      "epoch": 2.6516544117647056,
      "grad_norm": 0.5832224488258362,
      "learning_rate": 5.22109885620915e-06,
      "loss": 0.0235,
      "step": 11540
    },
    {
      "epoch": 2.6518841911764706,
      "grad_norm": 0.9386282563209534,
      "learning_rate": 5.220588235294118e-06,
      "loss": 0.0647,
      "step": 11541
    },
    {
      "epoch": 2.6521139705882355,
      "grad_norm": 1.292028546333313,
      "learning_rate": 5.220077614379085e-06,
      "loss": 0.0393,
      "step": 11542
    },
    {
      "epoch": 2.65234375,
      "grad_norm": 1.1272528171539307,
      "learning_rate": 5.219566993464053e-06,
      "loss": 0.0369,
      "step": 11543
    },
    {
      "epoch": 2.6525735294117645,
      "grad_norm": 1.084035038948059,
      "learning_rate": 5.21905637254902e-06,
      "loss": 0.0259,
      "step": 11544
    },
    {
      "epoch": 2.6528033088235294,
      "grad_norm": 1.0270404815673828,
      "learning_rate": 5.218545751633988e-06,
      "loss": 0.0318,
      "step": 11545
    },
    {
      "epoch": 2.6530330882352944,
      "grad_norm": 0.9085606932640076,
      "learning_rate": 5.218035130718955e-06,
      "loss": 0.0433,
      "step": 11546
    },
    {
      "epoch": 2.653262867647059,
      "grad_norm": 0.7296510338783264,
      "learning_rate": 5.217524509803922e-06,
      "loss": 0.0301,
      "step": 11547
    },
    {
      "epoch": 2.6534926470588234,
      "grad_norm": 0.9342669248580933,
      "learning_rate": 5.217013888888889e-06,
      "loss": 0.0538,
      "step": 11548
    },
    {
      "epoch": 2.6537224264705883,
      "grad_norm": 0.9593427777290344,
      "learning_rate": 5.216503267973857e-06,
      "loss": 0.0529,
      "step": 11549
    },
    {
      "epoch": 2.653952205882353,
      "grad_norm": 1.1765389442443848,
      "learning_rate": 5.215992647058824e-06,
      "loss": 0.0515,
      "step": 11550
    },
    {
      "epoch": 2.6541819852941178,
      "grad_norm": 1.0033608675003052,
      "learning_rate": 5.215482026143791e-06,
      "loss": 0.0453,
      "step": 11551
    },
    {
      "epoch": 2.6544117647058822,
      "grad_norm": 0.8483483791351318,
      "learning_rate": 5.214971405228758e-06,
      "loss": 0.0352,
      "step": 11552
    },
    {
      "epoch": 2.654641544117647,
      "grad_norm": 1.401289939880371,
      "learning_rate": 5.2144607843137264e-06,
      "loss": 0.0602,
      "step": 11553
    },
    {
      "epoch": 2.6548713235294117,
      "grad_norm": 1.2592934370040894,
      "learning_rate": 5.2139501633986935e-06,
      "loss": 0.0653,
      "step": 11554
    },
    {
      "epoch": 2.6551011029411766,
      "grad_norm": 0.8044084906578064,
      "learning_rate": 5.2134395424836605e-06,
      "loss": 0.0448,
      "step": 11555
    },
    {
      "epoch": 2.655330882352941,
      "grad_norm": 0.6675599217414856,
      "learning_rate": 5.2129289215686275e-06,
      "loss": 0.026,
      "step": 11556
    },
    {
      "epoch": 2.6555606617647056,
      "grad_norm": 0.6104105710983276,
      "learning_rate": 5.212418300653595e-06,
      "loss": 0.0252,
      "step": 11557
    },
    {
      "epoch": 2.6557904411764706,
      "grad_norm": 0.9167927503585815,
      "learning_rate": 5.211907679738562e-06,
      "loss": 0.0341,
      "step": 11558
    },
    {
      "epoch": 2.6560202205882355,
      "grad_norm": 0.7479572892189026,
      "learning_rate": 5.211397058823529e-06,
      "loss": 0.0289,
      "step": 11559
    },
    {
      "epoch": 2.65625,
      "grad_norm": 0.7058486938476562,
      "learning_rate": 5.210886437908496e-06,
      "loss": 0.0195,
      "step": 11560
    },
    {
      "epoch": 2.6564797794117645,
      "grad_norm": 0.844429075717926,
      "learning_rate": 5.210375816993465e-06,
      "loss": 0.0381,
      "step": 11561
    },
    {
      "epoch": 2.6567095588235294,
      "grad_norm": 0.8527987003326416,
      "learning_rate": 5.209865196078432e-06,
      "loss": 0.0393,
      "step": 11562
    },
    {
      "epoch": 2.6569393382352944,
      "grad_norm": 0.809378445148468,
      "learning_rate": 5.209354575163399e-06,
      "loss": 0.0474,
      "step": 11563
    },
    {
      "epoch": 2.657169117647059,
      "grad_norm": 0.9797695875167847,
      "learning_rate": 5.208843954248366e-06,
      "loss": 0.0365,
      "step": 11564
    },
    {
      "epoch": 2.6573988970588234,
      "grad_norm": 1.0335991382598877,
      "learning_rate": 5.208333333333334e-06,
      "loss": 0.0411,
      "step": 11565
    },
    {
      "epoch": 2.6576286764705883,
      "grad_norm": 0.9445726275444031,
      "learning_rate": 5.207822712418301e-06,
      "loss": 0.0418,
      "step": 11566
    },
    {
      "epoch": 2.657858455882353,
      "grad_norm": 1.0460318326950073,
      "learning_rate": 5.207312091503268e-06,
      "loss": 0.0409,
      "step": 11567
    },
    {
      "epoch": 2.6580882352941178,
      "grad_norm": 1.013973593711853,
      "learning_rate": 5.206801470588235e-06,
      "loss": 0.0458,
      "step": 11568
    },
    {
      "epoch": 2.6583180147058822,
      "grad_norm": 0.9902070164680481,
      "learning_rate": 5.206290849673204e-06,
      "loss": 0.0521,
      "step": 11569
    },
    {
      "epoch": 2.658547794117647,
      "grad_norm": 0.6151867508888245,
      "learning_rate": 5.205780228758171e-06,
      "loss": 0.0295,
      "step": 11570
    },
    {
      "epoch": 2.6587775735294117,
      "grad_norm": 0.9969947338104248,
      "learning_rate": 5.205269607843138e-06,
      "loss": 0.0395,
      "step": 11571
    },
    {
      "epoch": 2.6590073529411766,
      "grad_norm": 1.09215247631073,
      "learning_rate": 5.204758986928105e-06,
      "loss": 0.0457,
      "step": 11572
    },
    {
      "epoch": 2.659237132352941,
      "grad_norm": 0.8748459219932556,
      "learning_rate": 5.204248366013073e-06,
      "loss": 0.0342,
      "step": 11573
    },
    {
      "epoch": 2.6594669117647056,
      "grad_norm": 0.79112309217453,
      "learning_rate": 5.20373774509804e-06,
      "loss": 0.0372,
      "step": 11574
    },
    {
      "epoch": 2.6596966911764706,
      "grad_norm": 0.7766973972320557,
      "learning_rate": 5.203227124183007e-06,
      "loss": 0.0266,
      "step": 11575
    },
    {
      "epoch": 2.6599264705882355,
      "grad_norm": 0.8572011590003967,
      "learning_rate": 5.202716503267974e-06,
      "loss": 0.0427,
      "step": 11576
    },
    {
      "epoch": 2.66015625,
      "grad_norm": 0.8501192331314087,
      "learning_rate": 5.202205882352942e-06,
      "loss": 0.0395,
      "step": 11577
    },
    {
      "epoch": 2.6603860294117645,
      "grad_norm": 0.7392154932022095,
      "learning_rate": 5.2016952614379094e-06,
      "loss": 0.0421,
      "step": 11578
    },
    {
      "epoch": 2.6606158088235294,
      "grad_norm": 0.8037962317466736,
      "learning_rate": 5.2011846405228764e-06,
      "loss": 0.0282,
      "step": 11579
    },
    {
      "epoch": 2.6608455882352944,
      "grad_norm": 0.9984318017959595,
      "learning_rate": 5.2006740196078435e-06,
      "loss": 0.0487,
      "step": 11580
    },
    {
      "epoch": 2.661075367647059,
      "grad_norm": 0.830845296382904,
      "learning_rate": 5.200163398692811e-06,
      "loss": 0.0509,
      "step": 11581
    },
    {
      "epoch": 2.6613051470588234,
      "grad_norm": 0.9314013123512268,
      "learning_rate": 5.199652777777778e-06,
      "loss": 0.0489,
      "step": 11582
    },
    {
      "epoch": 2.6615349264705883,
      "grad_norm": 1.0094815492630005,
      "learning_rate": 5.199142156862745e-06,
      "loss": 0.0499,
      "step": 11583
    },
    {
      "epoch": 2.661764705882353,
      "grad_norm": 0.8071154952049255,
      "learning_rate": 5.198631535947712e-06,
      "loss": 0.0315,
      "step": 11584
    },
    {
      "epoch": 2.6619944852941178,
      "grad_norm": 1.0765657424926758,
      "learning_rate": 5.19812091503268e-06,
      "loss": 0.0391,
      "step": 11585
    },
    {
      "epoch": 2.6622242647058822,
      "grad_norm": 0.9794212579727173,
      "learning_rate": 5.197610294117647e-06,
      "loss": 0.0268,
      "step": 11586
    },
    {
      "epoch": 2.662454044117647,
      "grad_norm": 1.2383543252944946,
      "learning_rate": 5.197099673202614e-06,
      "loss": 0.0536,
      "step": 11587
    },
    {
      "epoch": 2.6626838235294117,
      "grad_norm": 0.778890073299408,
      "learning_rate": 5.196589052287582e-06,
      "loss": 0.0316,
      "step": 11588
    },
    {
      "epoch": 2.6629136029411766,
      "grad_norm": 1.025649905204773,
      "learning_rate": 5.19607843137255e-06,
      "loss": 0.0385,
      "step": 11589
    },
    {
      "epoch": 2.663143382352941,
      "grad_norm": 0.7021035552024841,
      "learning_rate": 5.195567810457517e-06,
      "loss": 0.0235,
      "step": 11590
    },
    {
      "epoch": 2.6633731617647056,
      "grad_norm": 1.070070743560791,
      "learning_rate": 5.195057189542484e-06,
      "loss": 0.0496,
      "step": 11591
    },
    {
      "epoch": 2.6636029411764706,
      "grad_norm": 1.290846347808838,
      "learning_rate": 5.194546568627451e-06,
      "loss": 0.0646,
      "step": 11592
    },
    {
      "epoch": 2.6638327205882355,
      "grad_norm": 0.8330895304679871,
      "learning_rate": 5.194035947712419e-06,
      "loss": 0.0436,
      "step": 11593
    },
    {
      "epoch": 2.6640625,
      "grad_norm": 0.844126284122467,
      "learning_rate": 5.193525326797386e-06,
      "loss": 0.0303,
      "step": 11594
    },
    {
      "epoch": 2.6642922794117645,
      "grad_norm": 0.8286404013633728,
      "learning_rate": 5.193014705882353e-06,
      "loss": 0.0295,
      "step": 11595
    },
    {
      "epoch": 2.6645220588235294,
      "grad_norm": 0.8263596296310425,
      "learning_rate": 5.19250408496732e-06,
      "loss": 0.0327,
      "step": 11596
    },
    {
      "epoch": 2.6647518382352944,
      "grad_norm": 0.7890433073043823,
      "learning_rate": 5.191993464052289e-06,
      "loss": 0.0414,
      "step": 11597
    },
    {
      "epoch": 2.664981617647059,
      "grad_norm": 0.5697675347328186,
      "learning_rate": 5.191482843137256e-06,
      "loss": 0.0123,
      "step": 11598
    },
    {
      "epoch": 2.6652113970588234,
      "grad_norm": 0.8867645263671875,
      "learning_rate": 5.190972222222223e-06,
      "loss": 0.0322,
      "step": 11599
    },
    {
      "epoch": 2.6654411764705883,
      "grad_norm": 0.8228205442428589,
      "learning_rate": 5.19046160130719e-06,
      "loss": 0.0514,
      "step": 11600
    },
    {
      "epoch": 2.665670955882353,
      "grad_norm": 0.9010721445083618,
      "learning_rate": 5.1899509803921575e-06,
      "loss": 0.0381,
      "step": 11601
    },
    {
      "epoch": 2.6659007352941178,
      "grad_norm": 0.8680221438407898,
      "learning_rate": 5.1894403594771246e-06,
      "loss": 0.0296,
      "step": 11602
    },
    {
      "epoch": 2.6661305147058822,
      "grad_norm": 1.0707241296768188,
      "learning_rate": 5.1889297385620916e-06,
      "loss": 0.0456,
      "step": 11603
    },
    {
      "epoch": 2.666360294117647,
      "grad_norm": 1.1218266487121582,
      "learning_rate": 5.188419117647059e-06,
      "loss": 0.049,
      "step": 11604
    },
    {
      "epoch": 2.6665900735294117,
      "grad_norm": 1.2333917617797852,
      "learning_rate": 5.187908496732027e-06,
      "loss": 0.0388,
      "step": 11605
    },
    {
      "epoch": 2.6668198529411766,
      "grad_norm": 0.9988042712211609,
      "learning_rate": 5.187397875816994e-06,
      "loss": 0.0541,
      "step": 11606
    },
    {
      "epoch": 2.667049632352941,
      "grad_norm": 1.093723177909851,
      "learning_rate": 5.186887254901961e-06,
      "loss": 0.038,
      "step": 11607
    },
    {
      "epoch": 2.6672794117647056,
      "grad_norm": 1.0858553647994995,
      "learning_rate": 5.186376633986928e-06,
      "loss": 0.0327,
      "step": 11608
    },
    {
      "epoch": 2.6675091911764706,
      "grad_norm": 0.8502625226974487,
      "learning_rate": 5.185866013071896e-06,
      "loss": 0.0294,
      "step": 11609
    },
    {
      "epoch": 2.6677389705882355,
      "grad_norm": 0.8573801517486572,
      "learning_rate": 5.185355392156863e-06,
      "loss": 0.03,
      "step": 11610
    },
    {
      "epoch": 2.66796875,
      "grad_norm": 1.5361006259918213,
      "learning_rate": 5.18484477124183e-06,
      "loss": 0.0737,
      "step": 11611
    },
    {
      "epoch": 2.6681985294117645,
      "grad_norm": 1.1114859580993652,
      "learning_rate": 5.184334150326797e-06,
      "loss": 0.0554,
      "step": 11612
    },
    {
      "epoch": 2.6684283088235294,
      "grad_norm": 0.795656144618988,
      "learning_rate": 5.183823529411766e-06,
      "loss": 0.032,
      "step": 11613
    },
    {
      "epoch": 2.6686580882352944,
      "grad_norm": 1.0143780708312988,
      "learning_rate": 5.183312908496733e-06,
      "loss": 0.038,
      "step": 11614
    },
    {
      "epoch": 2.668887867647059,
      "grad_norm": 1.225112795829773,
      "learning_rate": 5.1828022875817e-06,
      "loss": 0.0338,
      "step": 11615
    },
    {
      "epoch": 2.6691176470588234,
      "grad_norm": 0.7623660564422607,
      "learning_rate": 5.182291666666667e-06,
      "loss": 0.0401,
      "step": 11616
    },
    {
      "epoch": 2.6693474264705883,
      "grad_norm": 1.0179098844528198,
      "learning_rate": 5.181781045751635e-06,
      "loss": 0.0502,
      "step": 11617
    },
    {
      "epoch": 2.669577205882353,
      "grad_norm": 1.0980515480041504,
      "learning_rate": 5.181270424836602e-06,
      "loss": 0.0515,
      "step": 11618
    },
    {
      "epoch": 2.6698069852941178,
      "grad_norm": 0.8327233195304871,
      "learning_rate": 5.180759803921569e-06,
      "loss": 0.0376,
      "step": 11619
    },
    {
      "epoch": 2.6700367647058822,
      "grad_norm": 0.7568315863609314,
      "learning_rate": 5.180249183006536e-06,
      "loss": 0.0276,
      "step": 11620
    },
    {
      "epoch": 2.670266544117647,
      "grad_norm": 0.9659000039100647,
      "learning_rate": 5.179738562091504e-06,
      "loss": 0.0702,
      "step": 11621
    },
    {
      "epoch": 2.6704963235294117,
      "grad_norm": 0.8997316360473633,
      "learning_rate": 5.179227941176472e-06,
      "loss": 0.0445,
      "step": 11622
    },
    {
      "epoch": 2.6707261029411766,
      "grad_norm": 1.0114946365356445,
      "learning_rate": 5.178717320261439e-06,
      "loss": 0.0353,
      "step": 11623
    },
    {
      "epoch": 2.670955882352941,
      "grad_norm": 1.2550346851348877,
      "learning_rate": 5.178206699346406e-06,
      "loss": 0.0449,
      "step": 11624
    },
    {
      "epoch": 2.6711856617647056,
      "grad_norm": 1.0956834554672241,
      "learning_rate": 5.1776960784313735e-06,
      "loss": 0.05,
      "step": 11625
    },
    {
      "epoch": 2.6714154411764706,
      "grad_norm": 1.1468721628189087,
      "learning_rate": 5.1771854575163405e-06,
      "loss": 0.0631,
      "step": 11626
    },
    {
      "epoch": 2.6716452205882355,
      "grad_norm": 1.0499025583267212,
      "learning_rate": 5.1766748366013075e-06,
      "loss": 0.0405,
      "step": 11627
    },
    {
      "epoch": 2.671875,
      "grad_norm": 0.7439790964126587,
      "learning_rate": 5.1761642156862746e-06,
      "loss": 0.0417,
      "step": 11628
    },
    {
      "epoch": 2.6721047794117645,
      "grad_norm": 0.6569409370422363,
      "learning_rate": 5.175653594771242e-06,
      "loss": 0.0162,
      "step": 11629
    },
    {
      "epoch": 2.6723345588235294,
      "grad_norm": 0.9119036793708801,
      "learning_rate": 5.1751429738562094e-06,
      "loss": 0.0442,
      "step": 11630
    },
    {
      "epoch": 2.6725643382352944,
      "grad_norm": 1.0272955894470215,
      "learning_rate": 5.1746323529411764e-06,
      "loss": 0.0544,
      "step": 11631
    },
    {
      "epoch": 2.672794117647059,
      "grad_norm": 0.9429051280021667,
      "learning_rate": 5.1741217320261435e-06,
      "loss": 0.0526,
      "step": 11632
    },
    {
      "epoch": 2.6730238970588234,
      "grad_norm": 0.7626805305480957,
      "learning_rate": 5.173611111111112e-06,
      "loss": 0.0277,
      "step": 11633
    },
    {
      "epoch": 2.6732536764705883,
      "grad_norm": 0.9160351753234863,
      "learning_rate": 5.173100490196079e-06,
      "loss": 0.0273,
      "step": 11634
    },
    {
      "epoch": 2.673483455882353,
      "grad_norm": 0.9989741444587708,
      "learning_rate": 5.172589869281046e-06,
      "loss": 0.0458,
      "step": 11635
    },
    {
      "epoch": 2.6737132352941178,
      "grad_norm": 1.3202747106552124,
      "learning_rate": 5.172079248366013e-06,
      "loss": 0.0431,
      "step": 11636
    },
    {
      "epoch": 2.6739430147058822,
      "grad_norm": 1.015338659286499,
      "learning_rate": 5.171568627450981e-06,
      "loss": 0.0576,
      "step": 11637
    },
    {
      "epoch": 2.674172794117647,
      "grad_norm": 0.9037705659866333,
      "learning_rate": 5.171058006535948e-06,
      "loss": 0.0346,
      "step": 11638
    },
    {
      "epoch": 2.6744025735294117,
      "grad_norm": 0.7002215385437012,
      "learning_rate": 5.170547385620915e-06,
      "loss": 0.0301,
      "step": 11639
    },
    {
      "epoch": 2.6746323529411766,
      "grad_norm": 0.5750848054885864,
      "learning_rate": 5.170036764705882e-06,
      "loss": 0.0193,
      "step": 11640
    },
    {
      "epoch": 2.674862132352941,
      "grad_norm": 1.2420387268066406,
      "learning_rate": 5.169526143790851e-06,
      "loss": 0.0528,
      "step": 11641
    },
    {
      "epoch": 2.6750919117647056,
      "grad_norm": 1.0358011722564697,
      "learning_rate": 5.169015522875818e-06,
      "loss": 0.0394,
      "step": 11642
    },
    {
      "epoch": 2.6753216911764706,
      "grad_norm": 0.7178292274475098,
      "learning_rate": 5.168504901960785e-06,
      "loss": 0.0259,
      "step": 11643
    },
    {
      "epoch": 2.6755514705882355,
      "grad_norm": 0.7280053496360779,
      "learning_rate": 5.167994281045752e-06,
      "loss": 0.0287,
      "step": 11644
    },
    {
      "epoch": 2.67578125,
      "grad_norm": 1.488326907157898,
      "learning_rate": 5.16748366013072e-06,
      "loss": 0.0414,
      "step": 11645
    },
    {
      "epoch": 2.6760110294117645,
      "grad_norm": 0.9652297496795654,
      "learning_rate": 5.166973039215687e-06,
      "loss": 0.0413,
      "step": 11646
    },
    {
      "epoch": 2.6762408088235294,
      "grad_norm": 0.9306685924530029,
      "learning_rate": 5.166462418300654e-06,
      "loss": 0.0437,
      "step": 11647
    },
    {
      "epoch": 2.6764705882352944,
      "grad_norm": 1.0380513668060303,
      "learning_rate": 5.165951797385621e-06,
      "loss": 0.0443,
      "step": 11648
    },
    {
      "epoch": 2.676700367647059,
      "grad_norm": 0.9462034106254578,
      "learning_rate": 5.1654411764705895e-06,
      "loss": 0.0317,
      "step": 11649
    },
    {
      "epoch": 2.6769301470588234,
      "grad_norm": 0.7563260793685913,
      "learning_rate": 5.1649305555555565e-06,
      "loss": 0.0436,
      "step": 11650
    },
    {
      "epoch": 2.6771599264705883,
      "grad_norm": 1.0638679265975952,
      "learning_rate": 5.1644199346405235e-06,
      "loss": 0.0711,
      "step": 11651
    },
    {
      "epoch": 2.677389705882353,
      "grad_norm": 0.7957229614257812,
      "learning_rate": 5.1639093137254905e-06,
      "loss": 0.0428,
      "step": 11652
    },
    {
      "epoch": 2.6776194852941178,
      "grad_norm": 0.8433597087860107,
      "learning_rate": 5.163398692810458e-06,
      "loss": 0.049,
      "step": 11653
    },
    {
      "epoch": 2.6778492647058822,
      "grad_norm": 0.9158632755279541,
      "learning_rate": 5.162888071895425e-06,
      "loss": 0.0566,
      "step": 11654
    },
    {
      "epoch": 2.678079044117647,
      "grad_norm": 1.0614444017410278,
      "learning_rate": 5.162377450980392e-06,
      "loss": 0.0443,
      "step": 11655
    },
    {
      "epoch": 2.6783088235294117,
      "grad_norm": 1.0664669275283813,
      "learning_rate": 5.1618668300653594e-06,
      "loss": 0.0453,
      "step": 11656
    },
    {
      "epoch": 2.6785386029411766,
      "grad_norm": 0.9981890320777893,
      "learning_rate": 5.161356209150328e-06,
      "loss": 0.0481,
      "step": 11657
    },
    {
      "epoch": 2.678768382352941,
      "grad_norm": 0.9570900797843933,
      "learning_rate": 5.160845588235295e-06,
      "loss": 0.0332,
      "step": 11658
    },
    {
      "epoch": 2.6789981617647056,
      "grad_norm": 0.8528833389282227,
      "learning_rate": 5.160334967320262e-06,
      "loss": 0.0343,
      "step": 11659
    },
    {
      "epoch": 2.6792279411764706,
      "grad_norm": 1.358628749847412,
      "learning_rate": 5.159824346405229e-06,
      "loss": 0.073,
      "step": 11660
    },
    {
      "epoch": 2.6794577205882355,
      "grad_norm": 0.6753958463668823,
      "learning_rate": 5.159313725490197e-06,
      "loss": 0.0211,
      "step": 11661
    },
    {
      "epoch": 2.6796875,
      "grad_norm": 1.1364256143569946,
      "learning_rate": 5.158803104575164e-06,
      "loss": 0.0355,
      "step": 11662
    },
    {
      "epoch": 2.6799172794117645,
      "grad_norm": 0.5838291645050049,
      "learning_rate": 5.158292483660131e-06,
      "loss": 0.0286,
      "step": 11663
    },
    {
      "epoch": 2.6801470588235294,
      "grad_norm": 0.839869499206543,
      "learning_rate": 5.157781862745098e-06,
      "loss": 0.0344,
      "step": 11664
    },
    {
      "epoch": 2.6803768382352944,
      "grad_norm": 0.8836169838905334,
      "learning_rate": 5.157271241830066e-06,
      "loss": 0.042,
      "step": 11665
    },
    {
      "epoch": 2.680606617647059,
      "grad_norm": 1.4240273237228394,
      "learning_rate": 5.156760620915033e-06,
      "loss": 0.0463,
      "step": 11666
    },
    {
      "epoch": 2.6808363970588234,
      "grad_norm": 0.9286363124847412,
      "learning_rate": 5.156250000000001e-06,
      "loss": 0.0492,
      "step": 11667
    },
    {
      "epoch": 2.6810661764705883,
      "grad_norm": 0.9205119609832764,
      "learning_rate": 5.155739379084968e-06,
      "loss": 0.0422,
      "step": 11668
    },
    {
      "epoch": 2.681295955882353,
      "grad_norm": 0.7779777646064758,
      "learning_rate": 5.155228758169935e-06,
      "loss": 0.0389,
      "step": 11669
    },
    {
      "epoch": 2.6815257352941178,
      "grad_norm": 1.0391778945922852,
      "learning_rate": 5.154718137254903e-06,
      "loss": 0.0475,
      "step": 11670
    },
    {
      "epoch": 2.6817555147058822,
      "grad_norm": 0.9016000628471375,
      "learning_rate": 5.15420751633987e-06,
      "loss": 0.0298,
      "step": 11671
    },
    {
      "epoch": 2.681985294117647,
      "grad_norm": 0.9218811392784119,
      "learning_rate": 5.153696895424837e-06,
      "loss": 0.0386,
      "step": 11672
    },
    {
      "epoch": 2.6822150735294117,
      "grad_norm": 0.7956081032752991,
      "learning_rate": 5.153186274509804e-06,
      "loss": 0.0317,
      "step": 11673
    },
    {
      "epoch": 2.6824448529411766,
      "grad_norm": 1.40241277217865,
      "learning_rate": 5.152675653594772e-06,
      "loss": 0.0633,
      "step": 11674
    },
    {
      "epoch": 2.682674632352941,
      "grad_norm": 0.7812710404396057,
      "learning_rate": 5.152165032679739e-06,
      "loss": 0.0448,
      "step": 11675
    },
    {
      "epoch": 2.6829044117647056,
      "grad_norm": 0.7401503920555115,
      "learning_rate": 5.151654411764706e-06,
      "loss": 0.0417,
      "step": 11676
    },
    {
      "epoch": 2.6831341911764706,
      "grad_norm": 0.6969195604324341,
      "learning_rate": 5.1511437908496735e-06,
      "loss": 0.038,
      "step": 11677
    },
    {
      "epoch": 2.6833639705882355,
      "grad_norm": 0.7917830348014832,
      "learning_rate": 5.150633169934641e-06,
      "loss": 0.0321,
      "step": 11678
    },
    {
      "epoch": 2.68359375,
      "grad_norm": 0.8003763556480408,
      "learning_rate": 5.150122549019608e-06,
      "loss": 0.0427,
      "step": 11679
    },
    {
      "epoch": 2.6838235294117645,
      "grad_norm": 0.9308568239212036,
      "learning_rate": 5.149611928104575e-06,
      "loss": 0.0414,
      "step": 11680
    },
    {
      "epoch": 2.6840533088235294,
      "grad_norm": 0.9190835356712341,
      "learning_rate": 5.149101307189542e-06,
      "loss": 0.0483,
      "step": 11681
    },
    {
      "epoch": 2.6842830882352944,
      "grad_norm": 1.0642774105072021,
      "learning_rate": 5.14859068627451e-06,
      "loss": 0.0391,
      "step": 11682
    },
    {
      "epoch": 2.684512867647059,
      "grad_norm": 0.9496816396713257,
      "learning_rate": 5.148080065359477e-06,
      "loss": 0.0361,
      "step": 11683
    },
    {
      "epoch": 2.6847426470588234,
      "grad_norm": 0.9409750699996948,
      "learning_rate": 5.147569444444444e-06,
      "loss": 0.0564,
      "step": 11684
    },
    {
      "epoch": 2.6849724264705883,
      "grad_norm": 1.1146934032440186,
      "learning_rate": 5.147058823529411e-06,
      "loss": 0.0401,
      "step": 11685
    },
    {
      "epoch": 2.685202205882353,
      "grad_norm": 0.7222950458526611,
      "learning_rate": 5.14654820261438e-06,
      "loss": 0.0202,
      "step": 11686
    },
    {
      "epoch": 2.6854319852941178,
      "grad_norm": 0.8228883147239685,
      "learning_rate": 5.146037581699347e-06,
      "loss": 0.0409,
      "step": 11687
    },
    {
      "epoch": 2.6856617647058822,
      "grad_norm": 0.7706849575042725,
      "learning_rate": 5.145526960784314e-06,
      "loss": 0.0285,
      "step": 11688
    },
    {
      "epoch": 2.685891544117647,
      "grad_norm": 0.9461027383804321,
      "learning_rate": 5.145016339869281e-06,
      "loss": 0.0309,
      "step": 11689
    },
    {
      "epoch": 2.6861213235294117,
      "grad_norm": 1.224280595779419,
      "learning_rate": 5.144505718954249e-06,
      "loss": 0.0404,
      "step": 11690
    },
    {
      "epoch": 2.6863511029411766,
      "grad_norm": 0.8730249404907227,
      "learning_rate": 5.143995098039216e-06,
      "loss": 0.0247,
      "step": 11691
    },
    {
      "epoch": 2.686580882352941,
      "grad_norm": 0.7841340899467468,
      "learning_rate": 5.143484477124183e-06,
      "loss": 0.0426,
      "step": 11692
    },
    {
      "epoch": 2.6868106617647056,
      "grad_norm": 1.1042836904525757,
      "learning_rate": 5.14297385620915e-06,
      "loss": 0.0491,
      "step": 11693
    },
    {
      "epoch": 2.6870404411764706,
      "grad_norm": 1.2342584133148193,
      "learning_rate": 5.142463235294119e-06,
      "loss": 0.0507,
      "step": 11694
    },
    {
      "epoch": 2.6872702205882355,
      "grad_norm": 1.0782599449157715,
      "learning_rate": 5.141952614379086e-06,
      "loss": 0.0415,
      "step": 11695
    },
    {
      "epoch": 2.6875,
      "grad_norm": 1.0516618490219116,
      "learning_rate": 5.141441993464053e-06,
      "loss": 0.0379,
      "step": 11696
    },
    {
      "epoch": 2.6877297794117645,
      "grad_norm": 0.7842694520950317,
      "learning_rate": 5.14093137254902e-06,
      "loss": 0.0352,
      "step": 11697
    },
    {
      "epoch": 2.6879595588235294,
      "grad_norm": 0.7357803583145142,
      "learning_rate": 5.140420751633988e-06,
      "loss": 0.0326,
      "step": 11698
    },
    {
      "epoch": 2.6881893382352944,
      "grad_norm": 1.0846643447875977,
      "learning_rate": 5.139910130718955e-06,
      "loss": 0.0499,
      "step": 11699
    },
    {
      "epoch": 2.688419117647059,
      "grad_norm": 0.9081441760063171,
      "learning_rate": 5.139399509803922e-06,
      "loss": 0.0391,
      "step": 11700
    },
    {
      "epoch": 2.6886488970588234,
      "grad_norm": 1.1519355773925781,
      "learning_rate": 5.138888888888889e-06,
      "loss": 0.0574,
      "step": 11701
    },
    {
      "epoch": 2.6888786764705883,
      "grad_norm": 0.9159612655639648,
      "learning_rate": 5.138378267973857e-06,
      "loss": 0.0337,
      "step": 11702
    },
    {
      "epoch": 2.689108455882353,
      "grad_norm": 0.8947683572769165,
      "learning_rate": 5.137867647058824e-06,
      "loss": 0.035,
      "step": 11703
    },
    {
      "epoch": 2.6893382352941178,
      "grad_norm": 0.8729574084281921,
      "learning_rate": 5.137357026143791e-06,
      "loss": 0.0296,
      "step": 11704
    },
    {
      "epoch": 2.6895680147058822,
      "grad_norm": 0.7643545269966125,
      "learning_rate": 5.136846405228758e-06,
      "loss": 0.0272,
      "step": 11705
    },
    {
      "epoch": 2.689797794117647,
      "grad_norm": 0.85930335521698,
      "learning_rate": 5.136335784313726e-06,
      "loss": 0.0371,
      "step": 11706
    },
    {
      "epoch": 2.6900275735294117,
      "grad_norm": 1.0910766124725342,
      "learning_rate": 5.135825163398693e-06,
      "loss": 0.0442,
      "step": 11707
    },
    {
      "epoch": 2.6902573529411766,
      "grad_norm": 0.746841311454773,
      "learning_rate": 5.13531454248366e-06,
      "loss": 0.028,
      "step": 11708
    },
    {
      "epoch": 2.690487132352941,
      "grad_norm": 1.151638388633728,
      "learning_rate": 5.134803921568627e-06,
      "loss": 0.0353,
      "step": 11709
    },
    {
      "epoch": 2.6907169117647056,
      "grad_norm": 1.0221660137176514,
      "learning_rate": 5.134293300653595e-06,
      "loss": 0.0528,
      "step": 11710
    },
    {
      "epoch": 2.6909466911764706,
      "grad_norm": 1.2275397777557373,
      "learning_rate": 5.133782679738563e-06,
      "loss": 0.0599,
      "step": 11711
    },
    {
      "epoch": 2.6911764705882355,
      "grad_norm": 1.1684383153915405,
      "learning_rate": 5.13327205882353e-06,
      "loss": 0.0624,
      "step": 11712
    },
    {
      "epoch": 2.69140625,
      "grad_norm": 1.1865376234054565,
      "learning_rate": 5.132761437908497e-06,
      "loss": 0.0315,
      "step": 11713
    },
    {
      "epoch": 2.6916360294117645,
      "grad_norm": 0.9997686743736267,
      "learning_rate": 5.132250816993465e-06,
      "loss": 0.0589,
      "step": 11714
    },
    {
      "epoch": 2.6918658088235294,
      "grad_norm": 0.9541792869567871,
      "learning_rate": 5.131740196078432e-06,
      "loss": 0.0342,
      "step": 11715
    },
    {
      "epoch": 2.6920955882352944,
      "grad_norm": 1.0651805400848389,
      "learning_rate": 5.131229575163399e-06,
      "loss": 0.0293,
      "step": 11716
    },
    {
      "epoch": 2.692325367647059,
      "grad_norm": 1.0532432794570923,
      "learning_rate": 5.130718954248366e-06,
      "loss": 0.0457,
      "step": 11717
    },
    {
      "epoch": 2.6925551470588234,
      "grad_norm": 1.2441084384918213,
      "learning_rate": 5.130208333333334e-06,
      "loss": 0.045,
      "step": 11718
    },
    {
      "epoch": 2.6927849264705883,
      "grad_norm": 1.1210963726043701,
      "learning_rate": 5.129697712418301e-06,
      "loss": 0.0372,
      "step": 11719
    },
    {
      "epoch": 2.693014705882353,
      "grad_norm": 0.912802517414093,
      "learning_rate": 5.129187091503268e-06,
      "loss": 0.0366,
      "step": 11720
    },
    {
      "epoch": 2.6932444852941178,
      "grad_norm": 0.9954087138175964,
      "learning_rate": 5.128676470588235e-06,
      "loss": 0.0405,
      "step": 11721
    },
    {
      "epoch": 2.6934742647058822,
      "grad_norm": 0.6571635603904724,
      "learning_rate": 5.1281658496732036e-06,
      "loss": 0.034,
      "step": 11722
    },
    {
      "epoch": 2.693704044117647,
      "grad_norm": 0.8215681314468384,
      "learning_rate": 5.1276552287581706e-06,
      "loss": 0.031,
      "step": 11723
    },
    {
      "epoch": 2.6939338235294117,
      "grad_norm": 0.9535942673683167,
      "learning_rate": 5.127144607843138e-06,
      "loss": 0.0442,
      "step": 11724
    },
    {
      "epoch": 2.6941636029411766,
      "grad_norm": 0.9372411370277405,
      "learning_rate": 5.126633986928105e-06,
      "loss": 0.0316,
      "step": 11725
    },
    {
      "epoch": 2.694393382352941,
      "grad_norm": 0.9521920084953308,
      "learning_rate": 5.1261233660130725e-06,
      "loss": 0.0386,
      "step": 11726
    },
    {
      "epoch": 2.6946231617647056,
      "grad_norm": 0.8209615349769592,
      "learning_rate": 5.1256127450980395e-06,
      "loss": 0.0315,
      "step": 11727
    },
    {
      "epoch": 2.6948529411764706,
      "grad_norm": 0.9124928116798401,
      "learning_rate": 5.1251021241830065e-06,
      "loss": 0.0292,
      "step": 11728
    },
    {
      "epoch": 2.6950827205882355,
      "grad_norm": 1.1620486974716187,
      "learning_rate": 5.1245915032679735e-06,
      "loss": 0.0481,
      "step": 11729
    },
    {
      "epoch": 2.6953125,
      "grad_norm": 1.1277096271514893,
      "learning_rate": 5.124080882352942e-06,
      "loss": 0.0516,
      "step": 11730
    },
    {
      "epoch": 2.6955422794117645,
      "grad_norm": 1.1251071691513062,
      "learning_rate": 5.123570261437909e-06,
      "loss": 0.0378,
      "step": 11731
    },
    {
      "epoch": 2.6957720588235294,
      "grad_norm": 1.084529995918274,
      "learning_rate": 5.123059640522876e-06,
      "loss": 0.0508,
      "step": 11732
    },
    {
      "epoch": 2.6960018382352944,
      "grad_norm": 1.2391016483306885,
      "learning_rate": 5.122549019607843e-06,
      "loss": 0.0343,
      "step": 11733
    },
    {
      "epoch": 2.696231617647059,
      "grad_norm": 0.740050196647644,
      "learning_rate": 5.122038398692811e-06,
      "loss": 0.0255,
      "step": 11734
    },
    {
      "epoch": 2.6964613970588234,
      "grad_norm": 0.7777258157730103,
      "learning_rate": 5.121527777777778e-06,
      "loss": 0.0368,
      "step": 11735
    },
    {
      "epoch": 2.6966911764705883,
      "grad_norm": 0.8512300848960876,
      "learning_rate": 5.121017156862745e-06,
      "loss": 0.0374,
      "step": 11736
    },
    {
      "epoch": 2.696920955882353,
      "grad_norm": 0.8975664377212524,
      "learning_rate": 5.120506535947712e-06,
      "loss": 0.0527,
      "step": 11737
    },
    {
      "epoch": 2.6971507352941178,
      "grad_norm": 1.0174280405044556,
      "learning_rate": 5.119995915032681e-06,
      "loss": 0.0317,
      "step": 11738
    },
    {
      "epoch": 2.6973805147058822,
      "grad_norm": 0.853110671043396,
      "learning_rate": 5.119485294117648e-06,
      "loss": 0.036,
      "step": 11739
    },
    {
      "epoch": 2.697610294117647,
      "grad_norm": 1.244679570198059,
      "learning_rate": 5.118974673202615e-06,
      "loss": 0.0543,
      "step": 11740
    },
    {
      "epoch": 2.6978400735294117,
      "grad_norm": 0.9828718304634094,
      "learning_rate": 5.118464052287582e-06,
      "loss": 0.0471,
      "step": 11741
    },
    {
      "epoch": 2.6980698529411766,
      "grad_norm": 1.3036690950393677,
      "learning_rate": 5.11795343137255e-06,
      "loss": 0.0912,
      "step": 11742
    },
    {
      "epoch": 2.698299632352941,
      "grad_norm": 0.9101777672767639,
      "learning_rate": 5.117442810457517e-06,
      "loss": 0.0286,
      "step": 11743
    },
    {
      "epoch": 2.6985294117647056,
      "grad_norm": 0.897917628288269,
      "learning_rate": 5.116932189542484e-06,
      "loss": 0.0295,
      "step": 11744
    },
    {
      "epoch": 2.6987591911764706,
      "grad_norm": 0.8354395031929016,
      "learning_rate": 5.116421568627451e-06,
      "loss": 0.028,
      "step": 11745
    },
    {
      "epoch": 2.6989889705882355,
      "grad_norm": 1.3300609588623047,
      "learning_rate": 5.1159109477124195e-06,
      "loss": 0.0511,
      "step": 11746
    },
    {
      "epoch": 2.69921875,
      "grad_norm": 1.0167442560195923,
      "learning_rate": 5.1154003267973865e-06,
      "loss": 0.0543,
      "step": 11747
    },
    {
      "epoch": 2.6994485294117645,
      "grad_norm": 0.8024541139602661,
      "learning_rate": 5.1148897058823536e-06,
      "loss": 0.0246,
      "step": 11748
    },
    {
      "epoch": 2.6996783088235294,
      "grad_norm": 0.8014575242996216,
      "learning_rate": 5.1143790849673206e-06,
      "loss": 0.0394,
      "step": 11749
    },
    {
      "epoch": 2.6999080882352944,
      "grad_norm": 0.9350178837776184,
      "learning_rate": 5.1138684640522884e-06,
      "loss": 0.0425,
      "step": 11750
    },
    {
      "epoch": 2.700137867647059,
      "grad_norm": 0.8651694059371948,
      "learning_rate": 5.1133578431372554e-06,
      "loss": 0.0381,
      "step": 11751
    },
    {
      "epoch": 2.7003676470588234,
      "grad_norm": 1.0048930644989014,
      "learning_rate": 5.1128472222222225e-06,
      "loss": 0.0521,
      "step": 11752
    },
    {
      "epoch": 2.7005974264705883,
      "grad_norm": 0.8047730326652527,
      "learning_rate": 5.1123366013071895e-06,
      "loss": 0.0289,
      "step": 11753
    },
    {
      "epoch": 2.700827205882353,
      "grad_norm": 1.2023783922195435,
      "learning_rate": 5.111825980392157e-06,
      "loss": 0.0685,
      "step": 11754
    },
    {
      "epoch": 2.7010569852941178,
      "grad_norm": 1.1486212015151978,
      "learning_rate": 5.111315359477124e-06,
      "loss": 0.0433,
      "step": 11755
    },
    {
      "epoch": 2.7012867647058822,
      "grad_norm": 1.0001753568649292,
      "learning_rate": 5.110804738562092e-06,
      "loss": 0.037,
      "step": 11756
    },
    {
      "epoch": 2.701516544117647,
      "grad_norm": 0.9389370679855347,
      "learning_rate": 5.110294117647059e-06,
      "loss": 0.034,
      "step": 11757
    },
    {
      "epoch": 2.7017463235294117,
      "grad_norm": 0.9047792553901672,
      "learning_rate": 5.109783496732027e-06,
      "loss": 0.0303,
      "step": 11758
    },
    {
      "epoch": 2.7019761029411766,
      "grad_norm": 0.9270491600036621,
      "learning_rate": 5.109272875816994e-06,
      "loss": 0.0438,
      "step": 11759
    },
    {
      "epoch": 2.702205882352941,
      "grad_norm": 0.7598361372947693,
      "learning_rate": 5.108762254901961e-06,
      "loss": 0.0286,
      "step": 11760
    },
    {
      "epoch": 2.7024356617647056,
      "grad_norm": 1.1477848291397095,
      "learning_rate": 5.108251633986928e-06,
      "loss": 0.0494,
      "step": 11761
    },
    {
      "epoch": 2.7026654411764706,
      "grad_norm": 1.0830796957015991,
      "learning_rate": 5.107741013071896e-06,
      "loss": 0.0514,
      "step": 11762
    },
    {
      "epoch": 2.7028952205882355,
      "grad_norm": 0.9106705188751221,
      "learning_rate": 5.107230392156863e-06,
      "loss": 0.0327,
      "step": 11763
    },
    {
      "epoch": 2.703125,
      "grad_norm": 0.6858466863632202,
      "learning_rate": 5.10671977124183e-06,
      "loss": 0.0148,
      "step": 11764
    },
    {
      "epoch": 2.7033547794117645,
      "grad_norm": Infinity,
      "learning_rate": 5.106209150326797e-06,
      "loss": 0.0562,
      "step": 11765
    },
    {
      "epoch": 2.7035845588235294,
      "grad_norm": 1.2209125757217407,
      "learning_rate": 5.106209150326797e-06,
      "loss": 0.0641,
      "step": 11766
    },
    {
      "epoch": 2.7038143382352944,
      "grad_norm": 1.0768803358078003,
      "learning_rate": 5.105698529411766e-06,
      "loss": 0.0474,
      "step": 11767
    },
    {
      "epoch": 2.704044117647059,
      "grad_norm": 1.0406875610351562,
      "learning_rate": 5.105187908496733e-06,
      "loss": 0.0529,
      "step": 11768
    },
    {
      "epoch": 2.7042738970588234,
      "grad_norm": 0.8740423321723938,
      "learning_rate": 5.1046772875817e-06,
      "loss": 0.0388,
      "step": 11769
    },
    {
      "epoch": 2.7045036764705883,
      "grad_norm": 0.7896448969841003,
      "learning_rate": 5.104166666666667e-06,
      "loss": 0.0258,
      "step": 11770
    },
    {
      "epoch": 2.704733455882353,
      "grad_norm": 0.5863845348358154,
      "learning_rate": 5.103656045751635e-06,
      "loss": 0.0283,
      "step": 11771
    },
    {
      "epoch": 2.7049632352941178,
      "grad_norm": 1.2436004877090454,
      "learning_rate": 5.103145424836602e-06,
      "loss": 0.0466,
      "step": 11772
    },
    {
      "epoch": 2.7051930147058822,
      "grad_norm": 0.916443407535553,
      "learning_rate": 5.102634803921569e-06,
      "loss": 0.0364,
      "step": 11773
    },
    {
      "epoch": 2.705422794117647,
      "grad_norm": 1.0806541442871094,
      "learning_rate": 5.102124183006536e-06,
      "loss": 0.0412,
      "step": 11774
    },
    {
      "epoch": 2.7056525735294117,
      "grad_norm": 0.9023584723472595,
      "learning_rate": 5.101613562091504e-06,
      "loss": 0.0366,
      "step": 11775
    },
    {
      "epoch": 2.7058823529411766,
      "grad_norm": 1.3460575342178345,
      "learning_rate": 5.101102941176471e-06,
      "loss": 0.0591,
      "step": 11776
    },
    {
      "epoch": 2.706112132352941,
      "grad_norm": 0.7903119921684265,
      "learning_rate": 5.1005923202614384e-06,
      "loss": 0.0322,
      "step": 11777
    },
    {
      "epoch": 2.7063419117647056,
      "grad_norm": 0.9925861358642578,
      "learning_rate": 5.1000816993464054e-06,
      "loss": 0.0436,
      "step": 11778
    },
    {
      "epoch": 2.7065716911764706,
      "grad_norm": 0.6533001065254211,
      "learning_rate": 5.099571078431373e-06,
      "loss": 0.0317,
      "step": 11779
    },
    {
      "epoch": 2.7068014705882355,
      "grad_norm": 0.7637979984283447,
      "learning_rate": 5.09906045751634e-06,
      "loss": 0.022,
      "step": 11780
    },
    {
      "epoch": 2.70703125,
      "grad_norm": 0.8789666891098022,
      "learning_rate": 5.098549836601307e-06,
      "loss": 0.0363,
      "step": 11781
    },
    {
      "epoch": 2.7072610294117645,
      "grad_norm": 0.9945337772369385,
      "learning_rate": 5.098039215686274e-06,
      "loss": 0.0307,
      "step": 11782
    },
    {
      "epoch": 2.7074908088235294,
      "grad_norm": 0.6689796447753906,
      "learning_rate": 5.097528594771243e-06,
      "loss": 0.0236,
      "step": 11783
    },
    {
      "epoch": 2.7077205882352944,
      "grad_norm": 0.7909583449363708,
      "learning_rate": 5.09701797385621e-06,
      "loss": 0.0295,
      "step": 11784
    },
    {
      "epoch": 2.707950367647059,
      "grad_norm": 0.7418053150177002,
      "learning_rate": 5.096507352941177e-06,
      "loss": 0.0435,
      "step": 11785
    },
    {
      "epoch": 2.7081801470588234,
      "grad_norm": 1.1527824401855469,
      "learning_rate": 5.095996732026144e-06,
      "loss": 0.0553,
      "step": 11786
    },
    {
      "epoch": 2.7084099264705883,
      "grad_norm": 1.0515460968017578,
      "learning_rate": 5.095486111111112e-06,
      "loss": 0.0464,
      "step": 11787
    },
    {
      "epoch": 2.708639705882353,
      "grad_norm": 0.9571171402931213,
      "learning_rate": 5.094975490196079e-06,
      "loss": 0.039,
      "step": 11788
    },
    {
      "epoch": 2.7088694852941178,
      "grad_norm": 1.0237033367156982,
      "learning_rate": 5.094464869281046e-06,
      "loss": 0.0491,
      "step": 11789
    },
    {
      "epoch": 2.7090992647058822,
      "grad_norm": 0.7447566390037537,
      "learning_rate": 5.093954248366013e-06,
      "loss": 0.0297,
      "step": 11790
    },
    {
      "epoch": 2.709329044117647,
      "grad_norm": 0.7643121480941772,
      "learning_rate": 5.093443627450982e-06,
      "loss": 0.0338,
      "step": 11791
    },
    {
      "epoch": 2.7095588235294117,
      "grad_norm": 1.120429277420044,
      "learning_rate": 5.092933006535949e-06,
      "loss": 0.0514,
      "step": 11792
    },
    {
      "epoch": 2.7097886029411766,
      "grad_norm": 1.0462002754211426,
      "learning_rate": 5.092422385620916e-06,
      "loss": 0.0424,
      "step": 11793
    },
    {
      "epoch": 2.710018382352941,
      "grad_norm": 1.1723248958587646,
      "learning_rate": 5.091911764705883e-06,
      "loss": 0.0602,
      "step": 11794
    },
    {
      "epoch": 2.7102481617647056,
      "grad_norm": 0.7643424272537231,
      "learning_rate": 5.091401143790851e-06,
      "loss": 0.023,
      "step": 11795
    },
    {
      "epoch": 2.7104779411764706,
      "grad_norm": 1.066033959388733,
      "learning_rate": 5.090890522875818e-06,
      "loss": 0.0521,
      "step": 11796
    },
    {
      "epoch": 2.7107077205882355,
      "grad_norm": 1.105231523513794,
      "learning_rate": 5.090379901960785e-06,
      "loss": 0.0433,
      "step": 11797
    },
    {
      "epoch": 2.7109375,
      "grad_norm": 1.0305514335632324,
      "learning_rate": 5.089869281045752e-06,
      "loss": 0.0406,
      "step": 11798
    },
    {
      "epoch": 2.7111672794117645,
      "grad_norm": 0.8463359475135803,
      "learning_rate": 5.0893586601307195e-06,
      "loss": 0.0288,
      "step": 11799
    },
    {
      "epoch": 2.7113970588235294,
      "grad_norm": 1.2091726064682007,
      "learning_rate": 5.0888480392156865e-06,
      "loss": 0.0447,
      "step": 11800
    },
    {
      "epoch": 2.7116268382352944,
      "grad_norm": 1.1728357076644897,
      "learning_rate": 5.088337418300654e-06,
      "loss": 0.0509,
      "step": 11801
    },
    {
      "epoch": 2.711856617647059,
      "grad_norm": 1.1175479888916016,
      "learning_rate": 5.087826797385621e-06,
      "loss": 0.0448,
      "step": 11802
    },
    {
      "epoch": 2.7120863970588234,
      "grad_norm": 0.7625688314437866,
      "learning_rate": 5.087316176470589e-06,
      "loss": 0.0229,
      "step": 11803
    },
    {
      "epoch": 2.7123161764705883,
      "grad_norm": 1.3560580015182495,
      "learning_rate": 5.086805555555556e-06,
      "loss": 0.0609,
      "step": 11804
    },
    {
      "epoch": 2.712545955882353,
      "grad_norm": 0.9691938757896423,
      "learning_rate": 5.086294934640523e-06,
      "loss": 0.0404,
      "step": 11805
    },
    {
      "epoch": 2.7127757352941178,
      "grad_norm": 0.8568229675292969,
      "learning_rate": 5.08578431372549e-06,
      "loss": 0.0384,
      "step": 11806
    },
    {
      "epoch": 2.7130055147058822,
      "grad_norm": 0.851274847984314,
      "learning_rate": 5.085273692810458e-06,
      "loss": 0.0235,
      "step": 11807
    },
    {
      "epoch": 2.713235294117647,
      "grad_norm": 1.395609974861145,
      "learning_rate": 5.084763071895425e-06,
      "loss": 0.0481,
      "step": 11808
    },
    {
      "epoch": 2.7134650735294117,
      "grad_norm": 1.1719383001327515,
      "learning_rate": 5.084252450980392e-06,
      "loss": 0.0371,
      "step": 11809
    },
    {
      "epoch": 2.7136948529411766,
      "grad_norm": 0.8890160918235779,
      "learning_rate": 5.083741830065359e-06,
      "loss": 0.0338,
      "step": 11810
    },
    {
      "epoch": 2.713924632352941,
      "grad_norm": 1.0932292938232422,
      "learning_rate": 5.083231209150328e-06,
      "loss": 0.0476,
      "step": 11811
    },
    {
      "epoch": 2.7141544117647056,
      "grad_norm": 1.0337145328521729,
      "learning_rate": 5.082720588235295e-06,
      "loss": 0.052,
      "step": 11812
    },
    {
      "epoch": 2.7143841911764706,
      "grad_norm": 0.9782022833824158,
      "learning_rate": 5.082209967320262e-06,
      "loss": 0.0456,
      "step": 11813
    },
    {
      "epoch": 2.7146139705882355,
      "grad_norm": 0.6670717000961304,
      "learning_rate": 5.081699346405229e-06,
      "loss": 0.0279,
      "step": 11814
    },
    {
      "epoch": 2.71484375,
      "grad_norm": 1.1091930866241455,
      "learning_rate": 5.081188725490197e-06,
      "loss": 0.0496,
      "step": 11815
    },
    {
      "epoch": 2.7150735294117645,
      "grad_norm": 0.7574344873428345,
      "learning_rate": 5.080678104575164e-06,
      "loss": 0.0304,
      "step": 11816
    },
    {
      "epoch": 2.7153033088235294,
      "grad_norm": 0.9138942956924438,
      "learning_rate": 5.080167483660131e-06,
      "loss": 0.0359,
      "step": 11817
    },
    {
      "epoch": 2.7155330882352944,
      "grad_norm": 0.9173101186752319,
      "learning_rate": 5.079656862745098e-06,
      "loss": 0.0366,
      "step": 11818
    },
    {
      "epoch": 2.715762867647059,
      "grad_norm": 1.1457799673080444,
      "learning_rate": 5.079146241830067e-06,
      "loss": 0.0576,
      "step": 11819
    },
    {
      "epoch": 2.7159926470588234,
      "grad_norm": 0.690288782119751,
      "learning_rate": 5.078635620915034e-06,
      "loss": 0.0267,
      "step": 11820
    },
    {
      "epoch": 2.7162224264705883,
      "grad_norm": 0.9689952731132507,
      "learning_rate": 5.078125000000001e-06,
      "loss": 0.0438,
      "step": 11821
    },
    {
      "epoch": 2.716452205882353,
      "grad_norm": 0.8951690793037415,
      "learning_rate": 5.077614379084968e-06,
      "loss": 0.0547,
      "step": 11822
    },
    {
      "epoch": 2.7166819852941178,
      "grad_norm": 0.8857076168060303,
      "learning_rate": 5.077103758169935e-06,
      "loss": 0.0329,
      "step": 11823
    },
    {
      "epoch": 2.7169117647058822,
      "grad_norm": 0.8920397162437439,
      "learning_rate": 5.0765931372549025e-06,
      "loss": 0.0273,
      "step": 11824
    },
    {
      "epoch": 2.717141544117647,
      "grad_norm": 1.2365684509277344,
      "learning_rate": 5.0760825163398695e-06,
      "loss": 0.0451,
      "step": 11825
    },
    {
      "epoch": 2.7173713235294117,
      "grad_norm": 0.8270229697227478,
      "learning_rate": 5.0755718954248365e-06,
      "loss": 0.022,
      "step": 11826
    },
    {
      "epoch": 2.7176011029411766,
      "grad_norm": 0.8689626455307007,
      "learning_rate": 5.0750612745098035e-06,
      "loss": 0.0458,
      "step": 11827
    },
    {
      "epoch": 2.717830882352941,
      "grad_norm": 0.6708065867424011,
      "learning_rate": 5.074550653594772e-06,
      "loss": 0.0329,
      "step": 11828
    },
    {
      "epoch": 2.7180606617647056,
      "grad_norm": 0.8413195610046387,
      "learning_rate": 5.074040032679739e-06,
      "loss": 0.0373,
      "step": 11829
    },
    {
      "epoch": 2.7182904411764706,
      "grad_norm": 1.0319150686264038,
      "learning_rate": 5.073529411764706e-06,
      "loss": 0.049,
      "step": 11830
    },
    {
      "epoch": 2.7185202205882355,
      "grad_norm": 1.1376252174377441,
      "learning_rate": 5.073018790849673e-06,
      "loss": 0.0327,
      "step": 11831
    },
    {
      "epoch": 2.71875,
      "grad_norm": 1.6017322540283203,
      "learning_rate": 5.072508169934641e-06,
      "loss": 0.0822,
      "step": 11832
    },
    {
      "epoch": 2.7189797794117645,
      "grad_norm": 0.9410998225212097,
      "learning_rate": 5.071997549019608e-06,
      "loss": 0.0342,
      "step": 11833
    },
    {
      "epoch": 2.7192095588235294,
      "grad_norm": 1.0572900772094727,
      "learning_rate": 5.071486928104575e-06,
      "loss": 0.0466,
      "step": 11834
    },
    {
      "epoch": 2.7194393382352944,
      "grad_norm": 0.7187544703483582,
      "learning_rate": 5.070976307189542e-06,
      "loss": 0.0188,
      "step": 11835
    },
    {
      "epoch": 2.719669117647059,
      "grad_norm": 1.1322611570358276,
      "learning_rate": 5.070465686274511e-06,
      "loss": 0.0349,
      "step": 11836
    },
    {
      "epoch": 2.7198988970588234,
      "grad_norm": 1.3762892484664917,
      "learning_rate": 5.069955065359478e-06,
      "loss": 0.0708,
      "step": 11837
    },
    {
      "epoch": 2.7201286764705883,
      "grad_norm": 0.9161861538887024,
      "learning_rate": 5.069444444444445e-06,
      "loss": 0.0544,
      "step": 11838
    },
    {
      "epoch": 2.720358455882353,
      "grad_norm": 0.9424586296081543,
      "learning_rate": 5.068933823529412e-06,
      "loss": 0.0261,
      "step": 11839
    },
    {
      "epoch": 2.7205882352941178,
      "grad_norm": 0.7403854727745056,
      "learning_rate": 5.06842320261438e-06,
      "loss": 0.019,
      "step": 11840
    },
    {
      "epoch": 2.7208180147058822,
      "grad_norm": 0.9497438669204712,
      "learning_rate": 5.067912581699347e-06,
      "loss": 0.0233,
      "step": 11841
    },
    {
      "epoch": 2.721047794117647,
      "grad_norm": 0.6970778107643127,
      "learning_rate": 5.067401960784314e-06,
      "loss": 0.0324,
      "step": 11842
    },
    {
      "epoch": 2.7212775735294117,
      "grad_norm": 0.9229238033294678,
      "learning_rate": 5.066891339869281e-06,
      "loss": 0.0654,
      "step": 11843
    },
    {
      "epoch": 2.7215073529411766,
      "grad_norm": 0.9462069272994995,
      "learning_rate": 5.066380718954249e-06,
      "loss": 0.0289,
      "step": 11844
    },
    {
      "epoch": 2.721737132352941,
      "grad_norm": 1.038440227508545,
      "learning_rate": 5.065870098039216e-06,
      "loss": 0.0515,
      "step": 11845
    },
    {
      "epoch": 2.7219669117647056,
      "grad_norm": 0.8806952834129333,
      "learning_rate": 5.065359477124184e-06,
      "loss": 0.0328,
      "step": 11846
    },
    {
      "epoch": 2.7221966911764706,
      "grad_norm": 0.8789827823638916,
      "learning_rate": 5.064848856209151e-06,
      "loss": 0.029,
      "step": 11847
    },
    {
      "epoch": 2.7224264705882355,
      "grad_norm": 0.9715100526809692,
      "learning_rate": 5.0643382352941185e-06,
      "loss": 0.0379,
      "step": 11848
    },
    {
      "epoch": 2.72265625,
      "grad_norm": 1.7514468431472778,
      "learning_rate": 5.0638276143790855e-06,
      "loss": 0.0423,
      "step": 11849
    },
    {
      "epoch": 2.7228860294117645,
      "grad_norm": 0.8455551266670227,
      "learning_rate": 5.0633169934640525e-06,
      "loss": 0.033,
      "step": 11850
    },
    {
      "epoch": 2.7231158088235294,
      "grad_norm": 0.978630781173706,
      "learning_rate": 5.0628063725490195e-06,
      "loss": 0.0514,
      "step": 11851
    },
    {
      "epoch": 2.7233455882352944,
      "grad_norm": 0.7068141102790833,
      "learning_rate": 5.062295751633987e-06,
      "loss": 0.0239,
      "step": 11852
    },
    {
      "epoch": 2.723575367647059,
      "grad_norm": 1.208206295967102,
      "learning_rate": 5.061785130718954e-06,
      "loss": 0.0501,
      "step": 11853
    },
    {
      "epoch": 2.7238051470588234,
      "grad_norm": 0.6035454869270325,
      "learning_rate": 5.061274509803921e-06,
      "loss": 0.0252,
      "step": 11854
    },
    {
      "epoch": 2.7240349264705883,
      "grad_norm": 0.7079594731330872,
      "learning_rate": 5.060763888888888e-06,
      "loss": 0.0179,
      "step": 11855
    },
    {
      "epoch": 2.724264705882353,
      "grad_norm": 1.0282565355300903,
      "learning_rate": 5.060253267973857e-06,
      "loss": 0.0392,
      "step": 11856
    },
    {
      "epoch": 2.7244944852941178,
      "grad_norm": 0.8850796818733215,
      "learning_rate": 5.059742647058824e-06,
      "loss": 0.0423,
      "step": 11857
    },
    {
      "epoch": 2.7247242647058822,
      "grad_norm": 1.4447779655456543,
      "learning_rate": 5.059232026143791e-06,
      "loss": 0.0512,
      "step": 11858
    },
    {
      "epoch": 2.724954044117647,
      "grad_norm": 0.6874492168426514,
      "learning_rate": 5.058721405228758e-06,
      "loss": 0.0215,
      "step": 11859
    },
    {
      "epoch": 2.7251838235294117,
      "grad_norm": 0.7290908098220825,
      "learning_rate": 5.058210784313726e-06,
      "loss": 0.0186,
      "step": 11860
    },
    {
      "epoch": 2.7254136029411766,
      "grad_norm": 0.9806897640228271,
      "learning_rate": 5.057700163398693e-06,
      "loss": 0.0481,
      "step": 11861
    },
    {
      "epoch": 2.725643382352941,
      "grad_norm": 0.9898988604545593,
      "learning_rate": 5.05718954248366e-06,
      "loss": 0.034,
      "step": 11862
    },
    {
      "epoch": 2.7258731617647056,
      "grad_norm": 1.8101309537887573,
      "learning_rate": 5.056678921568627e-06,
      "loss": 0.0458,
      "step": 11863
    },
    {
      "epoch": 2.7261029411764706,
      "grad_norm": 1.0390162467956543,
      "learning_rate": 5.056168300653596e-06,
      "loss": 0.0592,
      "step": 11864
    },
    {
      "epoch": 2.7263327205882355,
      "grad_norm": 0.7927043437957764,
      "learning_rate": 5.055657679738563e-06,
      "loss": 0.034,
      "step": 11865
    },
    {
      "epoch": 2.7265625,
      "grad_norm": 0.7986708283424377,
      "learning_rate": 5.05514705882353e-06,
      "loss": 0.0358,
      "step": 11866
    },
    {
      "epoch": 2.7267922794117645,
      "grad_norm": 0.7768110632896423,
      "learning_rate": 5.054636437908497e-06,
      "loss": 0.0477,
      "step": 11867
    },
    {
      "epoch": 2.7270220588235294,
      "grad_norm": 0.5674538016319275,
      "learning_rate": 5.054125816993465e-06,
      "loss": 0.0271,
      "step": 11868
    },
    {
      "epoch": 2.7272518382352944,
      "grad_norm": 1.0851635932922363,
      "learning_rate": 5.053615196078432e-06,
      "loss": 0.0392,
      "step": 11869
    },
    {
      "epoch": 2.727481617647059,
      "grad_norm": 1.0132620334625244,
      "learning_rate": 5.053104575163399e-06,
      "loss": 0.0329,
      "step": 11870
    },
    {
      "epoch": 2.7277113970588234,
      "grad_norm": 1.2022119760513306,
      "learning_rate": 5.052593954248366e-06,
      "loss": 0.055,
      "step": 11871
    },
    {
      "epoch": 2.7279411764705883,
      "grad_norm": 0.5940645933151245,
      "learning_rate": 5.0520833333333344e-06,
      "loss": 0.0156,
      "step": 11872
    },
    {
      "epoch": 2.728170955882353,
      "grad_norm": 1.1048651933670044,
      "learning_rate": 5.0515727124183015e-06,
      "loss": 0.0412,
      "step": 11873
    },
    {
      "epoch": 2.7284007352941178,
      "grad_norm": 1.1089224815368652,
      "learning_rate": 5.0510620915032685e-06,
      "loss": 0.0423,
      "step": 11874
    },
    {
      "epoch": 2.7286305147058822,
      "grad_norm": 0.8470520377159119,
      "learning_rate": 5.0505514705882355e-06,
      "loss": 0.0308,
      "step": 11875
    },
    {
      "epoch": 2.728860294117647,
      "grad_norm": 1.0163614749908447,
      "learning_rate": 5.050040849673203e-06,
      "loss": 0.0481,
      "step": 11876
    },
    {
      "epoch": 2.7290900735294117,
      "grad_norm": 0.9824914932250977,
      "learning_rate": 5.04953022875817e-06,
      "loss": 0.0484,
      "step": 11877
    },
    {
      "epoch": 2.7293198529411766,
      "grad_norm": 1.5419222116470337,
      "learning_rate": 5.049019607843137e-06,
      "loss": 0.0621,
      "step": 11878
    },
    {
      "epoch": 2.729549632352941,
      "grad_norm": 1.2198050022125244,
      "learning_rate": 5.048508986928104e-06,
      "loss": 0.0749,
      "step": 11879
    },
    {
      "epoch": 2.7297794117647056,
      "grad_norm": 0.8260977864265442,
      "learning_rate": 5.047998366013073e-06,
      "loss": 0.0247,
      "step": 11880
    },
    {
      "epoch": 2.7300091911764706,
      "grad_norm": 0.8974297046661377,
      "learning_rate": 5.04748774509804e-06,
      "loss": 0.0392,
      "step": 11881
    },
    {
      "epoch": 2.7302389705882355,
      "grad_norm": 1.0909178256988525,
      "learning_rate": 5.046977124183007e-06,
      "loss": 0.0375,
      "step": 11882
    },
    {
      "epoch": 2.73046875,
      "grad_norm": 0.8706563115119934,
      "learning_rate": 5.046466503267974e-06,
      "loss": 0.0311,
      "step": 11883
    },
    {
      "epoch": 2.7306985294117645,
      "grad_norm": 0.5970072746276855,
      "learning_rate": 5.045955882352942e-06,
      "loss": 0.019,
      "step": 11884
    },
    {
      "epoch": 2.7309283088235294,
      "grad_norm": 0.8682546615600586,
      "learning_rate": 5.045445261437909e-06,
      "loss": 0.0333,
      "step": 11885
    },
    {
      "epoch": 2.7311580882352944,
      "grad_norm": 1.440425992012024,
      "learning_rate": 5.044934640522876e-06,
      "loss": 0.0564,
      "step": 11886
    },
    {
      "epoch": 2.731387867647059,
      "grad_norm": 0.9935818314552307,
      "learning_rate": 5.044424019607843e-06,
      "loss": 0.0445,
      "step": 11887
    },
    {
      "epoch": 2.7316176470588234,
      "grad_norm": 0.7496659159660339,
      "learning_rate": 5.043913398692811e-06,
      "loss": 0.0212,
      "step": 11888
    },
    {
      "epoch": 2.7318474264705883,
      "grad_norm": 0.925049364566803,
      "learning_rate": 5.043402777777778e-06,
      "loss": 0.0564,
      "step": 11889
    },
    {
      "epoch": 2.732077205882353,
      "grad_norm": 0.9565902352333069,
      "learning_rate": 5.042892156862745e-06,
      "loss": 0.0379,
      "step": 11890
    },
    {
      "epoch": 2.7323069852941178,
      "grad_norm": 0.8659435510635376,
      "learning_rate": 5.042381535947713e-06,
      "loss": 0.0371,
      "step": 11891
    },
    {
      "epoch": 2.7325367647058822,
      "grad_norm": 1.3167864084243774,
      "learning_rate": 5.041870915032681e-06,
      "loss": 0.028,
      "step": 11892
    },
    {
      "epoch": 2.732766544117647,
      "grad_norm": 1.0476864576339722,
      "learning_rate": 5.041360294117648e-06,
      "loss": 0.0403,
      "step": 11893
    },
    {
      "epoch": 2.7329963235294117,
      "grad_norm": 1.0682834386825562,
      "learning_rate": 5.040849673202615e-06,
      "loss": 0.0393,
      "step": 11894
    },
    {
      "epoch": 2.7332261029411766,
      "grad_norm": 0.9951730966567993,
      "learning_rate": 5.040339052287582e-06,
      "loss": 0.0508,
      "step": 11895
    },
    {
      "epoch": 2.733455882352941,
      "grad_norm": 0.8695606589317322,
      "learning_rate": 5.0398284313725496e-06,
      "loss": 0.0534,
      "step": 11896
    },
    {
      "epoch": 2.7336856617647056,
      "grad_norm": 0.9375710487365723,
      "learning_rate": 5.039317810457517e-06,
      "loss": 0.0255,
      "step": 11897
    },
    {
      "epoch": 2.7339154411764706,
      "grad_norm": 0.7295433282852173,
      "learning_rate": 5.038807189542484e-06,
      "loss": 0.0268,
      "step": 11898
    },
    {
      "epoch": 2.7341452205882355,
      "grad_norm": 1.245587944984436,
      "learning_rate": 5.038296568627451e-06,
      "loss": 0.0572,
      "step": 11899
    },
    {
      "epoch": 2.734375,
      "grad_norm": 0.5782256126403809,
      "learning_rate": 5.037785947712419e-06,
      "loss": 0.0207,
      "step": 11900
    },
    {
      "epoch": 2.7346047794117645,
      "grad_norm": 0.7217608690261841,
      "learning_rate": 5.037275326797386e-06,
      "loss": 0.0429,
      "step": 11901
    },
    {
      "epoch": 2.7348345588235294,
      "grad_norm": 0.9965821504592896,
      "learning_rate": 5.036764705882353e-06,
      "loss": 0.0399,
      "step": 11902
    },
    {
      "epoch": 2.7350643382352944,
      "grad_norm": 1.58640718460083,
      "learning_rate": 5.03625408496732e-06,
      "loss": 0.0634,
      "step": 11903
    },
    {
      "epoch": 2.735294117647059,
      "grad_norm": 1.0077279806137085,
      "learning_rate": 5.035743464052288e-06,
      "loss": 0.0381,
      "step": 11904
    },
    {
      "epoch": 2.7355238970588234,
      "grad_norm": 0.969458818435669,
      "learning_rate": 5.035232843137255e-06,
      "loss": 0.0354,
      "step": 11905
    },
    {
      "epoch": 2.7357536764705883,
      "grad_norm": 1.0856201648712158,
      "learning_rate": 5.034722222222222e-06,
      "loss": 0.0575,
      "step": 11906
    },
    {
      "epoch": 2.735983455882353,
      "grad_norm": 0.9590882658958435,
      "learning_rate": 5.034211601307189e-06,
      "loss": 0.035,
      "step": 11907
    },
    {
      "epoch": 2.7362132352941178,
      "grad_norm": 1.4779037237167358,
      "learning_rate": 5.033700980392158e-06,
      "loss": 0.0523,
      "step": 11908
    },
    {
      "epoch": 2.7364430147058822,
      "grad_norm": 0.8471127152442932,
      "learning_rate": 5.033190359477125e-06,
      "loss": 0.0337,
      "step": 11909
    },
    {
      "epoch": 2.736672794117647,
      "grad_norm": 1.0541696548461914,
      "learning_rate": 5.032679738562092e-06,
      "loss": 0.0399,
      "step": 11910
    },
    {
      "epoch": 2.7369025735294117,
      "grad_norm": 1.0938293933868408,
      "learning_rate": 5.032169117647059e-06,
      "loss": 0.0459,
      "step": 11911
    },
    {
      "epoch": 2.7371323529411766,
      "grad_norm": 1.0444608926773071,
      "learning_rate": 5.031658496732027e-06,
      "loss": 0.0325,
      "step": 11912
    },
    {
      "epoch": 2.737362132352941,
      "grad_norm": 1.0011727809906006,
      "learning_rate": 5.031147875816994e-06,
      "loss": 0.0423,
      "step": 11913
    },
    {
      "epoch": 2.7375919117647056,
      "grad_norm": 0.9799313545227051,
      "learning_rate": 5.030637254901961e-06,
      "loss": 0.0384,
      "step": 11914
    },
    {
      "epoch": 2.7378216911764706,
      "grad_norm": 2.041229248046875,
      "learning_rate": 5.030126633986928e-06,
      "loss": 0.0707,
      "step": 11915
    },
    {
      "epoch": 2.7380514705882355,
      "grad_norm": 1.1785411834716797,
      "learning_rate": 5.029616013071897e-06,
      "loss": 0.0368,
      "step": 11916
    },
    {
      "epoch": 2.73828125,
      "grad_norm": 1.2228301763534546,
      "learning_rate": 5.029105392156864e-06,
      "loss": 0.0419,
      "step": 11917
    },
    {
      "epoch": 2.7385110294117645,
      "grad_norm": 0.7755507826805115,
      "learning_rate": 5.028594771241831e-06,
      "loss": 0.0357,
      "step": 11918
    },
    {
      "epoch": 2.7387408088235294,
      "grad_norm": 0.8541204333305359,
      "learning_rate": 5.028084150326798e-06,
      "loss": 0.0407,
      "step": 11919
    },
    {
      "epoch": 2.7389705882352944,
      "grad_norm": 1.2754203081130981,
      "learning_rate": 5.0275735294117655e-06,
      "loss": 0.0906,
      "step": 11920
    },
    {
      "epoch": 2.739200367647059,
      "grad_norm": 1.0258034467697144,
      "learning_rate": 5.0270629084967326e-06,
      "loss": 0.0487,
      "step": 11921
    },
    {
      "epoch": 2.7394301470588234,
      "grad_norm": 0.9444652795791626,
      "learning_rate": 5.0265522875816996e-06,
      "loss": 0.0364,
      "step": 11922
    },
    {
      "epoch": 2.7396599264705883,
      "grad_norm": 0.9664589166641235,
      "learning_rate": 5.026041666666667e-06,
      "loss": 0.0384,
      "step": 11923
    },
    {
      "epoch": 2.739889705882353,
      "grad_norm": 0.9900614023208618,
      "learning_rate": 5.0255310457516344e-06,
      "loss": 0.0366,
      "step": 11924
    },
    {
      "epoch": 2.7401194852941178,
      "grad_norm": 1.0876452922821045,
      "learning_rate": 5.025020424836602e-06,
      "loss": 0.0435,
      "step": 11925
    },
    {
      "epoch": 2.7403492647058822,
      "grad_norm": 1.197719931602478,
      "learning_rate": 5.024509803921569e-06,
      "loss": 0.0494,
      "step": 11926
    },
    {
      "epoch": 2.740579044117647,
      "grad_norm": 0.808664858341217,
      "learning_rate": 5.023999183006536e-06,
      "loss": 0.0391,
      "step": 11927
    },
    {
      "epoch": 2.7408088235294117,
      "grad_norm": 1.6331861019134521,
      "learning_rate": 5.023488562091504e-06,
      "loss": 0.0411,
      "step": 11928
    },
    {
      "epoch": 2.7410386029411766,
      "grad_norm": 0.8071765303611755,
      "learning_rate": 5.022977941176471e-06,
      "loss": 0.033,
      "step": 11929
    },
    {
      "epoch": 2.741268382352941,
      "grad_norm": 0.7470616102218628,
      "learning_rate": 5.022467320261438e-06,
      "loss": 0.023,
      "step": 11930
    },
    {
      "epoch": 2.7414981617647056,
      "grad_norm": 1.1444772481918335,
      "learning_rate": 5.021956699346405e-06,
      "loss": 0.0351,
      "step": 11931
    },
    {
      "epoch": 2.7417279411764706,
      "grad_norm": 0.946650505065918,
      "learning_rate": 5.021446078431373e-06,
      "loss": 0.0415,
      "step": 11932
    },
    {
      "epoch": 2.7419577205882355,
      "grad_norm": 0.812039852142334,
      "learning_rate": 5.02093545751634e-06,
      "loss": 0.038,
      "step": 11933
    },
    {
      "epoch": 2.7421875,
      "grad_norm": 0.9846711754798889,
      "learning_rate": 5.020424836601307e-06,
      "loss": 0.0482,
      "step": 11934
    },
    {
      "epoch": 2.7424172794117645,
      "grad_norm": 0.8306106925010681,
      "learning_rate": 5.019914215686275e-06,
      "loss": 0.0316,
      "step": 11935
    },
    {
      "epoch": 2.7426470588235294,
      "grad_norm": 1.2235275506973267,
      "learning_rate": 5.019403594771243e-06,
      "loss": 0.0495,
      "step": 11936
    },
    {
      "epoch": 2.7428768382352944,
      "grad_norm": 1.0898057222366333,
      "learning_rate": 5.01889297385621e-06,
      "loss": 0.0514,
      "step": 11937
    },
    {
      "epoch": 2.743106617647059,
      "grad_norm": 0.915490984916687,
      "learning_rate": 5.018382352941177e-06,
      "loss": 0.0399,
      "step": 11938
    },
    {
      "epoch": 2.7433363970588234,
      "grad_norm": 0.6991997361183167,
      "learning_rate": 5.017871732026144e-06,
      "loss": 0.0298,
      "step": 11939
    },
    {
      "epoch": 2.7435661764705883,
      "grad_norm": 1.2728413343429565,
      "learning_rate": 5.017361111111112e-06,
      "loss": 0.0409,
      "step": 11940
    },
    {
      "epoch": 2.743795955882353,
      "grad_norm": 0.9723066091537476,
      "learning_rate": 5.016850490196079e-06,
      "loss": 0.0395,
      "step": 11941
    },
    {
      "epoch": 2.7440257352941178,
      "grad_norm": 1.058842658996582,
      "learning_rate": 5.016339869281046e-06,
      "loss": 0.066,
      "step": 11942
    },
    {
      "epoch": 2.7442555147058822,
      "grad_norm": 1.1428250074386597,
      "learning_rate": 5.015829248366013e-06,
      "loss": 0.062,
      "step": 11943
    },
    {
      "epoch": 2.744485294117647,
      "grad_norm": 1.2822256088256836,
      "learning_rate": 5.0153186274509815e-06,
      "loss": 0.0562,
      "step": 11944
    },
    {
      "epoch": 2.7447150735294117,
      "grad_norm": 0.8283197283744812,
      "learning_rate": 5.0148080065359485e-06,
      "loss": 0.0303,
      "step": 11945
    },
    {
      "epoch": 2.7449448529411766,
      "grad_norm": 0.718351423740387,
      "learning_rate": 5.0142973856209155e-06,
      "loss": 0.0268,
      "step": 11946
    },
    {
      "epoch": 2.745174632352941,
      "grad_norm": 0.7064782977104187,
      "learning_rate": 5.0137867647058825e-06,
      "loss": 0.0361,
      "step": 11947
    },
    {
      "epoch": 2.7454044117647056,
      "grad_norm": 0.9174840450286865,
      "learning_rate": 5.01327614379085e-06,
      "loss": 0.0309,
      "step": 11948
    },
    {
      "epoch": 2.7456341911764706,
      "grad_norm": 1.0749766826629639,
      "learning_rate": 5.0127655228758174e-06,
      "loss": 0.0453,
      "step": 11949
    },
    {
      "epoch": 2.7458639705882355,
      "grad_norm": 1.04696786403656,
      "learning_rate": 5.0122549019607844e-06,
      "loss": 0.0233,
      "step": 11950
    },
    {
      "epoch": 2.74609375,
      "grad_norm": 0.7824094295501709,
      "learning_rate": 5.0117442810457515e-06,
      "loss": 0.0361,
      "step": 11951
    },
    {
      "epoch": 2.7463235294117645,
      "grad_norm": 1.019411325454712,
      "learning_rate": 5.01123366013072e-06,
      "loss": 0.0278,
      "step": 11952
    },
    {
      "epoch": 2.7465533088235294,
      "grad_norm": 1.2965041399002075,
      "learning_rate": 5.010723039215687e-06,
      "loss": 0.0497,
      "step": 11953
    },
    {
      "epoch": 2.7467830882352944,
      "grad_norm": 1.1037520170211792,
      "learning_rate": 5.010212418300654e-06,
      "loss": 0.0361,
      "step": 11954
    },
    {
      "epoch": 2.747012867647059,
      "grad_norm": 0.7973174452781677,
      "learning_rate": 5.009701797385621e-06,
      "loss": 0.0383,
      "step": 11955
    },
    {
      "epoch": 2.7472426470588234,
      "grad_norm": 1.040258765220642,
      "learning_rate": 5.009191176470589e-06,
      "loss": 0.0423,
      "step": 11956
    },
    {
      "epoch": 2.7474724264705883,
      "grad_norm": 1.7431368827819824,
      "learning_rate": 5.008680555555556e-06,
      "loss": 0.0251,
      "step": 11957
    },
    {
      "epoch": 2.747702205882353,
      "grad_norm": 0.8761784434318542,
      "learning_rate": 5.008169934640523e-06,
      "loss": 0.0334,
      "step": 11958
    },
    {
      "epoch": 2.7479319852941178,
      "grad_norm": 0.8284948468208313,
      "learning_rate": 5.00765931372549e-06,
      "loss": 0.0187,
      "step": 11959
    },
    {
      "epoch": 2.7481617647058822,
      "grad_norm": 1.289930820465088,
      "learning_rate": 5.007148692810459e-06,
      "loss": 0.0496,
      "step": 11960
    },
    {
      "epoch": 2.748391544117647,
      "grad_norm": 0.9146247506141663,
      "learning_rate": 5.006638071895426e-06,
      "loss": 0.0233,
      "step": 11961
    },
    {
      "epoch": 2.7486213235294117,
      "grad_norm": 1.2495718002319336,
      "learning_rate": 5.006127450980393e-06,
      "loss": 0.0642,
      "step": 11962
    },
    {
      "epoch": 2.7488511029411766,
      "grad_norm": 1.1578675508499146,
      "learning_rate": 5.00561683006536e-06,
      "loss": 0.0401,
      "step": 11963
    },
    {
      "epoch": 2.749080882352941,
      "grad_norm": 0.945806086063385,
      "learning_rate": 5.005106209150328e-06,
      "loss": 0.0452,
      "step": 11964
    },
    {
      "epoch": 2.7493106617647056,
      "grad_norm": 0.97463458776474,
      "learning_rate": 5.004595588235295e-06,
      "loss": 0.0353,
      "step": 11965
    },
    {
      "epoch": 2.7495404411764706,
      "grad_norm": 0.6477546095848083,
      "learning_rate": 5.004084967320262e-06,
      "loss": 0.0352,
      "step": 11966
    },
    {
      "epoch": 2.7497702205882355,
      "grad_norm": 1.1241995096206665,
      "learning_rate": 5.003574346405229e-06,
      "loss": 0.045,
      "step": 11967
    },
    {
      "epoch": 2.75,
      "grad_norm": 1.038657784461975,
      "learning_rate": 5.003063725490197e-06,
      "loss": 0.0541,
      "step": 11968
    },
    {
      "epoch": 2.7502297794117645,
      "grad_norm": 0.8802235126495361,
      "learning_rate": 5.0025531045751645e-06,
      "loss": 0.0434,
      "step": 11969
    },
    {
      "epoch": 2.7504595588235294,
      "grad_norm": 0.9943229556083679,
      "learning_rate": 5.0020424836601315e-06,
      "loss": 0.051,
      "step": 11970
    },
    {
      "epoch": 2.7506893382352944,
      "grad_norm": 1.1676256656646729,
      "learning_rate": 5.0015318627450985e-06,
      "loss": 0.0399,
      "step": 11971
    },
    {
      "epoch": 2.750919117647059,
      "grad_norm": 1.1751974821090698,
      "learning_rate": 5.001021241830066e-06,
      "loss": 0.0615,
      "step": 11972
    },
    {
      "epoch": 2.7511488970588234,
      "grad_norm": 0.8684673309326172,
      "learning_rate": 5.000510620915033e-06,
      "loss": 0.0387,
      "step": 11973
    },
    {
      "epoch": 2.7513786764705883,
      "grad_norm": 0.7648904323577881,
      "learning_rate": 5e-06,
      "loss": 0.0354,
      "step": 11974
    },
    {
      "epoch": 2.751608455882353,
      "grad_norm": 1.2515332698822021,
      "learning_rate": 4.999489379084967e-06,
      "loss": 0.0281,
      "step": 11975
    },
    {
      "epoch": 2.7518382352941178,
      "grad_norm": 1.1250489950180054,
      "learning_rate": 4.998978758169935e-06,
      "loss": 0.0636,
      "step": 11976
    },
    {
      "epoch": 2.7520680147058822,
      "grad_norm": 1.9127655029296875,
      "learning_rate": 4.998468137254902e-06,
      "loss": 0.0612,
      "step": 11977
    },
    {
      "epoch": 2.752297794117647,
      "grad_norm": 1.1893136501312256,
      "learning_rate": 4.997957516339869e-06,
      "loss": 0.0512,
      "step": 11978
    },
    {
      "epoch": 2.7525275735294117,
      "grad_norm": 1.228704571723938,
      "learning_rate": 4.997446895424836e-06,
      "loss": 0.0435,
      "step": 11979
    },
    {
      "epoch": 2.7527573529411766,
      "grad_norm": 0.8883818984031677,
      "learning_rate": 4.996936274509804e-06,
      "loss": 0.0384,
      "step": 11980
    },
    {
      "epoch": 2.752987132352941,
      "grad_norm": 1.089706301689148,
      "learning_rate": 4.996425653594771e-06,
      "loss": 0.0395,
      "step": 11981
    },
    {
      "epoch": 2.7532169117647056,
      "grad_norm": 0.7938096523284912,
      "learning_rate": 4.995915032679739e-06,
      "loss": 0.0406,
      "step": 11982
    },
    {
      "epoch": 2.7534466911764706,
      "grad_norm": 1.1288729906082153,
      "learning_rate": 4.995404411764706e-06,
      "loss": 0.0346,
      "step": 11983
    },
    {
      "epoch": 2.7536764705882355,
      "grad_norm": 0.7483994364738464,
      "learning_rate": 4.994893790849674e-06,
      "loss": 0.0465,
      "step": 11984
    },
    {
      "epoch": 2.75390625,
      "grad_norm": 0.9851988554000854,
      "learning_rate": 4.994383169934641e-06,
      "loss": 0.0386,
      "step": 11985
    },
    {
      "epoch": 2.7541360294117645,
      "grad_norm": 0.9559573531150818,
      "learning_rate": 4.993872549019608e-06,
      "loss": 0.0427,
      "step": 11986
    },
    {
      "epoch": 2.7543658088235294,
      "grad_norm": 0.9416896104812622,
      "learning_rate": 4.993361928104575e-06,
      "loss": 0.0324,
      "step": 11987
    },
    {
      "epoch": 2.7545955882352944,
      "grad_norm": 0.9200868606567383,
      "learning_rate": 4.992851307189543e-06,
      "loss": 0.039,
      "step": 11988
    },
    {
      "epoch": 2.754825367647059,
      "grad_norm": 1.17721426486969,
      "learning_rate": 4.99234068627451e-06,
      "loss": 0.0512,
      "step": 11989
    },
    {
      "epoch": 2.7550551470588234,
      "grad_norm": 0.9282509088516235,
      "learning_rate": 4.991830065359478e-06,
      "loss": 0.0329,
      "step": 11990
    },
    {
      "epoch": 2.7552849264705883,
      "grad_norm": 1.3027489185333252,
      "learning_rate": 4.991319444444445e-06,
      "loss": 0.0509,
      "step": 11991
    },
    {
      "epoch": 2.755514705882353,
      "grad_norm": 0.9344802498817444,
      "learning_rate": 4.990808823529413e-06,
      "loss": 0.0371,
      "step": 11992
    },
    {
      "epoch": 2.7557444852941178,
      "grad_norm": 1.371228814125061,
      "learning_rate": 4.99029820261438e-06,
      "loss": 0.0816,
      "step": 11993
    },
    {
      "epoch": 2.7559742647058822,
      "grad_norm": 0.8749962449073792,
      "learning_rate": 4.989787581699347e-06,
      "loss": 0.028,
      "step": 11994
    },
    {
      "epoch": 2.756204044117647,
      "grad_norm": 0.6891665458679199,
      "learning_rate": 4.989276960784314e-06,
      "loss": 0.0195,
      "step": 11995
    },
    {
      "epoch": 2.7564338235294117,
      "grad_norm": 0.8182868957519531,
      "learning_rate": 4.9887663398692815e-06,
      "loss": 0.0382,
      "step": 11996
    },
    {
      "epoch": 2.7566636029411766,
      "grad_norm": 0.9220894575119019,
      "learning_rate": 4.9882557189542485e-06,
      "loss": 0.0366,
      "step": 11997
    },
    {
      "epoch": 2.756893382352941,
      "grad_norm": 1.248664379119873,
      "learning_rate": 4.987745098039216e-06,
      "loss": 0.0439,
      "step": 11998
    },
    {
      "epoch": 2.7571231617647056,
      "grad_norm": 1.6960046291351318,
      "learning_rate": 4.987234477124183e-06,
      "loss": 0.0477,
      "step": 11999
    },
    {
      "epoch": 2.7573529411764706,
      "grad_norm": 0.7429404258728027,
      "learning_rate": 4.98672385620915e-06,
      "loss": 0.0241,
      "step": 12000
    },
    {
      "epoch": 2.7573529411764706,
      "eval_loss": 0.04444612190127373,
      "eval_runtime": 2006.1237,
      "eval_samples_per_second": 4.439,
      "eval_steps_per_second": 2.22,
      "step": 12000
    },
    {
      "epoch": 2.7575827205882355,
      "grad_norm": 1.015625238418579,
      "learning_rate": 4.986213235294117e-06,
      "loss": 0.0335,
      "step": 12001
    },
    {
      "epoch": 2.7578125,
      "grad_norm": 0.6773311495780945,
      "learning_rate": 4.985702614379085e-06,
      "loss": 0.028,
      "step": 12002
    },
    {
      "epoch": 2.7580422794117645,
      "grad_norm": 0.7462339997291565,
      "learning_rate": 4.985191993464052e-06,
      "loss": 0.0346,
      "step": 12003
    },
    {
      "epoch": 2.7582720588235294,
      "grad_norm": 0.8693113327026367,
      "learning_rate": 4.98468137254902e-06,
      "loss": 0.0537,
      "step": 12004
    },
    {
      "epoch": 2.7585018382352944,
      "grad_norm": 1.0299713611602783,
      "learning_rate": 4.984170751633987e-06,
      "loss": 0.0359,
      "step": 12005
    },
    {
      "epoch": 2.758731617647059,
      "grad_norm": 1.317055106163025,
      "learning_rate": 4.983660130718955e-06,
      "loss": 0.0444,
      "step": 12006
    },
    {
      "epoch": 2.7589613970588234,
      "grad_norm": 0.9393401741981506,
      "learning_rate": 4.983149509803922e-06,
      "loss": 0.0517,
      "step": 12007
    },
    {
      "epoch": 2.7591911764705883,
      "grad_norm": 1.0987523794174194,
      "learning_rate": 4.982638888888889e-06,
      "loss": 0.0361,
      "step": 12008
    },
    {
      "epoch": 2.759420955882353,
      "grad_norm": 1.1880947351455688,
      "learning_rate": 4.982128267973856e-06,
      "loss": 0.0476,
      "step": 12009
    },
    {
      "epoch": 2.7596507352941178,
      "grad_norm": 0.8930673003196716,
      "learning_rate": 4.981617647058824e-06,
      "loss": 0.0355,
      "step": 12010
    },
    {
      "epoch": 2.7598805147058822,
      "grad_norm": 1.3344905376434326,
      "learning_rate": 4.981107026143791e-06,
      "loss": 0.0625,
      "step": 12011
    },
    {
      "epoch": 2.760110294117647,
      "grad_norm": 0.9395694732666016,
      "learning_rate": 4.980596405228759e-06,
      "loss": 0.0362,
      "step": 12012
    },
    {
      "epoch": 2.7603400735294117,
      "grad_norm": 0.6884341835975647,
      "learning_rate": 4.980085784313726e-06,
      "loss": 0.0301,
      "step": 12013
    },
    {
      "epoch": 2.7605698529411766,
      "grad_norm": 0.7931740880012512,
      "learning_rate": 4.979575163398694e-06,
      "loss": 0.0146,
      "step": 12014
    },
    {
      "epoch": 2.760799632352941,
      "grad_norm": 0.9811141490936279,
      "learning_rate": 4.979064542483661e-06,
      "loss": 0.0418,
      "step": 12015
    },
    {
      "epoch": 2.7610294117647056,
      "grad_norm": 0.9073314070701599,
      "learning_rate": 4.978553921568628e-06,
      "loss": 0.0321,
      "step": 12016
    },
    {
      "epoch": 2.7612591911764706,
      "grad_norm": 1.0016928911209106,
      "learning_rate": 4.978043300653595e-06,
      "loss": 0.0419,
      "step": 12017
    },
    {
      "epoch": 2.7614889705882355,
      "grad_norm": 0.6964641213417053,
      "learning_rate": 4.977532679738563e-06,
      "loss": 0.0342,
      "step": 12018
    },
    {
      "epoch": 2.76171875,
      "grad_norm": 0.7093384861946106,
      "learning_rate": 4.97702205882353e-06,
      "loss": 0.03,
      "step": 12019
    },
    {
      "epoch": 2.7619485294117645,
      "grad_norm": 0.9586435556411743,
      "learning_rate": 4.9765114379084975e-06,
      "loss": 0.0409,
      "step": 12020
    },
    {
      "epoch": 2.7621783088235294,
      "grad_norm": 0.7973924279212952,
      "learning_rate": 4.9760008169934645e-06,
      "loss": 0.0291,
      "step": 12021
    },
    {
      "epoch": 2.7624080882352944,
      "grad_norm": 0.837060272693634,
      "learning_rate": 4.9754901960784315e-06,
      "loss": 0.0293,
      "step": 12022
    },
    {
      "epoch": 2.762637867647059,
      "grad_norm": 0.8937405347824097,
      "learning_rate": 4.9749795751633985e-06,
      "loss": 0.0337,
      "step": 12023
    },
    {
      "epoch": 2.7628676470588234,
      "grad_norm": 1.4435516595840454,
      "learning_rate": 4.974468954248366e-06,
      "loss": 0.0735,
      "step": 12024
    },
    {
      "epoch": 2.7630974264705883,
      "grad_norm": 0.7780578136444092,
      "learning_rate": 4.973958333333333e-06,
      "loss": 0.0351,
      "step": 12025
    },
    {
      "epoch": 2.763327205882353,
      "grad_norm": 1.1358824968338013,
      "learning_rate": 4.973447712418301e-06,
      "loss": 0.0626,
      "step": 12026
    },
    {
      "epoch": 2.7635569852941178,
      "grad_norm": 0.7923478484153748,
      "learning_rate": 4.972937091503268e-06,
      "loss": 0.0455,
      "step": 12027
    },
    {
      "epoch": 2.7637867647058822,
      "grad_norm": 1.0068613290786743,
      "learning_rate": 4.972426470588236e-06,
      "loss": 0.043,
      "step": 12028
    },
    {
      "epoch": 2.764016544117647,
      "grad_norm": 1.101114273071289,
      "learning_rate": 4.971915849673203e-06,
      "loss": 0.0353,
      "step": 12029
    },
    {
      "epoch": 2.7642463235294117,
      "grad_norm": 0.6559021472930908,
      "learning_rate": 4.97140522875817e-06,
      "loss": 0.0217,
      "step": 12030
    },
    {
      "epoch": 2.7644761029411766,
      "grad_norm": 0.9935383796691895,
      "learning_rate": 4.970894607843137e-06,
      "loss": 0.0424,
      "step": 12031
    },
    {
      "epoch": 2.764705882352941,
      "grad_norm": 1.0194979906082153,
      "learning_rate": 4.970383986928105e-06,
      "loss": 0.0275,
      "step": 12032
    },
    {
      "epoch": 2.7649356617647056,
      "grad_norm": 0.7876886129379272,
      "learning_rate": 4.969873366013072e-06,
      "loss": 0.0419,
      "step": 12033
    },
    {
      "epoch": 2.7651654411764706,
      "grad_norm": 1.1040664911270142,
      "learning_rate": 4.96936274509804e-06,
      "loss": 0.0524,
      "step": 12034
    },
    {
      "epoch": 2.7653952205882355,
      "grad_norm": 0.9596403241157532,
      "learning_rate": 4.968852124183007e-06,
      "loss": 0.0368,
      "step": 12035
    },
    {
      "epoch": 2.765625,
      "grad_norm": 1.1024982929229736,
      "learning_rate": 4.968341503267975e-06,
      "loss": 0.0539,
      "step": 12036
    },
    {
      "epoch": 2.7658547794117645,
      "grad_norm": 0.9241881966590881,
      "learning_rate": 4.967830882352942e-06,
      "loss": 0.0386,
      "step": 12037
    },
    {
      "epoch": 2.7660845588235294,
      "grad_norm": 0.8297303915023804,
      "learning_rate": 4.967320261437909e-06,
      "loss": 0.0358,
      "step": 12038
    },
    {
      "epoch": 2.7663143382352944,
      "grad_norm": 0.7714031934738159,
      "learning_rate": 4.966809640522876e-06,
      "loss": 0.0236,
      "step": 12039
    },
    {
      "epoch": 2.766544117647059,
      "grad_norm": 1.273451566696167,
      "learning_rate": 4.966299019607844e-06,
      "loss": 0.0536,
      "step": 12040
    },
    {
      "epoch": 2.7667738970588234,
      "grad_norm": 0.7188438773155212,
      "learning_rate": 4.965788398692811e-06,
      "loss": 0.0251,
      "step": 12041
    },
    {
      "epoch": 2.7670036764705883,
      "grad_norm": 0.829984188079834,
      "learning_rate": 4.9652777777777786e-06,
      "loss": 0.0373,
      "step": 12042
    },
    {
      "epoch": 2.767233455882353,
      "grad_norm": 0.7396655678749084,
      "learning_rate": 4.964767156862746e-06,
      "loss": 0.0395,
      "step": 12043
    },
    {
      "epoch": 2.7674632352941178,
      "grad_norm": 0.805223286151886,
      "learning_rate": 4.964256535947713e-06,
      "loss": 0.0319,
      "step": 12044
    },
    {
      "epoch": 2.7676930147058822,
      "grad_norm": 1.382891297340393,
      "learning_rate": 4.96374591503268e-06,
      "loss": 0.044,
      "step": 12045
    },
    {
      "epoch": 2.767922794117647,
      "grad_norm": 0.8772612810134888,
      "learning_rate": 4.9632352941176475e-06,
      "loss": 0.0265,
      "step": 12046
    },
    {
      "epoch": 2.7681525735294117,
      "grad_norm": 1.0518437623977661,
      "learning_rate": 4.9627246732026145e-06,
      "loss": 0.0412,
      "step": 12047
    },
    {
      "epoch": 2.7683823529411766,
      "grad_norm": 1.3252665996551514,
      "learning_rate": 4.962214052287582e-06,
      "loss": 0.0618,
      "step": 12048
    },
    {
      "epoch": 2.768612132352941,
      "grad_norm": 1.0544848442077637,
      "learning_rate": 4.961703431372549e-06,
      "loss": 0.0365,
      "step": 12049
    },
    {
      "epoch": 2.7688419117647056,
      "grad_norm": 0.9163448214530945,
      "learning_rate": 4.961192810457517e-06,
      "loss": 0.0504,
      "step": 12050
    },
    {
      "epoch": 2.7690716911764706,
      "grad_norm": 1.1897978782653809,
      "learning_rate": 4.960682189542484e-06,
      "loss": 0.0585,
      "step": 12051
    },
    {
      "epoch": 2.7693014705882355,
      "grad_norm": 1.0259339809417725,
      "learning_rate": 4.960171568627451e-06,
      "loss": 0.0421,
      "step": 12052
    },
    {
      "epoch": 2.76953125,
      "grad_norm": 0.8495569229125977,
      "learning_rate": 4.959660947712418e-06,
      "loss": 0.0399,
      "step": 12053
    },
    {
      "epoch": 2.7697610294117645,
      "grad_norm": 0.9061691761016846,
      "learning_rate": 4.959150326797386e-06,
      "loss": 0.0427,
      "step": 12054
    },
    {
      "epoch": 2.7699908088235294,
      "grad_norm": 0.7921795845031738,
      "learning_rate": 4.958639705882353e-06,
      "loss": 0.0271,
      "step": 12055
    },
    {
      "epoch": 2.7702205882352944,
      "grad_norm": 1.0095536708831787,
      "learning_rate": 4.958129084967321e-06,
      "loss": 0.0316,
      "step": 12056
    },
    {
      "epoch": 2.770450367647059,
      "grad_norm": 1.0817946195602417,
      "learning_rate": 4.957618464052288e-06,
      "loss": 0.0439,
      "step": 12057
    },
    {
      "epoch": 2.7706801470588234,
      "grad_norm": 1.1299556493759155,
      "learning_rate": 4.957107843137256e-06,
      "loss": 0.0495,
      "step": 12058
    },
    {
      "epoch": 2.7709099264705883,
      "grad_norm": 0.9987715482711792,
      "learning_rate": 4.956597222222223e-06,
      "loss": 0.0597,
      "step": 12059
    },
    {
      "epoch": 2.771139705882353,
      "grad_norm": 0.8201766014099121,
      "learning_rate": 4.95608660130719e-06,
      "loss": 0.034,
      "step": 12060
    },
    {
      "epoch": 2.7713694852941178,
      "grad_norm": 1.3405046463012695,
      "learning_rate": 4.955575980392157e-06,
      "loss": 0.0629,
      "step": 12061
    },
    {
      "epoch": 2.7715992647058822,
      "grad_norm": 0.7132400870323181,
      "learning_rate": 4.955065359477125e-06,
      "loss": 0.0243,
      "step": 12062
    },
    {
      "epoch": 2.771829044117647,
      "grad_norm": 1.1444551944732666,
      "learning_rate": 4.954554738562092e-06,
      "loss": 0.0462,
      "step": 12063
    },
    {
      "epoch": 2.7720588235294117,
      "grad_norm": 1.1426106691360474,
      "learning_rate": 4.95404411764706e-06,
      "loss": 0.0567,
      "step": 12064
    },
    {
      "epoch": 2.7722886029411766,
      "grad_norm": 0.7749243974685669,
      "learning_rate": 4.953533496732027e-06,
      "loss": 0.0355,
      "step": 12065
    },
    {
      "epoch": 2.772518382352941,
      "grad_norm": 1.0142136812210083,
      "learning_rate": 4.953022875816994e-06,
      "loss": 0.043,
      "step": 12066
    },
    {
      "epoch": 2.7727481617647056,
      "grad_norm": 0.9628939032554626,
      "learning_rate": 4.952512254901961e-06,
      "loss": 0.0469,
      "step": 12067
    },
    {
      "epoch": 2.7729779411764706,
      "grad_norm": 0.7567558884620667,
      "learning_rate": 4.9520016339869286e-06,
      "loss": 0.0352,
      "step": 12068
    },
    {
      "epoch": 2.7732077205882355,
      "grad_norm": 1.2926199436187744,
      "learning_rate": 4.951491013071896e-06,
      "loss": 0.0538,
      "step": 12069
    },
    {
      "epoch": 2.7734375,
      "grad_norm": 0.7386723756790161,
      "learning_rate": 4.9509803921568634e-06,
      "loss": 0.0378,
      "step": 12070
    },
    {
      "epoch": 2.7736672794117645,
      "grad_norm": 1.5481853485107422,
      "learning_rate": 4.9504697712418305e-06,
      "loss": 0.0437,
      "step": 12071
    },
    {
      "epoch": 2.7738970588235294,
      "grad_norm": 0.7726816534996033,
      "learning_rate": 4.949959150326798e-06,
      "loss": 0.0176,
      "step": 12072
    },
    {
      "epoch": 2.7741268382352944,
      "grad_norm": 1.352656602859497,
      "learning_rate": 4.949448529411765e-06,
      "loss": 0.0542,
      "step": 12073
    },
    {
      "epoch": 2.774356617647059,
      "grad_norm": 0.8429611921310425,
      "learning_rate": 4.948937908496732e-06,
      "loss": 0.0429,
      "step": 12074
    },
    {
      "epoch": 2.7745863970588234,
      "grad_norm": 0.8574904203414917,
      "learning_rate": 4.948427287581699e-06,
      "loss": 0.0416,
      "step": 12075
    },
    {
      "epoch": 2.7748161764705883,
      "grad_norm": 0.661440372467041,
      "learning_rate": 4.947916666666667e-06,
      "loss": 0.026,
      "step": 12076
    },
    {
      "epoch": 2.775045955882353,
      "grad_norm": 1.1090167760849,
      "learning_rate": 4.947406045751634e-06,
      "loss": 0.0586,
      "step": 12077
    },
    {
      "epoch": 2.7752757352941178,
      "grad_norm": 0.8123332262039185,
      "learning_rate": 4.946895424836602e-06,
      "loss": 0.0348,
      "step": 12078
    },
    {
      "epoch": 2.7755055147058822,
      "grad_norm": 0.8656630516052246,
      "learning_rate": 4.946384803921569e-06,
      "loss": 0.0331,
      "step": 12079
    },
    {
      "epoch": 2.775735294117647,
      "grad_norm": 1.2619225978851318,
      "learning_rate": 4.945874183006536e-06,
      "loss": 0.0544,
      "step": 12080
    },
    {
      "epoch": 2.7759650735294117,
      "grad_norm": 0.8194150328636169,
      "learning_rate": 4.945363562091504e-06,
      "loss": 0.0305,
      "step": 12081
    },
    {
      "epoch": 2.7761948529411766,
      "grad_norm": 0.7805039286613464,
      "learning_rate": 4.944852941176471e-06,
      "loss": 0.0384,
      "step": 12082
    },
    {
      "epoch": 2.776424632352941,
      "grad_norm": 0.5236833095550537,
      "learning_rate": 4.944342320261438e-06,
      "loss": 0.0201,
      "step": 12083
    },
    {
      "epoch": 2.7766544117647056,
      "grad_norm": 0.8086005449295044,
      "learning_rate": 4.943831699346406e-06,
      "loss": 0.0411,
      "step": 12084
    },
    {
      "epoch": 2.7768841911764706,
      "grad_norm": 1.0463711023330688,
      "learning_rate": 4.943321078431373e-06,
      "loss": 0.0425,
      "step": 12085
    },
    {
      "epoch": 2.7771139705882355,
      "grad_norm": 0.8184342980384827,
      "learning_rate": 4.942810457516341e-06,
      "loss": 0.0472,
      "step": 12086
    },
    {
      "epoch": 2.77734375,
      "grad_norm": 0.8599852919578552,
      "learning_rate": 4.942299836601308e-06,
      "loss": 0.0334,
      "step": 12087
    },
    {
      "epoch": 2.7775735294117645,
      "grad_norm": 0.906001627445221,
      "learning_rate": 4.941789215686275e-06,
      "loss": 0.0354,
      "step": 12088
    },
    {
      "epoch": 2.7778033088235294,
      "grad_norm": 1.0067216157913208,
      "learning_rate": 4.941278594771242e-06,
      "loss": 0.0481,
      "step": 12089
    },
    {
      "epoch": 2.7780330882352944,
      "grad_norm": 0.982322633266449,
      "learning_rate": 4.94076797385621e-06,
      "loss": 0.0445,
      "step": 12090
    },
    {
      "epoch": 2.778262867647059,
      "grad_norm": 0.7824245691299438,
      "learning_rate": 4.940257352941177e-06,
      "loss": 0.0221,
      "step": 12091
    },
    {
      "epoch": 2.7784926470588234,
      "grad_norm": 1.0343598127365112,
      "learning_rate": 4.9397467320261445e-06,
      "loss": 0.0427,
      "step": 12092
    },
    {
      "epoch": 2.7787224264705883,
      "grad_norm": 0.9666479825973511,
      "learning_rate": 4.9392361111111115e-06,
      "loss": 0.0312,
      "step": 12093
    },
    {
      "epoch": 2.778952205882353,
      "grad_norm": 0.901795506477356,
      "learning_rate": 4.938725490196079e-06,
      "loss": 0.0488,
      "step": 12094
    },
    {
      "epoch": 2.7791819852941178,
      "grad_norm": 0.9630973935127258,
      "learning_rate": 4.9382148692810464e-06,
      "loss": 0.0392,
      "step": 12095
    },
    {
      "epoch": 2.7794117647058822,
      "grad_norm": 0.7810278534889221,
      "learning_rate": 4.9377042483660134e-06,
      "loss": 0.0257,
      "step": 12096
    },
    {
      "epoch": 2.779641544117647,
      "grad_norm": 0.7097760438919067,
      "learning_rate": 4.9371936274509805e-06,
      "loss": 0.0338,
      "step": 12097
    },
    {
      "epoch": 2.7798713235294117,
      "grad_norm": 1.2391873598098755,
      "learning_rate": 4.936683006535948e-06,
      "loss": 0.053,
      "step": 12098
    },
    {
      "epoch": 2.7801011029411766,
      "grad_norm": 0.9641627073287964,
      "learning_rate": 4.936172385620915e-06,
      "loss": 0.0419,
      "step": 12099
    },
    {
      "epoch": 2.780330882352941,
      "grad_norm": 1.0185229778289795,
      "learning_rate": 4.935661764705883e-06,
      "loss": 0.0538,
      "step": 12100
    },
    {
      "epoch": 2.7805606617647056,
      "grad_norm": 0.9338609576225281,
      "learning_rate": 4.93515114379085e-06,
      "loss": 0.0398,
      "step": 12101
    },
    {
      "epoch": 2.7807904411764706,
      "grad_norm": 1.6169703006744385,
      "learning_rate": 4.934640522875817e-06,
      "loss": 0.0681,
      "step": 12102
    },
    {
      "epoch": 2.7810202205882355,
      "grad_norm": 0.7783387899398804,
      "learning_rate": 4.934129901960785e-06,
      "loss": 0.053,
      "step": 12103
    },
    {
      "epoch": 2.78125,
      "grad_norm": 0.9981479048728943,
      "learning_rate": 4.933619281045752e-06,
      "loss": 0.0642,
      "step": 12104
    },
    {
      "epoch": 2.7814797794117645,
      "grad_norm": 1.1275869607925415,
      "learning_rate": 4.933108660130719e-06,
      "loss": 0.0407,
      "step": 12105
    },
    {
      "epoch": 2.7817095588235294,
      "grad_norm": 1.021781325340271,
      "learning_rate": 4.932598039215687e-06,
      "loss": 0.0578,
      "step": 12106
    },
    {
      "epoch": 2.7819393382352944,
      "grad_norm": 1.3515253067016602,
      "learning_rate": 4.932087418300654e-06,
      "loss": 0.054,
      "step": 12107
    },
    {
      "epoch": 2.782169117647059,
      "grad_norm": 0.8769814968109131,
      "learning_rate": 4.931576797385622e-06,
      "loss": 0.0208,
      "step": 12108
    },
    {
      "epoch": 2.7823988970588234,
      "grad_norm": 1.0830512046813965,
      "learning_rate": 4.931066176470589e-06,
      "loss": 0.0733,
      "step": 12109
    },
    {
      "epoch": 2.7826286764705883,
      "grad_norm": 0.8143881559371948,
      "learning_rate": 4.930555555555556e-06,
      "loss": 0.0344,
      "step": 12110
    },
    {
      "epoch": 2.782858455882353,
      "grad_norm": 0.9984893202781677,
      "learning_rate": 4.930044934640523e-06,
      "loss": 0.0307,
      "step": 12111
    },
    {
      "epoch": 2.7830882352941178,
      "grad_norm": 0.9620746970176697,
      "learning_rate": 4.929534313725491e-06,
      "loss": 0.0341,
      "step": 12112
    },
    {
      "epoch": 2.7833180147058822,
      "grad_norm": 0.7467537522315979,
      "learning_rate": 4.929023692810458e-06,
      "loss": 0.0218,
      "step": 12113
    },
    {
      "epoch": 2.783547794117647,
      "grad_norm": 0.843756914138794,
      "learning_rate": 4.928513071895426e-06,
      "loss": 0.0275,
      "step": 12114
    },
    {
      "epoch": 2.7837775735294117,
      "grad_norm": 0.9157576560974121,
      "learning_rate": 4.928002450980393e-06,
      "loss": 0.0386,
      "step": 12115
    },
    {
      "epoch": 2.7840073529411766,
      "grad_norm": 0.921328067779541,
      "learning_rate": 4.9274918300653605e-06,
      "loss": 0.0465,
      "step": 12116
    },
    {
      "epoch": 2.784237132352941,
      "grad_norm": 0.6466056108474731,
      "learning_rate": 4.9269812091503275e-06,
      "loss": 0.0245,
      "step": 12117
    },
    {
      "epoch": 2.7844669117647056,
      "grad_norm": 0.9078070521354675,
      "learning_rate": 4.9264705882352945e-06,
      "loss": 0.035,
      "step": 12118
    },
    {
      "epoch": 2.7846966911764706,
      "grad_norm": 0.9929229021072388,
      "learning_rate": 4.9259599673202615e-06,
      "loss": 0.0491,
      "step": 12119
    },
    {
      "epoch": 2.7849264705882355,
      "grad_norm": 0.7003406882286072,
      "learning_rate": 4.925449346405229e-06,
      "loss": 0.0258,
      "step": 12120
    },
    {
      "epoch": 2.78515625,
      "grad_norm": 0.8550239205360413,
      "learning_rate": 4.924938725490196e-06,
      "loss": 0.0278,
      "step": 12121
    },
    {
      "epoch": 2.7853860294117645,
      "grad_norm": 1.079728126525879,
      "learning_rate": 4.924428104575164e-06,
      "loss": 0.045,
      "step": 12122
    },
    {
      "epoch": 2.7856158088235294,
      "grad_norm": 0.937659740447998,
      "learning_rate": 4.923917483660131e-06,
      "loss": 0.0387,
      "step": 12123
    },
    {
      "epoch": 2.7858455882352944,
      "grad_norm": 0.9608662128448486,
      "learning_rate": 4.923406862745098e-06,
      "loss": 0.0284,
      "step": 12124
    },
    {
      "epoch": 2.786075367647059,
      "grad_norm": 1.0421720743179321,
      "learning_rate": 4.922896241830066e-06,
      "loss": 0.0441,
      "step": 12125
    },
    {
      "epoch": 2.7863051470588234,
      "grad_norm": 0.7612653374671936,
      "learning_rate": 4.922385620915033e-06,
      "loss": 0.0261,
      "step": 12126
    },
    {
      "epoch": 2.7865349264705883,
      "grad_norm": 1.1964824199676514,
      "learning_rate": 4.921875e-06,
      "loss": 0.0539,
      "step": 12127
    },
    {
      "epoch": 2.786764705882353,
      "grad_norm": 0.9767103791236877,
      "learning_rate": 4.921364379084967e-06,
      "loss": 0.043,
      "step": 12128
    },
    {
      "epoch": 2.7869944852941178,
      "grad_norm": 0.8773915767669678,
      "learning_rate": 4.920853758169935e-06,
      "loss": 0.0473,
      "step": 12129
    },
    {
      "epoch": 2.7872242647058822,
      "grad_norm": 0.5709303021430969,
      "learning_rate": 4.920343137254902e-06,
      "loss": 0.0192,
      "step": 12130
    },
    {
      "epoch": 2.787454044117647,
      "grad_norm": 0.8786331415176392,
      "learning_rate": 4.91983251633987e-06,
      "loss": 0.0429,
      "step": 12131
    },
    {
      "epoch": 2.7876838235294117,
      "grad_norm": 1.0642837285995483,
      "learning_rate": 4.919321895424837e-06,
      "loss": 0.0508,
      "step": 12132
    },
    {
      "epoch": 2.7879136029411766,
      "grad_norm": 1.1031125783920288,
      "learning_rate": 4.918811274509804e-06,
      "loss": 0.0479,
      "step": 12133
    },
    {
      "epoch": 2.788143382352941,
      "grad_norm": 1.3097772598266602,
      "learning_rate": 4.918300653594771e-06,
      "loss": 0.0244,
      "step": 12134
    },
    {
      "epoch": 2.7883731617647056,
      "grad_norm": 0.8467215895652771,
      "learning_rate": 4.917790032679739e-06,
      "loss": 0.0307,
      "step": 12135
    },
    {
      "epoch": 2.7886029411764706,
      "grad_norm": 1.1138815879821777,
      "learning_rate": 4.917279411764706e-06,
      "loss": 0.0478,
      "step": 12136
    },
    {
      "epoch": 2.7888327205882355,
      "grad_norm": 1.3938919305801392,
      "learning_rate": 4.916768790849674e-06,
      "loss": 0.0372,
      "step": 12137
    },
    {
      "epoch": 2.7890625,
      "grad_norm": 1.1930376291275024,
      "learning_rate": 4.916258169934641e-06,
      "loss": 0.0675,
      "step": 12138
    },
    {
      "epoch": 2.7892922794117645,
      "grad_norm": 1.2104506492614746,
      "learning_rate": 4.915747549019609e-06,
      "loss": 0.0467,
      "step": 12139
    },
    {
      "epoch": 2.7895220588235294,
      "grad_norm": 0.886307954788208,
      "learning_rate": 4.915236928104576e-06,
      "loss": 0.0427,
      "step": 12140
    },
    {
      "epoch": 2.7897518382352944,
      "grad_norm": 1.111930012702942,
      "learning_rate": 4.914726307189543e-06,
      "loss": 0.0492,
      "step": 12141
    },
    {
      "epoch": 2.789981617647059,
      "grad_norm": 1.4139171838760376,
      "learning_rate": 4.91421568627451e-06,
      "loss": 0.0492,
      "step": 12142
    },
    {
      "epoch": 2.7902113970588234,
      "grad_norm": 0.7161739468574524,
      "learning_rate": 4.9137050653594775e-06,
      "loss": 0.0304,
      "step": 12143
    },
    {
      "epoch": 2.7904411764705883,
      "grad_norm": 0.7985420227050781,
      "learning_rate": 4.9131944444444445e-06,
      "loss": 0.0365,
      "step": 12144
    },
    {
      "epoch": 2.790670955882353,
      "grad_norm": 1.0980757474899292,
      "learning_rate": 4.912683823529412e-06,
      "loss": 0.0463,
      "step": 12145
    },
    {
      "epoch": 2.7909007352941178,
      "grad_norm": 0.8404101133346558,
      "learning_rate": 4.912173202614379e-06,
      "loss": 0.0433,
      "step": 12146
    },
    {
      "epoch": 2.7911305147058822,
      "grad_norm": 0.9420490860939026,
      "learning_rate": 4.911662581699346e-06,
      "loss": 0.0277,
      "step": 12147
    },
    {
      "epoch": 2.791360294117647,
      "grad_norm": 1.2907066345214844,
      "learning_rate": 4.911151960784314e-06,
      "loss": 0.0508,
      "step": 12148
    },
    {
      "epoch": 2.7915900735294117,
      "grad_norm": 1.0852668285369873,
      "learning_rate": 4.910641339869281e-06,
      "loss": 0.051,
      "step": 12149
    },
    {
      "epoch": 2.7918198529411766,
      "grad_norm": 1.0867348909378052,
      "learning_rate": 4.910130718954248e-06,
      "loss": 0.0397,
      "step": 12150
    },
    {
      "epoch": 2.792049632352941,
      "grad_norm": 1.017534852027893,
      "learning_rate": 4.909620098039216e-06,
      "loss": 0.0395,
      "step": 12151
    },
    {
      "epoch": 2.7922794117647056,
      "grad_norm": 1.0148427486419678,
      "learning_rate": 4.909109477124183e-06,
      "loss": 0.0317,
      "step": 12152
    },
    {
      "epoch": 2.7925091911764706,
      "grad_norm": 0.6623861789703369,
      "learning_rate": 4.908598856209151e-06,
      "loss": 0.0286,
      "step": 12153
    },
    {
      "epoch": 2.7927389705882355,
      "grad_norm": 1.100669503211975,
      "learning_rate": 4.908088235294118e-06,
      "loss": 0.0458,
      "step": 12154
    },
    {
      "epoch": 2.79296875,
      "grad_norm": 0.7715691328048706,
      "learning_rate": 4.907577614379085e-06,
      "loss": 0.034,
      "step": 12155
    },
    {
      "epoch": 2.7931985294117645,
      "grad_norm": 1.2672336101531982,
      "learning_rate": 4.907066993464052e-06,
      "loss": 0.0544,
      "step": 12156
    },
    {
      "epoch": 2.7934283088235294,
      "grad_norm": 0.6228026747703552,
      "learning_rate": 4.90655637254902e-06,
      "loss": 0.0213,
      "step": 12157
    },
    {
      "epoch": 2.7936580882352944,
      "grad_norm": 1.1038188934326172,
      "learning_rate": 4.906045751633987e-06,
      "loss": 0.056,
      "step": 12158
    },
    {
      "epoch": 2.793887867647059,
      "grad_norm": 1.0670400857925415,
      "learning_rate": 4.905535130718955e-06,
      "loss": 0.0478,
      "step": 12159
    },
    {
      "epoch": 2.7941176470588234,
      "grad_norm": 0.8239169716835022,
      "learning_rate": 4.905024509803922e-06,
      "loss": 0.0373,
      "step": 12160
    },
    {
      "epoch": 2.7943474264705883,
      "grad_norm": 1.3238637447357178,
      "learning_rate": 4.90451388888889e-06,
      "loss": 0.0366,
      "step": 12161
    },
    {
      "epoch": 2.794577205882353,
      "grad_norm": 0.7517900466918945,
      "learning_rate": 4.904003267973857e-06,
      "loss": 0.04,
      "step": 12162
    },
    {
      "epoch": 2.7948069852941178,
      "grad_norm": 0.831529438495636,
      "learning_rate": 4.903492647058824e-06,
      "loss": 0.0267,
      "step": 12163
    },
    {
      "epoch": 2.7950367647058822,
      "grad_norm": 0.8796035647392273,
      "learning_rate": 4.902982026143791e-06,
      "loss": 0.0458,
      "step": 12164
    },
    {
      "epoch": 2.795266544117647,
      "grad_norm": 0.7874595522880554,
      "learning_rate": 4.902471405228759e-06,
      "loss": 0.0305,
      "step": 12165
    },
    {
      "epoch": 2.7954963235294117,
      "grad_norm": 1.0895624160766602,
      "learning_rate": 4.901960784313726e-06,
      "loss": 0.048,
      "step": 12166
    },
    {
      "epoch": 2.7957261029411766,
      "grad_norm": 0.9712521433830261,
      "learning_rate": 4.9014501633986935e-06,
      "loss": 0.0336,
      "step": 12167
    },
    {
      "epoch": 2.795955882352941,
      "grad_norm": 1.0428080558776855,
      "learning_rate": 4.9009395424836605e-06,
      "loss": 0.0415,
      "step": 12168
    },
    {
      "epoch": 2.7961856617647056,
      "grad_norm": 0.9363957047462463,
      "learning_rate": 4.9004289215686275e-06,
      "loss": 0.0335,
      "step": 12169
    },
    {
      "epoch": 2.7964154411764706,
      "grad_norm": 1.0521925687789917,
      "learning_rate": 4.899918300653595e-06,
      "loss": 0.0411,
      "step": 12170
    },
    {
      "epoch": 2.7966452205882355,
      "grad_norm": 0.776810348033905,
      "learning_rate": 4.899407679738562e-06,
      "loss": 0.0318,
      "step": 12171
    },
    {
      "epoch": 2.796875,
      "grad_norm": 1.5626509189605713,
      "learning_rate": 4.898897058823529e-06,
      "loss": 0.0646,
      "step": 12172
    },
    {
      "epoch": 2.7971047794117645,
      "grad_norm": 1.185662865638733,
      "learning_rate": 4.898386437908497e-06,
      "loss": 0.0439,
      "step": 12173
    },
    {
      "epoch": 2.7973345588235294,
      "grad_norm": 0.9250586628913879,
      "learning_rate": 4.897875816993464e-06,
      "loss": 0.0387,
      "step": 12174
    },
    {
      "epoch": 2.7975643382352944,
      "grad_norm": 0.803561806678772,
      "learning_rate": 4.897365196078432e-06,
      "loss": 0.0209,
      "step": 12175
    },
    {
      "epoch": 2.797794117647059,
      "grad_norm": 2.4139037132263184,
      "learning_rate": 4.896854575163399e-06,
      "loss": 0.036,
      "step": 12176
    },
    {
      "epoch": 2.7980238970588234,
      "grad_norm": 0.7836581468582153,
      "learning_rate": 4.896343954248366e-06,
      "loss": 0.0324,
      "step": 12177
    },
    {
      "epoch": 2.7982536764705883,
      "grad_norm": 0.9236767888069153,
      "learning_rate": 4.895833333333333e-06,
      "loss": 0.0403,
      "step": 12178
    },
    {
      "epoch": 2.798483455882353,
      "grad_norm": 1.0395474433898926,
      "learning_rate": 4.895322712418301e-06,
      "loss": 0.0437,
      "step": 12179
    },
    {
      "epoch": 2.7987132352941178,
      "grad_norm": 1.1378105878829956,
      "learning_rate": 4.894812091503268e-06,
      "loss": 0.0415,
      "step": 12180
    },
    {
      "epoch": 2.7989430147058822,
      "grad_norm": 0.7584251165390015,
      "learning_rate": 4.894301470588236e-06,
      "loss": 0.0311,
      "step": 12181
    },
    {
      "epoch": 2.799172794117647,
      "grad_norm": 0.7323287725448608,
      "learning_rate": 4.893790849673203e-06,
      "loss": 0.0197,
      "step": 12182
    },
    {
      "epoch": 2.7994025735294117,
      "grad_norm": 0.9464086890220642,
      "learning_rate": 4.893280228758171e-06,
      "loss": 0.046,
      "step": 12183
    },
    {
      "epoch": 2.7996323529411766,
      "grad_norm": 0.769737958908081,
      "learning_rate": 4.892769607843138e-06,
      "loss": 0.0328,
      "step": 12184
    },
    {
      "epoch": 2.799862132352941,
      "grad_norm": 0.7591519951820374,
      "learning_rate": 4.892258986928105e-06,
      "loss": 0.0263,
      "step": 12185
    },
    {
      "epoch": 2.8000919117647056,
      "grad_norm": 1.2149685621261597,
      "learning_rate": 4.891748366013072e-06,
      "loss": 0.0471,
      "step": 12186
    },
    {
      "epoch": 2.8003216911764706,
      "grad_norm": 1.0812443494796753,
      "learning_rate": 4.89123774509804e-06,
      "loss": 0.0389,
      "step": 12187
    },
    {
      "epoch": 2.8005514705882355,
      "grad_norm": 1.0111923217773438,
      "learning_rate": 4.890727124183007e-06,
      "loss": 0.0334,
      "step": 12188
    },
    {
      "epoch": 2.80078125,
      "grad_norm": 1.2206743955612183,
      "learning_rate": 4.890216503267975e-06,
      "loss": 0.0431,
      "step": 12189
    },
    {
      "epoch": 2.8010110294117645,
      "grad_norm": 1.279984474182129,
      "learning_rate": 4.889705882352942e-06,
      "loss": 0.0552,
      "step": 12190
    },
    {
      "epoch": 2.8012408088235294,
      "grad_norm": 1.086693525314331,
      "learning_rate": 4.889195261437909e-06,
      "loss": 0.038,
      "step": 12191
    },
    {
      "epoch": 2.8014705882352944,
      "grad_norm": 1.099439024925232,
      "learning_rate": 4.8886846405228765e-06,
      "loss": 0.0453,
      "step": 12192
    },
    {
      "epoch": 2.801700367647059,
      "grad_norm": 0.9790965914726257,
      "learning_rate": 4.8881740196078435e-06,
      "loss": 0.0421,
      "step": 12193
    },
    {
      "epoch": 2.8019301470588234,
      "grad_norm": 0.9100666642189026,
      "learning_rate": 4.8876633986928105e-06,
      "loss": 0.0502,
      "step": 12194
    },
    {
      "epoch": 2.8021599264705883,
      "grad_norm": 0.5641616582870483,
      "learning_rate": 4.887152777777778e-06,
      "loss": 0.0244,
      "step": 12195
    },
    {
      "epoch": 2.802389705882353,
      "grad_norm": 0.7709372639656067,
      "learning_rate": 4.886642156862745e-06,
      "loss": 0.0305,
      "step": 12196
    },
    {
      "epoch": 2.8026194852941178,
      "grad_norm": 0.906929075717926,
      "learning_rate": 4.886131535947713e-06,
      "loss": 0.0358,
      "step": 12197
    },
    {
      "epoch": 2.8028492647058822,
      "grad_norm": 0.8249468207359314,
      "learning_rate": 4.88562091503268e-06,
      "loss": 0.0342,
      "step": 12198
    },
    {
      "epoch": 2.803079044117647,
      "grad_norm": 0.9968357682228088,
      "learning_rate": 4.885110294117647e-06,
      "loss": 0.0394,
      "step": 12199
    },
    {
      "epoch": 2.8033088235294117,
      "grad_norm": 1.100683331489563,
      "learning_rate": 4.884599673202614e-06,
      "loss": 0.0436,
      "step": 12200
    },
    {
      "epoch": 2.8035386029411766,
      "grad_norm": 1.2153278589248657,
      "learning_rate": 4.884089052287582e-06,
      "loss": 0.0667,
      "step": 12201
    },
    {
      "epoch": 2.803768382352941,
      "grad_norm": 1.7013365030288696,
      "learning_rate": 4.883578431372549e-06,
      "loss": 0.0452,
      "step": 12202
    },
    {
      "epoch": 2.8039981617647056,
      "grad_norm": 0.8923551440238953,
      "learning_rate": 4.883067810457517e-06,
      "loss": 0.0406,
      "step": 12203
    },
    {
      "epoch": 2.8042279411764706,
      "grad_norm": 0.9251273274421692,
      "learning_rate": 4.882557189542484e-06,
      "loss": 0.0449,
      "step": 12204
    },
    {
      "epoch": 2.8044577205882355,
      "grad_norm": 1.1145954132080078,
      "learning_rate": 4.882046568627452e-06,
      "loss": 0.0589,
      "step": 12205
    },
    {
      "epoch": 2.8046875,
      "grad_norm": 0.8601078391075134,
      "learning_rate": 4.881535947712419e-06,
      "loss": 0.0268,
      "step": 12206
    },
    {
      "epoch": 2.8049172794117645,
      "grad_norm": 1.2963825464248657,
      "learning_rate": 4.881025326797386e-06,
      "loss": 0.0597,
      "step": 12207
    },
    {
      "epoch": 2.8051470588235294,
      "grad_norm": 1.0308631658554077,
      "learning_rate": 4.880514705882353e-06,
      "loss": 0.0347,
      "step": 12208
    },
    {
      "epoch": 2.8053768382352944,
      "grad_norm": 1.043044090270996,
      "learning_rate": 4.880004084967321e-06,
      "loss": 0.053,
      "step": 12209
    },
    {
      "epoch": 2.805606617647059,
      "grad_norm": 0.68700110912323,
      "learning_rate": 4.879493464052288e-06,
      "loss": 0.0303,
      "step": 12210
    },
    {
      "epoch": 2.8058363970588234,
      "grad_norm": 1.0587564706802368,
      "learning_rate": 4.878982843137256e-06,
      "loss": 0.0522,
      "step": 12211
    },
    {
      "epoch": 2.8060661764705883,
      "grad_norm": 0.7056215405464172,
      "learning_rate": 4.878472222222223e-06,
      "loss": 0.0184,
      "step": 12212
    },
    {
      "epoch": 2.806295955882353,
      "grad_norm": 0.8689293265342712,
      "learning_rate": 4.87796160130719e-06,
      "loss": 0.0338,
      "step": 12213
    },
    {
      "epoch": 2.8065257352941178,
      "grad_norm": 0.8602428436279297,
      "learning_rate": 4.8774509803921576e-06,
      "loss": 0.0238,
      "step": 12214
    },
    {
      "epoch": 2.8067555147058822,
      "grad_norm": 0.7328630089759827,
      "learning_rate": 4.876940359477125e-06,
      "loss": 0.034,
      "step": 12215
    },
    {
      "epoch": 2.806985294117647,
      "grad_norm": 1.3154336214065552,
      "learning_rate": 4.876429738562092e-06,
      "loss": 0.0348,
      "step": 12216
    },
    {
      "epoch": 2.8072150735294117,
      "grad_norm": 0.6300972104072571,
      "learning_rate": 4.8759191176470595e-06,
      "loss": 0.0331,
      "step": 12217
    },
    {
      "epoch": 2.8074448529411766,
      "grad_norm": 0.9763787984848022,
      "learning_rate": 4.8754084967320265e-06,
      "loss": 0.0443,
      "step": 12218
    },
    {
      "epoch": 2.807674632352941,
      "grad_norm": 1.111459732055664,
      "learning_rate": 4.874897875816994e-06,
      "loss": 0.0466,
      "step": 12219
    },
    {
      "epoch": 2.8079044117647056,
      "grad_norm": 0.6587950587272644,
      "learning_rate": 4.874387254901961e-06,
      "loss": 0.0319,
      "step": 12220
    },
    {
      "epoch": 2.8081341911764706,
      "grad_norm": 1.1470530033111572,
      "learning_rate": 4.873876633986928e-06,
      "loss": 0.0605,
      "step": 12221
    },
    {
      "epoch": 2.8083639705882355,
      "grad_norm": 0.6923814415931702,
      "learning_rate": 4.873366013071895e-06,
      "loss": 0.0299,
      "step": 12222
    },
    {
      "epoch": 2.80859375,
      "grad_norm": 0.7286046147346497,
      "learning_rate": 4.872855392156863e-06,
      "loss": 0.0245,
      "step": 12223
    },
    {
      "epoch": 2.8088235294117645,
      "grad_norm": 0.9757100343704224,
      "learning_rate": 4.87234477124183e-06,
      "loss": 0.0621,
      "step": 12224
    },
    {
      "epoch": 2.8090533088235294,
      "grad_norm": 0.8168524503707886,
      "learning_rate": 4.871834150326798e-06,
      "loss": 0.0285,
      "step": 12225
    },
    {
      "epoch": 2.8092830882352944,
      "grad_norm": 1.0096937417984009,
      "learning_rate": 4.871323529411765e-06,
      "loss": 0.0651,
      "step": 12226
    },
    {
      "epoch": 2.809512867647059,
      "grad_norm": 0.8065726161003113,
      "learning_rate": 4.870812908496733e-06,
      "loss": 0.0216,
      "step": 12227
    },
    {
      "epoch": 2.8097426470588234,
      "grad_norm": 1.0206944942474365,
      "learning_rate": 4.8703022875817e-06,
      "loss": 0.0547,
      "step": 12228
    },
    {
      "epoch": 2.8099724264705883,
      "grad_norm": 0.9405269026756287,
      "learning_rate": 4.869791666666667e-06,
      "loss": 0.0425,
      "step": 12229
    },
    {
      "epoch": 2.810202205882353,
      "grad_norm": 0.8887366056442261,
      "learning_rate": 4.869281045751634e-06,
      "loss": 0.0479,
      "step": 12230
    },
    {
      "epoch": 2.8104319852941178,
      "grad_norm": 0.9095830321311951,
      "learning_rate": 4.868770424836602e-06,
      "loss": 0.0543,
      "step": 12231
    },
    {
      "epoch": 2.8106617647058822,
      "grad_norm": 1.172946572303772,
      "learning_rate": 4.868259803921569e-06,
      "loss": 0.0464,
      "step": 12232
    },
    {
      "epoch": 2.810891544117647,
      "grad_norm": 0.7447929978370667,
      "learning_rate": 4.867749183006537e-06,
      "loss": 0.0334,
      "step": 12233
    },
    {
      "epoch": 2.8111213235294117,
      "grad_norm": 1.1308358907699585,
      "learning_rate": 4.867238562091504e-06,
      "loss": 0.045,
      "step": 12234
    },
    {
      "epoch": 2.8113511029411766,
      "grad_norm": 0.9428460597991943,
      "learning_rate": 4.866727941176471e-06,
      "loss": 0.0336,
      "step": 12235
    },
    {
      "epoch": 2.811580882352941,
      "grad_norm": 0.948283314704895,
      "learning_rate": 4.866217320261438e-06,
      "loss": 0.0418,
      "step": 12236
    },
    {
      "epoch": 2.8118106617647056,
      "grad_norm": 0.9683722257614136,
      "learning_rate": 4.865706699346406e-06,
      "loss": 0.0455,
      "step": 12237
    },
    {
      "epoch": 2.8120404411764706,
      "grad_norm": 0.805458664894104,
      "learning_rate": 4.865196078431373e-06,
      "loss": 0.0242,
      "step": 12238
    },
    {
      "epoch": 2.8122702205882355,
      "grad_norm": 1.113330602645874,
      "learning_rate": 4.8646854575163405e-06,
      "loss": 0.0663,
      "step": 12239
    },
    {
      "epoch": 2.8125,
      "grad_norm": 0.815372109413147,
      "learning_rate": 4.8641748366013076e-06,
      "loss": 0.0272,
      "step": 12240
    },
    {
      "epoch": 2.8127297794117645,
      "grad_norm": 0.6510669589042664,
      "learning_rate": 4.8636642156862754e-06,
      "loss": 0.0163,
      "step": 12241
    },
    {
      "epoch": 2.8129595588235294,
      "grad_norm": 0.7315855622291565,
      "learning_rate": 4.8631535947712424e-06,
      "loss": 0.0255,
      "step": 12242
    },
    {
      "epoch": 2.8131893382352944,
      "grad_norm": 1.0996983051300049,
      "learning_rate": 4.8626429738562095e-06,
      "loss": 0.058,
      "step": 12243
    },
    {
      "epoch": 2.813419117647059,
      "grad_norm": 0.9164804220199585,
      "learning_rate": 4.8621323529411765e-06,
      "loss": 0.0468,
      "step": 12244
    },
    {
      "epoch": 2.8136488970588234,
      "grad_norm": 1.3083109855651855,
      "learning_rate": 4.861621732026144e-06,
      "loss": 0.0546,
      "step": 12245
    },
    {
      "epoch": 2.8138786764705883,
      "grad_norm": 1.1031240224838257,
      "learning_rate": 4.861111111111111e-06,
      "loss": 0.0396,
      "step": 12246
    },
    {
      "epoch": 2.814108455882353,
      "grad_norm": 1.1015784740447998,
      "learning_rate": 4.860600490196079e-06,
      "loss": 0.0558,
      "step": 12247
    },
    {
      "epoch": 2.8143382352941178,
      "grad_norm": 0.773600161075592,
      "learning_rate": 4.860089869281046e-06,
      "loss": 0.0338,
      "step": 12248
    },
    {
      "epoch": 2.8145680147058822,
      "grad_norm": 1.5060880184173584,
      "learning_rate": 4.859579248366014e-06,
      "loss": 0.0626,
      "step": 12249
    },
    {
      "epoch": 2.814797794117647,
      "grad_norm": 0.8531455397605896,
      "learning_rate": 4.859068627450981e-06,
      "loss": 0.0378,
      "step": 12250
    },
    {
      "epoch": 2.8150275735294117,
      "grad_norm": 0.9838364124298096,
      "learning_rate": 4.858558006535948e-06,
      "loss": 0.0433,
      "step": 12251
    },
    {
      "epoch": 2.8152573529411766,
      "grad_norm": 0.9655705094337463,
      "learning_rate": 4.858047385620915e-06,
      "loss": 0.0402,
      "step": 12252
    },
    {
      "epoch": 2.815487132352941,
      "grad_norm": 1.172847032546997,
      "learning_rate": 4.857536764705883e-06,
      "loss": 0.0452,
      "step": 12253
    },
    {
      "epoch": 2.8157169117647056,
      "grad_norm": 0.7081531882286072,
      "learning_rate": 4.85702614379085e-06,
      "loss": 0.0259,
      "step": 12254
    },
    {
      "epoch": 2.8159466911764706,
      "grad_norm": 1.14933180809021,
      "learning_rate": 4.856515522875818e-06,
      "loss": 0.0457,
      "step": 12255
    },
    {
      "epoch": 2.8161764705882355,
      "grad_norm": 1.0996947288513184,
      "learning_rate": 4.856004901960785e-06,
      "loss": 0.0512,
      "step": 12256
    },
    {
      "epoch": 2.81640625,
      "grad_norm": 0.7615473866462708,
      "learning_rate": 4.855494281045752e-06,
      "loss": 0.0231,
      "step": 12257
    },
    {
      "epoch": 2.8166360294117645,
      "grad_norm": 1.0344818830490112,
      "learning_rate": 4.854983660130719e-06,
      "loss": 0.0598,
      "step": 12258
    },
    {
      "epoch": 2.8168658088235294,
      "grad_norm": 1.040274977684021,
      "learning_rate": 4.854473039215687e-06,
      "loss": 0.0467,
      "step": 12259
    },
    {
      "epoch": 2.8170955882352944,
      "grad_norm": 1.1219325065612793,
      "learning_rate": 4.853962418300654e-06,
      "loss": 0.04,
      "step": 12260
    },
    {
      "epoch": 2.817325367647059,
      "grad_norm": 0.6979397535324097,
      "learning_rate": 4.853451797385622e-06,
      "loss": 0.0446,
      "step": 12261
    },
    {
      "epoch": 2.8175551470588234,
      "grad_norm": 0.680267870426178,
      "learning_rate": 4.852941176470589e-06,
      "loss": 0.0282,
      "step": 12262
    },
    {
      "epoch": 2.8177849264705883,
      "grad_norm": 0.8111640214920044,
      "learning_rate": 4.8524305555555565e-06,
      "loss": 0.0289,
      "step": 12263
    },
    {
      "epoch": 2.818014705882353,
      "grad_norm": 0.8205832242965698,
      "learning_rate": 4.8519199346405235e-06,
      "loss": 0.0344,
      "step": 12264
    },
    {
      "epoch": 2.8182444852941178,
      "grad_norm": 0.7774686813354492,
      "learning_rate": 4.8514093137254905e-06,
      "loss": 0.0309,
      "step": 12265
    },
    {
      "epoch": 2.8184742647058822,
      "grad_norm": 0.631776750087738,
      "learning_rate": 4.8508986928104576e-06,
      "loss": 0.0232,
      "step": 12266
    },
    {
      "epoch": 2.818704044117647,
      "grad_norm": 0.6328125,
      "learning_rate": 4.850388071895425e-06,
      "loss": 0.0257,
      "step": 12267
    },
    {
      "epoch": 2.8189338235294117,
      "grad_norm": 0.9203553199768066,
      "learning_rate": 4.8498774509803924e-06,
      "loss": 0.0287,
      "step": 12268
    },
    {
      "epoch": 2.8191636029411766,
      "grad_norm": 0.9141179323196411,
      "learning_rate": 4.84936683006536e-06,
      "loss": 0.0397,
      "step": 12269
    },
    {
      "epoch": 2.819393382352941,
      "grad_norm": 0.9528211355209351,
      "learning_rate": 4.848856209150327e-06,
      "loss": 0.035,
      "step": 12270
    },
    {
      "epoch": 2.8196231617647056,
      "grad_norm": 1.0306559801101685,
      "learning_rate": 4.848345588235295e-06,
      "loss": 0.0532,
      "step": 12271
    },
    {
      "epoch": 2.8198529411764706,
      "grad_norm": 1.170501947402954,
      "learning_rate": 4.847834967320262e-06,
      "loss": 0.0598,
      "step": 12272
    },
    {
      "epoch": 2.8200827205882355,
      "grad_norm": 1.382405161857605,
      "learning_rate": 4.847324346405229e-06,
      "loss": 0.0672,
      "step": 12273
    },
    {
      "epoch": 2.8203125,
      "grad_norm": 1.1041955947875977,
      "learning_rate": 4.846813725490196e-06,
      "loss": 0.0512,
      "step": 12274
    },
    {
      "epoch": 2.8205422794117645,
      "grad_norm": 1.0589673519134521,
      "learning_rate": 4.846303104575164e-06,
      "loss": 0.0523,
      "step": 12275
    },
    {
      "epoch": 2.8207720588235294,
      "grad_norm": 0.8421102166175842,
      "learning_rate": 4.845792483660131e-06,
      "loss": 0.0364,
      "step": 12276
    },
    {
      "epoch": 2.8210018382352944,
      "grad_norm": 0.8783448934555054,
      "learning_rate": 4.845281862745099e-06,
      "loss": 0.0333,
      "step": 12277
    },
    {
      "epoch": 2.821231617647059,
      "grad_norm": 0.8590503931045532,
      "learning_rate": 4.844771241830066e-06,
      "loss": 0.0298,
      "step": 12278
    },
    {
      "epoch": 2.8214613970588234,
      "grad_norm": 0.9517439603805542,
      "learning_rate": 4.844260620915033e-06,
      "loss": 0.0335,
      "step": 12279
    },
    {
      "epoch": 2.8216911764705883,
      "grad_norm": 0.738419234752655,
      "learning_rate": 4.84375e-06,
      "loss": 0.0383,
      "step": 12280
    },
    {
      "epoch": 2.821920955882353,
      "grad_norm": 0.842153012752533,
      "learning_rate": 4.843239379084968e-06,
      "loss": 0.0375,
      "step": 12281
    },
    {
      "epoch": 2.8221507352941178,
      "grad_norm": 0.7142738699913025,
      "learning_rate": 4.842728758169935e-06,
      "loss": 0.045,
      "step": 12282
    },
    {
      "epoch": 2.8223805147058822,
      "grad_norm": 1.0258376598358154,
      "learning_rate": 4.842218137254902e-06,
      "loss": 0.0665,
      "step": 12283
    },
    {
      "epoch": 2.822610294117647,
      "grad_norm": 0.8847494721412659,
      "learning_rate": 4.84170751633987e-06,
      "loss": 0.0337,
      "step": 12284
    },
    {
      "epoch": 2.8228400735294117,
      "grad_norm": 0.9549160599708557,
      "learning_rate": 4.841196895424837e-06,
      "loss": 0.0421,
      "step": 12285
    },
    {
      "epoch": 2.8230698529411766,
      "grad_norm": 1.1172047853469849,
      "learning_rate": 4.840686274509805e-06,
      "loss": 0.0391,
      "step": 12286
    },
    {
      "epoch": 2.823299632352941,
      "grad_norm": 0.5730412602424622,
      "learning_rate": 4.840175653594772e-06,
      "loss": 0.0156,
      "step": 12287
    },
    {
      "epoch": 2.8235294117647056,
      "grad_norm": 1.3097448348999023,
      "learning_rate": 4.839665032679739e-06,
      "loss": 0.0372,
      "step": 12288
    },
    {
      "epoch": 2.8237591911764706,
      "grad_norm": 0.7811247110366821,
      "learning_rate": 4.839154411764706e-06,
      "loss": 0.0338,
      "step": 12289
    },
    {
      "epoch": 2.8239889705882355,
      "grad_norm": 1.1625354290008545,
      "learning_rate": 4.8386437908496735e-06,
      "loss": 0.0597,
      "step": 12290
    },
    {
      "epoch": 2.82421875,
      "grad_norm": 1.2038803100585938,
      "learning_rate": 4.8381331699346405e-06,
      "loss": 0.0363,
      "step": 12291
    },
    {
      "epoch": 2.8244485294117645,
      "grad_norm": 0.8587795495986938,
      "learning_rate": 4.837622549019608e-06,
      "loss": 0.0364,
      "step": 12292
    },
    {
      "epoch": 2.8246783088235294,
      "grad_norm": 1.3405252695083618,
      "learning_rate": 4.837111928104575e-06,
      "loss": 0.0489,
      "step": 12293
    },
    {
      "epoch": 2.8249080882352944,
      "grad_norm": 0.6074646711349487,
      "learning_rate": 4.836601307189543e-06,
      "loss": 0.029,
      "step": 12294
    },
    {
      "epoch": 2.825137867647059,
      "grad_norm": 0.6736716032028198,
      "learning_rate": 4.83609068627451e-06,
      "loss": 0.0294,
      "step": 12295
    },
    {
      "epoch": 2.8253676470588234,
      "grad_norm": 1.244125485420227,
      "learning_rate": 4.835580065359477e-06,
      "loss": 0.0547,
      "step": 12296
    },
    {
      "epoch": 2.8255974264705883,
      "grad_norm": 0.9743883013725281,
      "learning_rate": 4.835069444444444e-06,
      "loss": 0.0431,
      "step": 12297
    },
    {
      "epoch": 2.825827205882353,
      "grad_norm": 0.8507810831069946,
      "learning_rate": 4.834558823529412e-06,
      "loss": 0.0367,
      "step": 12298
    },
    {
      "epoch": 2.8260569852941178,
      "grad_norm": 0.8972543478012085,
      "learning_rate": 4.834048202614379e-06,
      "loss": 0.0429,
      "step": 12299
    },
    {
      "epoch": 2.8262867647058822,
      "grad_norm": 0.6964954137802124,
      "learning_rate": 4.833537581699347e-06,
      "loss": 0.0392,
      "step": 12300
    },
    {
      "epoch": 2.826516544117647,
      "grad_norm": 1.0718001127243042,
      "learning_rate": 4.833026960784314e-06,
      "loss": 0.0477,
      "step": 12301
    },
    {
      "epoch": 2.8267463235294117,
      "grad_norm": 0.7149079442024231,
      "learning_rate": 4.832516339869281e-06,
      "loss": 0.0268,
      "step": 12302
    },
    {
      "epoch": 2.8269761029411766,
      "grad_norm": 1.0771000385284424,
      "learning_rate": 4.832005718954248e-06,
      "loss": 0.0558,
      "step": 12303
    },
    {
      "epoch": 2.827205882352941,
      "grad_norm": 1.296462059020996,
      "learning_rate": 4.831495098039216e-06,
      "loss": 0.0612,
      "step": 12304
    },
    {
      "epoch": 2.8274356617647056,
      "grad_norm": 0.9621692895889282,
      "learning_rate": 4.830984477124183e-06,
      "loss": 0.0397,
      "step": 12305
    },
    {
      "epoch": 2.8276654411764706,
      "grad_norm": 1.0644046068191528,
      "learning_rate": 4.830473856209151e-06,
      "loss": 0.0448,
      "step": 12306
    },
    {
      "epoch": 2.8278952205882355,
      "grad_norm": 0.9825946688652039,
      "learning_rate": 4.829963235294118e-06,
      "loss": 0.0399,
      "step": 12307
    },
    {
      "epoch": 2.828125,
      "grad_norm": 0.9039973616600037,
      "learning_rate": 4.829452614379086e-06,
      "loss": 0.036,
      "step": 12308
    },
    {
      "epoch": 2.8283547794117645,
      "grad_norm": 1.009067416191101,
      "learning_rate": 4.828941993464053e-06,
      "loss": 0.0474,
      "step": 12309
    },
    {
      "epoch": 2.8285845588235294,
      "grad_norm": 1.0230950117111206,
      "learning_rate": 4.82843137254902e-06,
      "loss": 0.0364,
      "step": 12310
    },
    {
      "epoch": 2.8288143382352944,
      "grad_norm": 1.2424015998840332,
      "learning_rate": 4.827920751633987e-06,
      "loss": 0.0668,
      "step": 12311
    },
    {
      "epoch": 2.829044117647059,
      "grad_norm": 0.8628908395767212,
      "learning_rate": 4.827410130718955e-06,
      "loss": 0.0268,
      "step": 12312
    },
    {
      "epoch": 2.8292738970588234,
      "grad_norm": 1.1353235244750977,
      "learning_rate": 4.826899509803922e-06,
      "loss": 0.0708,
      "step": 12313
    },
    {
      "epoch": 2.8295036764705883,
      "grad_norm": 0.8753201961517334,
      "learning_rate": 4.8263888888888895e-06,
      "loss": 0.034,
      "step": 12314
    },
    {
      "epoch": 2.829733455882353,
      "grad_norm": 0.8268288373947144,
      "learning_rate": 4.8258782679738565e-06,
      "loss": 0.035,
      "step": 12315
    },
    {
      "epoch": 2.8299632352941178,
      "grad_norm": 0.7735722064971924,
      "learning_rate": 4.825367647058824e-06,
      "loss": 0.0358,
      "step": 12316
    },
    {
      "epoch": 2.8301930147058822,
      "grad_norm": 0.712948203086853,
      "learning_rate": 4.824857026143791e-06,
      "loss": 0.0319,
      "step": 12317
    },
    {
      "epoch": 2.830422794117647,
      "grad_norm": 1.11715829372406,
      "learning_rate": 4.824346405228758e-06,
      "loss": 0.0517,
      "step": 12318
    },
    {
      "epoch": 2.8306525735294117,
      "grad_norm": 0.9782201647758484,
      "learning_rate": 4.823835784313725e-06,
      "loss": 0.0451,
      "step": 12319
    },
    {
      "epoch": 2.8308823529411766,
      "grad_norm": 0.8723735809326172,
      "learning_rate": 4.823325163398693e-06,
      "loss": 0.0412,
      "step": 12320
    },
    {
      "epoch": 2.831112132352941,
      "grad_norm": 0.9907899498939514,
      "learning_rate": 4.82281454248366e-06,
      "loss": 0.039,
      "step": 12321
    },
    {
      "epoch": 2.8313419117647056,
      "grad_norm": 0.7858091592788696,
      "learning_rate": 4.822303921568628e-06,
      "loss": 0.0261,
      "step": 12322
    },
    {
      "epoch": 2.8315716911764706,
      "grad_norm": 0.9785557389259338,
      "learning_rate": 4.821793300653595e-06,
      "loss": 0.0491,
      "step": 12323
    },
    {
      "epoch": 2.8318014705882355,
      "grad_norm": 1.063190221786499,
      "learning_rate": 4.821282679738562e-06,
      "loss": 0.0551,
      "step": 12324
    },
    {
      "epoch": 2.83203125,
      "grad_norm": 1.0789391994476318,
      "learning_rate": 4.820772058823529e-06,
      "loss": 0.0549,
      "step": 12325
    },
    {
      "epoch": 2.8322610294117645,
      "grad_norm": 1.1218286752700806,
      "learning_rate": 4.820261437908497e-06,
      "loss": 0.0457,
      "step": 12326
    },
    {
      "epoch": 2.8324908088235294,
      "grad_norm": 0.8145714998245239,
      "learning_rate": 4.819750816993464e-06,
      "loss": 0.0409,
      "step": 12327
    },
    {
      "epoch": 2.8327205882352944,
      "grad_norm": 0.8928808569908142,
      "learning_rate": 4.819240196078432e-06,
      "loss": 0.0549,
      "step": 12328
    },
    {
      "epoch": 2.832950367647059,
      "grad_norm": 1.256146788597107,
      "learning_rate": 4.818729575163399e-06,
      "loss": 0.049,
      "step": 12329
    },
    {
      "epoch": 2.8331801470588234,
      "grad_norm": 0.7971833944320679,
      "learning_rate": 4.818218954248367e-06,
      "loss": 0.0342,
      "step": 12330
    },
    {
      "epoch": 2.8334099264705883,
      "grad_norm": 0.7067771553993225,
      "learning_rate": 4.817708333333334e-06,
      "loss": 0.0215,
      "step": 12331
    },
    {
      "epoch": 2.833639705882353,
      "grad_norm": 1.064429521560669,
      "learning_rate": 4.817197712418301e-06,
      "loss": 0.053,
      "step": 12332
    },
    {
      "epoch": 2.8338694852941178,
      "grad_norm": 1.0922915935516357,
      "learning_rate": 4.816687091503268e-06,
      "loss": 0.0624,
      "step": 12333
    },
    {
      "epoch": 2.8340992647058822,
      "grad_norm": 0.830457329750061,
      "learning_rate": 4.816176470588236e-06,
      "loss": 0.0374,
      "step": 12334
    },
    {
      "epoch": 2.834329044117647,
      "grad_norm": 0.6957126259803772,
      "learning_rate": 4.815665849673203e-06,
      "loss": 0.0319,
      "step": 12335
    },
    {
      "epoch": 2.8345588235294117,
      "grad_norm": 0.9693406224250793,
      "learning_rate": 4.815155228758171e-06,
      "loss": 0.0531,
      "step": 12336
    },
    {
      "epoch": 2.8347886029411766,
      "grad_norm": 0.9180847406387329,
      "learning_rate": 4.814644607843138e-06,
      "loss": 0.0633,
      "step": 12337
    },
    {
      "epoch": 2.835018382352941,
      "grad_norm": 0.7741562724113464,
      "learning_rate": 4.8141339869281055e-06,
      "loss": 0.0348,
      "step": 12338
    },
    {
      "epoch": 2.8352481617647056,
      "grad_norm": 1.0413371324539185,
      "learning_rate": 4.8136233660130725e-06,
      "loss": 0.0415,
      "step": 12339
    },
    {
      "epoch": 2.8354779411764706,
      "grad_norm": 0.9849749803543091,
      "learning_rate": 4.8131127450980395e-06,
      "loss": 0.0448,
      "step": 12340
    },
    {
      "epoch": 2.8357077205882355,
      "grad_norm": 1.022706151008606,
      "learning_rate": 4.8126021241830065e-06,
      "loss": 0.0472,
      "step": 12341
    },
    {
      "epoch": 2.8359375,
      "grad_norm": 0.6761258840560913,
      "learning_rate": 4.812091503267974e-06,
      "loss": 0.0325,
      "step": 12342
    },
    {
      "epoch": 2.8361672794117645,
      "grad_norm": 1.0153557062149048,
      "learning_rate": 4.811580882352941e-06,
      "loss": 0.0426,
      "step": 12343
    },
    {
      "epoch": 2.8363970588235294,
      "grad_norm": 1.070473551750183,
      "learning_rate": 4.811070261437909e-06,
      "loss": 0.0566,
      "step": 12344
    },
    {
      "epoch": 2.8366268382352944,
      "grad_norm": 0.8168407678604126,
      "learning_rate": 4.810559640522876e-06,
      "loss": 0.047,
      "step": 12345
    },
    {
      "epoch": 2.836856617647059,
      "grad_norm": 0.9816703200340271,
      "learning_rate": 4.810049019607843e-06,
      "loss": 0.0498,
      "step": 12346
    },
    {
      "epoch": 2.8370863970588234,
      "grad_norm": 0.858964741230011,
      "learning_rate": 4.80953839869281e-06,
      "loss": 0.0345,
      "step": 12347
    },
    {
      "epoch": 2.8373161764705883,
      "grad_norm": 1.5377904176712036,
      "learning_rate": 4.809027777777778e-06,
      "loss": 0.067,
      "step": 12348
    },
    {
      "epoch": 2.837545955882353,
      "grad_norm": 0.9197247624397278,
      "learning_rate": 4.808517156862745e-06,
      "loss": 0.0476,
      "step": 12349
    },
    {
      "epoch": 2.8377757352941178,
      "grad_norm": 1.1634292602539062,
      "learning_rate": 4.808006535947713e-06,
      "loss": 0.0538,
      "step": 12350
    },
    {
      "epoch": 2.8380055147058822,
      "grad_norm": 0.9142543077468872,
      "learning_rate": 4.80749591503268e-06,
      "loss": 0.0458,
      "step": 12351
    },
    {
      "epoch": 2.838235294117647,
      "grad_norm": 1.455721378326416,
      "learning_rate": 4.806985294117648e-06,
      "loss": 0.0466,
      "step": 12352
    },
    {
      "epoch": 2.8384650735294117,
      "grad_norm": 0.8929352760314941,
      "learning_rate": 4.806474673202615e-06,
      "loss": 0.0418,
      "step": 12353
    },
    {
      "epoch": 2.8386948529411766,
      "grad_norm": 0.6572287678718567,
      "learning_rate": 4.805964052287582e-06,
      "loss": 0.0233,
      "step": 12354
    },
    {
      "epoch": 2.838924632352941,
      "grad_norm": 1.4585620164871216,
      "learning_rate": 4.805453431372549e-06,
      "loss": 0.0419,
      "step": 12355
    },
    {
      "epoch": 2.8391544117647056,
      "grad_norm": 0.8427384495735168,
      "learning_rate": 4.804942810457517e-06,
      "loss": 0.0442,
      "step": 12356
    },
    {
      "epoch": 2.8393841911764706,
      "grad_norm": 1.1750727891921997,
      "learning_rate": 4.804432189542484e-06,
      "loss": 0.0442,
      "step": 12357
    },
    {
      "epoch": 2.8396139705882355,
      "grad_norm": 0.7638046145439148,
      "learning_rate": 4.803921568627452e-06,
      "loss": 0.0244,
      "step": 12358
    },
    {
      "epoch": 2.83984375,
      "grad_norm": 0.7764726877212524,
      "learning_rate": 4.803410947712419e-06,
      "loss": 0.0262,
      "step": 12359
    },
    {
      "epoch": 2.8400735294117645,
      "grad_norm": 0.962834894657135,
      "learning_rate": 4.8029003267973866e-06,
      "loss": 0.0292,
      "step": 12360
    },
    {
      "epoch": 2.8403033088235294,
      "grad_norm": 0.9311920404434204,
      "learning_rate": 4.802389705882354e-06,
      "loss": 0.0338,
      "step": 12361
    },
    {
      "epoch": 2.8405330882352944,
      "grad_norm": 1.2964907884597778,
      "learning_rate": 4.801879084967321e-06,
      "loss": 0.0619,
      "step": 12362
    },
    {
      "epoch": 2.840762867647059,
      "grad_norm": 1.071401834487915,
      "learning_rate": 4.801368464052288e-06,
      "loss": 0.0557,
      "step": 12363
    },
    {
      "epoch": 2.8409926470588234,
      "grad_norm": 1.0639336109161377,
      "learning_rate": 4.8008578431372555e-06,
      "loss": 0.0476,
      "step": 12364
    },
    {
      "epoch": 2.8412224264705883,
      "grad_norm": 0.8563806414604187,
      "learning_rate": 4.8003472222222225e-06,
      "loss": 0.0384,
      "step": 12365
    },
    {
      "epoch": 2.841452205882353,
      "grad_norm": 0.9990318417549133,
      "learning_rate": 4.79983660130719e-06,
      "loss": 0.0439,
      "step": 12366
    },
    {
      "epoch": 2.8416819852941178,
      "grad_norm": 0.6770834922790527,
      "learning_rate": 4.799325980392157e-06,
      "loss": 0.0232,
      "step": 12367
    },
    {
      "epoch": 2.8419117647058822,
      "grad_norm": 0.7169339060783386,
      "learning_rate": 4.798815359477124e-06,
      "loss": 0.026,
      "step": 12368
    },
    {
      "epoch": 2.842141544117647,
      "grad_norm": 0.9635779857635498,
      "learning_rate": 4.798304738562091e-06,
      "loss": 0.051,
      "step": 12369
    },
    {
      "epoch": 2.8423713235294117,
      "grad_norm": 0.8795830011367798,
      "learning_rate": 4.797794117647059e-06,
      "loss": 0.0273,
      "step": 12370
    },
    {
      "epoch": 2.8426011029411766,
      "grad_norm": 1.1812114715576172,
      "learning_rate": 4.797283496732026e-06,
      "loss": 0.0488,
      "step": 12371
    },
    {
      "epoch": 2.842830882352941,
      "grad_norm": 1.1097949743270874,
      "learning_rate": 4.796772875816994e-06,
      "loss": 0.0435,
      "step": 12372
    },
    {
      "epoch": 2.8430606617647056,
      "grad_norm": 0.8162018656730652,
      "learning_rate": 4.796262254901961e-06,
      "loss": 0.0305,
      "step": 12373
    },
    {
      "epoch": 2.8432904411764706,
      "grad_norm": 1.3315151929855347,
      "learning_rate": 4.795751633986929e-06,
      "loss": 0.0364,
      "step": 12374
    },
    {
      "epoch": 2.8435202205882355,
      "grad_norm": 1.31434965133667,
      "learning_rate": 4.795241013071896e-06,
      "loss": 0.046,
      "step": 12375
    },
    {
      "epoch": 2.84375,
      "grad_norm": 0.9124109148979187,
      "learning_rate": 4.794730392156863e-06,
      "loss": 0.0473,
      "step": 12376
    },
    {
      "epoch": 2.8439797794117645,
      "grad_norm": 1.065703272819519,
      "learning_rate": 4.79421977124183e-06,
      "loss": 0.0423,
      "step": 12377
    },
    {
      "epoch": 2.8442095588235294,
      "grad_norm": 0.8037610054016113,
      "learning_rate": 4.793709150326798e-06,
      "loss": 0.032,
      "step": 12378
    },
    {
      "epoch": 2.8444393382352944,
      "grad_norm": 0.893061637878418,
      "learning_rate": 4.793198529411765e-06,
      "loss": 0.0535,
      "step": 12379
    },
    {
      "epoch": 2.844669117647059,
      "grad_norm": 1.235929250717163,
      "learning_rate": 4.792687908496733e-06,
      "loss": 0.0418,
      "step": 12380
    },
    {
      "epoch": 2.8448988970588234,
      "grad_norm": 1.4170204401016235,
      "learning_rate": 4.7921772875817e-06,
      "loss": 0.0617,
      "step": 12381
    },
    {
      "epoch": 2.8451286764705883,
      "grad_norm": 1.023655652999878,
      "learning_rate": 4.791666666666668e-06,
      "loss": 0.0499,
      "step": 12382
    },
    {
      "epoch": 2.845358455882353,
      "grad_norm": 1.0302150249481201,
      "learning_rate": 4.791156045751635e-06,
      "loss": 0.025,
      "step": 12383
    },
    {
      "epoch": 2.8455882352941178,
      "grad_norm": 1.037846565246582,
      "learning_rate": 4.790645424836602e-06,
      "loss": 0.0451,
      "step": 12384
    },
    {
      "epoch": 2.8458180147058822,
      "grad_norm": 0.9060896635055542,
      "learning_rate": 4.790134803921569e-06,
      "loss": 0.0483,
      "step": 12385
    },
    {
      "epoch": 2.846047794117647,
      "grad_norm": 1.100351095199585,
      "learning_rate": 4.7896241830065366e-06,
      "loss": 0.0459,
      "step": 12386
    },
    {
      "epoch": 2.8462775735294117,
      "grad_norm": 1.5085794925689697,
      "learning_rate": 4.789113562091504e-06,
      "loss": 0.0507,
      "step": 12387
    },
    {
      "epoch": 2.8465073529411766,
      "grad_norm": 0.9487745761871338,
      "learning_rate": 4.7886029411764714e-06,
      "loss": 0.0526,
      "step": 12388
    },
    {
      "epoch": 2.846737132352941,
      "grad_norm": 0.7793209552764893,
      "learning_rate": 4.7880923202614385e-06,
      "loss": 0.0286,
      "step": 12389
    },
    {
      "epoch": 2.8469669117647056,
      "grad_norm": 1.0574589967727661,
      "learning_rate": 4.7875816993464055e-06,
      "loss": 0.0352,
      "step": 12390
    },
    {
      "epoch": 2.8471966911764706,
      "grad_norm": 0.8447635769844055,
      "learning_rate": 4.7870710784313725e-06,
      "loss": 0.0304,
      "step": 12391
    },
    {
      "epoch": 2.8474264705882355,
      "grad_norm": 0.6250870823860168,
      "learning_rate": 4.78656045751634e-06,
      "loss": 0.0304,
      "step": 12392
    },
    {
      "epoch": 2.84765625,
      "grad_norm": 0.9537634253501892,
      "learning_rate": 4.786049836601307e-06,
      "loss": 0.0306,
      "step": 12393
    },
    {
      "epoch": 2.8478860294117645,
      "grad_norm": 1.0005197525024414,
      "learning_rate": 4.785539215686275e-06,
      "loss": 0.0461,
      "step": 12394
    },
    {
      "epoch": 2.8481158088235294,
      "grad_norm": 1.4365417957305908,
      "learning_rate": 4.785028594771242e-06,
      "loss": 0.0585,
      "step": 12395
    },
    {
      "epoch": 2.8483455882352944,
      "grad_norm": 1.0074586868286133,
      "learning_rate": 4.78451797385621e-06,
      "loss": 0.0519,
      "step": 12396
    },
    {
      "epoch": 2.848575367647059,
      "grad_norm": 0.7142027020454407,
      "learning_rate": 4.784007352941177e-06,
      "loss": 0.0306,
      "step": 12397
    },
    {
      "epoch": 2.8488051470588234,
      "grad_norm": 0.5650729537010193,
      "learning_rate": 4.783496732026144e-06,
      "loss": 0.0133,
      "step": 12398
    },
    {
      "epoch": 2.8490349264705883,
      "grad_norm": 1.0140347480773926,
      "learning_rate": 4.782986111111111e-06,
      "loss": 0.0408,
      "step": 12399
    },
    {
      "epoch": 2.849264705882353,
      "grad_norm": 0.576431393623352,
      "learning_rate": 4.782475490196079e-06,
      "loss": 0.024,
      "step": 12400
    },
    {
      "epoch": 2.8494944852941178,
      "grad_norm": 1.2845492362976074,
      "learning_rate": 4.781964869281046e-06,
      "loss": 0.0435,
      "step": 12401
    },
    {
      "epoch": 2.8497242647058822,
      "grad_norm": 0.7700408101081848,
      "learning_rate": 4.781454248366014e-06,
      "loss": 0.0353,
      "step": 12402
    },
    {
      "epoch": 2.849954044117647,
      "grad_norm": 0.9975390434265137,
      "learning_rate": 4.780943627450981e-06,
      "loss": 0.0394,
      "step": 12403
    },
    {
      "epoch": 2.8501838235294117,
      "grad_norm": 0.9537520408630371,
      "learning_rate": 4.780433006535948e-06,
      "loss": 0.0441,
      "step": 12404
    },
    {
      "epoch": 2.8504136029411766,
      "grad_norm": 1.0207940340042114,
      "learning_rate": 4.779922385620916e-06,
      "loss": 0.0458,
      "step": 12405
    },
    {
      "epoch": 2.850643382352941,
      "grad_norm": 1.3148102760314941,
      "learning_rate": 4.779411764705883e-06,
      "loss": 0.0572,
      "step": 12406
    },
    {
      "epoch": 2.8508731617647056,
      "grad_norm": 1.1351293325424194,
      "learning_rate": 4.77890114379085e-06,
      "loss": 0.06,
      "step": 12407
    },
    {
      "epoch": 2.8511029411764706,
      "grad_norm": 1.3160300254821777,
      "learning_rate": 4.778390522875818e-06,
      "loss": 0.0406,
      "step": 12408
    },
    {
      "epoch": 2.8513327205882355,
      "grad_norm": 0.8413583040237427,
      "learning_rate": 4.777879901960785e-06,
      "loss": 0.0441,
      "step": 12409
    },
    {
      "epoch": 2.8515625,
      "grad_norm": 1.0532057285308838,
      "learning_rate": 4.7773692810457525e-06,
      "loss": 0.0433,
      "step": 12410
    },
    {
      "epoch": 2.8517922794117645,
      "grad_norm": 1.325026512145996,
      "learning_rate": 4.7768586601307195e-06,
      "loss": 0.078,
      "step": 12411
    },
    {
      "epoch": 2.8520220588235294,
      "grad_norm": 0.9725186228752136,
      "learning_rate": 4.7763480392156866e-06,
      "loss": 0.0328,
      "step": 12412
    },
    {
      "epoch": 2.8522518382352944,
      "grad_norm": 1.0826940536499023,
      "learning_rate": 4.7758374183006536e-06,
      "loss": 0.0412,
      "step": 12413
    },
    {
      "epoch": 2.852481617647059,
      "grad_norm": 0.9463297128677368,
      "learning_rate": 4.7753267973856214e-06,
      "loss": 0.0456,
      "step": 12414
    },
    {
      "epoch": 2.8527113970588234,
      "grad_norm": 0.9734913110733032,
      "learning_rate": 4.7748161764705885e-06,
      "loss": 0.0368,
      "step": 12415
    },
    {
      "epoch": 2.8529411764705883,
      "grad_norm": 1.0596109628677368,
      "learning_rate": 4.774305555555556e-06,
      "loss": 0.0452,
      "step": 12416
    },
    {
      "epoch": 2.853170955882353,
      "grad_norm": 1.112317681312561,
      "learning_rate": 4.773794934640523e-06,
      "loss": 0.0572,
      "step": 12417
    },
    {
      "epoch": 2.8534007352941178,
      "grad_norm": 0.8982276916503906,
      "learning_rate": 4.773284313725491e-06,
      "loss": 0.0419,
      "step": 12418
    },
    {
      "epoch": 2.8536305147058822,
      "grad_norm": 0.8316593766212463,
      "learning_rate": 4.772773692810458e-06,
      "loss": 0.0355,
      "step": 12419
    },
    {
      "epoch": 2.853860294117647,
      "grad_norm": 0.7891138792037964,
      "learning_rate": 4.772263071895425e-06,
      "loss": 0.0236,
      "step": 12420
    },
    {
      "epoch": 2.8540900735294117,
      "grad_norm": 0.5243480205535889,
      "learning_rate": 4.771752450980392e-06,
      "loss": 0.0124,
      "step": 12421
    },
    {
      "epoch": 2.8543198529411766,
      "grad_norm": 0.7183535099029541,
      "learning_rate": 4.77124183006536e-06,
      "loss": 0.0326,
      "step": 12422
    },
    {
      "epoch": 2.854549632352941,
      "grad_norm": 0.974159300327301,
      "learning_rate": 4.770731209150327e-06,
      "loss": 0.0458,
      "step": 12423
    },
    {
      "epoch": 2.8547794117647056,
      "grad_norm": 0.8262898325920105,
      "learning_rate": 4.770220588235295e-06,
      "loss": 0.0355,
      "step": 12424
    },
    {
      "epoch": 2.8550091911764706,
      "grad_norm": 0.8480653166770935,
      "learning_rate": 4.769709967320262e-06,
      "loss": 0.0254,
      "step": 12425
    },
    {
      "epoch": 2.8552389705882355,
      "grad_norm": 1.0442370176315308,
      "learning_rate": 4.769199346405229e-06,
      "loss": 0.0569,
      "step": 12426
    },
    {
      "epoch": 2.85546875,
      "grad_norm": 1.076735019683838,
      "learning_rate": 4.768688725490197e-06,
      "loss": 0.0409,
      "step": 12427
    },
    {
      "epoch": 2.8556985294117645,
      "grad_norm": 0.8347008228302002,
      "learning_rate": 4.768178104575164e-06,
      "loss": 0.0333,
      "step": 12428
    },
    {
      "epoch": 2.8559283088235294,
      "grad_norm": 0.8818522691726685,
      "learning_rate": 4.767667483660131e-06,
      "loss": 0.0282,
      "step": 12429
    },
    {
      "epoch": 2.8561580882352944,
      "grad_norm": 1.010323405265808,
      "learning_rate": 4.767156862745099e-06,
      "loss": 0.0482,
      "step": 12430
    },
    {
      "epoch": 2.856387867647059,
      "grad_norm": 0.9549342393875122,
      "learning_rate": 4.766646241830066e-06,
      "loss": 0.0451,
      "step": 12431
    },
    {
      "epoch": 2.8566176470588234,
      "grad_norm": 0.8457433581352234,
      "learning_rate": 4.766135620915034e-06,
      "loss": 0.0381,
      "step": 12432
    },
    {
      "epoch": 2.8568474264705883,
      "grad_norm": 1.146908164024353,
      "learning_rate": 4.765625000000001e-06,
      "loss": 0.0414,
      "step": 12433
    },
    {
      "epoch": 2.857077205882353,
      "grad_norm": 0.8183826804161072,
      "learning_rate": 4.765114379084968e-06,
      "loss": 0.0308,
      "step": 12434
    },
    {
      "epoch": 2.8573069852941178,
      "grad_norm": 0.9739585518836975,
      "learning_rate": 4.764603758169935e-06,
      "loss": 0.0439,
      "step": 12435
    },
    {
      "epoch": 2.8575367647058822,
      "grad_norm": 0.7389104962348938,
      "learning_rate": 4.764093137254902e-06,
      "loss": 0.0211,
      "step": 12436
    },
    {
      "epoch": 2.857766544117647,
      "grad_norm": 0.721850574016571,
      "learning_rate": 4.7635825163398695e-06,
      "loss": 0.0171,
      "step": 12437
    },
    {
      "epoch": 2.8579963235294117,
      "grad_norm": 0.847824215888977,
      "learning_rate": 4.7630718954248366e-06,
      "loss": 0.0326,
      "step": 12438
    },
    {
      "epoch": 2.8582261029411766,
      "grad_norm": 0.8564535975456238,
      "learning_rate": 4.762561274509804e-06,
      "loss": 0.0264,
      "step": 12439
    },
    {
      "epoch": 2.858455882352941,
      "grad_norm": 0.7988131046295166,
      "learning_rate": 4.7620506535947714e-06,
      "loss": 0.0301,
      "step": 12440
    },
    {
      "epoch": 2.8586856617647056,
      "grad_norm": 1.1724166870117188,
      "learning_rate": 4.761540032679739e-06,
      "loss": 0.0553,
      "step": 12441
    },
    {
      "epoch": 2.8589154411764706,
      "grad_norm": 0.9662587642669678,
      "learning_rate": 4.761029411764706e-06,
      "loss": 0.0511,
      "step": 12442
    },
    {
      "epoch": 2.8591452205882355,
      "grad_norm": 0.7294086217880249,
      "learning_rate": 4.760518790849673e-06,
      "loss": 0.0332,
      "step": 12443
    },
    {
      "epoch": 2.859375,
      "grad_norm": 0.9326704144477844,
      "learning_rate": 4.76000816993464e-06,
      "loss": 0.04,
      "step": 12444
    },
    {
      "epoch": 2.8596047794117645,
      "grad_norm": 0.6570813655853271,
      "learning_rate": 4.759497549019608e-06,
      "loss": 0.0277,
      "step": 12445
    },
    {
      "epoch": 2.8598345588235294,
      "grad_norm": 1.4506932497024536,
      "learning_rate": 4.758986928104575e-06,
      "loss": 0.0679,
      "step": 12446
    },
    {
      "epoch": 2.8600643382352944,
      "grad_norm": 1.3423173427581787,
      "learning_rate": 4.758476307189543e-06,
      "loss": 0.0636,
      "step": 12447
    },
    {
      "epoch": 2.860294117647059,
      "grad_norm": 0.9368056654930115,
      "learning_rate": 4.75796568627451e-06,
      "loss": 0.0364,
      "step": 12448
    },
    {
      "epoch": 2.8605238970588234,
      "grad_norm": 0.8615005016326904,
      "learning_rate": 4.757455065359478e-06,
      "loss": 0.0404,
      "step": 12449
    },
    {
      "epoch": 2.8607536764705883,
      "grad_norm": 0.7072017192840576,
      "learning_rate": 4.756944444444445e-06,
      "loss": 0.0279,
      "step": 12450
    },
    {
      "epoch": 2.860983455882353,
      "grad_norm": 1.2119289636611938,
      "learning_rate": 4.756433823529412e-06,
      "loss": 0.0538,
      "step": 12451
    },
    {
      "epoch": 2.8612132352941178,
      "grad_norm": 1.3161197900772095,
      "learning_rate": 4.755923202614379e-06,
      "loss": 0.0501,
      "step": 12452
    },
    {
      "epoch": 2.8614430147058822,
      "grad_norm": 0.9486405849456787,
      "learning_rate": 4.755412581699347e-06,
      "loss": 0.0474,
      "step": 12453
    },
    {
      "epoch": 2.861672794117647,
      "grad_norm": 1.1589245796203613,
      "learning_rate": 4.754901960784314e-06,
      "loss": 0.0366,
      "step": 12454
    },
    {
      "epoch": 2.8619025735294117,
      "grad_norm": 0.96617591381073,
      "learning_rate": 4.754391339869282e-06,
      "loss": 0.0253,
      "step": 12455
    },
    {
      "epoch": 2.8621323529411766,
      "grad_norm": 0.9977214932441711,
      "learning_rate": 4.753880718954249e-06,
      "loss": 0.0476,
      "step": 12456
    },
    {
      "epoch": 2.862362132352941,
      "grad_norm": 0.990536093711853,
      "learning_rate": 4.753370098039216e-06,
      "loss": 0.0354,
      "step": 12457
    },
    {
      "epoch": 2.8625919117647056,
      "grad_norm": 1.2092827558517456,
      "learning_rate": 4.752859477124183e-06,
      "loss": 0.0428,
      "step": 12458
    },
    {
      "epoch": 2.8628216911764706,
      "grad_norm": 0.9900290966033936,
      "learning_rate": 4.752348856209151e-06,
      "loss": 0.0407,
      "step": 12459
    },
    {
      "epoch": 2.8630514705882355,
      "grad_norm": 0.8414373397827148,
      "learning_rate": 4.751838235294118e-06,
      "loss": 0.0394,
      "step": 12460
    },
    {
      "epoch": 2.86328125,
      "grad_norm": 1.1221363544464111,
      "learning_rate": 4.7513276143790855e-06,
      "loss": 0.0538,
      "step": 12461
    },
    {
      "epoch": 2.8635110294117645,
      "grad_norm": 0.8679177165031433,
      "learning_rate": 4.7508169934640525e-06,
      "loss": 0.043,
      "step": 12462
    },
    {
      "epoch": 2.8637408088235294,
      "grad_norm": 0.7629793882369995,
      "learning_rate": 4.75030637254902e-06,
      "loss": 0.0318,
      "step": 12463
    },
    {
      "epoch": 2.8639705882352944,
      "grad_norm": 0.9581804871559143,
      "learning_rate": 4.749795751633987e-06,
      "loss": 0.0422,
      "step": 12464
    },
    {
      "epoch": 2.864200367647059,
      "grad_norm": 0.8517807126045227,
      "learning_rate": 4.749285130718954e-06,
      "loss": 0.0345,
      "step": 12465
    },
    {
      "epoch": 2.8644301470588234,
      "grad_norm": 1.1117960214614868,
      "learning_rate": 4.7487745098039214e-06,
      "loss": 0.0461,
      "step": 12466
    },
    {
      "epoch": 2.8646599264705883,
      "grad_norm": 0.8152185082435608,
      "learning_rate": 4.748263888888889e-06,
      "loss": 0.0368,
      "step": 12467
    },
    {
      "epoch": 2.864889705882353,
      "grad_norm": 1.277408480644226,
      "learning_rate": 4.747753267973856e-06,
      "loss": 0.0528,
      "step": 12468
    },
    {
      "epoch": 2.8651194852941178,
      "grad_norm": 0.7645505666732788,
      "learning_rate": 4.747242647058824e-06,
      "loss": 0.0297,
      "step": 12469
    },
    {
      "epoch": 2.8653492647058822,
      "grad_norm": 0.9165648221969604,
      "learning_rate": 4.746732026143791e-06,
      "loss": 0.0276,
      "step": 12470
    },
    {
      "epoch": 2.865579044117647,
      "grad_norm": 1.1797370910644531,
      "learning_rate": 4.746221405228759e-06,
      "loss": 0.0566,
      "step": 12471
    },
    {
      "epoch": 2.8658088235294117,
      "grad_norm": 0.8413130640983582,
      "learning_rate": 4.745710784313726e-06,
      "loss": 0.0375,
      "step": 12472
    },
    {
      "epoch": 2.8660386029411766,
      "grad_norm": 1.0505400896072388,
      "learning_rate": 4.745200163398693e-06,
      "loss": 0.043,
      "step": 12473
    },
    {
      "epoch": 2.866268382352941,
      "grad_norm": 0.856593906879425,
      "learning_rate": 4.74468954248366e-06,
      "loss": 0.0316,
      "step": 12474
    },
    {
      "epoch": 2.8664981617647056,
      "grad_norm": 0.8810541033744812,
      "learning_rate": 4.744178921568628e-06,
      "loss": 0.0349,
      "step": 12475
    },
    {
      "epoch": 2.8667279411764706,
      "grad_norm": 1.1966146230697632,
      "learning_rate": 4.743668300653595e-06,
      "loss": 0.0519,
      "step": 12476
    },
    {
      "epoch": 2.8669577205882355,
      "grad_norm": 0.5108185410499573,
      "learning_rate": 4.743157679738563e-06,
      "loss": 0.0205,
      "step": 12477
    },
    {
      "epoch": 2.8671875,
      "grad_norm": 0.8859243392944336,
      "learning_rate": 4.74264705882353e-06,
      "loss": 0.0398,
      "step": 12478
    },
    {
      "epoch": 2.8674172794117645,
      "grad_norm": 0.937623143196106,
      "learning_rate": 4.742136437908497e-06,
      "loss": 0.0416,
      "step": 12479
    },
    {
      "epoch": 2.8676470588235294,
      "grad_norm": 1.0026640892028809,
      "learning_rate": 4.741625816993464e-06,
      "loss": 0.0587,
      "step": 12480
    },
    {
      "epoch": 2.8678768382352944,
      "grad_norm": 1.4955419301986694,
      "learning_rate": 4.741115196078432e-06,
      "loss": 0.0579,
      "step": 12481
    },
    {
      "epoch": 2.868106617647059,
      "grad_norm": 0.9223200082778931,
      "learning_rate": 4.740604575163399e-06,
      "loss": 0.0354,
      "step": 12482
    },
    {
      "epoch": 2.8683363970588234,
      "grad_norm": 0.6954981684684753,
      "learning_rate": 4.740093954248367e-06,
      "loss": 0.0244,
      "step": 12483
    },
    {
      "epoch": 2.8685661764705883,
      "grad_norm": 0.7095933556556702,
      "learning_rate": 4.739583333333334e-06,
      "loss": 0.0229,
      "step": 12484
    },
    {
      "epoch": 2.868795955882353,
      "grad_norm": 0.7603880763053894,
      "learning_rate": 4.7390727124183015e-06,
      "loss": 0.0326,
      "step": 12485
    },
    {
      "epoch": 2.8690257352941178,
      "grad_norm": 1.1949959993362427,
      "learning_rate": 4.7385620915032685e-06,
      "loss": 0.0536,
      "step": 12486
    },
    {
      "epoch": 2.8692555147058822,
      "grad_norm": 1.0454689264297485,
      "learning_rate": 4.7380514705882355e-06,
      "loss": 0.0367,
      "step": 12487
    },
    {
      "epoch": 2.869485294117647,
      "grad_norm": 0.844484806060791,
      "learning_rate": 4.7375408496732025e-06,
      "loss": 0.0495,
      "step": 12488
    },
    {
      "epoch": 2.8697150735294117,
      "grad_norm": 1.0547319650650024,
      "learning_rate": 4.73703022875817e-06,
      "loss": 0.041,
      "step": 12489
    },
    {
      "epoch": 2.8699448529411766,
      "grad_norm": 0.9316116571426392,
      "learning_rate": 4.736519607843137e-06,
      "loss": 0.0391,
      "step": 12490
    },
    {
      "epoch": 2.870174632352941,
      "grad_norm": 0.9308735728263855,
      "learning_rate": 4.736008986928105e-06,
      "loss": 0.0453,
      "step": 12491
    },
    {
      "epoch": 2.8704044117647056,
      "grad_norm": 1.0482547283172607,
      "learning_rate": 4.735498366013072e-06,
      "loss": 0.042,
      "step": 12492
    },
    {
      "epoch": 2.8706341911764706,
      "grad_norm": 1.1254945993423462,
      "learning_rate": 4.734987745098039e-06,
      "loss": 0.03,
      "step": 12493
    },
    {
      "epoch": 2.8708639705882355,
      "grad_norm": 1.186980128288269,
      "learning_rate": 4.734477124183007e-06,
      "loss": 0.0518,
      "step": 12494
    },
    {
      "epoch": 2.87109375,
      "grad_norm": 0.8876209259033203,
      "learning_rate": 4.733966503267974e-06,
      "loss": 0.0538,
      "step": 12495
    },
    {
      "epoch": 2.8713235294117645,
      "grad_norm": 1.2381707429885864,
      "learning_rate": 4.733455882352941e-06,
      "loss": 0.0658,
      "step": 12496
    },
    {
      "epoch": 2.8715533088235294,
      "grad_norm": 0.7479816675186157,
      "learning_rate": 4.732945261437909e-06,
      "loss": 0.0326,
      "step": 12497
    },
    {
      "epoch": 2.8717830882352944,
      "grad_norm": 0.8273930549621582,
      "learning_rate": 4.732434640522876e-06,
      "loss": 0.0211,
      "step": 12498
    },
    {
      "epoch": 2.872012867647059,
      "grad_norm": 0.5620341300964355,
      "learning_rate": 4.731924019607844e-06,
      "loss": 0.021,
      "step": 12499
    },
    {
      "epoch": 2.8722426470588234,
      "grad_norm": 0.7894870638847351,
      "learning_rate": 4.731413398692811e-06,
      "loss": 0.0337,
      "step": 12500
    },
    {
      "epoch": 2.8722426470588234,
      "eval_loss": 0.044333383440971375,
      "eval_runtime": 2006.5462,
      "eval_samples_per_second": 4.438,
      "eval_steps_per_second": 2.219,
      "step": 12500
    },
    {
      "epoch": 2.8724724264705883,
      "grad_norm": 0.9948020577430725,
      "learning_rate": 4.730902777777778e-06,
      "loss": 0.0294,
      "step": 12501
    },
    {
      "epoch": 2.872702205882353,
      "grad_norm": 0.9973068237304688,
      "learning_rate": 4.730392156862745e-06,
      "loss": 0.0369,
      "step": 12502
    },
    {
      "epoch": 2.8729319852941178,
      "grad_norm": 1.0149061679840088,
      "learning_rate": 4.729881535947713e-06,
      "loss": 0.0347,
      "step": 12503
    },
    {
      "epoch": 2.8731617647058822,
      "grad_norm": 0.6496778726577759,
      "learning_rate": 4.72937091503268e-06,
      "loss": 0.0288,
      "step": 12504
    },
    {
      "epoch": 2.873391544117647,
      "grad_norm": 0.9973568320274353,
      "learning_rate": 4.728860294117648e-06,
      "loss": 0.0513,
      "step": 12505
    },
    {
      "epoch": 2.8736213235294117,
      "grad_norm": 0.6871604323387146,
      "learning_rate": 4.728349673202615e-06,
      "loss": 0.0221,
      "step": 12506
    },
    {
      "epoch": 2.8738511029411766,
      "grad_norm": 0.9563209414482117,
      "learning_rate": 4.727839052287583e-06,
      "loss": 0.0355,
      "step": 12507
    },
    {
      "epoch": 2.874080882352941,
      "grad_norm": 0.8793860077857971,
      "learning_rate": 4.72732843137255e-06,
      "loss": 0.0442,
      "step": 12508
    },
    {
      "epoch": 2.8743106617647056,
      "grad_norm": 0.8908469080924988,
      "learning_rate": 4.726817810457517e-06,
      "loss": 0.0287,
      "step": 12509
    },
    {
      "epoch": 2.8745404411764706,
      "grad_norm": 0.9192293286323547,
      "learning_rate": 4.726307189542484e-06,
      "loss": 0.036,
      "step": 12510
    },
    {
      "epoch": 2.8747702205882355,
      "grad_norm": 1.3643746376037598,
      "learning_rate": 4.7257965686274515e-06,
      "loss": 0.0493,
      "step": 12511
    },
    {
      "epoch": 2.875,
      "grad_norm": 0.7667855620384216,
      "learning_rate": 4.7252859477124185e-06,
      "loss": 0.0421,
      "step": 12512
    },
    {
      "epoch": 2.8752297794117645,
      "grad_norm": 0.888859212398529,
      "learning_rate": 4.724775326797386e-06,
      "loss": 0.0261,
      "step": 12513
    },
    {
      "epoch": 2.8754595588235294,
      "grad_norm": 1.2500003576278687,
      "learning_rate": 4.724264705882353e-06,
      "loss": 0.0591,
      "step": 12514
    },
    {
      "epoch": 2.8756893382352944,
      "grad_norm": 0.7557210326194763,
      "learning_rate": 4.72375408496732e-06,
      "loss": 0.0298,
      "step": 12515
    },
    {
      "epoch": 2.875919117647059,
      "grad_norm": 1.1809500455856323,
      "learning_rate": 4.723243464052288e-06,
      "loss": 0.0315,
      "step": 12516
    },
    {
      "epoch": 2.8761488970588234,
      "grad_norm": 0.9944943189620972,
      "learning_rate": 4.722732843137255e-06,
      "loss": 0.033,
      "step": 12517
    },
    {
      "epoch": 2.8763786764705883,
      "grad_norm": 0.8996578454971313,
      "learning_rate": 4.722222222222222e-06,
      "loss": 0.0538,
      "step": 12518
    },
    {
      "epoch": 2.876608455882353,
      "grad_norm": 1.3840664625167847,
      "learning_rate": 4.72171160130719e-06,
      "loss": 0.0464,
      "step": 12519
    },
    {
      "epoch": 2.8768382352941178,
      "grad_norm": 0.8239704966545105,
      "learning_rate": 4.721200980392157e-06,
      "loss": 0.0213,
      "step": 12520
    },
    {
      "epoch": 2.8770680147058822,
      "grad_norm": 0.9129224419593811,
      "learning_rate": 4.720690359477125e-06,
      "loss": 0.04,
      "step": 12521
    },
    {
      "epoch": 2.877297794117647,
      "grad_norm": 1.0974293947219849,
      "learning_rate": 4.720179738562092e-06,
      "loss": 0.055,
      "step": 12522
    },
    {
      "epoch": 2.8775275735294117,
      "grad_norm": 0.8973863124847412,
      "learning_rate": 4.719669117647059e-06,
      "loss": 0.0425,
      "step": 12523
    },
    {
      "epoch": 2.8777573529411766,
      "grad_norm": 1.011505126953125,
      "learning_rate": 4.719158496732026e-06,
      "loss": 0.0415,
      "step": 12524
    },
    {
      "epoch": 2.877987132352941,
      "grad_norm": 0.8339554071426392,
      "learning_rate": 4.718647875816994e-06,
      "loss": 0.0362,
      "step": 12525
    },
    {
      "epoch": 2.8782169117647056,
      "grad_norm": 0.8072992563247681,
      "learning_rate": 4.718137254901961e-06,
      "loss": 0.0338,
      "step": 12526
    },
    {
      "epoch": 2.8784466911764706,
      "grad_norm": 0.7346842288970947,
      "learning_rate": 4.717626633986929e-06,
      "loss": 0.0315,
      "step": 12527
    },
    {
      "epoch": 2.8786764705882355,
      "grad_norm": 0.9506469964981079,
      "learning_rate": 4.717116013071896e-06,
      "loss": 0.0518,
      "step": 12528
    },
    {
      "epoch": 2.87890625,
      "grad_norm": 0.8255664110183716,
      "learning_rate": 4.716605392156864e-06,
      "loss": 0.0314,
      "step": 12529
    },
    {
      "epoch": 2.8791360294117645,
      "grad_norm": 1.0572131872177124,
      "learning_rate": 4.716094771241831e-06,
      "loss": 0.0573,
      "step": 12530
    },
    {
      "epoch": 2.8793658088235294,
      "grad_norm": 0.8957965970039368,
      "learning_rate": 4.715584150326798e-06,
      "loss": 0.0624,
      "step": 12531
    },
    {
      "epoch": 2.8795955882352944,
      "grad_norm": 0.9337263703346252,
      "learning_rate": 4.715073529411765e-06,
      "loss": 0.0469,
      "step": 12532
    },
    {
      "epoch": 2.879825367647059,
      "grad_norm": 1.0345903635025024,
      "learning_rate": 4.714562908496733e-06,
      "loss": 0.0319,
      "step": 12533
    },
    {
      "epoch": 2.8800551470588234,
      "grad_norm": 1.2433195114135742,
      "learning_rate": 4.7140522875817e-06,
      "loss": 0.0541,
      "step": 12534
    },
    {
      "epoch": 2.8802849264705883,
      "grad_norm": 1.085010290145874,
      "learning_rate": 4.7135416666666675e-06,
      "loss": 0.0492,
      "step": 12535
    },
    {
      "epoch": 2.880514705882353,
      "grad_norm": 0.8481053709983826,
      "learning_rate": 4.7130310457516345e-06,
      "loss": 0.0367,
      "step": 12536
    },
    {
      "epoch": 2.8807444852941178,
      "grad_norm": 0.7871527075767517,
      "learning_rate": 4.7125204248366015e-06,
      "loss": 0.0235,
      "step": 12537
    },
    {
      "epoch": 2.8809742647058822,
      "grad_norm": 0.9868716597557068,
      "learning_rate": 4.712009803921569e-06,
      "loss": 0.0447,
      "step": 12538
    },
    {
      "epoch": 2.881204044117647,
      "grad_norm": 0.8694427013397217,
      "learning_rate": 4.711499183006536e-06,
      "loss": 0.0364,
      "step": 12539
    },
    {
      "epoch": 2.8814338235294117,
      "grad_norm": 0.9805411100387573,
      "learning_rate": 4.710988562091503e-06,
      "loss": 0.0415,
      "step": 12540
    },
    {
      "epoch": 2.8816636029411766,
      "grad_norm": 1.2615395784378052,
      "learning_rate": 4.710477941176471e-06,
      "loss": 0.0694,
      "step": 12541
    },
    {
      "epoch": 2.881893382352941,
      "grad_norm": 0.9761202931404114,
      "learning_rate": 4.709967320261438e-06,
      "loss": 0.0449,
      "step": 12542
    },
    {
      "epoch": 2.8821231617647056,
      "grad_norm": 0.78704833984375,
      "learning_rate": 4.709456699346406e-06,
      "loss": 0.0285,
      "step": 12543
    },
    {
      "epoch": 2.8823529411764706,
      "grad_norm": 0.8692733645439148,
      "learning_rate": 4.708946078431373e-06,
      "loss": 0.0427,
      "step": 12544
    },
    {
      "epoch": 2.8825827205882355,
      "grad_norm": 0.9082254767417908,
      "learning_rate": 4.70843545751634e-06,
      "loss": 0.0393,
      "step": 12545
    },
    {
      "epoch": 2.8828125,
      "grad_norm": 1.4174883365631104,
      "learning_rate": 4.707924836601307e-06,
      "loss": 0.0488,
      "step": 12546
    },
    {
      "epoch": 2.8830422794117645,
      "grad_norm": 0.7392109036445618,
      "learning_rate": 4.707414215686275e-06,
      "loss": 0.0286,
      "step": 12547
    },
    {
      "epoch": 2.8832720588235294,
      "grad_norm": 0.7926936149597168,
      "learning_rate": 4.706903594771242e-06,
      "loss": 0.0402,
      "step": 12548
    },
    {
      "epoch": 2.8835018382352944,
      "grad_norm": 0.6812323927879333,
      "learning_rate": 4.70639297385621e-06,
      "loss": 0.0253,
      "step": 12549
    },
    {
      "epoch": 2.883731617647059,
      "grad_norm": 1.6840165853500366,
      "learning_rate": 4.705882352941177e-06,
      "loss": 0.1084,
      "step": 12550
    },
    {
      "epoch": 2.8839613970588234,
      "grad_norm": 0.6423259973526001,
      "learning_rate": 4.705371732026145e-06,
      "loss": 0.0391,
      "step": 12551
    },
    {
      "epoch": 2.8841911764705883,
      "grad_norm": 0.9547125697135925,
      "learning_rate": 4.704861111111112e-06,
      "loss": 0.0467,
      "step": 12552
    },
    {
      "epoch": 2.884420955882353,
      "grad_norm": 0.9246789813041687,
      "learning_rate": 4.704350490196079e-06,
      "loss": 0.0584,
      "step": 12553
    },
    {
      "epoch": 2.8846507352941178,
      "grad_norm": 1.140680193901062,
      "learning_rate": 4.703839869281046e-06,
      "loss": 0.0795,
      "step": 12554
    },
    {
      "epoch": 2.8848805147058822,
      "grad_norm": 0.9070611000061035,
      "learning_rate": 4.703329248366014e-06,
      "loss": 0.0435,
      "step": 12555
    },
    {
      "epoch": 2.885110294117647,
      "grad_norm": 0.8110395669937134,
      "learning_rate": 4.702818627450981e-06,
      "loss": 0.0321,
      "step": 12556
    },
    {
      "epoch": 2.8853400735294117,
      "grad_norm": 1.2164546251296997,
      "learning_rate": 4.7023080065359485e-06,
      "loss": 0.0591,
      "step": 12557
    },
    {
      "epoch": 2.8855698529411766,
      "grad_norm": 0.7577088475227356,
      "learning_rate": 4.7017973856209156e-06,
      "loss": 0.0289,
      "step": 12558
    },
    {
      "epoch": 2.885799632352941,
      "grad_norm": 0.9643139839172363,
      "learning_rate": 4.7012867647058826e-06,
      "loss": 0.0333,
      "step": 12559
    },
    {
      "epoch": 2.8860294117647056,
      "grad_norm": 0.7816805243492126,
      "learning_rate": 4.70077614379085e-06,
      "loss": 0.0233,
      "step": 12560
    },
    {
      "epoch": 2.8862591911764706,
      "grad_norm": 1.208357572555542,
      "learning_rate": 4.7002655228758175e-06,
      "loss": 0.0472,
      "step": 12561
    },
    {
      "epoch": 2.8864889705882355,
      "grad_norm": 1.24091637134552,
      "learning_rate": 4.6997549019607845e-06,
      "loss": 0.0553,
      "step": 12562
    },
    {
      "epoch": 2.88671875,
      "grad_norm": 1.0038930177688599,
      "learning_rate": 4.699244281045752e-06,
      "loss": 0.0328,
      "step": 12563
    },
    {
      "epoch": 2.8869485294117645,
      "grad_norm": 0.7166935205459595,
      "learning_rate": 4.698733660130719e-06,
      "loss": 0.0355,
      "step": 12564
    },
    {
      "epoch": 2.8871783088235294,
      "grad_norm": 1.2815806865692139,
      "learning_rate": 4.698223039215687e-06,
      "loss": 0.0514,
      "step": 12565
    },
    {
      "epoch": 2.8874080882352944,
      "grad_norm": 0.7944867014884949,
      "learning_rate": 4.697712418300654e-06,
      "loss": 0.03,
      "step": 12566
    },
    {
      "epoch": 2.887637867647059,
      "grad_norm": 0.8524795770645142,
      "learning_rate": 4.697201797385621e-06,
      "loss": 0.0507,
      "step": 12567
    },
    {
      "epoch": 2.8878676470588234,
      "grad_norm": 0.989769458770752,
      "learning_rate": 4.696691176470588e-06,
      "loss": 0.0491,
      "step": 12568
    },
    {
      "epoch": 2.8880974264705883,
      "grad_norm": 0.7885070443153381,
      "learning_rate": 4.696180555555556e-06,
      "loss": 0.0412,
      "step": 12569
    },
    {
      "epoch": 2.888327205882353,
      "grad_norm": 0.9889886975288391,
      "learning_rate": 4.695669934640523e-06,
      "loss": 0.0397,
      "step": 12570
    },
    {
      "epoch": 2.8885569852941178,
      "grad_norm": 0.9303694367408752,
      "learning_rate": 4.695159313725491e-06,
      "loss": 0.0419,
      "step": 12571
    },
    {
      "epoch": 2.8887867647058822,
      "grad_norm": 1.08664071559906,
      "learning_rate": 4.694648692810458e-06,
      "loss": 0.0612,
      "step": 12572
    },
    {
      "epoch": 2.889016544117647,
      "grad_norm": 0.8991473913192749,
      "learning_rate": 4.694138071895426e-06,
      "loss": 0.0379,
      "step": 12573
    },
    {
      "epoch": 2.8892463235294117,
      "grad_norm": 1.009206771850586,
      "learning_rate": 4.693627450980393e-06,
      "loss": 0.0501,
      "step": 12574
    },
    {
      "epoch": 2.8894761029411766,
      "grad_norm": 0.8901565670967102,
      "learning_rate": 4.69311683006536e-06,
      "loss": 0.0436,
      "step": 12575
    },
    {
      "epoch": 2.889705882352941,
      "grad_norm": 0.8577218055725098,
      "learning_rate": 4.692606209150327e-06,
      "loss": 0.0251,
      "step": 12576
    },
    {
      "epoch": 2.8899356617647056,
      "grad_norm": 1.0090410709381104,
      "learning_rate": 4.692095588235295e-06,
      "loss": 0.0488,
      "step": 12577
    },
    {
      "epoch": 2.8901654411764706,
      "grad_norm": 0.9217844009399414,
      "learning_rate": 4.691584967320262e-06,
      "loss": 0.0345,
      "step": 12578
    },
    {
      "epoch": 2.8903952205882355,
      "grad_norm": 1.0809739828109741,
      "learning_rate": 4.69107434640523e-06,
      "loss": 0.0651,
      "step": 12579
    },
    {
      "epoch": 2.890625,
      "grad_norm": 0.9049465656280518,
      "learning_rate": 4.690563725490197e-06,
      "loss": 0.0371,
      "step": 12580
    },
    {
      "epoch": 2.8908547794117645,
      "grad_norm": 0.713164210319519,
      "learning_rate": 4.690053104575164e-06,
      "loss": 0.0341,
      "step": 12581
    },
    {
      "epoch": 2.8910845588235294,
      "grad_norm": 0.9030759334564209,
      "learning_rate": 4.689542483660131e-06,
      "loss": 0.0514,
      "step": 12582
    },
    {
      "epoch": 2.8913143382352944,
      "grad_norm": 0.9036017656326294,
      "learning_rate": 4.6890318627450985e-06,
      "loss": 0.0371,
      "step": 12583
    },
    {
      "epoch": 2.891544117647059,
      "grad_norm": 1.0186389684677124,
      "learning_rate": 4.6885212418300656e-06,
      "loss": 0.05,
      "step": 12584
    },
    {
      "epoch": 2.8917738970588234,
      "grad_norm": 0.8720951080322266,
      "learning_rate": 4.688010620915033e-06,
      "loss": 0.0416,
      "step": 12585
    },
    {
      "epoch": 2.8920036764705883,
      "grad_norm": 0.8583978414535522,
      "learning_rate": 4.6875000000000004e-06,
      "loss": 0.0481,
      "step": 12586
    },
    {
      "epoch": 2.892233455882353,
      "grad_norm": 0.8808491826057434,
      "learning_rate": 4.6869893790849675e-06,
      "loss": 0.0424,
      "step": 12587
    },
    {
      "epoch": 2.8924632352941178,
      "grad_norm": 0.6462544202804565,
      "learning_rate": 4.686478758169935e-06,
      "loss": 0.0228,
      "step": 12588
    },
    {
      "epoch": 2.8926930147058822,
      "grad_norm": 1.086975336074829,
      "learning_rate": 4.685968137254902e-06,
      "loss": 0.0597,
      "step": 12589
    },
    {
      "epoch": 2.892922794117647,
      "grad_norm": 1.0416820049285889,
      "learning_rate": 4.685457516339869e-06,
      "loss": 0.0265,
      "step": 12590
    },
    {
      "epoch": 2.8931525735294117,
      "grad_norm": 1.054900050163269,
      "learning_rate": 4.684946895424836e-06,
      "loss": 0.0424,
      "step": 12591
    },
    {
      "epoch": 2.8933823529411766,
      "grad_norm": 0.974133312702179,
      "learning_rate": 4.684436274509804e-06,
      "loss": 0.0321,
      "step": 12592
    },
    {
      "epoch": 2.893612132352941,
      "grad_norm": 0.7690533399581909,
      "learning_rate": 4.683925653594771e-06,
      "loss": 0.0253,
      "step": 12593
    },
    {
      "epoch": 2.8938419117647056,
      "grad_norm": 0.9698582887649536,
      "learning_rate": 4.683415032679739e-06,
      "loss": 0.0389,
      "step": 12594
    },
    {
      "epoch": 2.8940716911764706,
      "grad_norm": 0.8152304887771606,
      "learning_rate": 4.682904411764706e-06,
      "loss": 0.0338,
      "step": 12595
    },
    {
      "epoch": 2.8943014705882355,
      "grad_norm": 1.4600608348846436,
      "learning_rate": 4.682393790849674e-06,
      "loss": 0.0587,
      "step": 12596
    },
    {
      "epoch": 2.89453125,
      "grad_norm": 0.9200457334518433,
      "learning_rate": 4.681883169934641e-06,
      "loss": 0.0548,
      "step": 12597
    },
    {
      "epoch": 2.8947610294117645,
      "grad_norm": 0.8886755108833313,
      "learning_rate": 4.681372549019608e-06,
      "loss": 0.0438,
      "step": 12598
    },
    {
      "epoch": 2.8949908088235294,
      "grad_norm": 1.0425748825073242,
      "learning_rate": 4.680861928104575e-06,
      "loss": 0.0405,
      "step": 12599
    },
    {
      "epoch": 2.8952205882352944,
      "grad_norm": 0.8786852955818176,
      "learning_rate": 4.680351307189543e-06,
      "loss": 0.0404,
      "step": 12600
    },
    {
      "epoch": 2.895450367647059,
      "grad_norm": 0.8531848192214966,
      "learning_rate": 4.67984068627451e-06,
      "loss": 0.0342,
      "step": 12601
    },
    {
      "epoch": 2.8956801470588234,
      "grad_norm": 1.0818347930908203,
      "learning_rate": 4.679330065359478e-06,
      "loss": 0.0548,
      "step": 12602
    },
    {
      "epoch": 2.8959099264705883,
      "grad_norm": 1.0245065689086914,
      "learning_rate": 4.678819444444445e-06,
      "loss": 0.0318,
      "step": 12603
    },
    {
      "epoch": 2.896139705882353,
      "grad_norm": 1.0093142986297607,
      "learning_rate": 4.678308823529412e-06,
      "loss": 0.0484,
      "step": 12604
    },
    {
      "epoch": 2.8963694852941178,
      "grad_norm": 0.946137011051178,
      "learning_rate": 4.67779820261438e-06,
      "loss": 0.0304,
      "step": 12605
    },
    {
      "epoch": 2.8965992647058822,
      "grad_norm": 0.8058091998100281,
      "learning_rate": 4.677287581699347e-06,
      "loss": 0.0375,
      "step": 12606
    },
    {
      "epoch": 2.896829044117647,
      "grad_norm": 1.0061510801315308,
      "learning_rate": 4.676776960784314e-06,
      "loss": 0.0436,
      "step": 12607
    },
    {
      "epoch": 2.8970588235294117,
      "grad_norm": 0.8911247253417969,
      "learning_rate": 4.6762663398692815e-06,
      "loss": 0.0416,
      "step": 12608
    },
    {
      "epoch": 2.8972886029411766,
      "grad_norm": 0.904792070388794,
      "learning_rate": 4.6757557189542485e-06,
      "loss": 0.0391,
      "step": 12609
    },
    {
      "epoch": 2.897518382352941,
      "grad_norm": 1.2571320533752441,
      "learning_rate": 4.675245098039216e-06,
      "loss": 0.0497,
      "step": 12610
    },
    {
      "epoch": 2.8977481617647056,
      "grad_norm": 0.9690021872520447,
      "learning_rate": 4.674734477124183e-06,
      "loss": 0.0447,
      "step": 12611
    },
    {
      "epoch": 2.8979779411764706,
      "grad_norm": 1.0433008670806885,
      "learning_rate": 4.6742238562091504e-06,
      "loss": 0.0373,
      "step": 12612
    },
    {
      "epoch": 2.8982077205882355,
      "grad_norm": 0.5677279233932495,
      "learning_rate": 4.6737132352941174e-06,
      "loss": 0.0184,
      "step": 12613
    },
    {
      "epoch": 2.8984375,
      "grad_norm": 0.9221081137657166,
      "learning_rate": 4.673202614379085e-06,
      "loss": 0.0323,
      "step": 12614
    },
    {
      "epoch": 2.8986672794117645,
      "grad_norm": 0.9176472425460815,
      "learning_rate": 4.672691993464052e-06,
      "loss": 0.0256,
      "step": 12615
    },
    {
      "epoch": 2.8988970588235294,
      "grad_norm": 1.036237359046936,
      "learning_rate": 4.67218137254902e-06,
      "loss": 0.0386,
      "step": 12616
    },
    {
      "epoch": 2.8991268382352944,
      "grad_norm": 1.0261085033416748,
      "learning_rate": 4.671670751633987e-06,
      "loss": 0.0467,
      "step": 12617
    },
    {
      "epoch": 2.899356617647059,
      "grad_norm": 1.0408204793930054,
      "learning_rate": 4.671160130718955e-06,
      "loss": 0.0444,
      "step": 12618
    },
    {
      "epoch": 2.8995863970588234,
      "grad_norm": 1.0056743621826172,
      "learning_rate": 4.670649509803922e-06,
      "loss": 0.0498,
      "step": 12619
    },
    {
      "epoch": 2.8998161764705883,
      "grad_norm": 1.122657060623169,
      "learning_rate": 4.670138888888889e-06,
      "loss": 0.0484,
      "step": 12620
    },
    {
      "epoch": 2.900045955882353,
      "grad_norm": 1.1075011491775513,
      "learning_rate": 4.669628267973856e-06,
      "loss": 0.0392,
      "step": 12621
    },
    {
      "epoch": 2.9002757352941178,
      "grad_norm": 1.2064907550811768,
      "learning_rate": 4.669117647058824e-06,
      "loss": 0.0581,
      "step": 12622
    },
    {
      "epoch": 2.9005055147058822,
      "grad_norm": 0.9005743265151978,
      "learning_rate": 4.668607026143791e-06,
      "loss": 0.0444,
      "step": 12623
    },
    {
      "epoch": 2.900735294117647,
      "grad_norm": 0.9307702779769897,
      "learning_rate": 4.668096405228759e-06,
      "loss": 0.0386,
      "step": 12624
    },
    {
      "epoch": 2.9009650735294117,
      "grad_norm": 1.0648843050003052,
      "learning_rate": 4.667585784313726e-06,
      "loss": 0.0506,
      "step": 12625
    },
    {
      "epoch": 2.9011948529411766,
      "grad_norm": 0.7797765731811523,
      "learning_rate": 4.667075163398693e-06,
      "loss": 0.0205,
      "step": 12626
    },
    {
      "epoch": 2.901424632352941,
      "grad_norm": 0.8743475675582886,
      "learning_rate": 4.66656454248366e-06,
      "loss": 0.044,
      "step": 12627
    },
    {
      "epoch": 2.9016544117647056,
      "grad_norm": 1.049724817276001,
      "learning_rate": 4.666053921568628e-06,
      "loss": 0.0324,
      "step": 12628
    },
    {
      "epoch": 2.9018841911764706,
      "grad_norm": 0.916977047920227,
      "learning_rate": 4.665543300653595e-06,
      "loss": 0.0477,
      "step": 12629
    },
    {
      "epoch": 2.9021139705882355,
      "grad_norm": 0.6403510570526123,
      "learning_rate": 4.665032679738563e-06,
      "loss": 0.0236,
      "step": 12630
    },
    {
      "epoch": 2.90234375,
      "grad_norm": 0.7125319242477417,
      "learning_rate": 4.66452205882353e-06,
      "loss": 0.0294,
      "step": 12631
    },
    {
      "epoch": 2.9025735294117645,
      "grad_norm": 0.8705291748046875,
      "learning_rate": 4.6640114379084975e-06,
      "loss": 0.0363,
      "step": 12632
    },
    {
      "epoch": 2.9028033088235294,
      "grad_norm": 0.8471569418907166,
      "learning_rate": 4.6635008169934645e-06,
      "loss": 0.0336,
      "step": 12633
    },
    {
      "epoch": 2.9030330882352944,
      "grad_norm": 0.683266818523407,
      "learning_rate": 4.6629901960784315e-06,
      "loss": 0.0375,
      "step": 12634
    },
    {
      "epoch": 2.903262867647059,
      "grad_norm": 0.49217498302459717,
      "learning_rate": 4.6624795751633985e-06,
      "loss": 0.0161,
      "step": 12635
    },
    {
      "epoch": 2.9034926470588234,
      "grad_norm": 0.608799159526825,
      "learning_rate": 4.661968954248366e-06,
      "loss": 0.0153,
      "step": 12636
    },
    {
      "epoch": 2.9037224264705883,
      "grad_norm": 0.7835713624954224,
      "learning_rate": 4.661458333333333e-06,
      "loss": 0.0328,
      "step": 12637
    },
    {
      "epoch": 2.903952205882353,
      "grad_norm": 0.9112241268157959,
      "learning_rate": 4.660947712418301e-06,
      "loss": 0.0466,
      "step": 12638
    },
    {
      "epoch": 2.9041819852941178,
      "grad_norm": 0.7776644825935364,
      "learning_rate": 4.660437091503268e-06,
      "loss": 0.0366,
      "step": 12639
    },
    {
      "epoch": 2.9044117647058822,
      "grad_norm": 0.7554966807365417,
      "learning_rate": 4.659926470588236e-06,
      "loss": 0.0335,
      "step": 12640
    },
    {
      "epoch": 2.904641544117647,
      "grad_norm": 0.9026305079460144,
      "learning_rate": 4.659415849673203e-06,
      "loss": 0.0442,
      "step": 12641
    },
    {
      "epoch": 2.9048713235294117,
      "grad_norm": 0.9893150329589844,
      "learning_rate": 4.65890522875817e-06,
      "loss": 0.05,
      "step": 12642
    },
    {
      "epoch": 2.9051011029411766,
      "grad_norm": 0.9068124890327454,
      "learning_rate": 4.658394607843137e-06,
      "loss": 0.0398,
      "step": 12643
    },
    {
      "epoch": 2.905330882352941,
      "grad_norm": 0.8305756449699402,
      "learning_rate": 4.657883986928105e-06,
      "loss": 0.0453,
      "step": 12644
    },
    {
      "epoch": 2.9055606617647056,
      "grad_norm": 0.7230596542358398,
      "learning_rate": 4.657373366013072e-06,
      "loss": 0.0278,
      "step": 12645
    },
    {
      "epoch": 2.9057904411764706,
      "grad_norm": 0.7389720678329468,
      "learning_rate": 4.65686274509804e-06,
      "loss": 0.0209,
      "step": 12646
    },
    {
      "epoch": 2.9060202205882355,
      "grad_norm": 0.8275640606880188,
      "learning_rate": 4.656352124183007e-06,
      "loss": 0.0375,
      "step": 12647
    },
    {
      "epoch": 2.90625,
      "grad_norm": 0.8993839025497437,
      "learning_rate": 4.655841503267974e-06,
      "loss": 0.0379,
      "step": 12648
    },
    {
      "epoch": 2.9064797794117645,
      "grad_norm": 0.9456440806388855,
      "learning_rate": 4.655330882352941e-06,
      "loss": 0.0437,
      "step": 12649
    },
    {
      "epoch": 2.9067095588235294,
      "grad_norm": 0.7941210865974426,
      "learning_rate": 4.654820261437909e-06,
      "loss": 0.0288,
      "step": 12650
    },
    {
      "epoch": 2.9069393382352944,
      "grad_norm": 0.6325044631958008,
      "learning_rate": 4.654309640522876e-06,
      "loss": 0.0238,
      "step": 12651
    },
    {
      "epoch": 2.907169117647059,
      "grad_norm": 1.3167164325714111,
      "learning_rate": 4.653799019607844e-06,
      "loss": 0.0576,
      "step": 12652
    },
    {
      "epoch": 2.9073988970588234,
      "grad_norm": 0.8488944172859192,
      "learning_rate": 4.653288398692811e-06,
      "loss": 0.0315,
      "step": 12653
    },
    {
      "epoch": 2.9076286764705883,
      "grad_norm": 0.9325525760650635,
      "learning_rate": 4.652777777777779e-06,
      "loss": 0.0238,
      "step": 12654
    },
    {
      "epoch": 2.907858455882353,
      "grad_norm": 0.8811128735542297,
      "learning_rate": 4.652267156862746e-06,
      "loss": 0.032,
      "step": 12655
    },
    {
      "epoch": 2.9080882352941178,
      "grad_norm": 0.7236031293869019,
      "learning_rate": 4.651756535947713e-06,
      "loss": 0.027,
      "step": 12656
    },
    {
      "epoch": 2.9083180147058822,
      "grad_norm": 0.7485277056694031,
      "learning_rate": 4.65124591503268e-06,
      "loss": 0.0323,
      "step": 12657
    },
    {
      "epoch": 2.908547794117647,
      "grad_norm": 0.7834179997444153,
      "learning_rate": 4.6507352941176475e-06,
      "loss": 0.0367,
      "step": 12658
    },
    {
      "epoch": 2.9087775735294117,
      "grad_norm": 0.9020988941192627,
      "learning_rate": 4.6502246732026145e-06,
      "loss": 0.0503,
      "step": 12659
    },
    {
      "epoch": 2.9090073529411766,
      "grad_norm": 0.7188431024551392,
      "learning_rate": 4.649714052287582e-06,
      "loss": 0.0387,
      "step": 12660
    },
    {
      "epoch": 2.909237132352941,
      "grad_norm": 0.9034604430198669,
      "learning_rate": 4.649203431372549e-06,
      "loss": 0.0421,
      "step": 12661
    },
    {
      "epoch": 2.9094669117647056,
      "grad_norm": 1.6241633892059326,
      "learning_rate": 4.648692810457517e-06,
      "loss": 0.057,
      "step": 12662
    },
    {
      "epoch": 2.9096966911764706,
      "grad_norm": 0.933205783367157,
      "learning_rate": 4.648182189542484e-06,
      "loss": 0.0277,
      "step": 12663
    },
    {
      "epoch": 2.9099264705882355,
      "grad_norm": 0.6978749632835388,
      "learning_rate": 4.647671568627451e-06,
      "loss": 0.0174,
      "step": 12664
    },
    {
      "epoch": 2.91015625,
      "grad_norm": 1.0005143880844116,
      "learning_rate": 4.647160947712418e-06,
      "loss": 0.0361,
      "step": 12665
    },
    {
      "epoch": 2.9103860294117645,
      "grad_norm": 1.2295973300933838,
      "learning_rate": 4.646650326797386e-06,
      "loss": 0.0346,
      "step": 12666
    },
    {
      "epoch": 2.9106158088235294,
      "grad_norm": 0.7385166883468628,
      "learning_rate": 4.646139705882353e-06,
      "loss": 0.0271,
      "step": 12667
    },
    {
      "epoch": 2.9108455882352944,
      "grad_norm": 1.1075607538223267,
      "learning_rate": 4.645629084967321e-06,
      "loss": 0.0522,
      "step": 12668
    },
    {
      "epoch": 2.911075367647059,
      "grad_norm": 0.9246078133583069,
      "learning_rate": 4.645118464052288e-06,
      "loss": 0.0296,
      "step": 12669
    },
    {
      "epoch": 2.9113051470588234,
      "grad_norm": 1.0320147275924683,
      "learning_rate": 4.644607843137255e-06,
      "loss": 0.0414,
      "step": 12670
    },
    {
      "epoch": 2.9115349264705883,
      "grad_norm": 1.035365343093872,
      "learning_rate": 4.644097222222222e-06,
      "loss": 0.0363,
      "step": 12671
    },
    {
      "epoch": 2.911764705882353,
      "grad_norm": 0.9188258647918701,
      "learning_rate": 4.64358660130719e-06,
      "loss": 0.038,
      "step": 12672
    },
    {
      "epoch": 2.9119944852941178,
      "grad_norm": 1.0102459192276,
      "learning_rate": 4.643075980392157e-06,
      "loss": 0.0408,
      "step": 12673
    },
    {
      "epoch": 2.9122242647058822,
      "grad_norm": 1.0512374639511108,
      "learning_rate": 4.642565359477125e-06,
      "loss": 0.0436,
      "step": 12674
    },
    {
      "epoch": 2.912454044117647,
      "grad_norm": 0.9591039419174194,
      "learning_rate": 4.642054738562092e-06,
      "loss": 0.0346,
      "step": 12675
    },
    {
      "epoch": 2.9126838235294117,
      "grad_norm": 1.0024902820587158,
      "learning_rate": 4.64154411764706e-06,
      "loss": 0.0313,
      "step": 12676
    },
    {
      "epoch": 2.9129136029411766,
      "grad_norm": 0.9597322940826416,
      "learning_rate": 4.641033496732027e-06,
      "loss": 0.0384,
      "step": 12677
    },
    {
      "epoch": 2.913143382352941,
      "grad_norm": 0.9908260703086853,
      "learning_rate": 4.640522875816994e-06,
      "loss": 0.0331,
      "step": 12678
    },
    {
      "epoch": 2.9133731617647056,
      "grad_norm": 0.6814208626747131,
      "learning_rate": 4.640012254901961e-06,
      "loss": 0.0316,
      "step": 12679
    },
    {
      "epoch": 2.9136029411764706,
      "grad_norm": 1.1909810304641724,
      "learning_rate": 4.639501633986929e-06,
      "loss": 0.0436,
      "step": 12680
    },
    {
      "epoch": 2.9138327205882355,
      "grad_norm": 1.3829320669174194,
      "learning_rate": 4.638991013071896e-06,
      "loss": 0.038,
      "step": 12681
    },
    {
      "epoch": 2.9140625,
      "grad_norm": 0.8759384155273438,
      "learning_rate": 4.6384803921568635e-06,
      "loss": 0.0334,
      "step": 12682
    },
    {
      "epoch": 2.9142922794117645,
      "grad_norm": 0.8645376563072205,
      "learning_rate": 4.6379697712418305e-06,
      "loss": 0.0397,
      "step": 12683
    },
    {
      "epoch": 2.9145220588235294,
      "grad_norm": 1.0554550886154175,
      "learning_rate": 4.637459150326798e-06,
      "loss": 0.0381,
      "step": 12684
    },
    {
      "epoch": 2.9147518382352944,
      "grad_norm": 0.9117711782455444,
      "learning_rate": 4.636948529411765e-06,
      "loss": 0.0361,
      "step": 12685
    },
    {
      "epoch": 2.914981617647059,
      "grad_norm": 1.0692616701126099,
      "learning_rate": 4.636437908496732e-06,
      "loss": 0.0559,
      "step": 12686
    },
    {
      "epoch": 2.9152113970588234,
      "grad_norm": 0.7818966507911682,
      "learning_rate": 4.635927287581699e-06,
      "loss": 0.0333,
      "step": 12687
    },
    {
      "epoch": 2.9154411764705883,
      "grad_norm": 1.0672892332077026,
      "learning_rate": 4.635416666666667e-06,
      "loss": 0.0618,
      "step": 12688
    },
    {
      "epoch": 2.915670955882353,
      "grad_norm": 0.8660772442817688,
      "learning_rate": 4.634906045751634e-06,
      "loss": 0.0327,
      "step": 12689
    },
    {
      "epoch": 2.9159007352941178,
      "grad_norm": 0.738431453704834,
      "learning_rate": 4.634395424836602e-06,
      "loss": 0.0258,
      "step": 12690
    },
    {
      "epoch": 2.9161305147058822,
      "grad_norm": 0.7424513697624207,
      "learning_rate": 4.633884803921569e-06,
      "loss": 0.0202,
      "step": 12691
    },
    {
      "epoch": 2.916360294117647,
      "grad_norm": 0.8705479502677917,
      "learning_rate": 4.633374183006536e-06,
      "loss": 0.0444,
      "step": 12692
    },
    {
      "epoch": 2.9165900735294117,
      "grad_norm": 0.9325426816940308,
      "learning_rate": 4.632863562091503e-06,
      "loss": 0.038,
      "step": 12693
    },
    {
      "epoch": 2.9168198529411766,
      "grad_norm": 0.9419500827789307,
      "learning_rate": 4.632352941176471e-06,
      "loss": 0.0396,
      "step": 12694
    },
    {
      "epoch": 2.917049632352941,
      "grad_norm": 0.8461973667144775,
      "learning_rate": 4.631842320261438e-06,
      "loss": 0.0335,
      "step": 12695
    },
    {
      "epoch": 2.9172794117647056,
      "grad_norm": 1.002947449684143,
      "learning_rate": 4.631331699346406e-06,
      "loss": 0.0566,
      "step": 12696
    },
    {
      "epoch": 2.9175091911764706,
      "grad_norm": 0.8734794855117798,
      "learning_rate": 4.630821078431373e-06,
      "loss": 0.0285,
      "step": 12697
    },
    {
      "epoch": 2.9177389705882355,
      "grad_norm": 0.9437015056610107,
      "learning_rate": 4.630310457516341e-06,
      "loss": 0.0552,
      "step": 12698
    },
    {
      "epoch": 2.91796875,
      "grad_norm": 0.8723509907722473,
      "learning_rate": 4.629799836601308e-06,
      "loss": 0.0403,
      "step": 12699
    },
    {
      "epoch": 2.9181985294117645,
      "grad_norm": 0.7848381996154785,
      "learning_rate": 4.629289215686275e-06,
      "loss": 0.0365,
      "step": 12700
    },
    {
      "epoch": 2.9184283088235294,
      "grad_norm": 1.1237502098083496,
      "learning_rate": 4.628778594771242e-06,
      "loss": 0.0467,
      "step": 12701
    },
    {
      "epoch": 2.9186580882352944,
      "grad_norm": 0.7506232261657715,
      "learning_rate": 4.62826797385621e-06,
      "loss": 0.0176,
      "step": 12702
    },
    {
      "epoch": 2.918887867647059,
      "grad_norm": 0.5995901226997375,
      "learning_rate": 4.627757352941177e-06,
      "loss": 0.0244,
      "step": 12703
    },
    {
      "epoch": 2.9191176470588234,
      "grad_norm": 1.1226617097854614,
      "learning_rate": 4.6272467320261446e-06,
      "loss": 0.0608,
      "step": 12704
    },
    {
      "epoch": 2.9193474264705883,
      "grad_norm": 2.3559439182281494,
      "learning_rate": 4.6267361111111116e-06,
      "loss": 0.0413,
      "step": 12705
    },
    {
      "epoch": 2.919577205882353,
      "grad_norm": 0.8681263327598572,
      "learning_rate": 4.6262254901960794e-06,
      "loss": 0.0285,
      "step": 12706
    },
    {
      "epoch": 2.9198069852941178,
      "grad_norm": 1.111321210861206,
      "learning_rate": 4.6257148692810465e-06,
      "loss": 0.0443,
      "step": 12707
    },
    {
      "epoch": 2.9200367647058822,
      "grad_norm": 1.2982925176620483,
      "learning_rate": 4.6252042483660135e-06,
      "loss": 0.0358,
      "step": 12708
    },
    {
      "epoch": 2.920266544117647,
      "grad_norm": 0.8392292857170105,
      "learning_rate": 4.6246936274509805e-06,
      "loss": 0.0203,
      "step": 12709
    },
    {
      "epoch": 2.9204963235294117,
      "grad_norm": 1.121945858001709,
      "learning_rate": 4.624183006535948e-06,
      "loss": 0.0423,
      "step": 12710
    },
    {
      "epoch": 2.9207261029411766,
      "grad_norm": 0.9850946664810181,
      "learning_rate": 4.623672385620915e-06,
      "loss": 0.0387,
      "step": 12711
    },
    {
      "epoch": 2.920955882352941,
      "grad_norm": 0.9331770539283752,
      "learning_rate": 4.623161764705883e-06,
      "loss": 0.0361,
      "step": 12712
    },
    {
      "epoch": 2.9211856617647056,
      "grad_norm": 0.98804771900177,
      "learning_rate": 4.62265114379085e-06,
      "loss": 0.0377,
      "step": 12713
    },
    {
      "epoch": 2.9214154411764706,
      "grad_norm": 0.7441019415855408,
      "learning_rate": 4.622140522875817e-06,
      "loss": 0.0325,
      "step": 12714
    },
    {
      "epoch": 2.9216452205882355,
      "grad_norm": 1.117811679840088,
      "learning_rate": 4.621629901960784e-06,
      "loss": 0.0374,
      "step": 12715
    },
    {
      "epoch": 2.921875,
      "grad_norm": 1.5081787109375,
      "learning_rate": 4.621119281045752e-06,
      "loss": 0.0404,
      "step": 12716
    },
    {
      "epoch": 2.9221047794117645,
      "grad_norm": 0.954804539680481,
      "learning_rate": 4.620608660130719e-06,
      "loss": 0.0333,
      "step": 12717
    },
    {
      "epoch": 2.9223345588235294,
      "grad_norm": 0.9697843194007874,
      "learning_rate": 4.620098039215687e-06,
      "loss": 0.0318,
      "step": 12718
    },
    {
      "epoch": 2.9225643382352944,
      "grad_norm": 0.8214927315711975,
      "learning_rate": 4.619587418300654e-06,
      "loss": 0.0284,
      "step": 12719
    },
    {
      "epoch": 2.922794117647059,
      "grad_norm": 1.0490514039993286,
      "learning_rate": 4.619076797385622e-06,
      "loss": 0.0388,
      "step": 12720
    },
    {
      "epoch": 2.9230238970588234,
      "grad_norm": 0.7361562848091125,
      "learning_rate": 4.618566176470589e-06,
      "loss": 0.0432,
      "step": 12721
    },
    {
      "epoch": 2.9232536764705883,
      "grad_norm": 0.9923126697540283,
      "learning_rate": 4.618055555555556e-06,
      "loss": 0.04,
      "step": 12722
    },
    {
      "epoch": 2.923483455882353,
      "grad_norm": 0.7246404886245728,
      "learning_rate": 4.617544934640523e-06,
      "loss": 0.0309,
      "step": 12723
    },
    {
      "epoch": 2.9237132352941178,
      "grad_norm": 0.9674923419952393,
      "learning_rate": 4.617034313725491e-06,
      "loss": 0.0495,
      "step": 12724
    },
    {
      "epoch": 2.9239430147058822,
      "grad_norm": 0.9950189590454102,
      "learning_rate": 4.616523692810458e-06,
      "loss": 0.05,
      "step": 12725
    },
    {
      "epoch": 2.924172794117647,
      "grad_norm": 1.4348762035369873,
      "learning_rate": 4.616013071895426e-06,
      "loss": 0.0394,
      "step": 12726
    },
    {
      "epoch": 2.9244025735294117,
      "grad_norm": 1.2999187707901,
      "learning_rate": 4.615502450980393e-06,
      "loss": 0.0415,
      "step": 12727
    },
    {
      "epoch": 2.9246323529411766,
      "grad_norm": 1.333093523979187,
      "learning_rate": 4.6149918300653605e-06,
      "loss": 0.0592,
      "step": 12728
    },
    {
      "epoch": 2.924862132352941,
      "grad_norm": 0.9155221581459045,
      "learning_rate": 4.6144812091503275e-06,
      "loss": 0.0396,
      "step": 12729
    },
    {
      "epoch": 2.9250919117647056,
      "grad_norm": 0.553817629814148,
      "learning_rate": 4.6139705882352946e-06,
      "loss": 0.0199,
      "step": 12730
    },
    {
      "epoch": 2.9253216911764706,
      "grad_norm": 0.9372256398200989,
      "learning_rate": 4.6134599673202616e-06,
      "loss": 0.0364,
      "step": 12731
    },
    {
      "epoch": 2.9255514705882355,
      "grad_norm": 1.0064524412155151,
      "learning_rate": 4.6129493464052294e-06,
      "loss": 0.0481,
      "step": 12732
    },
    {
      "epoch": 2.92578125,
      "grad_norm": 0.6940855383872986,
      "learning_rate": 4.6124387254901965e-06,
      "loss": 0.0343,
      "step": 12733
    },
    {
      "epoch": 2.9260110294117645,
      "grad_norm": 0.9298992156982422,
      "learning_rate": 4.611928104575164e-06,
      "loss": 0.0437,
      "step": 12734
    },
    {
      "epoch": 2.9262408088235294,
      "grad_norm": 1.2451480627059937,
      "learning_rate": 4.611417483660131e-06,
      "loss": 0.0559,
      "step": 12735
    },
    {
      "epoch": 2.9264705882352944,
      "grad_norm": 1.0280957221984863,
      "learning_rate": 4.610906862745098e-06,
      "loss": 0.0356,
      "step": 12736
    },
    {
      "epoch": 2.926700367647059,
      "grad_norm": 0.7950206398963928,
      "learning_rate": 4.610396241830065e-06,
      "loss": 0.0453,
      "step": 12737
    },
    {
      "epoch": 2.9269301470588234,
      "grad_norm": 0.7835903167724609,
      "learning_rate": 4.609885620915033e-06,
      "loss": 0.0296,
      "step": 12738
    },
    {
      "epoch": 2.9271599264705883,
      "grad_norm": 1.2010067701339722,
      "learning_rate": 4.609375e-06,
      "loss": 0.0569,
      "step": 12739
    },
    {
      "epoch": 2.927389705882353,
      "grad_norm": 1.2684099674224854,
      "learning_rate": 4.608864379084967e-06,
      "loss": 0.049,
      "step": 12740
    },
    {
      "epoch": 2.9276194852941178,
      "grad_norm": 1.3606958389282227,
      "learning_rate": 4.608353758169935e-06,
      "loss": 0.0603,
      "step": 12741
    },
    {
      "epoch": 2.9278492647058822,
      "grad_norm": 0.9668526649475098,
      "learning_rate": 4.607843137254902e-06,
      "loss": 0.0447,
      "step": 12742
    },
    {
      "epoch": 2.928079044117647,
      "grad_norm": 1.0177533626556396,
      "learning_rate": 4.60733251633987e-06,
      "loss": 0.041,
      "step": 12743
    },
    {
      "epoch": 2.9283088235294117,
      "grad_norm": 0.9956971406936646,
      "learning_rate": 4.606821895424837e-06,
      "loss": 0.0462,
      "step": 12744
    },
    {
      "epoch": 2.9285386029411766,
      "grad_norm": 0.5315461754798889,
      "learning_rate": 4.606311274509804e-06,
      "loss": 0.0178,
      "step": 12745
    },
    {
      "epoch": 2.928768382352941,
      "grad_norm": 1.0769150257110596,
      "learning_rate": 4.605800653594771e-06,
      "loss": 0.0292,
      "step": 12746
    },
    {
      "epoch": 2.9289981617647056,
      "grad_norm": 1.1446963548660278,
      "learning_rate": 4.605290032679739e-06,
      "loss": 0.0437,
      "step": 12747
    },
    {
      "epoch": 2.9292279411764706,
      "grad_norm": 0.7143843173980713,
      "learning_rate": 4.604779411764706e-06,
      "loss": 0.0245,
      "step": 12748
    },
    {
      "epoch": 2.9294577205882355,
      "grad_norm": 1.0633996725082397,
      "learning_rate": 4.604268790849674e-06,
      "loss": 0.0302,
      "step": 12749
    },
    {
      "epoch": 2.9296875,
      "grad_norm": 1.2010067701339722,
      "learning_rate": 4.603758169934641e-06,
      "loss": 0.0547,
      "step": 12750
    },
    {
      "epoch": 2.9299172794117645,
      "grad_norm": 0.7545008659362793,
      "learning_rate": 4.603247549019609e-06,
      "loss": 0.0327,
      "step": 12751
    },
    {
      "epoch": 2.9301470588235294,
      "grad_norm": 0.7688930630683899,
      "learning_rate": 4.602736928104576e-06,
      "loss": 0.0311,
      "step": 12752
    },
    {
      "epoch": 2.9303768382352944,
      "grad_norm": 1.1666321754455566,
      "learning_rate": 4.602226307189543e-06,
      "loss": 0.0549,
      "step": 12753
    },
    {
      "epoch": 2.930606617647059,
      "grad_norm": 0.9868365526199341,
      "learning_rate": 4.60171568627451e-06,
      "loss": 0.047,
      "step": 12754
    },
    {
      "epoch": 2.9308363970588234,
      "grad_norm": 1.2428295612335205,
      "learning_rate": 4.6012050653594775e-06,
      "loss": 0.0552,
      "step": 12755
    },
    {
      "epoch": 2.9310661764705883,
      "grad_norm": 0.8691544532775879,
      "learning_rate": 4.6006944444444446e-06,
      "loss": 0.0324,
      "step": 12756
    },
    {
      "epoch": 2.931295955882353,
      "grad_norm": 0.8553561568260193,
      "learning_rate": 4.600183823529412e-06,
      "loss": 0.0384,
      "step": 12757
    },
    {
      "epoch": 2.9315257352941178,
      "grad_norm": 0.9782585501670837,
      "learning_rate": 4.5996732026143794e-06,
      "loss": 0.0508,
      "step": 12758
    },
    {
      "epoch": 2.9317555147058822,
      "grad_norm": 1.2250534296035767,
      "learning_rate": 4.5991625816993464e-06,
      "loss": 0.0581,
      "step": 12759
    },
    {
      "epoch": 2.931985294117647,
      "grad_norm": 1.15569269657135,
      "learning_rate": 4.5986519607843135e-06,
      "loss": 0.0624,
      "step": 12760
    },
    {
      "epoch": 2.9322150735294117,
      "grad_norm": 0.6532244682312012,
      "learning_rate": 4.598141339869281e-06,
      "loss": 0.0341,
      "step": 12761
    },
    {
      "epoch": 2.9324448529411766,
      "grad_norm": 0.979995608329773,
      "learning_rate": 4.597630718954248e-06,
      "loss": 0.0439,
      "step": 12762
    },
    {
      "epoch": 2.932674632352941,
      "grad_norm": 0.9213777184486389,
      "learning_rate": 4.597120098039216e-06,
      "loss": 0.0369,
      "step": 12763
    },
    {
      "epoch": 2.9329044117647056,
      "grad_norm": 1.207575798034668,
      "learning_rate": 4.596609477124183e-06,
      "loss": 0.0526,
      "step": 12764
    },
    {
      "epoch": 2.9331341911764706,
      "grad_norm": 0.7863007187843323,
      "learning_rate": 4.596098856209151e-06,
      "loss": 0.0209,
      "step": 12765
    },
    {
      "epoch": 2.9333639705882355,
      "grad_norm": 1.3727054595947266,
      "learning_rate": 4.595588235294118e-06,
      "loss": 0.0669,
      "step": 12766
    },
    {
      "epoch": 2.93359375,
      "grad_norm": 1.7844493389129639,
      "learning_rate": 4.595077614379085e-06,
      "loss": 0.0764,
      "step": 12767
    },
    {
      "epoch": 2.9338235294117645,
      "grad_norm": 0.6406422853469849,
      "learning_rate": 4.594566993464052e-06,
      "loss": 0.0283,
      "step": 12768
    },
    {
      "epoch": 2.9340533088235294,
      "grad_norm": 0.7742989659309387,
      "learning_rate": 4.59405637254902e-06,
      "loss": 0.038,
      "step": 12769
    },
    {
      "epoch": 2.9342830882352944,
      "grad_norm": 1.4255620241165161,
      "learning_rate": 4.593545751633987e-06,
      "loss": 0.0646,
      "step": 12770
    },
    {
      "epoch": 2.934512867647059,
      "grad_norm": 1.1628174781799316,
      "learning_rate": 4.593035130718955e-06,
      "loss": 0.0532,
      "step": 12771
    },
    {
      "epoch": 2.9347426470588234,
      "grad_norm": 1.3142842054367065,
      "learning_rate": 4.592524509803922e-06,
      "loss": 0.0585,
      "step": 12772
    },
    {
      "epoch": 2.9349724264705883,
      "grad_norm": 0.9519795775413513,
      "learning_rate": 4.59201388888889e-06,
      "loss": 0.043,
      "step": 12773
    },
    {
      "epoch": 2.935202205882353,
      "grad_norm": 1.2538304328918457,
      "learning_rate": 4.591503267973857e-06,
      "loss": 0.0381,
      "step": 12774
    },
    {
      "epoch": 2.9354319852941178,
      "grad_norm": 0.8621246218681335,
      "learning_rate": 4.590992647058824e-06,
      "loss": 0.0333,
      "step": 12775
    },
    {
      "epoch": 2.9356617647058822,
      "grad_norm": 0.6971923112869263,
      "learning_rate": 4.590482026143791e-06,
      "loss": 0.0313,
      "step": 12776
    },
    {
      "epoch": 2.935891544117647,
      "grad_norm": 0.9762097001075745,
      "learning_rate": 4.589971405228759e-06,
      "loss": 0.0353,
      "step": 12777
    },
    {
      "epoch": 2.9361213235294117,
      "grad_norm": 1.1251463890075684,
      "learning_rate": 4.589460784313726e-06,
      "loss": 0.0612,
      "step": 12778
    },
    {
      "epoch": 2.9363511029411766,
      "grad_norm": 0.7593898773193359,
      "learning_rate": 4.5889501633986935e-06,
      "loss": 0.026,
      "step": 12779
    },
    {
      "epoch": 2.936580882352941,
      "grad_norm": 0.8601680397987366,
      "learning_rate": 4.5884395424836605e-06,
      "loss": 0.027,
      "step": 12780
    },
    {
      "epoch": 2.9368106617647056,
      "grad_norm": 0.7902361750602722,
      "learning_rate": 4.5879289215686275e-06,
      "loss": 0.0341,
      "step": 12781
    },
    {
      "epoch": 2.9370404411764706,
      "grad_norm": 0.9122761487960815,
      "learning_rate": 4.5874183006535946e-06,
      "loss": 0.043,
      "step": 12782
    },
    {
      "epoch": 2.9372702205882355,
      "grad_norm": 0.9370951652526855,
      "learning_rate": 4.586907679738562e-06,
      "loss": 0.05,
      "step": 12783
    },
    {
      "epoch": 2.9375,
      "grad_norm": 0.9091260433197021,
      "learning_rate": 4.5863970588235294e-06,
      "loss": 0.044,
      "step": 12784
    },
    {
      "epoch": 2.9377297794117645,
      "grad_norm": 1.267804503440857,
      "learning_rate": 4.585886437908497e-06,
      "loss": 0.0556,
      "step": 12785
    },
    {
      "epoch": 2.9379595588235294,
      "grad_norm": 0.8914327621459961,
      "learning_rate": 4.585375816993464e-06,
      "loss": 0.0595,
      "step": 12786
    },
    {
      "epoch": 2.9381893382352944,
      "grad_norm": 0.8030794262886047,
      "learning_rate": 4.584865196078432e-06,
      "loss": 0.0243,
      "step": 12787
    },
    {
      "epoch": 2.938419117647059,
      "grad_norm": 1.0006531476974487,
      "learning_rate": 4.584354575163399e-06,
      "loss": 0.0447,
      "step": 12788
    },
    {
      "epoch": 2.9386488970588234,
      "grad_norm": 0.9291812181472778,
      "learning_rate": 4.583843954248366e-06,
      "loss": 0.0436,
      "step": 12789
    },
    {
      "epoch": 2.9388786764705883,
      "grad_norm": 1.0387169122695923,
      "learning_rate": 4.583333333333333e-06,
      "loss": 0.0358,
      "step": 12790
    },
    {
      "epoch": 2.939108455882353,
      "grad_norm": 1.5782514810562134,
      "learning_rate": 4.582822712418301e-06,
      "loss": 0.031,
      "step": 12791
    },
    {
      "epoch": 2.9393382352941178,
      "grad_norm": 0.6903795599937439,
      "learning_rate": 4.582312091503268e-06,
      "loss": 0.0286,
      "step": 12792
    },
    {
      "epoch": 2.9395680147058822,
      "grad_norm": 1.0789824724197388,
      "learning_rate": 4.581801470588236e-06,
      "loss": 0.0499,
      "step": 12793
    },
    {
      "epoch": 2.939797794117647,
      "grad_norm": 0.7073947787284851,
      "learning_rate": 4.581290849673203e-06,
      "loss": 0.0319,
      "step": 12794
    },
    {
      "epoch": 2.9400275735294117,
      "grad_norm": 0.7115063071250916,
      "learning_rate": 4.580780228758171e-06,
      "loss": 0.0317,
      "step": 12795
    },
    {
      "epoch": 2.9402573529411766,
      "grad_norm": 0.9782428741455078,
      "learning_rate": 4.580269607843138e-06,
      "loss": 0.0402,
      "step": 12796
    },
    {
      "epoch": 2.940487132352941,
      "grad_norm": 0.644513726234436,
      "learning_rate": 4.579758986928105e-06,
      "loss": 0.0281,
      "step": 12797
    },
    {
      "epoch": 2.9407169117647056,
      "grad_norm": 0.9059993028640747,
      "learning_rate": 4.579248366013072e-06,
      "loss": 0.0499,
      "step": 12798
    },
    {
      "epoch": 2.9409466911764706,
      "grad_norm": 0.9421434998512268,
      "learning_rate": 4.57873774509804e-06,
      "loss": 0.0643,
      "step": 12799
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.7158067226409912,
      "learning_rate": 4.578227124183007e-06,
      "loss": 0.0471,
      "step": 12800
    },
    {
      "epoch": 2.94140625,
      "grad_norm": 0.7670303583145142,
      "learning_rate": 4.577716503267975e-06,
      "loss": 0.0494,
      "step": 12801
    },
    {
      "epoch": 2.9416360294117645,
      "grad_norm": 0.8565787076950073,
      "learning_rate": 4.577205882352942e-06,
      "loss": 0.0417,
      "step": 12802
    },
    {
      "epoch": 2.9418658088235294,
      "grad_norm": 1.4923301935195923,
      "learning_rate": 4.576695261437909e-06,
      "loss": 0.031,
      "step": 12803
    },
    {
      "epoch": 2.9420955882352944,
      "grad_norm": 0.9931204319000244,
      "learning_rate": 4.576184640522876e-06,
      "loss": 0.0384,
      "step": 12804
    },
    {
      "epoch": 2.942325367647059,
      "grad_norm": 0.9033329486846924,
      "learning_rate": 4.5756740196078435e-06,
      "loss": 0.0303,
      "step": 12805
    },
    {
      "epoch": 2.9425551470588234,
      "grad_norm": 0.8383492827415466,
      "learning_rate": 4.5751633986928105e-06,
      "loss": 0.0332,
      "step": 12806
    },
    {
      "epoch": 2.9427849264705883,
      "grad_norm": 0.9383378624916077,
      "learning_rate": 4.574652777777778e-06,
      "loss": 0.0309,
      "step": 12807
    },
    {
      "epoch": 2.943014705882353,
      "grad_norm": 1.0850324630737305,
      "learning_rate": 4.574142156862745e-06,
      "loss": 0.0417,
      "step": 12808
    },
    {
      "epoch": 2.9432444852941178,
      "grad_norm": 0.8632086515426636,
      "learning_rate": 4.573631535947713e-06,
      "loss": 0.039,
      "step": 12809
    },
    {
      "epoch": 2.9434742647058822,
      "grad_norm": 0.7546429634094238,
      "learning_rate": 4.57312091503268e-06,
      "loss": 0.0332,
      "step": 12810
    },
    {
      "epoch": 2.943704044117647,
      "grad_norm": 0.9625216126441956,
      "learning_rate": 4.572610294117647e-06,
      "loss": 0.039,
      "step": 12811
    },
    {
      "epoch": 2.9439338235294117,
      "grad_norm": 0.8454521298408508,
      "learning_rate": 4.572099673202614e-06,
      "loss": 0.0419,
      "step": 12812
    },
    {
      "epoch": 2.9441636029411766,
      "grad_norm": 1.0714293718338013,
      "learning_rate": 4.571589052287582e-06,
      "loss": 0.0358,
      "step": 12813
    },
    {
      "epoch": 2.944393382352941,
      "grad_norm": 1.006922721862793,
      "learning_rate": 4.571078431372549e-06,
      "loss": 0.0415,
      "step": 12814
    },
    {
      "epoch": 2.9446231617647056,
      "grad_norm": 0.6300355792045593,
      "learning_rate": 4.570567810457517e-06,
      "loss": 0.0328,
      "step": 12815
    },
    {
      "epoch": 2.9448529411764706,
      "grad_norm": 1.2697750329971313,
      "learning_rate": 4.570057189542484e-06,
      "loss": 0.0709,
      "step": 12816
    },
    {
      "epoch": 2.9450827205882355,
      "grad_norm": 1.1115028858184814,
      "learning_rate": 4.569546568627451e-06,
      "loss": 0.0365,
      "step": 12817
    },
    {
      "epoch": 2.9453125,
      "grad_norm": 0.8085494637489319,
      "learning_rate": 4.569035947712419e-06,
      "loss": 0.0256,
      "step": 12818
    },
    {
      "epoch": 2.9455422794117645,
      "grad_norm": 1.5156989097595215,
      "learning_rate": 4.568525326797386e-06,
      "loss": 0.0646,
      "step": 12819
    },
    {
      "epoch": 2.9457720588235294,
      "grad_norm": 1.387658953666687,
      "learning_rate": 4.568014705882353e-06,
      "loss": 0.0526,
      "step": 12820
    },
    {
      "epoch": 2.9460018382352944,
      "grad_norm": 1.4009519815444946,
      "learning_rate": 4.567504084967321e-06,
      "loss": 0.0439,
      "step": 12821
    },
    {
      "epoch": 2.946231617647059,
      "grad_norm": 1.1950314044952393,
      "learning_rate": 4.566993464052288e-06,
      "loss": 0.0558,
      "step": 12822
    },
    {
      "epoch": 2.9464613970588234,
      "grad_norm": 0.8840930461883545,
      "learning_rate": 4.566482843137256e-06,
      "loss": 0.0267,
      "step": 12823
    },
    {
      "epoch": 2.9466911764705883,
      "grad_norm": 0.7918720841407776,
      "learning_rate": 4.565972222222223e-06,
      "loss": 0.0305,
      "step": 12824
    },
    {
      "epoch": 2.946920955882353,
      "grad_norm": 0.9289208054542542,
      "learning_rate": 4.56546160130719e-06,
      "loss": 0.0349,
      "step": 12825
    },
    {
      "epoch": 2.9471507352941178,
      "grad_norm": 0.9811870455741882,
      "learning_rate": 4.564950980392157e-06,
      "loss": 0.0428,
      "step": 12826
    },
    {
      "epoch": 2.9473805147058822,
      "grad_norm": 1.1075986623764038,
      "learning_rate": 4.564440359477125e-06,
      "loss": 0.0426,
      "step": 12827
    },
    {
      "epoch": 2.947610294117647,
      "grad_norm": 0.8604787588119507,
      "learning_rate": 4.563929738562092e-06,
      "loss": 0.0301,
      "step": 12828
    },
    {
      "epoch": 2.9478400735294117,
      "grad_norm": 1.14301598072052,
      "learning_rate": 4.5634191176470595e-06,
      "loss": 0.0543,
      "step": 12829
    },
    {
      "epoch": 2.9480698529411766,
      "grad_norm": 0.7460900545120239,
      "learning_rate": 4.5629084967320265e-06,
      "loss": 0.0313,
      "step": 12830
    },
    {
      "epoch": 2.948299632352941,
      "grad_norm": 0.9075396060943604,
      "learning_rate": 4.562397875816994e-06,
      "loss": 0.038,
      "step": 12831
    },
    {
      "epoch": 2.9485294117647056,
      "grad_norm": 0.8531310558319092,
      "learning_rate": 4.561887254901961e-06,
      "loss": 0.0326,
      "step": 12832
    },
    {
      "epoch": 2.9487591911764706,
      "grad_norm": 1.0935224294662476,
      "learning_rate": 4.561376633986928e-06,
      "loss": 0.0561,
      "step": 12833
    },
    {
      "epoch": 2.9489889705882355,
      "grad_norm": 0.7572465538978577,
      "learning_rate": 4.560866013071895e-06,
      "loss": 0.0427,
      "step": 12834
    },
    {
      "epoch": 2.94921875,
      "grad_norm": 1.0652130842208862,
      "learning_rate": 4.560355392156863e-06,
      "loss": 0.044,
      "step": 12835
    },
    {
      "epoch": 2.9494485294117645,
      "grad_norm": 0.959945023059845,
      "learning_rate": 4.55984477124183e-06,
      "loss": 0.049,
      "step": 12836
    },
    {
      "epoch": 2.9496783088235294,
      "grad_norm": 0.8624086380004883,
      "learning_rate": 4.559334150326798e-06,
      "loss": 0.0401,
      "step": 12837
    },
    {
      "epoch": 2.9499080882352944,
      "grad_norm": 1.0775808095932007,
      "learning_rate": 4.558823529411765e-06,
      "loss": 0.0242,
      "step": 12838
    },
    {
      "epoch": 2.950137867647059,
      "grad_norm": 0.7484883666038513,
      "learning_rate": 4.558312908496732e-06,
      "loss": 0.0318,
      "step": 12839
    },
    {
      "epoch": 2.9503676470588234,
      "grad_norm": 0.7117681503295898,
      "learning_rate": 4.5578022875817e-06,
      "loss": 0.027,
      "step": 12840
    },
    {
      "epoch": 2.9505974264705883,
      "grad_norm": 0.734948992729187,
      "learning_rate": 4.557291666666667e-06,
      "loss": 0.0233,
      "step": 12841
    },
    {
      "epoch": 2.950827205882353,
      "grad_norm": 1.022703766822815,
      "learning_rate": 4.556781045751634e-06,
      "loss": 0.0316,
      "step": 12842
    },
    {
      "epoch": 2.9510569852941178,
      "grad_norm": 1.23149836063385,
      "learning_rate": 4.556270424836602e-06,
      "loss": 0.051,
      "step": 12843
    },
    {
      "epoch": 2.9512867647058822,
      "grad_norm": 0.8531738519668579,
      "learning_rate": 4.555759803921569e-06,
      "loss": 0.0403,
      "step": 12844
    },
    {
      "epoch": 2.951516544117647,
      "grad_norm": 0.949478268623352,
      "learning_rate": 4.555249183006537e-06,
      "loss": 0.0322,
      "step": 12845
    },
    {
      "epoch": 2.9517463235294117,
      "grad_norm": 1.264736533164978,
      "learning_rate": 4.554738562091504e-06,
      "loss": 0.0454,
      "step": 12846
    },
    {
      "epoch": 2.9519761029411766,
      "grad_norm": 1.1805468797683716,
      "learning_rate": 4.554227941176471e-06,
      "loss": 0.0405,
      "step": 12847
    },
    {
      "epoch": 2.952205882352941,
      "grad_norm": 0.9604682326316833,
      "learning_rate": 4.553717320261438e-06,
      "loss": 0.0466,
      "step": 12848
    },
    {
      "epoch": 2.9524356617647056,
      "grad_norm": 1.0119450092315674,
      "learning_rate": 4.553206699346406e-06,
      "loss": 0.0398,
      "step": 12849
    },
    {
      "epoch": 2.9526654411764706,
      "grad_norm": 0.7345097661018372,
      "learning_rate": 4.552696078431373e-06,
      "loss": 0.0286,
      "step": 12850
    },
    {
      "epoch": 2.9528952205882355,
      "grad_norm": 2.0295307636260986,
      "learning_rate": 4.5521854575163406e-06,
      "loss": 0.0566,
      "step": 12851
    },
    {
      "epoch": 2.953125,
      "grad_norm": 1.6049211025238037,
      "learning_rate": 4.551674836601308e-06,
      "loss": 0.0389,
      "step": 12852
    },
    {
      "epoch": 2.9533547794117645,
      "grad_norm": 0.8326483368873596,
      "learning_rate": 4.5511642156862755e-06,
      "loss": 0.0289,
      "step": 12853
    },
    {
      "epoch": 2.9535845588235294,
      "grad_norm": 0.8992457389831543,
      "learning_rate": 4.5506535947712425e-06,
      "loss": 0.0347,
      "step": 12854
    },
    {
      "epoch": 2.9538143382352944,
      "grad_norm": 0.7490426301956177,
      "learning_rate": 4.5501429738562095e-06,
      "loss": 0.0247,
      "step": 12855
    },
    {
      "epoch": 2.954044117647059,
      "grad_norm": 0.8396969437599182,
      "learning_rate": 4.5496323529411765e-06,
      "loss": 0.0231,
      "step": 12856
    },
    {
      "epoch": 2.9542738970588234,
      "grad_norm": 1.155584692955017,
      "learning_rate": 4.549121732026144e-06,
      "loss": 0.0524,
      "step": 12857
    },
    {
      "epoch": 2.9545036764705883,
      "grad_norm": 0.87497478723526,
      "learning_rate": 4.548611111111111e-06,
      "loss": 0.0419,
      "step": 12858
    },
    {
      "epoch": 2.954733455882353,
      "grad_norm": 0.7732737064361572,
      "learning_rate": 4.548100490196079e-06,
      "loss": 0.0275,
      "step": 12859
    },
    {
      "epoch": 2.9549632352941178,
      "grad_norm": 0.8594356179237366,
      "learning_rate": 4.547589869281046e-06,
      "loss": 0.0369,
      "step": 12860
    },
    {
      "epoch": 2.9551930147058822,
      "grad_norm": 1.2197355031967163,
      "learning_rate": 4.547079248366013e-06,
      "loss": 0.0636,
      "step": 12861
    },
    {
      "epoch": 2.955422794117647,
      "grad_norm": 0.8014513850212097,
      "learning_rate": 4.546568627450981e-06,
      "loss": 0.0474,
      "step": 12862
    },
    {
      "epoch": 2.9556525735294117,
      "grad_norm": 1.399100422859192,
      "learning_rate": 4.546058006535948e-06,
      "loss": 0.0532,
      "step": 12863
    },
    {
      "epoch": 2.9558823529411766,
      "grad_norm": 0.9312686920166016,
      "learning_rate": 4.545547385620915e-06,
      "loss": 0.0247,
      "step": 12864
    },
    {
      "epoch": 2.956112132352941,
      "grad_norm": 0.9619810581207275,
      "learning_rate": 4.545036764705883e-06,
      "loss": 0.0379,
      "step": 12865
    },
    {
      "epoch": 2.9563419117647056,
      "grad_norm": 0.7133727073669434,
      "learning_rate": 4.54452614379085e-06,
      "loss": 0.0196,
      "step": 12866
    },
    {
      "epoch": 2.9565716911764706,
      "grad_norm": 0.9816346764564514,
      "learning_rate": 4.544015522875818e-06,
      "loss": 0.0396,
      "step": 12867
    },
    {
      "epoch": 2.9568014705882355,
      "grad_norm": 1.0917614698410034,
      "learning_rate": 4.543504901960785e-06,
      "loss": 0.0265,
      "step": 12868
    },
    {
      "epoch": 2.95703125,
      "grad_norm": 1.0494897365570068,
      "learning_rate": 4.542994281045752e-06,
      "loss": 0.0458,
      "step": 12869
    },
    {
      "epoch": 2.9572610294117645,
      "grad_norm": 1.3679628372192383,
      "learning_rate": 4.542483660130719e-06,
      "loss": 0.0532,
      "step": 12870
    },
    {
      "epoch": 2.9574908088235294,
      "grad_norm": 0.8921939730644226,
      "learning_rate": 4.541973039215687e-06,
      "loss": 0.0346,
      "step": 12871
    },
    {
      "epoch": 2.9577205882352944,
      "grad_norm": 0.8275704383850098,
      "learning_rate": 4.541462418300654e-06,
      "loss": 0.0263,
      "step": 12872
    },
    {
      "epoch": 2.957950367647059,
      "grad_norm": 0.7795329689979553,
      "learning_rate": 4.540951797385622e-06,
      "loss": 0.0345,
      "step": 12873
    },
    {
      "epoch": 2.9581801470588234,
      "grad_norm": 0.870453953742981,
      "learning_rate": 4.540441176470589e-06,
      "loss": 0.0378,
      "step": 12874
    },
    {
      "epoch": 2.9584099264705883,
      "grad_norm": 1.1773052215576172,
      "learning_rate": 4.5399305555555565e-06,
      "loss": 0.0318,
      "step": 12875
    },
    {
      "epoch": 2.958639705882353,
      "grad_norm": 1.3813165426254272,
      "learning_rate": 4.5394199346405236e-06,
      "loss": 0.0361,
      "step": 12876
    },
    {
      "epoch": 2.9588694852941178,
      "grad_norm": 1.1492122411727905,
      "learning_rate": 4.5389093137254906e-06,
      "loss": 0.0375,
      "step": 12877
    },
    {
      "epoch": 2.9590992647058822,
      "grad_norm": 0.8658735752105713,
      "learning_rate": 4.538398692810458e-06,
      "loss": 0.0498,
      "step": 12878
    },
    {
      "epoch": 2.959329044117647,
      "grad_norm": 1.1557869911193848,
      "learning_rate": 4.5378880718954255e-06,
      "loss": 0.0403,
      "step": 12879
    },
    {
      "epoch": 2.9595588235294117,
      "grad_norm": 1.2723509073257446,
      "learning_rate": 4.5373774509803925e-06,
      "loss": 0.054,
      "step": 12880
    },
    {
      "epoch": 2.9597886029411766,
      "grad_norm": 0.8974535465240479,
      "learning_rate": 4.53686683006536e-06,
      "loss": 0.0421,
      "step": 12881
    },
    {
      "epoch": 2.960018382352941,
      "grad_norm": 0.8951773047447205,
      "learning_rate": 4.536356209150327e-06,
      "loss": 0.0337,
      "step": 12882
    },
    {
      "epoch": 2.9602481617647056,
      "grad_norm": 0.6532343626022339,
      "learning_rate": 4.535845588235294e-06,
      "loss": 0.0273,
      "step": 12883
    },
    {
      "epoch": 2.9604779411764706,
      "grad_norm": 0.760023832321167,
      "learning_rate": 4.535334967320262e-06,
      "loss": 0.0294,
      "step": 12884
    },
    {
      "epoch": 2.9607077205882355,
      "grad_norm": 1.15432870388031,
      "learning_rate": 4.534824346405229e-06,
      "loss": 0.063,
      "step": 12885
    },
    {
      "epoch": 2.9609375,
      "grad_norm": 0.8763634562492371,
      "learning_rate": 4.534313725490196e-06,
      "loss": 0.0401,
      "step": 12886
    },
    {
      "epoch": 2.9611672794117645,
      "grad_norm": 0.6113200187683105,
      "learning_rate": 4.533803104575164e-06,
      "loss": 0.0315,
      "step": 12887
    },
    {
      "epoch": 2.9613970588235294,
      "grad_norm": 0.960837721824646,
      "learning_rate": 4.533292483660131e-06,
      "loss": 0.0292,
      "step": 12888
    },
    {
      "epoch": 2.9616268382352944,
      "grad_norm": 1.4924606084823608,
      "learning_rate": 4.532781862745099e-06,
      "loss": 0.0597,
      "step": 12889
    },
    {
      "epoch": 2.961856617647059,
      "grad_norm": 2.4483766555786133,
      "learning_rate": 4.532271241830066e-06,
      "loss": 0.0405,
      "step": 12890
    },
    {
      "epoch": 2.9620863970588234,
      "grad_norm": 0.6523166298866272,
      "learning_rate": 4.531760620915033e-06,
      "loss": 0.0223,
      "step": 12891
    },
    {
      "epoch": 2.9623161764705883,
      "grad_norm": 1.0481137037277222,
      "learning_rate": 4.53125e-06,
      "loss": 0.0307,
      "step": 12892
    },
    {
      "epoch": 2.962545955882353,
      "grad_norm": 1.3263345956802368,
      "learning_rate": 4.530739379084967e-06,
      "loss": 0.0676,
      "step": 12893
    },
    {
      "epoch": 2.9627757352941178,
      "grad_norm": 1.123852014541626,
      "learning_rate": 4.530228758169935e-06,
      "loss": 0.0691,
      "step": 12894
    },
    {
      "epoch": 2.9630055147058822,
      "grad_norm": 0.7693976163864136,
      "learning_rate": 4.529718137254902e-06,
      "loss": 0.0355,
      "step": 12895
    },
    {
      "epoch": 2.963235294117647,
      "grad_norm": 1.268934726715088,
      "learning_rate": 4.52920751633987e-06,
      "loss": 0.0416,
      "step": 12896
    },
    {
      "epoch": 2.9634650735294117,
      "grad_norm": 0.8658076524734497,
      "learning_rate": 4.528696895424837e-06,
      "loss": 0.0358,
      "step": 12897
    },
    {
      "epoch": 2.9636948529411766,
      "grad_norm": 0.7670572996139526,
      "learning_rate": 4.528186274509805e-06,
      "loss": 0.0229,
      "step": 12898
    },
    {
      "epoch": 2.963924632352941,
      "grad_norm": 1.0122532844543457,
      "learning_rate": 4.527675653594772e-06,
      "loss": 0.0297,
      "step": 12899
    },
    {
      "epoch": 2.9641544117647056,
      "grad_norm": 0.8229095935821533,
      "learning_rate": 4.527165032679739e-06,
      "loss": 0.0278,
      "step": 12900
    },
    {
      "epoch": 2.9643841911764706,
      "grad_norm": 0.8602035045623779,
      "learning_rate": 4.526654411764706e-06,
      "loss": 0.0312,
      "step": 12901
    },
    {
      "epoch": 2.9646139705882355,
      "grad_norm": 0.9985779523849487,
      "learning_rate": 4.5261437908496736e-06,
      "loss": 0.034,
      "step": 12902
    },
    {
      "epoch": 2.96484375,
      "grad_norm": 0.8767102360725403,
      "learning_rate": 4.5256331699346406e-06,
      "loss": 0.0344,
      "step": 12903
    },
    {
      "epoch": 2.9650735294117645,
      "grad_norm": 0.9294791221618652,
      "learning_rate": 4.5251225490196084e-06,
      "loss": 0.0302,
      "step": 12904
    },
    {
      "epoch": 2.9653033088235294,
      "grad_norm": 0.7516921758651733,
      "learning_rate": 4.5246119281045754e-06,
      "loss": 0.0377,
      "step": 12905
    },
    {
      "epoch": 2.9655330882352944,
      "grad_norm": 0.8225033283233643,
      "learning_rate": 4.5241013071895425e-06,
      "loss": 0.0369,
      "step": 12906
    },
    {
      "epoch": 2.965762867647059,
      "grad_norm": 1.404420256614685,
      "learning_rate": 4.52359068627451e-06,
      "loss": 0.0485,
      "step": 12907
    },
    {
      "epoch": 2.9659926470588234,
      "grad_norm": 0.847987174987793,
      "learning_rate": 4.523080065359477e-06,
      "loss": 0.0248,
      "step": 12908
    },
    {
      "epoch": 2.9662224264705883,
      "grad_norm": 1.0008783340454102,
      "learning_rate": 4.522569444444444e-06,
      "loss": 0.0306,
      "step": 12909
    },
    {
      "epoch": 2.966452205882353,
      "grad_norm": 1.339517593383789,
      "learning_rate": 4.522058823529412e-06,
      "loss": 0.0538,
      "step": 12910
    },
    {
      "epoch": 2.9666819852941178,
      "grad_norm": 1.1436647176742554,
      "learning_rate": 4.521548202614379e-06,
      "loss": 0.0404,
      "step": 12911
    },
    {
      "epoch": 2.9669117647058822,
      "grad_norm": 1.7497748136520386,
      "learning_rate": 4.521037581699347e-06,
      "loss": 0.0837,
      "step": 12912
    },
    {
      "epoch": 2.967141544117647,
      "grad_norm": 1.2071201801300049,
      "learning_rate": 4.520526960784314e-06,
      "loss": 0.0486,
      "step": 12913
    },
    {
      "epoch": 2.9673713235294117,
      "grad_norm": 1.0488215684890747,
      "learning_rate": 4.520016339869281e-06,
      "loss": 0.0372,
      "step": 12914
    },
    {
      "epoch": 2.9676011029411766,
      "grad_norm": 1.0914487838745117,
      "learning_rate": 4.519505718954248e-06,
      "loss": 0.0513,
      "step": 12915
    },
    {
      "epoch": 2.967830882352941,
      "grad_norm": 0.6575266122817993,
      "learning_rate": 4.518995098039216e-06,
      "loss": 0.0239,
      "step": 12916
    },
    {
      "epoch": 2.9680606617647056,
      "grad_norm": 0.9654605388641357,
      "learning_rate": 4.518484477124183e-06,
      "loss": 0.0427,
      "step": 12917
    },
    {
      "epoch": 2.9682904411764706,
      "grad_norm": 0.7971001267433167,
      "learning_rate": 4.517973856209151e-06,
      "loss": 0.0375,
      "step": 12918
    },
    {
      "epoch": 2.9685202205882355,
      "grad_norm": 1.1156898736953735,
      "learning_rate": 4.517463235294118e-06,
      "loss": 0.0479,
      "step": 12919
    },
    {
      "epoch": 2.96875,
      "grad_norm": 0.9352452754974365,
      "learning_rate": 4.516952614379086e-06,
      "loss": 0.0422,
      "step": 12920
    },
    {
      "epoch": 2.9689797794117645,
      "grad_norm": 0.8015785813331604,
      "learning_rate": 4.516441993464053e-06,
      "loss": 0.0424,
      "step": 12921
    },
    {
      "epoch": 2.9692095588235294,
      "grad_norm": 1.7252658605575562,
      "learning_rate": 4.51593137254902e-06,
      "loss": 0.0145,
      "step": 12922
    },
    {
      "epoch": 2.9694393382352944,
      "grad_norm": 0.67922043800354,
      "learning_rate": 4.515420751633987e-06,
      "loss": 0.0263,
      "step": 12923
    },
    {
      "epoch": 2.969669117647059,
      "grad_norm": 0.7578632831573486,
      "learning_rate": 4.514910130718955e-06,
      "loss": 0.0446,
      "step": 12924
    },
    {
      "epoch": 2.9698988970588234,
      "grad_norm": 1.0907158851623535,
      "learning_rate": 4.514399509803922e-06,
      "loss": 0.0347,
      "step": 12925
    },
    {
      "epoch": 2.9701286764705883,
      "grad_norm": 0.933716893196106,
      "learning_rate": 4.5138888888888895e-06,
      "loss": 0.0429,
      "step": 12926
    },
    {
      "epoch": 2.970358455882353,
      "grad_norm": 0.9673768281936646,
      "learning_rate": 4.5133782679738565e-06,
      "loss": 0.036,
      "step": 12927
    },
    {
      "epoch": 2.9705882352941178,
      "grad_norm": 1.1068334579467773,
      "learning_rate": 4.5128676470588236e-06,
      "loss": 0.0441,
      "step": 12928
    },
    {
      "epoch": 2.9708180147058822,
      "grad_norm": 0.6050518751144409,
      "learning_rate": 4.512357026143791e-06,
      "loss": 0.0177,
      "step": 12929
    },
    {
      "epoch": 2.971047794117647,
      "grad_norm": 0.8446731567382812,
      "learning_rate": 4.5118464052287584e-06,
      "loss": 0.0318,
      "step": 12930
    },
    {
      "epoch": 2.9712775735294117,
      "grad_norm": 1.1837048530578613,
      "learning_rate": 4.5113357843137254e-06,
      "loss": 0.0706,
      "step": 12931
    },
    {
      "epoch": 2.9715073529411766,
      "grad_norm": 0.9381661415100098,
      "learning_rate": 4.510825163398693e-06,
      "loss": 0.0297,
      "step": 12932
    },
    {
      "epoch": 2.971737132352941,
      "grad_norm": 0.9840019941329956,
      "learning_rate": 4.51031454248366e-06,
      "loss": 0.0419,
      "step": 12933
    },
    {
      "epoch": 2.9719669117647056,
      "grad_norm": 1.7287665605545044,
      "learning_rate": 4.509803921568628e-06,
      "loss": 0.0448,
      "step": 12934
    },
    {
      "epoch": 2.9721966911764706,
      "grad_norm": 1.1753071546554565,
      "learning_rate": 4.509293300653595e-06,
      "loss": 0.0297,
      "step": 12935
    },
    {
      "epoch": 2.9724264705882355,
      "grad_norm": 0.8088911771774292,
      "learning_rate": 4.508782679738562e-06,
      "loss": 0.0419,
      "step": 12936
    },
    {
      "epoch": 2.97265625,
      "grad_norm": 0.9077069163322449,
      "learning_rate": 4.508272058823529e-06,
      "loss": 0.0399,
      "step": 12937
    },
    {
      "epoch": 2.9728860294117645,
      "grad_norm": 0.7673566937446594,
      "learning_rate": 4.507761437908497e-06,
      "loss": 0.0434,
      "step": 12938
    },
    {
      "epoch": 2.9731158088235294,
      "grad_norm": 0.9657711982727051,
      "learning_rate": 4.507250816993464e-06,
      "loss": 0.0494,
      "step": 12939
    },
    {
      "epoch": 2.9733455882352944,
      "grad_norm": 0.9175900816917419,
      "learning_rate": 4.506740196078432e-06,
      "loss": 0.0277,
      "step": 12940
    },
    {
      "epoch": 2.973575367647059,
      "grad_norm": 0.9379652738571167,
      "learning_rate": 4.506229575163399e-06,
      "loss": 0.0297,
      "step": 12941
    },
    {
      "epoch": 2.9738051470588234,
      "grad_norm": 1.0461418628692627,
      "learning_rate": 4.505718954248367e-06,
      "loss": 0.0306,
      "step": 12942
    },
    {
      "epoch": 2.9740349264705883,
      "grad_norm": 1.1012392044067383,
      "learning_rate": 4.505208333333334e-06,
      "loss": 0.0429,
      "step": 12943
    },
    {
      "epoch": 2.974264705882353,
      "grad_norm": 1.0983515977859497,
      "learning_rate": 4.504697712418301e-06,
      "loss": 0.0385,
      "step": 12944
    },
    {
      "epoch": 2.9744944852941178,
      "grad_norm": 0.9814823269844055,
      "learning_rate": 4.504187091503268e-06,
      "loss": 0.0542,
      "step": 12945
    },
    {
      "epoch": 2.9747242647058822,
      "grad_norm": 0.7593258023262024,
      "learning_rate": 4.503676470588236e-06,
      "loss": 0.037,
      "step": 12946
    },
    {
      "epoch": 2.974954044117647,
      "grad_norm": 1.9397011995315552,
      "learning_rate": 4.503165849673203e-06,
      "loss": 0.0585,
      "step": 12947
    },
    {
      "epoch": 2.9751838235294117,
      "grad_norm": 1.831876277923584,
      "learning_rate": 4.502655228758171e-06,
      "loss": 0.0393,
      "step": 12948
    },
    {
      "epoch": 2.9754136029411766,
      "grad_norm": 0.5285803079605103,
      "learning_rate": 4.502144607843138e-06,
      "loss": 0.0127,
      "step": 12949
    },
    {
      "epoch": 2.975643382352941,
      "grad_norm": 1.4746019840240479,
      "learning_rate": 4.501633986928105e-06,
      "loss": 0.0644,
      "step": 12950
    },
    {
      "epoch": 2.9758731617647056,
      "grad_norm": 1.0452076196670532,
      "learning_rate": 4.5011233660130725e-06,
      "loss": 0.0368,
      "step": 12951
    },
    {
      "epoch": 2.9761029411764706,
      "grad_norm": 0.69450443983078,
      "learning_rate": 4.5006127450980395e-06,
      "loss": 0.031,
      "step": 12952
    },
    {
      "epoch": 2.9763327205882355,
      "grad_norm": 0.953668475151062,
      "learning_rate": 4.5001021241830065e-06,
      "loss": 0.0309,
      "step": 12953
    },
    {
      "epoch": 2.9765625,
      "grad_norm": 1.4969069957733154,
      "learning_rate": 4.499591503267974e-06,
      "loss": 0.0457,
      "step": 12954
    },
    {
      "epoch": 2.9767922794117645,
      "grad_norm": 0.964821994304657,
      "learning_rate": 4.499080882352941e-06,
      "loss": 0.0442,
      "step": 12955
    },
    {
      "epoch": 2.9770220588235294,
      "grad_norm": 1.006399393081665,
      "learning_rate": 4.498570261437909e-06,
      "loss": 0.0286,
      "step": 12956
    },
    {
      "epoch": 2.9772518382352944,
      "grad_norm": 0.8464847803115845,
      "learning_rate": 4.498059640522876e-06,
      "loss": 0.0419,
      "step": 12957
    },
    {
      "epoch": 2.977481617647059,
      "grad_norm": 1.2756050825119019,
      "learning_rate": 4.497549019607843e-06,
      "loss": 0.0616,
      "step": 12958
    },
    {
      "epoch": 2.9777113970588234,
      "grad_norm": 0.6677843928337097,
      "learning_rate": 4.49703839869281e-06,
      "loss": 0.0245,
      "step": 12959
    },
    {
      "epoch": 2.9779411764705883,
      "grad_norm": 0.8716106414794922,
      "learning_rate": 4.496527777777778e-06,
      "loss": 0.0319,
      "step": 12960
    },
    {
      "epoch": 2.978170955882353,
      "grad_norm": 1.1037724018096924,
      "learning_rate": 4.496017156862745e-06,
      "loss": 0.0313,
      "step": 12961
    },
    {
      "epoch": 2.9784007352941178,
      "grad_norm": 0.5769269466400146,
      "learning_rate": 4.495506535947713e-06,
      "loss": 0.0255,
      "step": 12962
    },
    {
      "epoch": 2.9786305147058822,
      "grad_norm": 1.2224940061569214,
      "learning_rate": 4.49499591503268e-06,
      "loss": 0.0255,
      "step": 12963
    },
    {
      "epoch": 2.978860294117647,
      "grad_norm": 1.5425186157226562,
      "learning_rate": 4.494485294117648e-06,
      "loss": 0.0491,
      "step": 12964
    },
    {
      "epoch": 2.9790900735294117,
      "grad_norm": 1.2021517753601074,
      "learning_rate": 4.493974673202615e-06,
      "loss": 0.0594,
      "step": 12965
    },
    {
      "epoch": 2.9793198529411766,
      "grad_norm": 0.9962508082389832,
      "learning_rate": 4.493464052287582e-06,
      "loss": 0.0342,
      "step": 12966
    },
    {
      "epoch": 2.979549632352941,
      "grad_norm": 1.398228406906128,
      "learning_rate": 4.492953431372549e-06,
      "loss": 0.0456,
      "step": 12967
    },
    {
      "epoch": 2.9797794117647056,
      "grad_norm": 1.129431962966919,
      "learning_rate": 4.492442810457517e-06,
      "loss": 0.0446,
      "step": 12968
    },
    {
      "epoch": 2.9800091911764706,
      "grad_norm": 0.824573814868927,
      "learning_rate": 4.491932189542484e-06,
      "loss": 0.0461,
      "step": 12969
    },
    {
      "epoch": 2.9802389705882355,
      "grad_norm": 1.3329561948776245,
      "learning_rate": 4.491421568627452e-06,
      "loss": 0.0474,
      "step": 12970
    },
    {
      "epoch": 2.98046875,
      "grad_norm": 1.0120657682418823,
      "learning_rate": 4.490910947712419e-06,
      "loss": 0.0497,
      "step": 12971
    },
    {
      "epoch": 2.9806985294117645,
      "grad_norm": 1.6633410453796387,
      "learning_rate": 4.490400326797386e-06,
      "loss": 0.0372,
      "step": 12972
    },
    {
      "epoch": 2.9809283088235294,
      "grad_norm": 1.8080923557281494,
      "learning_rate": 4.489889705882353e-06,
      "loss": 0.0693,
      "step": 12973
    },
    {
      "epoch": 2.9811580882352944,
      "grad_norm": 0.754551351070404,
      "learning_rate": 4.489379084967321e-06,
      "loss": 0.0365,
      "step": 12974
    },
    {
      "epoch": 2.981387867647059,
      "grad_norm": 0.999086856842041,
      "learning_rate": 4.488868464052288e-06,
      "loss": 0.0462,
      "step": 12975
    },
    {
      "epoch": 2.9816176470588234,
      "grad_norm": 1.2514996528625488,
      "learning_rate": 4.4883578431372555e-06,
      "loss": 0.0456,
      "step": 12976
    },
    {
      "epoch": 2.9818474264705883,
      "grad_norm": 1.2262765169143677,
      "learning_rate": 4.4878472222222225e-06,
      "loss": 0.0492,
      "step": 12977
    },
    {
      "epoch": 2.982077205882353,
      "grad_norm": 1.1662131547927856,
      "learning_rate": 4.48733660130719e-06,
      "loss": 0.0545,
      "step": 12978
    },
    {
      "epoch": 2.9823069852941178,
      "grad_norm": 0.9708914160728455,
      "learning_rate": 4.486825980392157e-06,
      "loss": 0.033,
      "step": 12979
    },
    {
      "epoch": 2.9825367647058822,
      "grad_norm": 1.183350920677185,
      "learning_rate": 4.486315359477124e-06,
      "loss": 0.0385,
      "step": 12980
    },
    {
      "epoch": 2.982766544117647,
      "grad_norm": 1.0580953359603882,
      "learning_rate": 4.485804738562091e-06,
      "loss": 0.0336,
      "step": 12981
    },
    {
      "epoch": 2.9829963235294117,
      "grad_norm": 0.9610129594802856,
      "learning_rate": 4.485294117647059e-06,
      "loss": 0.0415,
      "step": 12982
    },
    {
      "epoch": 2.9832261029411766,
      "grad_norm": 0.8249691724777222,
      "learning_rate": 4.484783496732026e-06,
      "loss": 0.0346,
      "step": 12983
    },
    {
      "epoch": 2.983455882352941,
      "grad_norm": 1.0540093183517456,
      "learning_rate": 4.484272875816994e-06,
      "loss": 0.0393,
      "step": 12984
    },
    {
      "epoch": 2.9836856617647056,
      "grad_norm": 1.1439392566680908,
      "learning_rate": 4.483762254901961e-06,
      "loss": 0.0628,
      "step": 12985
    },
    {
      "epoch": 2.9839154411764706,
      "grad_norm": 1.7492945194244385,
      "learning_rate": 4.483251633986929e-06,
      "loss": 0.0446,
      "step": 12986
    },
    {
      "epoch": 2.9841452205882355,
      "grad_norm": 0.8160531520843506,
      "learning_rate": 4.482741013071896e-06,
      "loss": 0.0277,
      "step": 12987
    },
    {
      "epoch": 2.984375,
      "grad_norm": 0.8533651232719421,
      "learning_rate": 4.482230392156863e-06,
      "loss": 0.037,
      "step": 12988
    },
    {
      "epoch": 2.9846047794117645,
      "grad_norm": 0.9298462271690369,
      "learning_rate": 4.48171977124183e-06,
      "loss": 0.0421,
      "step": 12989
    },
    {
      "epoch": 2.9848345588235294,
      "grad_norm": 1.0536125898361206,
      "learning_rate": 4.481209150326798e-06,
      "loss": 0.0469,
      "step": 12990
    },
    {
      "epoch": 2.9850643382352944,
      "grad_norm": 0.8294172286987305,
      "learning_rate": 4.480698529411765e-06,
      "loss": 0.0405,
      "step": 12991
    },
    {
      "epoch": 2.985294117647059,
      "grad_norm": 0.8219180703163147,
      "learning_rate": 4.480187908496733e-06,
      "loss": 0.0325,
      "step": 12992
    },
    {
      "epoch": 2.9855238970588234,
      "grad_norm": 1.2271150350570679,
      "learning_rate": 4.4796772875817e-06,
      "loss": 0.0546,
      "step": 12993
    },
    {
      "epoch": 2.9857536764705883,
      "grad_norm": 0.605525016784668,
      "learning_rate": 4.479166666666667e-06,
      "loss": 0.0263,
      "step": 12994
    },
    {
      "epoch": 2.985983455882353,
      "grad_norm": 0.7217562198638916,
      "learning_rate": 4.478656045751634e-06,
      "loss": 0.0348,
      "step": 12995
    },
    {
      "epoch": 2.9862132352941178,
      "grad_norm": 0.6634719967842102,
      "learning_rate": 4.478145424836602e-06,
      "loss": 0.0353,
      "step": 12996
    },
    {
      "epoch": 2.9864430147058822,
      "grad_norm": 0.8790847063064575,
      "learning_rate": 4.477634803921569e-06,
      "loss": 0.0335,
      "step": 12997
    },
    {
      "epoch": 2.986672794117647,
      "grad_norm": 1.2950706481933594,
      "learning_rate": 4.477124183006537e-06,
      "loss": 0.0451,
      "step": 12998
    },
    {
      "epoch": 2.9869025735294117,
      "grad_norm": 0.8872159123420715,
      "learning_rate": 4.476613562091504e-06,
      "loss": 0.0232,
      "step": 12999
    },
    {
      "epoch": 2.9871323529411766,
      "grad_norm": 0.8256739377975464,
      "learning_rate": 4.4761029411764715e-06,
      "loss": 0.0354,
      "step": 13000
    },
    {
      "epoch": 2.9871323529411766,
      "eval_loss": 0.04393832013010979,
      "eval_runtime": 2005.7799,
      "eval_samples_per_second": 4.44,
      "eval_steps_per_second": 2.22,
      "step": 13000
    },
    {
      "epoch": 2.987362132352941,
      "grad_norm": 0.7438389658927917,
      "learning_rate": 4.4755923202614385e-06,
      "loss": 0.034,
      "step": 13001
    },
    {
      "epoch": 2.9875919117647056,
      "grad_norm": 0.9168144464492798,
      "learning_rate": 4.4750816993464055e-06,
      "loss": 0.0571,
      "step": 13002
    },
    {
      "epoch": 2.9878216911764706,
      "grad_norm": 0.7293013334274292,
      "learning_rate": 4.4745710784313725e-06,
      "loss": 0.031,
      "step": 13003
    },
    {
      "epoch": 2.9880514705882355,
      "grad_norm": 0.8220841884613037,
      "learning_rate": 4.47406045751634e-06,
      "loss": 0.0409,
      "step": 13004
    },
    {
      "epoch": 2.98828125,
      "grad_norm": 0.9727342128753662,
      "learning_rate": 4.473549836601307e-06,
      "loss": 0.0452,
      "step": 13005
    },
    {
      "epoch": 2.9885110294117645,
      "grad_norm": 1.144546627998352,
      "learning_rate": 4.473039215686275e-06,
      "loss": 0.0383,
      "step": 13006
    },
    {
      "epoch": 2.9887408088235294,
      "grad_norm": 1.014471173286438,
      "learning_rate": 4.472528594771242e-06,
      "loss": 0.0401,
      "step": 13007
    },
    {
      "epoch": 2.9889705882352944,
      "grad_norm": 0.7244170904159546,
      "learning_rate": 4.47201797385621e-06,
      "loss": 0.0314,
      "step": 13008
    },
    {
      "epoch": 2.989200367647059,
      "grad_norm": 0.9333207011222839,
      "learning_rate": 4.471507352941177e-06,
      "loss": 0.0559,
      "step": 13009
    },
    {
      "epoch": 2.9894301470588234,
      "grad_norm": 0.8613595962524414,
      "learning_rate": 4.470996732026144e-06,
      "loss": 0.0376,
      "step": 13010
    },
    {
      "epoch": 2.9896599264705883,
      "grad_norm": 0.8035822510719299,
      "learning_rate": 4.470486111111111e-06,
      "loss": 0.0442,
      "step": 13011
    },
    {
      "epoch": 2.989889705882353,
      "grad_norm": 1.191011905670166,
      "learning_rate": 4.469975490196079e-06,
      "loss": 0.0248,
      "step": 13012
    },
    {
      "epoch": 2.9901194852941178,
      "grad_norm": 1.5168354511260986,
      "learning_rate": 4.469464869281046e-06,
      "loss": 0.0352,
      "step": 13013
    },
    {
      "epoch": 2.9903492647058822,
      "grad_norm": 0.9615588188171387,
      "learning_rate": 4.468954248366014e-06,
      "loss": 0.0401,
      "step": 13014
    },
    {
      "epoch": 2.990579044117647,
      "grad_norm": 1.0763459205627441,
      "learning_rate": 4.468443627450981e-06,
      "loss": 0.0431,
      "step": 13015
    },
    {
      "epoch": 2.9908088235294117,
      "grad_norm": 1.0908528566360474,
      "learning_rate": 4.467933006535948e-06,
      "loss": 0.0422,
      "step": 13016
    },
    {
      "epoch": 2.9910386029411766,
      "grad_norm": 0.9433610439300537,
      "learning_rate": 4.467422385620915e-06,
      "loss": 0.0352,
      "step": 13017
    },
    {
      "epoch": 2.991268382352941,
      "grad_norm": 0.9770048260688782,
      "learning_rate": 4.466911764705883e-06,
      "loss": 0.0324,
      "step": 13018
    },
    {
      "epoch": 2.9914981617647056,
      "grad_norm": 0.7203168272972107,
      "learning_rate": 4.46640114379085e-06,
      "loss": 0.0337,
      "step": 13019
    },
    {
      "epoch": 2.9917279411764706,
      "grad_norm": 1.1385226249694824,
      "learning_rate": 4.465890522875818e-06,
      "loss": 0.0495,
      "step": 13020
    },
    {
      "epoch": 2.9919577205882355,
      "grad_norm": 0.8546443581581116,
      "learning_rate": 4.465379901960785e-06,
      "loss": 0.0318,
      "step": 13021
    },
    {
      "epoch": 2.9921875,
      "grad_norm": 1.1223349571228027,
      "learning_rate": 4.4648692810457526e-06,
      "loss": 0.0503,
      "step": 13022
    },
    {
      "epoch": 2.9924172794117645,
      "grad_norm": 1.3332772254943848,
      "learning_rate": 4.4643586601307196e-06,
      "loss": 0.0439,
      "step": 13023
    },
    {
      "epoch": 2.9926470588235294,
      "grad_norm": 0.8646920919418335,
      "learning_rate": 4.463848039215687e-06,
      "loss": 0.032,
      "step": 13024
    },
    {
      "epoch": 2.9928768382352944,
      "grad_norm": 1.1842597723007202,
      "learning_rate": 4.463337418300654e-06,
      "loss": 0.0499,
      "step": 13025
    },
    {
      "epoch": 2.993106617647059,
      "grad_norm": 0.8912604451179504,
      "learning_rate": 4.4628267973856215e-06,
      "loss": 0.0421,
      "step": 13026
    },
    {
      "epoch": 2.9933363970588234,
      "grad_norm": 0.8492463827133179,
      "learning_rate": 4.4623161764705885e-06,
      "loss": 0.0357,
      "step": 13027
    },
    {
      "epoch": 2.9935661764705883,
      "grad_norm": 0.9101549386978149,
      "learning_rate": 4.461805555555556e-06,
      "loss": 0.0346,
      "step": 13028
    },
    {
      "epoch": 2.993795955882353,
      "grad_norm": 0.9216589331626892,
      "learning_rate": 4.461294934640523e-06,
      "loss": 0.0399,
      "step": 13029
    },
    {
      "epoch": 2.9940257352941178,
      "grad_norm": 0.8875559568405151,
      "learning_rate": 4.460784313725491e-06,
      "loss": 0.0364,
      "step": 13030
    },
    {
      "epoch": 2.9942555147058822,
      "grad_norm": 0.8950324654579163,
      "learning_rate": 4.460273692810458e-06,
      "loss": 0.0376,
      "step": 13031
    },
    {
      "epoch": 2.994485294117647,
      "grad_norm": 0.8238549828529358,
      "learning_rate": 4.459763071895425e-06,
      "loss": 0.0332,
      "step": 13032
    },
    {
      "epoch": 2.9947150735294117,
      "grad_norm": 0.8744175434112549,
      "learning_rate": 4.459252450980392e-06,
      "loss": 0.0376,
      "step": 13033
    },
    {
      "epoch": 2.9949448529411766,
      "grad_norm": 0.9179202914237976,
      "learning_rate": 4.45874183006536e-06,
      "loss": 0.039,
      "step": 13034
    },
    {
      "epoch": 2.995174632352941,
      "grad_norm": 0.7888345122337341,
      "learning_rate": 4.458231209150327e-06,
      "loss": 0.0319,
      "step": 13035
    },
    {
      "epoch": 2.9954044117647056,
      "grad_norm": 1.3199241161346436,
      "learning_rate": 4.457720588235295e-06,
      "loss": 0.0506,
      "step": 13036
    },
    {
      "epoch": 2.9956341911764706,
      "grad_norm": 0.8100031018257141,
      "learning_rate": 4.457209967320262e-06,
      "loss": 0.0296,
      "step": 13037
    },
    {
      "epoch": 2.9958639705882355,
      "grad_norm": 0.8973710536956787,
      "learning_rate": 4.456699346405229e-06,
      "loss": 0.038,
      "step": 13038
    },
    {
      "epoch": 2.99609375,
      "grad_norm": 1.1039537191390991,
      "learning_rate": 4.456188725490196e-06,
      "loss": 0.0483,
      "step": 13039
    },
    {
      "epoch": 2.9963235294117645,
      "grad_norm": 0.7011679410934448,
      "learning_rate": 4.455678104575164e-06,
      "loss": 0.0229,
      "step": 13040
    },
    {
      "epoch": 2.9965533088235294,
      "grad_norm": 0.86702561378479,
      "learning_rate": 4.455167483660131e-06,
      "loss": 0.0368,
      "step": 13041
    },
    {
      "epoch": 2.9967830882352944,
      "grad_norm": 0.9205888509750366,
      "learning_rate": 4.454656862745099e-06,
      "loss": 0.0367,
      "step": 13042
    },
    {
      "epoch": 2.997012867647059,
      "grad_norm": 0.8394136428833008,
      "learning_rate": 4.454146241830066e-06,
      "loss": 0.0413,
      "step": 13043
    },
    {
      "epoch": 2.9972426470588234,
      "grad_norm": 1.0618600845336914,
      "learning_rate": 4.453635620915034e-06,
      "loss": 0.0459,
      "step": 13044
    },
    {
      "epoch": 2.9974724264705883,
      "grad_norm": 0.8265432715415955,
      "learning_rate": 4.453125000000001e-06,
      "loss": 0.0329,
      "step": 13045
    },
    {
      "epoch": 2.997702205882353,
      "grad_norm": 0.9579228162765503,
      "learning_rate": 4.452614379084968e-06,
      "loss": 0.0369,
      "step": 13046
    },
    {
      "epoch": 2.9979319852941178,
      "grad_norm": 1.6150827407836914,
      "learning_rate": 4.452103758169935e-06,
      "loss": 0.0863,
      "step": 13047
    },
    {
      "epoch": 2.9981617647058822,
      "grad_norm": 0.9981009364128113,
      "learning_rate": 4.451593137254902e-06,
      "loss": 0.0594,
      "step": 13048
    },
    {
      "epoch": 2.998391544117647,
      "grad_norm": 0.9028506278991699,
      "learning_rate": 4.4510825163398696e-06,
      "loss": 0.033,
      "step": 13049
    },
    {
      "epoch": 2.9986213235294117,
      "grad_norm": 1.1672929525375366,
      "learning_rate": 4.450571895424837e-06,
      "loss": 0.0375,
      "step": 13050
    },
    {
      "epoch": 2.9988511029411766,
      "grad_norm": 0.8932778835296631,
      "learning_rate": 4.4500612745098044e-06,
      "loss": 0.0367,
      "step": 13051
    },
    {
      "epoch": 2.999080882352941,
      "grad_norm": 1.6630184650421143,
      "learning_rate": 4.4495506535947715e-06,
      "loss": 0.0364,
      "step": 13052
    },
    {
      "epoch": 2.9993106617647056,
      "grad_norm": 0.9192806482315063,
      "learning_rate": 4.449040032679739e-06,
      "loss": 0.0409,
      "step": 13053
    },
    {
      "epoch": 2.9995404411764706,
      "grad_norm": 1.18869948387146,
      "learning_rate": 4.448529411764706e-06,
      "loss": 0.0477,
      "step": 13054
    },
    {
      "epoch": 2.9997702205882355,
      "grad_norm": 0.9645683765411377,
      "learning_rate": 4.448018790849673e-06,
      "loss": 0.0448,
      "step": 13055
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.8114604949951172,
      "learning_rate": 4.44750816993464e-06,
      "loss": 0.045,
      "step": 13056
    }
  ],
  "logging_steps": 1,
  "max_steps": 21760,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1075535664288727e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
